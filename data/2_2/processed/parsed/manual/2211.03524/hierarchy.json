{
    "elements": {
        "2211.03524_6d9af95a66a2a8d32115c4f2c2955b97": "Document Root 2211.03524",
        "2211.03524_708aede88adbc288358e60e7a474bb44": "=1",
        "2211.03524_e353dbe42c8654f33588d4da0b517469": "Abstract",
        "2211.03524_65b7321c781a2ae4d65b93e73ad79364": "Modern Review Helpfulness Prediction systems are dependent upon multiple modalities, typically texts and images",
        "2211.03524_b4cfc1f5f8c183453be058e62352e65a": "Unfortunately, those contemporary approaches pay scarce attention to polish representations of cross-modal relations and tend to suffer from inferior optimization",
        "2211.03524_835929b98c03989eefee7fb2a4fc4d96": "This might cause harm to modelâs predictions in numerous cases",
        "2211.03524_bdc60cb0f639772eae48432ec58f8d9a": "To overcome the aforementioned issues, we propose Multi-modal Contrastive Learning for Multimodal Review Helpfulness Prediction (MRHP) problem, concentrating on mutual information between input modalities to explicitly elaborate cross-modal relations",
        "2211.03524_e55ebf67794a6aa41adec17be99d1af1": "In addition, we introduce Adaptive Weighting scheme for our contrastive learning approach in order to increase flexibility in optimization",
        "2211.03524_a057417ffcb1060ab81a5cc4520aed75": "Lastly, we propose Multimodal Interaction module to address the unalignment nature of multimodal data, thereby assisting the model in producing more reasonable multimodal representations",
        "2211.03524_fea01ca36d17da47506476a7b2d4779a": "Experimental results show that our method outperforms prior baselines and achieves state-of-the-art results on two publicly available benchmark datasets for MRHP problem.",
        "2211.03524_0b79795d3efc95b9976c7c5b933afce2": "Introduction",
        "2211.03524_c10223451e0c18b5f4ee9732b7b69a57": "Current e-commerce sites such as Amazon, Ebay, etc., construct review platforms to collect user feedback concerning their products",
        "2211.03524_5b26e45cdff9b5c2dc69dd5f5aa22b78": "These platforms play a fundamental role in online transactions since they help future consumers collect useful reviews which assist them in deciding whether to make the purchase or not",
        "2211.03524_c80f71b0c45f4b6ca695ee9ea1a4d79a": "Unfortunately, nowadays the number of user-generated reviews is overwhelming, raising doubts related to the relevance and veracity of reviews",
        "2211.03524_bd1b67e19fc16f61d916ea494bb5c451": "Therefore, there is a need to verify the quality of reviews before publishing them to prospective customers",
        "2211.03524_abca67b46b21a1354d28639370a76df8": "As a result, this inspires a recent surge of interest targeting the Review Helpfulness Prediction (RHP) problem.",
        "2211.03524_e0b1364a938758ad9e909d13acbecc08": "\\begin{table}[h!]\n\\centering\n\\begin{tabular}{p{0.9\\linewidth}}\n% \\toprule\n\\textbf{Product Information} \\\\\n\\small{\nThe Cooks Standard 6-Quart Stainless Steel Stockpot with Lid is made with 18/10 stainless steel with an aluminum disc layered in the bottom. The aluminum disc bottom provides even heat distribution and prevents hot spots. Tempered glass lid with steam hole vent makes viewing food easy. Stainless steel riveted handles offer durability. Induction compatible. Works on gas, electric, glass, ceramic, etc. Oven safe to 500F, glass lid to 350F. Dishwasher safe.} \\\\\n\\includegraphics[width=0.3\\linewidth]{images/product_images/pic_4_0.jpg} \\includegraphics[width=0.3\\linewidth]{images/product_images/pic_4_1.jpg} \\\\\n\\midrule\n\\textbf{Review 1} \\\\\n\\small{\nI needed a stainless steel pot for canning my tomatoes.  I learned the hard way that you have to use a non-reactive pot or else your end result will be inedible (I thought I was using stainless steel but quickly realized it wasnt)  I headed to Amazon and came across this Cooks Standard SS Cookpot with cover and bought it after reading the reviews.  I have had it for just under a year and it still looks just as good as the day I bought it.  I couldn't be happier with my purchase!  Oh, and by the way, this one actually is stainless steel unlike the other pot I bought that said it was and wasn't.} \\\\\n% Label score: \\textbf{4} \\\\\n% MCR score: \\textbf{0.168} \\\\\n% Our Model score: \\textbf{4.651} \\\\\n\\midrule\n\\textbf{Review 2} \\\\\n\\small{\nI ordered it on May 21st. What a waste of time and money.} \\\\\n\\includegraphics[width=0.3\\linewidth]{images/review_images/pic_1_0.jpg} \\\\\n% Label score: \\textbf{1} \\\\\n% MCR score: \\textbf{3.637} \\\\\n% Our Model score: \\textbf{0.743} \\\\\n% \\bottomrule\n\\end{tabular}\n\\small\n\\begin{tabular}{ccc}\n\\toprule\n& Review 1 & Review 2 \\\\\n\\midrule\nLabel score & 4 & 1 \\\\\nMCR score & 0.168 & 3.637 \\\\\nOur Model score & \\textbf{4.651} & \\textbf{0.743} \\\\\n\\bottomrule\n\\end{tabular}\n\\caption{Example of unreasonable predictions in the Multimodal Review Helpfulness Prediction task.}\n\\label{table:example}\n\\vspace{-5mm}\n\\end{table}",
        "2211.03524_2abe0aec5f8e1418625ad6d0adbe22b0": "Two principal groups of early efforts focus on purely textual data",
        "2211.03524_5114adf7fc7abc3e8aea5a5a8ff9b710": "The first group follows feature engineering techniques, retrieving argument-based features",
        "2211.03524_c4e010f4c5632d68dc76a97c1f7199c8": "\\cite{liu2017using}",
        "2211.03524_7c6e47040ec4ec0743d8b2ed6894fdd9": ", lexical features",
        "2211.03524_510b62ebb57406da22671c7529f906ce": "\\cite{krishnamoorthy2015linguistic}",
        "2211.03524_b7582e1decd7fa6d75e39d738b8cf674": ", and semantic features",
        "2211.03524_1ec7e11c52dae56a066ee54f0ed8d2b6": "\\cite{kim2006automatically}",
        "2211.03524_326227012bf26e620c3f8d16268e976b": ", as input to their classifier",
        "2211.03524_94074deeb7132844ce03b278c2f39f1e": "Inherently, their methods are labor-intensive and vulnerable to the typical issues of conventional machine learning methods",
        "2211.03524_a849b4997fe6689bdf5949b1653b8654": "Instead of relying on manual features, the second group leverages deep neural models, for instance, RNN",
        "2211.03524_f6691406cda571d81bf5db9e3d11ff32": "\\cite{alsmadi2020predicting}",
        "2211.03524_028a1a22b53d5fca76f9c5cc4acd4fd2": "and CNN",
        "2211.03524_4798c6a6fac065cdd7f0aa5c37599b2a": "\\cite{chen2018cross}",
        "2211.03524_a6f8085963c630f147b68fc6d074005a": ", to learn rich features automatically",
        "2211.03524_f0a1d11bbaeb34d26baee7a07e3929c6": "Nonetheless, their approach is ineffective because the helpfulness of a review is not only contingent upon textual information but also other modalities",
        "2211.03524_c12ef666167dd5a18a25fab8908878e8": "To cope with the above issues, recent works",
        "2211.03524_2fdbf0daf9641ef0664fe61c05cd66a2": "\\cite{liu2021multi,han2022sancl}",
        "2211.03524_6f2fd9afa906f7cec3ff388a8bcb9d04": "proposed to utilize multi-modality via the Multi-perspective Coherent Reasoning (MCR) model",
        "2211.03524_5153208847bb048a3dcf3a8d2b4a3fdc": "Hypothesizing that a review is helpful if it exhibits coherent text and images with the product information, those works take into account both textual and visual modality of the inputs, then estimate their coherence level to discern whether the reviews are",
        "2211.03524_e81c4e4f2b7b93b481e13a8553c2ae1b": "or",
        "2211.03524_745772ff4463e10227beaec3089c6319": "However, the MCR model contains a detrimental drawback",
        "2211.03524_fb15335fe970946dbb5420700bd456fc": "Particularly, it aims to maximize the scores",
        "2211.03524_ba66d68eb9a990aafd4790736867038a": "$s_p$",
        "2211.03524_08186ed412cbd6c802ed3e7037180254": "of positive (helpful) product-review pairs while minimizing those",
        "2211.03524_aabe1517ce1102595512b736cbf264bb": "$s_n$",
        "2211.03524_448126902c751ef78e16b1e5133bfdc3": "of negative (unhelpful) pairs",
        "2211.03524_67df41a93f7fcdec36345bd802578bf9": "Hence, it was assumed that following the aforementioned manner would project features with similar semantics to stay close and those with disparate ones to be distant apart",
        "2211.03524_f4ad6143baad30fe78a5681ed7b03082": "Unfortunately, in multimodal learning, this was shown not to be the case, causing the model to learn ad-hoc representations",
        "2211.03524_e7a0c6b8c0ab38899ffa0d284e897cff": "\\cite{zolfaghari2021crossclr}",
        "2211.03524_63e625fba6407f7a19f47ae7ba1ab888": "This is one reason leading to unreasonable predictions of MCR in Table",
        "2211.03524_3f0cd42c015332ba18f0ba125d065a93": "As it can be seen, even though Review 1 closely relates to the product of",
        "2211.03524_226c2463fab716291f0e56d31dee39f0": ", the model classifies it as",
        "2211.03524_defd66ff5540373ac8aea4ecf9719a0c": "In addition, the target of Review 2âs text content is vague because it does not specifically correspond to the",
        "2211.03524_a2d62795398ed7a879936a55dcb3fe7d": "In fact, it can be used for any product",
        "2211.03524_5ecb27137c5c40f294dbb88c61348e8c": "Moreover, the image does not clearly show any hint of the",
        "2211.03524_ab256241aac70f922e45e2936a5a4770": "as well",
        "2211.03524_6bfae4ed4f5694bc3b525893859bc29c": "Despite such vagueness, the output of MCR for Review 2 is still",
        "2211.03524_fa25fd6b32312a7c7a2fa42d6098dda3": "As a remedy to this problem, we propose Cross-modal Contrastive Learning to mine the mutual information of cross-modal relations in the input to capture more sensible representations",
        "2211.03524_3f815a46e1635e351671e77be12bc104": "Nonetheless, plainly applying symmetric gradient pattern, which is similar to MCR that they assign equivalent penalty to",
        "2211.03524_be5d5d37542d75f93a87094459f76678": "and",
        "2211.03524_1a30e964ad51e71693d47ae48e4a5b60": ", is inflexible",
        "2211.03524_a4f891615b8e12abde1b1c712ddda73e": "In cases that",
        "2211.03524_ae1b6a69ae60ba63800667e8ed47882e": "is small and",
        "2211.03524_c65a217da5a031e3222492bfe4af93dc": "is already negatively skewed, or both",
        "2211.03524_965e43a737236b5a851abb1a056a9c8a": "are positively skewed, it is irrational to assign equivalent penalties to both",
        "2211.03524_0e3caff75557d68f7ded82ade2effb9e": "Last but not least, MCR directly leverages Coherent Reasoning, repeatedly enforcing alignment among modalities in the input",
        "2211.03524_e4fb16fd0e2ee61ea0da297956b4f1eb": "This ignores the unaligned nature of multimodal input, for example, images might only refer to a particular section in the text, hence do not completely align with the textual content",
        "2211.03524_cd12deaf0bfe16ccc10f20b0a7d3fd53": "In consequence, strictly forming alignment can make the model learn inefficient multimodal representations",
        "2211.03524_4fbf752170de41f8ed55f24942805fd4": "\\cite{tsai2019multimodal}",
        "2211.03524_d6b9ec4f8cddb7229cdc03175bc2d13c": "To overcome the above problems, we propose an adaptive scheme to accomplish the flexibility in the optimization of our contrastive learning stage",
        "2211.03524_82aa257a9b8fb7f155b8556934ff4e53": "Finally, we propose to adopt a multimodal attention module that reinforces one modalityâs high-level features with low-level ones of other modalities",
        "2211.03524_e964b1ab1fcb2481c36228b09f2df794": "This not only relaxes the alignment assumption but also informs one modality of information of others, encouraging refined representation learning",
        "2211.03524_7931ff12353cc34adedbfa1c10080344": "In sum, our contributions are three-fold:",
        "2211.03524_a8f65dd93445b90d34246cc201862695": "List (itemize)",
        "2211.03524_7d74f3b92b19da5e606d737d339a9679": "Item",
        "2211.03524_6f7d51813b47f0b9f4f0da190787d6f6": "We propose an Adaptive Cross-modal Contrastive Learning for Review Helpfulness Prediction task by polishing cross-modal relation representations.",
        "2211.03524_cc80a79c7927300ceaf9df1022f58bcb": "We propose a Multimodal Interaction module which correlates modalitiesâ features without depending upon the alignment assumption.",
        "2211.03524_7ab520c4cfd86dfd800ead379c4b6817": "We conducted extensive experiments on two datasets for the RHP problem and found that our method outperforms other baselines which are both textual-only and multimodal, and obtains state-of-the-art results on those benchmarks.",
        "2211.03524_d3d944395953c0de6d885982db1654c1": "Model Architecture",
        "2211.03524_29f85ae34c0f8741bbfb695e701dfcd5": "\\begin{figure*}[t]\n    \\centering\n    \\includegraphics[width=\\linewidth]{figures/fig_model.pdf}\n    \\caption{Diagram of our Multimodal Review Helpfulness Prediction model.}\n    \\label{fig:model}\n\\end{figure*}",
        "2211.03524_19fa406aef1e85c202a2e2cf561b800b": "In this section we delineate the overall architecture of our MRHP model",
        "2211.03524_1b6dd7e4cfb5fa9efcc0ae2808aa9f31": "Particular modules of our system are depicted in Figure",
        "2211.03524_5058f1af8388633f609cadb75a75dc9d": ".",
        "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe": "Problem Definition",
        "2211.03524_b872547bd17b83d987c3f484aebffdd9": "Given a product item",
        "2211.03524_2ec6e630f199f589a2402fdf3e0289d5": "$p$",
        "2211.03524_74bf553bb5cb404ed3c6d9b452ff6c3d": ", which consists of a description",
        "2211.03524_cf190f6d94a59f7eb276fc95dcb091a5": "$T^p$",
        "2211.03524_2abd21e10454a879d63f55dab19b2b1f": "and images",
        "2211.03524_510f2acb5ca51b8eb8432b683eb9f1d3": "$I^p$",
        "2211.03524_ca1738b49f3961baca3cbe9cafc2b7d3": ", and a set of reviews",
        "2211.03524_27aeb5ccf23a78c7c5460846dbb37fe1": "$R = \\{r_1,â¦, r_N\\}$",
        "2211.03524_2ed8a5cea4527e3547da57e124c12ce2": ", where each review is composed of user-generated text",
        "2211.03524_ccc455e82339a14a7ad0d373dbfd9bfd": "$T^r_i$",
        "2211.03524_56dd3026ecf108103e0a1cf5158d89d0": "$I^r_i$",
        "2211.03524_7a6cfaf61548e1bf4538a1888d6f3e88": ", RHP modelâs task is to generate the scores",
        "2211.03524_635f47adc7d00049f722f776fac45266": "\\begin{equation}\n    s_i = f(p, r_i), \\quad 1 \\leq i \\leq N\n\\end{equation}",
        "2211.03524_567904efe9e64d9faf3e41ef402cb568": "where",
        "2211.03524_f9c4988898e7f532b9f826a75014ed3c": "$N$",
        "2211.03524_b64eba476e1d09ef8dd0e63fd809e29e": "is the number of reviews for product",
        "2211.03524_190083ef7a1625fbc75f243cffb9c96d": "$f$",
        "2211.03524_0f0f6efffb51ae375c425db4e0ce91ff": "is the scoring function of the RHP model",
        "2211.03524_ae5d0f370468314570c04f60745cfcca": "Empirically, each score estimated by",
        "2211.03524_fab2d45efd926f2faf3cc20d425b6f38": "indicates the helpfulness level of each review, and the ground-truth is the descending sort order of helpfulness scores.",
        "2211.03524_2a44187d78593138f279fac225ae3d61": "Encoding Modules",
        "2211.03524_7d5d1652c4b3c4e181bb03c2bd2a3ca4": "Our model accepts product description",
        "2211.03524_7b1f450c2dc51b73da5b35080b7a9b6c": ", product images",
        "2211.03524_1bfae9b14eb4b21ddad93740415d1788": ", review text",
        "2211.03524_3f23c2488a25d7dc5d5e59673fb775c2": ", and review images",
        "2211.03524_7279bff3a9816e133796d853089254e6": "as input",
        "2211.03524_f0bf7e1774b7ccc1d3ee4fe011bd1b3a": "The encoding process of those elements is described as follows.",
        "2211.03524_5ab10c1197274918c30b313abbc6cc63": "Product description and review text are sequences of words",
        "2211.03524_6939ae2cab0949f3ff8d1a3d04fe8067": "Each sequence is indexed into the word embedding layer and then passed into the respective LSTM layer for product or review.",
        "2211.03524_123da0a65cb18a49a4bf484695ac5152": "K^p =",
        "2211.03524_fbe2accac3e37a150710e32bb7e7800a": "^p (",
        "2211.03524_b14a7b8059d9c055954c92674ce60032": "_",
        "2211.03524_8d9a1ce7ef3148e7502875a18d1bd0a0": "(T^p))",
        "2211.03524_ebe3551425450e9850fa1f21a38b3d72": "K^r =",
        "2211.03524_18dabfa0970bcde267fa6bc35b26d064": "^r (",
        "2211.03524_19d9977a91b00463c72c584bcea066f5": "(T^r))",
        "2211.03524_2c0b42c913dd0fade191a612ed3728cf": "$K^p \\in \\mathbb{R}^{l_p \\times d}$",
        "2211.03524_c0cb5f0fcf239ab3d9c1fcd31fff1efc": ",",
        "2211.03524_27d790a6e667a77a6db4eb6046c1d6df": "$K^r \\in \\mathbb{R}^{l_r \\times d}$",
        "2211.03524_247ca9d8cf371e16f3db4442254b82af": "$l_p$",
        "2211.03524_0d97f4b752272b2c27b01feef8a05c90": "$l_r$",
        "2211.03524_0ada0e62e5a4f921051419e195c3f707": "are the sequence lengths of product and review text respectively, and",
        "2211.03524_2103f85b8b1477f430fc407cad462224": "$d$",
        "2211.03524_41490f763aff8d86d072e0979f8f5b55": "is the hidden size.",
        "2211.03524_00bbd95ed734afc6f9d81774219f4867": "We follow",
        "2211.03524_b9a47b3f50d13d4af048143fcb35850f": "\\citet{anderson2018bottom}",
        "2211.03524_acbc4ca2cd262510f43b44abc3afe470": "to take detected objects as embeddings of the image",
        "2211.03524_a6aebf93d3259929d77b90dd561e0f31": "In particular, a pre-trained Faster R-CNN is applied to extract ROI features for",
        "2211.03524_0e51a2dede42189d77627c4d742822c3": "$m$",
        "2211.03524_5891da2d64975cae48d175d1e001f5da": "objects",
        "2211.03524_10014044fc0bc5f93592dfc858f8813d": "$\\{\\mathbf{a}_1, \\mathbf{a}_2, â¦, \\mathbf{a}_m\\}$",
        "2211.03524_626ca6f855d08f7c22de1485a8f2906b": "from the product and review images",
        "2211.03524_8c74cb9f14046239e8022733f7598f26": "Subsequently, we encode extracted features using the self-attention module (SelfAttn)",
        "2211.03524_2fdb4d0205b168a4fc84398a3e37cd72": "\\cite{vaswani2017attention}",
        "2211.03524_2b8011e962697b7ca36692f92c4200a2": "\\begin{equation}\n    A = \\text{SelfAttn}(\\{\\mathbf{a}_1, \\mathbf{a}_2, ..., \\mathbf{a}_m\\})\n\\end{equation}",
        "2211.03524_b11c2ca1869dd4e9116defdfc8230139": "$A \\in \\mathbb{R}^{m \\times d}$",
        "2211.03524_36abe1bb3059514a94218980445e74a3": "is the hidden size",
        "2211.03524_a6ca8cfe924069c054b100e2103515f4": "Here we use",
        "2211.03524_ccb1f38f0c2d0afbf5db6ae95d952e04": "$A^p$",
        "2211.03524_7714fde4c6b7d01381cddbc18456244a": "$A^r$",
        "2211.03524_89c8a969ae84df7438227dd380adac2b": "to indicate product and review image features, respectively.",
        "2211.03524_d3c78727bfe27cc8c5e4299732545547": "Multimodal Interaction Module",
        "2211.03524_a4b332cc02b18a29c5cce6b352726d67": "We consider two components",
        "2211.03524_11c596de17c342edeed29f489aa4b274": "$\\gamma$",
        "2211.03524_1d0496971a2775f4887d1df25cea4f7e": "$\\eta$",
        "2211.03524_9dcfa68d289b63848c4d5d75f7f63eb9": "with their inputs",
        "2211.03524_915787506d91edc9ebf4309663447792": "$X_\\gamma$",
        "2211.03524_f9780a6cd3f8979e127f2334de9f9a8a": "$X_\\eta$",
        "2211.03524_a29f17caa3e965b909d1aef183a202e4": ", where",
        "2211.03524_b22e46b54b9ad07c7b2b1a57ad30425f": "is the concatenation of input elements apart from the one in",
        "2211.03524_d10d7300ace26fa99e46be8f100fdeec": "For instance, if",
        "2211.03524_053ea152b451065d48bd6894b1373837": "$\\gamma = {K^p}$",
        "2211.03524_fb4f3b79910c6656439b97f695d3f658": ", then",
        "2211.03524_7b1cb7ec3681931f982088c8de8278a6": "$\\eta = [K^r, A^p, A^r]$",
        "2211.03524_513b5d2c3e507906c33431f230fde0fa": "$[., .]$",
        "2211.03524_ce4a591b0be792861f20b1b9924fb9c2": "indicates the concatenation operation",
        "2211.03524_2977befd992a498349651c15f8a49daf": "We define each cross-modal attention block to have three components",
        "2211.03524_1afcdb0f704394b16fe85fb40c45ca7a": "$Q$",
        "2211.03524_d6328eaebbcd5c358f426dbea4bdbf70": "$K$",
        "2211.03524_8a0e2b549d223aba55a866c38d1c9275": ", and",
        "2211.03524_a9a3a4a202d80326bda413b5562d5cd1": "$V$",
        "2211.03524_853ae90f0351324bd73ea615e6487517": ":",
        "2211.03524_7cd9c4c3344f1c6d7924b621ff783506": "Q_",
        "2211.03524_4ef60a5fa5ad51be21a63d5065e7e63f": "= X_",
        "2211.03524_81b675fa9e743d769acb92496e626e53": "W_",
        "2211.03524_59ba51e11a31bcb6417fb512003ac3de": "K_",
        "2211.03524_90a6edf15b9fbcd8ccd9383ad593f8c2": "V_",
        "2211.03524_93d6e6c9cd603bc19125faeab0b7aefd": "$W_{Q_\\gamma} \\in \\mathbb{R}^{d_\\gamma \\times d_k}$",
        "2211.03524_253f9f126e1e672ff9b07f0451886e3a": "$W_{K_\\eta} \\in \\mathbb{R}^{d_\\eta \\times d_k}$",
        "2211.03524_41dc8de0ae38f44c55458505946a9722": "$W_{V_\\eta} \\in \\mathbb{R}^{d_\\eta \\times d_v}$",
        "2211.03524_301da3cbc3f0e1c54e0bba43d9ca9ebf": "are weight matrices",
        "2211.03524_4120691b29a334a29d95e9af083b75da": "The interaction between",
        "2211.03524_ebc761027dc39560e7be51f832f41558": "is computed in the cross-attention manner",
        "2211.03524_64eb0d7486337a16d5c489291981397b": "\\begin{equation}\n    \\begin{split}\n        Z_\\gamma = \\text{CM}_{\\gamma} (X_\\gamma, X_\\eta)\n        = \\text{softmax} \\left(\\frac{Q_\\gamma \\cdot K^T_{\\eta}}{\\sqrt{d_k}}\\right) \\cdot V_\\eta\n    \\end{split}\n\\end{equation}",
        "2211.03524_224367653c24d452073ad9ba9f20c67c": "Our full module comprises",
        "2211.03524_78ec2b7008296ce0561cf83393cb746d": "$D$",
        "2211.03524_949cf3ae4a8ea9932713a1a029dbd12d": "layers of the above-mentioned attention block, as indicated in the right part of Figure",
        "2211.03524_c06853578d5402a0bdacbd60a1b96fd4": "Theoretically, the computation is carried out as follows",
        "2211.03524_fe40ec2bc207cc92133c8b3deb669acc": "[0] = X_",
        "2211.03524_700b7f3f3b74b1b95c701e0b30b4b20d": "T[i] =",
        "2211.03524_12a7d949440a58ec3b336da4dbf81b5e": "[i] (",
        "2211.03524_e8ec656b1b1b25f1e7b1965edad53314": "(Q_",
        "2211.03524_3b5009de2f2eb82416b690a2b0b92b9a": "[i-1]),",
        "2211.03524_42534ccbc88518484411932a3776e584": "(X_",
        "2211.03524_196b8e67d3bb60511f084eb205293069": "))",
        "2211.03524_d2ef12fa0b4947a68e1df4696645891c": "U_",
        "2211.03524_e1bd9c1288ed8b59c04af124009b7369": "[i] = T[i] + Q_",
        "2211.03524_2e9c273d6519389c94ca4629edc0e64d": "[i-1]",
        "2211.03524_b3e77481b595b641bcd3daea10007f24": "[i] =",
        "2211.03524_84c40473414caf2ed4a7b1283e48bbf4": "(",
        "2211.03524_cda04cae6ec457611db4c9d43b8c1479": "(U_",
        "2211.03524_df4e0035b3899165c827c11902261367": "[i]))",
        "2211.03524_d41a1c2dfb6b7aa12089330b8584ed52": "$\\textit{LN}$",
        "2211.03524_4c00dbdaf32c048274e88be77d561b8f": "denotes layer normalization operator",
        "2211.03524_acc2bb77450a0e3bf56c2881b0eb575b": "We iteratively estimate cross-modal features for product text, product images, review text, and review images with a view to obtaining",
        "2211.03524_8e521161895f9b5d456dd9022b002ee1": "$H^p$",
        "2211.03524_7c99f0ab7a4085aa6d9bc7d39aa95cc3": "$V^p$",
        "2211.03524_ff79e78cdb7f88d5aaf52d1c4d034735": "$H^r$",
        "2211.03524_db9ec36a50879de8a3170ac5f9d19b77": "$V^r$",
        "2211.03524_9b0028550273f126bc2f47c11c48152b": "H^p = Q^p_k[D],",
        "2211.03524_fe2115f710dd32f6ae6980577437516d": "V^p = Q^p_a[D]",
        "2211.03524_482b25ccdcbe48d3d4a2770eb85bcd16": "H^r = Q^r_k[D],",
        "2211.03524_0f34db4e3701432b8688c35b8b68d30f": "V^r = Q^r_a[D]",
        "2211.03524_9a7283ebdb9b065770ddb694f7153260": "After our cross-modal interaction module, we proceed to pass features to undertake relation fusion in three paths: intra-modal, inter-modal, and intra-review.",
        "2211.03524_6c648e511827def6e147585c4033d9b0": "The intra-modal alignment is calculated for two relation kinds: (1) product text - review text and (2) product image - review image",
        "2211.03524_005573a93a67f7255e6529fa392e4f6e": "Firstly, we learn alignment among intra-modal features via self-attention modules",
        "2211.03524_c619c487af65289bd6267227de82b937": "H^",
        "2211.03524_43ec3e5dee6e706af7766fffea512721": "=",
        "2211.03524_6266e1e9410a052e5266156d98408607": "([H^p, H^r])",
        "2211.03524_1b6c985b5902d2f01d5956a3b8db70ec": "V^",
        "2211.03524_8ebd4a6001a1d8a971f7781ebbc564ae": "([V^p, V^r])",
        "2211.03524_c5d70cde28bbd096512dde85a412b63f": "Then intra-modal hidden representations are fed to a CNN, and continuously a max-pooling layer to attain salient entries",
        "2211.03524_ba5010c82f7507179105d5ad40a040e3": "\\begin{equation}\n    \\mathbf{z}^\\text{intraM} = \\text{MaxPool} (\\text{CNN}([H^{\\text{intraM}}, V^{\\text{intraM}}]))\n\\end{equation}",
        "2211.03524_dc058eb32e9ff85d34c067ddd079ad34": "Similar to intra-modal alignment, inter-modal one is calculated for two types of relations as well: (1) product text - review image and (2) product image - review text",
        "2211.03524_54271eaf8f3737a0821e394e3075a515": "The first step is also to relate feature components using self-attention modules",
        "2211.03524_c9f6e2806601c9352928a7877cf17290": "([H^p, V^r])",
        "2211.03524_0119500665a667bc80d24869e4ff059c": "([V^p, H^r])",
        "2211.03524_ea93022480bdbeac5cc6b1ac00d8da40": "We adopt a mean-pool layer to aggregate inter-modal features and then concatenate the pooled vectors to construct the final inter-modal representation",
        "2211.03524_5e826beae830db9e2e236aef30ab3590": "I^",
        "2211.03524_a3cff49d6c21596624ef2f4d3624329c": "(H^",
        "2211.03524_9371d7a2e3ae86a00aab4771e39d255d": ")",
        "2211.03524_7e6a2afe551e067a75fafacf47a6d981": "^",
        "2211.03524_6e047dbb7eeecacd1fd7d34a32e0a942": "= [I^",
        "2211.03524_51c8eadb081f25d165b23e78c56b15cd": ", I^",
        "2211.03524_0fbd1776e1ad22c59a7080d35c7fd4db": "]",
        "2211.03524_1d167807e05e83916cf0768977f058f8": "The estimation of intra-review module completely mimics the inter-modal manner",
        "2211.03524_ee849ff35521100b41030846a66045ae": "The only discrimination is that the estimation is taken upon two different relations: (1) product text - product image and (2) review text - review image.",
        "2211.03524_f36bfc56f3be257a02720c3c862aa89f": "([H^p, V^p])",
        "2211.03524_1a761b1a2f99c8fe702436f021b1f6b4": "([H^r, V^r])",
        "2211.03524_f30639fbb1c77c2934a00975b33a81b3": "G^",
        "2211.03524_21365cd605386936488d14a793f37139": "= [G^",
        "2211.03524_7b672cd8994320ecd5f4951865a1bd66": ", G^",
        "2211.03524_4439cd0529504b19b6d522c0ada0d6c0": "Finally, we concatenate intra-modal, inter-modal, and intra-review output, and then feed the concatenated vector to the linear layer to obtain the ranking score:",
        "2211.03524_24bf8bd6e9b9cb047396f662d56a8f63": "= [",
        "2211.03524_dd177a923b099610383c2a2f7aac5887": "f(p,r_i) =",
        "2211.03524_2d94e9e57bff93acb26d60251d69e97e": "Training Strategies",
        "2211.03524_181db63079b74fe95ba190fa64d9cbb4": "Adaptive Cross-modal Contrastive Learning",
        "2211.03524_534fbd0711dcf88c8ca609ce779bc351": "In this section, we explain the formulation and adaptive pattern along with its derivation of our Cross-modal Contrastive Learning.",
        "2211.03524_476521a4ccd843bc06b60d55c0eb88e7": "First of all, we extract hidden states of helpful product-review pairs",
        "2211.03524_5354514233dd5852065a1ea81243f30c": "Second of all, hidden features are max-pooled to extract meaningful entries.",
        "2211.03524_a2a9ccc59907254f5f4a3320e62aa06d": "^p =",
        "2211.03524_7ee9e6364f9d29fdca80025ee951985d": "(H^p),",
        "2211.03524_cb0eb7509736e32e7dc242466a4411ca": "^r =",
        "2211.03524_ba3283ca4872487c8e167b85c13a6850": "(H^r)",
        "2211.03524_5818059f70f734538d8467d3d8437f6a": "(V^p),",
        "2211.03524_4bad86f7d95dded1568ab9e22960f90e": "(V^r)",
        "2211.03524_93ae29432fcd73a425f0addef25e6064": "We formulate our contrastive learning framework taking positive and negative pairs from the above-mentioned cross-modal features",
        "2211.03524_babfbbb729ce0ba996785e1b12d4c58b": "In our framework, we hypothesize that pairs established by modalities of the same sample are positive, whereas those formed by modalities of distinct ones are negative.",
        "2211.03524_c81f48ecd935347fd20655f7077e1cc2": "\\begin{equation}\n    \\mathcal{L}_{\\text{CE}} = -\\sum_{i=1}^{B} \\text{sim}(\\mathbf{t}^1_i, \\mathbf{t}^2_i) +  \\sum_{j=1, k=1, j \\neq k}^{B} \\text{sim}(\\mathbf{t}_j^{1}, \\mathbf{t}_k^{2})\n\\end{equation}",
        "2211.03524_bb6ca6c89727d01de14dfac4c2a73421": "$\\mathbf{t}^1, \\mathbf{t}^2 \\in \\{\\mathbf{h}^p, \\mathbf{h}^r, \\mathbf{v}^p, \\mathbf{v}^r\\}$",
        "2211.03524_61e84f854bc6258d4108d08d4c4a0852": "$B$",
        "2211.03524_3a0f08f4fbfffbf0ea8a83d5d6612cb1": "denotes the batch size in the training process.",
        "2211.03524_c8180bfe1a7d2bbaef9d8251516fc0a2": "The standard contrastive objective suffers from inflexible optimization due to irrational gradient assignment to positive and negative pairs",
        "2211.03524_bbc2eade11f67e31fb0b44e11420d91e": "As a result, to tackle the problem, we propose the Adaptive Weighting Strategy for our contrastive framework",
        "2211.03524_0bdbae768273714dc9d7fb6e29210ba3": "Initially, we introduce weights",
        "2211.03524_11fb4b8a7a6422f7615096150ec36a07": "$\\epsilon^p$",
        "2211.03524_d952a0f2a8495c60002d2705f542fd16": "$\\epsilon^n$",
        "2211.03524_7e29a08876e0803b9015193a218111df": "to represent distances from the optimum, then integrate them into positive and negative terms of our loss.",
        "2211.03524_23069c37667a080b8d6a8c09ca0c587b": "\\begin{equation}\n\\begin{split}\n    &\\mathcal{L}_{\\text{AdaptiveCE}} = -\\sum_{i=1}^{B} \\epsilon^p_i \\cdot \\text{sim}(\\mathbf{t}^1_i, \\mathbf{t}^2_i) \\\\\n    &+ \\sum_{j=1, k=1, j \\neq k}^{B} \\epsilon_{j,k}^n \\cdot \\text{sim}(\\mathbf{t}_j^{1}, \\mathbf{t}_k^{2})\n\\end{split}\n\\label{eq:adaptive_ce}\n\\end{equation}",
        "2211.03524_98d010141e93b94948f5c1bdc3ea1c79": "$\\epsilon_i^p = [o^p - \\text{sim}(\\mathbf{t}^1_i, \\mathbf{t}^2_i)]_+$",
        "2211.03524_52ed0ddc3096f0c5e619c7da760b8b80": "$\\epsilon_{j,k}^n = [\\text{sim}(\\mathbf{t}^1_j, \\mathbf{t}^2_k) - o^n]_+$",
        "2211.03524_63e1438acaa0e812984ebe083a0f3950": "Investigating the intuition to determine the values for",
        "2211.03524_18dcb9aec32468241d6e192142d5ed9f": "$o^p$",
        "2211.03524_95ec06a7fc34421fcee675a3a167fa79": "$o^n$",
        "2211.03524_19634fc0143725dc6bb3765e4ba3ea90": ", we continue to conduct derivation and arrive in the following theorem",
        "2211.03524_28b423b3e84a6dcbc088ae1b14abcab3": "Adaptive Contrastive Loss (",
        "2211.03524_57207979d57274c38d03d005805d234e": ") has the hyperspherical form:",
        "2211.03524_e5cf03e24124c1c587ddd6fa4fc1c612": "\\begin{equation*}\n    \\begin{split}\n       &\\mathcal{L}_{\\text{AdaptiveCE}} = \\sum_{i=1}^{B} \\left(\\text{sim} (\\mathbf{t}^1_i, \\mathbf{t}^2_i) - \\frac{o^p}{2}\\right)^2 \\\\\n       &+ \\sum_{j=1, k=1, j \\neq k}^{B} \\left(\\text{sim} (\\mathbf{t}^1_j, \\mathbf{t}^2_k) - \\frac{o^n}{2}\\right)^2 - C, \\\\\n       &\\quad \\text{where} \\, C > 0         \n    \\end{split}\n\\end{equation*}",
        "2211.03524_870c423cce2561a13b3d705f9c4c1a5f": "We provide the proof for Theorem (",
        "2211.03524_bc170999e675977a518d7376c8533c2a": ") in the Appendix section",
        "2211.03524_f23ed61f998917b34b8a34ddd383e090": "As a consequence, theoretically the contrastive objective arrives in the optimum when",
        "2211.03524_0abb2294e277488ac8058ed69e7a1017": "$\\text{sim}(\\mathbf{t}_i^1, \\mathbf{t}_i^2) = \\frac{o^p}{2}$",
        "2211.03524_b06466e6b68d453b5c2291f9f652f493": "$\\text{sim}(\\mathbf{t}_j^1, \\mathbf{t}_k^2) = \\frac{o^n}{2}$",
        "2211.03524_51810f33437ccd1e173df96fc9829ff4": "Based upon this observation, in our experiments we set",
        "2211.03524_9923970f09bc2c40eb68730777195e45": "$o^p = 2$",
        "2211.03524_53006e8bf32d363f5dd72a552cf2e884": "$o^n = 0$",
        "2211.03524_9d01c264e0abd10873f1798378f9e799": "Training Objective",
        "2211.03524_c68d9e0e0243a64ad489d24b7313ff61": "For the Review Helpfulness Prediction problem, the modelâs parameters are updated according to the pairwise ranking loss as follows",
        "2211.03524_de688f8d2b603a1c09b7d7b7ab9c4316": "\\begin{equation}\n    \\mathcal{L}_{\\text{ranking}} = \\sum_i \\text{max} (0, \\beta - f(p_i, r^{+}) + f(p_i, r^{-}))\n\\end{equation}",
        "2211.03524_9b08333396b6df91aefd2d51630581ac": "$r^{+}$",
        "2211.03524_0eddd2a9eb13177117e92bb524d62379": "$r^{-}$",
        "2211.03524_4c30a5a9a92c33a2f27cd09ec1d238ed": "are random reviews in which",
        "2211.03524_4c9057c5951288619aa3444ecb6cdbe2": "possesses a higher helpfulness level than",
        "2211.03524_e582caf96bd4bd4baf89bf4c96b64691": "We jointly combine the contrastive goal with the ranking objective of the Review Helpfulness Prediction problem to train our model",
        "2211.03524_005368ad99037db26a7daa3d472d0f2e": "\\begin{equation}\n    \\mathcal{L} = \\mathcal{L}_\\text{AdaptiveCE} + \\mathcal{L}_\\text{ranking}\n\\end{equation}",
        "2211.03524_4829262cecb9828817b33e0f9c907f91": "Experiments",
        "2211.03524_e3a2d4d4fc002f90824eacce38cd67e7": "\\begin{table}[ht]\n\\centering\n\\resizebox{\\linewidth}{!}{\n\\begin{tabular}{l|l|ccc}\n\\toprule\n\\multirow{2}{*}{\\textbf{Dataset}} & \\multirow{2}{*}{\\textbf{Split}} & \\multicolumn{3}{c}{\\textbf{Category (Product / Review)}} \\\\ \n& & Clothing & Electronics. & Home \\\\\n\\midrule\n \\multirow{2}{*}{Lazada} & Train \\& Dev & 8K/130K & 5K/52K & 4K/16K  \\\\\n  & Test & 2K/32K & 1K/13K & 1K/13K \\\\\n\\midrule\n \\multirow{2}{*}{Amazon} & Train \\& Dev & 16K/349K & 13K/325K & 18K/462K  \\\\\n  & Test & 4K/87K & 3K/80K & 5K/111K \\\\\n \\bottomrule\n\\end{tabular} }\n\\caption{\nStatistics of MRHP datasets.}\n\\label{table:datasets}\n\\end{table}",
        "2211.03524_f0536dd4df99776762a028f15f4e8faf": "\\begin{table*}[t]\n\\centering\n\\resizebox{1\\textwidth}{!}{\n\\begin{tabular}{|l|l|ccc|ccc|ccc|}\n\\toprule\n\\multirow{2}{*}{\\textbf{Type}} & \\multirow{2}{*}{\\textbf{Method}} & \\multicolumn{3}{c|}{\\textbf{Clothing}} & \\multicolumn{3}{c|}{\\textbf{Electronics}} & \\multicolumn{3}{c|}{\\textbf{Home}} \\\\ \n &  & \\textbf{MAP} & \\textbf{N@3} & \\textbf{N@5} & \\textbf{MAP} & \\textbf{N@3} & \\textbf{N@5} & \\textbf{MAP} & \\textbf{N@3} & \\textbf{N@5} \\\\\n\\midrule\n\\multirow{4}{*}{Text-only} & BiMPM & 60.0 & 52.4 & 57.7 & 74.4 & 67.3 & 72.2 & 70.6 & 64.7 & 69.1 \\\\\n & EG-CNN & 60.4 & 51.7 & 57.5 & 73.5 & 66.3 & 70.8 & 70.7 & 63.4 & 68.5 \\\\\n & Conv-KNRM & 62.1 & 54.3 & 59.9 & 74.1 & 67.1 & 71.9 & 71.4 & 65.7 & 70.5 \\\\\n & PRH-Net & 62.1 & 54.9 & 59.9 & 74.3 & 67.0 & 72.2 & 71.6 & 65.2 & 70.0 \\\\\n\\midrule\n\\multirow{4}{*}{Multimodal} & SSE-Cross & 66.1 & 59.7 & 64.8 & 76.0 & 68.9 & 73.8 & 72.2 & 66.0 & 71.0 \\\\\n & DR-Net & 66.5 & 60.7 & 65.3 & 76.1 & 69.2 & 74.0 & 72.4 & 66.3 & 71.4 \\\\\n & MCR & 68.8 & 62.3 & 67.0 & 76.8 & 70.7 & 75.0 & 73.8 & 67.0 & 72.2 \\\\\n & \\textbf{Our Model} & \\textbf{70.3} & \\textbf{64.7} & \\textbf{69.0} & \\textbf{78.2} & \\textbf{72.4} & \\textbf{76.5} & \\textbf{75.2} & \\textbf{68.8} & \\textbf{73.7} \\\\\n\\bottomrule\n\\end{tabular} }\n\\caption{\nHelpfulness Prediction results on Lazada-MRHP dataset.}\n\\label{table:lazada_results}\n\\end{table*}",
        "2211.03524_9cc1a26ee1adb640cf64b759d14ab9f4": "\\begin{table*}[t]\n\\centering\n\\resizebox{1\\textwidth}{!}{\n\\begin{tabular}{|l|l|ccc|ccc|ccc|}\n\\toprule\n\\multirow{2}{*}{\\textbf{Type}} & \\multirow{2}{*}{\\textbf{Method}} & \\multicolumn{3}{c|}{\\textbf{Clothing}} & \\multicolumn{3}{c|}{\\textbf{Electronics}} & \\multicolumn{3}{c|}{\\textbf{Home}} \\\\ \n &  & \\textbf{MAP} & \\textbf{N@3} & \\textbf{N@5} & \\textbf{MAP} & \\textbf{N@3} & \\textbf{N@5} & \\textbf{MAP} & \\textbf{N@3} & \\textbf{N@5} \\\\\n\\midrule\n\\multirow{4}{*}{Text-only} & BiMPM & 57.7 & 41.8 & 46.0 & 52.3 & 40.5 & 44.1 & 56.6 & 43.6 & 47.6 \\\\\n & EG-CNN & 56.4 & 40.6 & 44.7 & 51.5 & 39.4 & 42.1 & 55.3 & 42.4 & 46.7 \\\\\n & Conv-KNRM & 57.2 & 41.2 & 45.6 & 52.6 & 40.5 & 44.2 & 57.4 & 44.5 & 48.4 \\\\\n & PRH-Net & 58.3 & 42.2 & 46.5 & 52.4 & 40.1 & 43.9 & 57.1 & 44.3 & 48.1 \\\\\n\\midrule\n\\multirow{4}{*}{Multimodal} & SSE-Cross & 65.0 & 56.0 & 59.1 & 53.7 & 43.8 & 47.2 & 60.8 & 51.0 & 54.0 \\\\\n & DR-Net & 65.2 & 56.1 & 59.2 & 53.9 & 44.2 & 47.5 & 61.2 & 51.8 & 54.6 \\\\\n & MCR & 66.4 & 57.3 & 60.2 & 54.4 & 45.0 & 48.1 & 62.6 & 53.5 & 56.6 \\\\\n & \\textbf{Our Model} & \\textbf{67.4} & \\textbf{58.6} & \\textbf{61.6} & \\textbf{56.5} & \\textbf{47.6} & \\textbf{50.8} & \\textbf{63.5} & \\textbf{54.6} & \\textbf{57.8} \\\\\n\\bottomrule\n\\end{tabular} }\n\\caption{\nHelpfulness Prediction results on Amazon-MRHP dataset.}\n\\label{table:amazon_results}\n\\end{table*}",
        "2211.03524_f1cb45f64cdd7b55480ba6aeecd7b797": "Datasets",
        "2211.03524_0adf4f282d88deac26b8c54521c9dcd1": "We evaluate our methods on two publicly available benchmark datasets for MRHP task: Lazada-MRHP and Amazon-MRHP.",
        "2211.03524_7f3b6092a77ff5c95cd43edd2f5044f6": "\\cite{liu2021multi}",
        "2211.03524_98b0c1e24c7e6b691015b30ac6f29688": "consists of product items and artificial reviews on Lazada.com, an e-commerce platform in Southest Asia",
        "2211.03524_5932ad75dee143143271c256a95c2b5d": "All of the texts in the dataset are expressed in Indonesian.",
        "2211.03524_60a6d65d191d09ee5fa7c20d915155cd": "is collected from Amazon.com, the large-scale international e-commerce platform",
        "2211.03524_5740a0e40486a401a5d943b2c41a21a3": "Product information and associated reviews are in English and extracted between 2016 and 2018",
        "2211.03524_512ce02d1b950031b4dc75e1793095fb": "Both datasets comprise 3 categories: (i) Clothing, Shoes",
        "2211.03524_e40276f20da39b77d867d506d9fc0ff7": "Jewelry (Clothing), (ii) Electronics (Electronics), and (iii) Home",
        "2211.03524_85af0395b5a7c75f68a449c958e91f25": "Kitchen (Home)",
        "2211.03524_4cbb038a6315936d6bf039bf16df0f25": "We present the statistics of them in Table",
        "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1": "Implementation Details",
        "2211.03524_ed7d43e420a29a5fb6541a8f3bee5cb9": "We use a 1-layer LSTM with hidden dimension size of 128",
        "2211.03524_81050f4b94b9e879acd0f905034e10c7": "We initialize our word embedding with fastText embedding",
        "2211.03524_7037f1f1cd300a1f3ca92f5bd5ea4d73": "\\cite{bojanowski2017enriching}",
        "2211.03524_3bfbfd6d7d27e8e9e95ed1cd152d3151": "for Lazada-MRHP dataset and 300-dimensional GloVe pretrained word vectors",
        "2211.03524_b11d092f5f8860197cdcb0e60d797ca9": "\\cite{pennington2014glove}",
        "2211.03524_ec7fe1415d1f79c342612d498d903547": "for Amazon-MRHP dataset",
        "2211.03524_8e19fd919451f22031d37a4b05da2bb9": "We set our multimodal attention module to have",
        "2211.03524_6f0762a68085aa729be0b5437777fd78": "$D = 5$",
        "2211.03524_00dd26a7927f09a4069945988520e254": "attention layers",
        "2211.03524_3ab9edc08f5225b94ed1d4d77d2936db": "For the visual modality, we extract 2048-dimensional ROI features from each image and encode them into 128-dimensional vectors",
        "2211.03524_22f94f9b2409e1a97321db2d952e3046": "Our entire model is trained end-to-end with Adam optimizer",
        "2211.03524_ce7e0d6f94fd99b5a93d5ed919adbc7f": "\\cite{kingma2014adam}",
        "2211.03524_699bcfafd70b592187fd42112ac96aac": "and batch size of 32",
        "2211.03524_b4b14e4b5a84dd46541e4dc45f4e978a": "For the training objective, we set the value of the margin in the ranking loss to be 1.",
        "2211.03524_e6165364272d788efe0ea86b9c72ebb4": "Baselines",
        "2211.03524_a7f2162da7e202733a6e3a9c7cccaf35": "We compare our proposed architecture against the following baselines:",
        "2211.03524_b9e1eef049631cc3fa29c476e57b312b": "\\cite{wang2017bilateral}",
        "2211.03524_9c8e115215fcbfd00462da493beaf83b": ": a ranking model which encodes input sentences in two directions to ascertain the matching result.",
        "2211.03524_3bb61e822be89ace42d93345281adc91": "\\cite{dai2018convolutional}",
        "2211.03524_fffcdccfc28d22f9378b50de6956351d": ": a CNN-based model which encodes n-gram of multiple lengths and uses kernel pooling to generate the final ranking score.",
        "2211.03524_db9b825695091d7fcc63c9162d8c532d": ": a CNN-based model targeting data scarcity and OOV problem in RHP task via taking advantage of character-based representations and domain discriminators.",
        "2211.03524_e87bf7c1536de4aae5245870db17038d": "\\cite{fan2019product}",
        "2211.03524_16a9d7474bef235ed58c31183fad104a": ": a baseline to predict helpfulness of a review by taking into consideration both product text and product metadata.",
        "2211.03524_8778a7220f6455f88091a685a1817477": "\\cite{xu2020reasoning}",
        "2211.03524_ba74a93bf6015feed10d8ef673b4de77": ": a cross-modality approach that models contrast in associated contexts by leveraging decomposition and relation modules.",
        "2211.03524_579f37ed729d64d1079929f215be4be2": "\\cite{abavisani2020multimodal}",
        "2211.03524_e487146317e77cd61fb920a85e07315c": ": multimodal model to fuse different modalities with stochastic shared embeddings.",
        "2211.03524_a3b7e11477f648f3cde7c3a93bda3589": ": a baseline model focusing on coherent reasoning.",
        "2211.03524_72d8f780e4b3d5a94869889a49476157": "\\begin{table*}[ht]\n\\centering\n\\resizebox{\\textwidth}{!}{\n\\begin{tabular}{|l|ccc|ccc|ccc|}\n\\toprule\n\\multirow{2}{*}{\\textbf{Dataset}} & \\multicolumn{3}{c|}{\\textbf{Clothing}} & \\multicolumn{3}{c|}{\\textbf{Electronics}} & \\multicolumn{3}{c|}{\\textbf{Home}} \\\\ \n & \\textbf{MAP} & \\textbf{N@3} & \\textbf{N@5} & \\textbf{MAP} & \\textbf{N@3} & \\textbf{N@5} & \\textbf{MAP} & \\textbf{N@3} & \\textbf{N@5} \\\\\n\\midrule\n Lazada & $4.48 \\cdot 10^{-2}$ & $1.55 \\cdot 10^{-2}$ & $3.93 \\cdot 10^{-2}$ & $4.54 \\cdot 10^{-3}$ & $1.05 \\cdot 10^{-4}$ & $2.63 \\cdot 10^{-3}$ & $1.09 \\cdot 10^{-3}$ & $3.40 \\cdot 10^{-2}$ & $3.68 \\cdot 10^{-3}$ \\\\\n Amazon & $3.45 \\cdot 10^{-2}$ & $4.22 \\cdot 10^{-2}$ & $1.86 \\cdot 10^{-2}$ & $4.37 \\cdot 10^{-3}$ & $2.81 \\cdot 10^{-2}$ & $3.04 \\cdot 10^{-2}$ & $2.04 \\cdot 10^{-3}$ & $3.30 \\cdot 10^{-3}$ & $6.50 \\cdot 10^{-3}$ \\\\\n\\bottomrule\n\\end{tabular} }\n\\caption{\nSignificance test of the results of our model against MCR model. }\n\\label{table:sig_tests}\n\\end{table*}",
        "2211.03524_4c2d5bcc78f1a29692326617d046f9f8": "Automatic Evaluation",
        "2211.03524_84d8298209171837bf0e668735a9ba23": "In Table",
        "2211.03524_3a28185838318392df66bb182ae838c4": ", we follow previous work",
        "2211.03524_4c1aa0a8a325d56718176b74503199eb": "to report Mean Average Precision (MAP), Normalized Discounted Cumulative Gain (NDCG@N)",
        "2211.03524_6ff0fe501b8a3df93e5f61eaaf6a1d98": "\\cite{jarvelin2017ir}",
        "2211.03524_f4bb31e1a5ea9a13c548e7f3c59760cb": "$N = 3$",
        "2211.03524_c3bf56131b9241bc4287f97b8ab2c631": "$N = 5$",
        "2211.03524_41ee73bb04ee93d4915deaeaa312f72b": "As it can be seen, multimodal approaches achieve better performance than text-only ones",
        "2211.03524_04d0b24986bf4044036bb48842216c57": "For Lazada-MRHP dataset, we achieve an absolute improvement of NDCG@3 of 2.4 points in Clothing, NDCG@5 of",
        "2211.03524_63911a33a07929c171fc208a00e73fd6": "$1.5$",
        "2211.03524_4ff370b2f2c939ff82d9a683d7ac97ac": "points in Electronics, and MAP of",
        "2211.03524_70c680abd35a3b7c839b334b37c9fb25": "$1.4$",
        "2211.03524_6b7e471f1a0e8dff47eaa9b60929f461": "points in Home over the previous best method, which is MCR",
        "2211.03524_a9bcf3d8d5f231bcf9366dcbe51b0856": "In addition, our model also obtains better results than the best text-only RHP model, which is PRH-Net, with a gain of NDCG@3 of",
        "2211.03524_105fb59f1762d94dff7248fc7263da0e": "$9.8$",
        "2211.03524_4758493d941e462815135a0cf4b67191": "points in Clothing, NDCG@5 of",
        "2211.03524_c659495dd5c12e3c69420441086a2905": "$4.3$",
        "2211.03524_3343a701a8ca09c3d93166c5b4a3c2cc": "$3.6$",
        "2211.03524_0bb279c61d8534c34755615f3e42efe7": "points in Home",
        "2211.03524_6fa8d24aff44132b497b7c8586261389": "Those results prove that our method can produce reasonable rankings for associated reviews",
        "2211.03524_9d80b41de138a5def450fdbad5d24a82": "For Amazon dataset, which is written in English, our model outperforms MCR on all 3 categories, by NDCG@5 of",
        "2211.03524_3bd3a67e29ea6eb297066d35aed12fe2": "points in Clothing,",
        "2211.03524_fed835ed4f98666eeb77c99d04a766f3": "$2.7$",
        "2211.03524_6e016d142dd419b70733a0ede6281530": "points in Electronics, and",
        "2211.03524_7e56203a12062402bf1d50931ab882f6": "$1.2$",
        "2211.03524_47ec326e6b3e3ceb8973ab03f189447c": "points in Home, respectively",
        "2211.03524_7264ae0532c24926c33069a73222a336": "These results have verified that our interaction module and optimization approach can come up with more useful multimodal fusion than previous state-of-the-art baselines, not only in English context but other language one as well",
        "2211.03524_c5afb211d3cb5ab0e98edcb2a28de66c": "We also perform significance tests to evaluate the statistical significance of our improvement on two datasets Amazon-MRHP and Lazada-MRHP, and note p-values in Table",
        "2211.03524_ffe0b5bfd6c1d8acf866eebdad2f132c": "As shown in the table, all of the p-values are smaller than",
        "2211.03524_09b35b77d506cef3840e129c2e29ed1f": "$0.05$",
        "2211.03524_e871ca4a79bf57855118361540b16ff5": ", verifying the statistical significance in the enhancement of our method against prior best MRHP model, MCR",
        "2211.03524_5579f4787eefd1d1c376e39fa934fedd": "Case Study",
        "2211.03524_ca056bbc2d4d279f3c5285ee746350ad": ", we introduce an example of one product item and two reviews extracted from Electronics category of Amazon-MRHP dataset",
        "2211.03524_d621ce0aedeefec30ca5a669b34a6855": "Whereas MCR fails to predict relevant helpfulness scores, our model successfully produces sensible rankings for both of them",
        "2211.03524_5cd663fc9219a761d9190940307857ae": "We hypothesize that our Multimodal Interaction module learns more meaningful representations and Adaptive Contrastive Learning framework acquires more logical hidden states of relations among input elements",
        "2211.03524_07a178e7fb7bb3221b896c88c7b51233": "Thus, our model is able to generate more rational outcomes.",
        "2211.03524_feb8fbabd70d0afca1c994a477267544": "Ablation Study",
        "2211.03524_0f55f9c994322adde74d75909394604b": "In this section, we proceed to study the impact of (1) Adaptive Contrastive Learning framework and (2) Cross-modal Interaction module.",
        "2211.03524_64473f6f6a32ddfe086078ca4424e058": "It is worth noting from Table",
        "2211.03524_ef06f2980be482803f5379c5cf70e135": "that plainly integrating contrastive learning brings less enhancement to the performance, with the improvement of NDCG@3 dropping",
        "2211.03524_5281c21aa165259c0b9528789fc287dd": "$0.53$",
        "2211.03524_59c73d741be7e94f8be9348f0b000748": "points in Lazada-MRHP dataset, NDCG@5 waning",
        "2211.03524_f9e0b9523f560cb85484cae3d61a95c1": "$0.84$",
        "2211.03524_a9454986dff6bed99962398b21f4e071": "points in Amazon-MRHP dataset",
        "2211.03524_3bf3efaafd4030fa92b670d63227b335": "Furthermore, completely removing contrastive objective hurts performance, as NDCG@3 score decreasing",
        "2211.03524_a109556bde996514144e6683abb96852": "$0.77$",
        "2211.03524_14584a35bf9d04767200ca32692d136c": "points in Lazada-MRHP, and MAP score declining",
        "2211.03524_f5dc263c3e57235508ee17d7c176ffce": "$1.06$",
        "2211.03524_5208f476f33d25bf2bfafd655726201a": "points in Amazon-MRHP",
        "2211.03524_76a42cac553c9c10beb8679370b225e7": "We hypothesize that the model loses the ability to learn efficient representations for cross-modal relations.",
        "2211.03524_68b97d8d3ba87710c31da8c1c0fa76db": "In this ablation, we eliminate the cross-modal interaction module",
        "2211.03524_24fc673195a7239d2a99758596e2a599": "As shown in Table",
        "2211.03524_03395d075a21a912186391c687f73799": ", without the module, the improvement is downgraded, for instance, N@3 drops",
        "2211.03524_a29a6e201f606b708916e6d177fd915b": "$1.89$",
        "2211.03524_51449f9af43ff76a96440970f4a2c94e": "points in Lazada-MRHP dataset, MAP shrinks",
        "2211.03524_bdea8edbca373ff7d962ba548a4bbefa": "$1.39$",
        "2211.03524_8279aa46bd1a01ff72e8794d6ffd8ad6": "It is hypothesized that without the module, the model is rigidly dependent upon the alignment nature among multimodal input elements, which brings about insensible modeling because in most cases, cross-modal elements are irrelevant to be bijectively mapped together.",
        "2211.03524_7148e3d77dc3533029cfe554b9d8fd86": "\\begin{table}[ht]\n\\centering\n\\resizebox{\\linewidth}{!}{\n\\begin{tabular}{|l|l|ccc|}\n\\toprule\n\\textbf{Dataset} & \\textbf{Model} & \\textbf{MAP} & \\textbf{N@3} & \\textbf{N@5} \\\\ \n\\midrule\n \\multirow{4}{*}{Lazada} & Our Model & \\textbf{78.15} & \\textbf{72.43} & \\textbf{76.49}  \\\\\n  & - w/o Adaptive Weighting & 77.90 & 71.90 & 75.97 \\\\\n  & - w/o Contrastive Objective & 77.69 & 71.66 & 75.85 \\\\\n  & - w/o Cross-modal Module & 77.32 & 70.54 & 74.86 \\\\\n\\midrule\n \\multirow{4}{*}{Amazon} & Our Model & \\textbf{56.49} & \\textbf{47.62} & \\textbf{50.79}  \\\\\n  & - w/o Adaptive Weighting & 56.03 & 46.98 & 49.95 \\\\\n  & - w/o Contrastive Objective & 55.43 & 46.30 & 49.02 \\\\\n  & - w/o Cross-modal Module & 55.10 & 45.67 & 48.50 \\\\\n \\bottomrule\n\\end{tabular} }\n\\caption{\nAblation study in Electronics category of Lazada-MRHP and Amazon-MRHP datasets.}\n\\label{table:ablation}\n\\vspace{-10pt}\n\\end{table}",
        "2211.03524_e946a6e8485f669e35fcc920b9dd22b2": "Impact of Contrastive Learning on Cross-modal Relations",
        "2211.03524_8e03ac60cf544426a232402e938691d5": "\\begin{table*}[t]\n\\centering\n\\resizebox{\\linewidth}{!}{\n\\begin{tabular}{|l|l|cc|cc|cc|}\n\\toprule\n\\multirow{2}{*}{\\textbf{Label}} & \\multirow{2}{*}{\\textbf{Model}} & \\multicolumn{2}{c|}{\\textbf{Intra-modal}} & \\multicolumn{2}{c|}{\\textbf{Inter-modal}} & \\multicolumn{2}{c|}{\\textbf{Intra-review}} \\\\ \n & & \\textbf{CS} & \\textbf{L2} & \\textbf{CS} & \\textbf{L2} & \\textbf{CS} & \\textbf{L2} \\\\\n\\midrule\n\\multirow{2}{*}{1} & MCR & 0.785 $\\pm$ 0.002 & 3.852 $\\pm$ 0.067 & 0.843 $\\pm$ 0.002 & 11.719 $\\pm$ 0.001 & 0.845 $\\pm$ 0.002 & 14.631 $\\pm$ 0.001 \\\\\n & Our Model & 0.875 $\\pm$ 0.002 & 6.545 $\\pm$ 0.007 & 0.957 $\\pm$ 0.002 & 13.934 $\\pm$ 0.027 & 0.953 $\\pm$ 0.002 & 15.160 $\\pm$ 0.036  \\\\\n \\midrule\n \\multirow{2}{*}{4} & MCR & 0.533 $\\pm$ 0.004 & 1.014 $\\pm$ 0.051 & 0.712 $\\pm$ 0.010 & 9.476 $\\pm$ 0.001 & 0.617 $\\pm$ 0.001 & 8.519 $\\pm$ 0.001 \\\\\n & Our Model & 0.433 $\\pm$ 0.001 & 0.981 $\\pm$ 0.005 & 0.564 $\\pm$ 0.001 & 4.179 $\\pm$ 0.017 & 0.538 $\\pm$ 0.001 & 3.827 $\\pm$ 0.020  \\\\\n\\bottomrule\n\\end{tabular} }\n\\caption{Intra-modal, Inter-modal, and Intra-review distances in Home category of Lazada-MRHP dataset.}\n\\label{table:lazada_cs_mse_dist}\n\\end{table*}",
        "2211.03524_fb5e4fd5fb85e3b4a69f304d9e86f3c0": "\\begin{table*}[t]\n\\centering\n\\resizebox{\\linewidth}{!}{\n\\begin{tabular}{|l|l|cc|cc|cc|}\n\\toprule\n\\multirow{2}{*}{\\textbf{Label}} & \\multirow{2}{*}{\\textbf{Model}} & \\multicolumn{2}{c|}{\\textbf{Intra-modal}} & \\multicolumn{2}{c|}{\\textbf{Inter-modal}} & \\multicolumn{2}{c|}{\\textbf{Intra-review}} \\\\ \n & & \\textbf{CS} & \\textbf{L2} & \\textbf{CS} & \\textbf{L2} & \\textbf{CS} & \\textbf{L2} \\\\\n\\midrule\n\\multirow{2}{*}{1} & MCR & 0.785 $\\pm$ 0.006 & 8.532 $\\pm$ 0.292 & 0.686 $\\pm$ 0.001 & 9.696 $\\pm$ 0.300 & 0.880 $\\pm$ 0.002 & 9.620 $\\pm$ 0.217 \\\\\n & Our Model & 0.971 $\\pm$ 0.001 & 10.663 $\\pm$ 0.770 & 0.976 $\\pm$ 0.001 & 13.234 $\\pm$ 0.493 & 0.970 $\\pm$ 0.001 & 12.222 $\\pm$ 0.431 \\\\\n \\midrule\n \\multirow{2}{*}{4} & MCR & 0.697 $\\pm$ 0.009 & 3.045 $\\pm$ 0.139 & 0.624 $\\pm$ 0.001 & 3.179 $\\pm$ 0.830 & 0.781 $\\pm$ 0.001\t& 5.098 $\\pm$ 0.636 \\\\\n & Our Model & 0.571 +- 0.001 & 1.572 +- 0.037 & 0.488 +- 0.001 & 1.460 +- 0.008 & 0.487 +- 0.001 & 3.555 +- 0.001 \\\\\n\\bottomrule\n\\end{tabular} }\n\\caption{Intra-modal, Inter-modal, and Intra-review distances in Home category of Amazon-MRHP dataset.}\n\\label{table:amazon_cs_mse_dist}\n\\end{table*}",
        "2211.03524_75bacc3aa58018ad6d31d619d8a33ae3": "Despite improved performances, it remains a quandary that whether the enhancement stems from more meaningful representations of input samples, which we hypothesize as a significant benefit of our contrastive learning framework",
        "2211.03524_70157143e063320e473816f25ccd3635": "For deeper investigation, we decide to statistically measure distances among input samples using standard distance functions",
        "2211.03524_51c45b795d5d18a3e4e0c37e8b20a141": "Table",
        "2211.03524_9ff71badc7bb5be717d678967666d0c2": "reveal the results of our experiment",
        "2211.03524_8d367b6caf63243a49b210cd81d1a72a": "In particular, we estimate the cosine distance (CS) and L2 distance (L2) between tokens of (1) product text - review text and product image - review image (intra-modal), (2) product text - review image and product image - review text (inter-modal), and (3) product text - product image and review text - review image (intra-review), then calculate the mean value of all samples",
        "2211.03524_dba49dc19fbc8226829ae5b40af29ba8": "As it can be seen, our frameworks are more efficient in attracting elements of helpful pairs and repelling those of unhelpful pairs.",
        "2211.03524_aed402c3112b4749a9a98a72cbe9093d": "Related Work",
        "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b": "Review Helpfulness Prediction",
        "2211.03524_2acc83398896b345157b054bf10c5722": "Past works that pursue Review Helpfulness Prediction (RHP) dilemma follow text-only approaches",
        "2211.03524_791f96a551c007ce3dd773bbfe6a94e1": "In general, they extract salient information, for instance lexical",
        "2211.03524_d54212adc29709f5de29853690b549b4": ", argument",
        "2211.03524_9e48ef2cc8b3f8d26b006a5ac0aa0b53": ", and emotional features",
        "2211.03524_07e1d4b8bca1ca5602463b09bf5c443f": "\\cite{martin2014prediction}",
        "2211.03524_f24a16f204aa61db5b1584bc2db8f98e": "from reviews",
        "2211.03524_b0ea4d29cbde15c03b16bb31eb51f14f": "Subsequently, these features are fed to a standard classifier such as Random Forest",
        "2211.03524_1c9896b6d1206cee08c205d2341a562f": "\\cite{louppe2014understanding}",
        "2211.03524_3758da54f3011e970e54e57b3370ac03": "in order to produce the output score",
        "2211.03524_483bd5b4d4976fca64a209f7a906227d": "Inspired by the meteoric development of computation resources, contemporary approaches seek to take advantage of deep learning techniques to tackle the RHP problem",
        "2211.03524_b3adae4156d780a03594d9e5c06b270e": "For instance,",
        "2211.03524_705e5d4885f87f0ff484d2f70387cfde": "\\citet{wang2017bilateral}",
        "2211.03524_9e70cb918019d45a0bf5261e7451ba8f": "propose multi-perspective matching between review and product information via applying attention mechanism",
        "2211.03524_a56c89d3c688cca621556188e4f9e10f": "Furthermore,",
        "2211.03524_8c0cf8c83c14d997da6a2032f4cc1c77": "\\citet{chen2018cross, dai2018convolutional}",
        "2211.03524_0be5f5e5ad1770c80299ed7f391dd37f": "adapt CNN models to learn textual representations in various views",
        "2211.03524_943c62e711565edcec17706c4eef97f4": "In reality, review content are not only determined by texts but also other modalities",
        "2211.03524_814b6f754a821f4784d1f3439db1bc3b": "As a consequence,",
        "2211.03524_4e1de59bd2009d7e3968e70232bc7bd0": "\\citet{fan2019product}",
        "2211.03524_32e2d5719555466bdb4aefe65899df7e": "integrate metadata information of the target product into the prediction model.",
        "2211.03524_047561083781873091efd984e09d6334": "\\citet{abavisani2020multimodal}",
        "2211.03524_d43c674f7e6fc59260cb2d6cd8a90a28": "filter out uninformative signals before fusing various modalities",
        "2211.03524_b6a89cee59803b7fa1665f4326ae520e": "Moreover,",
        "2211.03524_28146205695a86b3c8b9d87fe13678c1": "\\citet{liu2021multi}",
        "2211.03524_891409ad114c07e47d9c924f48bfea0d": "perform coherent reasoning to ascertain the matching level between product and numerous review items.",
        "2211.03524_699d18833ec9592b04834df425c9090d": "Contrastive Estimation",
        "2211.03524_6771da3d5782f0ea55f0e6c1a0fe5835": "Different from architectural techniques such as Knowledge Distillation",
        "2211.03524_6539a03b56959af71fc49043e5cdd134": "\\cite{hinton2015distilling, hahn2019self, nguyen2022improving}",
        "2211.03524_9ddc20aa5d5424dcf418dd24110e13f4": "or Variational AutoEncoder",
        "2211.03524_e18353e888a70bad25d70381e764b69e": "\\cite{zhao2020neural, nguyen2021enriching, nguyen2021contrastive, wang2019topic}",
        "2211.03524_68d0ccba1d13929f157dcab91325f305": ", Contrastive Learning has been introduced as a representation-based but universal mechanism to enhance natural language processing performance",
        "2211.03524_9e80aa7beade1f6c5ac2e082b340e1e0": "Proposed by",
        "2211.03524_abb02501f8c4c74e020bf1b9e5935db8": "\\citet{chopra2005learning}",
        "2211.03524_cf662cc8a8ab16780774fb0dc4f1bd45": ", Contrastive Learning has been widely adopted in myriad problems of Natural Language Processing (NLP)",
        "2211.03524_4ba0bab8d130572e9c2742a5aba3a709": "As an approach to polish text representations,",
        "2211.03524_1531b42fdb23fd6af246203a2ade1538": "\\citet{gao2021simcse, zhang2021pairwise, liu2021dialoguecse, nguyen2021contrastive}",
        "2211.03524_39ef66293508d503966e24bf51101dff": "employ contrastive loss to advance sentence embeddings and topic representations",
        "2211.03524_4b561fdfea529ee9d0ba20a91d8758c2": "For downstream tasks,",
        "2211.03524_eb3a371151e468d2237ff6c709ed7d61": "\\citet{cao2021cliff}",
        "2211.03524_02fe527b114e17d6ae95ba635037be35": "propose negative sampling strategies to generate noisy output so that the model can learn to distinguish correct summaries from incorrect ones in Document Summarization",
        "2211.03524_1871661ca82b182e09655d98540b0659": "For Spoken Question Answering (SQA),",
        "2211.03524_b2388e0c17a7e8dc2c33858ceef92d3f": "\\citet{you2021self}",
        "2211.03524_69bd6cf96c6c636443855f8a8235e555": "introduce augmentation algorithms in their contrastive learning stage so as to capture noisy-invariant representations of utterances",
        "2211.03524_fce5228d5eade5a2e0c88bedab5e348a": "Additionally,",
        "2211.03524_6796b16720067de80a6bc869ea6b250b": "\\citet{ke2021classic}",
        "2211.03524_018008124e9b6d38982aa52de68d247d": "inherit the formulation of the contrastive objective to construct distillation loss which transfers knowledge of the previous task to the current one",
        "2211.03524_e1d09d5a2e13bb50f3a16870363b8ab5": "Their proposals are to improve tasks in the Aspect Sentiment Classification domain",
        "2211.03524_22bdf76942d457c659a7302a4487a785": "Unfortunately, despite the surge of interest in exercising contrastive learning for NLP, research works to adapt the method to the MRHP task have been scant.",
        "2211.03524_6f8b794f3246b0c1e1780bb4d4d5dc53": "Conclusion",
        "2211.03524_f1c6a59eaed6776e58459183796f49ea": "In this paper, we propose methods to polish representation learning for the Multimodal Review Helpfulness Prediction task",
        "2211.03524_13cba83b203e04deb1cbed5379069258": "In particular, we aim to advance cross-modal relation representations by learning mutual information through contrastive learning",
        "2211.03524_e9b88f24f62e105124a102f48e4078fb": "In order to further enhance our framework, we propose an adaptive weighting strategy to encourage flexibility in optimization",
        "2211.03524_afeb4f4879ee14f97040954172efb72e": "Moreover, we integrate a cross-modal interaction module to loose the modelâs reliance on unalignment nature among modalities, continuing to refine multimodal representations",
        "2211.03524_6dde2ec54e97056f4e9672c969dbd464": "Our framework is able to outperform prior baselines and achieve state-of-the-art results on the MRHP problem.",
        "2211.03524_e646e16bee8b32e6ea29e30d01970a6c": "Limitations",
        "2211.03524_5fc39a9d6e49e25bba1e8988295db50f": "Despite the novelty and benefits of our method for Multimodal Review Helpfulness Prediction (MRHP) problem, it does include some drawbacks",
        "2211.03524_07bb3940d33e8d3d871d89dd32c37bf1": "Firstly, even though empirical results demonstrate that our approach not only works in English contexts, we have not conducted the verification in multilingual circumstances, in which product or review texts are written in different languages",
        "2211.03524_5a510e1fe535a7dd3319031d9ca48b60": "If a model is corroborated to work efficiaciously in such contexts, it is capable of providing myriad benefits for practical implementation, for example, e-commerce applications can leverage such one single model for multiple cross-lingual scenarios",
        "2211.03524_381c722b131156173f3046b4f2b614fa": "Furthermore, our work can also be extended to other domains",
        "2211.03524_bdb1d0a26959c504dd319b7da3933b79": "For instance, in movie assessment, we need to determine whether the review suits the material in the film, or visual scenes in the comment are consistent with the textual content",
        "2211.03524_732052832940835781b9d33a918f46ee": "These would form our prospective future directions",
        "2211.03524_91ab18032f3cc81ae7c7e6bdd0addf99": "Secondly, in the MRHP problem, there are several relationships that contrastive learning could exploit to burnish the performance",
        "2211.03524_f983bfc854e254a8514782c7c50f49e3": "In particular, performing contrastive discrimination between two sets of reviews is able to furnish the model with useful set-based representations, which consolidate general knowledge for better helpfulness prediction",
        "2211.03524_088221303d069096e3ca6e896eded063": "Similar insights are applicable for two sets of product information",
        "2211.03524_a992c603b5c8849693124012e398e805": "At the moment, we leave such promising perspectives for future work.",
        "2211.03524_527b5dd477abf95e8fe19aac201df396": "Acknowledgement",
        "2211.03524_befe590610aca483f5f09c9b75454961": "This work was supported by Alibaba Innovative Research (AIR) programme with research grant AN-GC-2021-005.",
        "2211.03524_bb050154059aa3649156a8562fd4f411": "Hyperspherical Form of Adaptive Contrastive Loss",
        "2211.03524_3457fcc98e70b7204fee74a82b260b60": "We have the initial formulation of the adaptive contrastive loss",
        "2211.03524_50fb7ce4aa7dc02112d0fdfa0721f120": "\\begin{equation}\n\\mathcal{L}_{\\text{AdaptiveCE}} = -\\sum_{i=1}^{B} \\epsilon^p_i \\cdot \\text{sim}(\\mathbf{t}^1_i, \\mathbf{t}^2_i) + \\sum_{j=1, k=1, j \\neq k}^{B} \\epsilon_{j,k}^n \\cdot \\text{sim}(\\mathbf{t}_j^{1}, \\mathbf{t}_k^{2})\n\\end{equation}",
        "2211.03524_f11b1892b308219697bfce55cd3c83cf": "We first substitute",
        "2211.03524_51a0f7b64b9202fe8b90052c52a0c285": "into the above equation,",
        "2211.03524_13a102be23513c9226a90a259496569d": "\\begin{align}\n& \\mathcal{L}_{\\text{AdaptiveCE}} = \\sum_{i=1}^{B} \\text{sim}(\\mathbf{t}^1_i, \\mathbf{t}^2_i)^2 - o^p \\cdot \\text{sim}(\\mathbf{t}^1_i, \\mathbf{t}^2_i)  + \\sum_{j=1, k=1, j \\neq k}^{B} \\text{sim}(\\mathbf{t}^1_i, \\mathbf{t}^2_i)^2 - o^n \\cdot \\text{sim}(\\mathbf{t}^1_j, \\mathbf{t}^2_k) \\\\\n& = \\sum_{i=1}^{B} \\left(\\text{sim}(\\mathbf{t}^1_i, \\mathbf{t}^2_i) - \\frac{o^p}{2}\\right)^2 + \\sum_{j=1, k=1, j \\neq k}^{B} \\left(\\text{sim}(\\mathbf{t}^1_j, \\mathbf{t}^2_k) - \\frac{o^n}{2}\\right)^2 - C \n\\end{align}",
        "2211.03524_e8a66ae6d7ec9ad9dc95198a2023f7b3": "$C =  \\left(\\frac{o^p}{2}\\right)^2 + \\left(\\frac{o^n}{2}\\right)^2$",
        "2211.03524_d1a1690bae535d291e3bcea9e875eaab": "Now we obtain the spherical form of our contrastive loss."
    },
    "hierarchy": {
        "1": {
            "2211.03524_708aede88adbc288358e60e7a474bb44": "2211.03524_6d9af95a66a2a8d32115c4f2c2955b97",
            "2211.03524_e353dbe42c8654f33588d4da0b517469": "2211.03524_6d9af95a66a2a8d32115c4f2c2955b97",
            "2211.03524_65b7321c781a2ae4d65b93e73ad79364": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_b4cfc1f5f8c183453be058e62352e65a": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_835929b98c03989eefee7fb2a4fc4d96": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_bdc60cb0f639772eae48432ec58f8d9a": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_e55ebf67794a6aa41adec17be99d1af1": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_a057417ffcb1060ab81a5cc4520aed75": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_fea01ca36d17da47506476a7b2d4779a": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_0b79795d3efc95b9976c7c5b933afce2": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_c10223451e0c18b5f4ee9732b7b69a57": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_5b26e45cdff9b5c2dc69dd5f5aa22b78": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_c80f71b0c45f4b6ca695ee9ea1a4d79a": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_bd1b67e19fc16f61d916ea494bb5c451": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_abca67b46b21a1354d28639370a76df8": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_e0b1364a938758ad9e909d13acbecc08": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_2abe0aec5f8e1418625ad6d0adbe22b0": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_5114adf7fc7abc3e8aea5a5a8ff9b710": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_c4e010f4c5632d68dc76a97c1f7199c8": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_7c6e47040ec4ec0743d8b2ed6894fdd9": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_510b62ebb57406da22671c7529f906ce": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_b7582e1decd7fa6d75e39d738b8cf674": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_1ec7e11c52dae56a066ee54f0ed8d2b6": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_326227012bf26e620c3f8d16268e976b": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_94074deeb7132844ce03b278c2f39f1e": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_a849b4997fe6689bdf5949b1653b8654": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_f6691406cda571d81bf5db9e3d11ff32": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_028a1a22b53d5fca76f9c5cc4acd4fd2": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_4798c6a6fac065cdd7f0aa5c37599b2a": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_a6f8085963c630f147b68fc6d074005a": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_f0a1d11bbaeb34d26baee7a07e3929c6": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_c12ef666167dd5a18a25fab8908878e8": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_2fdbf0daf9641ef0664fe61c05cd66a2": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_6f2fd9afa906f7cec3ff388a8bcb9d04": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_5153208847bb048a3dcf3a8d2b4a3fdc": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_e81c4e4f2b7b93b481e13a8553c2ae1b": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_745772ff4463e10227beaec3089c6319": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_fb15335fe970946dbb5420700bd456fc": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_ba66d68eb9a990aafd4790736867038a": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_08186ed412cbd6c802ed3e7037180254": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_aabe1517ce1102595512b736cbf264bb": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_448126902c751ef78e16b1e5133bfdc3": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_67df41a93f7fcdec36345bd802578bf9": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_f4ad6143baad30fe78a5681ed7b03082": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_e7a0c6b8c0ab38899ffa0d284e897cff": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_63e625fba6407f7a19f47ae7ba1ab888": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_3f0cd42c015332ba18f0ba125d065a93": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_226c2463fab716291f0e56d31dee39f0": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_defd66ff5540373ac8aea4ecf9719a0c": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_a2d62795398ed7a879936a55dcb3fe7d": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_5ecb27137c5c40f294dbb88c61348e8c": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_ab256241aac70f922e45e2936a5a4770": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_6bfae4ed4f5694bc3b525893859bc29c": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_fa25fd6b32312a7c7a2fa42d6098dda3": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_3f815a46e1635e351671e77be12bc104": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_be5d5d37542d75f93a87094459f76678": "2211.03524_bb050154059aa3649156a8562fd4f411",
            "2211.03524_1a30e964ad51e71693d47ae48e4a5b60": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_a4f891615b8e12abde1b1c712ddda73e": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_ae1b6a69ae60ba63800667e8ed47882e": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_c65a217da5a031e3222492bfe4af93dc": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_965e43a737236b5a851abb1a056a9c8a": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_0e3caff75557d68f7ded82ade2effb9e": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_e4fb16fd0e2ee61ea0da297956b4f1eb": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_cd12deaf0bfe16ccc10f20b0a7d3fd53": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_4fbf752170de41f8ed55f24942805fd4": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_d6b9ec4f8cddb7229cdc03175bc2d13c": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_82aa257a9b8fb7f155b8556934ff4e53": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_e964b1ab1fcb2481c36228b09f2df794": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_7931ff12353cc34adedbfa1c10080344": "2211.03524_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03524_a8f65dd93445b90d34246cc201862695": "2211.03524_e6165364272d788efe0ea86b9c72ebb4",
            "2211.03524_7d74f3b92b19da5e606d737d339a9679": "2211.03524_a8f65dd93445b90d34246cc201862695",
            "2211.03524_6f7d51813b47f0b9f4f0da190787d6f6": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_cc80a79c7927300ceaf9df1022f58bcb": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_7ab520c4cfd86dfd800ead379c4b6817": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_d3d944395953c0de6d885982db1654c1": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_29f85ae34c0f8741bbfb695e701dfcd5": "2211.03524_d3d944395953c0de6d885982db1654c1",
            "2211.03524_19fa406aef1e85c202a2e2cf561b800b": "2211.03524_d3d944395953c0de6d885982db1654c1",
            "2211.03524_1b6dd7e4cfb5fa9efcc0ae2808aa9f31": "2211.03524_d3d944395953c0de6d885982db1654c1",
            "2211.03524_5058f1af8388633f609cadb75a75dc9d": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe": "2211.03524_d3d944395953c0de6d885982db1654c1",
            "2211.03524_b872547bd17b83d987c3f484aebffdd9": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_2ec6e630f199f589a2402fdf3e0289d5": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_74bf553bb5cb404ed3c6d9b452ff6c3d": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_cf190f6d94a59f7eb276fc95dcb091a5": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_2abd21e10454a879d63f55dab19b2b1f": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_510f2acb5ca51b8eb8432b683eb9f1d3": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_ca1738b49f3961baca3cbe9cafc2b7d3": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_27aeb5ccf23a78c7c5460846dbb37fe1": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_2ed8a5cea4527e3547da57e124c12ce2": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_ccc455e82339a14a7ad0d373dbfd9bfd": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_56dd3026ecf108103e0a1cf5158d89d0": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_7a6cfaf61548e1bf4538a1888d6f3e88": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_635f47adc7d00049f722f776fac45266": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_567904efe9e64d9faf3e41ef402cb568": "2211.03524_bb050154059aa3649156a8562fd4f411",
            "2211.03524_f9c4988898e7f532b9f826a75014ed3c": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_b64eba476e1d09ef8dd0e63fd809e29e": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_190083ef7a1625fbc75f243cffb9c96d": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_0f0f6efffb51ae375c425db4e0ce91ff": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_ae5d0f370468314570c04f60745cfcca": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_fab2d45efd926f2faf3cc20d425b6f38": "2211.03524_1f2e4e60dc657345243d64f97fb1bbfe",
            "2211.03524_2a44187d78593138f279fac225ae3d61": "2211.03524_d3d944395953c0de6d885982db1654c1",
            "2211.03524_7d5d1652c4b3c4e181bb03c2bd2a3ca4": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_7b1f450c2dc51b73da5b35080b7a9b6c": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_1bfae9b14eb4b21ddad93740415d1788": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_3f23c2488a25d7dc5d5e59673fb775c2": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_7279bff3a9816e133796d853089254e6": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_f0bf7e1774b7ccc1d3ee4fe011bd1b3a": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_5ab10c1197274918c30b313abbc6cc63": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_6939ae2cab0949f3ff8d1a3d04fe8067": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_123da0a65cb18a49a4bf484695ac5152": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_fbe2accac3e37a150710e32bb7e7800a": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_b14a7b8059d9c055954c92674ce60032": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_8d9a1ce7ef3148e7502875a18d1bd0a0": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_ebe3551425450e9850fa1f21a38b3d72": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_18dabfa0970bcde267fa6bc35b26d064": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_19d9977a91b00463c72c584bcea066f5": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_2c0b42c913dd0fade191a612ed3728cf": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_c0cb5f0fcf239ab3d9c1fcd31fff1efc": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_27d790a6e667a77a6db4eb6046c1d6df": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_247ca9d8cf371e16f3db4442254b82af": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_0d97f4b752272b2c27b01feef8a05c90": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_0ada0e62e5a4f921051419e195c3f707": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_2103f85b8b1477f430fc407cad462224": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_41490f763aff8d86d072e0979f8f5b55": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_00bbd95ed734afc6f9d81774219f4867": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_b9a47b3f50d13d4af048143fcb35850f": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_acbc4ca2cd262510f43b44abc3afe470": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_a6aebf93d3259929d77b90dd561e0f31": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_0e51a2dede42189d77627c4d742822c3": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_5891da2d64975cae48d175d1e001f5da": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_10014044fc0bc5f93592dfc858f8813d": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_626ca6f855d08f7c22de1485a8f2906b": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_8c74cb9f14046239e8022733f7598f26": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_2fdb4d0205b168a4fc84398a3e37cd72": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_2b8011e962697b7ca36692f92c4200a2": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_b11c2ca1869dd4e9116defdfc8230139": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_36abe1bb3059514a94218980445e74a3": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_a6ca8cfe924069c054b100e2103515f4": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_ccb1f38f0c2d0afbf5db6ae95d952e04": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_7714fde4c6b7d01381cddbc18456244a": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_89c8a969ae84df7438227dd380adac2b": "2211.03524_2a44187d78593138f279fac225ae3d61",
            "2211.03524_d3c78727bfe27cc8c5e4299732545547": "2211.03524_d3d944395953c0de6d885982db1654c1",
            "2211.03524_a4b332cc02b18a29c5cce6b352726d67": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_11c596de17c342edeed29f489aa4b274": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_1d0496971a2775f4887d1df25cea4f7e": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_9dcfa68d289b63848c4d5d75f7f63eb9": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_915787506d91edc9ebf4309663447792": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_f9780a6cd3f8979e127f2334de9f9a8a": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_a29f17caa3e965b909d1aef183a202e4": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_b22e46b54b9ad07c7b2b1a57ad30425f": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_d10d7300ace26fa99e46be8f100fdeec": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_053ea152b451065d48bd6894b1373837": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_fb4f3b79910c6656439b97f695d3f658": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_7b1cb7ec3681931f982088c8de8278a6": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_513b5d2c3e507906c33431f230fde0fa": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_ce4a591b0be792861f20b1b9924fb9c2": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_2977befd992a498349651c15f8a49daf": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_1afcdb0f704394b16fe85fb40c45ca7a": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_d6328eaebbcd5c358f426dbea4bdbf70": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_8a0e2b549d223aba55a866c38d1c9275": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_a9a3a4a202d80326bda413b5562d5cd1": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_853ae90f0351324bd73ea615e6487517": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_7cd9c4c3344f1c6d7924b621ff783506": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_4ef60a5fa5ad51be21a63d5065e7e63f": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_81b675fa9e743d769acb92496e626e53": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_59ba51e11a31bcb6417fb512003ac3de": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_90a6edf15b9fbcd8ccd9383ad593f8c2": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_93d6e6c9cd603bc19125faeab0b7aefd": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_253f9f126e1e672ff9b07f0451886e3a": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_41dc8de0ae38f44c55458505946a9722": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_301da3cbc3f0e1c54e0bba43d9ca9ebf": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_4120691b29a334a29d95e9af083b75da": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_ebc761027dc39560e7be51f832f41558": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_64eb0d7486337a16d5c489291981397b": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_224367653c24d452073ad9ba9f20c67c": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_78ec2b7008296ce0561cf83393cb746d": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_949cf3ae4a8ea9932713a1a029dbd12d": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_c06853578d5402a0bdacbd60a1b96fd4": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_fe40ec2bc207cc92133c8b3deb669acc": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_700b7f3f3b74b1b95c701e0b30b4b20d": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_12a7d949440a58ec3b336da4dbf81b5e": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_e8ec656b1b1b25f1e7b1965edad53314": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_3b5009de2f2eb82416b690a2b0b92b9a": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_42534ccbc88518484411932a3776e584": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_196b8e67d3bb60511f084eb205293069": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_d2ef12fa0b4947a68e1df4696645891c": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_e1bd9c1288ed8b59c04af124009b7369": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_2e9c273d6519389c94ca4629edc0e64d": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_b3e77481b595b641bcd3daea10007f24": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_84c40473414caf2ed4a7b1283e48bbf4": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_cda04cae6ec457611db4c9d43b8c1479": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_df4e0035b3899165c827c11902261367": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_d41a1c2dfb6b7aa12089330b8584ed52": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_4c00dbdaf32c048274e88be77d561b8f": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_acc2bb77450a0e3bf56c2881b0eb575b": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_8e521161895f9b5d456dd9022b002ee1": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_7c99f0ab7a4085aa6d9bc7d39aa95cc3": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_ff79e78cdb7f88d5aaf52d1c4d034735": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_db9ec36a50879de8a3170ac5f9d19b77": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_9b0028550273f126bc2f47c11c48152b": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_fe2115f710dd32f6ae6980577437516d": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_482b25ccdcbe48d3d4a2770eb85bcd16": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_0f34db4e3701432b8688c35b8b68d30f": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_9a7283ebdb9b065770ddb694f7153260": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_6c648e511827def6e147585c4033d9b0": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_005573a93a67f7255e6529fa392e4f6e": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_c619c487af65289bd6267227de82b937": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_43ec3e5dee6e706af7766fffea512721": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_6266e1e9410a052e5266156d98408607": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_1b6c985b5902d2f01d5956a3b8db70ec": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_8ebd4a6001a1d8a971f7781ebbc564ae": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_c5d70cde28bbd096512dde85a412b63f": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_ba5010c82f7507179105d5ad40a040e3": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_dc058eb32e9ff85d34c067ddd079ad34": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_54271eaf8f3737a0821e394e3075a515": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_c9f6e2806601c9352928a7877cf17290": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_0119500665a667bc80d24869e4ff059c": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_ea93022480bdbeac5cc6b1ac00d8da40": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_5e826beae830db9e2e236aef30ab3590": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_a3cff49d6c21596624ef2f4d3624329c": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_9371d7a2e3ae86a00aab4771e39d255d": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_7e6a2afe551e067a75fafacf47a6d981": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_6e047dbb7eeecacd1fd7d34a32e0a942": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_51c8eadb081f25d165b23e78c56b15cd": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_0fbd1776e1ad22c59a7080d35c7fd4db": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_1d167807e05e83916cf0768977f058f8": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_ee849ff35521100b41030846a66045ae": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_f36bfc56f3be257a02720c3c862aa89f": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_1a761b1a2f99c8fe702436f021b1f6b4": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_f30639fbb1c77c2934a00975b33a81b3": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_21365cd605386936488d14a793f37139": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_7b672cd8994320ecd5f4951865a1bd66": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_4439cd0529504b19b6d522c0ada0d6c0": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_24bf8bd6e9b9cb047396f662d56a8f63": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_dd177a923b099610383c2a2f7aac5887": "2211.03524_d3c78727bfe27cc8c5e4299732545547",
            "2211.03524_2d94e9e57bff93acb26d60251d69e97e": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_181db63079b74fe95ba190fa64d9cbb4": "2211.03524_2d94e9e57bff93acb26d60251d69e97e",
            "2211.03524_534fbd0711dcf88c8ca609ce779bc351": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_476521a4ccd843bc06b60d55c0eb88e7": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_5354514233dd5852065a1ea81243f30c": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_a2a9ccc59907254f5f4a3320e62aa06d": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_7ee9e6364f9d29fdca80025ee951985d": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_cb0eb7509736e32e7dc242466a4411ca": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_ba3283ca4872487c8e167b85c13a6850": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_5818059f70f734538d8467d3d8437f6a": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_4bad86f7d95dded1568ab9e22960f90e": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_93ae29432fcd73a425f0addef25e6064": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_babfbbb729ce0ba996785e1b12d4c58b": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_c81f48ecd935347fd20655f7077e1cc2": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_bb6ca6c89727d01de14dfac4c2a73421": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_61e84f854bc6258d4108d08d4c4a0852": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_3a0f08f4fbfffbf0ea8a83d5d6612cb1": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_c8180bfe1a7d2bbaef9d8251516fc0a2": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_bbc2eade11f67e31fb0b44e11420d91e": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_0bdbae768273714dc9d7fb6e29210ba3": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_11fb4b8a7a6422f7615096150ec36a07": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_d952a0f2a8495c60002d2705f542fd16": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_7e29a08876e0803b9015193a218111df": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_23069c37667a080b8d6a8c09ca0c587b": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_98d010141e93b94948f5c1bdc3ea1c79": "2211.03524_bb050154059aa3649156a8562fd4f411",
            "2211.03524_52ed0ddc3096f0c5e619c7da760b8b80": "2211.03524_bb050154059aa3649156a8562fd4f411",
            "2211.03524_63e1438acaa0e812984ebe083a0f3950": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_18dcb9aec32468241d6e192142d5ed9f": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_95ec06a7fc34421fcee675a3a167fa79": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_19634fc0143725dc6bb3765e4ba3ea90": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_28b423b3e84a6dcbc088ae1b14abcab3": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_57207979d57274c38d03d005805d234e": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_e5cf03e24124c1c587ddd6fa4fc1c612": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_870c423cce2561a13b3d705f9c4c1a5f": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_bc170999e675977a518d7376c8533c2a": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_f23ed61f998917b34b8a34ddd383e090": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_0abb2294e277488ac8058ed69e7a1017": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_b06466e6b68d453b5c2291f9f652f493": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_51810f33437ccd1e173df96fc9829ff4": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_9923970f09bc2c40eb68730777195e45": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_53006e8bf32d363f5dd72a552cf2e884": "2211.03524_181db63079b74fe95ba190fa64d9cbb4",
            "2211.03524_9d01c264e0abd10873f1798378f9e799": "2211.03524_2d94e9e57bff93acb26d60251d69e97e",
            "2211.03524_c68d9e0e0243a64ad489d24b7313ff61": "2211.03524_9d01c264e0abd10873f1798378f9e799",
            "2211.03524_de688f8d2b603a1c09b7d7b7ab9c4316": "2211.03524_9d01c264e0abd10873f1798378f9e799",
            "2211.03524_9b08333396b6df91aefd2d51630581ac": "2211.03524_9d01c264e0abd10873f1798378f9e799",
            "2211.03524_0eddd2a9eb13177117e92bb524d62379": "2211.03524_9d01c264e0abd10873f1798378f9e799",
            "2211.03524_4c30a5a9a92c33a2f27cd09ec1d238ed": "2211.03524_9d01c264e0abd10873f1798378f9e799",
            "2211.03524_4c9057c5951288619aa3444ecb6cdbe2": "2211.03524_9d01c264e0abd10873f1798378f9e799",
            "2211.03524_e582caf96bd4bd4baf89bf4c96b64691": "2211.03524_9d01c264e0abd10873f1798378f9e799",
            "2211.03524_005368ad99037db26a7daa3d472d0f2e": "2211.03524_9d01c264e0abd10873f1798378f9e799",
            "2211.03524_4829262cecb9828817b33e0f9c907f91": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_e3a2d4d4fc002f90824eacce38cd67e7": "2211.03524_4829262cecb9828817b33e0f9c907f91",
            "2211.03524_f0536dd4df99776762a028f15f4e8faf": "2211.03524_4829262cecb9828817b33e0f9c907f91",
            "2211.03524_9cc1a26ee1adb640cf64b759d14ab9f4": "2211.03524_4829262cecb9828817b33e0f9c907f91",
            "2211.03524_f1cb45f64cdd7b55480ba6aeecd7b797": "2211.03524_4829262cecb9828817b33e0f9c907f91",
            "2211.03524_0adf4f282d88deac26b8c54521c9dcd1": "2211.03524_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03524_7f3b6092a77ff5c95cd43edd2f5044f6": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_98b0c1e24c7e6b691015b30ac6f29688": "2211.03524_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03524_5932ad75dee143143271c256a95c2b5d": "2211.03524_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03524_60a6d65d191d09ee5fa7c20d915155cd": "2211.03524_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03524_5740a0e40486a401a5d943b2c41a21a3": "2211.03524_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03524_512ce02d1b950031b4dc75e1793095fb": "2211.03524_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03524_e40276f20da39b77d867d506d9fc0ff7": "2211.03524_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03524_85af0395b5a7c75f68a449c958e91f25": "2211.03524_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03524_4cbb038a6315936d6bf039bf16df0f25": "2211.03524_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1": "2211.03524_4829262cecb9828817b33e0f9c907f91",
            "2211.03524_ed7d43e420a29a5fb6541a8f3bee5cb9": "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1",
            "2211.03524_81050f4b94b9e879acd0f905034e10c7": "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1",
            "2211.03524_7037f1f1cd300a1f3ca92f5bd5ea4d73": "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1",
            "2211.03524_3bfbfd6d7d27e8e9e95ed1cd152d3151": "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1",
            "2211.03524_b11d092f5f8860197cdcb0e60d797ca9": "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1",
            "2211.03524_ec7fe1415d1f79c342612d498d903547": "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1",
            "2211.03524_8e19fd919451f22031d37a4b05da2bb9": "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1",
            "2211.03524_6f0762a68085aa729be0b5437777fd78": "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1",
            "2211.03524_00dd26a7927f09a4069945988520e254": "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1",
            "2211.03524_3ab9edc08f5225b94ed1d4d77d2936db": "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1",
            "2211.03524_22f94f9b2409e1a97321db2d952e3046": "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1",
            "2211.03524_ce7e0d6f94fd99b5a93d5ed919adbc7f": "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1",
            "2211.03524_699bcfafd70b592187fd42112ac96aac": "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1",
            "2211.03524_b4b14e4b5a84dd46541e4dc45f4e978a": "2211.03524_c2b2b81b0d6751c1aa98cc1822ba50b1",
            "2211.03524_e6165364272d788efe0ea86b9c72ebb4": "2211.03524_4829262cecb9828817b33e0f9c907f91",
            "2211.03524_a7f2162da7e202733a6e3a9c7cccaf35": "2211.03524_e6165364272d788efe0ea86b9c72ebb4",
            "2211.03524_b9e1eef049631cc3fa29c476e57b312b": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_9c8e115215fcbfd00462da493beaf83b": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_3bb61e822be89ace42d93345281adc91": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_fffcdccfc28d22f9378b50de6956351d": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_db9b825695091d7fcc63c9162d8c532d": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_e87bf7c1536de4aae5245870db17038d": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_16a9d7474bef235ed58c31183fad104a": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_8778a7220f6455f88091a685a1817477": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_ba74a93bf6015feed10d8ef673b4de77": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_579f37ed729d64d1079929f215be4be2": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_e487146317e77cd61fb920a85e07315c": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_a3b7e11477f648f3cde7c3a93bda3589": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_72d8f780e4b3d5a94869889a49476157": "2211.03524_7d74f3b92b19da5e606d737d339a9679",
            "2211.03524_4c2d5bcc78f1a29692326617d046f9f8": "2211.03524_4829262cecb9828817b33e0f9c907f91",
            "2211.03524_84d8298209171837bf0e668735a9ba23": "2211.03524_5579f4787eefd1d1c376e39fa934fedd",
            "2211.03524_3a28185838318392df66bb182ae838c4": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_4c1aa0a8a325d56718176b74503199eb": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_6ff0fe501b8a3df93e5f61eaaf6a1d98": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_f4bb31e1a5ea9a13c548e7f3c59760cb": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_c3bf56131b9241bc4287f97b8ab2c631": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_41ee73bb04ee93d4915deaeaa312f72b": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_04d0b24986bf4044036bb48842216c57": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_63911a33a07929c171fc208a00e73fd6": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_4ff370b2f2c939ff82d9a683d7ac97ac": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_70c680abd35a3b7c839b334b37c9fb25": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_6b7e471f1a0e8dff47eaa9b60929f461": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_a9bcf3d8d5f231bcf9366dcbe51b0856": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_105fb59f1762d94dff7248fc7263da0e": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_4758493d941e462815135a0cf4b67191": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_c659495dd5c12e3c69420441086a2905": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_3343a701a8ca09c3d93166c5b4a3c2cc": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_0bb279c61d8534c34755615f3e42efe7": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_6fa8d24aff44132b497b7c8586261389": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_9d80b41de138a5def450fdbad5d24a82": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_3bd3a67e29ea6eb297066d35aed12fe2": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_fed835ed4f98666eeb77c99d04a766f3": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_6e016d142dd419b70733a0ede6281530": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_7e56203a12062402bf1d50931ab882f6": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_47ec326e6b3e3ceb8973ab03f189447c": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_7264ae0532c24926c33069a73222a336": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_c5afb211d3cb5ab0e98edcb2a28de66c": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_ffe0b5bfd6c1d8acf866eebdad2f132c": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_09b35b77d506cef3840e129c2e29ed1f": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_e871ca4a79bf57855118361540b16ff5": "2211.03524_4c2d5bcc78f1a29692326617d046f9f8",
            "2211.03524_5579f4787eefd1d1c376e39fa934fedd": "2211.03524_4829262cecb9828817b33e0f9c907f91",
            "2211.03524_ca056bbc2d4d279f3c5285ee746350ad": "2211.03524_5579f4787eefd1d1c376e39fa934fedd",
            "2211.03524_d621ce0aedeefec30ca5a669b34a6855": "2211.03524_5579f4787eefd1d1c376e39fa934fedd",
            "2211.03524_5cd663fc9219a761d9190940307857ae": "2211.03524_5579f4787eefd1d1c376e39fa934fedd",
            "2211.03524_07a178e7fb7bb3221b896c88c7b51233": "2211.03524_5579f4787eefd1d1c376e39fa934fedd",
            "2211.03524_feb8fbabd70d0afca1c994a477267544": "2211.03524_4829262cecb9828817b33e0f9c907f91",
            "2211.03524_0f55f9c994322adde74d75909394604b": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_64473f6f6a32ddfe086078ca4424e058": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_ef06f2980be482803f5379c5cf70e135": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_5281c21aa165259c0b9528789fc287dd": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_59c73d741be7e94f8be9348f0b000748": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_f9e0b9523f560cb85484cae3d61a95c1": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_a9454986dff6bed99962398b21f4e071": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_3bf3efaafd4030fa92b670d63227b335": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_a109556bde996514144e6683abb96852": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_14584a35bf9d04767200ca32692d136c": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_f5dc263c3e57235508ee17d7c176ffce": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_5208f476f33d25bf2bfafd655726201a": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_76a42cac553c9c10beb8679370b225e7": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_68b97d8d3ba87710c31da8c1c0fa76db": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_24fc673195a7239d2a99758596e2a599": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_03395d075a21a912186391c687f73799": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_a29a6e201f606b708916e6d177fd915b": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_51449f9af43ff76a96440970f4a2c94e": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_bdea8edbca373ff7d962ba548a4bbefa": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_8279aa46bd1a01ff72e8794d6ffd8ad6": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_7148e3d77dc3533029cfe554b9d8fd86": "2211.03524_feb8fbabd70d0afca1c994a477267544",
            "2211.03524_e946a6e8485f669e35fcc920b9dd22b2": "2211.03524_4829262cecb9828817b33e0f9c907f91",
            "2211.03524_8e03ac60cf544426a232402e938691d5": "2211.03524_e946a6e8485f669e35fcc920b9dd22b2",
            "2211.03524_fb5e4fd5fb85e3b4a69f304d9e86f3c0": "2211.03524_e946a6e8485f669e35fcc920b9dd22b2",
            "2211.03524_75bacc3aa58018ad6d31d619d8a33ae3": "2211.03524_e946a6e8485f669e35fcc920b9dd22b2",
            "2211.03524_70157143e063320e473816f25ccd3635": "2211.03524_e946a6e8485f669e35fcc920b9dd22b2",
            "2211.03524_51c45b795d5d18a3e4e0c37e8b20a141": "2211.03524_e946a6e8485f669e35fcc920b9dd22b2",
            "2211.03524_9ff71badc7bb5be717d678967666d0c2": "2211.03524_e946a6e8485f669e35fcc920b9dd22b2",
            "2211.03524_8d367b6caf63243a49b210cd81d1a72a": "2211.03524_e946a6e8485f669e35fcc920b9dd22b2",
            "2211.03524_dba49dc19fbc8226829ae5b40af29ba8": "2211.03524_e946a6e8485f669e35fcc920b9dd22b2",
            "2211.03524_aed402c3112b4749a9a98a72cbe9093d": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b": "2211.03524_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03524_2acc83398896b345157b054bf10c5722": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_791f96a551c007ce3dd773bbfe6a94e1": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_d54212adc29709f5de29853690b549b4": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_9e48ef2cc8b3f8d26b006a5ac0aa0b53": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_07e1d4b8bca1ca5602463b09bf5c443f": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_f24a16f204aa61db5b1584bc2db8f98e": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_b0ea4d29cbde15c03b16bb31eb51f14f": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_1c9896b6d1206cee08c205d2341a562f": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_3758da54f3011e970e54e57b3370ac03": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_483bd5b4d4976fca64a209f7a906227d": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_b3adae4156d780a03594d9e5c06b270e": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_705e5d4885f87f0ff484d2f70387cfde": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_9e70cb918019d45a0bf5261e7451ba8f": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_a56c89d3c688cca621556188e4f9e10f": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_8c0cf8c83c14d997da6a2032f4cc1c77": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_0be5f5e5ad1770c80299ed7f391dd37f": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_943c62e711565edcec17706c4eef97f4": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_814b6f754a821f4784d1f3439db1bc3b": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_4e1de59bd2009d7e3968e70232bc7bd0": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_32e2d5719555466bdb4aefe65899df7e": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_047561083781873091efd984e09d6334": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_d43c674f7e6fc59260cb2d6cd8a90a28": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_b6a89cee59803b7fa1665f4326ae520e": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_28146205695a86b3c8b9d87fe13678c1": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_891409ad114c07e47d9c924f48bfea0d": "2211.03524_2c1968d8a1efc68399afd49fd9b1e73b",
            "2211.03524_699d18833ec9592b04834df425c9090d": "2211.03524_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03524_6771da3d5782f0ea55f0e6c1a0fe5835": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_6539a03b56959af71fc49043e5cdd134": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_9ddc20aa5d5424dcf418dd24110e13f4": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_e18353e888a70bad25d70381e764b69e": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_68d0ccba1d13929f157dcab91325f305": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_9e80aa7beade1f6c5ac2e082b340e1e0": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_abb02501f8c4c74e020bf1b9e5935db8": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_cf662cc8a8ab16780774fb0dc4f1bd45": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_4ba0bab8d130572e9c2742a5aba3a709": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_1531b42fdb23fd6af246203a2ade1538": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_39ef66293508d503966e24bf51101dff": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_4b561fdfea529ee9d0ba20a91d8758c2": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_eb3a371151e468d2237ff6c709ed7d61": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_02fe527b114e17d6ae95ba635037be35": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_1871661ca82b182e09655d98540b0659": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_b2388e0c17a7e8dc2c33858ceef92d3f": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_69bd6cf96c6c636443855f8a8235e555": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_fce5228d5eade5a2e0c88bedab5e348a": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_6796b16720067de80a6bc869ea6b250b": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_018008124e9b6d38982aa52de68d247d": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_e1d09d5a2e13bb50f3a16870363b8ab5": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_22bdf76942d457c659a7302a4487a785": "2211.03524_699d18833ec9592b04834df425c9090d",
            "2211.03524_6f8b794f3246b0c1e1780bb4d4d5dc53": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_f1c6a59eaed6776e58459183796f49ea": "2211.03524_6f8b794f3246b0c1e1780bb4d4d5dc53",
            "2211.03524_13cba83b203e04deb1cbed5379069258": "2211.03524_6f8b794f3246b0c1e1780bb4d4d5dc53",
            "2211.03524_e9b88f24f62e105124a102f48e4078fb": "2211.03524_6f8b794f3246b0c1e1780bb4d4d5dc53",
            "2211.03524_afeb4f4879ee14f97040954172efb72e": "2211.03524_6f8b794f3246b0c1e1780bb4d4d5dc53",
            "2211.03524_6dde2ec54e97056f4e9672c969dbd464": "2211.03524_6f8b794f3246b0c1e1780bb4d4d5dc53",
            "2211.03524_e646e16bee8b32e6ea29e30d01970a6c": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_5fc39a9d6e49e25bba1e8988295db50f": "2211.03524_e646e16bee8b32e6ea29e30d01970a6c",
            "2211.03524_07bb3940d33e8d3d871d89dd32c37bf1": "2211.03524_e646e16bee8b32e6ea29e30d01970a6c",
            "2211.03524_5a510e1fe535a7dd3319031d9ca48b60": "2211.03524_e646e16bee8b32e6ea29e30d01970a6c",
            "2211.03524_381c722b131156173f3046b4f2b614fa": "2211.03524_e646e16bee8b32e6ea29e30d01970a6c",
            "2211.03524_bdb1d0a26959c504dd319b7da3933b79": "2211.03524_e646e16bee8b32e6ea29e30d01970a6c",
            "2211.03524_732052832940835781b9d33a918f46ee": "2211.03524_e646e16bee8b32e6ea29e30d01970a6c",
            "2211.03524_91ab18032f3cc81ae7c7e6bdd0addf99": "2211.03524_e646e16bee8b32e6ea29e30d01970a6c",
            "2211.03524_f983bfc854e254a8514782c7c50f49e3": "2211.03524_e646e16bee8b32e6ea29e30d01970a6c",
            "2211.03524_088221303d069096e3ca6e896eded063": "2211.03524_e646e16bee8b32e6ea29e30d01970a6c",
            "2211.03524_a992c603b5c8849693124012e398e805": "2211.03524_e646e16bee8b32e6ea29e30d01970a6c",
            "2211.03524_527b5dd477abf95e8fe19aac201df396": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_befe590610aca483f5f09c9b75454961": "2211.03524_527b5dd477abf95e8fe19aac201df396",
            "2211.03524_bb050154059aa3649156a8562fd4f411": "2211.03524_e353dbe42c8654f33588d4da0b517469",
            "2211.03524_3457fcc98e70b7204fee74a82b260b60": "2211.03524_bb050154059aa3649156a8562fd4f411",
            "2211.03524_50fb7ce4aa7dc02112d0fdfa0721f120": "2211.03524_bb050154059aa3649156a8562fd4f411",
            "2211.03524_f11b1892b308219697bfce55cd3c83cf": "2211.03524_bb050154059aa3649156a8562fd4f411",
            "2211.03524_51a0f7b64b9202fe8b90052c52a0c285": "2211.03524_bb050154059aa3649156a8562fd4f411",
            "2211.03524_13a102be23513c9226a90a259496569d": "2211.03524_bb050154059aa3649156a8562fd4f411",
            "2211.03524_e8a66ae6d7ec9ad9dc95198a2023f7b3": "2211.03524_bb050154059aa3649156a8562fd4f411",
            "2211.03524_d1a1690bae535d291e3bcea9e875eaab": "2211.03524_bb050154059aa3649156a8562fd4f411"
        }
    }
}