{
    "2006.10742": {
        "title": "Learning Invariant Representations for Reinforcement Learning without Reconstruction",
        "authors": [
            "Amy Zhang",
            "R. McAllister",
            "R. Calandra",
            "Y. Gal",
            "S. Levine"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "518b827e340c26582b5093401283a4f5cff605b9"
    },
    "2005.01643": {
        "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems",
        "authors": [
            "S. Levine",
            "Aviral Kumar",
            "G. Tucker",
            "Justin Fu"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "5e7bc93622416f14e6948a500278bfbe58cd3890"
    },
    "2401.09561": {
        "title": "Sharing Knowledge in Multi-Task Deep Reinforcement Learning",
        "authors": [
            "Carlo D'Eramo",
            "Davide Tateo",
            "Andrea Bonarini",
            "Marcello Restelli",
            "J. Peters"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "e74aded7d0839af48706c51a7b55af2ea20f0603"
    },
    "1912.01703": {
        "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
        "authors": [
            "Adam Paszke",
            "Sam Gross",
            "Francisco Massa",
            "Adam Lerer",
            "James Bradbury",
            "Gregory Chanan",
            "Trevor Killeen",
            "Zeming Lin",
            "N. Gimelshein",
            "L. Antiga",
            "Alban Desmaison",
            "Andreas Köpf",
            "E. Yang",
            "Zachary DeVito",
            "Martin Raison",
            "Alykhan Tejani",
            "Sasank Chilamkurthy",
            "Benoit Steiner",
            "Lu Fang",
            "Junjie Bai",
            "Soumith Chintala"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1"
    },
    "1911.08265": {
        "title": "Mastering Atari, Go, chess and shogi by planning with a learned model",
        "authors": [
            "Julian Schrittwieser",
            "Ioannis Antonoglou",
            "T. Hubert",
            "K. Simonyan",
            "L. Sifre",
            "Simon Schmitt",
            "A. Guez",
            "Edward Lockhart",
            "D. Hassabis",
            "T. Graepel",
            "T. Lillicrap",
            "David Silver"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "c39fb7a46335c23f7529dd6f9f980462fd38653a"
    },
    "1906.02736": {
        "title": "DeepMDP: Learning Continuous Latent Space Models for Representation Learning",
        "authors": [
            "Carles Gelada",
            "Saurabh Kumar",
            "Jacob Buckman",
            "Ofir Nachum",
            "Marc G. Bellemare"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "188dac491f04c56e1eb7d7b33ac6aa0b87303232"
    },
    "1901.09018": {
        "title": "Provably efficient RL with Rich Observations via Latent State Decoding",
        "authors": [
            "S. Du",
            "A. Krishnamurthy",
            "Nan Jiang",
            "Alekh Agarwal",
            "Miroslav Dudík",
            "J. Langford"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "bfec7990ecda25be96291bb658ac16bd1193a08f"
    },
    "1812.11118": {
        "title": "Reconciling modern machine-learning practice and the classical bias–variance trade-off",
        "authors": [
            "M. Belkin",
            "Daniel J. Hsu",
            "Siyuan Ma",
            "Soumik Mandal"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "f86f1748d1b6d22870f4347fd5d65314ba800583"
    },
    "1812.02868": {
        "title": "Measuring and Characterizing Generalization in Deep Reinforcement Learning",
        "authors": [
            "Sam Witty",
            "Jun Ki Lee",
            "Emma Tosch",
            "Akanksha Atrey",
            "M. Littman",
            "David D. Jensen"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "d3e3a6254f040a7e3065c078497347f785072d2f"
    },
    "1807.01736": {
        "title": "Transfer with Model Features in Reinforcement Learning",
        "authors": [
            "Lucas Lehnert",
            "M. Littman"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "a90f4821f848b2a56ebfbc81037e70d31d9dcf96"
    },
    "1901.10964": {
        "title": "Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement",
        "authors": [
            "André Barreto",
            "Diana Borsa",
            "John Quan",
            "T. Schaul",
            "David Silver",
            "Matteo Hessel",
            "D. Mankowitz",
            "Augustin Žídek",
            "R. Munos"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "f650f1fd44ab0778d30577f8c2077b2ff58830da"
    },
    "1804.07193": {
        "title": "Lipschitz Continuity in Model-based Reinforcement Learning",
        "authors": [
            "Kavosh Asadi",
            "Dipendra Kumar Misra",
            "M. Littman"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "c4f529934b6f22aa38e014e295a9737daa6e7db5"
    },
    "1803.10122": {
        "title": "World Models",
        "authors": [
            "David R Ha",
            "J. Schmidhuber"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "ff332c21562c87cab5891d495b7d0956f2d9228b"
    },
    "1801.09624": {
        "title": "Learning the Reward Function for a Misspecified Model",
        "authors": [
            "Erik Talvitie"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "900d3c8362686923e289c7ed6bc96c201e65d69c"
    },
    "1708.00102": {
        "title": "Advantages and Limitations of using Successor Features for Transfer in Reinforcement Learning",
        "authors": [
            "Lucas Lehnert",
            "Stefanie Tellex",
            "M. Littman"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "78ea78b128fb53d895696b2805eb21ecd11ede3b"
    },
    "1707.06203": {
        "title": "Imagination-Augmented Agents for Deep Reinforcement Learning",
        "authors": [
            "S. Racanière",
            "T. Weber",
            "David P. Reichert",
            "Lars Buesing",
            "A. Guez",
            "Danilo Jimenez Rezende",
            "Adrià Puigdomènech Badia",
            "O. Vinyals",
            "N. Heess",
            "Yujia Li",
            "Razvan Pascanu",
            "P. Battaglia",
            "D. Hassabis",
            "David Silver",
            "D. Wierstra"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "600bfe5f0597ebd84898f0c4270ddfb3750594f5"
    },
    "1707.03497": {
        "title": "Value Prediction Network",
        "authors": [
            "Junhyuk Oh",
            "Satinder Singh",
            "Honglak Lee"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "cf020b27d06efb28f3e5db264aceeec1f397817b"
    },
    "1706.04317": {
        "title": "Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics",
        "authors": [
            "Ken Kansky",
            "Tom Silver",
            "David A. Mély",
            "Mohamed Eldawy",
            "M. Lázaro-Gredilla",
            "Xinghua Lou",
            "N. Dorfman",
            "Szymon Sidor",
            "Scott Phoenix",
            "Dileep George"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "157f77a508c1645a2609c9b265391e9d1bfa95e4"
    },
    "1703.03400": {
        "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
        "authors": [
            "Chelsea Finn",
            "P. Abbeel",
            "S. Levine"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "c889d6f98e6d79b89c3a6adf8a921f88fa6ba518"
    },
    "1612.08810": {
        "title": "The Predictron: End-To-End Learning and Planning",
        "authors": [
            "David Silver",
            "H. V. Hasselt",
            "Matteo Hessel",
            "T. Schaul",
            "A. Guez",
            "Tim Harley",
            "Gabriel Dulac-Arnold",
            "David P. Reichert",
            "Neil C. Rabinowitz",
            "André Barreto",
            "T. Degris"
        ],
        "submission_date": "2016",
        "SemanticScholarId": "39b19ea254b0952f2abd23ad899420749816bb1d"
    },
    "1612.05533": {
        "title": "Deep reinforcement learning with successor features for navigation across similar environments",
        "authors": [
            "Jingwei Zhang",
            "Jost Tobias Springenberg",
            "Joschka Boedecker",
            "Wolfram Burgard"
        ],
        "submission_date": "2016",
        "SemanticScholarId": "1a0d50fd4a3e52b25c0a662b687daeb8ea963b4b"
    },
    "1612.06018": {
        "title": "Self-Correcting Models for Model-Based Reinforcement Learning",
        "authors": [
            "Erik Talvitie"
        ],
        "submission_date": "2016",
        "SemanticScholarId": "ea22d6190b1ae38fefd391e3d6c48d8807d72626"
    },
    "1612.00222": {
        "title": "Interaction Networks for Learning about Objects, Relations and Physics",
        "authors": [
            "P. Battaglia",
            "Razvan Pascanu",
            "Matthew Lai",
            "Danilo Jimenez Rezende",
            "K. Kavukcuoglu"
        ],
        "submission_date": "2016",
        "SemanticScholarId": "ae42c0cff384495683192b06bd985cdd7a54632a"
    },
    "1612.00341": {
        "title": "A Compositional Object-Based Approach to Learning Physical Dynamics",
        "authors": [
            "Michael Chang",
            "T. Ullman",
            "A. Torralba",
            "J. Tenenbaum"
        ],
        "submission_date": "2016",
        "SemanticScholarId": "a1786540a4e15f0757e1b84a02f98ed436a969e0"
    },
    "1611.07078": {
        "title": "A Deep Learning Approach for Joint Video Frame and Reward Prediction in Atari Games",
        "authors": [
            "Felix Leibfried",
            "Nate Kushman",
            "Katja Hofmann"
        ],
        "submission_date": "2016",
        "SemanticScholarId": "716776b39660f9e13859fa79790eb416d826fff3"
    },
    "1606.05312": {
        "title": "Successor Features for Transfer in Reinforcement Learning",
        "authors": [
            "André Barreto",
            "Will Dabney",
            "R. Munos",
            "Jonathan J. Hunt",
            "T. Schaul",
            "David Silver",
            "H. V. Hasselt"
        ],
        "submission_date": "2016",
        "SemanticScholarId": "d8686b657b61a37da351af2952aabd8b281de408"
    },
    "1606.02396": {
        "title": "Deep Successor Reinforcement Learning",
        "authors": [
            "Tejas D. Kulkarni",
            "A. Saeedi",
            "Simanta Gautam",
            "S. Gershman"
        ],
        "submission_date": "2016",
        "SemanticScholarId": "10a4992ece5baea79326a8878a6244eeacbc6af5"
    },
    "1512.03385": {
        "title": "Deep Residual Learning for Image Recognition",
        "authors": [
            "Kaiming He",
            "X. Zhang",
            "Shaoqing Ren",
            "Jian Sun"
        ],
        "submission_date": "2015",
        "SemanticScholarId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d"
    },
    "1511.06295": {
        "title": "Policy Distillation",
        "authors": [
            "Andrei A. Rusu",
            "Sergio Gomez Colmenarejo",
            "Çaglar Gülçehre",
            "Guillaume Desjardins",
            "J. Kirkpatrick",
            "Razvan Pascanu",
            "Volodymyr Mnih",
            "K. Kavukcuoglu",
            "R. Hadsell"
        ],
        "submission_date": "2015",
        "SemanticScholarId": "1c4927af526d5c28f7c2cfa492ece192d80a61d4"
    },
    "1507.08750": {
        "title": "Action-Conditional Video Prediction using Deep Networks in Atari Games",
        "authors": [
            "Junhyuk Oh",
            "Xiaoxiao Guo",
            "Honglak Lee",
            "Richard L. Lewis",
            "Satinder Singh"
        ],
        "submission_date": "2015",
        "SemanticScholarId": "e4257bc131c36504a04382290cbc27ca8bb27813"
    },
    "1412.6980": {
        "title": "Adam: A Method for Stochastic Optimization",
        "authors": [
            "Diederik P. Kingma",
            "Jimmy Ba"
        ],
        "submission_date": "2014",
        "SemanticScholarId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8"
    },
    "1312.5602": {
        "title": "Playing Atari with Deep Reinforcement Learning",
        "authors": [
            "Volodymyr Mnih",
            "K. Kavukcuoglu",
            "David Silver",
            "Alex Graves",
            "Ioannis Antonoglou",
            "D. Wierstra",
            "Martin A. Riedmiller"
        ],
        "submission_date": "2013",
        "SemanticScholarId": "2319a491378867c7049b3da055c5df60e1671158"
    },
    "1207.4114": {
        "title": "Metrics for Finite Markov Decision Processes",
        "authors": [
            "N. Ferns",
            "P. Panangaden",
            "Doina Precup"
        ],
        "submission_date": "2004",
        "SemanticScholarId": "2c85356cd182c16e0a2e5c4a97112efbc1132cdf"
    },
    "1106.1822": {
        "title": "Efficient Solution Algorithms for Factored MDPs",
        "authors": [
            "Carlos Guestrin",
            "D. Koller",
            "Ronald E. Parr",
            "Shobha Venkataraman"
        ],
        "submission_date": "2003",
        "SemanticScholarId": "2430b4748c4ffe8782ae4763d327ce48f3655639"
    }
}