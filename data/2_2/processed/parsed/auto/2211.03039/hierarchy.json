{
    "elements": {
        "2211.03039_70bd5acae03c22d5eddd06ef18ff5a0a": "Document Root 2211.03039",
        "2211.03039_708aede88adbc288358e60e7a474bb44": "=1",
        "2211.03039_e353dbe42c8654f33588d4da0b517469": "Abstract",
        "2211.03039_c85f8e8661ee3c776340f99397be3cfe": "Pre-trained Language Models (PLMs) have been applied in NLP tasks and achieve promising results",
        "2211.03039_bfb550fb9baee17d872c7ba045d30bfe": "Nevertheless, the fine-tuning procedure needs labeled data of the target domain, making it difficult to learn in low-resource and non-trivial labeled scenarios",
        "2211.03039_9f24a491938cce72ce342d5db97a9959": "To address these challenges, we propose Prompt-based Text Entailment (",
        "2211.03039_6abd71ca1b06e74f8504efcd944cbd69": ") for low-resource named entity recognition, which better leverages knowledge in the PLMs",
        "2211.03039_e1dbed4201e36f47a4fe0c89389b4537": "We first reformulate named entity recognition as the text entailment task",
        "2211.03039_80ae9c64057ed10061508323ce0caea2": "The original sentence with entity type-specific prompts is fed into PLMs to get entailment scores for each candidate",
        "2211.03039_c0bf77e39f24b5755d87a9263928af62": "The entity type with the top score is then selected as final label",
        "2211.03039_637beb8fad53c5e9868d3840c260bd98": "Then, we inject tagging labels into prompts and treat words as basic units instead of n-gram spans to reduce time complexity in generating candidates by n-grams enumeration",
        "2211.03039_40446ab153e6fab83c0658703c1e3f71": "Experimental results demonstrate that the proposed method",
        "2211.03039_b53468de021cf130d598d30e612f924d": "achieves competitive performance on the CoNLL03 dataset, and better than fine-tuned counterparts on the MIT Movie and Few-NERD dataset in low-resource settings.",
        "2211.03039_0b79795d3efc95b9976c7c5b933afce2": "Introduction",
        "2211.03039_f217b641b56b64ace4bfdce471e884b8": "Recently, Pre-trained Language Models (PLMs) have achieved promising improvement on several NLP tasks",
        "2211.03039_3591000aa66732a3379ce0129c2f464b": "\\cite{bert,roberta,lan2019albert}",
        "2211.03039_a2cf0e8e1fc930aa09e144837ffb2feb": "Nevertheless, fine-tuning language models still needs a moderate number of labeled data for downstream tasks",
        "2211.03039_7f85794999733d02a4f4b19563930d33": "When difficulties result in limited labeled data available, the trained model shows large variance in downstream performance under full fine-tuning",
        "2211.03039_1d9df6341e4bfceef3b7ce949c5dfc15": "\\cite{DBLP:conf/iclr/MosbachAK21,huggface_prompt}",
        "2211.03039_8ae2798d21ff6f0c4d84a8490bd2e2ab": "For example, labeling technical and professional terms can be time-consuming and labor-intensive in medical scenarios",
        "2211.03039_5c7a4b29917a038ee0ed26f79ce90917": "Moreover, crowd-sourced annotation is also limited by the reality of existing samples (e.g., when online health assistants are applied to rare diseases)",
        "2211.03039_c22593d6016c18ce75629593eae43024": "To address learning challenges in these low-resource scenarios, researchers find that PLMs can learn well by prompt-based learning",
        "2211.03039_7fc3d4fc6a43e08f28b9f9224cf3c148": "\\cite{schick2020exploiting,schick2020s,ADAPET}",
        "2211.03039_dde5a88688201d97325f36cf94924a24": "Prompt-based learning models the probability of text directly; it does not need an extra fully-connected layer usually used by fine-tuning",
        "2211.03039_c4f6b3065457e6423bad004096ebd72f": "The main idea is to reformulate NLP tasks as cloze-style question answering for better using the knowledge in PLMs",
        "2211.03039_689d6ec53c5ef105e1a6a91aa9c4e330": "The model predicts the word probability of masked positions and then derives the final output via mapping relations between words and labels",
        "2211.03039_e66c0ccdd25d9b90c54c1d3775c27c62": "Previous works have shown the ability of prompt-based learning under low-resource settings",
        "2211.03039_40ed9570a9b7f2993d146fa8a163b0c7": "\\cite{schick2020exploiting,schick2020s,schick-etal-2020-automatically,Lester}",
        "2211.03039_cabbc139b7f74771c47e3eb24d94c92b": "For example,",
        "2211.03039_d95c1729cf5316ad16706b6c7ecefeb9": "some prompt-based works have explored in classification and generation tasks where it is relatively easy to reformulate into cloze-style tasks (cf",
        "2211.03039_d2c24d59e0baff4d0155fbdf62590867": "Section",
        "2211.03039_9371d7a2e3ae86a00aab4771e39d255d": ")",
        "2211.03039_75d75f767f6cdef038e7b8eb66072603": "Nevertheless, the application to Named Entity Recognition (NER) still poses challenges for current methods",
        "2211.03039_b723b8f94b2dda2ec76e9fadfa7d21be": "Unlike text classification and text generation, NER is the task of identifying named entities (e.g.,",
        "2211.03039_c0cb5f0fcf239ab3d9c1fcd31fff1efc": ",",
        "2211.03039_2c0ed90f468b084cedcac9ad21ee9252": ") in a given sentence, and each unit of the input needs to be predicted",
        "2211.03039_a872cb2ee851470752e5be2c5188da8f": "If we directly use Masked Language Modeling (MLM) head to predict each unit label, the lexical and semantic coherence are ignored as there exists latent relationships between the tokens",
        "2211.03039_031db50a8f3b9605c24d609a606a5516": "\\cite{lample2016neural,elmo,TENER}",
        "2211.03039_eaa9aae94a5f120da84e1851cf22a6e6": "In this work, we propose",
        "2211.03039_84c40473414caf2ed4a7b1283e48bbf4": "(",
        "2211.03039_44270214e0d0dc5a351be08ad5333fd5": ") for low-resource NER",
        "2211.03039_00b0b0cde8754564ffd2b135bf481522": "Firstly, we reformulate NER as a",
        "2211.03039_478f3a4c51824ad23cb50c1c60670c0f": "task",
        "2211.03039_ad96c6d0164ff33fd04eea1dd1db0978": "Textual Entailment (TE) is the task of studying the relation of two sentences, Premise (P) and Hypothesis (H): whether H is true given P",
        "2211.03039_845ba328b997b4cf18eca22d70b4ff5e": "\\cite{snli}",
        "2211.03039_13ee1a4eacfe79ea0644c2358f6ca92a": "Specifically, we treat the original sentence as premise and entity type-specific prompt as a hypothesis",
        "2211.03039_4c0f09d0c188e17fc2f385bf8b7dfac1": "Given an entity type, the P and H are fed into PLMs to get entailment scores for each candidate",
        "2211.03039_9515d8abe8bff11f9897bbe55630d762": "Then, the entailment score is the probability of a specific token at the mask position of the prompt",
        "2211.03039_f9d17a553456c93f95f1462a17c0aabc": "After that, the entity type with the top entailment score is selected as the final label",
        "2211.03039_e822bf10b2d1dca7ca0d850cae4de331": "During inference, we enumerate all possible text spans or words in the input sentence as named entity candidates",
        "2211.03039_e0217a84d93416117569d41cbb831eef": "\\cite{templatener}",
        "2211.03039_0a7ebc8ffc23ab0dd4adbdf23658526e": "The reformulation provides a unified entailment framework for NER tasks where annotations are insufficient, as the model shares the same inference pattern across different domains",
        "2211.03039_590b0871b94190f2e9dea85deb853508": "As such, we can also leverage generic text entailment datasets such SNLI",
        "2211.03039_5d44a4447eda2f57cf2197963bed3698": "and MNLI",
        "2211.03039_7a48c1e74151dc40827fc2cca9b3ce5a": "\\cite{mnli}",
        "2211.03039_a1dbdf68df267698bb8a5abf9e0b3491": "to pre-train models, which transfer knowledge from the general domain and get better performance in new domains",
        "2211.03039_6d1b696acc848e549fbaccd52f1ab837": "Our method can be a step forward towards the development of a solution for the low-resource NER because any new domain does not typically have extensive annotated data in the real world, whereas it is feasible to obtain a couple of examples (e.g., online assistant)",
        "2211.03039_262a98edd149534f568917b0c8619ac9": "Moreover, considering the existence of noisy annotations,",
        "2211.03039_05eea48aa76ccf6558e9051b522c64f5": "achieves competitive F1 score on the CoNLL03 dataset",
        "2211.03039_d3dcd95348d6253166e427de311f708f": "\\cite{conll03}",
        "2211.03039_1f56b1910f322cc10e6795c41ab6a037": ", and better than fine-tuned counterparts by a large margin on the MIT Movie",
        "2211.03039_1b74c3bc45570c8ad63a475a0deb5a15": "\\cite{mit-dataset}",
        "2211.03039_905cacabb1f8b7a3a9b5d4272718440d": "and Few-NERD datasets",
        "2211.03039_e5c74a52b00a21de9722905aab545a4c": "\\cite{fewnerd}",
        "2211.03039_a3d9c1b7730382a9aced8bdc055ee3fe": "in low-resource settings.",
        "2211.03039_4c3880bb027f159e801041b1021e88e8": "Method",
        "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b": "Low-Resource Named Entity Recognition",
        "2211.03039_d5317b1bc6a657f8dd1b910c7a9478af": "Given a sentence",
        "2211.03039_e4eb5c8cc760684619c45cbd5c99f721": "$\\mathbf{X} = (x_{1}, x_{2}, \\dots x_{N})$",
        "2211.03039_300c988f71b77286f29e0e5aa3d504ea": "which contains",
        "2211.03039_f9c4988898e7f532b9f826a75014ed3c": "$N$",
        "2211.03039_1d68ce7c1dbb10312055e43648b4f26b": "words, the task is to produce",
        "2211.03039_3ebf1208ec8b789bb69a99b017e0d03e": "$\\mathbf{Y} = (y_{1}, y_{2}, \\dots y_{N})$",
        "2211.03039_eb7f46019127afce1fa7a65b3ad4931a": "which is the sequence of entity tags",
        "2211.03039_48620feaeb4ff61c808bc277cd17b647": "The tag",
        "2211.03039_192bb7f9b2a1376049fc150a7069e8f5": "$y_{i}\\in\\mathcal{Y}$",
        "2211.03039_f2a7eb6092cd378fbc9108e0718d4c44": "(e.g., B-LOC, I-PER, O) denotes the type of entity for each word",
        "2211.03039_dc80c8df8d6a3120a158fb62653b1321": "$x_{i}$",
        "2211.03039_a29f17caa3e965b909d1aef183a202e4": ", where",
        "2211.03039_fce9019a5e1fa63e079199cd9b11c55e": "$\\mathcal{Y}$",
        "2211.03039_11b060bc741548c3081237a2b3938914": "is a pre-defined set of tags",
        "2211.03039_f7dd294a42b138e63f3c35275255b3f6": "We are given a low-resource NER dataset",
        "2211.03039_995ad9771cbaa6367aece30812d36cc4": "$\\mathcal{D}_{\\text{train}}$",
        "2211.03039_dcae0abcf09f8345da2d20e34535a112": ", where the labeled examples to each NER type (e.g.,",
        "2211.03039_0f335855c35a8c615e822b0a9a8a2d88": "$<50$",
        "2211.03039_2fe39d1449c9beb10e1d955ad7f8dc01": ") are substantially less than that in the rich-resource NER dataset",
        "2211.03039_169c550735d170b96f499fee287216d0": "Our goal is to train an accurate NER model under this low-resource setting",
        "2211.03039_065a12795c741412124c164e9633eb36": "Previous methods usually treat NER as a sequence labeling task in which a neural encoder such as LSTM and BERT is used for representing the input sequence, and a softmax or a CRF layer is equipped as the output layer to get the tag sequence",
        "2211.03039_3874e1e7c3d06431da31da798f869ecf": "Formally, as the standard fine-tuning, NER model",
        "2211.03039_b5eaea000e06d5cf2e882f8fdbc71e36": "$\\mathcal{M}$",
        "2211.03039_e8f38282cd7b60d09582f88c465ad505": "parameterized by",
        "2211.03039_27e556cf3caa0673ac49a8f0de3c73ca": "$\\theta$",
        "2211.03039_4a39f9bc730ec1c3ce0439001d343a3e": "is trained to minimize the cross-entropy loss over token representations",
        "2211.03039_c521d04c38a4daa0db554966169409a4": "$\\mathbf{H} = [h_{1}, h_{2}, \\dots h_{N}]$",
        "2211.03039_6adbacb3f316f8c198a630f35a45142c": "that are generated from the neural encoder as follows:",
        "2211.03039_a5df1b8d7481c9168026e84934d22ca0": "\\begin{equation}\n\\mathcal{L}=-\\sum_{i=1}^{N} \\log f_{x_{i}, y_{i}}(\\mathbf{h} ; \\theta),\n\\end{equation}",
        "2211.03039_567904efe9e64d9faf3e41ef402cb568": "where",
        "2211.03039_190083ef7a1625fbc75f243cffb9c96d": "$f$",
        "2211.03039_c411ce9398a74c1e24d17801cb913e6d": "is the model's predicted conditional probability for golden label.",
        "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326": "Prompt-based Text Entailment",
        "2211.03039_223570432b30c86a7ea2b2aef9792d84": "Towards the low-resource NER task, a common way is to pre-train the neural encoder and output layer parameters with the rich-resource NER dataset",
        "2211.03039_043ea3dec61059693db0fe5b74ae0f36": "Another feasible way is to focus on the matching function learned by prototype-based network",
        "2211.03039_b9a790615116d6b66904a79159ae5b25": "\\cite{proto1}",
        "2211.03039_3070192562553c677e1a9a4911f44db9": "or nearest neighbor classification",
        "2211.03039_6395852169d4b4e2d09840e3f8b5cdb2": "\\cite{proto2}",
        "2211.03039_27ec9facfd9ea21c94c0ad5540d09455": "After that, a well-trained matching function can work well in the target tasks",
        "2211.03039_ce801644a749abfedcd80a396b61301d": "However, since the entity category is different, the parameter for the low-resource domain cannot be transferred directly from the source domain",
        "2211.03039_3294829ae6bb3aa97d5a6796aad07c42": "Moreover, the metric-based meta-learning methods assume that training and test tasks are in the same distribution but this assumption may not always be satisfied in practice",
        "2211.03039_cbb66f1b6f1a8aebff7315056d2ee19a": "\\cite{yin2020meta}",
        "2211.03039_f66eb4e7030d348a7dd3b32871d20686": "In this work, we reformulate named entity recognition as the text entailment task",
        "2211.03039_8cd041452821338d00bce0348c94051d": "As the NER task is not a standard entailment problem, we convert NER examples into labeled entailment instances",
        "2211.03039_51fa3e5893c395aa10aee106698651b3": "The input includes the original sentence as premise and entity type-specific prompt as a hypothesis (i.e., template)",
        "2211.03039_556e6e59c5d6ce6fea0c72f0dab24267": "The output is produced by an entailment classifier, predicting a label for each instance",
        "2211.03039_f6e7b6024ef519cc92e0785af75f39bf": "The entailment score is the probability of a specific token at the mask position of the prompt",
        "2211.03039_551b40dc0845d87679232a6ea42e173b": "Then, the entity type with the top entailment score is selected as the final label",
        "2211.03039_6074e85731fddc6d8204456d4feca68c": "For example, given a sentence",
        "2211.03039_226e747b0659adce4625544877c5d37d": "and a candidate",
        "2211.03039_8eb7693ed18753b01c8ac36595e57268": ", we define",
        "2211.03039_4afdc0615ef84ecda570d0cef898e562": "as prompt for each entity type",
        "2211.03039_6193195471fcc8693e0b9faac4a4567c": "Suppose the entailment score of token",
        "2211.03039_2d608001d661d88844c65c16dafdf7e1": "at [MASK] for <location> type is the highest of all entity types, we finally choose",
        "2211.03039_87d6497a017a6f8c3692c408c61f5a2d": "as the predicted label",
        "2211.03039_ee2bdbdfae3e73b8f00f8f846693130e": "For training, we sample three types of negative examples (see Appendix",
        "2211.03039_42974f01f9942ba3ee4a19ed85a9979c": "): false positive (i.e., replace the correct label with others), null label (i.e., replace the correct label with null), and non-entity replacement (i.e., replace golden entity with non-entity span)",
        "2211.03039_47484a608a9961415a8745ed2971506d": "is one prompt of",
        "2211.03039_32af0e11d7efeb90f93c912ce043e9c2": "false positive",
        "2211.03039_f8afc9908612e7375c3a174bc47952db": "example (i.e., the [MASK] label is",
        "2211.03039_153c955623a02570a9019ecb36180311": ", and it exists entities)",
        "2211.03039_2823e68a48295925aac49f17973d1679": "During training and inference, we can enumerate all possible text spans in the input sentence as named entity candidates",
        "2211.03039_e47d6f6b92cdfb696181c844f74e0e69": "To further reduce time complexity in generating candidates by n-grams enumeration, we inject tagging labels (e.g., I-location means the tag is inside a entity) into prompts and treat words as basic units instead of text spans during training and inference",
        "2211.03039_459e725ed0b6093d980b345a3d3a6972": "In other words, we consider prompts",
        "2211.03039_5ef85abe1a9b4e2dc8b00f22b32baca5": "(e.g.,",
        "2211.03039_131df25d463fa767af1eddfb826ad67c": "As PTE treats words as basic units for decoding, it optimizes time complexity at inference to O(L), which is in line with previous NER methods",
        "2211.03039_9e1cf0e585d14f3b7a1751c880033987": "It optimizes quadratic costs at inference to linear",
        "2211.03039_f157644a78cbefc1075e6554608d9562": "We also apply the Viterbi algorithm at inference, where transitions are computed on the training set",
        "2211.03039_77e57ba31d82d741769788a1ba3f42fe": "\\cite{DBLP:conf/acl/HouCLZLLL20}",
        "2211.03039_af558b33c4b52dba1aa92e371dc31c59": "The computational complexity of n-grams enumeration is O(",
        "2211.03039_e8831293b846e3a3799cd6a02e4a0cd9": "$L^2$",
        "2211.03039_801ade39dbf175c166bf45e4db57fae4": "), increasing quadratically with sequence length L. Overall, our method provides a unified entailment framework as the model shares the same inference pattern across different domains.",
        "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445": "Pattern Exploiting Training Framework",
        "2211.03039_09e0724f7e4c91b870438ed8a0596ce2": "The basic framework of",
        "2211.03039_de1e07d2e73389bf0e7352f392dd2a16": "is from",
        "2211.03039_decf9afa2f7ba1ec5e1eecc9ac93946c": "\\cite{ADAPET}",
        "2211.03039_11b00ac2005319804fc92a8e90e78d1c": "which is a variant of",
        "2211.03039_690c087bf39b56b77a2ba0f26d907031": "\\cite{schick2020exploiting, schick2020s}",
        "2211.03039_1137fc97bd701b044ef399768d5ec186": "Compared with",
        "2211.03039_68813ee50a90e1f482f7ebbe593ae775": "uses more supervision by decoupling the losses for the label tokens and a label-conditioned MLM objective over the total original input",
        "2211.03039_ee89c35444f2d3092d69e58a989251ec": "We introduce it by describing how to convert one example into a cloze-style question",
        "2211.03039_09761eea4e1c19514d7b4a22bec3bfb7": "The query-form in",
        "2211.03039_1b67e23d3c36e6bb34060982f8fa7b3a": "is defined by a Pattern-Verbalizer Pair (PVP)",
        "2211.03039_9033011b40e50fdb73506b4642879c19": "Each PVP consists of one pattern which describes how to convert the inputs into a cloze-style question with masked out tokens, and one verbalizer which describes the way to convert the classes into the output space of tokens",
        "2211.03039_6475de3c932cb3ab1ab64a2d9663cb22": "The PVP can be manually generated",
        "2211.03039_e7244cde98eb1890c0212ac6a9bf98a0": "\\cite{auxiliary-absa,lama}",
        "2211.03039_05923ac01f0d5c8cc7fa964326dd44f4": "or obtained by using an automatic search algorithm",
        "2211.03039_fe547e162fbd8bb2528a65225584ab3b": "\\cite{schick-etal-2020-automatically, gao2020making}",
        "2211.03039_5058f1af8388633f609cadb75a75dc9d": ".",
        "2211.03039_ea732dd9edf3771962ae83492e521517": "After that,",
        "2211.03039_23c4b427c97161f90317de1be93fc42b": "obtains logits from the model",
        "2211.03039_3a681eeaca73c2560d5e4344c9537719": "$G_m(x)$",
        "2211.03039_fbfafe237032d652296841dc19cb878e": "Given the space of output tokens",
        "2211.03039_aec0660726c0c3ba7c3dc36d9b6dbfcb": "computes a softmax over",
        "2211.03039_c89a5f676ef318a628043180c0d2d924": "$y \\in \\mathcal{Y}$",
        "2211.03039_0d563d57b04e757c7e8a2b4ca7adfdf3": ", using the logits from",
        "2211.03039_8679acf5457b92bc7e67570eda931846": "The final loss is shown as follows:",
        "2211.03039_a7a1cc239a13a67da5b9a2b525c31687": "Cross Task and Domain Transfer",
        "2211.03039_3fe3b0bef745b614a8c68b6ee4d1f5be": "To address the challenge when few labeled examples are available, we further train the sentence encoder on the TE datasets (e.g., MNLI) and apply it to the NER task",
        "2211.03039_ef1fc963c9ef818482bfc7b62aee77a3": "Then, our method can perform more knowledge transfer between the rich-resource NER dataset and the low-resource NER dataset",
        "2211.03039_b57bf9fd554644514d17235f25a20f5e": "Since there is no domain-related fully connected layer for fine-tuning, all parameters can be transferred in different domains even if the entity category does not match",
        "2211.03039_782f40fbd44a5ff265899b3739ca60b0": "Specially, we apply the text entailment method to the low-resource domain after firstly pre-training the NER model in the rich-resource domain",
        "2211.03039_9eb2c115260de55e67fa5087652d36e0": "This process is simple but can effectively transfer label knowledge",
        "2211.03039_af3e60a7199152a8851df7008fdbbdef": "As the output of our method is model-agnostic words (not tag index), the tag vocabulary with rich-resource and low-resource is a shared pre-trained language model vocabulary set",
        "2211.03039_a9e5641be3a70d63dff0fba9011d5c2b": "It allows our method to use the correlation of tags to enhance the effect of cross-domain transfer learning.",
        "2211.03039_4829262cecb9828817b33e0f9c907f91": "Experiments",
        "2211.03039_cda30a6d07967e09b5d348d2f9306dc1": "We compare our methods with several baselines on both rich-resource settings and low-resource settings",
        "2211.03039_a836f54ea41109d63518862051ae9ec3": "We use the CoNLL2003",
        "2211.03039_56cd920a56488f9669fef2546f351176": "as the rich-resource dataset, and MIT Movie",
        "2211.03039_bffbe539e7c4a05c588331678bb4561b": ", Few-NERD",
        "2211.03039_fc8e90dce9f04f2e3805b9612b81e169": "as the cross-domain low-resource datasets",
        "2211.03039_8c194122071d10e74d70fd4ddfa1d465": "And we conduct experiments on the CoNLL03 dataset in both full and low-resource settings",
        "2211.03039_3b753160288b6a3a00f407b49a7e352e": "The dataset statistics and experimental settings are included in Appendix",
        "2211.03039_be5d5d37542d75f93a87094459f76678": "and",
        "2211.03039_ef3eb2c11b1c0ff38002dca1a0c48825": "The standard precision, recall, and F1 score are used for model evaluation.",
        "2211.03039_798aedf4f2905f788893c61421cdc7ed": "Rich-Resource NER Results",
        "2211.03039_a1db0433e50c0e3a6ccd4ba9c4e0c545": "We first use the whole training set of the CoNLL03 to train the model and evaluate its performance on the test set",
        "2211.03039_51c45b795d5d18a3e4e0c37e8b20a141": "Table",
        "2211.03039_7a965d52c8d8c06fa38dc21fb006dd11": "shows the performance of the comparison method and our model on the test set",
        "2211.03039_7fd39b155cd25792189a3b45df4daba0": "We can find that although the potential applications of",
        "2211.03039_ceee975321c0ab90b8d719dfad236ee5": "is low-resource named entity recognition, it can also achieve competitive performance in rich-resource domain data sets",
        "2211.03039_3e2554f908eb18adbb813385c4be6e36": "Compared with BERT fine-tuning reported in the previous work, the",
        "2211.03039_2e658f8b4f8b47037ff6320e303021d3": "model using discrete manual design reduces the F1 by 0.32, while the",
        "2211.03039_7e26c09f9b2b84a7c6004bd0960c7f83": "model using the soft prompt method design mode",
        "2211.03039_e823ac25ef74ca053f48eff1242ef7d2": "\\cite{liu2021ptuning,ptuning}",
        "2211.03039_86b555e0f1f282c94c3a0221d1e8d9c2": "increases the F1 by 0.5",
        "2211.03039_a02b2c2958c2f9cf69a3c3c7eefaa34c": "It shows that our method effectively recognizes named entities, and soft prompts can improve performance compared with manually designed prompts",
        "2211.03039_5c84fd729009b66ccac4fee8cf315063": "More experimental results about TE patterns (",
        "2211.03039_80f52ea095a907d2610601176d5d4b60": ") are in the Appendix",
        "2211.03039_1457516a0e8e060af52e1b3402609ee3": "Cross Entity Type NER Results",
        "2211.03039_6f796b0e6deb4f4c2c0ee0ed5e10e117": "Following",
        "2211.03039_aa30f2df334851fcde2c276f63264627": "\\citet{templatener}",
        "2211.03039_42776608aa8d6ce44b463cac74f64acf": ", we sample the number of examples corresponding to different types of entities on the CoNLL03 data training set as new training set while keep test set unchanged",
        "2211.03039_3a3194f8468aef36d35c21e9ccd1956c": "Among them,",
        "2211.03039_12ae43e68edf9759c087f2b0db126479": "PER",
        "2211.03039_06f179e75bfac08c9b75c7f847f84a6b": "ORG",
        "2211.03039_2bca22f04f7a874735fc44b8f3dad4ed": "are rich-resource entity types, and",
        "2211.03039_7982b1597f92456d71b333fe2aead996": "LOC",
        "2211.03039_ca5c504c6136e20051be115160b0f0b8": "MISC",
        "2211.03039_96e44762bae7c64a1e634b42da3d6e2b": "are low-resource entity types",
        "2211.03039_0cec478ac359e9d447871bdce33224aa": "The experimental results are shown in Table",
        "2211.03039_6d6773f14fe2059ee673fc8e34449b60": "The results show that our method achieves better results than baselines on the low-resource entity types, thus improving overall performance",
        "2211.03039_56119dfbc7ac1b0ad1b5a33519be37a4": "On the other hand, our method is better than fine-tuning in both cases.",
        "2211.03039_d9f81e56a6929a52fc4aa145111f730e": "\\begin{table}[t!]\n\\centering\n\\small\n\\resizebox{\\linewidth}{!}{\n\\begin{tabular}{l|c|c|c}\n     \\hline\n    {\\bf Method} & {\\bf Precision} & {\\bf Recall} & {\\bf F1} \\\\\n    \\hline\n     % \\multicolumn{4}{c}{Traditional Models} \\\\\n    % \\hline\n    \\citet{label-agnostic} & - & - & 89.94 \\\\\n    \\citet{yang-etal-2018-design} & - & - & 90.77 \\\\\n    \\citet{lstm-cnn-crf} & - & - & 91.21 \\\\\n     BERT~\\cite{templatener} & 91.93 & 91.54 & 91.73 \\\\\n    \\citet{DBLP:conf/emnlp/YamadaASTM20} & - & - & \\bf{94.30} \n     \\\\\n     \\hline\n     Template BART~\\cite{templatener} & 90.51 & 93.34 & 91.90 \\\\\n     \n     \\texttt{PTE} (discrete) & 91.27 & 91.56 & 91.41 \\\\\n     \\texttt{PTE} (soft) & 92.01 & 92.45 & \\bf{92.23} \\\\\n     \\hline\n\\end{tabular}\n}\n\\caption{Model performance on the CoNLL03 test set.\\label{table:mp_conll}}\n\\end{table}",
        "2211.03039_cfee3df04e6934d42888970fd56aa5e7": "\\begin{table}[t]\n\\centering\n\\small\n\\resizebox{\\linewidth}{!}{\n\n\\begin{tabular}{l|c|c|c|c|c}\n     \\hline\n   \\textbf{Method} & {\\bf PER} & {\\bf ORG} & {\\bf LOC} & {\\bf MISC} & {\\bf Overall} \\\\\n    \\hline\n    BERT & 75.71 & 77.59 & 60.72 & 60.39 & 69.62 \\\\\n    Template BART & 84.49 & 72.61 & 71.98 & 73.37 & 75.59 \\\\\n    \\texttt{PTE} (BERT) & 85.34 & 72.89 & 73.01 & 74.32 & \\bf{76.40} \\\\\n     \\hline\n\\end{tabular}\n}\n\\caption{Cross entity type results on the CoNLL03. LOC and MISC are low-resource entity types, where PER and ORG are rich-resource entity types. \\label{table:conll_few}}\n% \\vspace{-2mm}\n\\end{table}",
        "2211.03039_62bba9fd2e439f7e569138a9e086c495": "Domain Transfer for Low-Resource NER",
        "2211.03039_c24f01ae76da86c6e2ddbeb466ed0e43": "\\begin{table}[t!]\n\\centering\n\\small\n\n\\vspace{-0.2cm}\n\\resizebox{\\linewidth}{!}{\n\\begin{tabular}{l|c|c|c|c|c|c}\\hline\n\\multicolumn{7}{c}{\\textit{MIT Movie} (12)}\\\\\n\\hline\n\n     \\textbf{Method} & {\\bf K=10} & {\\bf K=20} & {\\bf K=50} & {\\bf K=100} & {\\bf K=200} & {\\bf K=500} \\\\\n\\hline\n    \\citet{label-agnostic} &\\ 3.1 &\\ 4.5 &\\ 4.1 &\\ 5.3 &\\ 5.4 &\\ 8.6 \\\\\n    \\citet{example-ner} & 40.1 & 39.5 & 40.2 & 40.0 & 40.0 & 39.5 \\\\\n    Sequence Labeling BERT & 28.3 & 45.2 & 50.0 & 52.4 & 60.7 & 76.8 \\\\\n    \\citet{DBLP:conf/emnlp/YamadaASTM20} & 35.6 & 49.2 & 61.8 & 72.4 & 78.7 & 82.8 \\\\\n    % & \n    Template BART~\\cite{templatener} & 42.4 & 54.2 & 59.6 & 65.3 & 69.6 & 80.3 \\\\ \\hline\n     \\texttt{PTE} (discrete) & 46.9$\\dagger$ & 59.2$\\dagger$ & 66.9$\\dagger$ & 74.9$\\dagger$ & 79.9$\\dagger$ & 83.6\\\\\n     \\texttt{PTE} (soft) & \\textbf{47.8}$\\dagger$ & \\textbf{60.8}$\\dagger$ & \\textbf{68.1}$\\dagger$ & \\textbf{76.5}$\\dagger$ & \\textbf{83.6}$\\dagger$ & \\textbf{86.4}$\\dagger$ \\\\\n    \\hline \\hline\n    \\multicolumn{7}{c}{\\textit{Few-NERD} (8)}\\\\\\hline \n\n     \\textbf{Method} & {\\bf K=10} & {\\bf K=20} & {\\bf K=50} & {\\bf K=100} & {\\bf K=200} & {\\bf K=500} \\\\\n\\hline\n%     Source & Methods & 10 & 20 & 50 & 100 & 200 & 500 \\\\\n     \\citet{label-agnostic} &\\ 5.2 &\\ 4.1 &\\ 4.7 &\\ 7.8 &\\ 12.3 &\\ 10.1 \\\\\n     \\citet{example-ner} & 35.4 & 48.3 & 51.2 & 51.8 & 53.6 & 55.7 \\\\\n     Sequence Labeling BERT & 50.6 & 59.3 & 61.3 & 61.4 & 62.5 & 66.4 \\\\ \n     \\citet{DBLP:conf/emnlp/YamadaASTM20} & 51.7 & 60.1 & 62.3 & 61.0 & 62.5 & 66.8 \\\\ \n     \\hline\n     \\texttt{PTE} (discrete) & 51.8 & 59.7 & 60.5 & 61.3 & 61.8 & 63.4\\\\\n     \\texttt{PTE} (soft) & \\textbf{54.2} & \\textbf{61.4} & \\textbf{62.3} & \\textbf{62.5} & \\textbf{63.6} & \\textbf{67.4} \\\\\n \n\n\\hline\n\\end{tabular}\n}\n\\caption{\\label{tab:fewshot}F1 comparison of two low-resource NER datasets. We set 6 sample size $K$ for different low-resource settings. $\\dagger$ means a significant difference compared to Template BART ($p < .05$).}\n\\vspace{-0.2cm}\n% \\vspace{-2mm}\n\\end{table}",
        "2211.03039_e8d8f3f758250fac5aa0a1a7cf137253": "We do not use",
        "2211.03039_987c94b6a947783d954977f580122ad2": "-way",
        "2211.03039_d6328eaebbcd5c358f426dbea4bdbf70": "$K$",
        "2211.03039_c9ed7cca55bd649618b0dcdb7015005c": "-shot setting",
        "2211.03039_0813643d5567c0d26e4622e7e277f0d1": "\\cite{proto2,fewnerd}",
        "2211.03039_483b35f075c940daad4dc6c8a61873ef": "which samples",
        "2211.03039_61805bc6bad77f74247f24e47af945b8": "categories and",
        "2211.03039_dd10321006e606b99b579f4b1328d8aa": "examples for training in each episode because a sentence in the NER task may contain multiple entities from different types",
        "2211.03039_e600dbae7dad592ec5a80bdabe76d30c": "Thus, we randomly sample training data from the MIT Movie and Few-NERD datasets to simulate low-resource scenarios and use CoNLL03 as the rich-resource dataset",
        "2211.03039_1b654850f23f6901d908f55bced09866": "As such, we have only",
        "2211.03039_d6da906459f3c2f26222286daba98e61": "examples for each type of training",
        "2211.03039_23b868f41949ab56c790ffd6e86403e0": "We choose",
        "2211.03039_41ab89eb51f3012170301518bb135a5a": "$K\\in\\{10,20,50,100,200,500\\}$",
        "2211.03039_c2bedf7649f2c6aff01189cfd59bbbf0": "for experiments to evaluate the ability of the model on training data of different sizes",
        "2211.03039_db4ae72699f0ac36ac1e1618e049c075": "The experimental results are in Table",
        "2211.03039_a51cdaabc42425c1d88b25cefcc2ce74": "The results show that when the",
        "2211.03039_5c421b8fc6a2ec30472b344e145963ef": "value is relatively small, our",
        "2211.03039_b5c5c3bcb6a20573e954fe21c90ada85": "method can be better than the fine-tuning method, and this trend decreases with the increase of",
        "2211.03039_9ce8db5e68f8c0735b8825c28b84de99": "In addition, the soft mode is also better than the discrete mode in the case of a small number of samples",
        "2211.03039_91d9d79bad1cb5abeee571a77a499bde": "Overall, our method achieves the best results on both data sets in the low-resource scenario.",
        "2211.03039_20d10e7690dfde566c177cdea4fb24aa": "\\begin{figure}[t!]\n\\centering\n% \\small\n\\includegraphics[width=1.0\\linewidth]{ablation.pdf}\n  \\caption{F1 scores with different experimental settings and model variants.}\n  \\vspace{-4mm}\n   \\label{figablition}\n\\end{figure}",
        "2211.03039_feb8fbabd70d0afca1c994a477267544": "Ablation Study",
        "2211.03039_ff7762f26eebada0729ba7c96fcae6f3": "We conduct ablation experiments and the results are shown in Figure",
        "2211.03039_5148396766c7f4c15ae7667b19a9abcd": "The results show that (1) the selection of negative examples has a great impact on the performance of the model, especially the negative examples of the null label type",
        "2211.03039_2ff1dbf66f9ddee4caa1dc7092254e68": "However, in rich-resource scenario, the gap between full setting and decreased setting is not as much as the low-resource scenario; (2) the low-resource scenario is a challenge to the model, and the results of some variants are not inconsistent where prompt-based learning may not be as good as fine-tuning; (3) label conditioning and soft mode have a consistent effect on the model",
        "2211.03039_41d1d3ca7e3ed73e3ba9a6efe2a8d8e6": "These findings highlight that it still has room left to use prompt for effectively transferring knowledge in the case of low-resource scenario.",
        "2211.03039_aed402c3112b4749a9a98a72cbe9093d": "Related Work",
        "2211.03039_4c21f94ec432cd7f5a2937ef3140ebce": "\\citet{schick2020exploiting}",
        "2211.03039_77eb9408654cf9280db0afa76e180ef6": "address low-resource text classification by manually designing templates as prompt-based learning in a iterative training manner.",
        "2211.03039_e1289477f51c8e74663482443c8fd6db": "\\citet{gao2020making}",
        "2211.03039_254dcb99942b61acb6944e96ab5fe83e": "improve low-resource performance with well-designed templates with demonstrations.",
        "2211.03039_ee787914bf9379468130d62f901502cd": "\\citet{ptuning}",
        "2211.03039_88d089cdbd4ee3b6126848f292d5a7be": "apply continuous prompts for low-resource learning",
        "2211.03039_14e96863f15439e65ac124cbe70a8822": "Recently, some works",
        "2211.03039_bcc6bff7280870cd4dae1b958e8e261a": "\\cite{fewnerd,tong-etal-2021-learning,tempfree,LightNER}",
        "2211.03039_83519ef45684dda8df5a01b204735b21": "also focus on low-resource NER",
        "2211.03039_8fc132bcdfcd97fa8a3d5fb5de89a3d7": "In contrast, we propose to use prompt-tuning to treat NER as the TE task",
        "2211.03039_0944689dfb3e59e096a45147e7f6fa92": "Unlike traditional NER methods, we use prompt-based learning without an additional linear layer for fine-tuning",
        "2211.03039_9eca550bf0b824a50b96c0f81c15fa39": "By defining different prompts, the model is able to perform well in low-resource settings, which adapts to new domains with few labeled data",
        "2211.03039_f37580234f81471b3f78fe071e052d5d": "In contrast to recent work which also adopts prompt-based fine-tuning for NER",
        "2211.03039_f9015b562dec527beb47e10a697472ce": "\\cite{DBLP:journals/corr/abs-2109-13532}",
        "2211.03039_a4aa7be9de56ca886bc53ba8caf11b27": ", we show that the effectiveness of the text entailment reformulation for named entity recognition using PLMs.",
        "2211.03039_6f8b794f3246b0c1e1780bb4d4d5dc53": "Conclusion",
        "2211.03039_f21ef5e059b124d4d359df5fd780ef15": "In this paper, we apply prompt-based learning to low-resource named entity recognition",
        "2211.03039_64c24b282522ea04c01002786f648f69": "For token classification of NER, we reformulate it into a text entailment task",
        "2211.03039_56dda9a732b4f2f98747be604faf6106": "Our method transfers knowledge in different NLP tasks and domains, and performs better in low-resource scenarios",
        "2211.03039_6ff413504a055569291ac6855e2bc662": "Future work includes how to apply",
        "2211.03039_b091d43ab096e658a3970053ad805efa": "to other NLP tasks.",
        "2211.03039_8c73e08e59de906dd6d042b1d54c9d90": "*Acknowledgements",
        "2211.03039_7301e901ebaf23a78018b244f1323092": "We thank the anonymous reviewers for their insightful comments and suggestions",
        "2211.03039_17453a3aac610667c18faed46413486b": "This work is jointly supported by grants: Natural Science Foundation of China (No. 62006061,61872113,U1813215), Stable Support Program for Higher Education Institutions of Shenzhen (No",
        "2211.03039_9f0387ffc20fb040cb7a277dd8e1db6c": "GXWD20201230155427003-20200824155011001) and Strategic Emerging Industry Development Special Funds of Shenzhen(No",
        "2211.03039_8e8e8518dfb6f45fa3e4fe039db5765b": "JCYJ20200109113441941 and No",
        "2211.03039_5037e08fb0c5d51d2c9edc4df6e9f389": "XMHT20190108009).",
        "2211.03039_5a32a8c1c2d5a306163562b7daead774": "\\begin{table}[t!]\n\\centering\n    \\resizebox{\\linewidth}{!}{\n\\begin{tabular}{llccccc}\n\\toprule\n\\textbf{Datasets} & \\textbf{Domain} & \\textbf{\\# Type} &  \\textbf{\\# Tokens} & \\textbf{\\# Train} & \\textbf{\\# Dev} & \\textbf{\\# Test} \\\\\n\\midrule\nCoNLL03 & Reuters news stories & 4 & 21.0k & 14041 & 3250 & 3453 \\\\\nMIT Movie & Movie reviews & 12 & 6.0k & 7820 & 1955 & 2443\\\\\nFew-NERD & Wikipedia & 8 & 4601.2k & 131767 & 18824 & 37648 \\\\\n\\bottomrule\n\n\\end{tabular}}\n\\caption{Statistics of our datasets. We count the number of sentences in the training/development/test set, the number of tokens and the number of tags in datasets.}\n\\label{tab:dataset}\n\\end{table}",
        "2211.03039_bb2607864c67e364ec99bd0cccda055a": "\\begin{table}[t!]\n\\small\n    \\centering\n    \\resizebox{\\linewidth}{!}{\n    \\begin{tabular}{l|l}\n    \\hline\n        \\textbf{Type} & \\textbf{Templates} \\\\ \n    \\hline\n     Positive (Y) & <candidate> is the part of a <entity\\_type> entity. \\\\\n     \\hline\n     False positive (N) & <candidate> is the part of a <another\\_entity\\_type> entity. \\\\\n     \\hline\n     Non-entity (N) &  <others> is the part of a <entity\\_type> entity. \\\\\n     \\hline\n      \\multirow{2}{*}{Null label (Y/N)} & <others> is not a name entity. \\\\\n      & <candidate> is not a name entity.\\\\\n     \\hline\n \n    \\end{tabular}\n    }\n    \\caption{The discrete manually-crafted templates.}\n    \\label{tab:template}\n\\end{table}",
        "2211.03039_49396ea29a4bc1fe315583d82f138ec6": "\\begin{table}[t!]\n\\small\n    \\centering\n    \\resizebox{\\linewidth}{!}{\n    \\begin{tabular}{l|l}\n    \\hline\n      \\textbf{Number}  & \\textbf{Patterns} \\\\ \n    \\hline\n     Pattern\\#1 & [HYPOTHESIS] ? </s></s> [MASK], [PREMISE] </s> \\\\\n     \\hline\n      Pattern\\#2 & `` [HYPOTHESIS] '' ? </s></s> [MASK], `` [PREMISE] '' </s> \\\\\n     \\hline\n      Pattern\\#3 & [HYPOTHESIS] ? </s></s> [MASK]. [PREMISE] </s> \\\\ \n     \\hline\n       Pattern\\#4 & `` [HYPOTHESIS] '' ? </s></s> [MASK]. `` [PREMISE] '' </s> \\\\\n     \\hline\n \n    \\end{tabular}\n    }\n    \\caption{We list the patterns used by our method where <s> and </s> are start token and separated token.}\n    % sep_token='</s>', cls_token='<s>',\n    \\label{tab:pattern}\n\\end{table}",
        "2211.03039_cac2fb2387c36e91dc8022eadc17cdf1": "\\begin{figure}[t!]\n\\centering\n\\includegraphics[width=0.8\\linewidth]{pattern.pdf}\n  \\caption{The performance of different modes after up to 7000 training batches. The patterns we use are from RTE task of \\citet{ADAPET}. }\n  \\vspace{-4mm}\n   \\label{figpatt}\n\n\\end{figure}",
        "2211.03039_7df96b18c230f90ada0a9e2307226338": "Templates",
        "2211.03039_7f5effa802884cf674c4eeb8b5740750": "We use the naive random sampling method and the positive-negative ratio is 1:1.5 in the low-resource scenario after sampling",
        "2211.03039_24fc673195a7239d2a99758596e2a599": "As shown in Table",
        "2211.03039_f8da72e8df4eae188060bcfd644020a0": ", we list our templates for each example type used by",
        "2211.03039_56eedff9c82d406a4e2a072854eaa3c4": "(discrete)",
        "2211.03039_624d94623f05627998ba773eb1aee2cc": "Our soft prompt is to add different special tokens before the [MASK] to form a template and tune the embeddings of these tokens directly following",
        "2211.03039_41c1a81689fe3c2d53eac9c3ef39e730": "\\citet{typing}",
        "2211.03039_eee8961ee0263f9b5b554b0cdc559dcb": "used by",
        "2211.03039_a8fb897a965c878e00fceda66adaff2a": "(soft)",
        "2211.03039_8c176eb386389fb00abbb5be4b605820": "We leave it for future work to examine whether the NER performance further improves with a more well-designed soft prompt.",
        "2211.03039_274426c258ca87e26022241ee8637a67": "Dataset Statistics",
        "2211.03039_0ebd0dd97c4be80247623d1c59306639": "We use the following datasets where data statistics are displayed in Table",
        "2211.03039_faef25b51e0ddc0e4cacf718d92473a7": ": (1) The CoNLL03 dataset",
        "2211.03039_8234bfa73815cee3a25b832990674f13": "is from the English Reuters News and consists of 4 entity types",
        "2211.03039_7e1e8e914114b8157017f91ddc14060a": "We use the previous split in",
        "2211.03039_5de4fd645a7ca2259566906f610add78": "for our experiments",
        "2211.03039_303ecf13cde811b5022c976f6b9bb6ef": "The entity types are",
        "2211.03039_8a0e2b549d223aba55a866c38d1c9275": ", and",
        "2211.03039_43fcf9c0f196b2d9fe907e830681d19f": "The sampled training dataset in",
        "2211.03039_c83bad7984520f9434551e5d0674e8db": "includes 1500 organization entities, 1500 person entities, 150 location entities and 150 miscellaneous entities (2) The MIT Movie dataset",
        "2211.03039_75e79244b084f4c951b6c2dca473ea97": "is from queries related to movie information",
        "2211.03039_9ab20bfb928b9ec9caf285662dea51d2": ". (3) The Few-NERD dataset",
        "2211.03039_85a03835c77773d51eb4c84e4d394e40": "is a low-resource NER dataset with a hierarchy of 8 coarse-grained and 66 fine-grained entity types",
        "2211.03039_923078d206e58ce249a208853d4b6b31": "We use the coarse-grained entity in our experiments",
        "2211.03039_aa66d95e83ccb800b2bfb705185b36ba": "Experimental Settings",
        "2211.03039_734383ac2a530f3fbf1cac4de3283600": "We use the pre-trained models and codes provided by ADAPET and follow their default hyperparameter settings unless noted otherwise",
        "2211.03039_6fd224fdebea7de3f1cfbe2c7985629a": "The pre-trained language model of our method is BERT that is pre-trained in the MNLI datasets",
        "2211.03039_6782261ef302b9d782fc02c26beb27de": "We use AdamW optimizer and grid search batch size of",
        "2211.03039_005c128d6e551735fa5d938e44e7a613": "$8$",
        "2211.03039_92d273224a0759f4895be999c9a6f5e3": "$16$",
        "2211.03039_9b316764e592d513c7c6be2b9e112d73": "$32$",
        "2211.03039_d64dec47cdda1f4459e4b372716b573b": "for model training",
        "2211.03039_9631e762448068729807283079b18053": "We use grid search for learning rate from",
        "2211.03039_484a820730c34417d02147779a25dcf1": "$[1\\text{e-}5, 2\\text{e-}5, 3\\text{e-}5, 4\\text{e-}5, 5\\text{e-}5]$",
        "2211.03039_0604cdc474cea70e9c488601f3d49840": "And we grid search the optimal weight decay weight from",
        "2211.03039_bb48d3ac822989543954213275d66c18": "$[0.1, 0.01, 0.005, 0.001]$",
        "2211.03039_10ae091db18be64fe6091a9ea060b371": "The maximum sequence length, the dropout rate, the gradient accumulation steps, the maximum training steps and the warm-up ratio are set to",
        "2211.03039_9684129ebb778f48019391de80875252": "$256$",
        "2211.03039_22f2e6fc19e491418d1ec4ee1ef94335": "$0.1$",
        "2211.03039_c9a8203e07064b0228672de1f69b5189": "$7000$",
        "2211.03039_c98a8632b61cd7a55101e8fda222864a": "$0.06$",
        "2211.03039_4b99ad4f32b999c31dae0b336712e6d9": "respectively",
        "2211.03039_3d16c95d409bf1f00ba1a7426fbdb926": "Early stopping is also applied based on model performance on the development set",
        "2211.03039_8af38715e4e24f9b5d18f9d5470d97cd": "Our models are trained with NVIDIA Tesla V100s",
        "2211.03039_674c46ba9970a34dc8e96f882cd5dbec": "The verbalizer words are [",
        "2211.03039_a6105c0a611b41b08f1209506350279e": "yes",
        "2211.03039_7fa3b767c460b54a2be4d49030b349c7": "no",
        "2211.03039_e50eacd5ef36b3b6dea9b18ca0d5c208": "] and [",
        "2211.03039_b326b5062b2f0e69046810717534cb09": "true",
        "2211.03039_68934a3e9455fa72420237eb05902327": "false",
        "2211.03039_0fbd1776e1ad22c59a7080d35c7fd4db": "]",
        "2211.03039_a4704fd35f0308287f2937ba3eccf5fe": "The",
        "2211.03039_0fe1677705e987cac4f589ed600aa6b3": "$\\tau$",
        "2211.03039_dcb1026002fe1ba963e795fdd6b237fa": "of transition probability in decoding is selected by searching with",
        "2211.03039_09b35b77d506cef3840e129c2e29ed1f": "$0.05$",
        "2211.03039_e96f211f90614fd9c8488c8ddd18060d": "step from",
        "2211.03039_29632a9bf827ce0200454dd32fc3be82": "$0$",
        "2211.03039_01b6e20344b68835c5ed1ddedf20d531": "to",
        "2211.03039_034d0a6be0424bffe9a6e7ac9236c0f5": "$1$",
        "2211.03039_49b17ca206d83e19dd6a00931c2f6013": "For sequence labeling BERT fine-tuning, we train BERT with a softmax classifier following",
        "2211.03039_7435f8b4e71dfa9c45de96f4d3a5f95e": "\\citet{bert}",
        "2211.03039_71c0435629802199bbe85bfa870f2fcc": ", updating parameters using Adam with an initial learning rate of",
        "2211.03039_0269eb80e56fe4c4622bd8f25b1628b9": "$1\\text{e-}5$",
        "2211.03039_886048407e31e12825daa974248f19e3": ", and a batch size of",
        "2211.03039_d3da6719f806456b97d63b46ed882097": "Pattern Engineering",
        "2211.03039_38fdacc281d8b749caa01d89053872e7": "After designing templates of entity-specific hypothesis, we follow",
        "2211.03039_0a6571279706e1f78c791f9dabc45c0b": "\\citet{ADAPET}",
        "2211.03039_65cfa0c0b580e0ad358f192a3928e77f": "to define the TE patterns in Table",
        "2211.03039_86ca70f84b49953c2c1f52ab82646703": "and report results across all patterns for all datasets in Figure",
        "2211.03039_c30846cc8a245978d751d867865977ea": "We find that the subtle difference of the prompts impacts performance, while Pattern",
        "2211.03039_20d13383bc4a1362ce3216fc6357b699": "4 outperforms others across datasets and settings."
    },
    "hierarchy": {
        "1": {
            "2211.03039_708aede88adbc288358e60e7a474bb44": "2211.03039_70bd5acae03c22d5eddd06ef18ff5a0a",
            "2211.03039_e353dbe42c8654f33588d4da0b517469": "2211.03039_70bd5acae03c22d5eddd06ef18ff5a0a",
            "2211.03039_c85f8e8661ee3c776340f99397be3cfe": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_bfb550fb9baee17d872c7ba045d30bfe": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_9f24a491938cce72ce342d5db97a9959": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_6abd71ca1b06e74f8504efcd944cbd69": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_e1dbed4201e36f47a4fe0c89389b4537": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_80ae9c64057ed10061508323ce0caea2": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_c0bf77e39f24b5755d87a9263928af62": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_637beb8fad53c5e9868d3840c260bd98": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_40446ab153e6fab83c0658703c1e3f71": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_b53468de021cf130d598d30e612f924d": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_0b79795d3efc95b9976c7c5b933afce2": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_f217b641b56b64ace4bfdce471e884b8": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_3591000aa66732a3379ce0129c2f464b": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_a2cf0e8e1fc930aa09e144837ffb2feb": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_7f85794999733d02a4f4b19563930d33": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_1d9df6341e4bfceef3b7ce949c5dfc15": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_8ae2798d21ff6f0c4d84a8490bd2e2ab": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_5c7a4b29917a038ee0ed26f79ce90917": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_c22593d6016c18ce75629593eae43024": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_7fc3d4fc6a43e08f28b9f9224cf3c148": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_dde5a88688201d97325f36cf94924a24": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_c4f6b3065457e6423bad004096ebd72f": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_689d6ec53c5ef105e1a6a91aa9c4e330": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_e66c0ccdd25d9b90c54c1d3775c27c62": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_40ed9570a9b7f2993d146fa8a163b0c7": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_cabbc139b7f74771c47e3eb24d94c92b": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_d95c1729cf5316ad16706b6c7ecefeb9": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_d2c24d59e0baff4d0155fbdf62590867": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_9371d7a2e3ae86a00aab4771e39d255d": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_75d75f767f6cdef038e7b8eb66072603": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_b723b8f94b2dda2ec76e9fadfa7d21be": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_c0cb5f0fcf239ab3d9c1fcd31fff1efc": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_2c0ed90f468b084cedcac9ad21ee9252": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_a872cb2ee851470752e5be2c5188da8f": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_031db50a8f3b9605c24d609a606a5516": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_eaa9aae94a5f120da84e1851cf22a6e6": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_84c40473414caf2ed4a7b1283e48bbf4": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_44270214e0d0dc5a351be08ad5333fd5": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_00b0b0cde8754564ffd2b135bf481522": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_478f3a4c51824ad23cb50c1c60670c0f": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_ad96c6d0164ff33fd04eea1dd1db0978": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_845ba328b997b4cf18eca22d70b4ff5e": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_13ee1a4eacfe79ea0644c2358f6ca92a": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_4c0f09d0c188e17fc2f385bf8b7dfac1": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_9515d8abe8bff11f9897bbe55630d762": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_f9d17a553456c93f95f1462a17c0aabc": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_e822bf10b2d1dca7ca0d850cae4de331": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_e0217a84d93416117569d41cbb831eef": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_0a7ebc8ffc23ab0dd4adbdf23658526e": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_590b0871b94190f2e9dea85deb853508": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_5d44a4447eda2f57cf2197963bed3698": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_7a48c1e74151dc40827fc2cca9b3ce5a": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_a1dbdf68df267698bb8a5abf9e0b3491": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_6d1b696acc848e549fbaccd52f1ab837": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_262a98edd149534f568917b0c8619ac9": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_05eea48aa76ccf6558e9051b522c64f5": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_d3dcd95348d6253166e427de311f708f": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_1f56b1910f322cc10e6795c41ab6a037": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_1b74c3bc45570c8ad63a475a0deb5a15": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_905cacabb1f8b7a3a9b5d4272718440d": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_e5c74a52b00a21de9722905aab545a4c": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_a3d9c1b7730382a9aced8bdc055ee3fe": "2211.03039_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03039_4c3880bb027f159e801041b1021e88e8": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b": "2211.03039_4c3880bb027f159e801041b1021e88e8",
            "2211.03039_d5317b1bc6a657f8dd1b910c7a9478af": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_e4eb5c8cc760684619c45cbd5c99f721": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_300c988f71b77286f29e0e5aa3d504ea": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_f9c4988898e7f532b9f826a75014ed3c": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_1d68ce7c1dbb10312055e43648b4f26b": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_3ebf1208ec8b789bb69a99b017e0d03e": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_eb7f46019127afce1fa7a65b3ad4931a": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_48620feaeb4ff61c808bc277cd17b647": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_192bb7f9b2a1376049fc150a7069e8f5": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_f2a7eb6092cd378fbc9108e0718d4c44": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_dc80c8df8d6a3120a158fb62653b1321": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_a29f17caa3e965b909d1aef183a202e4": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_fce9019a5e1fa63e079199cd9b11c55e": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_11b060bc741548c3081237a2b3938914": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_f7dd294a42b138e63f3c35275255b3f6": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_995ad9771cbaa6367aece30812d36cc4": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_dcae0abcf09f8345da2d20e34535a112": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_0f335855c35a8c615e822b0a9a8a2d88": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_2fe39d1449c9beb10e1d955ad7f8dc01": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_169c550735d170b96f499fee287216d0": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_065a12795c741412124c164e9633eb36": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_3874e1e7c3d06431da31da798f869ecf": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_b5eaea000e06d5cf2e882f8fdbc71e36": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_e8f38282cd7b60d09582f88c465ad505": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_27e556cf3caa0673ac49a8f0de3c73ca": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_4a39f9bc730ec1c3ce0439001d343a3e": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_c521d04c38a4daa0db554966169409a4": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_6adbacb3f316f8c198a630f35a45142c": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_a5df1b8d7481c9168026e84934d22ca0": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_567904efe9e64d9faf3e41ef402cb568": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_190083ef7a1625fbc75f243cffb9c96d": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_c411ce9398a74c1e24d17801cb913e6d": "2211.03039_3a391fa9145f8d9bc4cfc09d36f9802b",
            "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326": "2211.03039_4c3880bb027f159e801041b1021e88e8",
            "2211.03039_223570432b30c86a7ea2b2aef9792d84": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_043ea3dec61059693db0fe5b74ae0f36": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_b9a790615116d6b66904a79159ae5b25": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_3070192562553c677e1a9a4911f44db9": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_6395852169d4b4e2d09840e3f8b5cdb2": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_27ec9facfd9ea21c94c0ad5540d09455": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_ce801644a749abfedcd80a396b61301d": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_3294829ae6bb3aa97d5a6796aad07c42": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_cbb66f1b6f1a8aebff7315056d2ee19a": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_f66eb4e7030d348a7dd3b32871d20686": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_8cd041452821338d00bce0348c94051d": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_51fa3e5893c395aa10aee106698651b3": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_556e6e59c5d6ce6fea0c72f0dab24267": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_f6e7b6024ef519cc92e0785af75f39bf": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_551b40dc0845d87679232a6ea42e173b": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_6074e85731fddc6d8204456d4feca68c": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_226e747b0659adce4625544877c5d37d": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_8eb7693ed18753b01c8ac36595e57268": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_4afdc0615ef84ecda570d0cef898e562": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_6193195471fcc8693e0b9faac4a4567c": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_2d608001d661d88844c65c16dafdf7e1": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_87d6497a017a6f8c3692c408c61f5a2d": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_ee2bdbdfae3e73b8f00f8f846693130e": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_42974f01f9942ba3ee4a19ed85a9979c": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_47484a608a9961415a8745ed2971506d": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_32af0e11d7efeb90f93c912ce043e9c2": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_f8afc9908612e7375c3a174bc47952db": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_153c955623a02570a9019ecb36180311": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_2823e68a48295925aac49f17973d1679": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_e47d6f6b92cdfb696181c844f74e0e69": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_459e725ed0b6093d980b345a3d3a6972": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_5ef85abe1a9b4e2dc8b00f22b32baca5": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_131df25d463fa767af1eddfb826ad67c": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_9e1cf0e585d14f3b7a1751c880033987": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_f157644a78cbefc1075e6554608d9562": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_77e57ba31d82d741769788a1ba3f42fe": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_af558b33c4b52dba1aa92e371dc31c59": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_e8831293b846e3a3799cd6a02e4a0cd9": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_801ade39dbf175c166bf45e4db57fae4": "2211.03039_0954bf83d09a1ffa2768c04b2c6f7326",
            "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445": "2211.03039_4c3880bb027f159e801041b1021e88e8",
            "2211.03039_09e0724f7e4c91b870438ed8a0596ce2": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_de1e07d2e73389bf0e7352f392dd2a16": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_decf9afa2f7ba1ec5e1eecc9ac93946c": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_11b00ac2005319804fc92a8e90e78d1c": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_690c087bf39b56b77a2ba0f26d907031": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_1137fc97bd701b044ef399768d5ec186": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_68813ee50a90e1f482f7ebbe593ae775": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_ee89c35444f2d3092d69e58a989251ec": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_09761eea4e1c19514d7b4a22bec3bfb7": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_1b67e23d3c36e6bb34060982f8fa7b3a": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_9033011b40e50fdb73506b4642879c19": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_6475de3c932cb3ab1ab64a2d9663cb22": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_e7244cde98eb1890c0212ac6a9bf98a0": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_05923ac01f0d5c8cc7fa964326dd44f4": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_fe547e162fbd8bb2528a65225584ab3b": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_5058f1af8388633f609cadb75a75dc9d": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_ea732dd9edf3771962ae83492e521517": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_23c4b427c97161f90317de1be93fc42b": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_3a681eeaca73c2560d5e4344c9537719": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_fbfafe237032d652296841dc19cb878e": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_aec0660726c0c3ba7c3dc36d9b6dbfcb": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_c89a5f676ef318a628043180c0d2d924": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_0d563d57b04e757c7e8a2b4ca7adfdf3": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_8679acf5457b92bc7e67570eda931846": "2211.03039_beb3efd6ec69e1a513cb5e40db2c6445",
            "2211.03039_a7a1cc239a13a67da5b9a2b525c31687": "2211.03039_4c3880bb027f159e801041b1021e88e8",
            "2211.03039_3fe3b0bef745b614a8c68b6ee4d1f5be": "2211.03039_a7a1cc239a13a67da5b9a2b525c31687",
            "2211.03039_ef1fc963c9ef818482bfc7b62aee77a3": "2211.03039_a7a1cc239a13a67da5b9a2b525c31687",
            "2211.03039_b57bf9fd554644514d17235f25a20f5e": "2211.03039_a7a1cc239a13a67da5b9a2b525c31687",
            "2211.03039_782f40fbd44a5ff265899b3739ca60b0": "2211.03039_a7a1cc239a13a67da5b9a2b525c31687",
            "2211.03039_9eb2c115260de55e67fa5087652d36e0": "2211.03039_a7a1cc239a13a67da5b9a2b525c31687",
            "2211.03039_af3e60a7199152a8851df7008fdbbdef": "2211.03039_a7a1cc239a13a67da5b9a2b525c31687",
            "2211.03039_a9e5641be3a70d63dff0fba9011d5c2b": "2211.03039_a7a1cc239a13a67da5b9a2b525c31687",
            "2211.03039_4829262cecb9828817b33e0f9c907f91": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_cda30a6d07967e09b5d348d2f9306dc1": "2211.03039_4829262cecb9828817b33e0f9c907f91",
            "2211.03039_a836f54ea41109d63518862051ae9ec3": "2211.03039_4829262cecb9828817b33e0f9c907f91",
            "2211.03039_56cd920a56488f9669fef2546f351176": "2211.03039_4829262cecb9828817b33e0f9c907f91",
            "2211.03039_bffbe539e7c4a05c588331678bb4561b": "2211.03039_4829262cecb9828817b33e0f9c907f91",
            "2211.03039_fc8e90dce9f04f2e3805b9612b81e169": "2211.03039_4829262cecb9828817b33e0f9c907f91",
            "2211.03039_8c194122071d10e74d70fd4ddfa1d465": "2211.03039_4829262cecb9828817b33e0f9c907f91",
            "2211.03039_3b753160288b6a3a00f407b49a7e352e": "2211.03039_4829262cecb9828817b33e0f9c907f91",
            "2211.03039_be5d5d37542d75f93a87094459f76678": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_ef3eb2c11b1c0ff38002dca1a0c48825": "2211.03039_4829262cecb9828817b33e0f9c907f91",
            "2211.03039_798aedf4f2905f788893c61421cdc7ed": "2211.03039_4829262cecb9828817b33e0f9c907f91",
            "2211.03039_a1db0433e50c0e3a6ccd4ba9c4e0c545": "2211.03039_798aedf4f2905f788893c61421cdc7ed",
            "2211.03039_51c45b795d5d18a3e4e0c37e8b20a141": "2211.03039_798aedf4f2905f788893c61421cdc7ed",
            "2211.03039_7a965d52c8d8c06fa38dc21fb006dd11": "2211.03039_798aedf4f2905f788893c61421cdc7ed",
            "2211.03039_7fd39b155cd25792189a3b45df4daba0": "2211.03039_798aedf4f2905f788893c61421cdc7ed",
            "2211.03039_ceee975321c0ab90b8d719dfad236ee5": "2211.03039_798aedf4f2905f788893c61421cdc7ed",
            "2211.03039_3e2554f908eb18adbb813385c4be6e36": "2211.03039_798aedf4f2905f788893c61421cdc7ed",
            "2211.03039_2e658f8b4f8b47037ff6320e303021d3": "2211.03039_798aedf4f2905f788893c61421cdc7ed",
            "2211.03039_7e26c09f9b2b84a7c6004bd0960c7f83": "2211.03039_798aedf4f2905f788893c61421cdc7ed",
            "2211.03039_e823ac25ef74ca053f48eff1242ef7d2": "2211.03039_798aedf4f2905f788893c61421cdc7ed",
            "2211.03039_86b555e0f1f282c94c3a0221d1e8d9c2": "2211.03039_798aedf4f2905f788893c61421cdc7ed",
            "2211.03039_a02b2c2958c2f9cf69a3c3c7eefaa34c": "2211.03039_798aedf4f2905f788893c61421cdc7ed",
            "2211.03039_5c84fd729009b66ccac4fee8cf315063": "2211.03039_798aedf4f2905f788893c61421cdc7ed",
            "2211.03039_80f52ea095a907d2610601176d5d4b60": "2211.03039_798aedf4f2905f788893c61421cdc7ed",
            "2211.03039_1457516a0e8e060af52e1b3402609ee3": "2211.03039_4829262cecb9828817b33e0f9c907f91",
            "2211.03039_6f796b0e6deb4f4c2c0ee0ed5e10e117": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_aa30f2df334851fcde2c276f63264627": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_42776608aa8d6ce44b463cac74f64acf": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_3a3194f8468aef36d35c21e9ccd1956c": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_12ae43e68edf9759c087f2b0db126479": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_06f179e75bfac08c9b75c7f847f84a6b": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_2bca22f04f7a874735fc44b8f3dad4ed": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_7982b1597f92456d71b333fe2aead996": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_ca5c504c6136e20051be115160b0f0b8": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_96e44762bae7c64a1e634b42da3d6e2b": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_0cec478ac359e9d447871bdce33224aa": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_6d6773f14fe2059ee673fc8e34449b60": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_56119dfbc7ac1b0ad1b5a33519be37a4": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_d9f81e56a6929a52fc4aa145111f730e": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_cfee3df04e6934d42888970fd56aa5e7": "2211.03039_1457516a0e8e060af52e1b3402609ee3",
            "2211.03039_62bba9fd2e439f7e569138a9e086c495": "2211.03039_4829262cecb9828817b33e0f9c907f91",
            "2211.03039_c24f01ae76da86c6e2ddbeb466ed0e43": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_e8d8f3f758250fac5aa0a1a7cf137253": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_987c94b6a947783d954977f580122ad2": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_d6328eaebbcd5c358f426dbea4bdbf70": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_c9ed7cca55bd649618b0dcdb7015005c": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_0813643d5567c0d26e4622e7e277f0d1": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_483b35f075c940daad4dc6c8a61873ef": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_61805bc6bad77f74247f24e47af945b8": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_dd10321006e606b99b579f4b1328d8aa": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_e600dbae7dad592ec5a80bdabe76d30c": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_1b654850f23f6901d908f55bced09866": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_d6da906459f3c2f26222286daba98e61": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_23b868f41949ab56c790ffd6e86403e0": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_41ab89eb51f3012170301518bb135a5a": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_c2bedf7649f2c6aff01189cfd59bbbf0": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_db4ae72699f0ac36ac1e1618e049c075": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_a51cdaabc42425c1d88b25cefcc2ce74": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_5c421b8fc6a2ec30472b344e145963ef": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_b5c5c3bcb6a20573e954fe21c90ada85": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_9ce8db5e68f8c0735b8825c28b84de99": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_91d9d79bad1cb5abeee571a77a499bde": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_20d10e7690dfde566c177cdea4fb24aa": "2211.03039_62bba9fd2e439f7e569138a9e086c495",
            "2211.03039_feb8fbabd70d0afca1c994a477267544": "2211.03039_4829262cecb9828817b33e0f9c907f91",
            "2211.03039_ff7762f26eebada0729ba7c96fcae6f3": "2211.03039_feb8fbabd70d0afca1c994a477267544",
            "2211.03039_5148396766c7f4c15ae7667b19a9abcd": "2211.03039_feb8fbabd70d0afca1c994a477267544",
            "2211.03039_2ff1dbf66f9ddee4caa1dc7092254e68": "2211.03039_feb8fbabd70d0afca1c994a477267544",
            "2211.03039_41d1d3ca7e3ed73e3ba9a6efe2a8d8e6": "2211.03039_feb8fbabd70d0afca1c994a477267544",
            "2211.03039_aed402c3112b4749a9a98a72cbe9093d": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_4c21f94ec432cd7f5a2937ef3140ebce": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_77eb9408654cf9280db0afa76e180ef6": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_e1289477f51c8e74663482443c8fd6db": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_254dcb99942b61acb6944e96ab5fe83e": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_ee787914bf9379468130d62f901502cd": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_88d089cdbd4ee3b6126848f292d5a7be": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_14e96863f15439e65ac124cbe70a8822": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_bcc6bff7280870cd4dae1b958e8e261a": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_83519ef45684dda8df5a01b204735b21": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_8fc132bcdfcd97fa8a3d5fb5de89a3d7": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_0944689dfb3e59e096a45147e7f6fa92": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_9eca550bf0b824a50b96c0f81c15fa39": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_f37580234f81471b3f78fe071e052d5d": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_f9015b562dec527beb47e10a697472ce": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_a4aa7be9de56ca886bc53ba8caf11b27": "2211.03039_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03039_6f8b794f3246b0c1e1780bb4d4d5dc53": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_f21ef5e059b124d4d359df5fd780ef15": "2211.03039_6f8b794f3246b0c1e1780bb4d4d5dc53",
            "2211.03039_64c24b282522ea04c01002786f648f69": "2211.03039_6f8b794f3246b0c1e1780bb4d4d5dc53",
            "2211.03039_56dda9a732b4f2f98747be604faf6106": "2211.03039_6f8b794f3246b0c1e1780bb4d4d5dc53",
            "2211.03039_6ff413504a055569291ac6855e2bc662": "2211.03039_6f8b794f3246b0c1e1780bb4d4d5dc53",
            "2211.03039_b091d43ab096e658a3970053ad805efa": "2211.03039_6f8b794f3246b0c1e1780bb4d4d5dc53",
            "2211.03039_8c73e08e59de906dd6d042b1d54c9d90": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_7301e901ebaf23a78018b244f1323092": "2211.03039_8c73e08e59de906dd6d042b1d54c9d90",
            "2211.03039_17453a3aac610667c18faed46413486b": "2211.03039_8c73e08e59de906dd6d042b1d54c9d90",
            "2211.03039_9f0387ffc20fb040cb7a277dd8e1db6c": "2211.03039_8c73e08e59de906dd6d042b1d54c9d90",
            "2211.03039_8e8e8518dfb6f45fa3e4fe039db5765b": "2211.03039_8c73e08e59de906dd6d042b1d54c9d90",
            "2211.03039_5037e08fb0c5d51d2c9edc4df6e9f389": "2211.03039_8c73e08e59de906dd6d042b1d54c9d90",
            "2211.03039_5a32a8c1c2d5a306163562b7daead774": "2211.03039_8c73e08e59de906dd6d042b1d54c9d90",
            "2211.03039_bb2607864c67e364ec99bd0cccda055a": "2211.03039_8c73e08e59de906dd6d042b1d54c9d90",
            "2211.03039_49396ea29a4bc1fe315583d82f138ec6": "2211.03039_8c73e08e59de906dd6d042b1d54c9d90",
            "2211.03039_cac2fb2387c36e91dc8022eadc17cdf1": "2211.03039_8c73e08e59de906dd6d042b1d54c9d90",
            "2211.03039_7df96b18c230f90ada0a9e2307226338": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_7f5effa802884cf674c4eeb8b5740750": "2211.03039_7df96b18c230f90ada0a9e2307226338",
            "2211.03039_24fc673195a7239d2a99758596e2a599": "2211.03039_7df96b18c230f90ada0a9e2307226338",
            "2211.03039_f8da72e8df4eae188060bcfd644020a0": "2211.03039_7df96b18c230f90ada0a9e2307226338",
            "2211.03039_56eedff9c82d406a4e2a072854eaa3c4": "2211.03039_7df96b18c230f90ada0a9e2307226338",
            "2211.03039_624d94623f05627998ba773eb1aee2cc": "2211.03039_7df96b18c230f90ada0a9e2307226338",
            "2211.03039_41c1a81689fe3c2d53eac9c3ef39e730": "2211.03039_7df96b18c230f90ada0a9e2307226338",
            "2211.03039_eee8961ee0263f9b5b554b0cdc559dcb": "2211.03039_7df96b18c230f90ada0a9e2307226338",
            "2211.03039_a8fb897a965c878e00fceda66adaff2a": "2211.03039_7df96b18c230f90ada0a9e2307226338",
            "2211.03039_8c176eb386389fb00abbb5be4b605820": "2211.03039_7df96b18c230f90ada0a9e2307226338",
            "2211.03039_274426c258ca87e26022241ee8637a67": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_0ebd0dd97c4be80247623d1c59306639": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_faef25b51e0ddc0e4cacf718d92473a7": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_8234bfa73815cee3a25b832990674f13": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_7e1e8e914114b8157017f91ddc14060a": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_5de4fd645a7ca2259566906f610add78": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_303ecf13cde811b5022c976f6b9bb6ef": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_8a0e2b549d223aba55a866c38d1c9275": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_43fcf9c0f196b2d9fe907e830681d19f": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_c83bad7984520f9434551e5d0674e8db": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_75e79244b084f4c951b6c2dca473ea97": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_9ab20bfb928b9ec9caf285662dea51d2": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_85a03835c77773d51eb4c84e4d394e40": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_923078d206e58ce249a208853d4b6b31": "2211.03039_274426c258ca87e26022241ee8637a67",
            "2211.03039_aa66d95e83ccb800b2bfb705185b36ba": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_734383ac2a530f3fbf1cac4de3283600": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_6fd224fdebea7de3f1cfbe2c7985629a": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_6782261ef302b9d782fc02c26beb27de": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_005c128d6e551735fa5d938e44e7a613": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_92d273224a0759f4895be999c9a6f5e3": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_9b316764e592d513c7c6be2b9e112d73": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_d64dec47cdda1f4459e4b372716b573b": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_9631e762448068729807283079b18053": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_484a820730c34417d02147779a25dcf1": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_0604cdc474cea70e9c488601f3d49840": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_bb48d3ac822989543954213275d66c18": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_10ae091db18be64fe6091a9ea060b371": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_9684129ebb778f48019391de80875252": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_22f2e6fc19e491418d1ec4ee1ef94335": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_c9a8203e07064b0228672de1f69b5189": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_c98a8632b61cd7a55101e8fda222864a": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_4b99ad4f32b999c31dae0b336712e6d9": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_3d16c95d409bf1f00ba1a7426fbdb926": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_8af38715e4e24f9b5d18f9d5470d97cd": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_674c46ba9970a34dc8e96f882cd5dbec": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_a6105c0a611b41b08f1209506350279e": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_7fa3b767c460b54a2be4d49030b349c7": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_e50eacd5ef36b3b6dea9b18ca0d5c208": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_b326b5062b2f0e69046810717534cb09": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_68934a3e9455fa72420237eb05902327": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_0fbd1776e1ad22c59a7080d35c7fd4db": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_a4704fd35f0308287f2937ba3eccf5fe": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_0fe1677705e987cac4f589ed600aa6b3": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_dcb1026002fe1ba963e795fdd6b237fa": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_09b35b77d506cef3840e129c2e29ed1f": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_e96f211f90614fd9c8488c8ddd18060d": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_29632a9bf827ce0200454dd32fc3be82": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_01b6e20344b68835c5ed1ddedf20d531": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_034d0a6be0424bffe9a6e7ac9236c0f5": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_49b17ca206d83e19dd6a00931c2f6013": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_7435f8b4e71dfa9c45de96f4d3a5f95e": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_71c0435629802199bbe85bfa870f2fcc": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_0269eb80e56fe4c4622bd8f25b1628b9": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_886048407e31e12825daa974248f19e3": "2211.03039_aa66d95e83ccb800b2bfb705185b36ba",
            "2211.03039_d3da6719f806456b97d63b46ed882097": "2211.03039_e353dbe42c8654f33588d4da0b517469",
            "2211.03039_38fdacc281d8b749caa01d89053872e7": "2211.03039_d3da6719f806456b97d63b46ed882097",
            "2211.03039_0a6571279706e1f78c791f9dabc45c0b": "2211.03039_d3da6719f806456b97d63b46ed882097",
            "2211.03039_65cfa0c0b580e0ad358f192a3928e77f": "2211.03039_d3da6719f806456b97d63b46ed882097",
            "2211.03039_86ca70f84b49953c2c1f52ab82646703": "2211.03039_d3da6719f806456b97d63b46ed882097",
            "2211.03039_c30846cc8a245978d751d867865977ea": "2211.03039_d3da6719f806456b97d63b46ed882097",
            "2211.03039_20d13383bc4a1362ce3216fc6357b699": "2211.03039_d3da6719f806456b97d63b46ed882097"
        }
    }
}