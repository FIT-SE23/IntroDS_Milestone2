@article{gadre2022clip,
  author = {Gadre, Samir Yitzhak and Wortsman, Mitchell and Ilharco, Gabriel and Schmidt, Ludwig and Song, Shuran},
  title = {Clip on wheels: Zero-shot object navigation as object localization and exploration},
  year = {2022},
  journal = {arXiv},
}
@inproceedings{wmt19,
  author = {Ng, Nathan and Yee, Kyra and Baevski, Alexei and Ott, Myle and Auli, Michael and Edunov, Sergey},
  title = {Facebook FAIR's WMT19 News Translation Task Submission},
  year = {2020},
  booktitle = {WMT},
}
@inproceedings{pashevich2021episodic,
  author = {Pashevich, Alexander and Schmid, Cordelia and Sun, Chen},
  title = {Episodic transformer for vision-and-language navigation},
  year = {2021},
  booktitle = {CVPR},
}
@inproceedings{al2022zero,
  author = {Al-Halah, Ziad and Ramakrishnan, Santhosh Kumar and Grauman, Kristen},
  title = {Zero experience required: Plug \& play modular transfer learning for semantic visual navigation},
  year = {2022},
  booktitle = {CVPR},
}
@inproceedings{jiang2020x,
  author = {Jiang, Zhengbao and Anastasopoulos, Antonios and Araki, Jun and Ding, Haibo and Neubig, Graham},
  title = {X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained Language Models},
  year = {2020},
  booktitle = {EMNLP},
}
@article{liu9planning,
  author = {Liu, Xiaotian and Palacios, Hector and Muise, Christian},
  title = {A Planning based Neural-Symbolic Approach for Embodied Instruction Following},
  year = {2022},
  journal = {CVPR Workshop on Embodied AI},
}
@article{suglia2021embodied,
  author = {Suglia, Alessandro and Gao, Qiaozi and Thomason, Jesse and Thattai, Govind and Sukhatme, Gaurav},
  title = {Embodied bert: A transformer model for embodied, language-guided visual task completion},
  year = {2021},
  journal = {ArXiv},
}
@article{murray2022following,
  author = {Murray, Michael and Cakmak, Maya},
  title = {Following Natural Language Instructions for Household Tasks with Landmark Guided Search and Reinforced Pose Adjustment},
  year = {2022},
  journal = {RA-L},
  publisher = {IEEE},
}
@inproceedings{das2018embodied,
  author = {Das, Abhishek and Datta, Samyak and Gkioxari, Georgia and Lee, Stefan and Parikh, Devi and Batra, Dhruv},
  title = {Embodied question answering},
  year = {2018},
  booktitle = {CVPR},
}
@article{sethian1996fast,
  author = {Sethian, James A},
  title = {A fast marching level set method for monotonically advancing fronts.},
  year = {1996},
  journal = {PNAS},
  volume = {93},
  number = {4},
  publisher = {National Acad Sciences},
}
@inproceedings{he2017mask,
  author = {He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  title = {Mask r-cnn},
  year = {2017},
  booktitle = {ICCV},
}
@inproceedings{film,
  author = {Min, So Yeon and Chaplot, Devendra Singh and Ravikumar, Pradeep Kumar and Bisk, Yonatan and Salakhutdinov, Ruslan},
  title = {FILM: Following Instructions in Language with Modular Methods},
  year = {2021},
  booktitle = {ICLR},
}
@inproceedings{anderson2018vision,
  author = {Anderson, Peter and Wu, Qi and Teney, Damien and Bruce, Jake and Johnson, Mark and S{\"u}nderhauf, Niko and Reid, Ian and Gould, Stephen and Van Den Hengel, Anton},
  title = {Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments},
  year = {2018},
  booktitle = {CVPR},
}
@inproceedings{ramakrishnan2022poni,
  author = {Ramakrishnan, Santhosh Kumar and Chaplot, Devendra Singh and Al-Halah, Ziad and Malik, Jitendra and Grauman, Kristen},
  title = {Poni: Potential functions for objectgoal navigation with interaction-free learning},
  year = {2022},
  booktitle = {CVPR},
}
@inproceedings{speer2017conceptnet,
  author = {Speer, Robyn and Chin, Joshua and Havasi, Catherine},
  title = {Conceptnet 5.5: An open multilingual graph of general knowledge},
  year = {2017},
  booktitle = {AAAI},
}
@inproceedings{ronneberger2015u,
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  title = {U-net: Convolutional networks for biomedical image segmentation},
  year = {2015},
  booktitle = {MICCAI},
  organization = {Springer},
}
@inproceedings{wolf-etal-2020-transformers,
  author = {Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
  title = {Transformers: State-of-the-Art Natural Language Processing},
  year = {2020},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  publisher = {ACL},
}
@inproceedings{radford2021learning,
  author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  title = {Learning transferable visual models from natural language supervision},
  year = {2021},
  booktitle = {International conference on machine learning},
  organization = {PMLR},
}
@article{majumdar2022zson,
  author = {Majumdar, Arjun and Aggarwal, Gunjan and Devnani, Bhavika and Hoffman, Judy and Batra, Dhruv},
  title = {Zson: Zero-shot object-goal navigation using multimodal goal embeddings},
  year = {2022},
  journal = {arXiv},
}
@inproceedings{zhu2020vision,
  author = {Zhu, Fengda and Zhu, Yi and Chang, Xiaojun and Liang, Xiaodan},
  title = {Vision-language navigation with self-supervised auxiliary reasoning tasks},
  year = {2020},
  booktitle = {CVPR},
}
@inproceedings{singh2002open,
  author = {Singh, Push and Lin, Thomas and Mueller, Erik T and Lim, Grace and Perkins, Travell and Zhu, Wan Li},
  title = {Open mind common sense: Knowledge acquisition from the general public},
  year = {2002},
  booktitle = {OTM Confederated International Conferences" On the Move to Meaningful Internet Systems"},
  organization = {Springer},
  pages = {1223--1237},
}
@software{gptneo,
  author = {Black, Sid and Gao, Leo and Wang, Phil and Leahy, Connor and Biderman, Stella},
  title = {{GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow}},
  publisher = {Zenodo},
  doi = {10.5281/zenodo.5297715},
  url = {https://doi.org/10.5281/zenodo.5297715},
}
@article{liu2022lebp,
  author = {Liu, Haoyu and Liu, Yang and He, Hongkai and Yang, Hangfang},
  title = {LEBP--Language Expectation \& Binding Policy: A Two-Stream Framework for Embodied Vision-and-Language Interaction Task Learning Agents},
  year = {2022},
  journal = {arXiv},
}
@inproceedings{alfred,
  author = {Shridhar, Mohit and Thomason, Jesse and Gordon, Daniel and Bisk, Yonatan and Han, Winson and Mottaghi, Roozbeh and Zettlemoyer, Luke and Fox, Dieter},
  title = {Alfred: A benchmark for interpreting grounded instructions for everyday tasks},
  year = {2020},
  booktitle = {CVPR},
}
@inproceedings{blukis2022persistent,
  author = {Blukis, Valts and Paxton, Chris and Fox, Dieter and Garg, Animesh and Artzi, Yoav},
  title = {A persistent spatial semantic representation for high-level natural language instruction execution},
  year = {2022},
  booktitle = {CORL},
  organization = {PMLR},
}
@inproceedings{petroni2019language,
  author = {Petroni, Fabio and Rockt{\"a}schel, Tim and Riedel, Sebastian and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander},
  title = {Language Models as Knowledge Bases?},
  year = {2019},
  booktitle = {EMNLP},
}
@article{ai2thor,
  author = {Eric Kolve and Roozbeh Mottaghi and Winson Han and Eli VanderBilt and Luca Weihs and Alvaro Herrasti and Daniel Gordon and Yuke Zhu and Abhinav Gupta and Ali Farhadi},
  title = {{AI2-THOR: An Interactive 3D Environment for Visual AI}},
  year = {2017},
  journal = {ArXiv},
  volume = {abs/1712.05474},
}
@inproceedings{devlin2018bert,
  author = {Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  year = {2019},
  booktitle = {NAACL},
}
@article{fried2018speaker,
  author = {Fried, Daniel and Hu, Ronghang and Cirik, Volkan and Rohrbach, Anna and Andreas, Jacob and Morency, Louis-Philippe and Berg-Kirkpatrick, Taylor and Saenko, Kate and Klein, Dan and Darrell, Trevor},
  title = {Speaker-follower models for vision-and-language navigation},
  year = {2018},
  journal = {NeurIPS},
  volume = {31},
}
@inproceedings{shridhar2020alfworld,
  author = {Shridhar, Mohit and Yuan, Xingdi and C{\^o}t{\'e}, Marc-Alexandre and Bisk, Yonatan and Trischler, Adam and Hausknecht, Matthew J},
  title = {ALFWorld: Aligning Text and Embodied Environments for Interactive Learning},
  year = {2021},
  booktitle = {ICLR},
}
@article{deitke2022procthor,
  author = {Deitke, Matt and VanderBilt, Eli and Herrasti, Alvaro and Weihs, Luca and Salvador, Jordi and Ehsani, Kiana and Han, Winson and Kolve, Eric and Farhadi, Ali and Kembhavi, Aniruddha and others},
  title = {ProcTHOR: Large-Scale Embodied AI Using Procedural Generation},
  year = {2022},
  journal = {arXiv},
}
@inproceedings{huang2022language,
  author = {Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  title = {Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  year = {2022},
  booktitle = {ICLR},
  organization = {PMLR},
}
@inproceedings{bisk2020experience,
  author = {Bisk, Yonatan and Holtzman, Ari and Thomason, Jesse and Andreas, Jacob and Bengio, Yoshua and Chai, Joyce and Lapata, Mirella and Lazaridou, Angeliki and May, Jonathan and Nisnevich, Aleksandr and others},
  title = {Experience Grounds Language},
  year = {2020},
  booktitle = {EMNLP},
}
@article{jiang2020can,
  author = {Jiang, Zhengbao and Xu, Frank F and Araki, Jun and Neubig, Graham},
  title = {How can we know what language models know?},
  year = {2020},
  journal = {TACL},
  volume = {8},
  publisher = {MIT Press},
}
@article{ahn2022can,
  author = {Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and others},
  title = {Do as i can, not as i say: Grounding language in robotic affordances},
  year = {2022},
  journal = {arXiv},
}
@inproceedings{qin2021learning,
  author = {Qin, Guanghui and Eisner, Jason},
  title = {Learning How to Ask: Querying LMs with Mixtures of Soft Prompts},
  year = {2021},
  booktitle = {NAACL},
}
