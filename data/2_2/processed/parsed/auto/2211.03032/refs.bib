@inproceedings{benchmark,
  author = {Papoudakis, Georgios and Christianos, Filippos and Sch{\"a}fer, Lukas and Albrecht, Stefano V},
  title = {Benchmarking multi-agent deep reinforcement learning algorithms in cooperative tasks},
  year = {2021},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
}
@article{PPO,
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  title = {Proximal policy optimization algorithms},
  year = {2017},
  journal = {arXiv preprint arXiv:1707.06347},
}
@inproceedings{COMA,
  author = {Foerster, Jakob N and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  title = {Counterfactual multi-agent policy gradients},
  year = {2018},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
}
@article{MAPPO,
  author = {Yu, Chao and Velu, Akash and Vinitsky, Eugene and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  title = {The surprising effectiveness of mappo in cooperative, multi-agent games},
  year = {2021},
  journal = {arXiv preprint arXiv:2103.01955},
}
@article{li2020f2a2,
  author = {Li, Wenhao and Jin, Bo and Wang, Xiangfeng and Yan, Junchi and Zha, Hongyuan},
  title = {F2a2: Flexible fully-decentralized approximate actor-critic for cooperative multi-agent reinforcement learning},
  year = {2020},
  journal = {arXiv preprint arXiv:2004.11145},
}
@inproceedings{DOP,
  author = {Yihan Wang and Beining Han and Tonghan Wang and Heng Dong and Chongjie Zhang},
  title = {DOP: Off-Policy Multi-Agent Decomposed Policy Gradients},
  year = {2021},
  booktitle = {International Conference on Learning Representations (ICLR)},
}
@article{sun2022monotonic,
  author = {Sun, Mingfei and Devlin, Sam and Hofmann, Katja and Whiteson, Shimon},
  title = {Monotonic Improvement Guarantees under Non-stationarity for Decentralized PPO},
  year = {2022},
  journal = {arXiv preprint arXiv:2202.00082},
}
@inproceedings{IQL,
  author = {Tan, Ming},
  title = {Multi-agent reinforcement learning: Independent vs. cooperative agents},
  year = {1993},
  booktitle = {International Conference on Machine Learning (ICML)},
}
@article{COPPO,
  author = {Wu, Zifan and Yu, Chao and Ye, Deheng and Zhang, Junge and Zhuo, Hankz Hankui and others},
  title = {Coordinated Proximal Policy Optimization},
  year = {2021},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume = {34},
}
@article{IDQN,
  author = {Ardi Tampuu and Tambet Matiisen and Dorian Kodelja and Ilya Kuzovkin and Kristjan Korjus and Juhan Aru and Jaan Aru and Raul Vicente},
  title = {Multiagent Cooperation and Competition with Deep Reinforcement Learning},
  year = {2015},
  journal = {arXiv preprint arXiv:1511.08779},
}
@article{MARL-survey,
  author = {Kaiqing Zhang and Zhuoran Yang and Tamer Basar},
  title = {Multi-Agent Reinforcement Learning: {A} Selective Overview of Theories and Algorithms},
  year = {2019},
  journal = {arXiv preprint arXiv:1911.10635},
}
@inproceedings{transfer,
  author = {Agarwal, Akshat and Kumar, Sumit and Sycara, Katia and Lewis, Michael},
  title = {Learning Transferable Cooperative Behavior in Multi-Agent Team},
  year = {2020},
  booktitle = {International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
}
@inproceedings{QPLEX,
  author = {Wang, Jianhao and Ren, Zhizhou and Liu, Terry and Yu, Yang and Zhang, Chongjie},
  title = {QPLEX: Duplex dueling multi-agent q-learning},
  year = {2021},
  booktitle = {International Conference on Learning Representations (ICLR)},
}
@article{DQN,
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  title = {Human-level control through deep reinforcement learning},
  year = {2015},
  journal = {Nature},
  volume = {518},
  number = {7540},
  pages = {529--533},
}
@inproceedings{TRPO,
  author = {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  title = {Trust region policy optimization},
  year = {2015},
  booktitle = {International Conference on Machine Learning (ICML)},
}
@inproceedings{QTRAN,
  author = {Kyunghwan {Son} and Daewoo {Kim} and Wan Ju {Kang} and David Earl {Hostallero} and Yung {Yi}},
  title = {QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning},
  year = {2019},
  booktitle = {International Conference on Machine Learning (ICML)},
}
@inproceedings{QMIX,
  author = {Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  title = {QMIX: monotonic value function factorisation for deep multi-agent reinforcement learning},
  year = {2018},
  booktitle = {International Conference on Machine Learning (ICML)},
}
@article{SMAC,
  author = {Samvelyan, Mikayel and Rashid, Tabish and de Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  title = {The starcraft multi-agent challenge},
  year = {2019},
  journal = {arXiv preprint arXiv:1902.04043},
}
@inproceedings{VDN,
  author = {Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vin{\'\i}cius Flores and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  title = {Value-Decomposition Networks For Cooperative Multi-Agent Learning Based On Team Reward.},
  year = {2018},
  booktitle = {International Conference on Autonomous Agents and MultiAgent Systems (AAMAS)},
}
@inproceedings{zhang2018fully,
  author = {Kaiqing {Zhang} and Zhuoran {Yang} and Han {Liu} and Tong {Zhang} and Tamer {Ba$s$ar.}},
  title = {Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents},
  year = {2018},
  booktitle = {International Conference on Machine Learning (ICML)},
}
@article{CO-MARLreview,
  author = {OroojlooyJadid, Afshin and Hajinezhad, Davood},
  title = {A review of cooperative multi-agent deep reinforcement learning},
  year = {2019},
  journal = {arXiv preprint arXiv:1908.03963},
}
@inproceedings{todorov2012mujoco,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  title = {Mujoco: A physics engine for model-based control},
  year = {2012},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
}
@article{HPO,
  author = {Yao, Hsuan-Yu and Hsieh, Ping-Chun and Ho, Kuo-Hao and Hu, Kai-Chun and Ouyang, Liang-Chun and Wu, I and others},
  title = {Hinge Policy Optimization: Rethinking Policy Improvement and Reinterpreting PPO},
  year = {2021},
  journal = {arXiv preprint arXiv:2110.13799},
}
@article{terry2020revisiting,
  author = {Terry, Justin K and Grammel, Nathaniel and Hari, Ananth and Santos, Luis and Black, Benjamin},
  title = {Revisiting parameter sharing in multi-agent deep reinforcement learning},
  year = {2020},
  journal = {arXiv preprint arXiv:2005.13625},
}
@inproceedings{DMAC,
  author = {Kefan Su and Zongqing Lu},
  title = {Divergence-Regularized Multi-Agent Actor-Critic},
  year = {2022},
  booktitle = {International Conference on Machine Learning (ICML)},
}
@inproceedings{MAAC,
  author = {Iqbal, Shariq and Sha, Fei},
  title = {Actor-attention-critic for multi-agent reinforcement learning},
  year = {2019},
  booktitle = {International Conference on Machine Learning (ICML)},
}
@inproceedings{undecideDECPOMDP,
  author = {Madani, Omid and Hanks, Steve and Condon, Anne},
  title = {On the undecidability of probabilistic planning and infinite-horizon partially observable Markov decision problems},
  year = {1999},
  booktitle = {AAAI/IAAI},
  pages = {541--548},
}
@article{Qatten,
  author = {Yang, Yaodong and Hao, Jianye and Liao, Ben and Shao, Kun and Chen, Guangyong and Liu, Wulong and Tang, Hongyao},
  title = {Qatten: A General Framework for Cooperative Multiagent Reinforcement Learning},
  year = {2020},
  journal = {arXiv preprint arXiv:2002.03939},
}
@article{IPPO,
  author = {de Witt, Christian Schroeder and Gupta, Tarun and Makoviichuk, Denys and Makoviychuk, Viktor and Torr, Philip HS and Sun, Mingfei and Whiteson, Shimon},
  title = {Is Independent Learning All You Need in the StarCraft Multi-Agent Challenge?},
  year = {2020},
  journal = {arXiv preprint arXiv:2011.09533},
}
@article{HAPPO,
  author = {Kuba, Jakub Grudzien and Chen, Ruiqing and Wen, Munning and Wen, Ying and Sun, Fanglei and Wang, Jun and Yang, Yaodong},
  title = {Trust region policy optimisation in multi-agent reinforcement learning},
  year = {2021},
  journal = {arXiv preprint arXiv:2109.11251},
}
@inproceedings{FOP,
  author = {Zhang, Tianhao and Li, Yueheng and Wang, Chen and Xie, Guangming and Lu, Zongqing},
  title = {FOP: Factorizing Optimal Joint Policy of Maximum-Entropy Multi-Agent Reinforcement Learning},
  year = {2021},
  booktitle = {International Conference on Machine Learning (ICML)},
}
@inproceedings{MADDPG,
  author = {Lowe, Ryan and Wu, Yi I and Tamar, Aviv and Harb, Jean and Abbeel, OpenAI Pieter and Mordatch, Igor},
  title = {Multi-agent actor-critic for mixed cooperative-competitive environments},
  year = {2017},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
}
@inproceedings{mamujoco,
  author = {Peng, Bei and Rashid, Tabish and Schroeder de Witt, Christian and Kamienny, Pierre-Alexandre and Torr, Philip and B{\"o}hmer, Wendelin and Whiteson, Shimon},
  title = {Facmac: Factored multi-agent centralised policy gradients},
  year = {2021},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
}
