@article{du2022noise,
  author = {Hongqiang Du and Lei Xie and Haizhou Li},
  title = {Noise-robust voice conversion with domain adversarial training},
  year = {2022},
  journal = {Neur. Net.},
  volume = {148},
  pages = {74--84},
}
@inproceedings{vcasvdata,
  author = {S. Shahnawazuddin and Waquar Ahmad and Nagaraj Adiga and Avinash Kumar},
  title = {In-Domain and Out-of-Domain Data Augmentation to Improve Children's Speaker Verification System in Limited Data Scenario},
  year = {2020},
  booktitle = {Proc. ICASSP},
  pages = {7554--7558},
}
@article{sisman2020overview,
  author = {Sisman, Berrak and Yamagishi, Junichi and King, Simon and Li, Haizhou},
  title = {An overview of voice conversion and its challenges: From statistical modeling to deep learning},
  year = {2020},
  journal = {IEEE/ACM Trans Audio Speech Lang. Process.},
  volume = {29},
  pages = {132--157},
  publisher = {IEEE},
}
@inproceedings{n2n,
  author = {Chao Xie and Yi{-}Chiao Wu and Patrick Lumban Tobing and Wen{-}Chin Huang and Tomoki Toda},
  title = {Direct Noisy Speech Modeling for Noisy-To-Noisy Voice Conversion},
  year = {2022},
  booktitle = {Proc. ICASSP},
  pages = {6787--6791},
}
@article{syang,
  author = {Shan Yang and Yuxuan Wang and Lei Xie},
  title = {Adversarial Feature Learning and Unsupervised Clustering Based Speech Synthesis for Found Data With Acoustic and Textual Noise},
  year = {2020},
  journal = {{IEEE} Signal Process. Lett.},
  volume = {27},
  pages = {1730--1734},
}
@article{veaux2016superseded,
  author = {Veaux, Christophe and Yamagishi, Junichi and MacDonald, Kirsten and others},
  title = {Superseded-cstr vctk corpus: English multi-speaker corpus for cstr voice cloning toolkit},
  year = {2016},
  publisher = {University of Edinburgh. The Centre for Speech Technology Research (CSTR)},
}
@inproceedings{againvc,
  author = {Yen{-}Hao Chen and Da{-}Yi Wu and Tsung{-}Han Wu and Hung{-}yi Lee},
  title = {Again-VC: {A} One-Shot Voice Conversion Using Activation Guidance and Adaptive Instance Normalization},
  year = {2021},
  booktitle = {Proc. ICASSP},
  pages = {5954--5958},
}
@article{mohammadi2017overview,
  author = {Mohammadi, Seyed Hamidreza and Kain, Alexander},
  title = {An overview of voice conversion systems},
  year = {2017},
  journal = {Speech Comm.},
  volume = {88},
  pages = {65--82},
  publisher = {Elsevier},
}
@inproceedings{le2019sdr,
  author = {Le Roux, Jonathan and Wisdom, Scott and Erdogan, Hakan and Hershey, John R},
  title = {SDR--half-baked or well done?},
  year = {2019},
  booktitle = {Proc. ICASSP},
  pages = {626--630},
}
@inproceedings{yao2021wenet,
  author = {Yao, Zhuoyuan and Wu, Di and Wang, Xiong and Zhang, Binbin and Yu, Fan and Yang, Chao and Peng, Zhendong and Chen, Xiaoyu and Xie, Lei and Lei, Xin},
  title = {Wenet: Production oriented streaming and non-streaming end-to-end speech recognition toolkit},
  year = {2021},
  booktitle = {Proc. Interspeech},
  pages = {4054--4058},
}
@inproceedings{dccrn,
  author = {Yanxin Hu and Yun Liu and Shubo Lv and Mengtao Xing and Shimin Zhang and Yihui Fu and Jian Wu and Bihong Zhang and Lei Xie},
  title = {{DCCRN:} Deep Complex Convolution Recurrent Network for Phase-Aware Speech Enhancement},
  year = {2020},
  booktitle = {Proc. Interspeech},
  pages = {2472--2476},
}
@inproceedings{robustvc,
  author = {Trung Dang and Dung N. Tran and Peter Chin and Kazuhito Koishida},
  title = {Training Robust Zero-Shot Voice Conversion Models with Self-Supervised Features},
  year = {2022},
  booktitle = {Proc. ICASSP},
  pages = {6557--6561},
}
@inproceedings{lmxue,
  author = {Liumeng Xue and Shan Yang and Na Hu and Dan Su and Lei Xie},
  title = {Learning Noise-independent Speech Representation for High-quality Voice Conversion for Noisy Target Speakers},
  year = {2022},
  booktitle = {Proc. Interspeech},
  pages = {2548--2552},
}
@inproceedings{phase,
  author = {Sefik Emre Eskimez and Takuya Yoshioka and Huaming Wang and Xiaofei Wang and Zhuo Chen and Xuedong Huang},
  title = {Personalized speech enhancement: new models and Comprehensive evaluation},
  year = {2022},
  booktitle = {Proc. ICASSP},
  pages = {356--360},
}
@inproceedings{hifigan,
  author = {Jungil Kong and Jaehyeon Kim and Jaekyoung Bae},
  title = {HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis},
  year = {2020},
  booktitle = {Proc. NeurIPS},
}
@inproceedings{wnxu,
  author = {Wei{-}Ning Hsu and Yu Zhang and Ron J. Weiss and Yu{-}An Chung and Yuxuan Wang and Yonghui Wu and James R. Glass},
  title = {Disentangling Correlated Speaker and Noise for Speech Synthesis via Data Augmentation and Adversarial Factorization},
  year = {2019},
  booktitle = {Proc. ICASSP},
  pages = {5901--5905},
}
@misc{musdb18,
  author = {Rafii, Zafar and Liutkus, Antoine and Fabian-Robert St{\"o}ter and Mimilakis, Stylianos Ioannis and Bittner, Rachel},
  title = {The {MUSDB18} corpus for music separation},
  url = {https://doi.org/10.5281/zenodo.1117372},
}
@inproceedings{svc,
  author = {Rajpura, Divyesh G. and Shah, Jui and Patel, Maitreya and Malaviya, Harshit and Phatnani, Kirtana and Patil, Hemant A.},
  title = {Effectiveness of Transfer Learning on Singing Voice Conversion in the Presence of Background Music},
  year = {2020},
  booktitle = {Proc. SPCOM},
  pages = {1-5},
}
@inproceedings{dns,
  author = {Chandan K. A. Reddy and Harishchandra Dubey and Vishak Gopal and Ross Cutler and Sebastian Braun and Hannes Gamper and Robert Aichner and Sriram Srinivasan},
  title = {{ICASSP} 2021 Deep Noise Suppression Challenge},
  year = {2021},
  booktitle = {Proc. ICASSP},
  pages = {6623--6627},
}
@inproceedings{acvc,
  author = {Damien Ronssin and Milos Cernak},
  title = {{AC-VC:} Non-Parallel Low Latency Phonetic Posteriorgrams Based Voice Conversion},
  year = {2021},
  booktitle = {Proc. ASRU},
  pages = {710--716},
}
@inproceedings{n2n1,
  author = {Chao Xie and Yi{-}Chiao Wu and Patrick Lumban Tobing and Wen{-}Chin Huang and Tomoki Toda},
  title = {Noisy-to-Noisy Voice Conversion Framework with Denoising Model},
  year = {2021},
  booktitle = {Proc. APSIPA},
  pages = {814--820},
}
@inproceedings{sedis,
  author = {Yangyang Xia and Sebastian Braun and Chandan K. A. Reddy and Harishchandra Dubey and Ross Cutler and Ivan Tashev},
  title = {Weighted Speech Distortion Losses for Neural-Network-Based Real-Time Speech Enhancement},
  year = {2020},
  booktitle = {Proc. ICASSP},
  pages = {871--875},
}
@inproceedings{asymloss,
  author = {Quan Wang and Ignacio Lopez{-}Moreno and Mert Saglam and Kevin W. Wilson and Alan Chiao and Renjie Liu and Yanzhang He and Wei Li and Jason Pelecanos and Marily Nika and Alexander Gruenstein},
  title = {VoiceFilter-Lite: Streaming Targeted Voice Separation for On-Device Speech Recognition},
  year = {2020},
  booktitle = {Proc. Interspeech},
  pages = {2677--2681},
}
@inproceedings{nvcnet,
  author = {Bac Nguyen and Fabien Cardinaux},
  title = {NVC-Net: End-To-End Adversarial Voice Conversion},
  year = {2022},
  booktitle = {Proc. ICASSP},
  pages = {7012--7016},
}
@inproceedings{vcasrdata,
  author = {S. Shahnawazuddin and Nagaraj Adiga and Kunal Kumar and Aayushi Poddar and Waquar Ahmad},
  title = {Voice Conversion Based Data Augmentation to Improve Children's Speech Recognition in Limited Data Scenario},
  year = {2020},
  booktitle = {Proc. Interspeech},
  pages = {4382--4386},
}
@inproceedings{pesq,
  author = {Rix, Antony W and Beerends, John G and Hollier, Michael P and Hekstra, Andries P},
  title = {Perceptual evaluation of speech quality (PESQ)-a new method for speech quality assessment of telephone networks and codecs},
  year = {2001},
  booktitle = {Proc. ICASSP},
  pages = {749--752},
}
@inproceedings{jcong,
  author = {Jian Cong and Shan Yang and Lei Xie and Guoqiao Yu and Guanglu Wan},
  title = {Data Efficient Voice Cloning from Noisy Samples with Domain Adversarial Training},
  year = {2020},
  booktitle = {Proc. Interspeech},
  pages = {811--815},
}
@inproceedings{VQMIVC,
  author = {Disong Wang and Liqun Deng and Yu Ting Yeung and Xiao Chen and Xunying Liu and Helen Meng},
  title = {{VQMIVC:} Vector Quantization and Mutual Information-Based Unsupervised Speech Representation Disentanglement for One-Shot Voice Conversion},
  year = {2021},
  booktitle = {Proc. Interspeech},
  pages = {1344--1348},
}
