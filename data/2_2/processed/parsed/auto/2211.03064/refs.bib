@inproceedings{naseer2021intriguing,
  author = {Muzammal Naseer and Kanchana Ranasinghe and Salman Khan and Munawar Hayat and Fahad Khan and Ming-Hsuan Yang},
  title = {Intriguing Properties of Vision Transformers},
  year = {2021},
  booktitle = {Advances in Neural Information Processing Systems},
}
@article{li2016understanding,
  author = {Li, Jiwei and Monroe, Will and Jurafsky, Dan},
  title = {Understanding neural networks through representation erasure},
  year = {2016},
  journal = {arXiv preprint arXiv:1612.08220},
}
@inproceedings{he2016deep,
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title = {Deep residual learning for image recognition},
  year = {2016},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages = {770--778},
}
@inproceedings{fong2017interpretable,
  author = {Fong, Ruth C and Vedaldi, Andrea},
  title = {Interpretable explanations of black boxes by meaningful perturbation},
  year = {2017},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages = {3429--3437},
}
@inproceedings{fong2019understanding,
  author = {Fong, Ruth and Patrick, Mandela and Vedaldi, Andrea},
  title = {Understanding deep networks via extremal perturbations and smooth masks},
  year = {2019},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages = {2950--2958},
}
@article{zhang2018top,
  author = {Zhang, Jianming and Bargal, Sarah Adel and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan},
  title = {Top-down neural attention by excitation backprop},
  year = {2018},
  journal = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  volume = {126},
  number = {10},
  pages = {1084--1102},
  publisher = {Springer},
}
@inproceedings{serrano2019attention,
  author = {Serrano, Sofia and Smith, Noah A},
  title = {Is Attention Interpretable?},
  year = {2019},
  booktitle = {Annual Meeting of the Association for Computational Linguistics},
  pages = {2931--2951},
}
@article{smilkov2017smoothgrad,
  author = {Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  title = {Smoothgrad: removing noise by adding noise},
  year = {2017},
  journal = {arXiv preprint arXiv:1706.03825},
}
@inproceedings{yuan2021tokens,
  author = {Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zi-Hang and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
  title = {Tokens-to-token vit: Training vision transformers from scratch on imagenet},
  year = {2021},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages = {558--567},
}
@inproceedings{sattarzadeh2021explaining,
  author = {Sattarzadeh, Sam and Sudhakar, Mahesh and Lem, Anthony and Mehryar, Shervin and Plataniotis, Konstantinos N and Jang, Jongseong and Kim, Hyunwoo and Jeong, Yeonjeong and Lee, Sangmin and Bae, Kyunghoon},
  title = {Explaining convolutional neural networks through attribution-based input sampling and block-wise feature aggregation},
  year = {2021},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {35},
  number = {13},
  pages = {11639--11647},
}
@inproceedings{zheng2021rethinking,
  author = {Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
  title = {Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers},
  year = {2021},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages = {6881--6890},
}
@inproceedings{deng2009imagenet,
  author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  title = {Imagenet: A large-scale hierarchical image database},
  year = {2009},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages = {248--255},
  organization = {Ieee},
}
@article{bach2015pixel,
  author = {Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  title = {On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
  year = {2015},
  journal = {PloS one},
  volume = {10},
  number = {7},
  pages = {e0130140},
  publisher = {Public Library of Science San Francisco, CA USA},
}
@article{doshi2017towards,
  author = {Doshi-Velez, Finale and Kim, Been},
  title = {Towards a rigorous science of interpretable machine learning},
  year = {2017},
  journal = {arXiv preprint arXiv:1702.08608},
}
@inproceedings{zeiler2014visualizing,
  author = {Zeiler, Matthew D and Fergus, Rob},
  title = {Visualizing and understanding convolutional networks},
  year = {2014},
  booktitle = {European conference on computer vision},
  pages = {818--833},
  organization = {Springer},
}
@inproceedings{yuan2021explaining,
  author = {Yuan, Tingyi and Li, Xuhong and Xiong, Haoyi and Cao, Hui and Dou, Dejing},
  title = {Explaining Information Flow Inside Vision Transformers Using Markov Chain},
  year = {2021},
  booktitle = {eXplainable AI approaches for debugging and diagnosis.},
}
@article{murtagh2014ward,
  author = {Murtagh, Fionn and Legendre, Pierre},
  title = {Ward’s hierarchical agglomerative clustering method: which algorithms implement Ward’s criterion?},
  year = {2014},
  journal = {Journal of classification},
  volume = {31},
  number = {3},
  pages = {274--295},
  publisher = {Springer},
}
@article{mullner2013fastcluster,
  author = {M{\"u}llner, Daniel},
  title = {fastcluster: Fast hierarchical, agglomerative clustering routines for R and Python},
  year = {2013},
  journal = {Journal of Statistical Software},
  volume = {53},
  pages = {1--18},
}
@inproceedings{wang2021pyramid,
  author = {Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  title = {Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  year = {2021},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages = {568--578},
}
@inproceedings{wang2020score,
  author = {Wang, Haofan and Wang, Zifan and Du, Mengnan and Yang, Fan and Zhang, Zijian and Ding, Sirui and Mardziel, Piotr and Hu, Xia},
  title = {Score-CAM: Score-weighted visual explanations for convolutional neural networks},
  year = {2020},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshop},
  pages = {24--25},
}
@inproceedings{touvron2021training,
  author = {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  title = {Training data-efficient image transformers \& distillation through attention},
  year = {2021},
  booktitle = {International Conference on Machine Learning},
  pages = {10347--10357},
  organization = {PMLR},
}
@article{gunning2019darpa,
  author = {Gunning, David and Aha, David W},
  title = {{DARPA}'s explainable artificial intelligence program},
  year = {2019},
  journal = {AI Magazine},
  volume = {40},
  number = {2},
  pages = {44--58},
  publisher = {Association for the Advancement of Artificial Intelligence},
}
@article{covert2022learning,
  author = {Covert, Ian and Kim, Chanwoo and Lee, Su-In},
  title = {Learning to estimate shapley values with vision transformers},
  year = {2022},
  journal = {arXiv preprint arXiv:2206.05282},
}
@inproceedings{selvaraju2017grad,
  author = {Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  title = {Grad-cam: Visual explanations from deep networks via gradient-based localization},
  year = {2017},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages = {618--626},
}
@inproceedings{abnar2020quantifying,
  author = {Abnar, Samira and Zuidema, Willem},
  title = {Quantifying Attention Flow in Transformers},
  year = {2020},
  booktitle = {Annual Meeting of the Association for Computational Linguistics},
  pages = {4190--4197},
}
@inproceedings{paul2022vision,
  author = {Paul, Sayak and Chen, Pin-Yu},
  title = {Vision transformers are robust learners},
  year = {2022},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {36},
  number = {2},
  pages = {2071--2081},
}
@inproceedings{lundberg2017unified,
  author = {Lundberg, Scott M and Lee, Su-In},
  title = {A unified approach to interpreting model predictions},
  year = {2017},
  booktitle = {Advances in Neural Information Processing Systems},
  pages = {4765--4774},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.Advances in Neural Information Processing Systems.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf},
  editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
}
@inproceedings{jain2019attention,
  author = {Jain, Sarthak and Wallace, Byron C},
  title = {Attention is not Explanation},
  year = {2019},
  booktitle = {Proceedings of NA Annual Meeting of the Association for Computational Linguistics-HLT},
  pages = {3543--3556},
}
@inproceedings{rebuffi2020there,
  author = {Rebuffi, Sylvestre-Alvise and Fong, Ruth and Ji, Xu and Vedaldi, Andrea},
  title = {There and back again: Revisiting backpropagation saliency methods},
  year = {2020},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages = {8839--8848},
}
@inproceedings{dosovitskiy2020image,
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  title = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  year = {2020},
  booktitle = {International conference on learning representations},
}
@inproceedings{bastings2020elephant,
  author = {Bastings, Jasmijn and Filippova, Katja},
  title = {The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?},
  year = {2020},
  booktitle = {Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},
  pages = {149--155},
}
@article{chu2021twins,
  author = {Chu, Xiangxiang and Tian, Zhi and Wang, Yuqing and Zhang, Bo and Ren, Haibing and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  title = {Twins: Revisiting the design of spatial attention in vision transformers},
  year = {2021},
  journal = {Advances in Neural Information Processing Systems},
  volume = {34},
  pages = {9355--9366},
}
@inproceedings{adebayo2018sanity,
  author = {Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
  title = {Sanity checks for saliency maps},
  year = {2018},
  booktitle = {Advances in Neural Information Processing Systems},
  pages = {9525--9536},
}
@inproceedings{voita2019analyzing,
  author = {Voita, Elena and Talbot, David and Moiseev, Fedor and Sennrich, Rico and Titov, Ivan},
  title = {Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned},
  year = {2019},
  booktitle = {Annual Meeting of the Association for Computational Linguistics},
  pages = {5797--5808},
  organization = {Annual Meeting of the Association for Computational Linguistics Anthology},
}
@inproceedings{liu2021swin,
  author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  title = {Swin transformer: Hierarchical vision transformer using shifted windows},
  year = {2021},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages = {10012--10022},
}
@inproceedings{chefer2021transformer,
  author = {Chefer, Hila and Gur, Shir and Wolf, Lior},
  title = {Transformer interpretability beyond attention visualization},
  year = {2021},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages = {782--791},
}
@inproceedings{sundararajan2017axiomatic,
  author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  title = {Axiomatic attribution for deep networks},
  year = {2017},
  booktitle = {International Conference on Machine Learning},
  pages = {3319--3328},
  organization = {PMLR},
}
@inproceedings{ribeiro2016should,
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  title = {" Why should I trust you?" Explaining the predictions of any classifier},
  year = {2016},
  booktitle = {Proceedings of the ACM SIGKDD international conference on knowledge discovery and data mining},
  pages = {1135--1144},
}
@article{raghu2021vision,
  author = {Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
  title = {Do vision transformers see like convolutional neural networks?},
  year = {2021},
  journal = {Advances in Neural Information Processing Systems},
  volume = {34},
  pages = {12116--12128},
}
@inproceedings{zhang2022nested,
  author = {Zhang, Zizhao and Zhang, Han and Zhao, Long and Chen, Ting and Arik, Sercan {\"O} and Pfister, Tomas},
  title = {Nested hierarchical transformer: Towards accurate, data-efficient and interpretable visual understanding},
  year = {2022},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {36},
  number = {3},
  pages = {3417--3425},
}
@inproceedings{petsiuk2018rise,
  author = {Vitali Petsiuk and Abir Das and Kate Saenko},
  title = {RISE: Randomized Input Sampling for Explanation of Black-box Models},
  year = {2018},
  booktitle = {Proceedings of the British Machine Vision Conference},
}
@inproceedings{carion2020end,
  author = {Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  title = {End-to-end object detection with transformers},
  year = {2020},
  booktitle = {European conference on computer vision},
  pages = {213--229},
  organization = {Springer},
}
@article{white2021contrastive,
  author = {White, Adam and Ngan, Kwun Ho and Phelan, James and Afgeh, Saman Sadeghi and Ryan, Kevin and Reyes-Aldasoro, Constantino Carlos and Garcez, Artur d'Avila},
  title = {Contrastive Counterfactual Visual Explanations With Overdetermination},
  year = {2021},
  journal = {arXiv preprint arXiv:2106.14556},
}
@article{shrikumar2017learning,
  author = {Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  title = {Learning important features through propagating activation differences},
  year = {2017},
  journal = {arXiv preprint arXiv:1704.02685},
}
@inproceedings{pruthi2020learning,
  author = {Pruthi, Danish and Gupta, Mansi and Dhingra, Bhuwan and Neubig, Graham and Lipton, Zachary C},
  title = {Learning to Deceive with Attention-Based Explanations},
  year = {2020},
  booktitle = {Annual Meeting of the Association for Computational Linguistics},
  pages = {4782--4793},
}
@inproceedings{chefer2021generic,
  author = {Chefer, Hila and Gur, Shir and Wolf, Lior},
  title = {Generic Attention-Model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers},
  year = {2021},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages = {397-406},
}
@article{miller2019explanation,
  author = {Miller, Tim},
  title = {Explanation in artificial intelligence: Insights from the social sciences},
  year = {2019},
  journal = {Artificial Intelligence},
  volume = {267},
  pages = {1--38},
  publisher = {Elsevier},
}
@inproceedings{tuli2021convolutional,
  author = {Tuli, Shikhar and Dasgupta, Ishita and Grant, Erin and Griffiths, Tom},
  title = {Are Convolutional Neural Networks or Transformers more like human vision?},
  year = {2021},
  booktitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume = {43},
  number = {43},
}
