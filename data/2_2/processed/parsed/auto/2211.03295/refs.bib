@inproceedings{he2016deep,
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title = {Deep residual learning for image recognition},
  year = {2016},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR)},
  pages = {770--778},
}
@inproceedings{vaswani2017attention,
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  title = {Attention is All you Need},
  year = {2017},
}
@article{cvmj2022PVTv2,
  author = {Wenhai Wang and Enze Xie and Xiang Li and Deng-Ping Fan and Kaitao Song and Ding Liang and Tong Lu and Ping Luo and Ling Shao},
  title = {PVTv2: Improved Baselines with Pyramid Vision Transformer},
  year = {2022},
  journal = {Computational Visual Media (CVMJ)},
}
@inproceedings{nips2021partial,
  author = {Geirhos, Robert and Narayanappa, Kantharaju and Mitzkus, Benjamin and Thieringer, Tizian and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland},
  title = {Partial success in closing the gap between human and machine vision},
  year = {2021},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
}
@inproceedings{tan2023openstl,
  author = {Tan, Cheng and Li, Siyuan and Gao, Zhangyang and Guan, Wenfei and Wang, Zedong and Liu, Zicheng and Wu, Lirong and Li, Stan Z},
  title = {OpenSTL: A Comprehensive Benchmark of Spatio-Temporal Predictive Learning},
  year = {2023},
  booktitle = {Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
}
@inproceedings{yu2022metaformer,
  author = {Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng},
  title = {Metaformer is actually what you need for vision},
  year = {2022},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {10819--10829},
}
@article{yamins2014performance,
  author = {Yamins, Daniel LK and Hong, Ha and Cadieu, Charles F and Solomon, Ethan A and Seibert, Darren and DiCarlo, James J},
  title = {Performance-optimized hierarchical models predict neural responses in higher visual cortex},
  year = {2014},
  journal = {Proceedings of the national academy of sciences},
  volume = {111},
  number = {23},
  pages = {8619--8624},
  publisher = {National Acad Sciences},
}
@inproceedings{nips2022hilo,
  author = {Pan, Zizheng and Cai, Jianfei and Zhuang, Bohan},
  title = {Fast Vision Transformers with HiLo Attention},
  year = {2022},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
}
@inproceedings{fan2021multiscale,
  author = {Fan, Haoqi and Xiong, Bo and Mangalam, Karttikeya and Li, Yanghao and Yan, Zhicheng and Malik, Jitendra and Feichtenhofer, Christoph},
  title = {Multiscale vision transformers},
  year = {2021},
  pages = {6824--6835},
}
@inproceedings{iccv2017ChannelP,
  author = {Yihui He and Xiangyu Zhang and Jian Sun},
  title = {Channel Pruning for Accelerating Very Deep Neural Networks},
  year = {2017},
  booktitle = {2017 IEEE International Conference on Computer Vision (ICCV)},
  pages = {1398-1406},
}
@article{nips2021coatnet,
  author = {Dai, Zihang and Liu, Hanxiao and Le, Quoc V and Tan, Mingxing},
  title = {Coatnet: Marrying convolution and attention for all data sizes},
  year = {2021},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume = {34},
  pages = {3965--3977},
}
@article{sifre2014rigid,
  author = {Sifre, Laurent and Mallat, St{\'e}phane},
  title = {Rigid-motion scattering for texture classification},
  year = {2014},
  journal = {arXiv preprint arXiv:1403.1687},
}
@inproceedings{nips2022focalnet,
  author = {Jianwei Yang and Chunyuan Li and Xiyang Dai and Jianfeng Gao},
  title = {Focal Modulation Networks},
  year = {2022},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
}
@inproceedings{nips2020byol,
  author = {Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre H and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Avila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and others},
  title = {Bootstrap your own latent: A new approach to self-supervised learning},
  year = {2020},
}
@inproceedings{xie2017aggregated,
  author = {Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  title = {Aggregated residual transformations for deep neural networks},
  year = {2017},
  pages = {1492--1500},
}
@article{guo2022van,
  author = {Guo, Meng-Hao and Lu, Cheng-Ze and Liu, Zheng-Ning and Cheng, Ming-Ming and Hu, Shi-Min},
  title = {Visual Attention Network},
  year = {2023},
  journal = {Computational Visual Media (CVMJ)},
  pages = {733–-752},
}
@article{cvpr2017fpn,
  author = {Tsung-Yi Lin and Piotr Doll{\'a}r and Ross B. Girshick and Kaiming He and Bharath Hariharan and Serge J. Belongie},
  title = {Feature Pyramid Networks for Object Detection},
  year = {2017},
  journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {936-944},
}
@inproceedings{nips2022EfficientFormer,
  author = {Yanyu Li and Geng Yuan and Yang Wen and Eric Hu and Georgios Evangelidis and S. Tulyakov and Yanzhi Wang and Jian Ren},
  title = {EfficientFormer: Vision Transformers at MobileNet Speed},
  year = {2022},
}
@inproceedings{iccv2019mobilenetv3,
  author = {Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  title = {Searching for mobilenetv3},
  year = {2019},
  booktitle = {Proceedings of the IEEE/CVF international conference on computer vision (ICCV)},
  pages = {1314--1324},
}
@inproceedings{hermann2020origins,
  author = {Hermann, Katherine and Chen, Ting and Kornblith, Simon},
  title = {The Origins and Prevalence of Texture Bias in Convolutional Neural Networks},
  year = {2020},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume = {33},
  pages = {19000--19015},
}
@inproceedings{jiang2021transgan,
  author = {Jiang, Yifan and Chang, Shiyu and Wang, Zhangyang},
  title = {Transgan: Two pure transformers can make one strong gan, and that can scale up},
  year = {2021},
}
@inproceedings{eccv2022deit3,
  author = {Hugo Touvron and Matthieu Cord and Herv'e J'egou},
  title = {DeiT III: Revenge of the ViT},
  year = {2022},
}
@inproceedings{bao2021beit,
  author = {Bao, Hangbo and Dong, Li and Wei, Furu},
  title = {Beit: Bert pre-training of image transformers},
  year = {2022},
}
@article{Luo2016ERF,
  author = {Wenjie Luo and Yujia Li and Raquel Urtasun and Richard S. Zemel},
  title = {Understanding the Effective Receptive Field in Deep Convolutional Neural Networks},
  year = {2016},
  journal = {ArXiv},
  volume = {abs/1701.04128},
}
@inproceedings{iccv2023Oriented1D,
  author = {Kirchmeyer, Alexandre and Deng, Jia},
  title = {Convolutional Networks with Oriented 1D Kernels},
  year = {2023},
}
@inproceedings{iccv2017Deformable,
  author = {Jifeng Dai and Haozhi Qi and Yuwen Xiong and Yi Li and Guodong Zhang and Han Hu and Yichen Wei},
  title = {Deformable Convolutional Networks},
  year = {2017},
  booktitle = {IEEE International Conference on Computer Vision (ICCV)},
  pages = {764-773},
}
@article{han2021transformer,
  author = {Han, Kai and Xiao, An and Wu, Enhua and Guo, Jianyuan and Xu, Chunjing and Wang, Yunhe},
  title = {Transformer in transformer},
  year = {2021},
  volume = {34},
  pages = {15908--15919},
}
@article{Shazeer2020GLU,
  author = {Noam M. Shazeer},
  title = {GLU Variants Improve Transformer},
  year = {2020},
  journal = {ArXiv},
  volume = {abs/2002.05202},
}
@inproceedings{zhong2020random,
  author = {Zhong, Zhun and Zheng, Liang and Kang, Guoliang and Li, Shaozi and Yang, Yi},
  title = {Random erasing data augmentation},
  year = {2020},
  booktitle = {Proceedings of the AAAI conference on artificial intelligence (AAAI)},
  pages = {13001--13008},
}
@inproceedings{nips2021TL,
  author = {Zihang Jiang and Qibin Hou and Li Yuan and Daquan Zhou and Yujun Shi and Xiaojie Jin and Anran Wang and Jiashi Feng},
  title = {All Tokens Matter: Token Labeling for Training Better Vision Transformers},
  year = {2021},
}
@inproceedings{cvpr2019ffhq,
  author = {Karras, Tero and Laine, Samuli and Aila, Timo},
  title = {A style-based generator architecture for generative adversarial networks},
  year = {2019},
  pages = {4401--4410},
}
@article{Lin2022SuperViT,
  author = {Mingbao Lin and Mengzhao Chen and Yu-xin Zhang and Ke Li and Yunhang Shen and Chunhua Shen and Rongrong Ji},
  title = {Super Vision Transformer},
  year = {2022},
  journal = {ArXiv},
  volume = {abs/2205.11397},
}
@inproceedings{szegedy2015going,
  author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  title = {Going deeper with convolutions},
  year = {2015},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR)},
  pages = {1--9},
}
@inproceedings{cvpr2022VideoSwin,
  author = {Ze Liu and Jia Ning and Yue Cao and Yixuan Wei and Zheng Zhang and Stephen Lin and Han Hu},
  title = {Video Swin Transformer},
  year = {2022},
  booktitle = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {3192-3201},
}
@article{zhang2020interpreting,
  author = {Zhang, Hao and Li, Sen and Ma, Yinchao and Li, Mingjie and Xie, Yichen and Zhang, Quanshi},
  title = {Interpreting and boosting dropout from a game-theoretic view},
  year = {2020},
  journal = {arXiv preprint arXiv:2009.11729},
}
@inproceedings{cvpr2019semanticFPN,
  author = {Alexander Kirillov and Ross B. Girshick and Kaiming He and Piotr Doll{\'a}r},
  title = {Panoptic Feature Pyramid Networks},
  year = {2019},
  booktitle = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {6392-6401},
}
@article{devlin2018bert,
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  title = {Bert: Pre-training of deep bidirectional transformers for language understanding},
  year = {2018},
  journal = {arXiv:1810.04805},
}
@inproceedings{feng2018evaluation,
  author = {Feng, Zhen-Hua and Huber, Patrik and Kittler, Josef and Hancock, Peter and Wu, Xiao-Jun and Zhao, Qijun and Koppen, Paul and R{\"a}tsch, Matthias},
  title = {Evaluation of dense 3D reconstruction from 2D face images in the wild},
  year = {2018},
  booktitle = {2018 13th IEEE International Conference on Automatic Face \& Gesture Recognition (FG 2018)},
  pages = {780--786},
  organization = {IEEE},
}
@inproceedings{deng2021discovering,
  author = {Deng, Huiqi and Ren, Qihan and Chen, Xu and Zhang, Hao and Ren, Jie and Zhang, Quanshi},
  title = {Discovering and Explaining the Representation Bottleneck of DNNs},
  year = {2022},
}
@inproceedings{iclr2019AdamW,
  author = {Ilya Loshchilov and Frank Hutter},
  title = {Decoupled Weight Decay Regularization},
  year = {2019},
  booktitle = {International Conference on Learning Representations (ICLR)},
}
@inproceedings{dauphin2017language,
  author = {Dauphin, Yann N and Fan, Angela and Auli, Michael and Grangier, David},
  title = {Language modeling with gated convolutional networks},
  year = {2017},
  booktitle = {International conference on machine learning (ICML)},
  pages = {933--941},
  organization = {PMLR},
}
@inproceedings{nips2022iformer,
  author = {Chenyang Si and Weihao Yu and Pan Zhou and Yichen Zhou and Xinchao Wang and Shuicheng Yan},
  title = {Inception Transformer},
  year = {2022},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
}
@article{zhou2021ibot,
  author = {Zhou, Jinghao and Wei, Chen and Wang, Huiyu and Shen, Wei and Xie, Cihang and Yuille, Alan and Kong, Tao},
  title = {ibot: Image bert pre-training with online tokenizer},
  year = {2021},
  journal = {arXiv preprint arXiv:2111.07832},
}
@inproceedings{arnab2021vivit,
  title = {Vivit: A video vision transformer},
  year = {2021},
  booktitle = {IEEE International Conference on Computer Vision (ICCV)},
}
@inproceedings{iclr2014adam,
  author = {Diederik P. Kingma and Jimmy Ba},
  title = {Adam: A Method for Stochastic Optimization},
  year = {2014},
}
@inproceedings{eccv2022AutoMix,
  author = {Zicheng Liu and Siyuan Li and Di Wu and Zhiyuan Chen and Lirong Wu and Jianzhu Guo and Stan Z. Li},
  title = {AutoMix: Unveiling the Power of Mixup for Stronger Classifiers},
  year = {2022},
}
@inproceedings{iclr2019shapebias,
  author = {Robert Geirhos and Patricia Rubisch and Claudio Michaelis and Matthias Bethge and Felix Wichmann and Wieland Brendel},
  title = {ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness},
  year = {2019},
}
@inproceedings{eccv2018CBAM,
  author = {Sanghyun Woo and Jongchan Park and Joon-Young Lee and In-So Kweon},
  title = {CBAM: Convolutional Block Attention Module},
  year = {2018},
}
@inproceedings{yuan2021tokens,
  author = {Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zihang and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
  title = {Tokens-to-token vit: Training vision transformers from scratch on imagenet},
  year = {2021},
  booktitle = {International Conference on Computer Vision (ICCV)},
  journal = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages = {538-547},
}
@inproceedings{iclr2022mobilevit,
  author = {Mehta, Sachin and Rastegari, Mohammad},
  title = {Mobilevit: light-weight, general-purpose, and mobile-friendly vision transformer},
  year = {2022},
}
@inproceedings{cvpr2017grad,
  author = {Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  title = {Grad-cam: Visual explanations from deep networks via gradient-based localization},
  year = {2017},
  booktitle = {Proceedings of the IEEE international conference on computer vision (CVPR)},
  pages = {618--626},
}
@inproceedings{iccv2019GCNet,
  author = {Yue Cao and Jiarui Xu and Stephen Lin and Fangyun Wei and Han Hu},
  title = {GCNet: Non-Local Networks Meet Squeeze-Excitation Networks and Beyond},
  year = {2019},
  booktitle = {2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)},
  pages = {1971-1980},
}
@inproceedings{eccv2022tinyvit,
  author = {Wu, Kan and Zhang, Jinnian and Peng, Houwen and Liu, Mengchen and Xiao, Bin and Fu, Jianlong and Yuan, Lu},
  title = {TinyViT: Fast Pretraining Distillation for Small Vision Transformers},
  year = {2022},
  booktitle = {European conference on computer vision (ECCV)},
}
@misc{mmpose2020,
  author = {MMPose Contributors},
  title = {OpenMMLab Pose Estimation Toolbox and Benchmark},
  year = {2020},
}
@article{2016layernorm,
  author = {Jimmy Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
  title = {Layer Normalization},
  year = {2016},
  journal = {ArXiv},
  volume = {abs/1607.06450},
}
@inproceedings{iclr2020lamb,
  author = {Yang You and Jing Li and Sashank Reddi and Jonathan Hseu and Sanjiv Kumar and Srinadh Bhojanapalli and Xiaodan Song and James Demmel and Kurt Keutzer and Cho-Jui Hsieh},
  title = {Large Batch Optimization for Deep Learning: Training {BERT} in 76 minutes},
  year = {2020},
}
@article{2022decouplemix,
  author = {Liu, Zicheng and Li, Siyuan and Wang, Ge and Tan, Cheng and Wu, Lirong and Li, Stan Z.},
  title = {Decoupled Mixup for Data-efficient Learning},
  year = {2022},
  journal = {ArXiv},
  volume = {abs/2203.10761},
}
@inproceedings{NIPS2017GhostBN,
  author = {Elad Hoffer and Itay Hubara and Daniel Soudry},
  title = {Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  year = {2017},
}
@inproceedings{iccv2021PVT,
  author = {Wenhai Wang and Enze Xie and Xiang Li and Deng-Ping Fan and Kaitao Song and Ding Liang and Tong Lu and Ping Luo and Ling Shao},
  title = {Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions},
  year = {2021},
  booktitle = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages = {548-558},
}
@article{pinto2022impartial,
  author = {Pinto, Francesco and Torr, Philip HS and Dokania, Puneet K},
  title = {An impartial take to the cnn vs transformer robustness contest},
  year = {2022},
}
@inproceedings{nips2021SOFT,
  author = {Jiachen Lu and Jinghan Yao and Junge Zhang and Xiatian Zhu and Hang Xu and Weiguo Gao and Chunjing Xu and Tao Xiang and Li Zhang},
  title = {SOFT: Softmax-free Transformer with Linear Complexity},
  year = {2021},
}
@article{wu2022bottleneck,
  author = {Wu, Fang and Li, Siyuan and Wu, Lirong and Li, Stan Z and Radev, Dragomir and Zhang, Qiang},
  title = {Discovering the Representation Bottleneck of Graph Neural Networks from Multi-order Interactions},
  year = {2022},
  journal = {arXiv preprint arXiv:2205.07266},
  volume = {abs/2205.07266},
  url = {https://api.semanticscholar.org/CorpusID:248811221},
}
@inproceedings{iclr2016dilated,
  author = {Fisher Yu and Vladlen Koltun},
  title = {Multi-Scale Context Aggregation by Dilated Convolutions},
  year = {2016},
}
@article{raghu2021vision,
  author = {Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
  title = {Do vision transformers see like convolutional neural networks?},
  year = {2021},
  volume = {34},
  pages = {12116--12128},
}
@inproceedings{cvpr2022simvp,
  author = {Gao, Zhangyang and Tan, Cheng and Wu, Lirong and Li, Stan Z.},
  title = {SimVP: Simpler Yet Better Video Prediction},
  year = {2022},
  pages = {3170-3180},
  month = {June},
}
@article{Brock2021NFNet,
  author = {Andrew Brock and Soham De and Samuel L. Smith and Karen Simonyan},
  title = {High-Performance Large-Scale Image Recognition Without Normalization},
  year = {2021},
  journal = {ArXiv},
  volume = {abs/2102.06171},
}
@article{hendrycks2016bridging,
  author = {Dan Hendrycks and Kevin Gimpel},
  title = {Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units},
  year = {2016},
  journal = {arXiv preprint arXiv:1606.08415},
}
@inproceedings{yun2019cutmix,
  author = {Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
  title = {Cutmix: Regularization strategy to train strong classifiers with localizable features},
  year = {2019},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages = {6023--6032},
}
@misc{mmhuman3d,
  author = {MMHuman3D Contributors},
  title = {OpenMMLab 3D Human Parametric Model Toolbox and Benchmark},
  year = {2021},
}
@inproceedings{cvpr2018mobilenetv2,
  author = {Mark Sandler and Andrew G. Howard and Menglong Zhu and Andrey Zhmoginov and Liang-Chieh Chen},
  title = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
  year = {2018},
  pages = {4510-4520},
}
@article{siam1992ema,
  author = {Boris Polyak and Anatoli B. Juditsky},
  title = {Acceleration of stochastic approximation by averaging},
  year = {1992},
  journal = {Siam Journal on Control and Optimization},
  volume = {30},
  pages = {838-855},
}
@inproceedings{cvpr2020repeat,
  author = {Hoffer, Elad and Ben-Nun, Tal and Hubara, Itay and Giladi, Niv and Hoefler, Torsten and Soudry, Daniel},
  title = {Augment Your Batch: Improving Generalization Through Instance Repetition},
  year = {2020},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {8126-8135},
}
@article{Wu2021PreciseBN,
  author = {Yuxin Wu and Justin Johnson},
  title = {Rethinking "Batch" in BatchNorm},
  year = {2021},
  journal = {ArXiv},
  volume = {abs/2105.07576},
}
@inproceedings{cvpr2020Orthogonal,
  author = {Jiayun Wang and Yubei Chen and Rudrasis Chakraborty and Stella X. Yu},
  title = {Orthogonal Convolutional Neural Networks},
  year = {2020},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {11502-11512},
}
@inproceedings{wang2018non,
  author = {Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
  title = {Non-local neural networks},
  year = {2018},
  pages = {7794--7803},
}
@inproceedings{nips2021Twins,
  author = {Xiangxiang Chu and Zhi Tian and Yuqing Wang and Bo Zhang and Haibing Ren and Xiaolin Wei and Huaxia Xia and Chunhua Shen},
  title = {Twins: Revisiting the Design of Spatial Attention in Vision Transformers},
  year = {2021},
}
@inproceedings{naseer2021intriguing,
  author = {Naseer, Muhammad Muzammal and Ranasinghe, Kanchana and Khan, Salman H and Hayat, Munawar and Shahbaz Khan, Fahad and Yang, Ming-Hsuan},
  title = {Intriguing properties of vision transformers},
  year = {2021},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
}
@misc{mmdetection,
  author = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},
  title = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark},
  year = {2019},
  journal = {arXiv preprint arXiv:1906.07155},
}
@article{Li2021SAMix,
  author = {Siyuan Li and Zicheng Liu and Di Wu and Zihan Liu and Stan Z. Li},
  title = {Boosting Discriminative Visual Representation Learning with Scenario-Agnostic Mixup},
  year = {2021},
  journal = {ArXiv},
  volume = {abs/2111.15454},
}
@inproceedings{eccv2018upernet,
  author = {Xiao, Tete and Liu, Yingcheng and Zhou, Bolei and Jiang, Yuning and Sun, Jian},
  title = {Unified Perceptual Parsing for Scene Understanding},
  year = {2018},
  booktitle = {European Conference on Computer Vision (ECCV)},
  organization = {Springer},
}
@inproceedings{eccv2018shufflenet,
  author = {Ma, Ningning and Zhang, Xiangyu and Zheng, Hai-Tao and Sun, Jian},
  title = {Shufflenet v2: Practical guidelines for efficient cnn architecture design},
  year = {2018},
  booktitle = {Proceedings of the European conference on computer vision (ECCV)},
  pages = {116--131},
}
@inproceedings{chollet2017xception,
  title = {Xception: Deep learning with depthwise separable convolutions},
  year = {2017},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR)},
  pages = {1251--1258},
}
@article{simonyan2014very,
  author = {Simonyan, Karen and Zisserman, Andrew},
  title = {Very deep convolutional networks for large-scale image recognition},
  year = {2014},
  journal = {arXiv preprint arXiv:1409.1556},
}
@inproceedings{iclr2022uniformer,
  author = {Li, Kunchang and Wang, Yali and Zhang, Junhao and Gao, Peng and Song, Guanglu and Liu, Yu and Li, Hongsheng and Qiao, Yu},
  title = {Uniformer: Unifying convolution and self-attention for visual recognition},
  year = {2022},
}
@article{lecun1998gradient,
  author = {LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  title = {Gradient-based learning applied to document recognition},
  year = {1998},
  journal = {Proceedings of the IEEE},
  volume = {86},
  number = {11},
  pages = {2278--2324},
  publisher = {Ieee},
}
@article{cvpr2019AutoAugment,
  author = {Ekin Dogus Cubuk and Barret Zoph and Dandelion Man{\'e} and Vijay Vasudevan and Quoc V. Le},
  title = {AutoAugment: Learning Augmentation Strategies From Data},
  year = {2019},
  journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {113-123},
}
@inproceedings{li2022A2MIM,
  author = {Siyuan Li and Di Wu and Fang Wu and Zelin Zang and Stan.Z.Li},
  title = {Architecture-Agnostic Masked Image Modeling - From ViT back to CNN},
  year = {2023},
}
@inproceedings{aaai2022shiftvit,
  author = {Guangting Wang and Yucheng Zhao and Chuanxin Tang and Chong Luo and Wenjun Zeng},
  title = {When Shift Operation Meets Vision Transformer: An Extremely Simple Alternative to Attention Mechanism},
  year = {2022},
}
@inproceedings{cvpr2022AViT,
  author = {Yin, Hongxu and Vahdat, Arash and Alvarez, Jose M. and Mallya, Arun and Kautz, Jan and Molchanov, Pavlo},
  title = {A-ViT: Adaptive Tokens for Efficient Vision Transformer},
  year = {2022},
  pages = {10799-10808},
}
@inproceedings{aaai2022LIT,
  author = {Zizheng Pan and Bohan Zhuang and Haoyu He and Jing Liu and Jianfei Cai},
  title = {Less is More: Pay Less Attention in Vision Transformers},
  year = {2022},
}
@inproceedings{touvron2021training,
  author = {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  title = {Training data-efficient image transformers \& distillation through attention},
  year = {2021},
  booktitle = {International Conference on Machine Learning (ICML)},
  pages = {10347--10357},
}
@inproceedings{cubuk2020randaugment,
  author = {Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  title = {Randaugment: Practical automated data augmentation with a reduced search space},
  year = {2020},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  pages = {702--703},
}
@inproceedings{icml2015mmnist,
  author = {Nitish Srivastava and Elman Mansimov and Ruslan Salakhutdinov},
  title = {Unsupervised Learning of Video Representations using {LSTM}s},
  year = {2015},
}
@inproceedings{Liu2022SLak,
  author = {S. Liu and Tianlong Chen and Xiaohan Chen and Xuxi Chen and Qiao Xiao and Boqian Wu and Mykola Pechenizkiy and Decebal Constantin Mocanu and Zhangyang Wang},
  title = {More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity},
  year = {2023},
}
@inproceedings{eccv2020ExPose,
  author = {Choutas, Vasileios and Pavlakos, Georgios and Bolkart, Timo and Tzionas, Dimitrios and Black, Michael J.},
  title = {Monocular Expressive Body Regression through Body-Driven Attention},
  year = {2020},
  booktitle = {European Conference on Computer Vision (ECCV)},
  pages = {20--40},
}
@inproceedings{hu2018squeeze,
  author = {Hu, Jie and Shen, Li and Sun, Gang},
  title = {Squeeze-and-excitation networks},
  year = {2018},
  pages = {7132--7141},
}
@article{cvpr2016inceptionv3,
  author = {Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Zbigniew Wojna},
  title = {Rethinking the Inception Architecture for Computer Vision},
  year = {2016},
  journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {2818-2826},
}
@inproceedings{nips2022hornet,
  author = {Yongming Rao and Wenliang Zhao and Yansong Tang and Jie Zhou and Ser Nam Lim and Jiwen Lu},
  title = {HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions},
  year = {2022},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
}
@article{Baker2018DeepCN,
  author = {Nicholas Baker and Hongjing Lu and Gennady Erlikhman and Philip J. Kellman},
  title = {Deep convolutional networks do not classify based on global object shape},
  year = {2018},
  journal = {PLoS Computational Biology},
  volume = {14},
  number = {12},
  pages = {e1006613},
  publisher = {Public Library of Science San Francisco, CA USA},
}
@article{loshchilov2016sgdr,
  author = {Loshchilov, Ilya and Hutter, Frank},
  title = {Sgdr: Stochastic gradient descent with warm restarts},
  year = {2016},
  journal = {arXiv preprint arXiv:1608.03983},
}
@article{2017MobileNet,
  author = {Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
  title = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
  year = {2017},
  journal = {ArXiv},
  volume = {abs/1704.04861},
}
@inproceedings{icml2022FAN,
  author = {Daquan Zhou and Zhiding Yu and Enze Xie and Chaowei Xiao and Anima Anandkumar and Jiashi Feng and Jos{\'e} Manuel {\'A}lvarez},
  title = {Understanding The Robustness in Vision Transformers},
  year = {2022},
}
@inproceedings{carion2020end,
  author = {Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  title = {End-to-end object detection with transformers},
  year = {2020},
}
@article{elfwing2018sigmoid,
  author = {Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
  title = {Sigmoid-weighted linear units for neural network function approximation in reinforcement learning},
  year = {2018},
  journal = {Neural Networks},
  volume = {107},
  pages = {3--11},
  publisher = {Elsevier},
}
@inproceedings{iccv2017retinanet,
  author = {Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  title = {Focal loss for dense object detection},
  year = {2017},
}
@inproceedings{guo2021cmt,
  author = {Guo, Jianyuan and Han, Kai and Wu, Han and Xu, Chang and Tang, Yehui and Xu, Chunjing and Wang, Yunhe},
  title = {Cmt: Convolutional neural networks meet vision transformers},
  year = {2022},
}
@inproceedings{eccv2018simple,
  author = {Xiao, Bin and Wu, Haiping and Wei, Yichen},
  title = {Simple Baselines for Human Pose Estimation and Tracking},
  year = {2018},
  booktitle = {European Conference on Computer Vision (ECCV)},
}
@inproceedings{icml2022Flowformer,
  author = {Haixu Wu and Jialong Wu and Jiehui Xu and Jianmin Wang and Mingsheng Long},
  title = {Flowformer: Linearizing Transformers with Conservation Flows},
  year = {2022},
}
@article{treisman1980feature,
  author = {Treisman, Anne M and Gelade, Garry},
  title = {A feature-integration theory of attention},
  year = {1980},
  journal = {Cognitive psychology},
  volume = {12},
  number = {1},
  pages = {97--136},
  publisher = {Elsevier},
}
@inproceedings{iclr2021characterizing,
  author = {Andrew Brock and Soham De and Samuel L. Smith},
  title = {Characterizing signal propagation to close the performance gap in unnormalized ResNets},
  year = {2021},
}
@inproceedings{zhang2017mixup,
  author = {Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  title = {mixup: Beyond empirical risk minimization},
  year = {2018},
}
@inproceedings{nips2021MLPMixer,
  author = {Ilya O. Tolstikhin and Neil Houlsby and Alexander Kolesnikov and Lucas Beyer and Xiaohua Zhai and Thomas Unterthiner and Jessica Yung and Daniel Keysers and Jakob Uszkoreit and Mario Lucic and Alexey Dosovitskiy},
  title = {MLP-Mixer: An all-MLP Architecture for Vision},
  year = {2021},
}
@inproceedings{eccv2022edgeformer,
  author = {Zhang, Haokui and Hu, Wenze and Wang, Xiaoyu},
  title = {EdgeFormer: Improving Light-weight ConvNets by Learning from Vision Transformers},
  year = {2022},
}
@article{2022convmixer,
  author = {Asher Trockman and J. Zico Kolter},
  title = {Patches Are All You Need?},
  year = {2022},
  journal = {ArXiv},
  volume = {abs/2201.09792},
}
@inproceedings{nips2020linformer,
  author = {Sinong Wang and Belinda Z. Li and Madian Khabsa and Han Fang and Hao Ma},
  title = {Linformer: Self-Attention with Linear Complexity},
  year = {2021},
}
@article{Krizhevsky2012ImageNetCW,
  author = {Alex Krizhevsky and Ilya Sutskever and Geoffrey E. Hinton},
  title = {ImageNet classification with deep convolutional neural networks},
  year = {2012},
  journal = {Communications of the ACM},
  volume = {60},
  pages = {84 - 90},
}
@inproceedings{cvpr2022MobileFormer,
  author = {Yinpeng Chen and Xiyang Dai and Dongdong Chen and Mengchen Liu and Xiaoyi Dong and Lu Yuan and Zicheng Liu},
  title = {Mobile-Former: Bridging MobileNet and Transformer},
  year = {2022},
}
@inproceedings{ioffe2015batch,
  author = {Ioffe, Sergey and Szegedy, Christian},
  title = {Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  year = {2015},
  pages = {448--456},
  organization = {PMLR},
}
@inproceedings{chen2021pre,
  author = {Chen, Hanting and Wang, Yunhe and Guo, Tianyu and Xu, Chang and Deng, Yiping and Liu, Zhenhua and Ma, Siwei and Xu, Chunjing and Xu, Chao and Gao, Wen},
  title = {Pre-trained image processing transformer},
  year = {2021},
}
@inproceedings{cvpr2009imagenet,
  author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  title = {{ImageNet: A large-scale hierarchical image database}},
  year = {2009},
}
@inproceedings{cvpr2022resnest,
  author = {Zhang, Hang and Wu, Chongruo and Zhang, Zhongyue and Zhu, Yi and Lin, Haibin and Zhang, Zhi and Sun, Yue and He, Tong and Mueller, Jonas and Manmatha, R and others},
  title = {Resnest: Split-attention networks},
  year = {2022},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {2736--2746},
}
@inproceedings{iccv2021dino,
  author = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J\'egou, Herv\'e and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  title = {Emerging Properties in Self-Supervised Vision Transformers},
  year = {2021},
  booktitle = {Proceedings of the International Conference on Computer Vision (ICCV)},
}
@article{brown2020language,
  author = {Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  title = {Language models are few-shot learners},
  year = {2020},
}
@misc{mmseg2020,
  author = {MMSegmentation Contributors},
  title = {{MMSegmentation}: OpenMMLab Semantic Segmentation Toolbox and Benchmark},
  year = {2020},
}
@misc{li2022openmixup,
  author = {Li, Siyuan and Wang, Zedong and Liu, Zicheng and Wu, Di and Stan Z. Li},
  title = {OpenMixup: Open Mixup Toolbox and Benchmark for Visual Representation Learning},
  year = {2022},
}
@inproceedings{icml2022FLASH,
  author = {Weizhe Hua and Zihang Dai and Hanxiao Liu and Quoc V. Le},
  title = {Transformer Quality in Linear Time},
  year = {2022},
}
@article{tpami2019cascade,
  author = {Cai, Zhaowei and Vasconcelos, Nuno},
  title = {Cascade R-CNN: High-Quality Object Detection and Instance Segmentation},
  year = {2019},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  issn = {1939-3539},
}
@inproceedings{cvpr2022convnext,
  author = {Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  title = {A convnet for the 2020s},
  year = {2022},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {11976--11986},
}
@article{han2021demystifying,
  author = {Han, Qi and Fan, Zejia and Dai, Qi and Sun, Lei and Cheng, Ming-Ming and Liu, Jiaying and Wang, Jingdong},
  title = {Demystifying Local Vision Transformer: Sparse Connectivity, Weight Sharing, and Dynamic Weight},
  year = {2021},
  journal = {arXiv:2106.04263},
}
@inproceedings{iclr2022cosFormer,
  author = {Zhen Qin and Weixuan Sun and Huicai Deng and Dongxu Li and Yunshen Wei and Baohong Lv and Junjie Yan and Lingpeng Kong and Yiran Zhong},
  title = {cosFormer: Rethinking Softmax in Attention},
  year = {2022},
}
@article{Zhou2018ADE20k,
  author = {Bolei Zhou and Hang Zhao and Xavier Puig and Sanja Fidler and Adela Barriuso and Antonio Torralba},
  title = {Semantic Understanding of Scenes Through the ADE20K Dataset},
  year = {2018},
  journal = {International Journal of Computer Vision (IJCV)},
  volume = {127},
  pages = {302-321},
}
@inproceedings{cvpr2022replknet,
  author = {Xiaohan Ding and X. Zhang and Yi Zhou and Jungong Han and Guiguang Ding and Jian Sun},
  title = {Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs},
  year = {2022},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
}
@inproceedings{2014MicrosoftCOCO,
  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  title = {Microsoft COCO: Common Objects in Context},
  year = {2014},
  pages = {740--755},
  organization = {Springer},
}
@inproceedings{iccv2021levit,
  author = {Graham, Benjamin and El-Nouby, Alaaeldin and Touvron, Hugo and Stock, Pierre and Joulin, Armand and J{\'e}gou, Herv{\'e} and Douze, Matthijs},
  title = {Levit: a vision transformer in convnet's clothing for faster inference},
  year = {2021},
  booktitle = {Proceedings of the IEEE/CVF international conference on computer vision (ICCV)},
  pages = {12259--12269},
}
@inproceedings{zhu2020deformable,
  author = {Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  title = {Deformable detr: Deformable transformers for end-to-end object detection},
  year = {2021},
}
@article{tpami2015faster,
  author = {Shaoqing Ren and Kaiming He and Ross B. Girshick and Jian Sun},
  title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
  year = {2015},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  volume = {39},
  pages = {1137-1149},
}
@article{cheng2021game,
  author = {Cheng, Xu and Chu, Chuntung and Zheng, Yi and Ren, Jie and Zhang, Quanshi},
  title = {A game-theoretic taxonomy of visual concepts in dnns},
  year = {2021},
  journal = {arXiv preprint arXiv:2106.10938},
}
@inproceedings{ancona2019explaining,
  author = {Ancona, Marco and Oztireli, Cengiz and Gross, Markus},
  title = {Explaining deep neural networks with a polynomial time algorithm for shapley value approximation},
  year = {2019},
  booktitle = {International Conference on Machine Learning (ICML)},
  pages = {272--281},
  organization = {PMLR},
}
@inproceedings{2017iccvmaskrcnn,
  author = {He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  title = {Mask r-cnn},
  year = {2017},
}
@article{2021patchconvnet,
  author = {Hugo Touvron and Matthieu Cord and Alaaeldin El-Nouby and Piotr Bojanowski and Armand Joulin and Gabriel Synnaeve and Jakob Verbeek and Herv'e J'egou},
  title = {Augmenting Convolutional networks with attention-based aggregation},
  year = {2021},
  journal = {arXiv preprint arXiv:2112.13692},
}
@inproceedings{nips2021vitc,
  author = {Tete Xiao and Mannat Singh and Eric Mintun and Trevor Darrell and Piotr Doll{\'a}r and Ross B. Girshick},
  title = {Early Convolutions Help Transformers See Better},
  year = {2021},
}
@inproceedings{bahdanau2014neural,
  author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  title = {Neural machine translation by jointly learning to align and translate},
  year = {2015},
}
@misc{wightman2021rsb,
  author = {Ross Wightman and Hugo Touvron and Hervé Jégou},
  title = {ResNet strikes back: An improved training procedure in timm},
  year = {2021},
}
@inproceedings{cvpr2022mae,
  author = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  title = {Masked autoencoders are scalable vision learners},
  year = {2022},
}
@inproceedings{liu2021swin,
  author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  title = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  year = {2021},
  booktitle = {International Conference on Computer Vision (ICCV)},
}
@inproceedings{parmar2018image,
  author = {Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
  title = {Image transformer},
  year = {2018},
}
@article{wu2021cvt,
  author = {Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},
  title = {Cvt: Introducing convolutions to vision transformers},
  year = {2021},
}
@inproceedings{wu2021rethinking,
  author = {Wu, Kan and Peng, Houwen and Chen, Minghao and Fu, Jianlong and Chao, Hongyang},
  title = {Rethinking and improving relative position encoding for vision transformer},
  year = {2021},
  pages = {10033--10041},
}
@article{2021shapebias,
  author = {Shikhar Tuli and Ishita Dasgupta and Erin Grant and Thomas L. Griffiths},
  title = {Are Convolutional Neural Networks or Transformers more like human vision?},
  year = {2021},
  journal = {ArXiv},
  volume = {abs/2105.07197},
}
@inproceedings{bmvc2016wrn,
  author = {Sergey Zagoruyko and Nikos Komodakis},
  title = {Wide Residual Networks},
  year = {2016},
  booktitle = {Proceedings of the British Machine Vision Conference (BMVC)},
}
@inproceedings{eccv2016droppath,
  author = {Gao Huang and Yu Sun and Zhuang Liu and Daniel Sedra and Kilian Q. Weinberger},
  title = {Deep Networks with Stochastic Depth},
  year = {2016},
}
@article{d2021convit,
  author = {d'Ascoli, St{\'e}phane and Touvron, Hugo and Leavitt, Matthew and Morcos, Ari and Biroli, Giulio and Sagun, Levent},
  title = {Convit: Improving vision transformers with soft convolutional inductive biases},
  year = {2021},
  journal = {arXiv preprint arXiv:2103.10697},
}
@inproceedings{iccv2019freihand,
  author = {Zimmermann, Christian and Ceylan, Duygu and Yang, Jimei and Russell, Bryan and Argus, Max and Brox, Thomas},
  title = {Freihand: A dataset for markerless capture of hand pose and shape from single rgb images},
  year = {2019},
  pages = {813--822},
}
@inproceedings{icml2019efficientnet,
  author = {Tan, Mingxing and Le, Quoc},
  title = {Efficientnet: Rethinking model scaling for convolutional neural networks},
  year = {2019},
  booktitle = {International conference on machine learning (ICML)},
  pages = {6105--6114},
  organization = {PMLR},
}
@inproceedings{iclr2021vit,
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  title = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  year = {2021},
}
@article{wang2022anti,
  author = {Wang, Peihao and Zheng, Wenqing and Chen, Tianlong and Wang, Zhangyang},
  title = {Anti-oversmoothing in deep vision transformers via the fourier domain analysis: From theory to practice},
  year = {2022},
}
@inproceedings{iclr2022how,
  author = {Park, Namuk and Kim, Songkuk},
  title = {How Do Vision Transformers Work?},
  year = {2022},
}
@inproceedings{cvpr2020regnet,
  author = {Ilija Radosavovic and Raj Prateek Kosaraju and Ross B. Girshick and Kaiming He and Piotr Doll{\'a}r},
  title = {Designing Network Design Spaces},
  year = {2020},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {10425-10433},
}
