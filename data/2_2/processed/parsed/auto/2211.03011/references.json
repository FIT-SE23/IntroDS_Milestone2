{
    "2305.06851": {
        "title": "Policy Gradient Algorithms Implicitly Optimize by Continuation",
        "authors": [
            "Adrien Bolland",
            "Gilles Louppe",
            "D. Ernst"
        ],
        "submission_date": "2023",
        "SemanticScholarId": "b0affaa6b830ee25b93169202df23cf9fce621a0"
    },
    "2106.01345": {
        "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling",
        "authors": [
            "Lili Chen",
            "Kevin Lu",
            "A. Rajeswaran",
            "Kimin Lee",
            "Aditya Grover",
            "M. Laskin",
            "P. Abbeel",
            "A. Srinivas",
            "Igor Mordatch"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500"
    },
    "2103.04047": {
        "title": "Reinforcement Learning, Bit by Bit",
        "authors": [
            "Xiuyuan Lu",
            "Benjamin Van Roy",
            "V. Dwaracherla",
            "M. Ibrahimi",
            "Ian Osband",
            "Zheng Wen"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "da45e961f285fdba9aefb3f4d4270620044eccb3"
    },
    "2010.08843": {
        "title": "Approximate information state for approximate planning and reinforcement learning in partially observed systems",
        "authors": [
            "Jayakumar Subramanian",
            "Amit Sinha",
            "Raihan Seraj",
            "A. Mahajan"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "abde7540643e5093cba41a2e4554116bb9241980"
    },
    "2006.03662": {
        "title": "Rapid Task-Solving in Novel Environments",
        "authors": [
            "Samuel Ritter",
            "Ryan Faulkner",
            "Laurent Sartran",
            "Adam Santoro",
            "M. Botvinick",
            "David Raposo"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "6f505f9b8611ea5d1fcf4405a6abb42e0c0c27f1"
    },
    "2003.08165": {
        "title": "Neuroevolution of self-interpretable agents",
        "authors": [
            "Yujin Tang",
            "Duong Nguyen",
            "David Ha"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "8cf62055fa0faab9c325f4b30415f5b0dc285434"
    },
    "1912.01603": {
        "title": "Dream to Control: Learning Behaviors by Latent Imagination",
        "authors": [
            "Danijar Hafner",
            "T. Lillicrap",
            "Jimmy Ba",
            "Mohammad Norouzi"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "0cc956565c7d249d4197eeb1dbab6523c648b2c9"
    },
    "1911.07141": {
        "title": "Working Memory Graphs",
        "authors": [
            "Ricky Loynd",
            "Roland Fernandez",
            "Asli Celikyilmaz",
            "Adith Swaminathan",
            "Matthew J. Hausknecht"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "0e58395ec5677ac3e6876c51cd1dba0cf299261e"
    },
    "1910.06764": {
        "title": "Stabilizing Transformers for Reinforcement Learning",
        "authors": [
            "Emilio Parisotto",
            "H. F. Song",
            "Jack W. Rae",
            "Razvan Pascanu",
            "Çaglar Gülçehre",
            "Siddhant M. Jayakumar",
            "Max Jaderberg",
            "Raphael Lopez Kaufman",
            "Aidan Clark",
            "Seb Noury",
            "M. Botvinick",
            "N. Heess",
            "R. Hadsell"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "59a916cdc943f0282908e6f3fa0360f4c5fb78d0"
    },
    "2405.10369": {
        "title": "Reinforcement learning",
        "authors": [
            "F. Wörgötter",
            "B. Porr"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "4ffb0130c2e19033a1696c32dac2239f702c8dc4"
    },
    "1906.02500": {
        "title": "Towards Interpretable Reinforcement Learning Using Attention Augmented Agents",
        "authors": [
            "A. Mott",
            "Daniel Zoran",
            "Mike Chrzanowski",
            "D. Wierstra",
            "Danilo Jimenez Rezende"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "a4a2d99d1c237d0818971ec9205e89128c57fb02"
    },
    "1906.02736": {
        "title": "DeepMDP: Learning Continuous Latent Space Models for Representation Learning",
        "authors": [
            "Carles Gelada",
            "Saurabh Kumar",
            "Jacob Buckman",
            "Ofir Nachum",
            "Marc G. Bellemare"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "188dac491f04c56e1eb7d7b33ac6aa0b87303232"
    },
    "1901.11530": {
        "title": "A Geometric Perspective on Optimal Representations for Reinforcement Learning",
        "authors": [
            "Marc G. Bellemare",
            "Will Dabney",
            "Robert Dadashi",
            "Adrien Ali Taïga",
            "P. S. Castro",
            "Nicolas Le Roux",
            "Dale Schuurmans",
            "Tor Lattimore",
            "Clare Lyle"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "b652fc6bac4d3ec0583212788be488c2e0a79012"
    },
    "1811.04551": {
        "title": "Learning Latent Dynamics for Planning from Pixels",
        "authors": [
            "Danijar Hafner",
            "T. Lillicrap",
            "Ian S. Fischer",
            "Ruben Villegas",
            "David R Ha",
            "Honglak Lee",
            "James Davidson"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "fea3e63c97c7292dc6fbcb3ffe7131eb54053986"
    },
    "1808.00177": {
        "title": "Learning dexterous in-hand manipulation",
        "authors": [
            "Marcin Andrychowicz",
            "Bowen Baker",
            "Maciek Chociej",
            "R. Józefowicz",
            "Bob McGrew",
            "J. Pachocki",
            "Arthur Petron",
            "Matthias Plappert",
            "Glenn Powell",
            "Alex Ray",
            "Jonas Schneider",
            "Szymon Sidor",
            "Joshua Tobin",
            "Peter Welinder",
            "Lilian Weng",
            "Wojciech Zaremba"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "d37a34c204a8beefcaef4dddddb7a90c16e973d4"
    },
    "1803.10122": {
        "title": "World Models",
        "authors": [
            "David R Ha",
            "J. Schmidhuber"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "ff332c21562c87cab5891d495b7d0956f2d9228b"
    },
    "1802.09477": {
        "title": "Addressing Function Approximation Error in Actor-Critic Methods",
        "authors": [
            "Scott Fujimoto",
            "H. V. Hoof",
            "D. Meger"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "4debb99c0c63bfaa97dd433bc2828e4dac81c48b"
    },
    "1802.01561": {
        "title": "IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures",
        "authors": [
            "L. Espeholt",
            "Hubert Soyer",
            "R. Munos",
            "K. Simonyan",
            "Volodymyr Mnih",
            "Tom Ward",
            "Yotam Doron",
            "Vlad Firoiu",
            "Tim Harley",
            "Iain Dunning",
            "S. Legg",
            "K. Kavukcuoglu"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "80196cdfcd0c6ce2953bf65a7f019971e2026386"
    },
    "1801.01290": {
        "title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor",
        "authors": [
            "Tuomas Haarnoja",
            "Aurick Zhou",
            "P. Abbeel",
            "S. Levine"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "811df72e210e20de99719539505da54762a11c6d"
    },
    "1707.06347": {
        "title": "Proximal Policy Optimization Algorithms",
        "authors": [
            "John Schulman",
            "Filip Wolski",
            "Prafulla Dhariwal",
            "Alec Radford",
            "Oleg Klimov"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b"
    },
    "1706.03762": {
        "title": "Attention is All you Need",
        "authors": [
            "Ashish Vaswani",
            "Noam M. Shazeer",
            "Niki Parmar",
            "Jakob Uszkoreit",
            "Llion Jones",
            "Aidan N. Gomez",
            "Lukasz Kaiser",
            "I. Polosukhin"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776"
    },
    "1703.01988": {
        "title": "Neural Episodic Control",
        "authors": [
            "Alexander Pritzel",
            "Benigno Uria",
            "Sriram Srinivasan",
            "A. Badia",
            "Oriol Vinyals",
            "Demis Hassabis",
            "Daan Wierstra",
            "Charles Blundell"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "37088dec26231bc5a4937054ebc862bb83a3db4d"
    },
    "1611.05397": {
        "title": "Reinforcement Learning with Unsupervised Auxiliary Tasks",
        "authors": [
            "Max Jaderberg",
            "Volodymyr Mnih",
            "Wojciech M. Czarnecki",
            "T. Schaul",
            "Joel Z. Leibo",
            "David Silver",
            "K. Kavukcuoglu"
        ],
        "submission_date": "2016",
        "SemanticScholarId": "d7bd6e3addd8bc8e2e154048300eea15f030ed33"
    },
    "1512.01693": {
        "title": "Deep Attention Recurrent Q-Network",
        "authors": [
            "Ivan Sorokin",
            "Alexey Seleznev",
            "Mikhail Pavlov",
            "A. Fedorov",
            "Anastasiia Ignateva"
        ],
        "submission_date": "2015",
        "SemanticScholarId": "4a63437aaee3267a5b427588adecb1c73a95b423"
    },
    "1509.02971": {
        "title": "Continuous control with deep reinforcement learning",
        "authors": [
            "T. Lillicrap",
            "Jonathan J. Hunt",
            "A. Pritzel",
            "N. Heess",
            "Tom Erez",
            "Yuval Tassa",
            "David Silver",
            "D. Wierstra"
        ],
        "submission_date": "2015",
        "SemanticScholarId": "024006d4c2a89f7acacc6e4438d156525b60a98f"
    },
    "1507.06527": {
        "title": "Deep Recurrent Q-Learning for Partially Observable MDPs",
        "authors": [
            "Matthew J. Hausknecht",
            "P. Stone"
        ],
        "submission_date": "2015",
        "SemanticScholarId": "f5f323e62acb75f785e00b4c90ace16f1690076f"
    },
    "1502.03044": {
        "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention",
        "authors": [
            "Ke Xu",
            "Jimmy Ba",
            "Ryan Kiros",
            "Kyunghyun Cho",
            "Aaron C. Courville",
            "R. Salakhutdinov",
            "R. Zemel",
            "Yoshua Bengio"
        ],
        "submission_date": "2015",
        "SemanticScholarId": "4d8f2d14af5991d4f0d050d22216825cac3157bd"
    },
    "1412.6980": {
        "title": "Adam: A Method for Stochastic Optimization",
        "authors": [
            "Diederik P. Kingma",
            "Jimmy Ba"
        ],
        "submission_date": "2014",
        "SemanticScholarId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8"
    },
    "1409.0473": {
        "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
        "authors": [
            "Dzmitry Bahdanau",
            "Kyunghyun Cho",
            "Yoshua Bengio"
        ],
        "submission_date": "2014",
        "SemanticScholarId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5"
    },
    "1407.5358": {
        "title": "Practical Kernel-Based Reinforcement Learning",
        "authors": [
            "André Barreto",
            "Doina Precup",
            "Joelle Pineau"
        ],
        "submission_date": "2014",
        "SemanticScholarId": "6b5e3887dcce35b467b565e51d20dc4007213c91"
    },
    "1407.3341": {
        "title": "Extreme State Aggregation beyond MDPs",
        "authors": [
            "Marcus Hutter"
        ],
        "submission_date": "2014",
        "SemanticScholarId": "7207dc8e9b4c54cce8847245a8148d74deff4930"
    },
    "1207.6076": {
        "title": "Equivalence of distance-based and RKHS-based statistics in hypothesis testing",
        "authors": [
            "D. Sejdinovic",
            "Bharath K. Sriperumbudur",
            "A. Gretton",
            "K. Fukumizu"
        ],
        "submission_date": "2012",
        "SemanticScholarId": "492a9f24c5202775f7e24300a2dab6136a04d476"
    },
    "1106.0676": {
        "title": "Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System",
        "authors": [
            "Michael Kearns",
            "D. Litman",
            "Satinder Singh",
            "M. Walker"
        ],
        "submission_date": "2011",
        "SemanticScholarId": "eb53b7c13156e3acacb47c1e51d93cefeabfaeb0"
    },
    "1207.4114": {
        "title": "Metrics for Finite Markov Decision Processes",
        "authors": [
            "N. Ferns",
            "P. Panangaden",
            "Doina Precup"
        ],
        "submission_date": "2004",
        "SemanticScholarId": "2c85356cd182c16e0a2e5c4a97112efbc1132cdf"
    },
    "1106.0665": {
        "title": "Infinite-Horizon Policy-Gradient Estimation",
        "authors": [
            "Jonathan Baxter",
            "P. Bartlett"
        ],
        "submission_date": "2001",
        "SemanticScholarId": "085fb3acabcbf80ef1bf47daec50d246475b072b"
    }
}