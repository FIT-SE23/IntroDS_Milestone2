{
    "elements": {
        "2211.03021_c5428fe9e3a9e1865a46802f85a28857": "Document Root 2211.03021",
        "2211.03021_4b09adc2daa8cae31186ee33d973da92": "1]",
        "2211.03021_e604f4348031a3aa7d7d89c9653bf105": "2]",
        "2211.03021_f7cca6f491db4dd9c61932be46d499df": "3]",
        "2211.03021_35dba5d75538a9bbe0b4da4422759a0e": "[1]",
        "2211.03021_beb4dbf9af069aa2df7b147229965085": "[2]",
        "2211.03021_f2577a6fc29b900fe7d4c6321346be48": "[3]",
        "2211.03021_e353dbe42c8654f33588d4da0b517469": "Abstract",
        "2211.03021_5084eb7dbf77f0f825541a9e1d9d8b71": "Graph neural networks (GNNs) have received great attention due to their success in various graph-related learning tasks",
        "2211.03021_9cd8b34bca0b48fed870c0d4dc7fc539": "Several GNN frameworks have then been developed for fast and easy implementation of GNN models",
        "2211.03021_d83837aecd64411fa7f89bdea4a4a190": "Despite their popularity, they are not well documented, and their implementations and system performance have not been well understood",
        "2211.03021_33028fac7375318390578bf83fbe0b52": "In particular, unlike the traditional GNNs that are trained based on the entire graph in a",
        "2211.03021_f5cf440bd79d728ab15493766fa751c7": "manner, recent GNNs have been developed with different graph sampling techniques for",
        "2211.03021_27c615b0c11b4b71fd277e0b4ce2bcca": "training of GNNs on large graphs",
        "2211.03021_e6b31197902eeecca8f6763ecc7f95cb": "While they improve the scalability, their training times still depend on the implementations in the frameworks as sampling and its associated operations can introduce non-negligible overhead and computational cost",
        "2211.03021_b86ffe4d0ce6f39ef00e0cad6c55535b": "In addition, it is unknown how much the frameworks are `eco-friendly' from a green computing perspective",
        "2211.03021_7d05dc3caae81676f566d650df90214f": "In this paper, we provide an in-depth study of two mainstream GNN frameworks along with three state-of-the-art GNNs to analyze their performance in terms of runtime and power/energy consumption",
        "2211.03021_358485ec638802e2109e11af2fc10ac9": "We conduct extensive benchmark experiments at several different levels and present detailed analysis results and observations, which could be helpful for further improvement and optimization.",
        "2211.03021_0b79795d3efc95b9976c7c5b933afce2": "Introduction",
        "2211.03021_8e70f5b0672367049ffa4ce4b26a8c76": "Graphs are everywhere, from social networks to transportation networks to biological networks",
        "2211.03021_6fb5ab51424f5086a90d9887fc645594": "It is of vital importance to mining graph-structured data",
        "2211.03021_3367bbb67d7e3887b703c5d3fdc0b471": "\\cite{li2021efficient,li2021estimating}",
        "2211.03021_f7a047a6591a94e227dd79a78f04ae91": "and learning on graphs",
        "2211.03021_9fb183392ea6214f787b6372a5f317fa": "\\cite{hamilton2020graph,ma2021deep}",
        "2211.03021_650f2ce41cfbaa199a59c8d9f8c646dd": "since they contain rich underlying information and can be used for a wide range of applications",
        "2211.03021_e99b2637bd8444555fc724aa5064fceb": "In particular, graph neural networks (GNNs) have attracted a lot of attention in recent years",
        "2211.03021_f1d3b9204392ac06247e2080d1b3fda5": "Unlike the conventional machine learning (ML) algorithms, which assume data samples are independent and identically distributed, GNNs take graph-structured data as input for downstream tasks and capture the correlation between data samples (nodes in the graph) according to their connections (edges in the graph)",
        "2211.03021_227c52d774ceb22fce44e72f0e5d3aca": "GNNs have been shown to be effective for many tasks, such as representation learning, node classification, and link prediction",
        "2211.03021_adf90b0c953ac1131e2395ba00707341": "Early GNN studies mainly reply on general deep learning (DL) frameworks, such as TensorFlow",
        "2211.03021_875e3e18e1abb7ac608f034cbd5cb90f": "\\cite{tensorflow2015-whitepaper}",
        "2211.03021_de34be68a00813eac60e9944bf8ba042": "and PyTorch",
        "2211.03021_9adf76fb40f75b10e8b34c9e087c37ed": "\\cite{NEURIPS2019_9015}",
        "2211.03021_a750bcebff4f76995461838a0d6377d3": "It is, however, non-trivial to implement a GNN model using the DL frameworks",
        "2211.03021_a6803f4f3036200f653327bdd49d3b92": "While they are designed and optimized for regular yet often dense data, real-world graphs often exhibit irregularity and sparsity, thereby making them inefficient for GNNs",
        "2211.03021_8a420c1f2e962ae942d77ab89db330ab": "Thus motivated, several GNN frameworks have been developed to speed up the computation and to simplify GNN implementation",
        "2211.03021_0290a5424420eebf5a6eef184638a4ba": "The examples include Graph Nets",
        "2211.03021_9a0e5b74d282b1e7b0d0a530e9c161bb": "\\cite{battaglia2018relational}",
        "2211.03021_38f5789269f1016240e709754a8f03ac": ", Deep Graph Library (DGL)",
        "2211.03021_f353b17811d87cc67766d8685f883ae0": "\\cite{wang2019deep}",
        "2211.03021_1dac1006f913dab6bdc7917049e05cf3": ", PyTorch Geometric (PyG)",
        "2211.03021_307f43234013f04344a4513e4deddf2d": "\\cite{FeyLenssen2019}",
        "2211.03021_e028dcb95a2245e0a1cacfdc6b005513": ", StellarGraph",
        "2211.03021_3df29fa52095c85baaae3346eff7c935": "\\cite{StellarGraph}",
        "2211.03021_639cf81bf8cccd980ba47ad71930892c": ", Spektral",
        "2211.03021_a23eda00745b4f173521aad6630e8edd": "\\cite{grattarola2021graph}",
        "2211.03021_dc6c6a9e7a94e40294edd834af0a2d83": ", TF-Geometric",
        "2211.03021_3de5c6ff47c7d29489ff80a960845523": "\\cite{hu2021efficient}",
        "2211.03021_403762af7ababcc98149f2ab89da3c9c": ", and CogDL",
        "2211.03021_f35410abd78c00fa06b495b85a4741d4": "\\cite{cen2021cogdl}",
        "2211.03021_ea43997c63dd9192740784db04e786e2": "DGL and PyG are two most popular ones among them, thanks to their user-friendly designs, rich functionalities, and easy-to-follow tutorials",
        "2211.03021_4c8d90a5582371258399e6079f1a5aa9": "Inspired by NetworkX",
        "2211.03021_06c839c6f2960d3a1fdd0aabca50746d": "\\cite{hagberg2008exploring}",
        "2211.03021_ff5f1c3e124c3c2339184529f8bf5902": ", DGL uses a graph-centric programming abstraction, making it easy for NetworkX users to use",
        "2211.03021_12f75bce9db42e5b4fe2bb775caffd35": "It defines a `DGLGraph' object as its key data structure for computations with graph-structured data and GNN operations",
        "2211.03021_7eb372c789a73feb86c8abf3f623866b": "DGL also realizes the message passing operations of GNNs with generalized sparse-dense matrix multiplication (g-SpMM) and generalized sampled dense-dense matrix multiplication (g-SDDMM)",
        "2211.03021_a2147a6b8e3f7dd7403dd7bbf9766f86": "Furthermore, it develops highly tuned CPU and GPU kernels for GNN operations and supports a wide range of applications for general-purpose graph learning",
        "2211.03021_e5bec33b9b4185b760df6a1182ac8460": "In addition, PyG is an extension library of PyTorch for deep learning on graph-structured data",
        "2211.03021_c938a968e43b0d9b3e0defc2d204249e": "It provides a simple `MessagePassing' interface for the message passing operations based on a gather-and-scatter paradigm, which is built on top of its own PyTorch Scatter",
        "2211.03021_e63400e880002785e004a686d0b7f643": "and PyTorch Sparse",
        "2211.03021_f5b79bf7e3f91f3ce3ac550c8052fe07": "that provide dedicated kernels for relevant computations",
        "2211.03021_18fe1ad6b36a76a13803db98043827f0": "It also provides a large number of off-the-shelf examples along with a lot of commonly used benchmark datasets for users to easily use and test",
        "2211.03021_5224dc31328aa58e2fcc1497609beaaa": "Both DGL and PyG have been updated and optimized significantly compared with their initial versions",
        "2211.03021_6d3862009e9ae7469526a5cb8d7c4c17": "However, their current implementations and system performance are not well understood",
        "2211.03021_2cc3ab887298bcb5683dfba6d45351f1": "On the other hand, `",
        "2211.03021_5af5b5504d15a12969dcfa304369cec9": "' becomes an important factor in both industry and academia due to climate change",
        "2211.03021_44efa1d139e7b45c6442c1388749530d": "Energy and power consumption ought to be critical metrics in ML/DL since training advanced models are often energy and resource hungry",
        "2211.03021_2ca22b3025eb6b71bb7c905bb5770ded": "Early studies in ML/DL have, however, mainly focused on improving their model accuracy to achieve state-of-the-art performance",
        "2211.03021_0674fba73a2e6914ea9b1fc55130bb81": "Schwartz",
        "2211.03021_907f03ebf285e895e554fa304da132bc": "\\cite{schwartz2020green}",
        "2211.03021_40f87b890d5b5eba0402ed6570c11643": "recently urge researchers to provide not only the accuracy, but also the efficiency in terms of carbon emission, energy consumption, runtime, to name a few",
        "2211.03021_7a9e0da80b21fac483811f3a67f8cfd7": "Strubell",
        "2211.03021_7ccd56d909776a8a8ed408b6d0df6b28": "\\cite{strubell2019energy}",
        "2211.03021_d17252d35fca56991dfe195b0ee80294": "bring power and energy concerns in ML/DL research by estimating the financial and environmental costs of building well-trained state-of-the-art natural language processing models",
        "2211.03021_d03b5449cc4bb2c1aa849e528db2e29a": "There is then a movement, albeit slowly, in recent studies that take power and energy consumption into consideration",
        "2211.03021_7fc26465cbff91bd26c97587bdad4a9a": "Nonetheless, there is no prior work to quantify the power and energy consumption of GNN models and frameworks",
        "2211.03021_8468b7f0d2cdc0cac258314b3eaf3b39": "In this paper, we study the two mainstream GNN frameworks",
        "2211.03021_53e359796fa092d0a332586a2bfaee15": "DGL and PyG, by evaluating their efficiency in terms of runtime (not only at the level of each key function but also at the level of the entire model), and power and energy consumption.",
        "2211.03021_c30f557e933995157922f0d3cb41eea6": "We benchmark their performance via functional testing on each main component of GNNs and three state-of-the-art GNNs, namely GraphSAGE, ClusterGCN, and GraphSAINT, which adopt graph sampling for mini-batch training",
        "2211.03021_a000d128e67e97af172068dd8c2a0838": "We further provide case studies on different implementation strategies, GPU-based sampling, and full-batch training",
        "2211.03021_7ced64ffe254d256c878cbdeec7220f6": "We provide detailed and comprehensive analysis to fully understand their performance and find opportunities for further improvement and optimization",
        "2211.03021_1e9d505bcaf30f5f87e55c2b82d1a6a5": "We summarize our contributions as follows:",
        "2211.03021_a8f65dd93445b90d34246cc201862695": "List (itemize)",
        "2211.03021_7d74f3b92b19da5e606d737d339a9679": "Item",
        "2211.03021_2482bc346f782bcfbb8fbf30d9bcd675": "First, we present the results of functional testing on each key component of building a GNN model in DGL and PyG, including data loader, sampler, and graph convolutional layers",
        "2211.03021_c2fd96f78899968e6f99ccfdaf3a5f0d": "We find that DGL is more efficient for sampling and GNN operations, especially when it comes to large graphs.",
        "2211.03021_cf24dfc2f5d33cb292c78eae9cf7df1d": "Second, we evaluate the efficiency of sampling and GNN operations on different hardware devices (CPU vs",
        "2211.03021_6a9b7b984a144feabf280d98506ead83": "GPU).",
        "2211.03021_d24c35179da4ebd203fe13a4b7bf4c68": "Third, we provide runtime breakdown of three state-of-the-art GNNs in both frameworks",
        "2211.03021_7380b8132be89e220d18bb59a280b052": "Our results indicate that there is still a room for further improvement, especially for sampling and data movement.",
        "2211.03021_c380ea320f25650fafe24aa1f0ff71b1": "Finally, we quantify the power and energy consumption of GNN models and frameworks",
        "2211.03021_77971160750cc58286373b05b145f675": "To the best of our knowledge, we are the first to analyze the GNN performance from such a green computing perspective.",
        "2211.03021_f36791fd11b29f26e27f40a1e26281f8": "Background and Related Work",
        "2211.03021_845b7115e0330d4f411795d66e496287": "Graph Neural Networks",
        "2211.03021_9332f3c42a166c54b9ef02aba198d8f9": "GNNs have emerged as an effective means for learning on graph-structured data",
        "2211.03021_4832f15c36bd0a15569298f161dc2891": "They commonly rely on a `feature aggregation' mechanism, which can be written as",
        "2211.03021_24f2697edac238fe23ccb018d2d6d0ff": "\\begin{equation*}\n\\setlength{\\abovedisplayskip}{5pt}\n\\setlength{\\belowdisplayskip}{5pt}\n\\mathbf{H}^{(l+1)} = f(\\mathbf{G}\\mathbf{H}^{(l)}\\mathbf{W}^{(l)}),\n\\end{equation*}",
        "2211.03021_567904efe9e64d9faf3e41ef402cb568": "where",
        "2211.03021_8824595f458085fe3bf467c4228300fc": "$f(\\cdot)$",
        "2211.03021_3202add59b81b4193c2328e4baa6aef5": "is a non-linear activation function that is applied element-wise,",
        "2211.03021_ae44fa1818647ed39ba79b316ce5dd87": "$\\mathbf{G}$",
        "2211.03021_8d435b0bef873b4c408eb9906fb37c0d": "is a graph matrix representing the graph structure, e.g., the adjacency or (normalized) Laplacian marix of the input graph, and",
        "2211.03021_d3a1366eb0b568eee312aae85992390f": "$\\mathbf{H}^{(l)}$",
        "2211.03021_be5d5d37542d75f93a87094459f76678": "and",
        "2211.03021_c73e2b97fdb4557468f71e86ea5a3f47": "$\\mathbf{W}^{(l)}$",
        "2211.03021_6e0dc03ba7048d7c5261ce28fd4843d7": "are the node feature/embedding matrix and the weight matrix of neural networks at",
        "2211.03021_2f2322dff5bde89c37bcae4116fe20a8": "$l$",
        "2211.03021_f50d68c04e2f198ecaf1bfb0c4e99399": "-th layer, respectively",
        "2211.03021_5b585da8b5e066d87cc63146b5c5b3f7": "In other words, it is the neighborhood aggregation or message passing as each node in the graph updates its current feature vector by aggregating the feature vectors (messages) from its neighbors.",
        "2211.03021_ed80d9ae28635a63812baef07e99e7a3": "\\begin{figure}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat[Full-batch training]{%\n\t\t\\includegraphics[width=0.85\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/full}\n\t}\n\t\\vspace{-3mm}\n\t\\subfloat[Mini-batch training]{%\n\t\t\\includegraphics[width=0.85\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/minibatch}\n\t}\n\t\\hspace{0mm}\n\t\\caption{Two training methods for GNNs.}\n\t\\label{fig:gnn}\n\t\\vspace{-3mm}\n\\end{figure}",
        "2211.03021_b1b88d6c7d1cd566406f0a098b364aac": "Due to the feature aggregation mechanism or the interdependence of the nodes (samples), traditional GNNs such as GCN",
        "2211.03021_c26a01ff413fee81abe4b4508a2b7336": "\\cite{kipf2016semi}",
        "2211.03021_e388d623a584788d180ebe5f3a9fcd7a": "and GAT",
        "2211.03021_f8079f9661cf573bf16884b9c62880fc": "\\cite{velivckovic2017graph}",
        "2211.03021_05d04483099af05663a340e1150fc83c": "were trained using the",
        "2211.03021_26d82f9209039dc4e1762eb6bb37f79b": "gradient descent, as shown in Figure",
        "2211.03021_69dfdf4e6a7c8489262f9d8b9958c9b3": "(a)",
        "2211.03021_3dfbb59fdf079baacbd786283731e49d": "In other words, they require the entire graph and node features to be maintained in memory, leading to a",
        "2211.03021_9958d8fd4f3e70dca1bc895ba76e63e9": "issue with large graphs",
        "2211.03021_b1dc8b8ad21600449d70f088bea6f6bd": "To cope with the scalability issue, recent GNNs have then adopted `sampling' techniques to construct",
        "2211.03021_40f4339a355b53b90e959a66c3408df4": "based on the graph structure to train GNNs on large graphs, as mini-batch gradient descent is used for deep neural networks",
        "2211.03021_59d59e47fe9e4192e9c9eaa3d2f7479b": "See Figure",
        "2211.03021_fd272c0291ff9655ef1985be3a3129ad": "(b) for illustration",
        "2211.03021_adec714ae69bef54c5ee79cfcb41955d": "Hamilton",
        "2211.03021_9f6e3e68ab147beb1e9f3ae2f351e58a": "\\cite{hamilton2017inductive}",
        "2211.03021_3287a89998950552362e60fb9ec3781c": "proposed GraphSAGE, which is the first work that introduces the use of sampling in training GNNs to improve the scalability",
        "2211.03021_8f4e33d27c3c1d3ebc675022b5426d87": "It combines neighborhood sampling, which samples",
        "2211.03021_63bb9849783d01d91403bc9a5fea12a2": "$k$",
        "2211.03021_ecef756118e82364052aee683ad63373": "-hop neighbors with a fixed sampling size for feature aggregation, with mini-batch training",
        "2211.03021_0fe0c9cb414606a563a1defc07f2615a": "However, its resulting computation graph can be still explosive and thus cause an out-of-memory issue for large graphs",
        "2211.03021_d6b780fb63d10cc33f73c249fd223299": "To alleviate this issue, Chen",
        "2211.03021_ca5710b4cfd5827dce07f068feb5fdc7": "\\cite{chen2018fastgcn}",
        "2211.03021_a59709d6a52ae38527472301036f0691": "developed FastGCN, which samples a fixed number of nodes in each GNN layer independently based on a pre-computed probability distribution",
        "2211.03021_f785efa005ccf73df9f81c5b919e1960": "Nonetheless, it can generate isolated nodes, thereby leading to an accuracy drop",
        "2211.03021_1ae9a3e8c0b40b153320232957da6e8b": "Zou",
        "2211.03021_e8e1e1ebacd33e7c8cfcf9f131aadc3b": "\\cite{zou2019layer}",
        "2211.03021_03d6a618958376c8d9daf33efdedbc08": "proposed a layer-dependent importance sampling algorithm called LADIES to resolve the sparsity issue in FastGCN, while it introduces additional computational cost and non-negligible overhead in the sampling process.",
        "2211.03021_b831fe0e49ce594ca800bad34288eee8": "\\begin{table*}[t]\n\t\\renewcommand{\\arraystretch}{1.2}\n\t\\caption{Dataset statistics}\n\t\\label{table:dataset}\n\t\\centering\n\t\\scriptsize\n\t\\begin{adjustbox}{width=1.8\\columnwidth,center}\n\t\t\\begin{tabular}{|c|c|c|c|c|c|c|}\n\t\t\t\\hline\n\t\t\tDataset & Description & \\# Nodes & \\# Edges & \\# Features & \\# Classes & Train / Val / Test \\\\\n\t\t\t\\hline\n\t\t\t\\hline\n\t\t\tPPI & Protein-Protein Interactions & 14,755 & 225,270 & 50 & 121 & 0.66 / 0.12 / 0.22 \\\\\n\t\t\t\\hline\n\t\t\tFlickr & Images Sharing Common Properties & 89,250 & 899,756 & 500 & 7 & 0.50 / 0.25 / 0.25 \\\\\n\t\t\t\\hline\n\t\t\togbn-Arxiv & Citation Network of arXiv CS papers & 169,343 & 1,166,243 & 128 & 40 & 0.54 / 0.29 / 0.17 \\\\\n\t\t\t\\hline\n\t\t\tReddit & Online Communities & 232,965 & 114,615,892 & 602 & 41 & 0.66 / 0.10 / 0.24\\\\\t\n\t\t\t\\hline\n\t\t\tYelp & Businesses and Reviews & 716,847 & 13,954,819 & 300 & 100 & 0.75 / 0.10 / 0.15 \\\\\n\t\t\t\\hline\n\t\t\togbn-Products & Amazon Product Co-purchasing Network & 2,449,029 & 61,859,140 & 100 & 47 & 0.08 / 0.02 / 0.90 \\\\\n\t\t\t\\hline\n\t\t\\end{tabular}\n\t\\end{adjustbox}\n\\end{table*}",
        "2211.03021_6707973aa1b9e5bc8c4b8bf3cd30238c": "In addition, Chiang",
        "2211.03021_f3df70d66ae8f48bfc5f508e3cad7404": "\\cite{chiang2019cluster}",
        "2211.03021_8d3311216be48e6d94e007003874ee77": "proposed ClusterGCN, which partitions the input graph into many small clusters, some of which are then randomly selected to form a subgraph",
        "2211.03021_3d26188738a0ff7685b888dcdd44baa5": "or, more precisely, mini-batch, during training",
        "2211.03021_0aa4384d514169f6f97125744b144427": "It highly improves the scalability of GNNs, although it can lead to data imbalance and information loss issues",
        "2211.03021_244a92ecd257fa7f801076d688773ba0": "Zeng",
        "2211.03021_d43513ed8989f66d9f3d98fbb135641b": "\\cite{zeng2019graphsaint}",
        "2211.03021_0f3bc1d0aa77343af27224bae261efe0": "proposed GraphSAINT, which constructs training batches by sampling subgraphs of the input graph",
        "2211.03021_ba6740bc576dc6440d031eba07c4432e": "They leveraged graph sampling techniques, such as node sampling, edge sampling, and random walk-based sampling, to obtain subgraphs.",
        "2211.03021_aed402c3112b4749a9a98a72cbe9093d": "Related Work",
        "2211.03021_4c99dcf90dfebbf0cffca7b620c63df9": "There are a few GNN benchmark studies in the literature",
        "2211.03021_fb22c55847700d6af9529431bf1c876c": "Dwivedi",
        "2211.03021_e5b084037ca3dc99c03fb8799c259dc2": "\\cite{dwivedi2020benchmarking}",
        "2211.03021_5d5d9470bca07b69626fdcd94e1ce77d": "introduced a benchmark framework along with a set of medium-scale graph datasets for a large collection of GNN models",
        "2211.03021_c02a4ac39326b9acd8fd00f8b197011c": "They developed the benchmark framework on top of PyG and DGL and presented the results in accuracy and training time,",
        "2211.03021_6679b1b3897904b39182dde0baedabfc": "without any detailed component analysis",
        "2211.03021_5961b9c45e8cd870020433a870618cd8": "Duan",
        "2211.03021_2d5c25c224daae7d13526b51e463da80": "\\cite{duan2018benchmarking}",
        "2211.03021_4ac72f5dc74517f14157994e61d8effb": "used a greedy",
        "2211.03021_755e9f5b91e51e0a09b25e0717e6a2bb": "search method to tune up the performance of several GNN models and reported the resulting accuracy of each model and its corresponding time and space complexity",
        "2211.03021_96641e4a5a09e69b32236adbdfd55407": "Zhang",
        "2211.03021_8d03936c0c46ddaddadddd96e4aa1605": "\\cite{zhang2020architectural}",
        "2211.03021_d953ea0c8d095934a3a8e6538b8a3a68": "provided a detailed workload analysis on the",
        "2211.03021_85e27891a07f4d423536f93b8dfd7c02": "of GNNs",
        "2211.03021_b3cd9344dad3ff77b4fd532b70660aa2": "Lin",
        "2211.03021_a35a87779cd98067a9eaf468e1df7998": "\\cite{lin2022characterizing}",
        "2211.03021_837028340d3ffe2f1e11531bd9f6dcae": "focused on the",
        "2211.03021_5bca6886482da97289e2f24f1d41484e": "benchmark of three GNN models implemented in PyG",
        "2211.03021_51a1a4894aaf6b468d0b2a0a4e94dfe2": "The studies in",
        "2211.03021_950db817b7d319f5781786be60def56b": "\\cite{baruah2021gnnmark,mernyei2020wiki,hu2020open}",
        "2211.03021_e36c050923be8f4dc9079158e104bd88": "presented new datasets for GNN benchmarking",
        "2211.03021_a606dc818f8937082770e76478b527e3": "The work by Wu",
        "2211.03021_98c3a8af105e96b8cc7c0a6affe43810": "\\cite{wu2021performance}",
        "2211.03021_6417e9ab8b5868282aef35e917de13b0": "is most relevant to our work as it is also concerned about the performance analysis of DGL and PyG",
        "2211.03021_2ccaebdec8c8fa51b0f9917ea78ca32b": "It was, however, based only on five datasets of",
        "2211.03021_fca1d24b23c26ef233efe20d315aca5f": "graphs with six GNN models, which are mostly traditional ones",
        "2211.03021_74b1977d83f6c1a98afa83fe86b09808": "Three datasets are for `graph' classification as a downstream task",
        "2211.03021_a75af13a5090fd001fa7d2f3847650b3": "The smallest one has 600 graphs, each with about 30 nodes and 60 edges on average, while the largest one has 80K graphs, each with about 70 nodes and 500 edges on average",
        "2211.03021_82e3b2d406c54c3c6c3582953e60afc5": "The other datasets are two small graphs (the larger one has about 20K nodes and 40K edges) for `node' classification",
        "2211.03021_cb9df689075b30219e70339cfcb2ef48": "For this downstream task, they focused on the",
        "2211.03021_6ee861e92c503196e940e4fb3e8c57c3": "training, not to mention lack of any detailed component analysis",
        "2211.03021_776ca20239d8c78761d6dbe2194a26ec": "We can summarize the",
        "2211.03021_a245bf8b340e875db1185fa6b5ff584b": "between our work and the GNN benchmark literature as follows",
        "2211.03021_a4d58118da7e4cef36b4e86676c7cc9a": "First, we provide a detailed and comprehensive analysis of DGL and PyG not only at the level of the efficiency (total training time) but also at the level of the runtime of each key component of GNN models",
        "2211.03021_a277e986057991b4c1f5e872f479d762": "Second, our benchmark of the frameworks is done based on a wide range of graphs, having the largest one with about 2.4M nodes and 61M edges, and three representative GNNs that support mini-batch training for scalability",
        "2211.03021_161edd00e22d6e1c010cc2db2840be79": "Finally, we present the energy and power efficiency of GNN models and frameworks.",
        "2211.03021_2ba0c1d2f0f117d4512ef6170fe0e015": "Methodology",
        "2211.03021_2a7e92f24cb59b197ef714d418b21bb4": "GNN Models",
        "2211.03021_b6f7678a36ea20ce39288ccca98376bb": "To evaluate the performance of two popular GNN frameworks",
        "2211.03021_5ba047da70383d89fcf6936e4897c27e": "DGL",
        "2211.03021_2a18b0c38dec1b3854c36ab255ca76d7": "and PyG",
        "2211.03021_cbcc7909a4f5bfcc1c66d2518481862b": ", we first consider several convolutional layers, which are key components of GNNs",
        "2211.03021_05ae55bc484fbb804f91910d14e8ed1b": "We then consider three representative sampling-based GNNs, namely GraphSAGE",
        "2211.03021_64e977b3c0b9f1ec17738f2e146703db": ", ClusterGCN",
        "2211.03021_67fad61f3c3f74e49e13b8d4c103b96a": ", and GraphSAINT",
        "2211.03021_b0253b1c82b57aff108954fd2c1a6c3c": ", implemented in DGL and PyG.",
        "2211.03021_f1cb45f64cdd7b55480ba6aeecd7b797": "Datasets",
        "2211.03021_27d8a4f511d1767236cc0959283bb99f": "We focus on supervised node classification tasks in this work",
        "2211.03021_16ddaf53f8777105252c587bdd1d7537": "To this end, we consider six popular real-world graph datsets, each of whose description and statistics are provided in Table",
        "2211.03021_4ff2e716a7d06ce5274b4090b39abad3": "See",
        "2211.03021_016877d6d6414ded334b306f7bcfa44a": "\\cite{hu2020open}",
        "2211.03021_dc70937d8580a0a367baea6c6570cddf": "for more details on the datasets",
        "2211.03021_6fd805609bfc1fc1774993c0cd3a7ce8": "As for how to split each dataset for training, validation, and testing, we follow the common way in the GNN benchmark literature, which is to use `ï¬xed partitions' given by the original authors",
        "2211.03021_d96810696104897aab20781b63cfd161": "The details are reported in the `Train/Val/Test' column of Table",
        "2211.03021_5058f1af8388633f609cadb75a75dc9d": ".",
        "2211.03021_10fd5b0215404cbc83e5ad3aac139001": "Hardware and Software Configuration",
        "2211.03021_70741464f0efb9181851ffbb0b001f35": "For hardware, all experiments are conducted on a Linux server equipped with Dual Intel Xeon Silver 4114 CPUs @ 2.2GHz with 64GB RAM, and an NVIDIA Quadro RTX 8000 GPU with 48GB memory",
        "2211.03021_196d90b3756fc1392ca6a7355998eda7": "For software, we use Python 3.8, PyTorch v1.11.0, DGL v0.8.2, and PyG v2.0.4",
        "2211.03021_6b21bee3605ebff92c4e2c3a84d6ef6c": "All GNN models were implemented based on the official examples provided by DGL with PyTorch backend and PyG",
        "2211.03021_5f52184829a02731016df1209ca50624": "To match the implementations in both frameworks for a fair comparison, we set the same values of the hyperparameters of samplers, convolutional layers, and other components of GNN models as long as both frameworks provide the same functional APIs",
        "2211.03021_ca34b8031179f5fa79c24520de8aea9c": "We use the default settings as provided by the frameworks otherwise",
        "2211.03021_25aab46f7e7258c06f95395d07a4c0cf": "Our code is available on GitHub.",
        "2211.03021_65053fb68cac0a0f658d89a4036db919": "Our main focus in this work is to evaluate the efficiency of the GNN frameworks in runtime and energy/power consumption",
        "2211.03021_b2de331b673da5db824bef969a217880": "Note that we here do not consider the accuracy of each GNN model as there is no clear difference between the frameworks",
        "2211.03021_6756e7ce71423c466c2125875e51b4cd": "\\cite{wang2019deep, FeyLenssen2019, wu2021performance}",
        "2211.03021_38d40364021fee8dc7efa082d04e3649": "We use",
        "2211.03021_7c642cae67f3ab0ceadfe47ed4b6fdec": "to measure the runtime of each key function of GNNs and that of each GNN model along with its breakdown results",
        "2211.03021_f00610e9f900215fe33a856189f5f655": "In addition, we use",
        "2211.03021_01197e049beff11d6a4647c15f0ae9e8": "to measure power and energy consumption, which is a Python package for tracking carbon emissions produced by algorithms and programs.",
        "2211.03021_2bd6f27c1c3e0660b344526e731ad482": "We use the sampling interval of 0.1 seconds in this tool instead of its default setting, which is 15 seconds",
        "2211.03021_795808168a9311d58e913b54150bd2c3": "Considering the fact that it is a software tool, we admit possible discrepancies between measured values and actual ones",
        "2211.03021_c152e5a339f04632b85cf089a08e2bf3": "Nonetheless, we emphasize that",
        "2211.03021_6fcaaae7eb53cec82cb888823834d8ee": "comparisons remain meaningful and informative regardless, not to mention that we are the first work to evaluate the power and energy consumption of GNNs and GNN frameworks.",
        "2211.03021_d1fb541327a140ceab489f7029524517": "Results and Discussion",
        "2211.03021_619650193cd1eb96d41e0f3cc9cb7d54": "In this section, we provide and discuss the detailed benchmark results on the efficiency of DGL and PyG.",
        "2211.03021_815ced4cd160150268883a86cc50e7ce": "\\begin{figure}[t]\n\t\\vspace{0mm}\n\t\\centering\n\t\\includegraphics[width=0.95\\linewidth, trim=2mm 1mm 2mm 1mm, clip]{fig/workflow}\n\t\\vspace{0mm}\n\t\\caption{Workflow of sampling-based GNN training.}\n\t\\vspace{0mm}\n\t\\label{fig:workflow}\n\\end{figure}",
        "2211.03021_a4abba138ae71c9c1f7a7468946c8501": "Functional Testing",
        "2211.03021_666df2f48cd16f38212c093999248769": "Figure",
        "2211.03021_310b249daa0d0256e387618889d93593": "illustrates the end-to-end workflow of training a sampling-based GNN with mini-batch training",
        "2211.03021_4e1063b75720ffb86e36a97dd1f8df32": "It can be divided into the following three main processes: data loading, graph sampling, and model training",
        "2211.03021_f7b93580c140d5b208bfb1f2ba1ec7a5": "We thus conduct `functional testing' on each main process to evaluate the performance of DGL and PyG",
        "2211.03021_9ab018720b308e65172598ce1200be5c": "Note that for the entire training process, data loading is a one-time operation while the other two process, i.e., graph sampling and model training, are performed repeatedly and periodically for each training batch",
        "2211.03021_ae4dabe1b18ccec73ae609a2957f160c": "Note also that we do not consider the inference of each model in this paper",
        "2211.03021_dc78dd3567adfa9965a1cabe32d76ae0": "We repeat the experiments for each functional test for ten times and report the average values",
        "2211.03021_737a47b1d4f7bec6970e24a5953e602e": "In addition, for the functional tests, we do not include the power/energy consumption results since the runtime of some functions are too small, e.g., a few milliseconds, which can lead to incorrect power/energy measurement.",
        "2211.03021_ac959e863067f33d7769e68f8d739cbc": "We first compare the data loader of DGL and PyG, which is used to load the input graph and its associated node features from storage and to create a library-specific graph object for the next process of graph sampling and model training",
        "2211.03021_7619b55a97370de76c33462acf8fd31d": "We present the runtime results in Figure",
        "2211.03021_a3a230d3e4fc7d1544e4b3df99bf8804": "There are two main reasons",
        "2211.03021_e528c9a653c2af2e0dd7745433f2215f": "First, while both frameworks provide an easy-to-use interface to create and process the datasets, PyG integrates more datasets (around 80) into its library as compared with DGL (around 40)",
        "2211.03021_914a4067440107d8d268a07806957d57": "Specifically, five out of six datasets used in this work can be directly accessed from PyG's `dataset' module while three datasets are already included in DGL",
        "2211.03021_87917ad1c768335353f026afeaee78d9": "Note that, for the datasets that are not included in the libraries, we follow the official instructions to process the raw datasets and to create their corresponding graph objects",
        "2211.03021_50e15dfded1c38252f054ca7f658f93f": "Second, DGL uses a graph-centric programming abstraction, which makes rich information of the input graph accessible and enables full control of manipulating the input graph",
        "2211.03021_17f23c4cbd7bb47296325380e53f7a3e": "As a consequence, the workload of creating a `DGLGraph' object is relatively higher than its counterpart in PyG.",
        "2211.03021_e85acd6de3c28a37abd7a16c7b8f7076": "\\begin{figure}[t]\n\t\\vspace{0mm}\n\t\\centering\n\t\\includegraphics[width=0.7\\linewidth, trim=2mm 1mm 2mm 1mm, clip]{fig/loader}\n\t\\vspace{0mm}\n\t\\caption{Runtime of data loader.}\n\t\\vspace{0mm}\n\t\\label{fig:loader}\n\t\\vspace{-3mm}\n\\end{figure}",
        "2211.03021_37fa18e12b5edb5ee8494bde422ef768": "\\begin{figure}[t]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat[Neighborhood sampler]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/neighbor-sampler}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[GraphSAINT sampler]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/saint-sampler}\n\t}\n\t\\vspace{0mm}\n\t\t\\subfloat[ClusterGCN sampler: METIS]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/cluster-sampler-METIS}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[ClusterGCN sampler: Combining]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/cluster-sampler}\n\t}\n\t\\vspace{0mm}\n\t\\caption{Runtime comparison of graph samplers. Note that the range of y-axis is different across different figures.}\n\t\\label{fig:sampler}\n\t\\vspace{-3mm}\n\\end{figure}",
        "2211.03021_5e7b512ddd497549691f23c4884c0520": "\\begin{figure*}[t]\n\t\\vspace{0mm}\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat[GCNConv-CPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/GCNConv-CPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[GCNConv-GPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/GCNConv-GPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[GCN2Conv-CPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/GCN2Conv-CPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[GCN2Conv-GPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/GCN2Conv-GPU}\n\t}\n\t\\vspace{-3mm}\n\t\\subfloat[GATConv-CPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/GATConv-CPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[GATConv-GPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/GATConv-GPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[GATv2Conv-CPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/GATv2Conv-CPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[GATv2Conv-GPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/GATv2Conv-GPU}\n\t}\n\t\\vspace{-3mm}\n\t\\subfloat[SAGEConv-CPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/SAGEConv-CPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[SAGEConv-GPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/SAGEConv-GPU}\n\t}\n\t\\hspace{0mm}\n\t\\centering\n\t\\subfloat[ChebConv-CPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/ChebConv-CPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[ChebConv-GPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/ChebConv-GPU}\n\t}\n\t\\vspace{-3mm}\n\t\\centering\n\t\\subfloat[TAGConv-CPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/TAGConv-CPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[TAGConv-GPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/TAGConv-GPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[SGConv-CPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/SGConv-CPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[SGConv-GPU]{%\n\t\t\\includegraphics[width=0.23\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/SGConv-GPU}\n\t}\n\t\\vspace{0mm}\n\t\\caption{Runtime of eight Conv layers. Note that the range of y-axis is different for CPU and GPU cases.}\n\t\\label{fig:Conv}\n\t\\vspace{-3mm}\n\\end{figure*}",
        "2211.03021_07de7fdbe5132dbf59e6990ef4bb23f5": "We then compare the performance of three different graph samplers provided by DGL and PyG, namely neighborhood sampler in GraphSAGE",
        "2211.03021_12d9ecf2b08e74350bf8800ab842da3c": ", graph clustering-based sampler in ClusterGCN",
        "2211.03021_0be5a6a17bc113c44d1e1ce169ef0bb7": ", and random walk-based sampler in GraphSAINT",
        "2211.03021_1d64937bcb3f63374560c99ad5e8547d": "For GraphSAGE sampler, we follow the settings in",
        "2211.03021_9a5c76a8940dbfaee9a7853a01fa2c25": ", which sample 25 and 10 neighbors per node in its first-hop and second-hop neighborhoods, respectively, with a batch size of 512",
        "2211.03021_43621416afcf8f3d1973e6c3808d53fa": "Note that each mini-batch is composed of 512 subgraphs",
        "2211.03021_020a83d3a2fcfd477dbed7d1e9809856": "For ClusterCGN sampler, there are two steps, which are (1) graph partitioning with METIS algorithm and (2) cluster aggregation",
        "2211.03021_3133fff3b490705f8d5a17913a413994": "The former partitions the input graph into a given number of small clusters with METIS algorithm, while the latter is to randomly select a few of them to form a subgraph for a training batch",
        "2211.03021_385ef398e4362fc470ab38a144d3684b": "Note that the former is done only once, but the latter is repeated to obtain different mini-batches",
        "2211.03021_05ff9aba6e83039a8262216030d09c9a": "In this experiment, we partition the input graph into 2000 clusters and combine 50 of them for each mini-batch",
        "2211.03021_8c3fb529cf3a87be02570734ec9491f9": "For GraphSAINT sampler, we use the random walk sampling method with 3000 roots and a walk length of two steps to construct subgraphs from the input graph for mini-batch training",
        "2211.03021_da42bc70faadfe38412caa8753861dd1": "While there are two other sampling methods, namely node sampling and edge sampling, in GraphSAINT, we here do not consider them as they are shown to be inferior to the random walk sampling",
        "2211.03021_964116f94208ea4352befdb4f8ab4d9d": "We measure the runtime of each sampler for one training epoch, i.e., one pass over the entire graph, and report the results in Figure",
        "2211.03021_bfcbf03e88868f168023494e70e8af38": "We observe that DGL implements its samplers in C++ with OpenMP, thus leading to superior performance to the ones of PyG, which are developed in Python",
        "2211.03021_6ea59fd697117a13eca1a3b422d039a0": "In addition, although the choices of hyperparameters can affect the sampling performance, GraphSAINT sampler is generally faster than GraphSAGE's neighborhood sampler and ClusterGCN sampler",
        "2211.03021_855b1d43a97a2fc6280da09d0059e107": "It is also worth noting that the neighborhood sampler can lead to a very large computational graph for each node, while the ClusterGCN sampler can lead to information loss and data imbalance",
        "2211.03021_3ea84540056d9160c4f1a0e5859e5a72": "Thus, we expect that the GraphSAINT sampler is a preferable choice in practice",
        "2211.03021_6fe2b6e52294cdb63994eedec3b85213": "Furthermore, we observe that PyG requires data format conversion to the compressed sparse column (CSC) format, e.g., if it was in the compressed sparse row (CSR) format, which turns out to be quite slow on large datasets",
        "2211.03021_d9b8c5153b59279bb0c6f2d90f2a21db": "Finally, while all three samplers in both DGL and PyG run on CPU, DGL also provides GPU support and CUDA-Unified Virtual Addressing (UVA) support for GraphSAGE, but not for other GNN models",
        "2211.03021_6592d7bed12277a1ea7e290a129c268b": "We shall discuss them in Section",
        "2211.03021_6d5a0b979e66ef10b7dfc2797488e28f": "A convolutional (Conv) layer is a key and dominant component of GNNs, and its runtime performance can often reflect the overall performance",
        "2211.03021_8eb9b503b1fb3be2228390ad13a0e0b9": "We thus conduct functional testing on a collection of Conv layers available in DGL and PyG",
        "2211.03021_1286f28ae142c3ea73c5050d4e800a0b": "Both frameworks provide an `nn' module that contains the implementations of popular Conv layers",
        "2211.03021_f2877483129860bbc14cbc1b4d795429": "We notice that PyG covers more than 50 Conv layers and DGL has about 30 of them",
        "2211.03021_0ae28ffdc2017da7d6522410e2ea71b9": "We here select eight commonly used Conv layers for functional testing",
        "2211.03021_e9d2a28c2dc93686ab0fe044a1b2ac09": "They are GCNConv",
        "2211.03021_13e615404de8de5610b06411675bb145": ", GCN2Conv",
        "2211.03021_f1740c9dd0b3463434ba0cff27346f5b": "\\cite{chen2020simple}",
        "2211.03021_23d1b1313fe03a235893191d950ee88b": ", ChebConv",
        "2211.03021_7c9271904682de5d3fab1b71c0b4ec30": "\\cite{defferrard2016convolutional}",
        "2211.03021_984d8513f33d34aec10aa658d11cd1f9": ", SAGEConv",
        "2211.03021_99354e4f84fdfd08ed3b7f261b09008f": ", GATConv",
        "2211.03021_c582a2719ef9ce7e36285912d02b9542": ", GATv2Conv",
        "2211.03021_76f9884d8476702b59cc7b5d2e3ae072": "\\cite{brody2021attentive}",
        "2211.03021_5555c7b4eb94b0c5cdb7dbd1dd7a07ae": ", TAGConv",
        "2211.03021_207ff281c169f225c8850602e2345cc8": "\\cite{du2017topology}",
        "2211.03021_3966cdb3be6447b98de358b400fd0f17": ", and SGConv",
        "2211.03021_e4c885361583ebc976a0e1a8e6b57257": "\\cite{wu2019simplifying}",
        "2211.03021_b4b3aad5fd9910750019ee22a3141632": "\\begin{figure}[t]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat[DGL-CPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsage-breakdown-DGL-CPU}\n\t}\n\t\\vspace{0mm}\n\t\\subfloat[DGL-CPUGPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsage-breakdown-DGL-CPUGPU}\n\t}\n\t\\hspace{1mm}\n\t\\subfloat[PyG-CPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsage-breakdown-PyG-CPU}\n\t}\n\t\\vspace{0mm}\n\t\\subfloat[PyG-CPUGPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsage-breakdown-PyG-CPUGPU}\n\t}\n\t\\vspace{0mm}\n\t\\caption{Runtime breakdown of GraphSAGE.}\n\t\\label{fig:sage-breakdown}\n\t\\vspace{-2mm}\n\\end{figure}",
        "2211.03021_1a2b3a0ad2bd29435ab9aadeda141c90": "We measure the runtime of executing each Conv layer on CPU and GPU",
        "2211.03021_cfc7f40ff7d9c89beee30cd680402b9b": "In other words, the reported runtime is equivalent to the time of running",
        "2211.03021_df399e60be33e291dbfebc47abd35226": "over a single Conv layer with the entire input graph",
        "2211.03021_ec6fd7a230c80e23389e797b88f12f63": "We manually set the hyperparameters to be the same across the frameworks for each Conv layer",
        "2211.03021_5e4fef298ce9373d973b1563f7729fd0": "The output dimension is fixed to be 256 for all test cases",
        "2211.03021_b988aca718bd8b90be4a372f23275124": "The results are presented in Figure",
        "2211.03021_c9dd80dca94971da74839fc012f5bafd": "The main reason for the performance on CPU is that DGL adopts an improved CPU message passing kernel developed by",
        "2211.03021_c71b548b902d4d36a42f7ce7f6b87388": "\\cite{md2021distgnn}",
        "2211.03021_4bb5cf1e5a764df9c109e66cff4a85de": "to boost the performance, while PyG relies on the CPU kernels included in its own PyTorch Sparse and PyTorch Scatter, where some `scatter' operations are not well optimized on CPU",
        "2211.03021_dfe4a1d6c193fa193119f58a0176fb44": "As for the performance on GPU, it is worth noting that our observation does not conflict but match with the observation in",
        "2211.03021_27120747d5fe9364300b4d89a2c172e3": ", which shows that PyG is more efficient than DGL, yet for small graphs",
        "2211.03021_51301c3f66993dd10f9f200d8ac90934": "Our observation also confirms the claim in",
        "2211.03021_86ca71ffe69b74511c150f4945f5a107": "Although DGL is a bit slower on small graphs due to its framework overhead, it is generally more efficient than PyG, especially on large graphs, thanks to its highly tuned kernels",
        "2211.03021_da11c184592dbe881cc44c1dba4fc014": "We also find that SAGEConv is relatively computationally cheaper than the other Conv layers, due to its simple aggregation operation",
        "2211.03021_aa3d08271aa5220efaf32b181465f185": "In addition, we observe that both frameworks provide",
        "2211.03021_ebc676a1155d0224ee7bc7a1dd83d28f": "kernels to improve their efficiency and scalability, where two separate message-passing and aggregation operations are merged as a single message aggregation operation",
        "2211.03021_4f4c4f9a3dd37de32d3ce660e3a0b459": "DGL uses `g.update",
        "2211.03021_970419e617205d28068d5bff787e4267": "all()' function to invoke its g-SpMM and g-SDDMM kernels, while PyG simply calls `matmul()' function in PyTorch Sparse",
        "2211.03021_7e1aefa64333da72ce353953c7d40564": "It is worth noting that PyG does not provide such fused kernel support for ChebConv, GATConv, and GATv2Conv layers",
        "2211.03021_fee133addc6ea5841fda749901301544": "As a result, all three layers of PyG suffer from an out-of-memory issue on large graphs.",
        "2211.03021_2cd0fa94e78616d0491115720db6c8ed": "\\begin{figure}[t]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsage-total-1}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsage-total-2}\n\t}\n\t\\vspace{-2mm}\n\t\\caption{Total runtime of GraphSAGE.}\n\t\\label{fig:sage-runtime}\n\t\\vspace{-3mm}\n\\end{figure}",
        "2211.03021_a85859a7bebf9cb0ff0caa8f0b83a4ae": "\\begin{figure}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsage-power-1}\n\t}\n\t\\vspace{0mm}\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsage-power-2}\n\t}\n\t\\vspace{-2mm}\n\t\\caption{Average power consumption of GraphSAGE.}\n\t\\label{fig:sage-power}\n\t\\vspace{-2mm}\n\\end{figure}",
        "2211.03021_23e932a946f6a6cfd121e08a60022489": "\\begin{figure}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsage-energy-1}\n\t}\n\t\\vspace{0mm}\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsage-energy-2}\n\t}\n\t\\vspace{-2mm}\n\t\\caption{Energy consumption of GraphSAGE.}\n\t\\label{fig:sage-energy}\n\t\\vspace{-3mm}\n\\end{figure}",
        "2211.03021_c1fe46878983ce12c96f6378be5b57aa": "Performance Evaluation of GNNs",
        "2211.03021_df0c3ce3ed49e52303ea23220b6ad1a1": "We evaluate three representative sampling-based GNNs, namely GraphSAGE, ClusterGCN, and GraphSAINT on CPU and GPU separately",
        "2211.03021_6f79697a705597550943bdf63e06b1d8": "We use `DGL-CPU' and `PyG-CPU' to indicate when both sampling and training are done on CPU and use `DGL-CPUGPU' and `PyG-CPUGPU' to indicate when sampling is done on CPU while training is done on GPU",
        "2211.03021_bbdea3feac2d8635564599f636589cbb": "We present their runtime breakdown, total runtime, average power consumption, and energy consumption in Figures",
        "2211.03021_f0089bf7f30acda55571fc46fc62e1f3": "Note that, for all three GNNs, we use the same hyperparameters of their samplers as used in the above functional testing",
        "2211.03021_c2e1dd7e8522a6c6b3f88320934103d5": "We use two convolutional layers for all three models and the hyperparameters of each GNN model are set to be the same across DGL and PyG for a fair comparison",
        "2211.03021_43eb6140587a1c1d3d05687eeb301964": "The reported results are based on the models trained by 10 epochs",
        "2211.03021_cef76529265c164053132cf47ceda453": "We repeated the same experiments multiple times and observed more or less the same results.",
        "2211.03021_60e0436c370e19ade51200511f595556": "\\begin{figure}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat[DGL-CPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/clustergcn-breakdown-DGL-CPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[DGL-CPUGPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/clustergcn-breakdown-DGL-CPUGPU}\n\t}\n\t\\vspace{-2mm}\n\t\\subfloat[PyG-CPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/clustergcn-breakdown-PyG-CPU}\n\t}\n\t\\vspace{0mm}\n\t\\subfloat[PyG-CPUGPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/clustergcn-breakdown-PyG-CPUGPU}\n\t}\n\t\\vspace{0mm}\n\t\\caption{Runtime breakdown of ClusterGCN.}\n\t\\label{fig:cluster-breakdown}\n\t\\vspace{-4mm}\n\\end{figure}",
        "2211.03021_e934bebd88793f91786c79af456b2e96": "\\begin{figure}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/clustergcn-total-1}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/clustergcn-total-2}\n\t}\n\t\\vspace{0mm}\n\t\\caption{Total runtime of ClusterGCN.}\n\t\\label{fig:clustergcn-runtime}\n\t\\vspace{-4mm}\n\\end{figure}",
        "2211.03021_31e1b1411169dadf88e1627258d1771d": "\\begin{figure}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/clustergcn-power-1}\n\t}\n\t\\vspace{0mm}\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/clustergcn-power-2}\n\t}\n\t\\vspace{0mm}\n\t\\caption{Average power consumption of ClusterGCN.}\n\t\\label{fig:cluster-power}\n\t\\vspace{-4mm}\n\\end{figure}",
        "2211.03021_c6b86eedb66581eeb379c3ad17761363": "\\begin{figure}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/clustergcn-energy-1}\n\t}\n\t\\vspace{0mm}\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/clustergcn-energy-2}\n\t}\n\t\\vspace{0mm}\n\t\\caption{Energy consumption of ClusterGCN.}\n\t\\label{fig:cluster-energy}\n\t\\vspace{-4mm}\n\\end{figure}",
        "2211.03021_3395936dbb4850fb7eaf7af44fce8e1b": "\\begin{figure}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat[DGL-CPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsaint-breakdown-DGL-CPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[DGL-CPUGPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsaint-breakdown-DGL-CPUGPU}\n\t}\n\t\\vspace{-2mm}\n\t\\subfloat[PyG-CPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsaint-breakdown-PyG-CPU}\n\t}\n\t\\vspace{0mm}\n\t\\subfloat[PyG-CPUGPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsaint-breakdown-PyG-CPUGPU}\n\t}\n\t\\vspace{0mm}\n\t\\caption{Runtime breakdown of GraphSAINT.}\n\t\\label{fig:saint-breakdown}\n\t\\vspace{-3.5mm}\n\\end{figure}",
        "2211.03021_110b4d45fec92b22bfd3a1fb8e2b0912": "\\begin{figure}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsaint-total-1}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsaint-total-2}\n\t}\n\t\\vspace{0mm}\n\t\\caption{Total runtime of GraphSAINT.}\n\t\\label{fig:saint-runtime}\n\t\\vspace{-4mm}\n\\end{figure}",
        "2211.03021_033945a071877c0115d3b923aa349705": "\\begin{figure}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsaint-power-1}\n\t}\n\t\\vspace{0mm}\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsaint-power-2}\n\t}\n\t\\vspace{0mm}\n\t\\caption{Average power consumption of GraphSAINT.}\n\t\\label{fig:saint-power}\n\t\\vspace{-4mm}\n\\end{figure}",
        "2211.03021_355a997683718a975a162ee348533ac6": "\\begin{figure}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsaint-energy-1}\n\t}\n\t\\vspace{0mm}\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsaint-energy-2}\n\t}\n\t\\vspace{0mm}\n\t\\caption{Energy consumption of GraphSAINT.}\n\t\\label{fig:saint-energy}\n\t\\vspace{-4mm}\n\\end{figure}",
        "2211.03021_1071f01918a5d64a129a0b44e5ea7af4": "As shown in Figure",
        "2211.03021_f9427d7eb326dd2439c05ccb6cfbc321": ", Figure",
        "2211.03021_2c682d02b99d54677aae02f840770ff5": ", and Figure",
        "2211.03021_f04bcef90fd94413879e0b342a6d18db": ", we break the runtime of each GNN into four parts, which are data loading, sampling, data movement, and model training",
        "2211.03021_315482e7a2f74141c836ff8ac01a1f32": "Data loading is done by `data loader' to load the input graph and its associated node features from storage to CPU memory",
        "2211.03021_d4749652d0da51273fab9c2dd221cf85": "Sampling is done by `sampler' to extract subgraphs and fetch the node features of the sampled subgraphs from the entire feature matrix for mini-batch training",
        "2211.03021_7df006a4c9469890e321c3a55efdc658": "Data movement is to copy the initial weight matrices of a GNN model, each subgraph matrix, and its corresponding node features from CPU to GPU",
        "2211.03021_ffef077d4a7eb8ba0099784ad2b08518": "Note that there is no data movement (from CPU to GPU) for DGL-CPU and PyG-CPU",
        "2211.03021_bbf91eb9515e8321870fde81e03abc91": "Model training includes forward propagation, backward propagation, and update of model weights",
        "2211.03021_8330935f123ab2dc8a2563351489f477": "Note that as the number of training epochs increases, the fraction of data loading in total runtime will decrease since it is a one-time operation",
        "2211.03021_94e38bfababdd76a86be9ee5347087e9": "However, sampling, data movement, and model training are performed repeatedly for different mini-batches.",
        "2211.03021_71a91d9fa3f504748843246b22be9679": "This observation indicates that there is a need to optimize sampling and its associated operations",
        "2211.03021_f69daac5240c491c77de9adfb9fc0f1f": "In particular, for PyG, its CPU kernel could be improved for not only sampling but also model training on CPU",
        "2211.03021_e6f221c64eb5cd231097150ea52c7a81": "In addition, we observe that data movement can also take a large portion of total runtime in both frameworks",
        "2211.03021_5345eda2259ccc924b894ee3cb8df481": "As shall be shown in Section",
        "2211.03021_bccc0bf680ce33e8b0b052f347544291": ", data pre-loading in the frameworks can be used to mitigate this issue.",
        "2211.03021_ba08a1d462fdb7ef16abfcd41def233e": "We observe that PyG is more efficient than DGL for small graphs when CPU is used for sampling and GPU is used for training, while DGL is generally more efficient for the other cases",
        "2211.03021_0746f1c032b38fc18d7d5b0623d91cc1": "In particular, PyG-CPUGPU is generally more efficient than DGL-CPUGPU for GraphSAINT",
        "2211.03021_4f588d77195a1b3e1bfe3325aa79ebca": "This behavior can be explained as follows",
        "2211.03021_53a2232bf71302c1727a679838d3a2ac": "With mini-batch training, a GNN model is trained based on sampled subgraphs, which are much smaller than the input graph",
        "2211.03021_adf7584dcd98c111fcc477e35c7a5945": "We observe that each sampled subgraph (corresponding to a mini-batch) by GraphSAINT sampler is relatively smaller than the ones by GraphSAGE's neighborhood sampler and ClusterGCN sampler",
        "2211.03021_140e2bb0963ded0b5364c15057655bf5": "Here the one with GraphSAGE's neighborhood sampler has multiple subgraphs for a mini-batch",
        "2211.03021_5dea455831cde8944bd4853844504783": "Also, recall that the performance gap of the GraphSAINT sampler between DGL and PyG is insignificant, as shown in Figure",
        "2211.03021_ac6b9dfb908763141775d97060d44a77": "Since PyG is more efficient in model training with small graphs, PyG becomes more efficient even for medium-size graphs with GraphSAINT, as shown in Figure",
        "2211.03021_689c541b3e85ffa6c36e3cb24fdbe662": "In addition, we find that there is no clear winner between DGL and PyG regarding average power consumption, which indicates that energy consumption mainly depends on overall runtime",
        "2211.03021_6f73fdf808470e44f56718cb7222114c": "We observe that GraphSAINT is more efficient in both runtime and energy consumption compared with the GraphSAGE and ClusterGCN, thanks to its light-weight sampling and GNN operations",
        "2211.03021_162b318a7f8461b33d0988d99e0b6e67": "Note that they are trained for the same number of epochs in our experiments",
        "2211.03021_258430a929245bb0413899570d6b82e8": "Nonetheless, we emphasize that different choices of the hyperparameters for each GNN in optimizing its accuracy would affect the efficiency in runtime and energy consumption differently.",
        "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226": "Case Studies",
        "2211.03021_5d02870a2d290de5c7f3d03a4461542a": "We next turn out attention to three case studies to further evaluate the performance of two GNN frameworks, regarding data pre-loading, GPU-based sampler, and full-batch model training",
        "2211.03021_bd688e80603d4e85defd6237853b26e1": "We focus on GraphSAGE for the case studies.",
        "2211.03021_7b8f0bdfc1e7e91416e2169503cd68c9": "As shown in Section",
        "2211.03021_e3fa0f80554bf70cb13dba8fd0cbad3b": ", data movement can be a problem when we use CPU for sampling and GPU for model training",
        "2211.03021_88b4233e88dfec0ce5600e289beb228f": "We here change the implementation strategy so as to pre-load the entire graph and its associated node features into the GPU",
        "2211.03021_54fc4e4c0865f08678f5b972f26840b6": ", which can avoid the overhead of repeated data movement, i.e., the movement of the features of nodes chosen in each mini-batch",
        "2211.03021_09b23d05d5ab1336cbfde1db40fe9ff9": "Both frameworks provide such a pre-loading option",
        "2211.03021_bbb56b43c7efaa27c8f319beaef51272": "With this option, the adjacency matrices of sampled subgraphs only need to be copied from CPU to GPU for each mini-batch periodically",
        "2211.03021_2e9d5d2f6ce2ff2b2fb77013e0503d47": "Note that a mini-batch is composed of a number of sampled subgraphs in GraphSAGE, where the number of sampled subgraphs is the mini-batch size",
        "2211.03021_449856eb4da1b1f238634c2e4ab17d40": "We present the resulting performance of DGL and PyG with GraphSAGE in Figure",
        "2211.03021_44a559e13e6de3b58def7128909a142b": "for runtime breakdown and in Figure",
        "2211.03021_90f14a25d1a52c3e4fdf3bf8a8a743e8": "for speedup results.",
        "2211.03021_519cd0fa15afeb8e2d3e9b9203f50e3e": "As expected, the pre-loading strategy saves up to 20x data movement time, thereby leading to about 2x overall speedup",
        "2211.03021_38a721fa32dae79e979155b605de8855": "Nonetheless,",
        "2211.03021_c6bcdacbd55e78d1efe121e01342443b": "It is often not the case in practice, especially for large graphs",
        "2211.03021_539598fa0be15051aa38bc5aa6b77223": "An alternative yet effective strategy would be to cache the features of nodes that are most frequently used for model training, i.e., partial information of the graph, into GPU memory upfront, to reduce overall data movement time",
        "2211.03021_0b0a6b18cc76c7e58bd39cb9094b772a": "\\cite{dong2021global}",
        "2211.03021_a71d6da16db27a8afffa37b2ee2ca930": "It is worth noting that DGL further provides an advanced feature called `pre-fetching' for asynchronous data movement and model computation",
        "2211.03021_2f338b2f54cbdb1b0b7e75c02ca43544": "We observed that the performance of DGL can be further improved, albeit a little bit, with this feature",
        "2211.03021_72ab5887535911f5b144b2426b75a24a": "We omit the results here for brevity.",
        "2211.03021_61d15f2ee3d682d65bee52a060eb5ace": "\\begin{figure}[t!]\n\t\\vspace{-2mm}\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat[Speedup of data movement]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/CPUGPU-preloading-Speedup-movement}\n\t}\n\t\\vspace{0mm}\n\t\\subfloat[Speedup of total runtime]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/CPUGPU-preloading-Speedup}\n\t}\n\t\\hspace{0mm}\n\t\\caption{Speedup of GraphSAGE when pre-loading the input graph and node features into GPU.}\n\t\\label{fig:speedup-preloading}\n\t\\vspace{-2mm}\n\\end{figure}",
        "2211.03021_7d3df9b24ec7a45c47ed0058e737de38": "\\begin{figure}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat[DGL-CPUGPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsage-breakdown-DGL-CPUGPU1}\n\t}\n\t\\vspace{0mm}\n\t\\subfloat[PyG-CPUGPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsage-breakdown-PyG-CPUGPU1}\n\t}\n\t\\vspace{0mm}\n\t\\caption{Runtime breakdown of GraphSAGE with data pre-loading.}\n\t\\label{fig:breakdown-preloading}\n\t\\vspace{-2mm}\n\\end{figure}",
        "2211.03021_a4b26c5bbdbe3701e39b5ccd3948b1ae": "\\begin{figure*}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat[Speedup over DGL-CPUGPU]{%\n\t\t\\includegraphics[width=0.3\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/GPU-Speedup-CPUGPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[Powerup over DGL-CPUGPU]{%\n\t\t\\includegraphics[width=0.3\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/GPU-Powerup-CPUGPU}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat[Greenup over DGL-CPUGPU]{%\n\t\t\\includegraphics[width=0.3\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/GPU-Greenup-CPUGPU}\n\t}\n\t\\vspace{0mm}\n\t\\caption{GPS-UP metrics of GraphSAGE with DGL's GPU-based sampler and UVA-based sampler.}\n\t\\label{fig:uvagpu-speedup}\n\\end{figure*}",
        "2211.03021_4c02dccac6c5b61b01cfd979b747d559": "\\begin{figure}[t!]\n\t\\vspace{-2mm}\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat[DGL-GPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsage-breakdown-DGL-GPU}\n\t}\n\t\\vspace{0mm}\n\t\\subfloat[DGL-UVAGPU]{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/graphsage-breakdown-DGL-UVAGPU}\n\t}\n\t\\vspace{0mm}\n\t\\caption{Runtime breakdown of GraphSAGE with DGL's GPU-based sampler and UVA-based sampler.}\n\t\\label{fig:uvagpu}\n\\end{figure}",
        "2211.03021_43a8c2b4e7edd00ec7eb51bdeec3c0c2": "As mentioned before, the GPU-based neighborhood sampler, i.e., the sampler in GraphSAGE, is available in DGL to accelerate its sampling operation and eliminate the need of moving sampled subgraphs from CPU to GPU for each mini-batch",
        "2211.03021_8ea824f4b5b1dbec0be2def60e769054": "If the GPU-based sampler is used together with the pre-loading option, it can also eliminate the repeated data transfer of node features, corresponding to sampled subgraphs for each mini-batch",
        "2211.03021_3178431ded63ae8bebaaad7e8a18b7d9": "This combination is, however, infeasible for the cases with large graphs and/or high-dimensional feature data that do not fit into GPU memory",
        "2211.03021_2e2a8f4fc2f23f145e076b30698d5da7": "In addition, DGL supports another sampler for GraphSAGE, which is the CUDA-Unified Virtual Addressing (UVA)-based sampler",
        "2211.03021_c14e238296666dd773604eb3dc540f78": "It uses GPU to perform the sampling operation on the input graph and node features pinned on CPU memory via zero-copy access",
        "2211.03021_b7d25187fbd6a3aab50bf5c374442794": "This UVA support allows DGL to deal with much larger graphs with the benefits of using GPU for sampling and model training",
        "2211.03021_2e5cf2500f4d5f9d2ed103e1f9a3726a": "Note that both UVA-based sampler and GPU-based sampler are currently only available for GraphSAGE in DGL",
        "2211.03021_6712391d74a4fc539db544678625d0c1": "We evaluate the performance of the GPU-based sampler (`DGL-GPU') and UVA-based sampler (`DGL-UVAGPU') to see how much improvement they can achieve",
        "2211.03021_2cd8136f5873089c246be2a0f83cd4bc": "For the former, we also use the data pre-loading option",
        "2211.03021_e65797aca47586a4f5939e692e45591c": "Their runtime-breakdown results are reported in Figure",
        "2211.03021_feaf752e8a06c1d01db9f1d5ab4f2387": "Here the data movement for DGL-GPU contains two parts, which are (1) copying the input graph and node features to GPU for sampling and (2) moving the initial GNN model from CPU to GPU for training",
        "2211.03021_f0d2c471f0e9dab215091e36483ba5ce": "For DGL-UVAGPU, the data movement is only for the initial model.",
        "2211.03021_b9f441619b2cfb3141828612df183eff": "We next use GPS-UP (Speedup, Greenup, and Powerup) metrics introduced in",
        "2211.03021_bb48ff3c7ef148cad388a9b9bd71bcd7": "\\cite{abdulsalam2015using}",
        "2211.03021_475e8a4a324d710d6a4df3c26b039e7d": "for further efficiency analysis",
        "2211.03021_52c7760f64b9dd28a8061aa8daed077b": "The metrics are designed for comparing two different implementations",
        "2211.03021_332948c5b5eef3f883350324b3c63b43": "One of them is an non-optimized version (i.e. baseline) and the other is an optimized version for better performance",
        "2211.03021_16f5c5c5100643fa0d2e5a915d5d848e": "Specifically, they are defined as",
        "2211.03021_b865c4b904c443681379412e07ec5033": "\\begin{equation*}\n\\setlength{\\abovedisplayskip}{5pt}\n\\setlength{\\belowdisplayskip}{5pt}\n\\text{Speedup} = \\frac{T_{\\phi}}{T_o}, \\quad \\text{Greenup} = \\frac{E_{\\phi}}{E_o},\n\\end{equation*}",
        "2211.03021_484eee83ae3e41364dda26cd232788ca": "\\begin{equation*}\n\\setlength{\\abovedisplayskip}{5pt}\n\\setlength{\\belowdisplayskip}{5pt}\n\\text{Powerup} = \\frac{P_o}{P_{\\phi}} = \\frac{E_o/T_o}{E_{\\phi}/T_{\\phi}} = \\frac{\\text{Speedup}}{\\text{Greenup}},\n\\end{equation*}",
        "2211.03021_96cc334a996dc419fb0ce6e687eb7eff": "$T_{\\phi}$",
        "2211.03021_c0cb5f0fcf239ab3d9c1fcd31fff1efc": ",",
        "2211.03021_83e2b21efb9ba2faed1eab6d7005361a": "$E_{\\phi}$",
        "2211.03021_8a0e2b549d223aba55a866c38d1c9275": ", and",
        "2211.03021_4f3d988e0c582adb55a7ec4393a9adfb": "$P_{\\phi}$",
        "2211.03021_dca7b3428d01160daa9454f10eb98ced": "are the runtime, energy consumption, and average power of the non-optimized version, respectively, and",
        "2211.03021_4a5f15fcde5aa7a938cddbe5bffb7388": "$T_o$",
        "2211.03021_7dd69adc2f392f49a3a3a60576579673": "$E_o$",
        "2211.03021_683816b114e1b77d574a09e7356e2185": "$P_o$",
        "2211.03021_a4c23978b27bc8066c40f6738117524c": "are the corresponding values of the optimized one, respectively",
        "2211.03021_0ecfeec2ad4266320e6851373b964952": "We here use DGL-CPUGPU as baseline and report Speedup, Greenup, and Powerup results achieved by DGL-GPU and DGL-UVAGPU over DGL-CPUGPU in Figure",
        "2211.03021_1b914b40413f1132b742e42bed8979e7": "As can be seen from Figure",
        "2211.03021_625671979ddf3570c12902cc9c619423": "(a), DGL-GPU achieves up to 5.5x speedup over DGL-CPUGPU",
        "2211.03021_4c1f6d3410c11fb3676e672ebd84463c": "DGL-UVAGPU is sightly slower than DGL-GPU, because the former uses zero-copy access to CPU memory, which is generally slower than having access to GPU onboard memory",
        "2211.03021_c89a343699607fc2a333e3c854f840cf": "From Figure",
        "2211.03021_0be9af89772c5dc6541638e0ad5c12d1": "(b), we also observe that Powerup is not always above one, which implies that the power consumption of using GPU for the sampler can be higher than the CPU counterpart",
        "2211.03021_6bff5867ff177ca86ecfa25e0da17dc8": "It happens, especially when there are a large number of edges for each node, e.g., the case of Reddit, making the sampling computation on GPU heavier",
        "2211.03021_5d6fc3d9cbed6ce59f078ffdd586f209": "Nonetheless, as shown in Figure",
        "2211.03021_5b92e9f47c1afcf0d98a407263fede84": "(c), we observe that Greenup is always above one",
        "2211.03021_190f3a0729e34de0756f2ddb7a966cc7": "In other words, it is",
        "2211.03021_84d0650ebd58afc562de79c176da898b": "using GPU for the sampler",
        "2211.03021_7c032ad962d3ffcf78b959692b5bd525": "While GPU can consume more power than CPU for the sampling operation, it significantly reduces the total runtime, which translates into smaller overall energy consumption",
        "2211.03021_e082ce0fb1517030d2fedcade76a85fe": "Our observations indicate the benefits of using GPU for the sampler of GNNs",
        "2211.03021_cd2a09e12ca798eca76ef2465714c0a0": "Nonetheless, this GPU support is currently only limited to GraphSAGE in DGL, and there is no such support in PyG",
        "2211.03021_73f3b4a3ff5bfc2d2cdb7e5572dc8995": "Note that there is a recent study",
        "2211.03021_e71eb478c8c99b958c9d930c213c75a1": "\\cite{jangda2021accelerating}",
        "2211.03021_806dcd77369aa8ffaa2c8d4dbad1cc78": "that leverages GPUs to accelerate graph sampling for GNNs.",
        "2211.03021_53c698d91c576c6f3ed144123f225968": "\\begin{figure}[t]\n\t\\vspace{-2mm}\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/fullbatch-training-1}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/fullbatch-training-2}\n\t}\n\t\\vspace{-1mm}\n\t\\caption{One epoch training time of full-batch GraphSAGE.}\n\t\\label{fig:fullbatch}\n\t\\vspace{-3mm}\n\\end{figure}",
        "2211.03021_9c7847aac89a1acdaf965a7f7ffa4858": "\\begin{figure}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/fullbatch-power-1}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/fullbatch-power-2}\n\t}\n\t\\vspace{-1mm}\n\t\\caption{Average power consumption of full-batch GraphSAGE while training.}\n\t\\label{fig:fullbatch-power}\n\t\\vspace{-3mm}\n\\end{figure}",
        "2211.03021_d2dfb9b22d23a7ebb356dfdd361a7f0d": "\\begin{figure}[t!]\n\t\\captionsetup[subfloat]{captionskip=1pt}\n\t\\centering\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/fullbatch-energy-1}\n\t}\n\t\\hspace{0mm}\n\t\\subfloat{%\n\t\t\\includegraphics[width=0.47\\linewidth, trim=0cm 0cm 0cm 0cm, clip]{fig/fullbatch-energy-2}\n\t}\n\t\\vspace{-1mm}\n\t\\caption{One epoch energy consumption of full-batch GraphSAGE.}\n\t\\label{fig:fullbatch-energy}\n\t\\vspace{-3mm}\n\\end{figure}",
        "2211.03021_c86e81681fe1c812a7ccc6d4fef4d3ea": "We have focused on three sampling-based GNNs with mini-batch training to evaluate the performance of the frameworks",
        "2211.03021_3fba64382f955d6b4633395431a18c55": "For a comprehensive evaluation, we here consider",
        "2211.03021_370b818a2ebfa7fa756a8a441b804b87": "training to train a GraphSAGE model, which is done based on the entire graph",
        "2211.03021_a3a5e560a84725eaa80af8e34861d1f4": "neighborhood sampling",
        "2211.03021_ce7587ea49e49d3298c5e6880ef15ac9": "Specifically, we use a GraphSAGE model with two layers having mean-aggregator and train the model on CPU and GPU using DGL and PyG separately",
        "2211.03021_0f9e12de1f2f6ba795c50defed258cab": "We present the experiment results, which are the average results of 100 runs for one training epoch, in runtime, power consumption, and energy consumption in Figures",
        "2211.03021_53ad699b31123921b09f0a7845118ce1": ", respectively",
        "2211.03021_08d1ee6f5195c6e7503d2542f234bb41": "We observe that DGL-CPU is much faster than PyG-CPU for full-bath model training",
        "2211.03021_c09f56f75146fb39dbf1dd645d27e357": "DGL-GPU training is slower than its PyG counterpart on the smallest graph PPI, while it is faster for the other five datasets",
        "2211.03021_050542c2ba23eb6520f61a08c1842884": "The results are consistent with our functional test results as reported above",
        "2211.03021_7a05e3bbed7afe03dfa9be8958315ef7": "We also observe that there is no clear difference in the average power consumption between the frameworks for model training",
        "2211.03021_a687693607eda3a7a1854ac61afff059": "That is, the differences in energy consumption between the frameworks mainly come from their differences in training time.",
        "2211.03021_6f8b794f3246b0c1e1780bb4d4d5dc53": "Conclusion",
        "2211.03021_200924574ea1daee8b178d15267b88e4": "We have characterized the efficiency of two mainstream GNN frameworks with three state-of-the-art sampling-based GNNs and six real-world graph datasets, which cover a wide range of graph sizes",
        "2211.03021_907d2dc70e7d84e00dfd998c69bc923a": "We have conducted extensive experiments to evaluate the performance of each key component of GNN models and frameworks as well as each GNN's model performance from the efficiency perspective in runtime and power/energy consumption",
        "2211.03021_5af4d0204e9359b9241ecb17bbf7df7f": "We expect that our observations at many different levels would be useful for further improvement and optimization of GNN models and frameworks.",
        "2211.03021_ec0bc5c569709d21640eea1a1b94540b": "*Acknowledgments",
        "2211.03021_788a1f899c2562e0ae3a1b369fa24dab": "This work was supported in part by a grant from SK hynix America and an equipment gift from NVIDIA",
        "2211.03021_2d2a206f828b0a378f26c849c1ebff7f": "This work was also supported in part by the National Science Foundation under Grant IIS-2209921."
    },
    "hierarchy": {
        "1": {
            "2211.03021_4b09adc2daa8cae31186ee33d973da92": "2211.03021_c5428fe9e3a9e1865a46802f85a28857",
            "2211.03021_e604f4348031a3aa7d7d89c9653bf105": "2211.03021_c5428fe9e3a9e1865a46802f85a28857",
            "2211.03021_f7cca6f491db4dd9c61932be46d499df": "2211.03021_c5428fe9e3a9e1865a46802f85a28857",
            "2211.03021_35dba5d75538a9bbe0b4da4422759a0e": "2211.03021_c5428fe9e3a9e1865a46802f85a28857",
            "2211.03021_beb4dbf9af069aa2df7b147229965085": "2211.03021_c5428fe9e3a9e1865a46802f85a28857",
            "2211.03021_f2577a6fc29b900fe7d4c6321346be48": "2211.03021_c5428fe9e3a9e1865a46802f85a28857",
            "2211.03021_e353dbe42c8654f33588d4da0b517469": "2211.03021_c5428fe9e3a9e1865a46802f85a28857",
            "2211.03021_5084eb7dbf77f0f825541a9e1d9d8b71": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_9cd8b34bca0b48fed870c0d4dc7fc539": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_d83837aecd64411fa7f89bdea4a4a190": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_33028fac7375318390578bf83fbe0b52": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_f5cf440bd79d728ab15493766fa751c7": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_27c615b0c11b4b71fd277e0b4ce2bcca": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_e6b31197902eeecca8f6763ecc7f95cb": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_b86ffe4d0ce6f39ef00e0cad6c55535b": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_7d05dc3caae81676f566d650df90214f": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_358485ec638802e2109e11af2fc10ac9": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_0b79795d3efc95b9976c7c5b933afce2": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_8e70f5b0672367049ffa4ce4b26a8c76": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_6fb5ab51424f5086a90d9887fc645594": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_3367bbb67d7e3887b703c5d3fdc0b471": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_f7a047a6591a94e227dd79a78f04ae91": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_9fb183392ea6214f787b6372a5f317fa": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_650f2ce41cfbaa199a59c8d9f8c646dd": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_e99b2637bd8444555fc724aa5064fceb": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_f1d3b9204392ac06247e2080d1b3fda5": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_227c52d774ceb22fce44e72f0e5d3aca": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_adf90b0c953ac1131e2395ba00707341": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_875e3e18e1abb7ac608f034cbd5cb90f": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_de34be68a00813eac60e9944bf8ba042": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_9adf76fb40f75b10e8b34c9e087c37ed": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_a750bcebff4f76995461838a0d6377d3": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_a6803f4f3036200f653327bdd49d3b92": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_8a420c1f2e962ae942d77ab89db330ab": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_0290a5424420eebf5a6eef184638a4ba": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_9a0e5b74d282b1e7b0d0a530e9c161bb": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_38f5789269f1016240e709754a8f03ac": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_f353b17811d87cc67766d8685f883ae0": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_1dac1006f913dab6bdc7917049e05cf3": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_307f43234013f04344a4513e4deddf2d": "2211.03021_2a7e92f24cb59b197ef714d418b21bb4",
            "2211.03021_e028dcb95a2245e0a1cacfdc6b005513": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_3df29fa52095c85baaae3346eff7c935": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_639cf81bf8cccd980ba47ad71930892c": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_a23eda00745b4f173521aad6630e8edd": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_dc6c6a9e7a94e40294edd834af0a2d83": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_3de5c6ff47c7d29489ff80a960845523": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_403762af7ababcc98149f2ab89da3c9c": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_f35410abd78c00fa06b495b85a4741d4": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_ea43997c63dd9192740784db04e786e2": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_4c8d90a5582371258399e6079f1a5aa9": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_06c839c6f2960d3a1fdd0aabca50746d": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_ff5f1c3e124c3c2339184529f8bf5902": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_12f75bce9db42e5b4fe2bb775caffd35": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_7eb372c789a73feb86c8abf3f623866b": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_a2147a6b8e3f7dd7403dd7bbf9766f86": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_e5bec33b9b4185b760df6a1182ac8460": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_c938a968e43b0d9b3e0defc2d204249e": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_e63400e880002785e004a686d0b7f643": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_f5b79bf7e3f91f3ce3ac550c8052fe07": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_18fe1ad6b36a76a13803db98043827f0": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_5224dc31328aa58e2fcc1497609beaaa": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_6d3862009e9ae7469526a5cb8d7c4c17": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_2cc3ab887298bcb5683dfba6d45351f1": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_5af5b5504d15a12969dcfa304369cec9": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_44efa1d139e7b45c6442c1388749530d": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_2ca22b3025eb6b71bb7c905bb5770ded": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_0674fba73a2e6914ea9b1fc55130bb81": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_907f03ebf285e895e554fa304da132bc": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_40f87b890d5b5eba0402ed6570c11643": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_7a9e0da80b21fac483811f3a67f8cfd7": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_7ccd56d909776a8a8ed408b6d0df6b28": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_d17252d35fca56991dfe195b0ee80294": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_d03b5449cc4bb2c1aa849e528db2e29a": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_7fc26465cbff91bd26c97587bdad4a9a": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_8468b7f0d2cdc0cac258314b3eaf3b39": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_53e359796fa092d0a332586a2bfaee15": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_c30f557e933995157922f0d3cb41eea6": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_a000d128e67e97af172068dd8c2a0838": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_7ced64ffe254d256c878cbdeec7220f6": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_1e9d505bcaf30f5f87e55c2b82d1a6a5": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_a8f65dd93445b90d34246cc201862695": "2211.03021_0b79795d3efc95b9976c7c5b933afce2",
            "2211.03021_7d74f3b92b19da5e606d737d339a9679": "2211.03021_a8f65dd93445b90d34246cc201862695",
            "2211.03021_2482bc346f782bcfbb8fbf30d9bcd675": "2211.03021_7d74f3b92b19da5e606d737d339a9679",
            "2211.03021_c2fd96f78899968e6f99ccfdaf3a5f0d": "2211.03021_7d74f3b92b19da5e606d737d339a9679",
            "2211.03021_cf24dfc2f5d33cb292c78eae9cf7df1d": "2211.03021_7d74f3b92b19da5e606d737d339a9679",
            "2211.03021_6a9b7b984a144feabf280d98506ead83": "2211.03021_7d74f3b92b19da5e606d737d339a9679",
            "2211.03021_d24c35179da4ebd203fe13a4b7bf4c68": "2211.03021_7d74f3b92b19da5e606d737d339a9679",
            "2211.03021_7380b8132be89e220d18bb59a280b052": "2211.03021_7d74f3b92b19da5e606d737d339a9679",
            "2211.03021_c380ea320f25650fafe24aa1f0ff71b1": "2211.03021_7d74f3b92b19da5e606d737d339a9679",
            "2211.03021_77971160750cc58286373b05b145f675": "2211.03021_7d74f3b92b19da5e606d737d339a9679",
            "2211.03021_f36791fd11b29f26e27f40a1e26281f8": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_845b7115e0330d4f411795d66e496287": "2211.03021_f36791fd11b29f26e27f40a1e26281f8",
            "2211.03021_9332f3c42a166c54b9ef02aba198d8f9": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_4832f15c36bd0a15569298f161dc2891": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_24f2697edac238fe23ccb018d2d6d0ff": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_567904efe9e64d9faf3e41ef402cb568": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_8824595f458085fe3bf467c4228300fc": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_3202add59b81b4193c2328e4baa6aef5": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_ae44fa1818647ed39ba79b316ce5dd87": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_8d435b0bef873b4c408eb9906fb37c0d": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_d3a1366eb0b568eee312aae85992390f": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_be5d5d37542d75f93a87094459f76678": "2211.03021_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03021_c73e2b97fdb4557468f71e86ea5a3f47": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_6e0dc03ba7048d7c5261ce28fd4843d7": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_2f2322dff5bde89c37bcae4116fe20a8": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_f50d68c04e2f198ecaf1bfb0c4e99399": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_5b585da8b5e066d87cc63146b5c5b3f7": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_ed80d9ae28635a63812baef07e99e7a3": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_b1b88d6c7d1cd566406f0a098b364aac": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_c26a01ff413fee81abe4b4508a2b7336": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_e388d623a584788d180ebe5f3a9fcd7a": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_f8079f9661cf573bf16884b9c62880fc": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_05d04483099af05663a340e1150fc83c": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_26d82f9209039dc4e1762eb6bb37f79b": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_69dfdf4e6a7c8489262f9d8b9958c9b3": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_3dfbb59fdf079baacbd786283731e49d": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_9958d8fd4f3e70dca1bc895ba76e63e9": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_b1dc8b8ad21600449d70f088bea6f6bd": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_40f4339a355b53b90e959a66c3408df4": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_59d59e47fe9e4192e9c9eaa3d2f7479b": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_fd272c0291ff9655ef1985be3a3129ad": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_adec714ae69bef54c5ee79cfcb41955d": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_9f6e3e68ab147beb1e9f3ae2f351e58a": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_3287a89998950552362e60fb9ec3781c": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_8f4e33d27c3c1d3ebc675022b5426d87": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_63bb9849783d01d91403bc9a5fea12a2": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_ecef756118e82364052aee683ad63373": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_0fe0c9cb414606a563a1defc07f2615a": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_d6b780fb63d10cc33f73c249fd223299": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_ca5710b4cfd5827dce07f068feb5fdc7": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_a59709d6a52ae38527472301036f0691": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_f785efa005ccf73df9f81c5b919e1960": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_1ae9a3e8c0b40b153320232957da6e8b": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_e8e1e1ebacd33e7c8cfcf9f131aadc3b": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_03d6a618958376c8d9daf33efdedbc08": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_b831fe0e49ce594ca800bad34288eee8": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_6707973aa1b9e5bc8c4b8bf3cd30238c": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_f3df70d66ae8f48bfc5f508e3cad7404": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_8d3311216be48e6d94e007003874ee77": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_3d26188738a0ff7685b888dcdd44baa5": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_0aa4384d514169f6f97125744b144427": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_244a92ecd257fa7f801076d688773ba0": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_d43513ed8989f66d9f3d98fbb135641b": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_0f3bc1d0aa77343af27224bae261efe0": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_ba6740bc576dc6440d031eba07c4432e": "2211.03021_845b7115e0330d4f411795d66e496287",
            "2211.03021_aed402c3112b4749a9a98a72cbe9093d": "2211.03021_f36791fd11b29f26e27f40a1e26281f8",
            "2211.03021_4c99dcf90dfebbf0cffca7b620c63df9": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_fb22c55847700d6af9529431bf1c876c": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_e5b084037ca3dc99c03fb8799c259dc2": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_5d5d9470bca07b69626fdcd94e1ce77d": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_c02a4ac39326b9acd8fd00f8b197011c": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_6679b1b3897904b39182dde0baedabfc": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_5961b9c45e8cd870020433a870618cd8": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_2d5c25c224daae7d13526b51e463da80": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_4ac72f5dc74517f14157994e61d8effb": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_755e9f5b91e51e0a09b25e0717e6a2bb": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_96641e4a5a09e69b32236adbdfd55407": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_8d03936c0c46ddaddadddd96e4aa1605": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_d953ea0c8d095934a3a8e6538b8a3a68": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_85e27891a07f4d423536f93b8dfd7c02": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_b3cd9344dad3ff77b4fd532b70660aa2": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_a35a87779cd98067a9eaf468e1df7998": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_837028340d3ffe2f1e11531bd9f6dcae": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_5bca6886482da97289e2f24f1d41484e": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_51a1a4894aaf6b468d0b2a0a4e94dfe2": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_950db817b7d319f5781786be60def56b": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_e36c050923be8f4dc9079158e104bd88": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_a606dc818f8937082770e76478b527e3": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_98c3a8af105e96b8cc7c0a6affe43810": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_6417e9ab8b5868282aef35e917de13b0": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_2ccaebdec8c8fa51b0f9917ea78ca32b": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_fca1d24b23c26ef233efe20d315aca5f": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_74b1977d83f6c1a98afa83fe86b09808": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_a75af13a5090fd001fa7d2f3847650b3": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_82e3b2d406c54c3c6c3582953e60afc5": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_cb9df689075b30219e70339cfcb2ef48": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_6ee861e92c503196e940e4fb3e8c57c3": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_776ca20239d8c78761d6dbe2194a26ec": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_a245bf8b340e875db1185fa6b5ff584b": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_a4d58118da7e4cef36b4e86676c7cc9a": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_a277e986057991b4c1f5e872f479d762": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_161edd00e22d6e1c010cc2db2840be79": "2211.03021_aed402c3112b4749a9a98a72cbe9093d",
            "2211.03021_2ba0c1d2f0f117d4512ef6170fe0e015": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_2a7e92f24cb59b197ef714d418b21bb4": "2211.03021_2ba0c1d2f0f117d4512ef6170fe0e015",
            "2211.03021_b6f7678a36ea20ce39288ccca98376bb": "2211.03021_2a7e92f24cb59b197ef714d418b21bb4",
            "2211.03021_5ba047da70383d89fcf6936e4897c27e": "2211.03021_2a7e92f24cb59b197ef714d418b21bb4",
            "2211.03021_2a18b0c38dec1b3854c36ab255ca76d7": "2211.03021_2a7e92f24cb59b197ef714d418b21bb4",
            "2211.03021_cbcc7909a4f5bfcc1c66d2518481862b": "2211.03021_2a7e92f24cb59b197ef714d418b21bb4",
            "2211.03021_05ae55bc484fbb804f91910d14e8ed1b": "2211.03021_2a7e92f24cb59b197ef714d418b21bb4",
            "2211.03021_64e977b3c0b9f1ec17738f2e146703db": "2211.03021_2a7e92f24cb59b197ef714d418b21bb4",
            "2211.03021_67fad61f3c3f74e49e13b8d4c103b96a": "2211.03021_2a7e92f24cb59b197ef714d418b21bb4",
            "2211.03021_b0253b1c82b57aff108954fd2c1a6c3c": "2211.03021_2a7e92f24cb59b197ef714d418b21bb4",
            "2211.03021_f1cb45f64cdd7b55480ba6aeecd7b797": "2211.03021_2ba0c1d2f0f117d4512ef6170fe0e015",
            "2211.03021_27d8a4f511d1767236cc0959283bb99f": "2211.03021_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03021_16ddaf53f8777105252c587bdd1d7537": "2211.03021_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03021_4ff2e716a7d06ce5274b4090b39abad3": "2211.03021_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03021_016877d6d6414ded334b306f7bcfa44a": "2211.03021_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03021_dc70937d8580a0a367baea6c6570cddf": "2211.03021_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03021_6fd805609bfc1fc1774993c0cd3a7ce8": "2211.03021_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03021_d96810696104897aab20781b63cfd161": "2211.03021_f1cb45f64cdd7b55480ba6aeecd7b797",
            "2211.03021_5058f1af8388633f609cadb75a75dc9d": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_10fd5b0215404cbc83e5ad3aac139001": "2211.03021_2ba0c1d2f0f117d4512ef6170fe0e015",
            "2211.03021_70741464f0efb9181851ffbb0b001f35": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_196d90b3756fc1392ca6a7355998eda7": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_6b21bee3605ebff92c4e2c3a84d6ef6c": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_5f52184829a02731016df1209ca50624": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_ca34b8031179f5fa79c24520de8aea9c": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_25aab46f7e7258c06f95395d07a4c0cf": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_65053fb68cac0a0f658d89a4036db919": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_b2de331b673da5db824bef969a217880": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_6756e7ce71423c466c2125875e51b4cd": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_38d40364021fee8dc7efa082d04e3649": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_7c642cae67f3ab0ceadfe47ed4b6fdec": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_f00610e9f900215fe33a856189f5f655": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_01197e049beff11d6a4647c15f0ae9e8": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_2bd6f27c1c3e0660b344526e731ad482": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_795808168a9311d58e913b54150bd2c3": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_c152e5a339f04632b85cf089a08e2bf3": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_6fcaaae7eb53cec82cb888823834d8ee": "2211.03021_10fd5b0215404cbc83e5ad3aac139001",
            "2211.03021_d1fb541327a140ceab489f7029524517": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_619650193cd1eb96d41e0f3cc9cb7d54": "2211.03021_d1fb541327a140ceab489f7029524517",
            "2211.03021_815ced4cd160150268883a86cc50e7ce": "2211.03021_d1fb541327a140ceab489f7029524517",
            "2211.03021_a4abba138ae71c9c1f7a7468946c8501": "2211.03021_d1fb541327a140ceab489f7029524517",
            "2211.03021_666df2f48cd16f38212c093999248769": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_310b249daa0d0256e387618889d93593": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_4e1063b75720ffb86e36a97dd1f8df32": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_f7b93580c140d5b208bfb1f2ba1ec7a5": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_9ab018720b308e65172598ce1200be5c": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_ae4dabe1b18ccec73ae609a2957f160c": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_dc78dd3567adfa9965a1cabe32d76ae0": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_737a47b1d4f7bec6970e24a5953e602e": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_ac959e863067f33d7769e68f8d739cbc": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_7619b55a97370de76c33462acf8fd31d": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_a3a230d3e4fc7d1544e4b3df99bf8804": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_e528c9a653c2af2e0dd7745433f2215f": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_914a4067440107d8d268a07806957d57": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_87917ad1c768335353f026afeaee78d9": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_50e15dfded1c38252f054ca7f658f93f": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_17f23c4cbd7bb47296325380e53f7a3e": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_e85acd6de3c28a37abd7a16c7b8f7076": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_37fa18e12b5edb5ee8494bde422ef768": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_5e7b512ddd497549691f23c4884c0520": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_07de7fdbe5132dbf59e6990ef4bb23f5": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_12d9ecf2b08e74350bf8800ab842da3c": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_0be5a6a17bc113c44d1e1ce169ef0bb7": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_1d64937bcb3f63374560c99ad5e8547d": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_9a5c76a8940dbfaee9a7853a01fa2c25": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_43621416afcf8f3d1973e6c3808d53fa": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_020a83d3a2fcfd477dbed7d1e9809856": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_3133fff3b490705f8d5a17913a413994": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_385ef398e4362fc470ab38a144d3684b": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_05ff9aba6e83039a8262216030d09c9a": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_8c3fb529cf3a87be02570734ec9491f9": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_da42bc70faadfe38412caa8753861dd1": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_964116f94208ea4352befdb4f8ab4d9d": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_bfcbf03e88868f168023494e70e8af38": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_6ea59fd697117a13eca1a3b422d039a0": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_855b1d43a97a2fc6280da09d0059e107": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_3ea84540056d9160c4f1a0e5859e5a72": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_6fe2b6e52294cdb63994eedec3b85213": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_d9b8c5153b59279bb0c6f2d90f2a21db": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_6592d7bed12277a1ea7e290a129c268b": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_6d5a0b979e66ef10b7dfc2797488e28f": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_8eb9b503b1fb3be2228390ad13a0e0b9": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_1286f28ae142c3ea73c5050d4e800a0b": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_f2877483129860bbc14cbc1b4d795429": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_0ae28ffdc2017da7d6522410e2ea71b9": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_e9d2a28c2dc93686ab0fe044a1b2ac09": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_13e615404de8de5610b06411675bb145": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_f1740c9dd0b3463434ba0cff27346f5b": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_23d1b1313fe03a235893191d950ee88b": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_7c9271904682de5d3fab1b71c0b4ec30": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_984d8513f33d34aec10aa658d11cd1f9": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_99354e4f84fdfd08ed3b7f261b09008f": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_c582a2719ef9ce7e36285912d02b9542": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_76f9884d8476702b59cc7b5d2e3ae072": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_5555c7b4eb94b0c5cdb7dbd1dd7a07ae": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_207ff281c169f225c8850602e2345cc8": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_3966cdb3be6447b98de358b400fd0f17": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_e4c885361583ebc976a0e1a8e6b57257": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_b4b3aad5fd9910750019ee22a3141632": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_1a2b3a0ad2bd29435ab9aadeda141c90": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_cfc7f40ff7d9c89beee30cd680402b9b": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_df399e60be33e291dbfebc47abd35226": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_ec6fd7a230c80e23389e797b88f12f63": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_5e4fef298ce9373d973b1563f7729fd0": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_b988aca718bd8b90be4a372f23275124": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_c9dd80dca94971da74839fc012f5bafd": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_c71b548b902d4d36a42f7ce7f6b87388": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_4bb5cf1e5a764df9c109e66cff4a85de": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_dfe4a1d6c193fa193119f58a0176fb44": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_27120747d5fe9364300b4d89a2c172e3": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_51301c3f66993dd10f9f200d8ac90934": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_86ca71ffe69b74511c150f4945f5a107": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_da11c184592dbe881cc44c1dba4fc014": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_aa3d08271aa5220efaf32b181465f185": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_ebc676a1155d0224ee7bc7a1dd83d28f": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_4f4c4f9a3dd37de32d3ce660e3a0b459": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_970419e617205d28068d5bff787e4267": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_7e1aefa64333da72ce353953c7d40564": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_fee133addc6ea5841fda749901301544": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_2cd0fa94e78616d0491115720db6c8ed": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_a85859a7bebf9cb0ff0caa8f0b83a4ae": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_23e932a946f6a6cfd121e08a60022489": "2211.03021_a4abba138ae71c9c1f7a7468946c8501",
            "2211.03021_c1fe46878983ce12c96f6378be5b57aa": "2211.03021_d1fb541327a140ceab489f7029524517",
            "2211.03021_df0c3ce3ed49e52303ea23220b6ad1a1": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_6f79697a705597550943bdf63e06b1d8": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_bbdea3feac2d8635564599f636589cbb": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_f0089bf7f30acda55571fc46fc62e1f3": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_c2e1dd7e8522a6c6b3f88320934103d5": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_43eb6140587a1c1d3d05687eeb301964": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_cef76529265c164053132cf47ceda453": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_60e0436c370e19ade51200511f595556": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_e934bebd88793f91786c79af456b2e96": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_31e1b1411169dadf88e1627258d1771d": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_c6b86eedb66581eeb379c3ad17761363": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_3395936dbb4850fb7eaf7af44fce8e1b": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_110b4d45fec92b22bfd3a1fb8e2b0912": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_033945a071877c0115d3b923aa349705": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_355a997683718a975a162ee348533ac6": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_1071f01918a5d64a129a0b44e5ea7af4": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_f9427d7eb326dd2439c05ccb6cfbc321": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_2c682d02b99d54677aae02f840770ff5": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_f04bcef90fd94413879e0b342a6d18db": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_315482e7a2f74141c836ff8ac01a1f32": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_d4749652d0da51273fab9c2dd221cf85": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_7df006a4c9469890e321c3a55efdc658": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_ffef077d4a7eb8ba0099784ad2b08518": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_bbf91eb9515e8321870fde81e03abc91": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_8330935f123ab2dc8a2563351489f477": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_94e38bfababdd76a86be9ee5347087e9": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_71a91d9fa3f504748843246b22be9679": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_f69daac5240c491c77de9adfb9fc0f1f": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_e6f221c64eb5cd231097150ea52c7a81": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_5345eda2259ccc924b894ee3cb8df481": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_bccc0bf680ce33e8b0b052f347544291": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_ba08a1d462fdb7ef16abfcd41def233e": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_0746f1c032b38fc18d7d5b0623d91cc1": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_4f588d77195a1b3e1bfe3325aa79ebca": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_53a2232bf71302c1727a679838d3a2ac": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_adf7584dcd98c111fcc477e35c7a5945": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_140e2bb0963ded0b5364c15057655bf5": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_5dea455831cde8944bd4853844504783": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_ac6b9dfb908763141775d97060d44a77": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_689c541b3e85ffa6c36e3cb24fdbe662": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_6f73fdf808470e44f56718cb7222114c": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_162b318a7f8461b33d0988d99e0b6e67": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_258430a929245bb0413899570d6b82e8": "2211.03021_c1fe46878983ce12c96f6378be5b57aa",
            "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226": "2211.03021_d1fb541327a140ceab489f7029524517",
            "2211.03021_5d02870a2d290de5c7f3d03a4461542a": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_bd688e80603d4e85defd6237853b26e1": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_7b8f0bdfc1e7e91416e2169503cd68c9": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_e3fa0f80554bf70cb13dba8fd0cbad3b": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_88b4233e88dfec0ce5600e289beb228f": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_54fc4e4c0865f08678f5b972f26840b6": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_09b23d05d5ab1336cbfde1db40fe9ff9": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_bbb56b43c7efaa27c8f319beaef51272": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_2e9d5d2f6ce2ff2b2fb77013e0503d47": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_449856eb4da1b1f238634c2e4ab17d40": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_44a559e13e6de3b58def7128909a142b": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_90f14a25d1a52c3e4fdf3bf8a8a743e8": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_519cd0fa15afeb8e2d3e9b9203f50e3e": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_38a721fa32dae79e979155b605de8855": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_c6bcdacbd55e78d1efe121e01342443b": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_539598fa0be15051aa38bc5aa6b77223": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_0b0a6b18cc76c7e58bd39cb9094b772a": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_a71d6da16db27a8afffa37b2ee2ca930": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_2f338b2f54cbdb1b0b7e75c02ca43544": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_72ab5887535911f5b144b2426b75a24a": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_61d15f2ee3d682d65bee52a060eb5ace": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_7d3df9b24ec7a45c47ed0058e737de38": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_a4b26c5bbdbe3701e39b5ccd3948b1ae": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_4c02dccac6c5b61b01cfd979b747d559": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_43a8c2b4e7edd00ec7eb51bdeec3c0c2": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_8ea824f4b5b1dbec0be2def60e769054": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_3178431ded63ae8bebaaad7e8a18b7d9": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_2e2a8f4fc2f23f145e076b30698d5da7": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_c14e238296666dd773604eb3dc540f78": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_b7d25187fbd6a3aab50bf5c374442794": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_2e5cf2500f4d5f9d2ed103e1f9a3726a": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_6712391d74a4fc539db544678625d0c1": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_2cd8136f5873089c246be2a0f83cd4bc": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_e65797aca47586a4f5939e692e45591c": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_feaf752e8a06c1d01db9f1d5ab4f2387": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_f0d2c471f0e9dab215091e36483ba5ce": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_b9f441619b2cfb3141828612df183eff": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_bb48ff3c7ef148cad388a9b9bd71bcd7": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_475e8a4a324d710d6a4df3c26b039e7d": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_52c7760f64b9dd28a8061aa8daed077b": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_332948c5b5eef3f883350324b3c63b43": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_16f5c5c5100643fa0d2e5a915d5d848e": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_b865c4b904c443681379412e07ec5033": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_484eee83ae3e41364dda26cd232788ca": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_96cc334a996dc419fb0ce6e687eb7eff": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_c0cb5f0fcf239ab3d9c1fcd31fff1efc": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_83e2b21efb9ba2faed1eab6d7005361a": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_8a0e2b549d223aba55a866c38d1c9275": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_4f3d988e0c582adb55a7ec4393a9adfb": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_dca7b3428d01160daa9454f10eb98ced": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_4a5f15fcde5aa7a938cddbe5bffb7388": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_7dd69adc2f392f49a3a3a60576579673": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_683816b114e1b77d574a09e7356e2185": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_a4c23978b27bc8066c40f6738117524c": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_0ecfeec2ad4266320e6851373b964952": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_1b914b40413f1132b742e42bed8979e7": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_625671979ddf3570c12902cc9c619423": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_4c1f6d3410c11fb3676e672ebd84463c": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_c89a343699607fc2a333e3c854f840cf": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_0be9af89772c5dc6541638e0ad5c12d1": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_6bff5867ff177ca86ecfa25e0da17dc8": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_5d6fc3d9cbed6ce59f078ffdd586f209": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_5b92e9f47c1afcf0d98a407263fede84": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_190f3a0729e34de0756f2ddb7a966cc7": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_84d0650ebd58afc562de79c176da898b": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_7c032ad962d3ffcf78b959692b5bd525": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_e082ce0fb1517030d2fedcade76a85fe": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_cd2a09e12ca798eca76ef2465714c0a0": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_73f3b4a3ff5bfc2d2cdb7e5572dc8995": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_e71eb478c8c99b958c9d930c213c75a1": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_806dcd77369aa8ffaa2c8d4dbad1cc78": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_53c698d91c576c6f3ed144123f225968": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_9c7847aac89a1acdaf965a7f7ffa4858": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_d2dfb9b22d23a7ebb356dfdd361a7f0d": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_c86e81681fe1c812a7ccc6d4fef4d3ea": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_3fba64382f955d6b4633395431a18c55": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_370b818a2ebfa7fa756a8a441b804b87": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_a3a5e560a84725eaa80af8e34861d1f4": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_ce7587ea49e49d3298c5e6880ef15ac9": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_0f9e12de1f2f6ba795c50defed258cab": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_53ad699b31123921b09f0a7845118ce1": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_08d1ee6f5195c6e7503d2542f234bb41": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_c09f56f75146fb39dbf1dd645d27e357": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_050542c2ba23eb6520f61a08c1842884": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_7a05e3bbed7afe03dfa9be8958315ef7": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_a687693607eda3a7a1854ac61afff059": "2211.03021_a0d2b6fe9ab0a7e386c4c21f70331226",
            "2211.03021_6f8b794f3246b0c1e1780bb4d4d5dc53": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_200924574ea1daee8b178d15267b88e4": "2211.03021_6f8b794f3246b0c1e1780bb4d4d5dc53",
            "2211.03021_907d2dc70e7d84e00dfd998c69bc923a": "2211.03021_6f8b794f3246b0c1e1780bb4d4d5dc53",
            "2211.03021_5af4d0204e9359b9241ecb17bbf7df7f": "2211.03021_6f8b794f3246b0c1e1780bb4d4d5dc53",
            "2211.03021_ec0bc5c569709d21640eea1a1b94540b": "2211.03021_e353dbe42c8654f33588d4da0b517469",
            "2211.03021_788a1f899c2562e0ae3a1b369fa24dab": "2211.03021_ec0bc5c569709d21640eea1a1b94540b",
            "2211.03021_2d2a206f828b0a378f26c849c1ebff7f": "2211.03021_ec0bc5c569709d21640eea1a1b94540b"
        }
    }
}