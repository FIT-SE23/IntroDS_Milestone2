@article{radfarconvrnn,
  title={{ConvRNN-T}: Convolutional Augmented Recurrent Neural Network Transducers for Streaming Speech Recognition},
  author={Radfar, Martin and Barnwal, Rohit and Swaminathan, Rupak Vignesh and Chang, Feng-Ju and Strimel, Grant P and Susanj, Nathan and Mouchtaris, Athanasios}
}

@article{kuchaiev2019nemo,
  title={Nemo: a toolkit for building {AI} applications using neural modules},
  author={Kuchaiev, Oleksii and Li, Jason and Nguyen, Huyen and Hrinchuk, Oleksii and Leary, Ryan and Ginsburg, Boris and Kriman, Samuel and Beliaev, Stanislav and Lavrukhin, Vitaly and Cook, Jack and others},
  journal={arXiv:1909.09577},
  year={2019}
}

@inproceedings{ott2019fairseq,
  title = {Fairseq: A Fast, Extensible Toolkit for Sequence Modeling},
  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},
  booktitle = {Proceedings of NAACL-HLT 2019: Demonstrations},
  year = {2019},
}

@inproceedings{watanabe2018espnet,
  author={Shinji Watanabe and Takaaki Hori and Shigeki Karita and Tomoki Hayashi and Jiro Nishitoba and Yuya Unno and Nelson {Enrique Yalta Soplin} and Jahn Heymann and Matthew Wiesner and Nanxin Chen and Adithya Renduchintala and Tsubasa Ochiai},
  title={{ESPnet}: End-to-End Speech Processing Toolkit},
  year={2018},
  booktitle={Interspeech},
}

@INPROCEEDINGS{
  povey2011kaldi,
  author = {Povey, Daniel and Ghoshal, Arnab and Boulianne, Gilles and Burget, Lukas and Glembek, Ondrej and Goel, Nagendra and Hannemann, Mirko and Motlicek, Petr and Qian, Yanmin and Schwarz, Petr and Silovsky, Jan and Stemmer, Georg and Vesely, Karel},
  title = {The {Kaldi} Speech Recognition Toolkit},
  booktitle = {Workshop on Automatic Speech Recognition and Understanding},
  year = {2011},
}

@INPROCEEDINGS{hu2020exploring,
  author={Hu, Hu and Zhao, Rui and Li, Jinyu and Lu, Liang and Gong, Yifan},
  booktitle={ICASSP }, 
  title={Exploring Pre-Training with Alignments for {RNN} Transducer Based End-to-End Speech Recognition}, 
  year={2020},
}

@article{majumdar2021citrinet,
  title={Citrinet: Closing the gap between non-autoregressive and autoregressive end-to-end models for automatic speech recognition},
  author={Majumdar, Somshubra and Balam, Jagadeesh and Hrinchuk, Oleksii and Lavrukhin, Vitaly and Noroozi, Vahid and Ginsburg, Boris},
  journal={arXiv:2104.01721},
  year={2021}
}

@inproceedings{yu2021fastemit,
  title={{FastEmit}: Low-latency streaming {ASR} with sequence-level emission regularization},
  author={Yu, Jiahui and Chiu, Chung-Cheng and Li, Bo and Chang, Shuo-yiin and Sainath, Tara N and He, Yanzhang and Narayanan, Arun and Han, Wei and Gulati, Anmol and Wu, Yonghui and others},
  booktitle={ICASSP },
  year={2021},
}

@INPROCEEDINGS{Ghodsi2020stateless,  
 author={Ghodsi, Mohammadreza and Liu, Xiaofeng and Apfel, James and Cabrera, Rodrigo and Weinstein, Eugene},  booktitle={ICASSP },
 title={{RNN-Transducer} with Stateless Prediction Network},   
 year={2020}, 
  }


@inproceedings{tripathi2019monotonic,
  title={Monotonic recurrent neural network transducer and decoding strategies},
  author={Tripathi, Anshuman and Lu, Han and Sak, Hasim and Soltau, Hagen},
  booktitle={Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={944--948},
  year={2019},
}

@article{graves2012sequence,
  title={Sequence transduction with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv:1211.3711},
  year={2012}
}

@inproceedings{graves2006connectionist,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={ICML},
  year={2006}
}

@inproceedings{chan2016listen,
  title={Listen, attend and spell: A neural network for large vocabulary conversational speech recognition},
  author={Chan, William and Jaitly, Navdeep and Le, Quoc and Vinyals, Oriol},
  booktitle={ICASSP},
  year={2016},
}

@article{gulati2020conformer,
  title={Conformer: Convolution-augmented transformer for speech recognition},
  author={Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and Yu, Jiahui and Han, Wei and Wang, Shibo and Zhang, Zhengdong and Wu, Yonghui and others},
  journal={arXiv:2005.08100},
  year={2020}
}


@article{han2020contextnet,
  title={Contextnet: Improving convolutional neural networks for automatic speech recognition with global context},
  author={Han, Wei and Zhang, Zhengdong and Zhang, Yu and Yu, Jiahui and Chiu, Chung-Cheng and Qin, James and Gulati, Anmol and Pang, Ruoming and Wu, Yonghui},
  journal={arXiv:2005.03191},
  year={2020}
}

@inproceedings{zhang2020transformer,
  title={Transformer transducer: A streamable speech recognition model with transformer encoders and {RNN-T} loss},
  author={Zhang, Qian and Lu, Han and Sak, Hasim and Tripathi, Anshuman and McDermott, Erik and Koo, Stephen and Kumar, Shankar},
  booktitle={ICASSP },
  year={2020},
}

@article{ren2019fastspeech,
  title={Fastspeech: Fast, robust and controllable text to speech},
  author={Ren, Yi and Ruan, Yangjun and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{prabhavalkar2021less,
  title={Less is more: Improved {RNN-T} decoding using limited label context and path merging},
  author={Prabhavalkar, Rohit and He, Yanzhang and Rybach, David and Campbell, Sean and Narayanan, Arun and Strohman, Trevor and Sainath, Tara N},
  booktitle={ICASSP },
  pages={5659--5663},
  year={2021},
  organization={IEEE}
}

@article{kuang2022pruned,
  title={Pruned {RNN-T} for fast, memory-efficient {ASR} training},
  author={Kuang, Fangjun and Guo, Liyong and Kang, Wei and Lin, Long and Luo, Mingshuang and Yao, Zengwei and Povey, Daniel},
  journal={arXiv:2206.13236},
  year={2022}
}

@inproceedings{xu2021regularizing,
  title={Regularizing Word Segmentation by Creating Misspellings.},
  author={Xu, Hainan and Audhkhasi, Kartik and Huang, Yinghui and Emond, Jesse and Ramabhadran, Bhuvana},
  booktitle={Interspeech},
  pages={2561--2565},
  year={2021}
}

@inproceedings{xu2021convolutional,
  title={Convolutional Dropout and Wordpiece Augmentation for End-to-End Speech Recognition},
  author={Xu, Hainan and Huang, Yinghui and Zhu, Yun and Audhkhasi, Kartik and Ramabhadran, Bhuvana},
  booktitle={ICASSP },
  year={2021},
}

@article{pratap2022star,
  title={Star Temporal Classification: Sequence classification with partially labeled data},
  author={Pratap, Vineel and Hannun, Awni and Synnaeve, Gabriel and Collobert, Ronan},
  journal={arXiv:2201.12208},
  year={2022}
}

@article{ravanelli2021speechbrain,
  title={{SpeechBrain}: A general-purpose speech toolkit},
  author={Ravanelli, Mirco and Parcollet, Titouan and Plantinga, Peter and Rouhe, Aku and Cornell, Samuele and Lugosch, Loren and Subakan, Cem and Dawalatabad, Nauman and Heba, Abdelwahab and Zhong, Jianyuan and others},
  journal={arXiv:2106.04624},
  year={2021}
}

@inproceedings{xu2018pruned,
  title={A pruned {RNN-LM} lattice-rescoring algorithm for automatic speech recognition},
  author={Xu, Hainan and Chen, Tongfei and Gao, Dongji and Wang, Yiming and Li, Ke and Goel, Nagendra and Carmiel, Yishay and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={ICASSP},
  pages={5929--5933},
  year={2018},
  organization={IEEE}
}

@inproceedings{xu2018neural,
  title={Neural network language modeling with letter-based features and importance sampling},
  author={Xu, Hainan and Li, Ke and Wang, Yiming and Wang, Jian and Kang, Shiyin and Chen, Xie and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={ICASSP},
  year={2018},
}

@inproceedings{wang2019espresso,
  title={Espresso: A fast end-to-end neural speech recognition toolkit},
  author={Wang, Yiming and Chen, Tongfei and Xu, Hainan and Ding, Shuoyang and Lv, Hang and Shao, Yiwen and Peng, Nanyun and Xie, Lei and Watanabe, Shinji and Khudanpur, Sanjeev},
  booktitle={Automatic Speech Recognition and Understanding Workshop (ASRU)},
  year={2019},
}


@inproceedings{li2019improving,
  title={Improving {RNN} transducer modeling for end-to-end speech recognition},
  author={Li, Jinyu and Zhao, Rui and Hu, Hu and Gong, Yifan},
  booktitle={Automatic Speech Recognition and Understanding Workshop (ASRU)},
  year={2019},
}

@inproceedings{li2018recurrent,
  title={Recurrent neural network language model adaptation for conversational speech recognition.},
  author={Li, Ke and Xu, Hainan and Wang, Yiming and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  volume={2018},
  pages={3373--3377},
  year={2018}
}

@inproceedings{chen2016phone,
  title={Phone Synchronous Decoding with {CTC} Lattice.},
  author={Chen, Zhehuai and Deng, Wei and Xu, Tao and Yu, Kai},
  booktitle={Interspeech},
  pages={1923--1927},
  year={2016}
}

@article{sennrich2015neural,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal={arXiv:1508.07909},
  year={2015}
}

@article{chorowski2015attention,
  title={Attention-based models for speech recognition},
  author={Chorowski, Jan K and Bahdanau, Dzmitry and Serdyuk, Dmitriy and Cho, Kyunghyun and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{mahadeokar2021alignment,
  title={Alignment restricted streaming recurrent neural network transducer},
  author={Mahadeokar, Jay and Shangguan, Yuan and Le, Duc and Keren, Gil and Su, Hang and Le, Thong and Yeh, Ching-Feng and Fuegen, Christian and Seltzer, Michael L},
  booktitle={Spoken Language Technology Workshop (SLT)},
  year={2021},
}

@inproceedings{shinohara22_interspeech,
  author={Yusuke Shinohara and Shinji Watanabe},
  title={{Minimum latency training of sequence transducers for streaming end-to-end speech recognition}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={2098--2102},
  doi={10.21437/Interspeech.2022-10989}
}

@article{wang2021voxpopuli,
  title={{VoxPopuli}: A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation},
  author={Wang, Changhan and Riviere, Morgane and Lee, Ann and Wu, Anne and Talnikar, Chaitanya and Haziza, Daniel and Williamson, Mary and Pino, Juan and Dupoux, Emmanuel},
  journal={ arXiv:2101.00390},
  year={2021}
}

@article{pratap2020mls,
  title={{MLS}: A large-scale multilingual dataset for speech research},
  author={Pratap, Vineel and Xu, Qiantong and Sriram, Anuroop and Synnaeve, Gabriel and Collobert, Ronan},
  journal={ arXiv:2012.03411},
  year={2020}
}

@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}