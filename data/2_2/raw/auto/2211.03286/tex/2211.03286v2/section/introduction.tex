\section{Introduction}
With recent advances in robotic perception, motion planning, and control, robots have become capable of conducting a series of tasks including autonomous driving \cite{ding2021epsilon}, exploration \cite{cai2021non, fu2022simultaneous},
% surveillance \cite{yu2019coverage, sung2020distributed},
and manipulation \cite{werfel2014designing, chou2020explaining}. This energizes the field of multi-agent systems where robots are organized in teams to conduct larger and more complex tasks \cite{korsah2013comprehensive, rizk2019cooperative}.

Apart from the planning and control of single-robot motions, fundamental problems in a multi-agent system include resource allocation, task assignment, and scheduling, i.e. identifying how many agents are needed for a task, determining which agent individual should perform a specific task requirement, and deriving a plan that the agents should follow to complete the tasks. In a multi-agent system, these three problems are considered in an optimization-based or a reinforcement learning-style framework \cite{banks2020multi, aksaray2015distributed, fu2020heterogeneous, fu2021robust, ravichandar2020strata, prorok2017impact, messing2022grstaps, liemhetcharat2011modeling, liemhetcharat2012weighted}.

While optimization model-based systems are usually scalable, generalizable, and require no training, they often assume the modeling parameters are known or can be provided \cite{fu2020heterogeneous, fu2021robust, ravichandar2020strata, prorok2017impact, messing2022grstaps, liemhetcharat2011modeling, liemhetcharat2012weighted}. However, in practice, model parameters are often unknown or contain significant uncertainty. Therefore, most existing optimization-based approaches are limited by this assumption. 
This work presents a method to learn the parameters of a task requirement and agent capability model, which can be applied in a task allocation problem to represent the required resources of each task and easily embedded as constraints in the optimization \cite{fu2020heterogeneous, fu2021robust, ravichandar2020strata, prorok2017impact}.
The procedure can be shown to be applied to different types of tasks (generalizable) when the assumption of a cumulative capability and known sparsity pattern, provided in Sec. \ref{sec:learning_model}, is satisfied.
The system architecture is summarized in Fig. \ref{fig:main_diagram} and will be discussed in the following sections. This paper provides the following contributions.

\begin{enumerate}[label={\arabic*)}]
    \item The development of a generalizable framework with training data gathering, task requirement learning, and task allocation planning for multi-agent tasks.
    \item The formulation of a linear program that learns the parameters of a task requirement and agent capability model for task allocation.
    \item A comprehensive computational investigation that evaluates the scalability, accuracy, and speed of the proposed learning program.
    \item The implementation of a ROS and Gazebo-based multi-agent simulation that validates the proposed framework through a practical case study. Open-source code:\\ {\footnotesize
    \urlstyle{same}
    % \url{https://gitlab.com/barton-research-group/open/learn-multiagent-taskreq}
    \url{https://brg.engin.umich.edu/publications/learn-multiagent-taskreq/}
    % \href{https://gitlab.com/barton-research-group/open/learn_multiagent_taskreq}{https://gitlab.com/barton-research-group/open/learn\_multiagent\_taskreq}
    }
\end{enumerate}



\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figure/main_diagram.pdf}
    \caption{System architecture. The architecture comprises: a simulation/experimental environment (Sec. \ref{sec:result_simulation}), a learning model that inputs team configurations and performances and learns agent capabilities and task requirements (Sec. \ref{sec:learning_model}), and a task allocation model that generates an optimal teaming plan based on the learned capabilities and task requirements (Sec. \ref{sec:task_allocation_model}).
    In the graph for the task allocation model, there are two task nodes, and s/u means the start and terminal nodes for the three agent types. The edges are highlighted if there is a number (also highlighted) of agents traveling the edge.
    }
    \label{fig:main_diagram}
\end{figure*}

