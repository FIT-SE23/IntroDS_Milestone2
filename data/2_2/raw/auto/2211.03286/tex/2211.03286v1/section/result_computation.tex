\section{Computational Evaluation}\label{sec:result_computation}

In this section, we computationally evaluate the scalability and optimality of the algorithm while de-emphasizing the physical meaning of the values involved in the test cases.
All computations are done on a laptop with an Apple M1 chip.
Note that we will show an example of applying our framework to a practical problem in Sec. \ref{sec:result_simulation}.

\subsection{Test Cases}

Assume for some tasks with the performance functions \(f_i(\cdot), i \in M\), the assumption in \eqref{eqn:one_to_one_map} holds. I.e., whether the task can be completed with a team \(\mathbf{y}_i\) can be accurately described as linear constraints.
We use the following \(f_i(\mathbf{y}_i)\) to replace the simulation or experiment that evaluates the performance of a team \(\mathbf{y}_i\) during the computation evaluation.
\begin{align}
    f_i(\mathbf{y}_i) =
    \begin{cases} 1, \quad A^g \mathbf{y}_i \geq \mathbf{b}_i^g \\
    0, \quad \textnormal{otherwise}
    \end{cases}
    \forall i \in M. \label{eqn:computational_function}
\end{align}

\(A^g\) and \(\mathbf{b}_i^g\) are the preset ground truth capabilities and task requirements and are unknown to the learning model. The learning model should estimate \(A\) and \(\mathbf{b}_i\) which describe the same constraints as \eqref{eqn:computational_function}.


We define eight test cases of different sizes (given in \tableref{} \ref{tab:random_test_cases}) and test the prediction accuracy and computational time of the learning model.
For each row in \tableref{} \ref{tab:random_test_cases}, we randomly initialize the ground truth matrices \(A^g\) and \(\mathbf{b}_i^g\) in \eqref{eqn:computational_function} based on the selected hyper-parameters and generate the data \((\mathbf{y}_i^l, f_i(\mathbf{y}_i^l)), l = 1, \cdots, n_L\).
For a particular task, the team configurations exist within \(\mathbf{y}_i \in [0, n_s]^{\numK{}}\),  where \(n_s\) is the number of agents within each type. As an example, if \(n_s = 5\) and there are \(\numK{} = 6\) related agent types, the size of the configuration space is \(46656 = (5+1)^6\).
% Note that \((n_s+1)^{\numK{}}\) is kept small such that all possible team configurations can be evaluated.



% Table generated by Excel2LaTeX from sheet 'Sheet3'
\begin{table}[t]
  \centering
  \caption{Test cases of different sizes and the training time. \(\numM{}\) is the task number. \(\numK{}\) is the number of agent types. \(n_s\) is the number of agents within each type. \(\numC{}\) is the number of capabilities. \(\bar{n}_L\) is the mean size of the team configuration space for the tasks, while \(\sum n_L\) is the sum. Entire: the average training time using the entire team configuration space. Random: the average training time using a random subset of team configurations.}
    \begin{tabular}{ccccccc|cc}
    \toprule
    Case  & \(\numM{}\) & \(\numK{}\) & \(\numC{}\) & \(n_s\) & \(\bar{n}_L\) & \(\sum n_L\) & Entire & Random \\
    \midrule
    0     & 8     & 6     & 8     & 5     & 1.5k  & 12k   & 5.8   & 0.6 \\
    1     & 8     & 6     & 8     & 5     & 6k    & 48k   & 20.7  & 0.5 \\
    2     & 8     & 6     & 16    & 5     & 6k    & 48k   & 51.2  & 1.1 \\
    3     & 8     & 6     & 32    & 5     & 6k    & 48k   & 104.7 & 2.6 \\
    4     & 20    & 6     & 8     & 5     & 7.5k  & 150k  & 59.8  & 1.4 \\
    5     & 40    & 6     & 8     & 5     & 7.5k  & 300k  & 108.4 & 2.7 \\
    6     & 40    & 6     & 16    & 5     & 7.5k  & 300k  & 275.1 & 5.9 \\
    7     & 40    & 6     & 32    & 5     & 7.5k  & 300k  & 542.1 & 12.0 \\
    \bottomrule
    \end{tabular}%
  \label{tab:random_test_cases}%
\end{table}%



\subsection{Accuracy and Computational Cost}

For each test case size in \tableref{} \ref{tab:random_test_cases}, we randomly generate 10 realizations and applied the learning model to estimate the capabilities and task requirements.
The learned values of \(A\) and \(\mathbf{b}_i\) are then used to predict whether a team can complete a task according to \eqref{eqn:computational_function}. The prediction is compared with the label generated by the ground truth \(A^g\) and \(\mathbf{b}_i^g\).

For a real-world problem, obtaining team performance samples can be expensive (through experiments/simulations), and evaluating the entire team configuration space for estimating the capability and requirements can be impractical. To investigate whether the model learns with a small training set, we evaluate the algorithm in two modes: 1) training and testing both on the entire team configuration space (up to 46656 samples for a task); 2) training on at most 200 randomly selected team configurations for each task while testing across the entire configuration space.

The distribution of prediction errors are shown in Fig. \ref{fig:computational_error}.
The prediction error is around 0.5-2\%. This shows that our algorithm can accurately recover the capability if the modeling assumptions are satisfied.
The test errors of the results trained on 200 randomly selected samples are only slightly larger than the model trained on the entire data set. 
Therefore, the task requirements and agent capabilities can be estimated using a small percentage of the data within the configuration space.

The learning model assumes the sparsity pattern is known.
However, we also evaluate the situations when we have inaccurate sparsity knowledge. The prediction errors do increase, but capabilities can still be estimated. For example, a 10\% error in the sparsity matrix results in 2-6\% prediction errors for the eight cases.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/full/bo_error_box.png}
    \caption{Prediction error tested on the complete data. `Entire' refers to the result trained with the entire configuration space (up to 46656 teams), while random contains a subset of the configuration space.}
    \label{fig:computational_error}
\end{figure}

The average training times are listed in \tableref{} \ref{tab:random_test_cases}.
The computational time grows linearly with respect to the number of tasks and capabilities. For case 7 (the largest case), the average training times using the entire configuration space versus randomly selected subsets are 542 and 12 seconds, respectively. From this analysis, the learning model can easily scale to a mission comprised of 40 subtasks and 32 different capabilities. 
Considering the training time needed, the model can update the capability and requirement values every few seconds for real-time applications.
