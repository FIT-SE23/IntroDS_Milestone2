@string{TPAMI="IEEE Transactions on Pattern Analysis and Machine Intelligence"}
@string{CVPR="Conference on Computer Vision and Pattern Recognition (CVPR)"}
@string{ICCV="International Conference on Computer Vision (ICCV)"}
@string{ECCV="European Conference on Computer Vision (ECCV)"}
@string{NIPS="Advances in Neural Information Processing Systems (NeurIPS)"}
@string{ICLR="International Conference on Learning Representations (ICLR)"}
@string{ICML="International Conference on Machine Learning (ICML)"}
@string{IJCV="International Journal of Computer Vision (IJCV)"}
@string{AAAI="AAAI Conference on Artificial Intelligence (AAAI)"}
@string{IJCAI="International Joint Conference on Artificial Intelligence"}
@string{WACV="Winter Conference on Applications of Computer Vision (WACV)"}
@string{KDD="ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)"}
@string{ACL="Annual Meeting of the Association for Computational Linguistics (ACL)"}
@string{CVMJ="Computational Visual Media (CVMJ)"}

%%%%%%%%%%%%%%%%%%%%%%%%%% Classicial Baselines %%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{bahdanau2014neural,
	title={Neural machine translation by jointly learning to align and translate},
	author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	booktitle=ICLR,
	year={2015}
}

@article{Baker2018DeepCN,
  title={Deep convolutional networks do not classify based on global object shape},
  author={Nicholas Baker and Hongjing Lu and Gennady Erlikhman and Philip J. Kellman},
  journal={PLoS Computational Biology},
  year={2018},
  volume={14},
  number={12},
  pages={e1006613},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{Krizhevsky2012ImageNetCW,
  title={ImageNet classification with deep convolutional neural networks},
  author={Alex Krizhevsky and Ilya Sutskever and Geoffrey E. Hinton},
  journal={Communications of the ACM},
  year={2012},
  volume={60},
  pages={84 - 90}
}

@article{yamins2014performance,
  title={Performance-optimized hierarchical models predict neural responses in higher visual cortex},
  author={Yamins, Daniel LK and Hong, Ha and Cadieu, Charles F and Solomon, Ethan A and Seibert, Darren and DiCarlo, James J},
  journal={Proceedings of the national academy of sciences},
  volume={111},
  number={23},
  pages={8619--8624},
  year={2014},
  publisher={National Acad Sciences}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@inproceedings{cvpr2015sparse,
  author={Heide, Felix and Heidrich, Wolfgang and Wetzstein, Gordon},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Fast and flexible convolutional sparse coding}, 
  year={2015},
  pages={5135-5143},
}

@inproceedings{acmmm2016EfficientMI,
  title={Efficient Mobile Implementation of A CNN-based Object Recognition System},
  author={Keiji Yanai and Ryosuke Tanno and Koichi Okamoto},
  booktitle={Proceedings of the 24th ACM international conference on Multimedia (MM)},
  year={2016}
}

@inproceedings{iccv2017ChannelP,
  title={Channel Pruning for Accelerating Very Deep Neural Networks},
  author={Yihui He and Xiangyu Zhang and Jian Sun},
  booktitle=ICCV,
  year={2017},
  pages={1398-1406}
}

@inproceedings{hermann2020origins,
  title={The Origins and Prevalence of Texture Bias in Convolutional Neural Networks},
  author={Hermann, Katherine and Chen, Ting and Kornblith, Simon},
  booktitle=NIPS,
  volume={33},
  pages={19000--19015},
  year={2020}
}

@inproceedings{vaswani2017attention,
  title={Attention is All you Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle=NIPS,
  year={2017}
}

@inproceedings{dauphin2017language,
  title={Language modeling with gated convolutional networks},
  author={Dauphin, Yann N and Fan, Angela and Auli, Michael and Grangier, David},
  booktitle=ICML,
  pages={933--941},
  year={2017},
  organization={PMLR}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv:1810.04805},
  year={2018}
}

@inproceedings{iclr2020LiteTrans,
  title={Lite Transformer with Long-Short Range Attention},
  author={Zhanghao Wu and Zhijian Liu and Ji Lin and Yujun Lin and Song Han},
  booktitle=ICLR,
  year={2020}
}

@inproceedings{nips2020linformer,
  title={Linformer: Self-Attention with Linear Complexity},
  author={Sinong Wang and Belinda Z. Li and Madian Khabsa and Han Fang and Hao Ma},
  booktitle=NIPS,
  year={2021}
}

@inproceedings{nips2021SOFT,
  title={SOFT: Softmax-free Transformer with Linear Complexity},
  author={Jiachen Lu and Jinghan Yao and Junge Zhang and Xiatian Zhu and Hang Xu and Weiguo Gao and Chunjing Xu and Tao Xiang and Li Zhang},
  booktitle=NIPS,
  year={2021},
}

@inproceedings{iclr2022cosFormer,
  title={cosFormer: Rethinking Softmax in Attention},
  author={Zhen Qin and Weixuan Sun and Huicai Deng and Dongxu Li and Yunshen Wei and Baohong Lv and Junjie Yan and Lingpeng Kong and Yiran Zhong},
  booktitle=ICLR,
  year={2022},
}

@inproceedings{icml2022Flowformer,
  title={Flowformer: Linearizing Transformers with Conservation Flows},
  author={Haixu Wu and Jialong Wu and Jiehui Xu and Jianmin Wang and Mingsheng Long},
  booktitle=ICML,
  year={2022}
}

@article{Ramachandran2017Swish,
  title={Swish: a Self-Gated Activation Function},
  author={Prajit Ramachandran and Barret Zoph and Quoc V. Le},
  journal={arXiv: Neural and Evolutionary Computing},
  year={2017}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal=NIPS,
  year={2020}
}

@inproceedings{zheng2021delayed,
  title={Delayed Propagation Transformer: A universal computation engine towards practical control in cyber-physical systems},
  author={Zheng, Wenqing and Guo, Qiangqiang and Yang, Hao and Wang, Peihao and Wang, Zhangyang},
  booktitle=NIPS,
  year={2021}
}

@inproceedings{iclr2021vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle=ICLR,
  year={2021}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle=ECCV,
  year={2020}
}

@inproceedings{zhu2020deformable,
  title={Deformable detr: Deformable transformers for end-to-end object detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  booktitle=ICLR,
  year={2021}
}

@inproceedings{chen2021pre,
  title={Pre-trained image processing transformer},
  author={Chen, Hanting and Wang, Yunhe and Guo, Tianyu and Xu, Chang and Deng, Yiping and Liu, Zhenhua and Ma, Siwei and Xu, Chunjing and Xu, Chao and Gao, Wen},
  booktitle=CVPR,
  year={2021}
}

@inproceedings{parmar2018image,
  title={Image transformer},
  author={Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
  booktitle=ICML,
  year={2018}
}

@inproceedings{jiang2021transgan,
  title={Transgan: Two pure transformers can make one strong gan, and that can scale up},
  author={Jiang, Yifan and Chang, Shiyu and Wang, Zhangyang},
  booktitle=NIPS,
  year={2021}
}

@inproceedings{arnab2021vivit,
  title={Vivit: A video vision transformer},
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
  booktitle=ICCV,
  year={2021}
}

@inproceedings{liu2021swin,
  title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle=ICCV,
  year={2021}
}

@inproceedings{cvpr2022VideoSwin,
  title={Video Swin Transformer},
  author={Ze Liu and Jia Ning and Yue Cao and Yixuan Wei and Zheng Zhang and Stephen Lin and Han Hu},
  booktitle=CVPR,
  year={2022},
  pages={3192-3201}
}

@inproceedings{iccv2021Conformer,
  title={Conformer: Local Features Coupling Global Representations for Visual Recognition},
  author={Zhiliang Peng and Wei Huang and Shanzhi Gu and Lingxi Xie and Yaowei Wang and Jianbin Jiao and Qixiang Ye},
  booktitle=ICCV,
  year={2021},
  pages={357-366},
}

@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle=ICML,
  year={2021}
}

@inproceedings{yuan2021tokens,
  title={Tokens-to-token vit: Training vision transformers from scratch on imagenet},
  author={Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zihang and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
  booktitle=ICCV,
  year={2021}
}

@misc{rw2019timm,
  author = {Ross Wightman},
  title = {PyTorch image models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}

@misc{wightman2021rsb,
    title={ResNet strikes back: An improved training procedure in timm},
    author={Ross Wightman and Hugo Touvron and Hervé Jégou},
    year={2021},
    eprint={2110.00476},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    howpublished = {\url{https://github.com/huggingface/pytorch-image-models}},
}

@article{han2021demystifying,
  title={Demystifying Local Vision Transformer: Sparse Connectivity, Weight Sharing, and Dynamic Weight},
  author={Han, Qi and Fan, Zejia and Dai, Qi and Sun, Lei and Cheng, Ming-Ming and Liu, Jiaying and Wang, Jingdong},
  journal={arXiv:2106.04263},
  year={2021}
}

@inproceedings{icml2021deit,
    title = {Training data-efficient image transformers \& distillation through attention},
    author = {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and Jegou, Herve},
    booktitle = {International Conference on Machine Learning (ICML)},
    pages = {10347--10357},
    year = {2021},
}

@inproceedings{eccv2022deit3,
  title={DeiT III: Revenge of the ViT},
  author={Hugo Touvron and Matthieu Cord and Herv'e J'egou},
  booktitle=ECCV,
  year={2022},
}

@inproceedings{nips2021TL,
  title={All Tokens Matter: Token Labeling for Training Better Vision Transformers},
  author={Zihang Jiang and Qibin Hou and Li Yuan and Daquan Zhou and Yujun Shi and Xiaojie Jin and Anran Wang and Jiashi Feng},
  booktitle=NIPS,
  year={2021}
}

@inproceedings{iccv2021PVT,
  title={Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions},
  author={Wenhai Wang and Enze Xie and Xiang Li and Deng-Ping Fan and Kaitao Song and Ding Liang and Tong Lu and Ping Luo and Ling Shao},
  booktitle=ICCV,
  year={2021},
  pages={548-558}
}

@article{cvmj2022PVTv2,
  title={PVTv2: Improved Baselines with Pyramid Vision Transformer},
  author={Wenhai Wang and Enze Xie and Xiang Li and Deng-Ping Fan and Kaitao Song and Ding Liang and Tong Lu and Ping Luo and Ling Shao},
  journal={Computational Visual Media (CVMJ)},
  year={2022},
}

@article{2021patchconvnet,
  title={Augmenting Convolutional networks with attention-based aggregation},
  author={Hugo Touvron and Matthieu Cord and Alaaeldin El-Nouby and Piotr Bojanowski and Armand Joulin and Gabriel Synnaeve and Jakob Verbeek and Herv'e J'egou},
  journal={arXiv preprint arXiv:2112.13692},
  year={2021},
}

@inproceedings{cvpr2022convnext,
  title={A convnet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle=CVPR,
  pages={11976--11986},
  year={2022}
}
@inproceedings{Woo2023ConvNeXtV2,
  title={ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders},
  author={Sanghyun Woo and Shoubhik Debnath and Ronghang Hu and Xinlei Chen and Zhuang Liu and In-So Kweon and Saining Xie},
  booktitle=CVPR,
  year={2023},
}

@inproceedings{yu2022metaformer,
  title={Metaformer is actually what you need for vision},
  author={Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng},
  booktitle=CVPR,
  pages={10819--10829},
  year={2022}
}

@article{2022convmixer,
  title={Patches Are All You Need?},
  author={Asher Trockman and J. Zico Kolter},
  journal={ArXiv},
  year={2022},
  volume={abs/2201.09792}
}

@inproceedings{nips2021MLPMixer,
  title={MLP-Mixer: An all-MLP Architecture for Vision},
  author={Ilya O. Tolstikhin and Neil Houlsby and Alexander Kolesnikov and Lucas Beyer and Xiaohua Zhai and Thomas Unterthiner and Jessica Yung and Daniel Keysers and Jakob Uszkoreit and Mario Lucic and Alexey Dosovitskiy},
  booktitle=NIPS,
  year={2021}
}

@inproceedings{wu2021rethinking,
  title={Rethinking and improving relative position encoding for vision transformer},
  author={Wu, Kan and Peng, Houwen and Chen, Minghao and Fu, Jianlong and Chao, Hongyang},
  booktitle=ICCV,
  pages={10033--10041},
  year={2021}
}

@inproceedings{guo2021cmt,
  title={Cmt: Convolutional neural networks meet vision transformers},
  author={Guo, Jianyuan and Han, Kai and Wu, Han and Xu, Chang and Tang, Yehui and Xu, Chunjing and Wang, Yunhe},
  booktitle=CVPR,
  year={2022}
}

@article{wu2021cvt,
  title={Cvt: Introducing convolutions to vision transformers},
  author={Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},
  journal=ICCV,
  year={2021}
}

@article{d2021convit,
  title={Convit: Improving vision transformers with soft convolutional inductive biases},
  author={d'Ascoli, St{\'e}phane and Touvron, Hugo and Leavitt, Matthew and Morcos, Ari and Biroli, Giulio and Sagun, Levent},
  journal={arXiv preprint arXiv:2103.10697},
  year={2021}
}

@InProceedings{cvpr2009imagenet,
  author    = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  title     = {{ImageNet: A large-scale hierarchical image database}},
  booktitle = CVPR,
  year      = {2009},
}

@article{raghu2021vision,
  title={Do vision transformers see like convolutional neural networks?},
  author={Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
  journal=NIPS,
  volume={34},
  pages={12116--12128},
  year={2021}
}

@article{han2021transformer,
  title={Transformer in transformer},
  author={Han, Kai and Xiao, An and Wu, Enhua and Guo, Jianyuan and Xu, Chunjing and Wang, Yunhe},
  journal=NIPS,
  volume={34},
  pages={15908--15919},
  year={2021}
}

@inproceedings{fan2021multiscale,
  title={Multiscale vision transformers},
  author={Fan, Haoqi and Xiong, Bo and Mangalam, Karttikeya and Li, Yanghao and Yan, Zhicheng and Malik, Jitendra and Feichtenhofer, Christoph},
  booktitle=ICCV,
  pages={6824--6835},
  year={2021}
}

@article{wang2022anti,
  title={Anti-oversmoothing in deep vision transformers via the fourier domain analysis: From theory to practice},
  author={Wang, Peihao and Zheng, Wenqing and Chen, Tianlong and Wang, Zhangyang},
  journal=ICLR,
  year={2022}
}

@article{pinto2022impartial,
  title={An impartial take to the cnn vs transformer robustness contest},
  author={Pinto, Francesco and Torr, Philip HS and Dokania, Puneet K},
  journal= ECCV,
  year={2022}
}

@article{Shazeer2020GLU,
  title={GLU Variants Improve Transformer},
  author={Noam M. Shazeer},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.05202}
}

@inproceedings{icml2022FLASH,
  title={Transformer Quality in Linear Time},
  author={Weizhe Hua and Zihang Dai and Hanxiao Liu and Quoc V. Le},
  booktitle=ICML,
  year={2022}
}

%%%%%%%%%%%%%%%%%%%%%%%%%% CNNs %%%%%%%%%%%%%%%%%%%%%%%%%%
@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{Zeiler2014VisualizingAU,
  title={Visualizing and Understanding Convolutional Networks},
  author={Matthew D. Zeiler and Rob Fergus},
  booktitle=ECCV,
  year={2014}
}

@inproceedings{Simonyan2014TwoStreamCN,
  title={Two-Stream Convolutional Networks for Action Recognition in Videos},
  author={Karen Simonyan and Andrew Zisserman},
  booktitle=NIPS,
  year={2014}
}

@article{sifre2014rigid,
  title={Rigid-motion scattering for texture classification},
  author={Sifre, Laurent and Mallat, St{\'e}phane},
  journal={arXiv preprint arXiv:1403.1687},
  year={2014}
}

@article{hendrycks2016bridging,
  title={Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units},
  author={Dan Hendrycks and Kevin Gimpel},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}
  
@article{srivastava2015highway,
  title={Highway networks},
  author={Srivastava, Rupesh Kumar and Greff, Klaus and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1505.00387},
  year={2015}
}

@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle=CVPR,
  pages={1--9},
  year={2015}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle=CVPR,
  pages={770--778},
  year={2016}
}

@inproceedings{bmvc2016wrn,
  title={Wide Residual Networks}, 
  author={Sergey Zagoruyko and Nikos Komodakis},
  booktitle={Proceedings of the British Machine Vision Conference (BMVC)},
  year={2016}
}

@article{cvpr2016inceptionv3,
  title={Rethinking the Inception Architecture for Computer Vision},
  author={Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Zbigniew Wojna},
  journal=CVPR,
  year={2016},
  pages={2818-2826}
}

@article{Luo2016ERF,
  title={Understanding the Effective Receptive Field in Deep Convolutional Neural Networks},
  author={Wenjie Luo and Yujia Li and Raquel Urtasun and Richard S. Zemel},
  journal={ArXiv},
  year={2016},
  volume={abs/1701.04128}
}

@inproceedings{chollet2017xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Fran{\c{c}}ois},
  booktitle=CVPR,
  pages={1251--1258},
  year={2017}
}

@inproceedings{xie2017aggregated,
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle=CVPR,
  pages={1492--1500},
  year={2017}
}

@article{cheng2021game,
  title={A game-theoretic taxonomy of visual concepts in dnns},
  author={Cheng, Xu and Chu, Chuntung and Zheng, Yi and Ren, Jie and Zhang, Quanshi},
  journal={arXiv preprint arXiv:2106.10938},
  year={2021}
}

@inproceedings{iccv2017Deformable,
  title={Deformable Convolutional Networks},
  author={Jifeng Dai and Haozhi Qi and Yuwen Xiong and Yi Li and Guodong Zhang and Han Hu and Yichen Wei},
  booktitle=ICCV,
  year={2017},
  pages={764-773}
}

@inproceedings{eccv2018CBAM,
  title={CBAM: Convolutional Block Attention Module},
  author={Sanghyun Woo and Jongchan Park and Joon-Young Lee and In-So Kweon},
  booktitle=ECCV,
  year={2018}
}

@inproceedings{iccv2019GCNet,
  title={GCNet: Non-Local Networks Meet Squeeze-Excitation Networks and Beyond},
  author={Yue Cao and Jiarui Xu and Stephen Lin and Fangyun Wei and Han Hu},
  booktitle={International Conference on Computer Vision Workshop (ICCVW)},
  year={2019},
  pages={1971-1980}
}

@inproceedings{cvpr2020Dynamic,
  title={Dynamic Convolution: Attention Over Convolution Kernels},
  author={Yinpeng Chen and Xiyang Dai and Mengchen Liu and Dongdong Chen and Lu Yuan and Zicheng Liu},
  booktitle=CVPR,
  year={2020},
  pages={11027-11036}
}

@inproceedings{iclr2021RevisitingDC,
  title={Revisiting Dynamic Convolution via Matrix Decomposition},
  author={Yunsheng Li and Yinpeng Chen and Xiyang Dai and Mengchen Liu and Dongdong Chen and Ye Yu and Lu Yuan and Zicheng Liu and Mei Chen and Nuno Vasconcelos},
  booktitle=ICLR,
  year={2021},
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle=ICML,
  pages={448--456},
  year={2015},
  organization={PMLR}
}

@inproceedings{iclr2016dilated,
  title={Multi-Scale Context Aggregation by Dilated Convolutions},
  author={Fisher Yu and Vladlen Koltun},
  booktitle=ICLR,
  year={2016},
}

@inproceedings{wang2018non,
  title={Non-local neural networks},
  author={Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
  booktitle=CVPR,
  pages={7794--7803},
  year={2018}
}

@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle=CVPR,
  pages={7132--7141},
  year={2018}
}

@article{elfwing2018sigmoid,
  title={Sigmoid-weighted linear units for neural network function approximation in reinforcement learning},
  author={Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
  journal={Neural Networks},
  volume={107},
  pages={3--11},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{cvpr2020regnet,
  title={Designing Network Design Spaces},
  author={Ilija Radosavovic and Raj Prateek Kosaraju and Ross B. Girshick and Kaiming He and Piotr Doll{\'a}r},
  booktitle=CVPR,
  year={2020},
  pages={10425-10433}
}

@inproceedings{cvpr2020Orthogonal,
  title={Orthogonal Convolutional Neural Networks},
  author={Jiayun Wang and Yubei Chen and Rudrasis Chakraborty and Stella X. Yu},
  booktitle=CVPR,
  year={2020},
  pages={11502-11512}
}


%%%%%%%%%%%%%%%%%%%%%%%%%% Light Architectures %%%%%%%%%%%%%%%%%%%%%%%%%%
@article{2017MobileNet,
  title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
  author={Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
  journal={ArXiv},
  year={2017},
  volume={abs/1704.04861}
}

@inproceedings{cvpr2018mobilenetv2,
  title={MobileNetV2: Inverted Residuals and Linear Bottlenecks},
  author={Mark Sandler and Andrew G. Howard and Menglong Zhu and Andrey Zhmoginov and Liang-Chieh Chen},
  booktitle=CVPR,
  year={2018},
  pages={4510-4520}
}

@inproceedings{iccv2019mobilenetv3,
    title={Searching for mobilenetv3},
    author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
    booktitle=ICCV,
    pages={1314--1324},
    year={2019}
}

@inproceedings{cvpr2018shufflenetv1,
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle=CVPR,
  pages={6848--6856},
  year={2018}
}

@inproceedings{eccv2018shufflenet,
    title={Shufflenet v2: Practical guidelines for efficient cnn architecture design},
    author={Ma, Ningning and Zhang, Xiangyu and Zheng, Hai-Tao and Sun, Jian},
    booktitle=ECCV,
    pages={116--131},
    year={2018}
}

@inproceedings{icml2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning (ICML)},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@inproceedings{icml2021EfficientNetV2,
  title={EfficientNetV2: Smaller Models and Faster Training},
  author={Mingxing Tan and Quoc V. Le},
  booktitle={International conference on machine learning (ICML)},
  year={2021},
}

@inproceedings{nips2021vitc,
  title={Early Convolutions Help Transformers See Better},
  author={Tete Xiao and Mannat Singh and Eric Mintun and Trevor Darrell and Piotr Doll{\'a}r and Ross B. Girshick},
  booktitle=NIPS,
  year={2021}
}

@inproceedings{iclr2022local,
  title={On the Connection between Local Attention and Dynamic Depth-wise Convolution},
  author={Qi Han and Zejia Fan and Qi Dai and Lei Sun and Ming-Ming Cheng and Jiaying Liu and Jingdong Wang},
  booktitle=ICLR,
  year={2022}
}

@inproceedings{iccv2021levit,
  title={Levit: a vision transformer in convnet's clothing for faster inference},
  author={Graham, Benjamin and El-Nouby, Alaaeldin and Touvron, Hugo and Stock, Pierre and Joulin, Armand and J{\'e}gou, Herv{\'e} and Douze, Matthijs},
  booktitle=ICCV,
  pages={12259--12269},
  year={2021}
}

@inproceedings{nips2021Twins,
  title={Twins: Revisiting the Design of Spatial Attention in Vision Transformers},
  author={Xiangxiang Chu and Zhi Tian and Yuqing Wang and Bo Zhang and Haibing Ren and Xiaolin Wei and Huaxia Xia and Chunhua Shen},
  booktitle=NIPS,
  year={2021}
}

@inproceedings{iccv2021coat,
  title={Micronet: Improving image recognition with extremely low flops},
  author={Li, Yunsheng and Chen, Yinpeng and Dai, Xiyang and Chen, Dongdong and Liu, Mengchen and Yuan, Lu and Liu, Zicheng and Zhang, Lei and Vasconcelos, Nuno},
  booktitle=ICCV,
  pages={468--477},
  year={2021}
}

@inproceedings{iccv2021pit,
    title={Rethinking spatial dimensions of vision transformers},
    author={Heo, Byeongho and Yun, Sangdoo and Han, Dongyoon and Chun, Sanghyuk and Choe, Junsuk and Oh, Seong Joon},
    booktitle=ICCV,
    pages={11936--11945},
    year={2021}
}
@inproceedings{iclr2022mobilevit,
    title={Mobilevit: light-weight, general-purpose, and mobile-friendly vision transformer},
    author={Mehta, Sachin and Rastegari, Mohammad},
    booktitle=ICLR,
    year={2022}
}

@inproceedings{iclr2022uniformer,
title={Uniformer: Unifying convolution and self-attention for visual recognition},
author={Li, Kunchang and Wang, Yali and Zhang, Junhao and Gao, Peng and Song, Guanglu and Liu, Yu and Li, Hongsheng and Qiao, Yu},
booktitle=ICLR,
year={2022}
}

@inproceedings{nips2021hrformer,
  title={HRFormer: High-Resolution Transformer for Dense Prediction},
  author={Yuhui Yuan and Rao Fu and Lang Huang and Weihong Lin and Chao Zhang and Xilin Chen and Jingdong Wang},
  booktitle=NIPS,
  year={2021}
}

@inproceedings{eccv2018simple,
    author={Xiao, Bin and Wu, Haiping and Wei, Yichen},
    title={Simple Baselines for Human Pose Estimation and Tracking},
    booktitle = {European Conference on Computer Vision (ECCV)},
    year = {2018}
}

@inproceedings{cvpr2022MobileFormer,
  title={Mobile-Former: Bridging MobileNet and Transformer},
  author={Yinpeng Chen and Xiyang Dai and Dongdong Chen and Mengchen Liu and Xiaoyi Dong and Lu Yuan and Zicheng Liu},
  booktitle=CVPR,
  year={2022},
}

@inproceedings{eccv2022edgeformer,
  title={EdgeFormer: Improving Light-weight ConvNets by Learning from Vision Transformers},
  author={Zhang, Haokui and Hu, Wenze and Wang, Xiaoyu},
  booktitle=ECCV,
  year={2022}
}

@inproceedings{eccv2022tinyvit,
  title={TinyViT: Fast Pretraining Distillation for Small Vision Transformers},
  author={Wu, Kan and Zhang, Jinnian and Peng, Houwen and Liu, Mengchen and Xiao, Bin and Fu, Jianlong and Yuan, Lu},
  booktitle={European conference on computer vision (ECCV)},
  year={2022}
}

@inproceedings{nips2022EfficientFormer,
  title={EfficientFormer: Vision Transformers at MobileNet Speed},
  author={Yanyu Li and Geng Yuan and Yang Wen and Eric Hu and Georgios Evangelidis and S. Tulyakov and Yanzhi Wang and Jian Ren},
  booktitle=NIPS,
  year={2022},
}

@article{guo2022van,
  title={Visual Attention Network},
  author={Guo, Meng-Hao and Lu, Cheng-Ze and Liu, Zheng-Ning and Cheng, Ming-Ming and Hu, Shi-Min},
  journal={Computational Visual Media (CVMJ)},
  pages={733–-752},
  year={2023},
}

@inproceedings{Chen2022CFViT,
  title={CF-ViT: A General Coarse-to-Fine Method for Vision Transformer},
  author={Mengzhao Chen and Mingbao Lin and Ke Li and Yunhang Shen and Yongjian Wu and Fei Chao and Rongrong Ji},
  booktitle=AAAI,
  year={2023},
}

@article{Lin2022SuperViT,
  title={Super Vision Transformer},
  author={Mingbao Lin and Mengzhao Chen and Yu-xin Zhang and Ke Li and Yunhang Shen and Chunhua Shen and Rongrong Ji},
  journal={ArXiv},
  year={2022},
  volume={abs/2205.11397}
}

%%%%%%%%%%%%%%%%%%%%%%%%%% Base Architectures %%%%%%%%%%%%%%%%%%%%%%%%%%
@article{cvpr2021botnet,
  title={Bottleneck Transformers for Visual Recognition},
  author={A. Srinivas and Tsung-Yi Lin and Niki Parmar and Jonathon Shlens and P. Abbeel and Ashish Vaswani},
  journal=CVPR,
  year={2021},
  pages={16514-16524}
}

@article{iccv2021t2t,
  title={Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet},
  author={Li Yuan and Yunpeng Chen and Tao Wang and Weihao Yu and Yujun Shi and Francis E. H. Tay and Jiashi Feng and Shuicheng Yan},
  journal=ICCV,
  year={2021},
  pages={538-547}
}

@inproceedings{cvpr2022replknet,
  title={Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs},
  author={Xiaohan Ding and X. Zhang and Yi Zhou and Jungong Han and Guiguang Ding and Jian Sun},
  booktitle=CVPR,
  year={2022}
}

@inproceedings{Liu2022SLak,
  title={More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity},
  author={S. Liu and Tianlong Chen and Xiaohan Chen and Xuxi Chen and Qiao Xiao and Boqian Wu and Mykola Pechenizkiy and Decebal Constantin Mocanu and Zhangyang Wang},
  booktitle=ICLR,
  year={2023},
}

@inproceedings{iccv2023Oriented1D,
  title={Convolutional Networks with Oriented 1D Kernels},
  author={Kirchmeyer, Alexandre and Deng, Jia},
  booktitle=ICCV,
  year={2023}
}

@inproceedings{eccv2022SReT,
  title={Sliced recursive transformer},
  author={Shen, Zhiqiang and Liu, Zechun and Xing, Eric},
  booktitle=ECCV,
  year={2022},
}

@inproceedings{eccv2022MaxViT,
  title={MaxViT: Multi-Axis Vision Transformer},
  author={Zhengzhong Tu and Hossein Talebi and Han Zhang and Feng Yang and Peyman Milanfar and Alan Conrad Bovik and Yinxiao Li},
  booktitle=ECCV,
  year={2022},
}

@inproceedings{cvpr2022resnest,
  title={Resnest: Split-attention networks},
  author={Zhang, Hang and Wu, Chongruo and Zhang, Zhongyue and Zhu, Yi and Lin, Haibin and Zhang, Zhi and Sun, Yue and He, Tong and Mueller, Jonas and Manmatha, R and others},
  booktitle=CVPR,
  pages={2736--2746},
  year={2022}
}

@article{nips2021vitae,
  title={Vitae: Vision transformer advanced by exploring intrinsic inductive bias},
  author={Xu, Yufei and Zhang, Qiming and Zhang, Jing and Tao, Dacheng},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={34},
  year={2021}
}

@article{nips2021coatnet,
    title={Coatnet: Marrying convolution and attention for all data sizes},
    author={Dai, Zihang and Liu, Hanxiao and Le, Quoc V and Tan, Mingxing},
    journal={Advances in Neural Information Processing Systems (NeurIPS)},
    volume={34},
    pages={3965--3977},
    year={2021}
}

@inproceedings{nips2021Focal,
  title={Focal Self-attention for Local-Global Interactions in Vision Transformers},
  author={Jianwei Yang and Chunyuan Li and Pengchuan Zhang and Xiyang Dai and Bin Xiao and Lu Yuan and Jianfeng Gao},
  booktitle=NIPS,
  year={2021},
}

@inproceedings{nips2021DVT,
  title={Not All Images are Worth 16x16 Words: Dynamic Transformers for Efficient Image Recognition},
  author={Yulin Wang and Rui Huang and Shiji Song and Zeyi Huang and Gao Huang},
  booktitle=NIPS,
  year={2021},
}

@inproceedings{cvpr2022AViT,
  author={Yin, Hongxu and Vahdat, Arash and Alvarez, Jose M. and Mallya, Arun and Kautz, Jan and Molchanov, Pavlo},
  booktitle=CVPR, 
  title={A-ViT: Adaptive Tokens for Efficient Vision Transformer}, 
  pages={10799-10808},
  year={2022},
}

@inproceedings{aaai2022shiftvit,
  title={When Shift Operation Meets Vision Transformer: An Extremely Simple Alternative to Attention Mechanism},
  author={Guangting Wang and Yucheng Zhao and Chuanxin Tang and Chong Luo and Wenjun Zeng},
  booktitle=AAAI,
  year={2022}
}

@inproceedings{cvpr2022CSWin,
    title={CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows},
    author={Xiaoyi Dong and Jianmin Bao and Dongdong Chen and Weiming Zhang and Nenghai Yu and Lu Yuan and Dong Chen and Baining Guo},
    booktitle=CVPR,
    year={2022}
}

@inproceedings{aaai2022LIT,
  title={Less is More: Pay Less Attention in Vision Transformers},
  author={Zizheng Pan and Bohan Zhuang and Haoyu He and Jing Liu and Jianfei Cai},
  booktitle=AAAI,
  year={2022},
}

@inproceedings{nips2022hilo,
  title={Fast Vision Transformers with HiLo Attention},
  author={Pan, Zizheng and Cai, Jianfei and Zhuang, Bohan},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022},
}

@inproceedings{nips2022hornet,
    title={HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions},
    author={Yongming Rao and Wenliang Zhao and Yansong Tang and Jie Zhou and Ser Nam Lim and Jiwen Lu},
    booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
    year={2022},
}

@inproceedings{nips2022iformer,
  title={Inception Transformer},
  author={Chenyang Si and Weihao Yu and Pan Zhou and Yichen Zhou and Xinchao Wang and Shuicheng Yan},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022},
}

@inproceedings{nips2022focalnet,
  title={Focal Modulation Networks}, 
  author={Jianwei Yang and Chunyuan Li and Xiyang Dai and Jianfeng Gao},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}

@article{Hou2022Conv2Former,
  title={Conv2Former: A Simple Transformer-Style ConvNet for Visual Recognition},
  author={Qibin Hou and Cheng Lu and Mingg-Ming Cheng and Jiashi Feng},
  journal={ArXiv},
  year={2022},
  volume={abs/2211.11943},
}

%%%%%%%%%%%%%%%%%%%%%%%%%% Datasets and Benchmarks %%%%%%%%%%%%%%%%%%%%%%%%%%
@article{treisman1980feature,
  title={A feature-integration theory of attention},
  author={Treisman, Anne M and Gelade, Garry},
  journal={Cognitive psychology},
  volume={12},
  number={1},
  pages={97--136},
  year={1980},
  publisher={Elsevier}
}

@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}

@inproceedings{2014MicrosoftCOCO,
  title={Microsoft COCO: Common Objects in Context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle=ECCV,
  pages={740--755},
  year={2014},
  organization={Springer}
}

@misc{mmdetection,
  title   = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark},
  author  = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and
             Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and
             Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and
             Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and
             Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong
             and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},
  journal= {arXiv preprint arXiv:1906.07155},
  year={2019},
  howpublished = {\url{https://github.com/open-mmlab/mmdetection}},
}

@article{tpami2015faster,
  title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
  author={Shaoqing Ren and Kaiming He and Ross B. Girshick and Jian Sun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  year={2015},
  volume={39},
  pages={1137-1149}
}

@inproceedings{cvpr2017fpn,
  title={Feature Pyramid Networks for Object Detection},
  author={Tsung-Yi Lin and Piotr Doll{\'a}r and Ross B. Girshick and Kaiming He and Bharath Hariharan and Serge J. Belongie},
  booktitle=CVPR,
  year={2017},
  pages={936-944}
}

@inproceedings{2017iccvmaskrcnn,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle=ICCV,
  year={2017}
}

@inproceedings{iccv2017retinanet,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle=ICCV,
  year={2017}
}

@article{tpami2019cascade,
   title={Cascade R-CNN: High-Quality Object Detection and Instance Segmentation},
   ISSN={1939-3539},
   journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Cai, Zhaowei and Vasconcelos, Nuno},
   year={2019},
}

@inproceedings{cvpr2019semanticFPN,
  title={Panoptic Feature Pyramid Networks},
  author={Alexander Kirillov and Ross B. Girshick and Kaiming He and Piotr Doll{\'a}r},
  booktitle=CVPR,
  year={2019},
  pages={6392-6401}
}

@inproceedings{eccv2020rsn,
    title={Learning Delicate Local Representations for Multi-Person Pose Estimation},
    author={Yuanhao Cai and Zhicheng Wang and Zhengxiong Luo and Binyi Yin and Angang Du and Haoqian Wang and Xinyu Zhou and Erjin Zhou and Xiangyu Zhang and Jian Sun},
    year={2020},
    booktitle=ECCV,
}

@inproceedings{cvpr2019hrnet,
  title={Deep high-resolution representation learning for human pose estimation},
  author={Sun, Ke and Xiao, Bin and Liu, Dong and Wang, Jingdong},
  booktitle=CVPR,
  pages={5693--5703},
  year={2019}
}

@article{Zhou2018ADE20k,
  title={Semantic Understanding of Scenes Through the ADE20K Dataset},
  author={Bolei Zhou and Hang Zhao and Xavier Puig and Sanja Fidler and Adela Barriuso and Antonio Torralba},
  journal={International Journal of Computer Vision (IJCV)},
  year={2018},
  volume={127},
  pages={302-321}
}

@inproceedings{eccv2018upernet,
  title={Unified Perceptual Parsing for Scene Understanding},
  author={Xiao, Tete and Liu, Yingcheng and Zhou, Bolei and Jiang, Yuning and Sun, Jian},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2018},
  organization={Springer}
}

@inproceedings{iclr2014adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Diederik P. Kingma and Jimmy Ba},
  booktitle=ICLR,
  year = {2014}
}

@InProceedings{iclr2019AdamW,
  title={Decoupled Weight Decay Regularization}, 
  author={Ilya Loshchilov and Frank Hutter},
  booktitle=ICLR, 
  year = {2019}
}

@InProceedings{iclr2020lamb,
  title = {Large Batch Optimization for Deep Learning: Training {BERT} in 76 minutes}, 
  author = {Yang You and  Jing Li and  Sashank Reddi and Jonathan Hseu and  Sanjiv Kumar and  Srinadh Bhojanapalli and Xiaodan Song and James Demmel and  Kurt Keutzer and Cho-Jui Hsieh}, 
  booktitle=ICLR, 
  year = {2020}
}

@inproceedings{eccv2016droppath,
  title={Deep Networks with Stochastic Depth},
  author={Gao Huang and Yu Sun and Zhuang Liu and Daniel Sedra and Kilian Q. Weinberger},
  booktitle=ECCV,
  year={2016}
}

@inproceedings{cvpr2020repeat,
  author={Hoffer, Elad and Ben-Nun, Tal and Hubara, Itay and Giladi, Niv and Hoefler, Torsten and Soudry, Daniel},
  booktitle=CVPR, 
  title={Augment Your Batch: Improving Generalization Through Instance Repetition}, 
  year={2020},
  pages={8126-8135},
}

@article{siam1992ema,
  title={Acceleration of stochastic approximation by averaging},
  author={Boris Polyak and Anatoli B. Juditsky},
  journal={Siam Journal on Control and Optimization},
  year={1992},
  volume={30},
  pages={838-855}
}

@inproceedings{zhang2017mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  booktitle=ICLR,
  year={2018}
}

@inproceedings{yun2019cutmix,
  title={Cutmix: Regularization strategy to train strong classifiers with localizable features},
  author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
  booktitle=ICCV,
  pages={6023--6032},
  year={2019}
}

@inproceedings{cubuk2020randaugment,
  title={Randaugment: Practical automated data augmentation with a reduced search space},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  pages={702--703},
  year={2020}
}

@article{cvpr2019AutoAugment,
  title={AutoAugment: Learning Augmentation Strategies From Data},
  author={Ekin Dogus Cubuk and Barret Zoph and Dandelion Man{\'e} and Vijay Vasudevan and Quoc V. Le},
  journal=CVPR,
  year={2019},
  pages={113-123},
}

@inproceedings{zhong2020random,
  title={Random erasing data augmentation},
  author={Zhong, Zhun and Zheng, Liang and Kang, Guoliang and Li, Shaozi and Yang, Yi},
  booktitle=AAAI,
  pages={13001--13008},
  year={2020}
}

@inproceedings{eccv2022AutoMix,
  title={AutoMix: Unveiling the Power of Mixup for Stronger Classifiers},
  author={Zicheng Liu and Siyuan Li and Di Wu and Zhiyuan Chen and Lirong Wu and Jianzhu Guo and Stan Z. Li},
  booktitle=ECCV,
  year={2022},
}

@article{Li2021SAMix,
  title={Boosting Discriminative Visual Representation Learning with Scenario-Agnostic Mixup},
  author={Siyuan Li and Zicheng Liu and Zedong Wang and Di Wu and Zihan Liu and Stan Z. Li},
  journal={ArXiv},
  year={2021},
  volume={abs/2111.15454}
}

@article{2022decouplemix,
  author = {Liu, Zicheng and Li, Siyuan and Wang, Ge and Tan, Cheng and Wu, Lirong and Li, Stan Z.},
  title = {Decoupled Mixup for Data-efficient Learning},
  journal={ArXiv},
  volume={abs/2203.10761},
  year = {2022},
}

@inproceedings{iclr2024semireward,
  title={SemiReward: A General Reward Model for Semi-supervised Learning},
  author={Siyuan Li and Weiyang Jin and Zedong Wang and Fang Wu and Zicheng Liu and Cheng Tan and Stan Z. Li},
  booktitle=ICLR,
  year={2024}
}

@inproceedings{iclr2024adautomix,
  title={Adversarial AutoMixup},
  author={Huafeng Qin and Xin Jin and Yun Jiang and Moun{\^i}m A. El-Yacoubi and Xinbo Gao},
  booktitle=ICLR,
  year={2024}
}

@inproceedings{cvpr2022ReflashDIS,
  title={Reflash Dropout in Image Super-Resolution},
  author={Xiangtao Kong and Xina Liu and Jinjin Gu and Y. Qiao and Chao Dong},
  booktitle=CVPR,
  year={2022},
  pages={5992-6002},
}

@inproceedings{cvpr2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle=CVPR,
  pages={618--626},
  year={2017}
}

@inproceedings{ancona2019explaining,
  title={Explaining deep neural networks with a polynomial time algorithm for shapley value approximation},
  author={Ancona, Marco and Oztireli, Cengiz and Gross, Markus},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={272--281},
  year={2019},
  organization={PMLR}
}

@inproceedings{iclr2019shapebias,
  title={ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness},
  author={Robert Geirhos and Patricia Rubisch and Claudio Michaelis and Matthias Bethge and Felix Wichmann and Wieland Brendel},
  booktitle=ICLR,
  year={2019},
}

@article{2021shapebias,
  title={Are Convolutional Neural Networks or Transformers more like human vision?},
  author={Shikhar Tuli and Ishita Dasgupta and Erin Grant and Thomas L. Griffiths},
  journal={ArXiv},
  year={2021},
  volume={abs/2105.07197}
}

@inproceedings{nips2021partial,
  title={Partial success in closing the gap between human and machine vision},
  author={Geirhos, Robert and Narayanappa, Kantharaju and Mitzkus, Benjamin and Thieringer, Tizian and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021},
}

@inproceedings{naseer2021intriguing,
  title={Intriguing properties of vision transformers},
  author={Naseer, Muhammad Muzammal and Ranasinghe, Kanchana and Khan, Salman H and Hayat, Munawar and Shahbaz Khan, Fahad and Yang, Ming-Hsuan},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021}
}

@article{zhang2020interpreting,
  title={Interpreting and boosting dropout from a game-theoretic view},
  author={Zhang, Hao and Li, Sen and Ma, Yinchao and Li, Mingjie and Xie, Yichen and Zhang, Quanshi},
  journal={arXiv preprint arXiv:2009.11729},
  year={2020},
}

@inproceedings{icml2019explaining,
  title={Explaining deep neural networks with a polynomial time algorithm for shapley value approximation},
  author={Ancona, Marco and Oztireli, Cengiz and Gross, Markus},
  booktitle=ICML,
  pages={272--281},
  year={2019},
}

@inproceedings{deng2021discovering,
  title={Discovering and Explaining the Representation Bottleneck of DNNs},
  author={Deng, Huiqi and Ren, Qihan and Chen, Xu and Zhang, Hao and Ren, Jie and Zhang, Quanshi},
  booktitle=ICLR,
  year={2022}
}

@article{Wu2022DiscoveringTR,
  title={Discovering the Representation Bottleneck of Graph Neural Networks from Multi-order Interactions},
  author={Fang Wu and Siyuan Li and Lirong Wu and Stan Z. Li and Dragomir R. Radev and Qian Zhang},
  journal={ArXiv},
  year={2022},
  volume={abs/2205.07266},
}

@inproceedings{iclr2022how,
  title={How Do Vision Transformers Work?},
  author={Park, Namuk and Kim, Songkuk},
  booktitle=ICLR,
  year={2022}
}

@inproceedings{icml2022FAN,
  title={Understanding The Robustness in Vision Transformers},
  author={Daquan Zhou and Zhiding Yu and Enze Xie and Chaowei Xiao and Anima Anandkumar and Jiashi Feng and Jos{\'e} Manuel {\'A}lvarez},
  booktitle=ICML,
  year={2022}
}

@inproceedings{ding2022repmlpnet,
  title={Repmlpnet: Hierarchical vision mlp with re-parameterized locality},
  author={Ding, Xiaohan and Chen, Honghao and Zhang, Xiangyu and Han, Jungong and Ding, Guiguang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={578--587},
  year={2022}
}

@inproceedings{nips2020byol,
  title={Bootstrap your own latent: A new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre H and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Avila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and others},
  year={2020},
  booktitle=NIPS,
}

@inproceedings{iccv2021dino,
  title={Emerging Properties in Self-Supervised Vision Transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J\'egou, Herv\'e  and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle=ICCV,
  year={2021}
}

@inproceedings{cvpr2022mae,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle=CVPR,
  year={2022}
}
@inproceedings{bao2021beit,
  title={Beit: Bert pre-training of image transformers},
  author={Bao, Hangbo and Dong, Li and Wei, Furu},
  booktitle=ICLR,
  year={2022}
}

@article{wu2022bottleneck,
  title={Discovering the Representation Bottleneck of Graph Neural Networks from Multi-order Interactions},
  author={Wu, Fang and Li, Siyuan and Wu, Lirong and Li, Stan Z and Radev, Dragomir and Zhang, Qiang},
  journal={arXiv preprint arXiv:2205.07266},
  year={2022}
}

@inproceedings{acl2019Learning,
  title={Learning Deep Transformer Models for Machine Translation},
  author={Qiang Wang and Bei Li and Tong Xiao and Jingbo Zhu and Changliang Li and Derek F. Wong and Lidia S. Chao},
  booktitle=ACL,
  year={2019}
}

@article{zhou2021ibot,
  title={ibot: Image bert pre-training with online tokenizer},
  author={Zhou, Jinghao and Wei, Chen and Wang, Huiyu and Shen, Wei and Xie, Cihang and Yuille, Alan and Kong, Tao},
  journal={arXiv preprint arXiv:2111.07832},
  year={2021}
}

@inproceedings{cvpr2020moco,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle=CVPR,
  pages={9729--9738},
  year={2020}
}
@inproceedings{zang2022dlme,
    title={DLME: Deep Local-flatness Manifold Embedding},
    author={Zang, Zelin and Li, Siyuan and Wu, Di and Wang, Ge and Shang, Lei and Sun, Baigui and Li, Hao and Li, Stan Z.},
    booktitle=ECCV,
    year={2022}
}
@article{tnnls2023genurl,
    title={GenURL: A General Framework for Unsupervised Representation Learning},
    author={Li, Siyuan Liu, Zicheng and Zang, Zelin and Wu, Di and Chen, Zhiyuan and Li, Stan Z.},
    journal={IEEE Transactions on Neural Networks and Learning Systems},
    year={2023}
}


@inproceedings{li2022A2MIM,
  title={Architecture-Agnostic Masked Image Modeling - From ViT back to CNN},
  author={Siyuan Li and Di Wu and Fang Wu and Zelin Zang and Stan.Z.Li},
  booktitle = ICML,
  year = {2023},
}
@article{Li2023MIMSurvey,
  title={Masked Modeling for Self-supervised Representation Learning on Vision and Beyond},
  author={Siyuan Li and Luyuan Zhang and Zedong Wang and Di Wu and Lirong Wu and Zicheng Liu and Jun Xia and Cheng Tan and Yang Liu and Baigui Sun and Stan Z. Li},
  journal={ArXiv},
  year={2023},
  volume={abs/2401.00897},
}

@inproceedings{nips2019pytorch,
    title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
    author = {Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Köpf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
    booktitle = NIPS,
    year = {2019},
}

@inproceedings{nips2015batchnorm,
  title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author={Sergey Ioffe and Christian Szegedy},
  booktitle = NIPS,
  year={2015},
}

@inproceedings{iclr2021characterizing,
  author={Andrew Brock and Soham De and Samuel L. Smith},
  title={Characterizing signal propagation to close the performance gap in
  unnormalized ResNets},
  booktitle=ICLR,
  year={2021}
}

@article{Brock2021NFNet,
  title={High-Performance Large-Scale Image Recognition Without Normalization},
  author={Andrew Brock and Soham De and Samuel L. Smith and Karen Simonyan},
  journal={ArXiv},
  year={2021},
  volume={abs/2102.06171}
}

%%%%%%%%%%%% Norm and Bnechmarks %%%%%%%%%%%%%
@article{2016layernorm,
  title={Layer Normalization},
  author={Jimmy Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
  journal={ArXiv},
  year={2016},
  volume={abs/1607.06450}
}

@inproceedings{cvpr2018SyncBN,
  title={MegDet: A Large Mini-Batch Object Detector},
  author={Chao Peng and Tete Xiao and Zeming Li and Yuning Jiang and Xiangyu Zhang and Kai Jia and Gang Yu and Jian Sun},
  booktitle=CVPR,
  year={2018},
  pages={6181-6189}
}

@inproceedings{NIPS2017GhostBN,
  title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  author={Elad Hoffer and Itay Hubara and Daniel Soudry},
  booktitle=NIPS,
  year={2017},
}

@article{Wu2021PreciseBN,
  title={Rethinking "Batch" in BatchNorm},
  author={Yuxin Wu and Justin Johnson},
  journal={ArXiv},
  year={2021},
  volume={abs/2105.07576}
}

@misc{mmseg2020,
    title={{MMSegmentation}: OpenMMLab Semantic Segmentation Toolbox and Benchmark},
    author={MMSegmentation Contributors},
    howpublished = {\url{https://github.com/open-mmlab/mmsegmentation}},
    year={2020}
}

@misc{mmpose2020,
    title={OpenMMLab Pose Estimation Toolbox and Benchmark},
    author={MMPose Contributors},
    howpublished = {\url{https://github.com/open-mmlab/mmpose}},
    year={2020}
}

@misc{mmhuman3d,
    title={OpenMMLab 3D Human Parametric Model Toolbox and Benchmark},
    author={MMHuman3D Contributors},
    howpublished = {\url{https://github.com/open-mmlab/mmhuman3d}},
    year={2021}
}

@inproceedings{eccv2020ExPose,
  title = {Monocular Expressive Body Regression through Body-Driven Attention},
  author = {Choutas, Vasileios and Pavlakos, Georgios and Bolkart, Timo and Tzionas, Dimitrios and Black, Michael J.},
  booktitle = {European Conference on Computer Vision (ECCV)},
  pages = {20--40},
  year = {2020},
}

@inproceedings{feng2018evaluation,
  title={Evaluation of dense 3D reconstruction from 2D face images in the wild},
  author={Feng, Zhen-Hua and Huber, Patrik and Kittler, Josef and Hancock, Peter and Wu, Xiao-Jun and Zhao, Qijun and Koppen, Paul and R{\"a}tsch, Matthias},
  booktitle={2018 13th IEEE International Conference on Automatic Face \& Gesture Recognition (FG 2018)},
  pages={780--786},
  year={2018},
  organization={IEEE}
}

@inproceedings{cvpr2019ffhq,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle=CVPR,
  pages={4401--4410},
  year={2019}
}

@inproceedings{iccv2019freihand,
  title={Freihand: A dataset for markerless capture of hand pose and shape from single rgb images},
  author={Zimmermann, Christian and Ceylan, Duygu and Yang, Jimei and Russell, Bryan and Argus, Max and Brox, Thomas},
  booktitle=ICCV,
  pages={813--822},
  year={2019}
}

@misc{li2022openmixup,
    title={OpenMixup: Open Mixup Toolbox and Benchmark for Visual Representation Learning},
    author={Li, Siyuan and Wang, Zedong and Liu, Zicheng and Wu, Di and Stan Z. Li},
    year={2022},
    eprint={2209.04851},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    howpublished = {\url{https://github.com/Westlake-AI/openmixup}},
}

@inproceedings{tan2023openstl,
  title={OpenSTL: A Comprehensive Benchmark of Spatio-Temporal Predictive Learning},
  author={Tan, Cheng and Li, Siyuan and Gao, Zhangyang and Guan, Wenfei and Wang, Zedong and Liu, Zicheng and Wu, Lirong and Li, Stan Z},
  booktitle={Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2023}
}

@inproceedings{cvpr2022simvp,
    author    = {Gao, Zhangyang and Tan, Cheng and Wu, Lirong and Li, Stan Z.},
    title     = {SimVP: Simpler Yet Better Video Prediction},
    booktitle = CVPR,
    month     = {June},
    year      = {2022},
    pages     = {3170-3180}
}

@inproceedings{icml2015mmnist,
  author    = {Nitish Srivastava and Elman Mansimov and Ruslan Salakhutdinov},
  title     = {Unsupervised Learning of Video Representations using {LSTM}s},
  booktitle = ICML,
  year      = {2015}
}
