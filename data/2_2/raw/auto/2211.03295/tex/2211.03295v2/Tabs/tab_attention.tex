\begin{table}[ht]
    \vspace{-0.5em}
    \setlength{\tabcolsep}{0.4mm}
    \centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lccc}
    \toprule
Method                                     & $\mathcal{S}(\cdot,\cdot)$ & $\mathcal{F}_{\phi}(\cdot)$                                               & $\mathcal{G}_{\psi}(\cdot)$ \\ \hline
Self-attention~\cite{vaswani2017attention} & $<\cdot,\cdot>$            & $\mathrm{Softmax}\big( C^{\frac{1}{2}}XW_{Q} (XW_{K})^{T} \big)$          & $XW_{V}$                   \\
Linear attention~\cite{nips2020linformer}  & $<\cdot,\cdot>$            & $\mathrm{Softmax}\big( C^{\frac{1}{2}} XW_{Q} (W_{E} XW_{K})^{T} \big)$   & $W_{F}XW_{V}$              \\
GLU~\cite{dauphin2017language}             & $\odot$                    & $\mathrm{Sigmoid}( XW_{\phi})$                                            & $XW_{\psi}$                \\
SE~\cite{hu2018squeeze}                    & $\odot$                    & $\mathrm{Sigmoid}\big( \big( \mathrm{GAP}(X)W_{\phi} \big)W_{\psi} \big)$ & $X$                        \\
%$\mathrm{Moga}(\cdot)$                     & $\odot$                    & $\mathrm{SiLU}\big( \mathrm{Conv}_{1\times 1}(X) \big)$                   & $\mathrm{SiLU}\big( \mathrm{Conv}_{1\times 1}(Y_{C}) \big)$                        \\
    \bottomrule
    \end{tabular}
    }
    \vspace{-0.5em}
    \caption{Examples of context aggregation methods according to Eq.~(\ref{eq:aggregate}). The sing-head version of self-attention and linear attention is presented as an illustration and $W$ denotes a linear projection.}
    \label{tab:attention}
    \vspace{-1.0em}
\end{table}
