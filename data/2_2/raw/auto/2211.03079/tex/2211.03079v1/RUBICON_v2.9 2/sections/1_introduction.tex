\section{Main} \label{sec:introduction}
% The rapid advancement of long read genome sequencing technologies has significantly advanced 
The rapid advancement of genomics and sequencing technologies continuously calls for the adjustment of existing algorithmic techniques or the development of entirely new computational methods across diverse biomedical domains~\cite{ginsburg2018precision, aryan2020moving, clark2019diagnosis, kingsmore2022genome,ginsburg2009genomic, bloom2021massively, quick2016realtime,yelagandula2021multiplexed, le2013selected, vladyslav2016whole, meyer2021critical, lapierre2020metalign, lapierre2019micop, meyer2022critical}. Modern sequencing machines~\cite{pollard_long_2018,senol_cali_nanopore_2019} are capable of sequencing complex genomic structures and variants with high accuracy and throughput using long-read sequencing technology~\cite{amarasinghe2020opportunities}. %, generate long reads, and simplify a genome assembly with high accuracy~\cite{amarasinghe2020opportunities}. 
Oxford Nanopore Technologies (ONT) is the most widely used long-read sequencing technology~\cite{amarasinghe2020opportunities,logsdon2020long,wang2021nanopore, jain2018nanopore, gong2019ultralong,branton2008potential}. ONT devices generate long \sr{genomic} reads\sr{, each of which has} a length ranging from a few hundred to a million base pairs or nucleotides, i.e., A, C, G, and T in the DNA alphabet~\cite{van2018third,ardui2018single,jain_nanopore_2018,kchouk2017generations,weirather2017comprehensive}.

ONT devices sequence a genome by measuring changes to an electrical signal  as a single strand of DNA is passed through a nanoscale hole or \textit{nanopore}~\cite{jain2016oxford}. % \srr{this sentence doesn't clarify the relationship between the electrical signal and the hole, we need to explain it gradually}. 
The generated \sr{noisy} electrical signal is decoded into a sequence of nucleotides using a computationally-expensive step\sr{, called} \textit{basecalling}~\cite{wick2019performance,pages2022comprehensive,wang2021nanopore,alser2022molecules, alser_technology_2021}. %genome sequence analysis to  generate a sequence of long reads.
% Each nucleic acid has different electrical resistance, which directly affects the passing electrical current~\cite{wang2021nanopore}.
% One of the very first and most fundamental computational step in genome sequence analysis is \emph{basecalling}~\cite{wick2019performance,pages2022comprehensive,wang2021nanopore,alser2022molecules, alser_technology_2021}. Basecalling plays a crucial role in many omics applications~\cite{urnet_zhang2020nanopore}. 
%Basecalling translates the changes in electrical {current} signal  into a %standard format (called \emph{FASTQ}) of 
%sequence of nucleotides \srr{our sentence in the abstract is more clear}. %(bp) or nucleotides, i.e., A, C, G, and T in the DNA alphabet.  
Basecallers need to address two key challenges to accurately basecall a raw sequencing input. First, provid\sr{ing} accurate predictions of each and every individual nucleotide, as the sensors measuring the changes in electrical current can only measure the effect of multiple neighboring nucleotides together~\cite{wick2019performance}. 
Second, tolerat\sr{ing} low signal-to-noise ratio (SNR) caused by thermal noise and the lack of statistically significant current signals triggered by DNA strand motions~\cite{pages2022comprehensive}.
% \srr{how about the third challenge of speed as well since they need to cope with the throughput of sequencing machine and you can give an example of decent throughput from ONT devices.}
%Addressing these challenges requires using complex \srr{not clear why? should we use an example of techniques used to solve these challenges?} algorithms that make basecalling one of the most computational-expensive steps in a typical genome analysis pipeline~\cite{lou2020helix,perevsini2021nanopore,xu2021fast,rang2018squiggle}.

Modern basecallers use deep learning-based models to significantly \sr{(by at least 10\%)} improve the accuracy \sr{of predicting a nucleotide base from the squiggle} compared to traditional non-deep learning-based basecallers~\cite{urnet_zhang2020nanopore,dias2019artificial, amarasinghe2020opportunities, firtina_apollo_2020, logsdon2020long, senol_cali_nanopore_2019, rang2018squiggle}. %\srr{CITE: From squiggle to basepair: computational approaches for improving nanopore sequencing read accuracy, Performance of neural network basecalling tools for Oxford Nanopore sequencing}}2
%The accuracy and speed of basecalling have critical implications for every subsequent step in genome analysis~\cite{wick2019performance}.
%\srr{Our goal is not to address these issues. I think first we need to introduce the problem we are solving, which is the long execution time of ONT basecalling. Then we discuss what makes it computationally expensive, which is the use of deep-learning. Why we use deep learning is because we need to address the following three issues by .....}
%To address these challenges, current state-of-the-art basecallers use deep learning-based \srr{it is still not clear how deep-learning can solve the three issues} models~\cite{urnet_zhang2020nanopore,dias2019artificial}.
The success of deep learning in genome basecalling is attributed to the advances in its architecture to model and identify spatial features in raw input data to predict nucleotides.  %\srr{is there a name to this process? citation? are all of them trial-and-error?}. A key aspect of designing
%a well-performing deep learning-based basecaller is deciding the type
%and number of nodes and how to compose and link them. Researchers enumerate all possible architectures \srr{what are these architectures?} from the search space and evaluate them in a brute-force manner. The traditional brute-force approach to train and evaluate
%a model is time-consuming \srr{CITE}: the sheer number of sub-architectures renders exhaustive search intractable.  
However, we observe the following five shortcomings with the current basecallers~\cite{urnet_zhang2020nanopore,catcaller_lv2020end,zeng2020causalcall,perevsini2021nanopore,lou2020helix,xu2021fast,konishi2021halcyon,huang2020sacall,neumann2022rodan}.
First, current state-of-the-art basecallers are slow and show poor performance on state-of-the-art CPU and GPU-based systems, bottlenecking the entire genomic analyses. For example, \gpf, the fastest state-of-the-art basecaller, takes $\sim$6 hours to basecall a 3 Gbps (Giga basepairs) human genome on a powerful server-grade GPU, while the subsequent step, i.e., read mapping, takes a fraction of basecalling time ($\sim$0.11 hours using minimap2~\cite{li_minimap_2016}).
%, leading to an imbalanced genome sequencing pipeline. %~\cite{} \srr{whhy is this slow? is it compared to sequencing? You can calculate the sequencing throughhput for MinION (420 bases / second) or PromethION (48* (420 bases / second)), you can also mention that basecalling can be done as part of secondary analysis when the sequencing data is stored in public databases..}

Second, since basecalling shares similarities with automatic-speech recognition (ASR) task, many researchers have directly \sr{adapted} established ASR models, such as Quartznet~\cite{kriman2020quartznet}, Citrinet~\cite{majumdar2021citrinet}, and  Conformers~\cite{gulati2020conformer}, \sr{for basecalling} without customizing the neural network architecture specifically for the basecalling problem. % \srr{specializing? customizing their architecture?} \sr{them}. 
Such an approach might lead to higher basecalling accuracy but at the cost of large and unoptimized neural network architecture. For example, \texttt{Guppy} has $\sim$7-27 million neural network model parameters\footnote{The parameters are weights of a neural network that are \textit{learned} during neural network training.}, and its research version, \bon, has $\sim$10 million neural network model parameters.    
%ONT developed one such basecaller called Bonito, and its production-ready version called Guppy that uses QuartzNet ASR structure.
%We observe that bonito is over-parameterized for basecalling task. 
We show in Section~\ref{suppsubsubsec:overprovision_prune} that we can \sr{eliminate} up to 85\% of the model parameters to achieve a 6.67$\times$ reduction in model size without any loss in basecalling accuracy. Therefore, current basecalling models are costly to run, and the inference latency becomes a \sr{major} bottleneck.


Third, modern basecallers are typically composed of convolution layers with skip connections\footnote{A skip connection allows to skip some of the layers in the neural network and feeds the output of one layer as the input to the next layers.}~\cite{szegedy2017inception} (allow reusing %\srr{reused? or allow reusing?}\srr{what skip connections are? this is more clear from Google search: "skips some of the layers in the neural network and feeds the output of one layer as the input to the next layers"} 
of activations from previous layers)
that creates two major performance \sr{issues}: %\srr{thhis is not an issue with basecalling, it is a challenge to accelerate them}.
(a) skip connections increase the data lifetime: the layers whose activations are reused in future layers must either wait for this reuse to occur before accepting new input or store the activations for later use by utilizing more memory. Thus, leading to high resource and storage requirements; and (b) skip connections often need to perform additional computation to match the channel size at the input of the non-consecutive layer, which increases the total model parameters, e.g., \bon requires $\sim$21.7\% additional model parameters due to the skip connections.
 
Fourth, current basecallers use floating-point precision (32 bits) to represent each neural network layer present in a basecaller. % \srr{ellaborate more in easier language, say something like representing each node using 16 bits instead of 2 bits or like..} for all the different \srr{how many layers normally? or a range of number? how large is this problem?} neural network layers. 
This leads to high bandwidth and processing demands. Thus, current basecallers with floating-point arithmetic precision have inefficient hardware implementations. We observe in Section~\ref{suppsubsubsec:overprovision_quant} that the arithmetic precision requirements of current basecallers can be reduced $\sim$4$\times$ by adjusting the precision for each neural network layer based on the target hardware and desired accuracy. %?} with intelligent co-design of neural network architecture and precision for each neural network layer.   

Fifth, basecallers that provide higher throughput have lower basecalling accuracy. For example, we show in Section~\ref{subsection:results_overall} and Supplementary~\ref{suppsec:guppy_compare}   that \gpf provides up to 10.3$\times$ higher basecalling performance using  8.7$\times$ lower model parameters at the expense of the   3.8\% lower basecalling accuracy compared to more accurate basecallers.

These five problems concurrently make basecalling slow, inefficient, and memory-hungry, bottlenecking all genomic analyses that depend on it. % limiting the types of devices on which heavy genomic analyses can be performed to high-performance computing systems
%Most of the existing basecallers lack dedicated hardware acceleration implementations, which could greatly reduce the basecalling time.
Therefore, there is a need to reduce the computation and memory cost of basecalling while maintaining their performance. However, developing a %\srr{why we need hardware-efficient basecallers? and what is the definition of hardware-efficient basecaller?} 
basecaller that can provide fast runtime performance with high accuracy requires a deep understanding of genome sequencing, machine learning, and hardware design. At present, computational biologists spend significant time and effort to design and implement new basecallers by an extensive trial-and-error process. 

%\srr{we need to highlight here that basecallers are usually adapting algorithms from other fields of research without optimizing them for genomic basecalling, then give examples such as QuartzNet from Speech Recognition.}
%\srr{we need to motivate the need to optimize them. Do we have any observations made when you optimize the model? HHow genomics is different from speech recognition...?}



% Recent work, such as~\cite{ambernas_zhang2021automated}, shows the importance of neural network search in genomics. However, such works do not consider the underlying hardware characteristics while optimizing a neural network model. Thus, leading to accurate but over-parameterized models with low inference throughput.

\gsss{
\textbf{Our goal} is to overcome the above issues by developing  a framework for specializing and optimizing a machine learning-based basecaller that provides high accuracy, high efficiency, and high performance for Nanopore sequencing machines. }

%\srr{why do we emphasize hardware-optimized a lot? is it only about that? solving the four issues above is also beneficial to software even if we couldn't demonstrate that due to the precision issue with the GPU...} basecaller that provides high accuracy, high efficiency, and high performance for Nanopore sequencing.

% \textbf{Our goal} is to overcome the above issues by developing (1) tools to systematically design hardware-optimized basecallers without requiring machine learning expertise;  and (2) a new hardware-optimized basecaller that provides both high accuracy and performance.



To this end, we introduce \framework, the first framework for specializing and optimizing a machine learning-based basecaller. \framework uses  two machine learning techniques to develop hardware-optimized basecallers that are specifically designed for basecalling. First, we propose \nas, a quantization-aware basecalling architecture search framework to specialize basecaller architectures for hardware implementation while considering hardware performance metrics (e.g., latency, throughput, etc.). \nas uses neural architecture search~\cite{zoph2016neural} to evaluate millions of different basecaller architectures. During the basecaller neural architecture search, \nas quantizes the neural network model by exploring and finding the best bit-width precision for each neural network layer, which largely reduces the memory and computational complexity of a basecaller. 
 Adding quantization to the basecaller neural architecture search dramatically increases the model search space ($\sim$6.72$\times$10$^{20}$ more viable options in our search space). However, \sr{jointly} optimizing basecalling neural network architecture search and quantization allows us to develop accurate basecaller \sr{architectures} that are optimized for hardware acceleration. Second,
we develop \strim to remove the skip connections \sr{presented} in modern basecallers to reduce resource and storage requirements without any loss in basecalling
accuracy. \strim performs a skip removal process using knowledge distillation~\cite{bucilua2006model}, where  we train a smaller network (\textit{student}) without skip connections to mimic a pre-trained bigger network (\textit{teacher}) with skip connections. We demonstrate the effectiveness of \nas and \strim to develop \mech, the first hardware-optimized
basecaller that performs fast and accurate basecalling. 

% To this end, we propose \mech, the first hardware-optimized
% basecaller that uses mixed precision computation. We perform hardware-neural co-design to
% develop \mech. %During the ML algorithm design stage, the computational burden of NN inference can be reduced by eliminating nonessential calculations through a modified training procedure.  
% We use two machine learning techniques to develop \mech that are designed explicitly for basecalling.  
% Third, we apply model pruning to remove network connections that are considered unimportant to keep the network performance unchanged. 

\hfill \break
\head{Key results} %\srr{please double check and make sure they are sorted by their importance} 
We compare \mech to three different basecallers. We demonstrate five key results.  First, \mech provides 16.56$\times$ higher basecalling throughput without any loss in basecalling accuracy compared to the most accurate state-of-the-art basecaller by leveraging mixed precision computation when implemented on a cutting-edge spatial vector computing system, i.e., the AMD-Xilinx Versal AI. Compared to the fastest basecaller, \mech provides, on average, 2.97\% higher basecalling accuracy with 7.06$\times$ higher basecalling throughput. Second, we show that \nas-designed models are 5.74$\times$ smaller in size with 2.41$\times$ fewer neural network model parameters than the best state-of-the-art basecaller. Third, by further using our \strim approach, \mech achieves a 6.88$\times$ and 2.94$\times$ reduction in neural network model size and number of parameters, respectively. Fourth, assemblies constructed
using reads basecalled by \mech lead to higher quality, more contiguous, and more complete assemblies for all evaluated species than that provided by other basecallers. Fifth, \mech provides a 1.82\%-26.49\% lower number of base mismatches with the largest number of mapped based and mapped reads compared to the baseline basecaller. Our experimental results on state-of-the-art computing systems show that \mech is a hardware-friendly, accurate, mixed-precision basecaller.  

% This work makes the following major contributions:
% \begin{itemize}
%     \item We develop \nas, the first quantization-aware basecalling neural architecture search framework to jointly specialize the basecalling neural network architecture and optimal bit-width precision for a given hardware acceleration platform.
%     \item We develop a novel technique, called \strim, to remove the skip connections present in modern basecallers to greatly reduce resource and storage requirements without any loss in basecalling accuracy. 
%     \item We propose \mech, the first hardware-optimized basecaller that performs fast and accurate basecalling while maintaining full quality and assembly contiguity.  
% %     \item We propose \nas, the first hardware-optimized
% % basecaller that uses mixed precision computation using quantization-aware neural architecture search
% % \item We introduce \strim to remove skip connections present in neural-architecture-based basecallers to reduce model size and hardware resource requirements without affecting the basecalling accuracy.
% \item We conduct an in-depth evaluation on  GPU and  cutting-edge spatial vector computing system, i.e., the AMD-Xilinx Versal AI Engine, showing \mech  is the fastest Nanopore sequencing basecaller to date, on all major state-of-the-art computing platforms. % Our evaluation results show that the current state-of-the-art basecallers are large, computationally-heavy, and unoptimized designs leading to poor hardware performance.
% \item We freely open-source \mech, \nas, and \strim to aid future research in basecalling.
% \end{itemize}
% limitations—over-provisioned, which could lead to...—why hardware acceleration —>co-optimize reduce computation without losing accuracy


% methods applied for resolving and challenges of these methods
