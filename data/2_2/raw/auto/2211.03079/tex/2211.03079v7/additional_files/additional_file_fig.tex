\hfill \break

\newpage
\section*{Supplementary Figures}
\begin{figure*}[h]
  \centering
  \includegraphics[width=\linewidth]{images/NAS_3.pdf}
  \vspace{-10pt}
  \caption{Overview of \nas. \nas evaluates a different set of candidate operations for convolution (\texttt{conv}) and quantization bits. In the figure, we show different options for kernel size (\texttt{KS}) (e.g., 3, 5, 9, etc.) and quantization bits  (4-b, 8-b, and 16-b) for each network layer. The identity operator removes a layer to get a shallower network. }
  \label{fig:nas}
  \vspace{12pt}
\end{figure*}


\begin{figure*}[h]
  \centering
  \includegraphics[width=0.9\linewidth]{images/skip_removal2.pdf}
%   \vspace{-20pt}
  \caption{Overview of \strim process for three epochs. We start with a large, overprovisioned floating-point precision model as the teacher network and our \nas mixed-precision model as the student network. During the training, \strim removes a skip connection from the student network every \texttt{n} epoch, starting with the first skip connection encountered in the network from the input.}
  \label{fig:skiptrim}
%   \vspace{-12pt}
\end{figure*}

  \begin{figure}[h]
  \centering
\includegraphics[width=0.65\linewidth,trim={0.2cm 0.25cm 0.2cm 0cm},clip]{images/skip_connection_sensitivity_4.pdf}
%   \vspace{-15pt}
  \caption{Basecaller sensitivity to skip connections.}
  \label{supfig:skip_sensitivity}
%   \vspace{-12pt}
\end{figure}

\begin{figure}[h]
  \centering
\includegraphics[width=0.6\linewidth,trim={0.2cm 0.25cm 0.4cm 0cm},clip]{images/kd_hyper3.pdf}
%   \vspace{-15pt}
  \caption{Sensitivity of \strim to hyper-parameters alpha ($\alpha$) and temperature ($\tau$).}
  \label{supfig:kd_hyper}
  \vspace{12pt}
\end{figure}


\begin{figure}[h]
  \centering
%   \includesvg{images/rubicon.svg}
  \includegraphics[width=0.5\linewidth]{images/rubicon_4.pdf}
%   \vspace{-20pt}
  \caption{Overview of \mech architecture. The normalized input signal is passed through a succession of quantized convolution blocks. Each block is composed of several processing steps (convolution, batch normalization, and activation). We represent the quantization as a tuple $<$weight, activation$>$. Initial layers use a higher precision for weights and activations, while the final layers use a lower precision. The final output is passed through a connectionist temporal classification (CTC) to produce the decoded sequence of nucleotides.}
  \label{fig:rubicon}
%   \vspace{-12pt}
\end{figure} 



 \begin{figure}[h]
 % %\yboxbegin
  \centering
  \includegraphics[width=1\linewidth]{images/2023.11.01.model_compare_pareto_all_1.pdf}%{images/model_compare_AMD_CRF_SUP_1.pdf}
  % \vspace{-5pt}
 \caption{Comparison of \hc{average} basecalling  throughput for \mechmp with baseline basecaller in terms of:  (a) average  basecalling accuracy, (b) model parameters, and (c) model size.}
  \label{supfig:model_compare_all}
%   \vspace{-12pt}
% %\yboxend
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{images/2023.11.01_basecalling_speed_nvidia_1.pdf}%{images/model_compare_AMD_CRF_1.pdf}
  % \vspace{-15pt}
    \caption{Performance comparison of \mech (using floating-point precision (\mechfp) and mixed-precision (\mechmp))~\sr{and five state-of-the-art basecallers on NVIDIA A40~\cite{a40}. The y-axis is on a logarithmic scale.}}
  \label{fig:model_compare_nvidia}
%   \vspace{-12pt}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=1\linewidth]{images/k-mer_freq_reads1.pdf}%{images/model_compare_AMD_CRF_1.pdf}
  % \vspace{-15pt}
    \caption{K-mer frequency analysis of generated reads from \mech and all the other evaluated basecallers.}
  \label{fig:kmer_reads}
%   \vspace{-12pt}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=1\linewidth]{images/k-mer_freq_assembly1.pdf}%{images/model_compare_AMD_CRF_1.pdf}
  % \vspace{-15pt}
    \caption{K-mer frequency analysis of generated assemblies of reads from \mech and all the other evaluated basecallers.}
  \label{fig:kmer_assembly}
%   \vspace{-12pt}
\end{figure}
