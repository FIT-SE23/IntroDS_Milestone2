\section*{Abstract}
\begin{abstract}
%%%%%%%%%%%%%%%%%%%%SHORT VERSION%%%%%%%%%%%%%%%%%%%%%%%%%%%

\gbwriting{
Nanopore sequencing generates noisy electrical signals that need to be converted into a standard string of DNA nucleotide bases using a computational step called basecalling.
%Nanopore sequencing is a widely used high-throughput sequencing technology. However, it yields noisy electrical signals, necessitating computationally expensive \emph{basecalling} step to convert noisy signals into DNA nucleotide sequences. 
The performance of basecalling has critical implications for all later steps in genome analysis. %Basecalling accuracy significantly influences the entire downstream genome analysis. %While deep learning models from speech recognition are often adopted for basecalling, their computational demands hinder efficiency. 
Therefore, there is a need to reduce the computation and memory cost of basecalling while maintaining accuracy.
We present \framework, a framework to develop efficient hardware-optimized basecallers. %\framework introduces Quantization-Aware Basecalling Neural Architecture Search (\nas) and \strim to optimize the basecaller architecture and reduce computational requirements. 
We demonstrate the effectiveness of \framework by developing \mech, the first hardware-optimized mixed-precision basecaller that performs efficient basecalling, outperforming the state-of-the-art
basecallers. %, providing a \rmpSpeedupDor speedup with a \rmpAccDor accuracy increase over the fastest basecaller and a \rmpSpeedupBonCTC speedup while maintaining accuracy compared to an expert-designed basecaller. 
We believe \framework offers a promising
path to develop future hardware-optimized basecallers.}



%%%%%%%%%%%%%%%%%%%%LONGER VERSION%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \srr{We need to find a better title, normally nature publishes titles that conclude the main results and not what the tool is. Something like: Optimizing Nanopore Sequencing Improves Genome Analysis}.
% Nanopore sequencing is a widely-used high-throughput genome sequencing technology that can sequence long fragments of a genome.
% \sr{Nanopore sequencing generates noisy electrical signals that need to be converted into a standard string of DNA nucleotide bases using a computational step called \emph{basecalling}.}
% %It uses a deep learning-based basecalling step to convert a raw input signal to DNA nucleotide bases (i.e., A, C, G, T). 
% The performance of basecalling has critical implications for all later steps in genome analysis.
% %Currently, basecallers \sr{are mainly based on deep learning techniques to provide high sequencing} accuracy without considering %\srr{this is not accurate as ONT always considers GPUs for acceleration} \gsf{sure, but they are not optimizing for underneath GPU architecture, e.g., taking advantage of tensor cores} 
% %the compute demands of such \sr{tools}. 
% %We observe that state-of-the-art basecallers (i.e., Guppy, Bonito) are slow, inefficient, and memory-hungry as researchers have adapted deep learning models from other domains without specialization to the basecalling purpose. 
% \gont{Many researchers adopt complex deep learning-based models from the speech recognition domain to perform basecalling without considering the compute demands of such models, which leads to slow, inefficient, and memory-hungry basecallers. Therefore, there is a need to reduce the computation and memory cost of basecalling while maintaining accuracy. However, developing a very fast basecaller that can provide high accuracy requires a deep understanding of genome sequencing, machine learning, and hardware design. Our goal is to develop a comprehensive framework for creating deep learning-based basecallers that provide high efficiency and performance.} %Our goal is to make basecalling highly efficient and fast by building the first framework for specializing and optimizing machine learning-based basecaller.
% %As a result, state-of-the-art basecallers are computationally intensive, making basecalling slow, inefficient, and memory-hungry, bottlenecking all genomic analyses that depend on it. \srr{what makes basecalling slow, inefficient, and memory hungry? We can directly say: We observe that state-of-the-art basecallers (i.e., Guppy, Bonito, Fast-Bonito) are slow, inefficient, and memory-hungry as they usually adapt deep-learning models from other domains without specialization to the basecalling purpose.}
% %Designing an efficient basecaller requires a deep understanding of machine learning, genome sequencing, and hardware design. 
% % \srr{it is not clear what hardware-optimized is?}
% % Our goal is to develop a hardware-optimized basecaller that provides high accuracy, high efficiency, and high performance for Nanopore sequencing machines. 
% % \srr{Our goal is to make basecalling highly efficient and fast with no accuracy loss by building the first framework for specializing and optimizing existing machine learning basecalling models.}
% We introduce \framework, a framework to develop hardware-optimized basecallers.  \framework consists of two novel machine-learning techniques that are specifically designed for basecalling. First, we introduce the first quantization-aware basecalling neural architecture search (\nas) framework to specialize the basecalling neural network architecture for a given hardware acceleration platform while jointly exploring and finding the best bit-width precision for each neural network layer. Second, we develop \strim, the first technique to remove the skip connections present in modern basecallers to greatly reduce resource and storage requirements without any loss in basecalling accuracy.  We demonstrate the benefits of \framework by developing \mech, the first hardware-optimized basecaller that performs fast and accurate basecalling. %Our experimental results show that \mech is 5.19$\times$ and 23.02$\times$ faster than the most accurate state-of-the-art basecaller when implemented on a state-of-the-art GPU and a real cutting-edge spatial vector computing system. We show that
% %Our experimental results show that \mech is 6.88$\times$ smaller in size and 2.94$\times$ fewer neural network model parameters with no loss in accuracy compared to the best state-of-the-art basecaller. 
% \go{Our experimental results on state-of-the-art computing systems show that \mech is a fast, memory-efficient, and hardware-friendly basecaller. Compared to the fastest state-of-the-art basecaller, \mech provides a 3.96$\times$ speedup with 2.97\% higher accuracy. Compared to an expert-designed basecaller, \mech provides a 141.15$\times$ speedup without losing accuracy while also achieving a 6.88$\times$ and 2.94$\times$ reduction in neural network model size and the number of parameters, respectively. }
% % \gssssss{Our experimental results on  state-of-the-art computing systems show that \mech is a hardware-friendly, accurate, mixed-precision basecaller with 16.56$\times$ faster performance than the most accurate basecaller and achieves a 6.88$\times$ and 2.94$\times$ reduction in neural network model size and the number of parameters, respectively.}
% % GPU. 
%  We show that \framework helps researchers develop hardware-optimized basecallers that are superior to expert-designed models  and can inspire independent future ideas. 
% % \srr{we need to mention the most important evaluation, which should be around how much existing models can be smaller, faster, more optimized, .... as this is our main argument.}
% % without requiring machine learning expertise. 
% % -designed models are superior than expert-designed models with 6.88$\times$ and 2.94$\times$ reduction in neural network model size and model parameters, respectively.



% %%%%%%%%%%%%%%%%%%%%LONG VERSION%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % %Basecalling is the first step in the genome sequencing pipeline that converts a raw electrical signal into base pairs  (i.e., A, C, G, and T in the DNA alphabet). The accuracy of this step is crucially important to the entire genome analysis. Basecalling is computationally intensive taking up to 40\% of the total execution time of the entire pipeline. 
% % Nanopore sequencing is a widely-used high-throughput genome sequencing technology that can sequence long fragments of a genome. 
% % \sr{Nanopore sequencing requires using an additional computational step, called \emph{basecalling}, that converts the output of Nanopore machines into standard data that \emph{all} existing genome analyses can understand.} 
% % %One of the very first and most fundamental computational steps in genome sequence analysis is basecalling. 
% % %It %\srr{which ones?} 
% % \sr{Basecalling} uses computationally-intensive %and over-provisioned 
% % deep learning %neural network 
% % models to translate the raw \sr{Nanopore data, }electrical current signal\sr{, in}to nucleotide bases (i.e., A, C, G, T).  %\srr{maybe you can remove the rest of the sentence as it is deep detail?} with skip connections in their network--reusing activations from previous layers. 
% % The accuracy and speed of this step have critical implications for every subsequent step in genome analysis. Unfortunately, \sr{state-of-the-art} basecallers are computationally very complex that makes basecalling slow, inefficient, and memory-hungry, bottlenecking \sr{\emph{all}} genomic analyses that \sr{require sequencing new samples.}
% % Inefficient basecalling \sr{necessitates the need for multiple expensive GPU devices that need to be integrated with the sequencing devices for performing only basecalling.} 
% % %limits the types of devices on which heavy genomic analyses can be performed to high-performance computing systems. %leading to high execution times and slow genome analysis %These three problems concurrently make basecalling slow, inefficient, and memory-hungry, bottlenecking all genomic analyses that depend on it 
% % There is a large need to reduce both the end-to-end execution time and the memory footprint of basecalling while maintaining high accuracy. 
% % At present, computational biologists spend significant time and effort to design and implement new basecallers by an extensive trial-and-error process. Our goal is to develop hardware-optimized basecaller that provides high accuracy, high efficiency, and high performance for Nanopore sequencing machines. 
% % %These basecallers are unoptimized for hardware acceleration and resources.  Our goal is to develop a new basecaller that provides both high accuracy and performance.

% % We propose two novel machine learning techniques to develop hardware-optimized basecallers.  
% % First, we introduce the first quantization-aware basecalling neural architecture search (\nas) framework to specialize the basecalling neural network architecture for a given hardware acceleration platform  without requiring machine learning expertise. \nas uses direct hardware metrics (e.g., latency, throughput, etc.) for optimization. During basecaller neural architecture search, \nas quantizes the neural network model by exploring and finding the best bit-width precision for each neural network layer, which largely reduces the memory and computational complexity of a basecaller. Second, we develop \strim, the first technique to remove the skip connections present in modern basecallers to greatly reduce resource and storage requirements without any loss in basecalling accuracy. We demonstrate the benefits of \nas and \strim by developing \mech, the first hardware-optimized basecaller that performs fast and accurate basecalling. 
% % % Third, we apply hardware-friendly pruning to our basecaller architecture to remove network connections that are considered unimportant while keeping the basecalling accuracy unchanged.


% % Our experimental results on real  state-of-the-art computing systems show that \mech is a hardware-friendly, accurate, mixed-precision basecaller with 5.19$\times$ faster performance compared to the most accurate state-of-the-art basecaller implementation on a state-of-the-art
% % GPU. 4.2$\times$ and 5.3$\times$ faster performance than the current state-of-the-art basecaller implementations on a state-of-the-art GPU. %CPU and GPU respectively. 
% % \mech, when implemented on a real cutting-edge spatial vector computing system, i.e., the AMD-Xilinx Versal AI Engine, achieves 23.02$\times$ higher performance compared to the best GPU baseline.   \mech provides 2.97\% lower number of base mismatches %fast basecalling performance without any loss in basecalling accuracy 
% % while maintaining full quality and assembly contiguity compared to the best previous basecaller. %We also demonstrate that each of the two major components of \mech provides significant benefits. 
% % We show that \nas-designed models are 5.74$\times$ smaller in size with 2.41$\times$ fewer neural network model parameters compared to the best state-of-the-art basecaller. By further using our \strim approach, \mech achieves a 6.88$\times$ and 2.94$\times$ reduction in neural network model size and parameters, respectively. %\nas and \strim provide efficient mechanism to create accurate and hardware-friendly deep learning models that can help researchers develop optimized basecallers. % without requiring machine learning expertise. 
% %  %These \mech components can be used in other ways and can inspire independent future ideas.



% %  %We perform hardware-neural co-design to develop \mech~while using three machine learning techniques. First, we develop quantization-aware basecaller architecture search (\nas) framework to  specialize basecaller architectures for hardware with direct hardware metrics (e.g., latency).  Second, we develop \strim that removes all the skip connections without any loss in basecalling accuracy.  Third, we apply model pruning to remove network connections that are considered unimportant to keep the network performance unchanged.
% % %Our experimental results show that \mech is hardware-friendly, mixed-precision, accurate basecaller with a 5.7$\times$ smaller model size. \srr{we can directly say it is 9.1x smaller model size instead of 5.7x...} By further removing skip connections we achieve 9.1$\times$ reductions in model size with 2.9$\times$ fewer model parameters compared to the baseline model. On CPU and \sr{NVIDIA} A100 GPU, \mech provides x and x performance improvements, respectively. We also evaluate \mech on a state-of-the-art spatial vector architecture, Xilinx Versal AI Engine, to achieve $\times$ higher performance compared to the baseline implementation. On FPGA and ASIC, \mech provides x bops performance, which x
\end{abstract}

