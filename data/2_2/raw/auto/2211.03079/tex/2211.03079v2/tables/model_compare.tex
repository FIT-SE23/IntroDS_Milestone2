\vspace{10pt}
\begin{table*}[h]
 \caption{Comparison of \mechmp with baseline basecallers in terms of basecalling throughput, basecalling accuracy, parameters, and model size. For basecalling throughput and basecalling accuracy, we report average (Avg.), minimum (Min.), maximum (Max.), 25th percentile (25th \%tile), and 75th percentile (75th \%tile) values for all the basecallers.}
    \label{suptab:compare}
\centering
% \resizebox{\linewidth}{!}{%
 \setstretch{0.9}
\renewcommand{\arraystretch}{1}
  \resizebox{1\linewidth}{!}{%
\begin{tabular}{l|l|l|rrrrr|rrrrr|r|r}
\hline
\textbf{Basecaller}  &  \textbf{Architecture}  &\textbf{Precision} &\multicolumn{5}{c|}{\textbf{Basecalling Throughput (kbp/sec)}}                                            & \multicolumn{5}{c|}{\textbf{Basecalling Accuracy (\%)}}                    & \multicolumn{1}{l|}{\textbf{Parameters}} & \multicolumn{1}{l}{\textbf{Model Size (MB)}} \\ \hline
           &    &      & \multicolumn{1}{r}{\textbf{Avg.}} & \multicolumn{1}{r}{\textbf{Min.}} & \multicolumn{1}{r}{\textbf{Max.}} & \multicolumn{1}{r}{\textbf{25th \%tile}} & \multicolumn{1}{c|}{\textbf{75th \%tile}} & \multicolumn{1}{r}{\textbf{Avg.}} & \multicolumn{1}{r}{\textbf{Min.}} & \multicolumn{1}{r}{\textbf{Max.}} & \multicolumn{1}{r}{\textbf{25th \%tile}} & \multicolumn{1}{r|}{\textbf{75th \%tile}} & \multicolumn{1}{r|}{--}                    & \multicolumn{1}{r}{--}                         \\
{\cc} &CNN & FP16/FP32 & 16.06                    & 9.04                     & 22.16                    & 12.45                           & 18.86                            & 84.88                    & 82.7     & 86.42    & 83.57       & 86.17       & 3,589,893        & 13.69                                        \\
{\gp}  &RNN & FP16/FP32    & 32.89                   & 17.43                     & 42.7                   & 29.75                           & 36.98                                               & \textbf{92.53} &\textbf{90.61} & \textbf{95.95}            &  \textbf{91.43}    &\textbf{93.72}      & 26,992,744       & 103.03                                       \\
{\gpf} &RNN & FP16/FP32 & 364.63                  & 54.32                    & 587.53                   & 260.98                         & 490.8                          & 87.16                    & 82.53 & 91.39    & 86.25       & 88.51       & 730,344          & 2.79                                         \\
{\bon} &CNN  &FP16/FP32    & 70.36                    & 37.41                    & 93.01                    & 57.49                           & 82.15                            & 89.92                    & 87.99    & 93.75    & 88.62       & 91.15       & 9,738,573        & 37.15                                        \\
{\mechmp}&CNN & Mixed-Precision & \textbf{1165.21}         & \textbf{392.03}          & \textbf{2293.95}         & \textbf{576.16}                 & \textbf{1604.91}                  & 89.98                    & 86.59    & 93.64    & 88.97       & 91.41        & 3,314,578        & 5.36                                         \\ \hline
\end{tabular}
}
\end{table*}
