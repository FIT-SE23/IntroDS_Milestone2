@article{TS_scheme,
  doi = {10.48550/ARXIV.2105.01477},
  
  url = {https://arxiv.org/abs/2105.01477},
  
  author = {Gratsea, Aikaterini and Huembeli, Patrick},
  
  keywords = {Quantum Physics (quant-ph), FOS: Physical sciences, FOS: Physical sciences},
  
  title = {Exploring Quantum Perceptron and Quantum Neural Network structures with a teacher-student scheme},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Variational_meas,
  doi = {10.48550/ARXIV.2110.13162},
  
  url = {https://arxiv.org/abs/2110.13162},
  
  author = {Jerbi, Sofiene and Fiderer, Lukas J. and Nautrup, Hendrik Poulsen and Kübler, Jonas M. and Briegel, Hans J. and Dunjko, Vedran},
  
  keywords = {Quantum Physics (quant-ph), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Quantum machine learning beyond kernel methods},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{Cai_2020,
	doi = {10.1103/physrevapplied.14.014059},
  
	url = {https://doi.org/10.1103%2Fphysrevapplied.14.014059},
  
	year = 2020,
	month = {jul},
  
	publisher = {American Physical Society ({APS})},
  
	volume = {14},
  
	number = {1},
  
	author = {Zhenyu Cai},
  
	title = {Resource Estimation for Quantum Variational Simulations of the Hubbard Model},
  
	journal = {Physical Review Applied}
}

@article{new1,
  doi = {10.48550/ARXIV.2209.05523},
  
  url = {https://arxiv.org/abs/2209.05523},
  
  author = {Peters, Evan and Schuld, Maria},
  
  keywords = {Quantum Physics (quant-ph), FOS: Physical sciences, FOS: Physical sciences},
  
  title = {Generalization despite overfitting in quantum machine learning models},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{NEW2,
  doi = {10.48550/ARXIV.2209.10345},
  
  url = {https://arxiv.org/abs/2209.10345},
  
  author = {Heimann, Dirk and Schönhoff, Gunnar and Kirchner, Frank},
  
  keywords = {Quantum Physics (quant-ph), FOS: Physical sciences, FOS: Physical sciences},
  
  title = {Learning capability of parametrized quantum circuits},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@article{Economou2,
	doi = {10.1038/s41467-019-10988-2},
  
	url = {https://doi.org/10.1038%2Fs41467-019-10988-2},
  
	year = 2019,
	month = {jul},
  
	publisher = {Springer Science and Business Media {LLC}
},
  
	volume = {10},
  
	number = {1},
  
	author = {Harper R. Grimsley and Sophia E. Economou and Edwin Barnes and Nicholas J. Mayhall},
  
	title = {An adaptive variational algorithm for exact molecular simulations on a quantum computer},
  
	journal = {Nature Communications}
}

@article{Moll_2018,
	doi = {10.1088/2058-9565/aab822},
  
	url = {https://doi.org/10.1088%2F2058-9565%2Faab822},
  
	year = 2018,
	month = {jun},
  
	publisher = {{IOP} Publishing},
  
	volume = {3},
  
	number = {3},
  
	pages = {030503},
  
	author = {Nikolaj Moll and Panagiotis Barkoutsos and Lev S Bishop and Jerry M Chow and Andrew Cross and Daniel J Egger and Stefan Filipp and Andreas Fuhrer and Jay M Gambetta and Marc Ganzhorn and Abhinav Kandala and Antonio Mezzacapo and Peter Müller and Walter Riess and Gian Salis and John Smolin and Ivano Tavernelli and Kristan Temme},
  
	title = {Quantum optimization using variational algorithms on near-term quantum devices},
  
	journal = {Quantum Science and Technology}
}

@article{info_scrambling,
  title = {Information Scrambling in Quantum Neural Networks},
  author = {Shen, Huitao and Zhang, Pengfei and You, Yi-Zhuang and Zhai, Hui},
  journal = {Phys. Rev. Lett.},
  volume = {124},
  issue = {20},
  pages = {200504},
  numpages = {6},
  year = {2020},
  month = {May},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.124.200504},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.124.200504}
}


@article{goal_of_QML,
  doi = {10.48550/ARXIV.2203.01340},
  
  url = {https://arxiv.org/abs/2203.01340},
  
  author = {Schuld, Maria and Killoran, Nathan},
  
  keywords = {Quantum Physics (quant-ph), FOS: Physical sciences, FOS: Physical sciences},
  
  title = {Is quantum advantage the right goal for quantum machine learning?},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{Alejandro_new,
  doi = {10.48550/ARXIV.2201.08770},
  
  url = {https://arxiv.org/abs/2201.08770},
  
  author = {Gili, Kaitlin and Mauri, Marta and Perdomo-Ortiz, Alejandro},
  
  keywords = {Machine Learning (cs.LG), Quantum Physics (quant-ph), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Physical sciences, FOS: Physical sciences},
  
  title = {Evaluating Generalization in Classical and Quantum Generative Models},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{Maria_kernel,
  doi = {10.48550/ARXIV.2101.11020},
  
  url = {https://arxiv.org/abs/2101.11020},
  
  author = {Schuld, Maria},
  
  keywords = {Quantum Physics (quant-ph), Machine Learning (stat.ML), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Supervised quantum machine learning models are kernel methods},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{Sim_2019,
	doi = {10.1002/qute.201900070},
  
	url = {https://doi.org/10.1002%2Fqute.201900070},
  
	year = 2019,
	month = {oct},
  
	publisher = {Wiley},
  
	volume = {2},
  
	number = {12},
  
	pages = {1900070},
  
	author = {Sukin Sim and Peter D. Johnson and Al{\'{a}
}n Aspuru-Guzik},
  
	title = {Expressibility and Entangling Capability of Parameterized Quantum Circuits for Hybrid Quantum-Classical Algorithms},
  
	journal = {Advanced Quantum Technologies}
}


@article{paper_storage,
  doi = {10.48550/ARXIV.2111.08414},
  
  url = {https://arxiv.org/abs/2111.08414},
  
  author = {Gratsea, Aikaterini and Kasper, Valentin and Lewenstein, Maciej},
  
  keywords = {Disordered Systems and Neural Networks (cond-mat.dis-nn), Quantum Physics (quant-ph), FOS: Physical sciences, FOS: Physical sciences},
  
  title = {Storage properties of a quantum perceptron},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{Hopfield1982,
	author = {Hopfield, J J},
	title = {Neural networks and physical systems with emergent collective computational abilities},
	volume = {79},
	number = {8},
	pages = {2554--2558},
	year = {1982},
	doi = {10.1073/pnas.79.8.2554},
	publisher = {National Academy of Sciences},
	abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/79/8/2554},
	journal = {Proceedings of the National Academy of Sciences}
}

@article{Hinton1983,
  author = {Hinton, Geoffrey E. and Sejnowski, Terrence J.},
  title = {Optimal Perceptual Inference},
  journal = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern Recognition},
  year = {1983},
  url = {https://www.bibsonomy.org/bibtex/249346852ab2da6e60c5ab1552b4840db/schaul}
}

@article{Hinton1985,
author = {Ackley, David H. and Hinton, Geoffrey E. and Sejnowski, Terrence J.},
title = {A Learning Algorithm for Boltzmann Machines*},
journal = {Cognitive Science},
volume = {9},
number = {1},
pages = {147-169},
doi = {https://doi.org/10.1207/s15516709cog0901\_7},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog0901_7},
year = {1985}
}

@article{rbm-universality,
  author={N. {Le Roux} and Y. {Bengio}},
  journal={Neural Computation}, 
  title={Representational Power of Restricted Boltzmann Machines and Deep Belief Networks}, 
  year={2008},
  volume={20},
  number={6},
  pages={1631-1649},
  doi={10.1162/neco.2008.04-07-510}}


@article{UAT2021,
   title={The Universal Approximation Property},
   ISSN={1573-7470},
   url={http://dx.doi.org/10.1007/s10472-020-09723-1},
   DOI={10.1007/s10472-020-09723-1},
   journal={Annals of Mathematics and Artificial Intelligence},
   publisher={Springer Science and Business Media LLC},
   author={Kratsios, Anastasis},
   year={2021},
   month={Jan}
}

@article{deep2017,
      title={From Deep to Shallow: Transformations of Deep Rectifier Networks}, 
      author={Senjian An and Farid Boussaid and Mohammed Bennamoun and Jiankun Hu},
      year={2017},
      eprint={1703.10355},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{Tree-cnn2019,
      title={Tree-CNN: A Hierarchical Deep Convolutional Neural Network for Incremental Learning}, 
      author={Deboleena Roy and Priyadarshini Panda and Kaushik Roy},
      year={2019},
      eprint={1802.05800},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{CNN,
      title={How convolutional neural network see the world - A survey of convolutional neural network visualization methods}, 
      author={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},
      year={2018},
      eprint={1804.11191},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{Nielsen,
      title={Neural Networks and Deep Learning}, 
      author={Michael A. Nielsen},
      year={2015},
      publisher={Determination press},
      url={http://neuralnetworksanddeeplearning.com}
}

@article{Tacchino2,
   title={Quantum implementation of an artificial feed-forward neural network},
   volume={5},
   ISSN={2058-9565},
   url={http://dx.doi.org/10.1088/2058-9565/abb8e4},
   DOI={10.1088/2058-9565/abb8e4},
   number={4},
   journal={Quantum Science and Technology},
   publisher={IOP Publishing},
   author={Tacchino, Francesco and Barkoutsos, Panagiotis and Macchiavello, Chiara and Tavernelli, Ivano and Gerace, Dario and Bajoni, Daniele},
   year={2020},
   month={Oct},
   pages={044010}
}

@article{Tacchino1,
   title={An artificial neuron implemented on an actual quantum processor},
   volume={5},
   ISSN={2056-6387},
   url={http://dx.doi.org/10.1038/s41534-019-0140-4},
   DOI={10.1038/s41534-019-0140-4},
   number={1},
   journal={npj Quantum Information},
   publisher={Springer Science and Business Media LLC},
   author={Tacchino, Francesco and Macchiavello, Chiara and Gerace, Dario and Bajoni, Daniele},
   year={2019},
   month={Mar}
}

@misc{similarTacchino,
      title={Universal discriminative quantum neural networks}, 
      author={Hongxiang Chen and Leonard Wossnig and Simone Severini and Hartmut Neven and Masoud Mohseni},
      year={2018},
      eprint={1805.08654},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@article{qBas,
	doi = {10.1038/s41534-019-0157-8},
  
	url = {https://doi.org/10.1038%2Fs41534-019-0157-8},
  
	year = 2019,
	month = {may},
  
	publisher = {Springer Science and Business Media {LLC}
},
  
	volume = {5},
  
	number = {1},
  
	author = {Marcello Benedetti and Delfina Garcia-Pintos and Oscar Perdomo and Vicente Leyton-Ortega and Yunseong Nam and Alejandro Perdomo-Ortiz},
  
	title = {A generative modeling approach for benchmarking and training shallow quantum circuits},
  
	journal = {npj Quantum Information}
}

@article{data_re-uploading,
   title={Data re-uploading for a universal quantum classifier},
   volume={4},
   ISSN={2521-327X},
   url={http://dx.doi.org/10.22331/q-2020-02-06-226},
   DOI={10.22331/q-2020-02-06-226},
   journal={Quantum},
   publisher={Verein zur Forderung des Open Access Publizierens in den Quantenwissenschaften},
   author={Pérez-Salinas, Adrián and Cervera-Lierta, Alba and Gil-Fuster, Elies and Latorre, José I.},
   year={2020},
   month={Feb},
   pages={226}
}

@article{XOR-def,
  title={Efficient synthesis of linear reversible circuits},
  author={Patel, Ketan N and Markov, Igor L and Hayes, John P},
  eprint={0302002},
  archivePrefix={arXiv},
  journal={arXiv preprint quant-ph/0302002},
  primaryClass={quant-ph},
  year={2003},
  url={https://arxiv.org/abs/quant-ph/0302002}
}

@article{schuld2020circuit,
   title={Circuit-centric quantum classifiers},
   volume={101},
   ISSN={2469-9934},
   url={http://dx.doi.org/10.1103/PhysRevA.101.032308},
   DOI={10.1103/physreva.101.032308},
   number={3},
   journal={Physical Review A},
   publisher={American Physical Society (APS)},
   author={Schuld, Maria and Bocharov, Alex and Svore, Krysta M. and Wiebe, Nathan},
   year={2020},
   month={Mar}
}


@article{oracles2,
author = {Panella, Massimo and Martinelli, Giuseppe},
title = {Neural networks with quantum architecture and quantum learning},
journal = {International Journal of Circuit Theory and Applications},
volume = {39},
number = {1},
pages = {61-77},
keywords = {quantum neural network, quantum architecture, quantum learning, nonlinear quantum circuit, exhaustive optimization},
doi = {https://doi.org/10.1002/cta.619},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cta.619},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cta.619},
abstract = {Abstract A method is proposed for solving the two key problems facing quantum neural networks: introduction of nonlinearity in the neuron operation and efficient use of quantum superposition in the learning algorithm. The former is indirectly solved by using suitable Boolean functions. The latter is based on the use of a suitable nonlinear quantum circuit. The resulting learning procedure does not apply any optimization method. The optimal neural network is obtained by applying an exhaustive search among all the possible solutions. The exhaustive search is carried out by the proposed quantum circuit composed of both linear and nonlinear components. Copyright © 2009 John Wiley \& Sons, Ltd.},
year = {2011}
}

@misc{McClean,
  title = {INTEGRATING OVER THE UNITARY GROUP},
  howpublished = {\url{https://jarrodmcclean.com/integrating-over-the-unitary-group/}},
  note = {Accessed: OCTOBER 14, 2015}
}

@article{Abbas_2021,
	doi = {10.1038/s43588-021-00084-1},
  
	url = {https://doi.org/10.1038%2Fs43588-021-00084-1},
  
	year = 2021,
	month = {jun},
  
	publisher = {Springer Science and Business Media {LLC}
},
  
	volume = {1},
  
	number = {6},
  
	pages = {403--409},
  
	author = {Amira Abbas and David Sutter and Christa Zoufal and Aurelien Lucchi and Alessio Figalli and Stefan Woerner},
  
	title = {The power of quantum neural networks},
  
	journal = {Nature Computational Science}
}

@misc{oracle1,
      title={Nonlinear Quantum Neuro-Psycho-Dynamics with Topological Phase Transitions}, 
      author={Vladimir G. Ivancevic and Tijana T. Ivancevic},
      year={2008},
      eprint={0807.3790},
      archivePrefix={arXiv},
      primaryClass={nlin.AO}
}

@misc{schuld2021quantum,
      title={Quantum machine learning models are kernel methods}, 
      author={Maria Schuld},
      year={2021},
      eprint={2101.11020},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@article{Schuld_Kiloran,
   title={Quantum Machine Learning in Feature Hilbert Spaces},
   volume={122},
   ISSN={1079-7114},
   url={http://dx.doi.org/10.1103/PhysRevLett.122.040504},
   DOI={10.1103/physrevlett.122.040504},
   number={4},
   journal={Physical Review Letters},
   publisher={American Physical Society (APS)},
   author={Schuld, Maria and Killoran, Nathan},
   year={2019},
   month={Feb}
}

@article{UHUH,
   title={Supervised learning with quantum-enhanced feature spaces},
   volume={567},
   ISSN={1476-4687},
   url={http://dx.doi.org/10.1038/s41586-019-0980-2},
   DOI={10.1038/s41586-019-0980-2},
   number={7747},
   journal={Nature},
   publisher={Springer Science and Business Media LLC},
   author={Havlíček, Vojtěch and Córcoles, Antonio D. and Temme, Kristan and Harrow, Aram W. and Kandala, Abhinav and Chow, Jerry M. and Gambetta, Jay M.},
   year={2019},
   month={Mar},
   pages={209–212}
}

@misc{huang2020power,
      title={Power of data in quantum machine learning}, 
      author={Hsin-Yuan Huang and Michael Broughton and Masoud Mohseni and Ryan Babbush and Sergio Boixo and Hartmut Neven and Jarrod R. McClean},
      year={2020},
      eprint={2011.01938},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@misc{schuld2020effect,
      title={The effect of data encoding on the expressive power of variational quantum machine learning models}, 
      author={Maria Schuld and Ryan Sweke and Johannes Jakob Meyer},
      year={2020},
      eprint={2008.08605},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@misc{data-encoding_Schuld,
      title={Quantum embeddings for machine learning}, 
      author={Seth Lloyd and Maria Schuld and Aroosa Ijaz and Josh Izaac and Nathan Killoran},
      year={2020},
      eprint={2001.03622},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@article{robust_data_encoding,
  title = {Robust data encodings for quantum classifiers},
  author = {LaRose, Ryan and Coyle, Brian},
  journal = {Phys. Rev. A},
  volume = {102},
  issue = {3},
  pages = {032420},
  numpages = {24},
  year = {2020},
  month = {Sep},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevA.102.032420},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.102.032420}
}

@article{Born_machine,
   title={Differentiable learning of quantum circuit Born machines},
   volume={98},
   ISSN={2469-9934},
   url={http://dx.doi.org/10.1103/PhysRevA.98.062324},
   DOI={10.1103/physreva.98.062324},
   number={6},
   journal={Physical Review A},
   publisher={American Physical Society (APS)},
   author={Liu, Jin-Guo and Wang, Lei},
   year={2018},
   month={Dec}
}

@misc{poggio2017deep,
      title={Why and When Can Deep -- but Not Shallow -- Networks Avoid the Curse of Dimensionality: a Review}, 
      author={Tomaso Poggio and Hrushikesh Mhaskar and Lorenzo Rosasco and Brando Miranda and Qianli Liao},
      year={2017},
      eprint={1611.00740},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{perezsalinas2021determining,
      title={Determining the proton content with a quantum computer}, 
      author={Adrián Pérez-Salinas and Juan Cruz-Martinez and Abdulla A. Alhajri and Stefano Carrazza},
      year={2021},
      eprint={2011.13934},
      archivePrefix={arXiv},
      primaryClass={hep-ph}
}

@misc{dqnn,
      title={Trainability of Dissipative Perceptron-Based Quantum Neural Networks}, 
      author={Kunal Sharma and M. Cerezo and Lukasz Cincio and Patrick J. Coles},
      year={2020},
      eprint={2005.12458},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@misc{NN_and_strucuter,
      title={How convolutional neural network see the world - A survey of convolutional neural network visualization methods}, 
      author={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},
      year={2018},
      eprint={1804.11191},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{cvpr,
  author={D. {Ciregan} and U. {Meier} and J. {Schmidhuber}},
  misctitle={2012 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Multi-column deep neural networks for image classification}, 
  year={2012},
  volume={},
  number={},
  pages={3642-3649},
  doi={10.1109/CVPR.2012.6248110}}
  
  @misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{qaoa,
      title={A Quantum Approximate Optimization Algorithm}, 
      author={Edward Farhi and Jeffrey Goldstone and Sam Gutmann},
      year={2014},
      eprint={1411.4028},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@article{VQE1,
   title={A variational eigenvalue solver on a photonic quantum processor},
   volume={5},
   ISSN={2041-1723},
   url={http://dx.doi.org/10.1038/ncomms5213},
   DOI={10.1038/ncomms5213},
   number={1},
   journal={Nature Communications},
   publisher={Springer Science and Business Media LLC},
   author={Peruzzo, Alberto and McClean, Jarrod and Shadbolt, Peter and Yung, Man-Hong and Zhou, Xiao-Qi and Love, Peter J. and Aspuru-Guzik, Alán and O’Brien, Jeremy L.},
   year={2014},
   month={Jul}
}

@inproceedings{qVol_theo,
  title={Quantum Volume},
  author={Lev Bishop and Sergey Bravyi and Andrew W. Cross and Jay M. Gambetta and John A. Smolin and March},
  year={2017}
}

@article{qVol_num,
	doi = {10.1088/2058-9565/aab822},
	url = {https://doi.org/10.1088/2058-9565/aab822},
	year = 2018,
	month = {jun},
	publisher = {{IOP} Publishing},
	volume = {3},
	number = {3},
	pages = {030503},
	author = {Nikolaj Moll and Panagiotis Barkoutsos and Lev S Bishop and Jerry M Chow and Andrew Cross and Daniel J Egger and Stefan Filipp and Andreas Fuhrer and Jay M Gambetta and Marc Ganzhorn and Abhinav Kandala and Antonio Mezzacapo and Peter Müller and Walter Riess and Gian Salis and John Smolin and Ivano Tavernelli and Kristan Temme},
	title = {Quantum optimization using variational algorithms on near-term quantum devices},
	journal = {Quantum Science and Technology}
}

@article{nature,
	doi = {10.1038/nature23879},
  
	url = {https://doi.org/10.1038%2Fnature23879},
  
	year = 2017,
	month = {sep},
  
	publisher = {Springer Science and Business Media {LLC}
},
  
	volume = {549},
  
	number = {7671},
  
	pages = {242--246},
  
	author = {Abhinav Kandala and Antonio Mezzacapo and Kristan Temme and Maika Takita and Markus Brink and Jerry M. Chow and Jay M. Gambetta},
  
	title = {Hardware-efficient variational quantum eigensolver for small molecules and quantum magnets},
  
	journal = {Nature}
}

@misc{VQE2,
      title={Classification with Quantum Neural Networks on Near Term Processors}, 
      author={Edward Farhi and Hartmut Neven},
      year={2018},
      eprint={1802.06002},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@article{nonlinearneuron,
   title={Nonlinear quantum neuron: A fundamental building block for quantum neural networks},
   volume={102},
   ISSN={2469-9934},
   url={http://dx.doi.org/10.1103/PhysRevA.102.052421},
   DOI={10.1103/physreva.102.052421},
   number={5},
   journal={Physical Review A},
   publisher={American Physical Society (APS)},
   author={Yan, Shilu and Qi, Hongsheng and Cui, Wei},
   year={2020},
   month={Nov}
}

@article{Wan_2017,
   title={Quantum generalisation of feedforward neural networks},
   volume={3},
   ISSN={2056-6387},
   url={http://dx.doi.org/10.1038/s41534-017-0032-4},
   DOI={10.1038/s41534-017-0032-4},
   number={1},
   journal={npj Quantum Information},
   publisher={Springer Science and Business Media LLC},
   author={Wan, Kwok Ho and Dahlsten, Oscar and Kristjánsson, Hlér and Gardner, Robert and Kim, M. S.},
   year={2017},
   month={Sep}
}

@article{rosenblatt1958perceptron,
  added-at = {2017-07-19T15:29:59.000+0200},
  author = {Rosenblatt, F.},
  biburl = {https://www.bibsonomy.org/bibtex/214ee8da21c66cd4d00d7ab6eca2d96a9/andreashdez},
  citeulike-article-id = {13697582},
  citeulike-linkout-0 = {http://dx.doi.org/10.1037/h0042519},
  doi = {10.1037/h0042519},
  interhash = {dc0cef9dc06033a04f525efdcde7a660},
  intrahash = {14ee8da21c66cd4d00d7ab6eca2d96a9},
  issn = {0033-295X},
  journal = {Psychological Review},
  keywords = {imported},
  number = 6,
  pages = {386--408},
  posted-at = {2016-05-02 20:23:36},
  priority = {2},
  timestamp = {2017-07-19T15:31:02.000+0200},
  title = {{The perceptron: A probabilistic model for information storage and organization in the brain.}},
  url = {http://dx.doi.org/10.1037/h0042519},
  volume = 65,
  year = 1958
}

@misc{sweke2020quantum,
      title={On the Quantum versus Classical Learnability of Discrete Distributions}, 
      author={Ryan Sweke and Jean-Pierre Seifert and Dominik Hangleiter and Jens Eisert},
      year={2020},
      eprint={2007.14451},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@article{Preskill_2018,
   title={Quantum Computing in the NISQ era and beyond},
   volume={2},
   ISSN={2521-327X},
   url={http://dx.doi.org/10.22331/q-2018-08-06-79},
   DOI={10.22331/q-2018-08-06-79},
   journal={Quantum},
   publisher={Verein zur Forderung des Open Access Publizierens in den Quantenwissenschaften},
   author={Preskill, John},
   year={2018},
   month={Aug},
   pages={79}
}

@misc{belkin2019reconciling,
      title={Reconciling modern machine learning practice and the bias-variance trade-off}, 
      author={Mikhail Belkin and Daniel Hsu and Siyuan Ma and Soumik Mandal},
      year={2019},
      eprint={1812.11118},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{YOUNES1996,
title = {Synchronous Boltzmann machines can be universal approximators},
journal = {Applied Mathematics Letters},
volume = {9},
number = {3},
pages = {109-113},
year = {1996},
issn = {0893-9659},
doi = {https://doi.org/10.1016/0893-9659(96)00041-9},
url = {https://www.sciencedirect.com/science/article/pii/0893965996000419},
author = {L. Younes},
keywords = {Synchronous random fields, Cellular automata, Gibbs distributions, Boltzmann machines, Neural networks},
abstract = {We prove in this paper that the class of reversible synchronous Boltzmann machines is universal for the representation of arbitrary functions defined on finite sets. This completes a similar result from Sussmann in the sequential case.}
}

@article{Tacchino3, 
  author={Tacchino, Francesco and Barkoutsos, Panagiotis Kl. and Macchiavello, Chiara and Gerace, Dario and Tavernelli, Ivano and Bajoni, Daniele},
  journal={2020 IEEE International Conference on Quantum Computing and Engineering (QCE)}, 
  title={Variational learning for quantum artificial neural networks}, 
  year={2020},
  volume={},
  number={},
  pages={130-136},
  doi={10.1109/QCE49297.2020.00026}
  }
  
 @article{Tacchino4,
   title={Quantum computing model of an artificial neuron with continuously valued input data},
   volume={1},
   ISSN={2632-2153},
   url={http://dx.doi.org/10.1088/2632-2153/abaf98},
   DOI={10.1088/2632-2153/abaf98},
   number={4},
   journal={Machine Learning: Science and Technology},
   publisher={IOP Publishing},
   author={Mangini, Stefano and Tacchino, Francesco and Gerace, Dario and Macchiavello, Chiara and Bajoni, Daniele},
   year={2020},
   month={Oct},
   pages={045008}
}

@book{book_Schuld,
author = {Schuld, Maria and Petruccione, Francesco},
misctitle = {Supervised Learning with Quantum Computers},
year = {2018},
publisher = {Springer Publishing Company, Incorporated},
edition = {1st},
abstract = {Quantum machine learning investigates how quantum computers can be used for data-driven prediction and decision making. The miscs summarises and conceptualises ideas of this relatively young discipline for an audience of computer scientists and physicists from a graduate level upwards. It aims at providing a starting point for those new to the field, showcasing a toy example of a quantum machine learning algorithm and providing a detailed introduction of the two parent disciplines. For more advanced readers, the misc discusses topics such as data encoding into quantum states, quantum algorithms and routines for inference and optimisation, as well as the construction and analysis of genuine ``quantum learning models''. A special focus lies on supervised learning, and applications for near-term quantum devices.},
url = {https://link.springer.com/book/10.1007%2F978-3-319-96424-9}
}

@article{pmlr-v22-montavon12, 
title = {Deep Boltzmann Machines as Feed-Forward Hierarchies}, author = {Gregoire Montavon and Mikio Braun and Klaus-Robert Muller}, 
title = {Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics}, 
pages = {798--804}, 
year = {2012}, 
editor = {Neil D. Lawrence and Mark Girolami}, 
volume = {22}, 
series = {Proceedings of Machine Learning Research}, 
address = {La Palma, Canary Islands}, month = {21--23 Apr}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v22/montavon12/montavon12.pdf}, url = {http://proceedings.mlr.press/v22/montavon12.html}, abstract = {The deep Boltzmann machine is a powerful model that extracts the hierarchical structure of observed data. While inference is typically slow due to its undirected nature, we argue that the emerging feature hierarchy is still explicit enough to be traversed in a feed-forward fashion. The claim is corroborated by training a set of deep neural networks on real data and measuring the evolution of the representation layer after layer. The analysis reveals that the deep Boltzmann machine produces a feed-forward hierarchy of increasingly invariant representations that clearly surpasses the layer-wise approach.} }

@misc{Nishimori,
author = {Nishimori, Hidetoshi},
doi = {10.1093/acprof:oso/9780198509417.001.0001},
isbn = {9780198509417},
month = {jul},
publisher = {Oxford University Press},
title = {Statistical Physics of Spin Glasses and Information Processing},
url = {https://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780198509417.001.0001/acprof-9780198509417},
year = {2001}
}

@misc{sharma2020trainability,
      title={Trainability of Dissipative Perceptron-Based Quantum Neural Networks}, 
      author={Kunal Sharma and M. Cerezo and Lukasz Cincio and Patrick J. Coles},
      year={2020},
      eprint={2005.12458},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}



@article{towardAI,
  title={Scaling learning algorithms towards AI},
  author={Bengio, Yoshua and LeCun, Yann and others},
  journal={Large-scale kernel machines},
  volume={34},
  number={5},
  pages={1--41},
  year={2007},
  url = { http://ieeexplore.ieee.org/document/6279976}
}

@article{congQuantumConvolutionalNeural2019,
  title = {Quantum Convolutional Neural Networks},
  author = {Cong, Iris and Choi, Soonwon and Lukin, Mikhail D.},
  year = {2019},
  month = dec,
  volume = {15},
  pages = {1273--1278},
  issn = {1745-2473, 1745-2481},
  doi = {10.1038/s41567-019-0648-8},
  file = {/Users/patrickhuembeli/Zotero/storage/WEQBF6K3/Cong et al. - 2019 - Quantum convolutional neural networks.pdf},
  journal = {Nature Physics},
  language = {en},
  number = {12}
}

@Inbook{Lloyd2003,
author="Lloyd, Seth
and Braunstein, Samuel L.",
editor="Braunstein, Samuel L.
and Pati, Arun K.",
title="Quantum Computation Over Continuous Variables",
bookTitle="Quantum Information with Continuous Variables",
year="2003",
publisher="Springer Netherlands",
address="Dordrecht",
pages="9--17",
abstract="This paper provides necessary and sufficient conditions for constructing a universal quantum computer over continuous variables. As an example, it is shown how a universal quantum computer for the amplitudes of the electromagnetic field might be constructed using simple linear devices such as beam splitters and phase shifters, together with squeezers and nonlinear devices such as Kerr-effect fibers and atoms in optical cavities. Such a device could in principle perform ``floating point'' computations. Problems of noise, finite precision, and error correction are discussed.",
isbn="978-94-015-1258-9",
doi="10.1007/978-94-015-1258-9_2",
url="https://doi.org/10.1007/978-94-015-1258-9_2"
}

@article{Erik,
   title={Unitary quantum perceptron as efficient universal approximator},
   volume={125},
   ISSN={1286-4854},
   url={http://dx.doi.org/10.1209/0295-5075/125/30004},
   DOI={10.1209/0295-5075/125/30004},
   number={3},
   journal={EPL (Europhysics Letters)},
   publisher={IOP Publishing},
   author={Torrontegui, E. and García-Ripoll, J. J.},
   year={2019},
   month={Mar},
   pages={30004}
}

@article{cybenkotApproximationSuperpositionsSigmoidal,
  abstract = {{In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function of n real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.}},
  added-at = {2012-03-02T03:39:18.000+0100},
  author = {Cybenko, G.},
  biburl = {https://www.bibsonomy.org/bibtex/2be85c56ae384216b2e35bdf79b7fb477/baby9992006},
  citeulike-article-id = {3561150},
  citeulike-linkout-0 = {http://dx.doi.org/10.1007/BF02551274},
  citeulike-linkout-1 = {http://www.springerlink.com/content/n873j15736072427},
  day = 1,
  doi = {10.1007/BF02551274},
  interhash = {96aecb02daa11041489259a8edb54070},
  intrahash = {be85c56ae384216b2e35bdf79b7fb477},
  issn = {0932-4194},
  journal = {Mathematics of Control, Signals, and Systems (MCSS)},
  keywords = {approximation, control, duckling, free, lunch, no, theorem, theory, ugly, universal},
  month = dec,
  number = 4,
  pages = {303--314},
  posted-at = {2012-02-28 13:17:08},
  priority = {2},
  publisher = {Springer London},
  timestamp = {2012-03-02T03:39:20.000+0100},
  title = {{Approximation by superpositions of a sigmoidal function}},
  url = {http://dx.doi.org/10.1007/BF02551274},
  volume = 2,
  year = 1989
}




@article{guRepresentationalPowerRestricted2020,
  title = {Towards the Representational Power of Restricted {{Boltzmann}} Machines},
  author = {Gu, Linyan and Zhou, Feng and Yang, Lihua},
  year = {2020},
  month = nov,
  volume = {415},
  pages = {358--367},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2020.07.090},
  abstract = {The restricted Boltzmann machine (RBM), which is a graphical model for binary random variables, has been proven to be a powerful tool in machine learning. However, theoretical foundations for understanding the approximation ability of RBMs are lacking. In this paper, we study the representational power of RBMs, with the focus lying on the sufficient number of hidden units of RBMs required to compute some classes of distributions of interest, with a fixed number of inputs. First, it is constructively shown how RBMs can approximate any distribution that depends on the scalar projection of the inputs onto a given vector up to arbitrary accuracy. Then, for any given distribution, we explore how it can be represented as the form that depends on the scalar projection of the inputs onto some vectors, and then study the properties of these vectors, from which a new proof for the universal approximation theorem of RBMs is deduced. Finally, we investigate the representational efficiency of RBMs by providing a description of all the distributions that can be efficiently computed by RBMs. More specifically, it is shown that a distribution can be computed by a polynomial-size RBM with polynomially bounded parameters, if and only if its mass can be computed by a two-layer feedforward network with threshold/ReLU activation functions, whose size and parameters are polynomially bounded.},
  file = {/Users/patrickhuembeli/Zotero/storage/HAAJV4NL/Gu et al. - 2020 - Towards the representational power of restricted B.pdf;/Users/patrickhuembeli/Zotero/storage/8T3SE4UA/S0925231220312546.html},
  journal = {Neurocomputing},
  keywords = {Representational efficiency,Representational power,Restricted Boltzmann machines,Threshold/ReLU neural networks},
  language = {en}
}

@article{patelEfficientSynthesisLinear2003a,
  title = {Efficient {{Synthesis}} of {{Linear Reversible Circuits}}},
  author = {Patel, K. N. and Markov, I. L. and Hayes, J. P.},
  year = {2003},
  month = feb,
  abstract = {In this paper we consider circuit synthesis for n-wire linear reversible circuits using the C-NOT gate library. These circuits are an important class of reversible circuits with applications to quantum computation. Previous algorithms, based on Gaussian elimination and LU-decomposition, yield circuits with O(n\^2) gates in the worst-case. However, an information theoretic bound suggests that it may be possible to reduce this to as few as O(n\^2/log n) gates. We present an algorithm that is optimal up to a multiplicative constant, as well as Theta(log n) times faster than previous methods. While our results are primarily asymptotic, simulation results show that even for relatively small n our algorithm is faster and yields more efficient circuits than the standard method. Generically our algorithm can be interpreted as a matrix decomposition algorithm, yielding an asymptotically efficient decomposition of a binary matrix into a product of elementary matrices.},
  archiveprefix = {arXiv},
  eprint = {quant-ph/0302002},
  eprinttype = {arxiv},
  file = {/Users/patrickhuembeli/Zotero/storage/XRPFD96G/Patel et al. - 2003 - Efficient Synthesis of Linear Reversible Circuits.pdf;/Users/patrickhuembeli/Zotero/storage/QH94MMAL/0302002.html},
  journal = {arXiv:quant-ph/0302002},
  keywords = {Quantum Physics}
}

@article{vinyalsGrandmasterLevelStarCraft2019,
  title = {Grandmaster Level in {{StarCraft II}} Using Multi-Agent Reinforcement Learning},
  author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P. and Jaderberg, Max and Vezhnevets, Alexander S. and Leblond, R{\'e}mi and Pohlen, Tobias and Dalibard, Valentin and Budden, David and Sulsky, Yury and Molloy, James and Paine, Tom L. and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Wu, Yuhuai and Ring, Roman and Yogatama, Dani and W{\"u}nsch, Dario and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Kavukcuoglu, Koray and Hassabis, Demis and Apps, Chris and Silver, David},
  year = {2019},
  month = nov,
  volume = {575},
  pages = {350--354},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1724-z},
  abstract = {Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions1\textendash 3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks5,6. We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players. AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.8\% of officially ranked human players.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
  file = {/Users/patrickhuembeli/Zotero/storage/B9LXRCTF/s41586-019-1724-z.html},
  journal = {Nature},
  language = {en},
  number = {7782}
}

@article{sousa2006universal,
  title={Universal quantum circuit for n-qubit quantum gate: A programmable quantum gate},
  author={Sousa, Paulo BM and Ramos, Rubens Viana},
  journal={arXiv preprint quant-ph/0602174},
  year={2006},
  url = {https://arxiv.org/abs/quant-ph/0602174}
}

@misc{perezsalinas2021qubit,
      title={One qubit as a Universal Approximant}, 
      author={Adrián Pérez-Salinas and David López-Núñez and Artur García-Sáez and P. Forn-Díaz and José I. Latorre},
      year={2021},
      eprint={2102.04032},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@book{geometry_of_quantum_states, place={Cambridge},
title={Geometry of Quantum States: An Introduction to Quantum Entanglement},
DOI={10.1017/CBO9780511535048}, publisher={Cambridge University Press}, 
author={Bengtsson, Ingemar and Zyczkowski, Karol}, year={2006}}

@book{wittek2014quantum,
  title={Quantum machine learning: what quantum computing means to data mining},
  author={Wittek, Peter},
  year={2014},
  publisher={Academic Press},
  DOI={10.1016/C2013-0-19170-2}
}

@article{bergholm2018pennylane,
  title={Pennylane: Automatic differentiation of hybrid quantum-classical computations},
  author={Bergholm, Ville and Izaac, Josh and Schuld, Maria and Gogolin, Christian and Alam, M Sohaib and Ahmed, Shahnawaz and Arrazola, Juan Miguel and Blank, Carsten and Delgado, Alain and Jahangiri, Soran and others},
  url = {https://arxiv.org/abs/1811.04968},
  journal={arXiv preprint arXiv:1811.04968},
  year={2018}
}

@misc{Git-repo,
  author = {A. Gratsea and P. Huembeli},
  title = {Explore quantum models with a teacher-student scheme} ,
  year = {2021},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/KaterinaGratsea/Teacher-student_scheme/blob/main/Teacher-Student_scheme.ipynb}
}

@article{PhysRevA.98.032309,
  title = {Quantum circuit learning},
  author = {Mitarai, K. and Negoro, M. and Kitagawa, M. and Fujii, K.},
  journal = {Phys. Rev. A},
  volume = {98},
  issue = {3},
  pages = {032309},
  numpages = {6},
  year = {2018},
  month = {Sep},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevA.98.032309},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.98.032309}
}

@article{Cao_2019,
	doi = {10.1021/acs.chemrev.8b00803},
  
	url = {https://doi.org/10.1021%2Facs.chemrev.8b00803},
  
	year = 2019,
	month = {aug},
  
	publisher = {American Chemical Society ({ACS})},
  
	volume = {119},
  
	number = {19},
  
	pages = {10856--10915},
  
	author = {Yudong Cao and Jonathan Romero and Jonathan P. Olson and Matthias Degroote and Peter D. Johnson and M{\'{a}
}ria Kieferov{\'{a}} and Ian D. Kivlichan and Tim Menke and Borja Peropadre and Nicolas P. D. Sawaya and Sukin Sim and Libor Veis and Al{\'{a}}n Aspuru-Guzik},
  
	title = {Quantum Chemistry in the Age of Quantum Computing},
  
	journal = {Chemical Reviews}
}

@article{PhysRevA.101.032308,
  title = {Circuit-centric quantum classifiers},
  author = {Schuld, Maria and Bocharov, Alex and Svore, Krysta M. and Wiebe, Nathan},
  journal = {Phys. Rev. A},
  volume = {101},
  issue = {3},
  pages = {032308},
  numpages = {8},
  year = {2020},
  month = {Mar},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevA.101.032308},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.101.032308}
}



@article{Ostaszewski_2021,
   title={Structure optimization for parameterized quantum circuits},
   volume={5},
   ISSN={2521-327X},
   url={http://dx.doi.org/10.22331/q-2021-01-28-391},
   DOI={10.22331/q-2021-01-28-391},
   journal={Quantum},
   publisher={Verein zur Forderung des Open Access Publizierens in den Quantenwissenschaften},
   author={Ostaszewski, Mateusz and Grant, Edward and Benedetti, Marcello},
   year={2021},
   month={Jan},
   pages={391}
}

@article{Schuld_kernel,
  doi = {10.48550/ARXIV.2101.11020},
  
  url = {https://arxiv.org/abs/2101.11020},
  
  author = {Schuld, Maria},
  
  keywords = {Quantum Physics (quant-ph), Machine Learning (stat.ML), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Supervised quantum machine learning models are kernel methods},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}



@article{ancilla_best,
  title = {Expressive power of parametrized quantum circuits},
  author = {Du, Yuxuan and Hsieh, Min-Hsiu and Liu, Tongliang and Tao, Dacheng},
  journal = {Phys. Rev. Research},
  volume = {2},
  issue = {3},
  pages = {033125},
  numpages = {16},
  year = {2020},
  month = {Jul},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevResearch.2.033125},
  url = {https://link.aps.org/doi/10.1103/PhysRevResearch.2.033125}
}

@misc{NC_book,
  Author = {Michael A. Nielsen and Isaac L. Chuang},
  Title = {Quantum Computation and Quantum Information: 10th Anniversary Edition},
  Publisher = {Cambridge University Press},
  Year = {2011},
  ISBN = {9781107002173}
}



@article{Economou,
	doi = {10.1103/prxquantum.2.020310},
  
	url = {https://doi.org/10.1103%2Fprxquantum.2.020310},
  
	year = 2021,
	month = {apr},
  
	publisher = {American Physical Society ({APS})},
  
	volume = {2},
  
	number = {2},
  
	author = {Ho Lun Tang and V.O. Shkolnikov and George S. Barron and Harper R. Grimsley and Nicholas J. Mayhall and Edwin Barnes and Sophia E. Economou},
  
	title = {Qubit-{ADAPT}-{VQE}: An Adaptive Algorithm for Constructing Hardware-Efficient Ansätze on a Quantum Processor},
  
	journal = {{PRX} Quantum}
}


@article{scrambling,
	doi = {10.1103/physrevresearch.3.l032057},
  
	url = {https://doi.org/10.1103%2Fphysrevresearch.3.l032057},
  
	year = 2021,
	month = {sep},
  
	publisher = {American Physical Society ({APS})},
  
	volume = {3},
  
	number = {3},
  
	author = {Yadong Wu and Pengfei Zhang and Hui Zhai},
  
	title = {Scrambling ability of quantum neural network architectures},
  
	journal = {Physical Review Research}
}

@article{Nahum_2018,
	doi = {10.1103/physrevx.8.021014},
  
	url = {https://doi.org/10.1103%2Fphysrevx.8.021014},
  
	year = 2018,
	month = {apr},
  
	publisher = {American Physical Society ({APS})},
  
	volume = {8},
  
	number = {2},
  
	author = {Adam Nahum and Sagar Vijay and Jeongwan Haah},
  
	title = {Operator Spreading in Random Unitary Circuits},
  
	journal = {Physical Review X}
}

@misc{modern_applications,
  doi = {10.48550/ARXIV.2204.04198},
  
  url = {https://arxiv.org/abs/2204.04198},
  
  author = {Dawid, Anna and Arnold, Julian and Requena, Borja and Gresch, Alexander and Płodzień, Marcin and Donatella, Kaelan and Nicoli, Kim and Stornati, Paolo and Koch, Rouven and Büttner, Miriam and Okuła, Robert and Muñoz-Gil, Gorka and Vargas-Hernández, Rodrigo A. and Cervera-Lierta, Alba and Carrasquilla, Juan and Dunjko, Vedran and Gabrié, Marylou and Huembeli, Patrick and van Nieuwenburg, Evert and Vicentini, Filippo and Wang, Lei and Wetzel, Sebastian J. and Carleo, Giuseppe and Greplová, Eliška and Krems, Roman and Marquardt, Florian and Tomza, Michał and Lewenstein, Maciej and Dauphin, Alexandre},
  
  keywords = {Quantum Physics (quant-ph), Disordered Systems and Neural Networks (cond-mat.dis-nn), Mesoscale and Nanoscale Physics (cond-mat.mes-hall), FOS: Physical sciences, FOS: Physical sciences},
  
  title = {Modern applications of machine learning in quantum sciences},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@article{Lewenstein_2021,
	doi = {10.1088/2058-9565/ac070f},
	url = {https://doi.org/10.1088/2058-9565/ac070f},
	year = 2021,
	month = {jul},
	publisher = {{IOP} Publishing},
	volume = {6},
	number = {4},
	pages = {045002},
	author = {Maciej Lewenstein and Aikaterini Gratsea and Andreu Riera-Campeny and Albert Aloy and Valentin Kasper and Anna Sanpera},
	title = {Storage capacity and learning capability of quantum neural networks},
	journal = {Quantum Science and Technology},
	abstract = {We study the storage capacity of quantum neural networks (QNNs), described by completely positive trace preserving (CPTP) maps acting on an N-dimensional Hilbert space. We demonstrate that attractor QNNs can store in a non-trivial manner up to N linearly independent pure states. For n qubits, QNNs can reach an exponential storage capacity, , clearly outperforming standard classical neural networks whose storage capacity scales linearly with the number of neurons n. We estimate, employing the Gardner program, the relative volume of CPTP maps with M ⩽ N stationary states and show that this volume decreases exponentially with M and shrinks to zero for M ⩾ N + 1. We generalize our results to QNNs storing mixed states as well as input–output relations for feed-forward QNNs. Our approach opens the path to relate storage properties of QNNs to the quantum features of the input–output states. This paper is dedicated to the memory of Peter Wittek.}
}

@misc{symmetry,
  doi = {10.48550/ARXIV.2205.06217},
  
  url = {https://arxiv.org/abs/2205.06217},
  
  author = {Meyer, Johannes Jakob and Mularski, Marian and Gil-Fuster, Elies and Mele, Antonio Anna and Arzani, Francesco and Wilms, Alissa and Eisert, Jens},
  
  keywords = {Quantum Physics (quant-ph), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Exploiting symmetry in variational quantum machine learning},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{Haferkamp_2022,
	doi = {10.1038/s41567-022-01539-6},
  
	url = {https://doi.org/10.1038%2Fs41567-022-01539-6},
  
	year = 2022,
	month = {mar},
  
	publisher = {Springer Science and Business Media {LLC}
},
  
	volume = {18},
  
	number = {5},
  
	pages = {528--532},
  
	author = {Jonas Haferkamp and Philippe Faist and Naga B. T. Kothakonda and Jens Eisert and Nicole Yunger Halpern},
  
	title = {Linear growth of quantum circuit complexity},
  
	journal = {Nature Physics}
}

@misc{q_advantage,
  doi = {10.48550/ARXIV.2101.06250},
  
  url = {https://arxiv.org/abs/2101.06250},
  
  author = {Alcazar, Javier and Perdomo-Ortiz, Alejandro},
  
  keywords = {Quantum Physics (quant-ph), FOS: Physical sciences, FOS: Physical sciences},
  
  title = {Enhancing Combinatorial Optimization with Quantum Generative Models},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{quantum_advantage,
  doi = {10.48550/ARXIV.2203.01340},
  
  url = {https://arxiv.org/abs/2203.01340},
  
  author = {Schuld, Maria and Killoran, Nathan},
  
  keywords = {Quantum Physics (quant-ph), FOS: Physical sciences, FOS: Physical sciences},
  
  title = {Is quantum advantage the right goal for quantum machine learning?},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@article{Roberts_2018,
	doi = {10.1007/jhep06(2018)122},
  
	url = {https://doi.org/10.1007%2Fjhep06%282018%29122},
  
	year = 2018,
	month = {jun},
  
	publisher = {Springer Science and Business Media {LLC}
},
  
	volume = {2018},
  
	number = {6},
  
	author = {Daniel A. Roberts and Douglas Stanford and Alexandre Streicher},
  
	title = {Operator growth in the {SYK} model},
  
	journal = {Journal of High Energy Physics}
}