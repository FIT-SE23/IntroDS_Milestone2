%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
\documentclass[pdflatex,sn-mathphys]{sn-jnl}% Math and Physical Sciences Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[sn-vancouver]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style
% \documentclass[sn-standardnature]{sn-jnl}% Standard Nature Portfolio Reference Style
%%\documentclass[default]{sn-jnl}% Default
%%\documentclass[default,iicol]{sn-jnl}% Default with double column layout


\jyear{2021}%

% \usepackage{natbib}


\usepackage{graphicx}  %插入图片的宏包
\usepackage{float}  %设置图片浮动位置的宏包
\usepackage{subfigure}  %插入多图时用子图显示的宏包
\usepackage{wrapfig}
% \begin{wrapfigure}{r}{0pt}
%     \centering
%     \includegraphics[width=0.4\columnwidth]{causal_viz.png}
%     \caption{Causal graph of sampling process.}
%     \label{fig:dag-fig}
% \end{wrapfigure}

\usepackage{caption}
\usepackage{booktabs}
\usepackage{epsfig}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{mathtools}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{makecell}
\usepackage{array}
\usepackage{hhline}


%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}

\title[Article Title]{Knowledge is Power: Understanding Causality Makes Legal Judgment Prediction Models More Generalizable and Robust}

%%=============================================================%%
%% Prefix	-> \pfx{Dr}
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% NatureName	-> \tanm{Poet Laureate} -> Title after name
%% Degrees	-> \dgr{MSc, PhD}
%% \author*[1,2]{\pfx{Dr} \fnm{Joergen W.} \spfx{van der} \sur{Ploeg} \sfx{IV} \tanm{Poet Laureate} 
%%                 \dgr{MSc, PhD}}\email{iauthor@gmail.com}
%%=============================================================%%

\author[1]{\fnm{Haotian} \sur{Chen}}\email{htchen18@fudan.edu.com}

\author[2]{\fnm{Lingwei} \sur{Zhang}}\email{lzhan218@jh.edu}
% \equalcont{These authors contributed equally to this work.}

\author[3]{\fnm{Yiran} \sur{Liu}}\email{liu-yr21@mails.tsinghua.edu.cn}
% \equalcont{These authors contributed equally to this work.} chenfc18@fudan.edu.cn

\author[1]{\fnm{Fanchao} \sur{Chen}}\email{chenfc18@fudan.edu.cn}

\author*[3]{\fnm{Yang} \sur{Yu}}\email{yangyu1@tsinghua.edu.cn}

\affil[1]{\orgdiv{School of Computer Science}, \orgname{Fudan University}, \orgaddress{\city{Shanghai}, \postcode{200433}, \country{China}}}

% \affil*[2]{\orgdiv{Department}, \orgname{Organization}, \orgaddress{\street{Street}, \city{City}, \postcode{10587}, \state{State}, \country{Country}}}

\affil[2]{\orgdiv{Department of Computer Science}, \orgname{Johns Hopkins University}, \orgaddress{\street{3910 Keswick Road}, \city{Baltimore}, \postcode{21211}, \state{MD}, \country{United States}}}

\affil[3]{\orgdiv{Institute for Interdisciplinary Information Sciences}, \orgname{Tsinghua University}, \orgaddress{\city{Beijing}, \postcode{610101}, \country{China}}}

%%==================================%%
%% sample for unstructured abstract %%
%%==================================%%

\abstract{
Legal Judgment Prediction (LJP), aiming to predict a judgment based on fact descriptions according to rule of law, serves as legal assistance to mitigate the great work burden of limited legal practitioners. Most existing methods apply various large-scale pre-trained language models (PLMs) finetuned in LJP tasks to obtain consistent improvements. However, we discover the fact that the state-of-the-art (SOTA) model makes judgment predictions according to irrelevant (or non-casual) information. The violation of rule of law not only weakens the robustness and generalization ability of models but also results in severe social problems like discrimination. In this paper, we use causal structural models (SCMs) to theoretically analyze how LJP models learn to make decisions and why they can succeed in passing the traditional testing paradigm without learning causality. According to our analysis, we provide two solutions intervening on data and model by causality, respectively. In detail, we first distinguish non-causal information by applying the open information extraction (OIE) technique. Then, we propose a method named the \textbf{C}ausal \textbf{I}nformation \textbf{E}nhanced \textbf{SA}mpling \textbf{M}ethod (CIESAM) to eliminate the non-causal information from data. To validate our theoretical analysis, we further propose another method using our proposed Causality-Aware Self-Attention Mechanism (CASAM) to guide the model to learn the underlying causality knowledge in legal texts. The confidence of CASAM in learning causal information is higher than that of CIESAM. The extensive experimental results show that both our proposed methods achieve state-of-the-art (SOTA) performance on three commonly used legal-specific datasets. The stronger performance of CASAM further demonstrates that causality is the key to the robustness and generalization ability of models. 
% which refines plain texts to form relational triplets (knowledge) having a high proportion of causal information.
% Then, by paying more attention to more potential causal information and restricting the consideration of irrelevant ones, CASAM tends to make predictions according to causality. The extensive experimental results show that our model is more generalizable and robust than the baselines and achieves a new SOTA performance on three commonly used legal-specific datasets. 
}

%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

% \keywords{keyword1, Keyword2, Keyword3, Keyword4}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section{Introduction}
Understanding why is critical for Legal Judgment prediction (LJP) models, which determines whether the legal artificial intelligence (legal AI) yields to the rule of law or to the rule of correlation. LJP is a crucial task of legal AI. A LJP model aims at assisting the legal practice by predicting the judgment of a certain case (e.g., charge, term of penalty, or law article) according to the corresponding case fact descriptions~\cite{zhao2022legal,cui2022survey}. In contrast to other natural-language processing tasks, the LJP model must correctly learn the reasons behind each case rather than only make predictions. Rule of law defines the uniform principles and protocols for all judgments in a country. Every judgment must have a clear reasoning process that can cite back to the rules in the laws. Therefore, there exists a stable and uniform common ground-truth knowledge underlying all judgment cases. If a LJP model is legitimated to be adopted for legal practice, it has to learn the common ground-truth knowledge. Otherwise, the judgment prediction is invalid even if it is accurate when fitting the historical cases. To sum up, only by learning rules of law represented by common ground causality, can models perform better, achieve more robustness, and be trustworthy. %Judges make the judgments based on rules of law (law articles), which can also be referred to as a certain kind of causal mechanism. Therefore, learning the underlying common ground knowledge (causality) in training data is the desiderata w.r.t. AI for law. 

Previous methods on legal text processing are based on rules~\cite{lawlor1963computers}, statistical methods~\cite{nagel1960weighting,keown1980mathematical}, or machine learning methods~\cite{katz2012quantitative,aletras2016predicting}, which suffers from being sensitive to noises and lacking generalization ability w.r.t. other law domains. Recently, the rapid development of large-scale pre-trained language models (PLMs) based on transformers significantly benefits this area~\cite{cui2022survey}. Some of the PLMs including BERT~\cite{devlin2018bert} are further pre-trained on legal corpora, such as Legal-BERT~\cite{chalkidis2020legalbert}, exhibiting the SOTA performance on legal text processing benchmarks (e.g., LexGLUE)~\cite{zheng2021when,chalkidis2022lexgluea}.


However, we found clues that the commonly adopted state-of-art LJP model~\cite{chalkidis2020legalbert} misunderstands the data and learns the spurious correlations. The current LJP model can make right predictions according to irrelevant reasons, which has not been reported yet. In Figure~\ref{fig:0}, we provide an example, where the prediction of Legal-BERT is reversed by a small change that does not cause an essential semantic change. Further, we discovered that the most important keywords deciding the model predictions mainly concentrated on punctuation marks and function words. A large number of predictions only rely on less than $5\%$ of words from the fact descriptions rather than considering the whole text as shown in Figure~\ref{fig:0}. All the evidence indicates that the current LJP models learn spurious correlations or shortcuts~\cite{geirhos2020shortcut} rather than the common ground-truth knowledge about the rules of the laws. 

% \begin{figure*}
%   \centering
  
%   \includegraphics[width=1.0\linewidth]{pictures/12.png}
%   \caption{Causal model of spurious correlation error}
%   \label{level}
% \end{figure*}

\begin{figure*}
  \centering
  \includegraphics[width=1.0\linewidth]{picture_new/Legal-Intro.pdf}
  \caption{An example of reversed prediction caused by character substitution.}
  \label{fig:0}
\end{figure*}

% 之所以出现这个问题，是模型开发的时候，从设计训练检验三方面都有问题。task的本质是从数据中反推结果，有很多可能性。architecture问题是没有用到已有知识降低不确定性，呼应human in the loop，使得模型没办法分辨。training问题是每个case里面的文本都有data imbalance。testing有问题，前面完成不了，我也发现不了。只看performance，没有attack，必须要有adversarial attack的这种testing。光划分数据集没用，test集也有这样的问题。组织人们对aigc进行attack的检验，看看有没有违反价值观等的问题。
In this paper, we reveal the principles for tackling the fatal problem. We use structural causal models (SCMs) to theoretically analyze the mechanism of learning models in the LJP task and then argue that three factors hamper the development of the current LJP models. Specifically, our analysis derives that the main challenge of learning models in this task is to infer the unique causal mechanism from its generated training data. Significant development rarely occurs in tackling this challenge due to three reasons. First, the learning models themselves neglect the use of human knowledge, which largely increases the uncertainty for them to infer causal relationships from the training data. Second, each case in the training data suffers from the problem of data imbalance, where high-frequency words often co-occur with other words and thus lead to the spurious correlation issue. Third, our current evaluation methods focus on measuring average error across a held-out test set, neglecting the fact that the test set and training set are identically independently distributed (i.i.d.): Models just need to greedily absorb all correlations that happen to be predictive in the test set even if they are not causal relationships. 

To address the issues, we provide two methods focusing on the improvement of training data and the architecture of models, respectively. From the perspective of data, we focus on mitigating the disturbance from non-causal information by removing them from the training data and thus propose a causal information-enhanced sampling method (CIESAM). From the perspective of model architecture, we aim to prevent the PLM from learning non-causal information by restricting the interaction (represented by attention weights) between causal and non-causal words. Specifically, we propose a causality-aware self-attention mechanism (CASAM) to reallocate the attention weights throughout the overall transformer encoder, which leads the PLM to pay more attention to causal information. The extensive experimental results show that both of our proposed methods perform better on generalization and robustness than the baseline models and achieve new SOTA performance on the three commonly used legal prediction datasets. Additionally, CASAM performs better than CIESAM as it learns from the unique ground-truth causal relationship.

\section{Problem Settings}
In this section, we propose a structural causal model to analyze the mechanism of learning models in the LJP task and then point out three factors that impede them from learning the rule of law. 


% How can these spurious correlations be learned? To minimize training errors, the self-attention mechanism in transformer-based PLMs greedily absorbs all correlations in training data for prediction~\cite{shen2021outofdistribution}. The mechanism resorts to such correlations through the dependencies among words, which are constructed by the unsupervised attention weights, and the weights will be inevitably misled by dataset bias due to the lack of relationship dependency annotation for the self-attention mechanism~\cite{yang2021causal}. Therefore, models learn spurious correlations instead of causal relationships. Predicting without understanding causality (e.g., rule of law) not only hurts the trust in the LJP models but also weakens the generalization ability and robustness of models. If the model does not learn the ground-truth knowledge underlying the cases but overfits for spurious correlations, the model is hard to work well in another dataset that has different writing patterns~\cite{cui2022stable}. Relying on spurious information also renders the model more vulnerable to adversarial attacks. If the irrelevant features are modified (attacked), models will largely change their predictions, which brings severe social problems. 

%这里我们提出了方法来解决问题。这个问题的挑战是什么。我们是怎么解决的。

%The phenomenon results in two consequences w.r.t. existing models: performance decline and being vulnerable to attacks. The underlying causes of the former is that the process of learning spurious correlations can be referred to as shortcut learning~\cite{geirhos2020shortcut}, where the learned shortcuts can not replace the common ground causalities and are demonstrated to damage the generalization ability of models. The damage worsens especially when the distribution of some test samples shifts significantly from the training data~\cite{cui2022stable}. The reason why models can be vulnerable to attacks is that the biased decision rules of models (distorted rules of law such as shortcuts) become the source of vulnerabilities.  

%In the current popular paradigm where models are required to directly learn from the sampled training data, models can suffer from overfitting: Models wrongly learn to predict based on the data-specific spurious features which is referred to as sampling bias. For example, X in CV, X in NLP ... As to existing models in LJP, we discover that they 

% In this paper, we use structural causal models (SCMs) to theoretically analyze the mechanism of how the nature of legal text data leads the LJP model to learn spurious correlations. We demonstrate that: (1) learning the spurious correlations makes the LJP models less generalizable and more vulnerable; and (2) the larger amount of causal information is learned by models, the stronger robustness and generalization ability will they achieve. To experimentally validate our analysis, we provide two methods focusing on the improvement of training data and the architecture of models, respectively. From the perspective of data, we focus on mitigating the disturbance from non-causal information by removing them from the training data and thus propose causal information enhanced sampling method (CIESAM). From the perspective of model architecture, we aim to prevent the PLM from learning non-causal information by restricting the interaction (represented by attention weights) between causal and non-causal words. To this end, we propose a causality-aware self-attention mechanism (CASAM) to reallocate the attention weights throughout the overall transformer encoder, which leads the PLM to pay more attention to causal information. The extensive experimental results show that both of our proposed methods perform better on generalization and robustness than the baseline models and achieve new SOTA performance on the three commonly used legal prediction datasets. Additionally, CASAM performs better than CIESAM as it learns from the unique ground-truth causal relationship.



% 文本中其实含有法律信息，就是图2generate的数据。但是一些东西阻碍了机器从数据中学到图示的关系。
% 为什么学不到causal成因
% imbalance of sample cases: sample augmentation or weighted approach can solve.
% imbalance of causal-noncausal information: above two approaches does not work. 
% 真实情况是图2，机器see-effect得到T和Y，因此要区分变量之间所有可能的情况，所有情况是图3，机器要从这些图里面找到对应的图并拟合配套的f。可是上述两种imbalance干扰了机器找到真实的结构和方程: rule of law。
% 1. 为了解决第一种imbalance，可以augmentation之后用training-testing来解决。
% 2. 如果解决第二种imbalance，training-testing就不够了。原因有二，其一，training和testing中本身都存在causal-noncausal的imbalance，因为有独立同分布假设。其二，causal-noncausal的imbalance不是简单可分的，都耦合在一起了，现在DNN从文本中抽取高维信息做分类（经过语义组合后的特征才真正构成因果信息）。所以在原始数据中无法进行data augmentation或者weights的计算。
% 3. 那为了学到真正的法律信息，我们需要熵减，需要外部信息的引入。外部信息可以通过先验知识引入，也可以通过human-in-the-loop输入，其目的都是为了让机器注意到causal information。

% \section{Causality of Legal Judgment Prediction}
% In this section, we detail the following logic: (1) there exists a stable and uniform common ground-truth causal relationship underlying all judgment cases (discussed in Section~\ref{SCM-sec1}); (2) it is essential for LJP models to learn the unique ground-truth causal relationship (discussed in Section~\ref{SCM-sec1}); (3) previous methods inevitably learn spurious correlations instead of causation (explained in Section~\ref{origin-sec2}); (4) learning spurious correlations instead of the ground-truth causation weakens the robustness and generalization ability of models (explained in Section~\ref{influence-sec3}); (5) the weakened ability can hardly be detected by the commonly used testing paradigm (elaborated in Section~\ref{deficiency-sec4}); (6) only by training a LJP model to learn the unique ground-truth causal relationship, can we obtain a trustworthy and well-performed model (derived in Section~\ref{learning-sec5}).
% In this section, we detail the following logic: (1) The training data is generated by the rule of law, thus containing the causal relationships that can be learned by models (discussed in Section~\ref{SCM-sec1}); (2) Two major challenges, presented by the imbalance of sample cases and the imbalance of causal and non-causal information, impede models from learning the rule of law (Section~\ref{challenge:sec2}); (3) failing to tackle the challenge renders models untrustworthy and far from being deployed in real-world applications (Section~\ref{influence-sec3}); (4) The first challenge can be addressed straightforwardly by selecting models that succeed in the training-testing paradigm with sample augmentation or weighted approach while the second challenge cannot be addressed in the same way due to i.i.d assumption and the entanglement of causal and non-causal information (Section~\ref{learning-sec5}). (5) Introducing external human knowledge is the key to making models learn causal relationships (i.e., rule of law; Section~\ref{learning-sec5}). 


\subsection{Structural Causal Model}
\label{SCM-sec1}
Here, we propose a structural causal model (SCM) to explain the underlying causal relationships in the LJP task. The SCM~\cite{pearl2009causal} represents the causal relations between variables by a directed acyclic graph (DAG). It denotes the random variables as nodes while their causal relationships as the directed edges. Literature~\cite{pearl2009causal} demonstrated that the same DAG also captures the conditional correlations between the same set of random variables. For example, we denote the fact that $X$ directly causes $Y$ by $X \rightarrow Y$. If $X$ is the common cause of both $Y$ and $Z$, the latter two variables are independent given $X$. 

The rules of law define a basket of causal relations between the facts of the criminal cases and the associated judgments. Because all judges have to follow the rules, the judgment cases in the same country must have a stable relationship between the facts and the judgments no matter the variance of judges. Therefore, we call those pieces of information about the facts deciding the judgments as the causal information $C$. While a judge prepares the case description $T$, she has to explain the relationship between the facts and the judgment $Y$. Beyond, $T$ is also contingent on other features denoted by $N$, such as the grammar principle and individual writing patterns. The features of $N$ do not influence the judgment $Y$ in the ground truth and are denoted as non-causal information. Due to the grammar requirements and other reasons, $N$ and $C$ can be correlated with each other. We model the above causal relation in Figure~\ref{causal-graph} named the current paradigm of learning models. According to the rules of law, $N$ has to be independent of $Y$. 
For example, for a fact description $T$ expressed by \textit{Bob, a 47 years old European white male, robbed Alice of her car.}, a court will make the judgment that Bob commits a robbery, regardless of the gender, race, region, or age of Bob. In this case, the event description \textit{Bob robbed Alice of her car} includes the causal information $C$ while the demographic information of Bob, as well as the usage of the function words, are non-causal information $N$. The usage of the function words, which is part of $N$, can correlate with the texts including $C$. 

\begin{figure}
  \centering
  \includegraphics[width=1.0\linewidth]{picture_new/Prob-Form.pdf}
  \caption{Structural causal model of the LJP task. The rule of law generates the data in LJP, and models are expected to accurately estimate the correlations between variables (the unique causal graph in purple). There are various potential results that are all optimal and possible to be learned by models. Three problems prevent models from learning the purple causal graph. Our proposed CIESAM filters the 4 yellow graphs and CASAM filters 10 graphs including the yellow and blue ones.}
  \label{causal-graph}
\end{figure}

% 根据因果图说为什么阻碍了模型学到因果。
\subsection{Three Unsolved Problems}
\label{challenge:sec2}
% In this section, we first explain how models can learn causality and then introduce two major challenges faced by learning models in the process of learning causality. 
In this section, we first explain how models can learn causality and then introduce three unsolved problems that prevent learning models from learning causality. 

\subsubsection{How to Learn Causality}
\label{how-to-learn-causality}
Models learn the correlation relationships among variables, which can be generated in either of the three ways: causality, confounding, and data selection bias~\cite{cui2022stable}. Only the correlations generated by causality are what we expect the models to learn from. For example, in Figure~\ref{causal-graph}, the correlation effect between $C$ and $Y$ learned by models equals the causal effect, which faithfully reflects their intrinsic dependency. Correlations generated in two other ways are often referred to as spurious correlations, which bring the following two challenges and hamper models from learning causality.

\subsubsection{Data Imbalance}
The first problem is data imbalance (i.e., selection bias). Usually, the raw data of case descriptions compose an imbalanced dataset of $C$, $N$, and $Y$. We use data-driven methods to train different models (estimators) for learning the correlation relationships between input variables and output variables~\cite{cui2022stable}. Consequently, the learning model can incorrectly fit the correlations between those variables. For instance, male criminals can be penalized harder than female ones in robbery cases because the males are stronger and thus can cause more serious damage. The random sampling process involves more cases where men cause serious damage. The data imbalance can lead the LJP model to misunderstand the relationship between gender (non-causal information $N$) and penalty decision (prediction $Y$) in robbery cases, thus causing the learning model to overfit the correlation between gender and penalty to improve its performance on the test set.

\subsubsection{Lack of Human Knowledge}
The second problem is the imbalance and entanglement between causal and non-causal information, which makes models unable to distinguish the correlations generated by causal information. Specifically, current LJP models are trained to self-explore $P(Y \mid T)$, the correlation between $Y$ and $T$, rather than directly learning $P(Y \mid C)$ due to the difficulty of comprehensively figuring out $C$. The learning process can lead the LJP model to learn the incorrect causal relation between $C$, $N$, and $Y$. Therefore, extra information that can reduce the information entropy, such as causal information or human knowledge, is of great urgency. Our logic basics are as follows. 

% 从头捋模型做了什么事
\noindent \textbf{Multiple Potential Estimating Results.} In the LJP task, judges recognize the causal relationship between the causal information in fact descriptions and their final prediction (i.e., $C \rightarrow Y$) in each case for fairness. The causal relationship between C and Y manifests the rule of law and is considered stable across all cases. Since models are not able to distinguish causal relationships, they are expected to accurately learn the correlation between $C$ and $Y$ from the training data to form the unique ground truth solution to LJP: The learned correlation between $C$ and $Y$ will be causal relation if there are no other spurious correlations in the training data. However, existing LJP models suffer from learning the ground truth causal relation. They are delicately designed to fit $P(Y \mid T)$, which generates spurious correlations between both ``$C$ and $N$'' and ``$N$ and $Y$'' in situations where $T$ is given as shown in Figure~\ref{causal-graph}. Consequently, there exist multiple potential learning results, which depend on the optimization process. The optimization process can also be random if the optimizer is developed from stochastic gradient descent. We list all of the potential decision rules (causality) in Figure~\ref{causal-graph} that are possible to be learned by models and presented by parameters.

% 黄色为什么，因为我只是把C丢给模型，让模型多学学C到Y，但是我没有告诉模型N和C之间是什么关系，所以当N和C一起被丢给模型的时候，模型无法区分N和C之间的指向关系，这就造成了N-C-Y有一条通路。这个通路就无法被打断。而模型可以打断这个。
% \begin{figure*}
%   \centering
%   \includegraphics[width=1.0\linewidth]{picture_new/causal-solutions.pdf}
%   \caption{All of the potential learning results from a given dataset. The training paradigm filters out some potential combinations of causal relationships (14 kinds of causal graphs in purple) as models are given $C$ and $N$ to predict $Y$. Based on the commonly used training paradigm, our proposed pipeline method CIECAM removes $N$ from training data, thus filtering another 6 kinds of graphs in yellow. CIECAM is not trained to learn the ground-truth causal relationship between $C$ and $N$, which is further conquered by CASAM through using attention weights to block $N$. CASAM filters 24 kinds of graphs, leaving the unique ground-truth graph for PLMs to learn.}
%   \label{causal-solution}
% \end{figure*}

\noindent \textbf{All Estimating Results Can be Optimal.} From the 25 potential learning results in Figure~\ref{causal-graph}, 11 results are optimal w.r.t. the training objective: They can experimentally (which is demonstrated by baseline models) and theoretically minimize the loss function to zero. The underlying reason is that most learned spurious correlations will establish in the testing set as the training set and test set are identically and independently distributed (sampled from the same distribution). In this setting, models greedily learn all correlations including spurious correlations to improve their performance with the cost of their generalization ability and robustness. We select the best-performed one while neglecting its other ability. To solve the issue, we communicate with legal experts to propose several legal-specific attacks for evaluation, the corresponding experiments and details are shown in Section~\ref{exp-settings} and Section~\ref{exp-robustness}. 

\noindent \textbf{Only One of Them is Our Need.} Among those correlations, only the correlation generated by $C \rightarrow Y$ is the ground truth solution that a model ought to learn. However, learning the correlation generated by $C \rightarrow Y$ becomes a random event $R$, whose probability can be determined by many factors, including training data and model. 

\subsubsection{Incomplete Testing Data}
\label{incomplete-testing-data}
The third problem is that the current testing data is not comprehensive. In the LJP task, the training data and testing data are assumed to be identically and independently distributed (i.i.d.): They are often sampled from the same distribution (e.g., a court like the European Court of Human Rights or a region like European). However, the i.i.d. assumption can easily be violated in real cases. Recent research~\cite{shen2021outofdistribution,wiles2022a} reports that learning models become vulnerable when exposed to test data with distributional shifts, which indicates that evaluating the out-of-distribution (OOD) generalization ability of models in LJP is of critical significance. The data for testing such an ability is neglected, which misleads the model selection and makes the learned spurious correlations undiscovered and even predictive in the current testing data: spurious correlations in training data can also be established in the testing data due to i.i.d. assumption. 


\subsection{Impact of Unsolved Problems}
\label{influence-sec3}
The above explanation manifests the dynamic that the spurious correlation error \textbf{weakens the generalization capability} of LJP models. Beyond the causal information, the non-causal information and the texts vary by judges and cases. For instance, the text of a legal case is contingent on the judge who is assigned to write the case description. The writing patterns of judges affect the functional relation between $N$ and $T$. Thus, if the LJP model incorrectly learns the spurious correlations between $N$ and $Y$ in the training set, the model can perform poorly in another set when the two sets have different writing patterns as well as different functional relations between $N$ and $Y$. However, due to rule of law, the relation between $C$ and $T$ is stable, if the LJP model correctly understands the reason for a judgment, the model can uniformly perform well in various data sets~\cite{cui2022stable}. 

Learning spurious correlations can also make the LJP model \textbf{less robust}. If the LJP model learns the spurious correlation, varying $N$ can lead to a change in the prediction results. However, in the ground truth, $N$'s variation must not affect $Y$ due to the principle of rule of law. 

% 熟知的解决办法有啥，但是解决不了第二个问题，因为XX。
\subsection{Our Solutions}
\label{learning-sec5}
The first problem is widely noticed by the AI community and tackled through various methods, including data augmentation and weighted approaches. However, the second and third problem is hardly noticed in the LJP task. The second problem can not be solved by adopting the same methods used in the first problem. Specifically, the LJP model considers $N$ as another cause of $Y$ rather than the non-causal information. While parts of $N$ play the same role in both training and testing sets, the cross-validation can fail to exclude the overfitting effects. For instance, the grammar rules play the same role in all case descriptions. Learning models can overfit the relation between the information about grammar rules and the legal judgments for improving prediction accuracy. In most situations (reflected by word frequency), the model makes predictions according to punctuation marks and function words.

Since only the purple causal graph in Figure~\ref{causal-graph} satisfies the rule of law, we focus on increasing its probability to be learned through data and model: two of the most crucial factors that largely affect a deep model. We achieve this goal by excluding the possibility of other potential estimates. Note that due to the precision of our adopted OIE tools (for distinguishing $N$ from $C$), we cannot perfectly implement exclusion in experiments. Instead, we can still approach our goal by reducing the possibility of other potential estimates. Specifically, we focus on preventing models from learning the spurious correlation between $N$ and $Y$. We consider two methods as follows. 

\noindent \textbf{Intervention on Data.} If we assume that the training data only comprise causal information $C$ labeled with $Y$, machine learning methods can only learn the correlation between $C$ and $Y$ (i.e., the causal relationship between $C$ and $Y$). However, the assumption can hardly be satisfied due to two reasons: (1) the causal information $C$ can be described by natural language in infinite ways, which is infeasible for the data collector to sample all of them in the training data; (2) non-causal information $N$ such as grammar and writing style can be inevitably involved into the training data. The former results in knowledge deficiency in the training data while the latter decreases the probability of the target estimate of parameters (occurrence of $R$). Therefore, to offset the decline of $P(R \vert X)$, we propose CIESAM for making attempt to filter the non-causal information.

\noindent \textbf{Intervention on Model.} We can also opt to improve the understanding ability of models, making them able to distinguish and avoid learning spurious correlations. For example, a straightforward linear model can avoid the disturbance of non-causal information if it knows the legal knowledge: It can set the coefficient in front of non-causal variables to zero regardless of their amount in the training data. To this end, we propose CASAM for infusing learning models with causal information and knowledge.

\noindent \textbf{Complete Testing Data by Legal-Specific Attacks.} We complete the testing data by proposing legal-specific attacks to bring distributional shifts into the data. More details are shown in Section~\ref{exp-settings}.

% 机器怎么决策，看gradient，gradient变才变。学会因果了会更稳定，gradient大改变才快。从没有这个词变成这个词有，变动的快不快。
% 判决改一个词变化，x改mask就有一个变动方向，这个变动引起了判决的变动，gradient找到词组。能够变化的点都找出来。
% IG，判断哪些其作用的时候不用一个个做实验。不大就不用mask了
% adversarial是词的也可以是parameter的，adversarial这个点上输入对输出有了一个大的变化。adversarial的方向体现了SCM，gradient体现了AI认为的输入到输出的因果关系。
% 参数有敏感的方向，什么样的embedding会在这个参数上起作用。y=b1x1+b2x2。文档或者case给定，b1才确定，否则其他词会分担走b1的影响力。case给定，讨论在这个case里面的x1，也就是说case1-x1的影响。

% 正文
\section{Methodology}
\label{model}

According to the above analysis, it is necessary to mitigate the spurious correlation error in the LJP model. Otherwise, the LJP model predicts the judgment according to spurious correlations and violates the rules of law. Consequently, the LJP model is not trustworthy even if it has a good prediction performance.

Directly eliminating the spurious correlation error is a challenge. To fully prevent models from learning spurious correlations, there are two straightforward options: 1) directly conditioning on $C$ or 2) removing $N$ to block its effect of misleading the training. However, there lacks a method of filtering out $C$ from the judgment case descriptions. In the case descriptions, causal and non-causal information are entangled to form complete semantic expression. It is hard to clarify and separate the causal information from the non-causal part in a case description. Further, the data imbalance is also hard to be corrected due to the nature of language such as the Zipf's law~\cite{reed2001pareto}. For instance, the methods of reweighting the samples such as propensity-score weighting are the major methods of correcting the data imbalance. However, it is hard to apply the reweighting methods to adjust the data imbalance existing in the fact descriptions. 

In this paper, we propose two methods of lowering the proportion of $N$ in the training data for LJP model and mitigating the spurious correlation error. The first method named causal information enhanced sampling method (CIESAM) is inspired by CATT~\cite{yang2021causal}, whose main idea is to control the training samples (or sampling process) for learning. The second method named causality-aware self-attention mechanism (CASAM) focuses on intervening in the computation process, rendering causal information to get noticed within and throughout the learning model. Both methods are based on the technology of open-information extraction (OIE). We notice that OIE tools are able to capture the minimal context that mostly maintains the content~\cite{stanovsky2018supervised}. It is possible to adopt OIE as a filter to separate the context that mainly includes the causal information of the legal texts from those that mainly include the non-causal information. Further, the open-source coreference method merges the context that possesses the same semantic~\cite{clark2016deep}. 

\begin{figure*}
  \centering
  %\vspace{-1.0cm}
  \includegraphics[width=1.0\linewidth]{picture_new/Legal-Model.pdf}
  \caption{Overview of our framework.}
  \label{framework}
\end{figure*}

To sum up, the overall framework can be divided into two steps. In the first step, we adopt the OIE and open-source coreference methods to refine the dataset and mitigate the data imbalance in legal texts. We first perform open information extraction (OIE) on input legal texts to discard the context that contains a high proportion of non-causal information. Then, we graphically structure the extracted pieces of information shown in Figure~\ref{framework}. In the extracted information (knowledge) graph, the nodes denote the subjects, objects, and predicates while the edges are dependencies. The nodes possessing the same semantic meaning will be merged into one by the open-source coreference model. During the process of constructing graphs, redundant non-causal information is further reduced by merging. Meanwhile, documents are substantially compressed to focus on core information. The above data processing lowers the proportion of $N$ in the legal-case texts, thereby mitigating the spurious correlation between $N$ and $Y$. In the second step, we apply the knowledge to intervene in the learning process in two ways. In the rest of this section, we provide the detail of our methods.


% 这部分自己的贡献是什么？模型方面的贡献是什么？
% 首先在文档级做共指，然后句级别做OIE，得到所有三元组之后，我们将S和O当作节点，将predicate当作边，根据共指关系把句级别分隔开的三元组们连接到共同的节点上，从而构成文档级的图。为了增加构图的准确性，我们还引入了TFIDF的规则，计算phrase之间的相似程度，并将相似的phrase对应的节点融合。
\subsection{Graph Construction by OIE.}
In this section, we detail the process of extracting graph structures from text, which aims to discard and merge redundant non-causal information. First, we apply coreference resolution~\cite{clark2016deep} and open information extraction~\cite{stanovsky2018supervised} tools to identify the corresponding mentions or pronouns of each entity, and then extract relational triplets from sentences. In our constructed graph, we represent subjects and objects as nodes, which are connected by predicates as directed edges. Second, the nodes will be merged to reduce redundant non-causal information if they have similar names or meanings, which is identified by TF-IDF overlap and coreference resolution tools, respectively. Finally, as to the subsequent newly extracted triplets, we also calculate the TF-IDF overlap between the existing triplets and the new one. If the value is higher than our predefined threshold, we rule out the new triplet to reduce information replication. 



% 考虑到前面的理论分析，即模型会吸收所有的correlation来做预测，不同于一般transformer-encoder里面的self-attention结构，where每个词之间都会产生相关性，都有权重，causal-attention-module这里进行了因果干预，打断了无关词对于其他词的影响，打断了N和C之间的关联，使得b不成立了，又因为N的权重被置0，所以模型无法通过调整N的权重来寻找spurious-correlation去minimize-training-error，所以模型更少考虑N的影响。具体实现上，在graph-construction之后，我们将graph转化为邻接矩阵，邻接矩阵反映了context中词与词之间的dependencies，我们直接令。。。
% 由此得到邻接矩阵A。文本被encode之后有QKV，QK用来计算词和词之间的dependency，这里我们用邻接矩阵A遮蔽不相关的关系，于是causal-module的输出表达为。
\subsection{CASAM} % 图画错了，embedding在外面，直接文本箭头embedding，图往下挪，上面标个CASAM。
We introduce our proposed CASAM in this section. CASAM partly inherits the architecture of the transformer~\cite{vaswani2017attention} or Legal-BERT~\cite{chalkidis2020legalbert} encoder which consists of L stacking blocks. Each block comprises a feed-forward network, residual connection, layer normalization, and a causal attention module.  Given a fact description $D$, we obtain its embedding matrix $\mathbf{X} \in \mathbb{R}^{N \times d}$ according to the embedding layer of a transformer encoder, where $N$ and $d$ denote the sequence length and the dimension of hidden layers, respectively. Following the transformer encoder, CASAM maps $\mathbf{X}$ to query, key, and value matrices in each block by $\mathbf{Q} = \mathbf{X} \mathbf{W}_{q}, \mathbf{K} = \mathbf{X} \mathbf{W}_{k}, \mathbf{V} = \mathbf{X} \mathbf{W}_{v},$
where $\mathbf{W}_{q}, \mathbf{W}_{k}, \mathbf{W}_{v} \in \mathbb{R}^{d \times k}$ are model parameters the in $l$-th block, $l$ is omitted in the equation for brevity.

Different from the widely adopted self-attention mechanism which considers all words to correlate with each other, our proposed causal attention module performs causal intervention between each word pair. The former provides abundant correlations represented by unsupervised attention weights for models to explore, neglecting the fact that learning methods will greedily absorb all correlations (including spurious correlations) found in data to minimize their training error, which leads to spurious correlation error. The latter tries to discern the potential causal relationships and block non-causal information to prevent learning spurious correlations. Specifically, our proposed CASAM first derives an adjacency matrix $\mathbf{A}$ according to a certain graph $\mathcal{G}$ constructed by the aforementioned open information extraction (OIE) tool. The entries $\mathbf{A}_{ij}$ tabulate the binary variable identifying whether the combination of $i$-th word and $j$-th word will causally affect the final judgment. Then, based on the original attention weights calculated by $\mathbf{S}=\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d}}$, the new attention weights are derived by,
\begin{equation}
    \mathbf{S}^\prime = \alpha \mathbf{S} + (1-\alpha) \mathbf{S} \odot \mathbf{A},
\end{equation}
where $\odot$ denotes the element-wise multiplication between matrices and $\alpha$ is a hyperparameter ranging from $0$ to $1$, which is adjusted according to the accuracy of an OIE tool: the more accurate the OIE tool, the higher the $\alpha$. The output $\mathbf{Y}$ of each causal attention module is derived by,
% and the final output $\mathbf{Y}^\prime$ of CASAM
\begin{equation}
    \mathbf{Y} = \operatorname{softmax}(\mathbf{S}^\prime) \mathbf{V}.
\end{equation}
% , \mathbf{Y}^\prime = \operatorname{CASAM}(\mathbf{Y})
We input $\mathbf{Y}$, the output of the final causal attention layer considered as the representation of a fact description $D$, into a linear layer followed by a sigmoid function to obtain the final predictions. 

\subsection{CIESAM}
CIESAM incorporates the processed data and the raw data for balancing the spurious correlation mitigation and information loss minimization. To avoid the conflict and inconsistency that occurred in encoding heterogeneous information through Transformer~\cite{shao2020graph}, we perform graph linearization to model the extracted graphs as sequences. Existing methods of converting graphs into sequences can roughly be divided into two categories: training graph-to-sequence models~\cite{wei2021graphtosequence} based on graph transformer~\cite{cai2020graph} or heterogeneous graph transformer~\cite{yao2020heterogeneous}, and graph linearization~\cite{fan2019using,pasunuru2021efficientlya} methods which artificially designing some rules to store graphs in a structured sequence. The latter faithfully express a graph and the former introduce noises in their generated sequences. To avoid introducing new non-causal information which may induce new spurious correlations, we adopt a graph linearization method, which is considered more suitable. Specifically, we first obtain the weights of nodes and edges by counting how many times their corresponding phrases appear in a document. Second, we perform graph traversal in a breadth-first manner according to the weights. Finally, the resulting sequences of graph traversal are adopted as the linearized graphs and encoded as $\mathbf{X}_g$. The final output of CIESAM is derived by,
\begin{equation}
\mathbf{Y}^\prime = \operatorname{LegalBERT}\left(\beta \mathbf{X} + \left(1 - \beta \right)\mathbf{X_g}\right),
\end{equation}
where $\beta$ is the hyperparameter ranging from $0$ to $1$. Its value is positively correlated with the accuracy of an OIE tool. Similar to CASAM, $\mathbf{Y}^\prime$ is input into a linear layer followed by a sigmoid function to predict the final judgment. 

\subsection{Model Selection}
Traditionally, the training data and validation data are i.i.d. and the latter are adopted to monitor the training process for selecting the best-performed version of a learning model. According to our analysis in Section~\ref{incomplete-testing-data}, the selection can be biased as the evaluation of the generalization ability of models is incomplete: lacking the evaluation of OOD performance. To solve the issue, we complete the validation data by our proposed legal-specific attacks to evaluate both the robustness and generalization ability of models. Different from previous methods, we aim to select the most robust and generalizable version of a learning model during the training process. 


\section{Experiments}
\subsection{Datasets}
\noindent \textbf{ECtHR Task A \& B.}  The European Court of Human Rights (ECtHR) dataset~\cite{chalkidis2019neural} is the only publicly available human-annotated LJP dataset in English, consisting of approximately 11,000 cases from the ECtHR database. In each case, allegations are written as fact descriptions, the judgment results --- about which of human rights provisions legislated by European Convention of Human Rights (ECHR) does the current state breach --- are recorded as the label. All cases are chronologically categorized as training set (9k, 2001-2016), development set (1k, 2016-2017), and test set (1k, 2017-2019). Each case can either violate single, multiple, or none of the given legal articles. For each model, the input is fact descriptions of a case, and the output is the judgment, represented by a set of violated articles. In Task A, the violated articles are considered by the court. In Task B, the violated articles are put forward by the applicants.

\noindent \textbf{LEDGAR.} LEDGAR (Labeled EDGAR) \cite{tuggener2020ledgar} is a dataset for contract provision classification. Considering the underlying common legal text classification techniques, we conduct experiments on the dataset not only for a more comprehensive evaluation, but also to test the generalization ability of models. In LEDGAR, the contract provisions are crawled from the U.S. Securities and Exchange Commission (SEC) website and are available from an Electronic Data Gathering, Analysis, and Retrieval (EDGAR) system on the website. Nearly 850k contract provisions from 12.5k categories are included in the originally proposed LEDGAR. Following the legal language understanding benchmark LexGLUE\cite{chalkidis2022lexgluea}, we use 80k contract provisions labeled with 100 most frequent categories from the original dataset. The dataset is chronologically split into a training set (60k, 2016-2017), a development set (10k, 2018), and a test set (10k, 2019).



% 
\subsection{Baselines}

\textbf{TFIDF+SVM} combines the Term Frequency and Inverse Document Frequency technique with a linear Support Vector Machine.
\\
\textbf{BERT}~\cite{devlin2019bert} is a pre-trained transformer model used to predict masked language and the next sentence.
\\
\textbf{RoBERTa}~\cite{liu2019roberta} is also a transformer-based model, it uses dynamic masking and uses larger training corpora in the pre-training stage compared with BERT. 
\\
\textbf{DeBERTa}~\cite{he2021deberta} computes attention using disentangled matrices and it applies an enhanced mask decoder. For the finetuning task, it proposes a new adversarial training technique.
\\
\textbf{Longformer}~\cite{beltagy2020longformer} uses sparse attention mechanism to make the model suitable for long sequence of language.
\\
\textbf{BigBird}~\cite{zaheer2020big} is also a transformer-based language model, it uses local, global, and random attention to get better performance on long sequences of language.
\\
\textbf{CaseLaw-BERT}~\cite{zheng2021when} is a law case oriented BERT model. This model is based on a BERT model and trained with law case data.
\\
\textbf{Legal-BERT}~\cite{chalkidis2020legalbert} model is similar to the CaseLaw-BERT model, they are both trained based on BERT. Legal-BERT is trained with legal corpora, contracts, law cases, and other law-related documents.

The backbone of our proposed model is based on Legal-BERT in this paper, our model can be easily extended to other backbones in future work. 




% \begin{table*}
%   \centering
%     \begin{tabular}{l|cc|cc|cc}
%       \toprule
%        \multirow{2}{*}{\textbf{Method}}  
%         &\multicolumn{2}{c|}{ECtHR(A)} &\multicolumn{2}{c|}{ECtHR(B)}&\multicolumn{2}{c}{LEDGAR} \\
%         & $\mu$-$F_1$  &  $m$-$F_1$   & $\mu$-$F_1$  &  $m$-$F_1$ & $\mu$-$F_1$  &  $m$-$F_1$    \\
%       \hline
%       TFIDF+SVM*         &   64.5    &   51.7  & 74.6  & 65.1    &   87.2    &   82.4    \\
%       \hline
%       BERT*              &   71.2    &   63.6  & 79.7  & 73.4    &   87.6    &   81.8    \\
%       RoBERTa*           &   69.2    &   59.0  & 77.3  & 68.9    &   87.9    &   82.3    \\
%       DeBERTa*           &   70.0    &   60.8  & 78.8  & 70.1    &   88.2    &   83.1    \\
%       \hline
%       Longformer*        &   69.9    &   64.7  & 79.4  & 71.7    &   88.2    &   83.0    \\
%       BigBird*           &   70.0    &   62.9  & 78.8  & 70.9    &   87.8    &   82.6    \\
%       \hline
%       CaseLaw-BERT*      &   69.8    &   62.9  & 78.8  & 70.3    &   88.3    &   83.0    \\
%       Legal-BERT*        &   70.0    &   64.0  & 80.4  & 74.7    &   88.2    &	83.0 	\\
%       \hline
%       % Legal-bert-ours    &   \textbf{72.9}    &   \textbf{63.3}   & \textbf{80.6}  & \textbf{75.2}   &   \textbf{88.2}    &	\textbf{81.9}    \\
%       CIESAM              &   \textbf{73.4}    &   \textbf{67.4}   & \textbf{81.0}  & \textbf{76.7}   &   \textbf{88.7}    &	\textbf{83.6}    \\
%       CASAM              &   \textbf{73.8}    &   \textbf{68.5}   & \textbf{81.4}  & \textbf{76.0}   &   \textbf{88.7}    &	\textbf{83.5}    \\
%       \bottomrule
%     \end{tabular}
%   \caption{Overall experimental results. The signal `*' denotes that the results of the corresponding models are quoted from LexGLUE~\cite{chalkidis2022lexgluea}.}
%     \label{main-results}
% \end{table*}



\subsection{Experimental Settings}
\label{exp-settings}
\noindent \textbf{Implementation Details.} 
Our experiment is based on PyTorch and Hugging Face Transformer~\cite{wolf2020transformersa}. 
At the graph construction stage, co-reference resolution predictor~\cite{clark2016deep} and OIE predictor~\cite{stanovsky2018supervised} are used to extract graph relationships and construct the graph. Later, we use breadth-first search  to get the linearized graph text.
We apply the pre-trained Legal BERT transformer from Hugging face to be our encoder. With the original fact descriptions and the corresponding graph text, we use two Legal BERT encoders to get the embeddings.  The learning rate is $1e-4$ and the optimizer is AdamW. 
Following previous work~\cite{chalkidis2022lexgluea}, we evaluate the performance (e.g., generalization ability) of models by $\mu$-$F_1$ and $m$-$F_1$ scores. 


% 几种attack是什么：虚词，所有词，句首序号，句首序号后的点，标点符号，助动词，冠词，除去of等表示时间地点外的介词
\noindent \textbf{Evaluated Attacks.}
According to the suggestions provided by experts in the legal domain, we consider several types of attacks for thorough robustness evaluation. In each type of the following attacks written in \textbf{bold}, we make a distinct perturbation in the given fact description that will not change the judgment from the perspective of the experts. For those attacks written in \textit{italics}, the perturbation will not change the judgment in most circumstances according to the experts. We provide descriptions of all types of attacks: (1) \textit{functional word attacks}. We adopt the token `[mask]' as a substitute for a functional word; (2) \textit{word-level attacks}, which mask a single word; (3) \textbf{sequence number attacks}, which remove the sequence number in front of the given description; (4) \textbf{dot attacks after sequence number}. We remove the dot after a sequence number; (5) \textbf{punctuation mark attacks}, which mask a punctuation mark; (6) \textbf{auxiliary verb attacks}, which mask an auxiliary verb; (7) \textbf{article attacks}, which mask an article before a noun; (8) \textbf{preposition attacks}. We attack prepositions except the preposition `of' (which may indicate the ownership relationship), the preposition `for' (which may represent whether someone does something on purpose), and those prepositions that locate between numbers.

To evaluate the robustness of models, we adopt \textbf{certified ratio} (\textbf{CR}) to measure the percentage of consistent predictions (unchanged predictions) under a perturbation (wrong predictions are also included) and $1-\text{CR}$ as the \textbf{success rate} (\textbf{SR}) of attack~\cite{gurel2022knowledge}. 


\begin{table}
  \centering
    \begin{tabular}{l|cc|cc|cc}
      \toprule
       \multirow{2}{*}{\textbf{Method}}  
        &\multicolumn{2}{c|}{ECtHR(A)} &\multicolumn{2}{c|}{ECtHR(B)}&\multicolumn{2}{c}{LEDGAR} \\
        & $\mu$-$F_1$  &  $m$-$F_1$   & $\mu$-$F_1$  &  $m$-$F_1$ & $\mu$-$F_1$  &  $m$-$F_1$    \\
      \hline
      TFIDF+SVM*         &   64.5    &   51.7  & 74.6  & 65.1    &   87.2    &   82.4    \\
      \hline
      BERT              &   71.1    &   61.2  & 79.2  & 72.1    &   88.0    &   82.1    \\
      RoBERTa           &   72.0    &   65.6  & 77.6  & 70.9    &   87.6    &   81.3    \\
      DeBERTa           &   71.5    &   66.7  & 80.2  & 73.1    &   88.1    &   82.9    \\
      \hline
      Longformer        &   71.0    &   62.1  & 79.7  & 71.9    &   87.7    &   81.3    \\
      BigBird           &   69.8    &   59.7  & 78.1  & 68.5    &   87.1    &   80.8    \\
      \hline
      CaseLaw-BERT      &   71.6    &   65.5  & 78.6  & 71.9    &   88.0    &   81.8    \\
      Legal-BERT        &   72.3    &   66.0  & 80.6  & 75.2    &   88.2    &	 81.9 	\\
      \hline
      % Legal-bert-ours    &   \textbf{72.9}    &   \textbf{63.3}   & \textbf{80.6}  & \textbf{75.2}   &   \textbf{88.2}    &	\textbf{81.9}    \\
      CIESAM              &   \textbf{73.4}    &   \textbf{67.4}   & \textbf{81.0}  & \textbf{76.7}   &   \textbf{88.7}    &	\textbf{83.6}    \\
      CASAM              &   \textbf{73.8}    &   \textbf{68.5}   & \textbf{81.4}  & \textbf{76.0}   &   \textbf{88.7}    &	\textbf{83.5}    \\
      \bottomrule
    \end{tabular}
  \caption{Overall experimental results. The signal `*' denotes that the results of the corresponding models are quoted from LexGLUE~\cite{chalkidis2022lexgluea}.}
    \label{main-results}
\end{table}

% 这种attribution方法的细节和合理性：一共三类attribution方法，我们选择了替换类，他也很好契合了我们的目标：分析模型得出正确判决最为依据的信息是什么。
\noindent \textbf{Attribution Method.}
Current feature attribution methods can be roughly divided into three categories: gradient-based methods which calculate a score for each input feature by gradients~\cite{springenberg2015striving,li2016visualizinga,simonyan2019deep}, reference-based methods which consider the difference between a predefined ``reference'' and the output of a model as the attribution score~\cite{ribeiro2016why,shrikumar2017learning,sundararajan2017axiomatic}, and erasure-based methods which measure the change of model prediction as the attribution score after removing the target feature~\cite{zeiler2014visualizinga,li2016visualizinga,feng2018pathologies,chen2020generating}. We adopt an erasure-based method~\cite{li2020bertattack} due to its simplicity and faithfulness. Specifically, if a fact description $D=[d_1,\dots,d_{i-1},d_i,d_{i+1},\dots]$ is input into a certain model, and the corresponding output prediction score on the ground truth label $y$ is $o_y(D)$, then the attribution value on $d_i$ is written by,
\begin{equation}
    F_y(d_i) = o_y(D) - o_y(D^\prime),
\end{equation}
where $D^\prime=[d_1,\dots,d_{i-1},[\operatorname{MASK}],d_{i+1},\dots]$.
Erasure-based methods directly satisfy the way of evaluating an AI judger by rule of law: Will the judgment change if the causal elements get erased or changed from the fact descriptions? Will the AI judger consistently stick to rule of law in any circumstances (e.g., changes in irrelevant information)?


\begin{table}
  \centering
  \scalebox{0.6}{
    \begin{tabular}{l|l|cc|cc|cc}
      \toprule
      \multirow{2}{*}{\textbf{Attack}} & \multirow{2}{*}{\textbf{Method}}   
        &\multicolumn{2}{c|}{ECtHR(A)} &\multicolumn{2}{c|}{ECtHR(B)} &\multicolumn{2}{c}{LEDGAR} \\
        & & CR & SR                 & CR & SR                       & CR & SR  \\ \hline
      \multirow{2}{*}{Functional word} %  虚词 & Bigbird            &  &  &  &  &  & \\
      & Bert            & 99.37 & 0.63 & 99.32 & 0.68 & 93.76 & 6.24	\\
      & RoBerta         & 99.29 & 0.71 & 99.06 & 0.94 & 95.81 & 4.19	\\
      % & DeBerta         &  &  &  &  & 96.97 & 3.03 \\
      & Longformer      & 91.46 & 8.54 & 93.63 & 6.37 & 96.48 & 3.52 \\
      & Bigbird         & 96.11 & 3.89 & 95.82 & 4.18 & 96.39 & 3.61 \\
      & CaseLaw-Bert    & 99.59 & 0.41 & 99.57 & 0.43 & 94.33 & 6.67	\\ \hhline{~|-|--|--|--}
      & Legal Bert      & 99.78 & 0.22 & 99.69 & 0.31 & 94.81 & 5.19	\\
      & CIESAM      & 99.69 & 0.31 & 99.75 & 0.25 & \textbf{96.54} & \textbf{3.46}\\
      & CASAM       & \textbf{99.89} & \textbf{0.11} & \textbf{99.88} & \textbf{0.12} & 96.17 & 3.83 \\ \hline
      \multirow{2}{*}{Word-level} % 所有词
      & Bert            & 99.27 & 0.73 & 99.23 & 0.77 & 84.00 & 16.00	\\
      & RoBerta         & 99.22 & 0.78 & 98.96 & 1.04 & 79.10 & 20.90	\\
      % & DeBerta         &  &  &  &  & 75.79 & 24.21 \\
      & Longformer      & 81.89 & 18.11 & 86.07 & 13.93 & 78.91 & 21.09 \\
      & Bigbird         & 83.35 & 16.65 & 85.63 & 14.37 & 81.61 & 18.39 \\
      & CaseLaw-Bert    & 99.45 & 0.55 & 99.42 & 0.58 & 86.06 & 13.94	\\ \hhline{~|-|--|--|--}
      & Legal Bert      & 99.66 & 0.34 & 99.53 & 0.47  & 88.73 & 11.27	\\
      & CIESAM      & 99.54 & 0.46 & 99.64 & 0.36 & \textbf{90.91} & \textbf{9.09}\\
      & CASAM       & \textbf{99.75} & \textbf{0.25}  & \textbf{99.79} & \textbf{0.21}  & 89.65 & 10.35 \\ \hline
      \multirow{2}{*}{Seq. Num.} % 句首序号
      & Bert            & 99.38 & 0.62 & 99.37 & 0.63 & - & -	\\
      & RoBerta         & 99.73 & 0.27 & 99.48 & 0.52 & - & -	\\
      % & DeBerta         &  &  &  &  & - & - \\
      & CaseLaw-Bert    & 99.58 & 0.42 & 99.47 & 0.53 & - & -	\\ \hhline{~|-|--|--|--}
      & Legal Bert      & 99.79 & 0.21  & 99.67 & 0.33 & - & -	\\
      & CIESAM      & 99.74 & 0.26 & 99.70 & 0.30 & - & - \\
      & CASAM       & \textbf{99.79} & \textbf{0.21}  & \textbf{99.87} & \textbf{0.13} & - & - \\ \hline
      \multirow{2}{*}{Dot after Seq. Num.} % 句首序号后的点
      & Bert            & 99.35 & 0.65 & 99.42 & 0.58 & - & -	\\
      & RoBerta         & 99.43 & 0.57 & 99.33 & 0.67 & - & -	\\
      % & DeBerta         &  &  &  &  & - & -\\
      & CaseLaw-Bert    & 99.73 & 0.27 & 99.70 & 0.30 & - & -	\\ \hhline{~|-|--|--|--}
      & Legal Bert      & \textbf{99.83} & \textbf{0.17} & 99.81 & 0.19 & - & -	\\
      & CIESAM      & 99.75 & 0.25 & 99.82 & 0.18 & - & - \\
      & CASAM       & \textbf{99.83} & \textbf{0.17} & \textbf{99.89} & \textbf{0.11} & - & - \\ \hline
      \multirow{2}{*}{Punctuation mark} % 标点符号
      & Bert            & 99.44 & 0.56 & 99.37 & 0.63 & 96.45 & 3.55	\\
      & RoBerta         & 99.30 & 0.70 & 99.09 & 0.91 & 95.97 & 4.03 \\
      % & DeBerta         &  &  &  &  & 97.06 & 2.94 \\
      & Longformer      & 91.59 & 8.41 & 93.58 & 6.42 & 96.79 & 3.21 \\
      & Bigbird         & 96.37 & 3.63 & 96.01 & 3.99 & 96.70 & 3.30 \\
      & CaseLaw-Bert    & 99.68 & 0.32 & 99.67 & 0.33 & 97.47 & 2.53	\\ \hhline{~|-|--|--|--}
      & Legal Bert      & 99.82 & 0.18 & 99.64 & 0.36 & 96.76 & 3.24 \\
      & CIESAM      & 99.72 & 0.28 & 99.80 & 0.2 & 95.68 & 4.32\\
      & CASAM       & \textbf{99.83} & \textbf{0.17}  & \textbf{99.87} & \textbf{0.13} & \textbf{98.08} & \textbf{1.92} \\ \hline 
      \multirow{2}{*}{Auxiliary Verb} % 助动词
      & Bert            & 99.54 & 0.46 & 99.21 & 0.79 & 98.22 & 1.78	\\
      & RoBerta         & 99.02 & 0.98 & 99.02 & 0.98 & 70.00 & 30.00	\\
      % & DeBerta         &  &  &  &  & 70.00 & 30.00 \\
      & Longformer      & 99.10 & 0.90 & 98.20 & 1.80 & 90.00 & 10.00 \\
      & Bigbird         & 99.27 & 0.73 & 99.27 & 0.73 & 90.00 & 10.00 \\ 
      & CaseLaw-Bert    & 99.63 & 0.37 & 99.67 & 0.37 & \textbf{99.05} & \textbf{0.95} \\ \hhline{~|-|--|--|--}
      & Legal Bert      & 99.74 & 0.26 & 99.65 & 0.35 & 98.48 & 1.52	\\
      & CIESAM      & 99.70 & 0.30 & 99.71 & 0.29 & 92.64 & 7.36\\
      & CASAM       & \textbf{99.88} & \textbf{0.12}  & \textbf{99.89} & \textbf{0.11} & 98.89 & 1.11 \\ \hline
      \multirow{2}{*}{Article} % 冠词
      & Bert            & 99.35 & 0.65 & 99.32 & 0.68 & 98.45 & 1.55	\\
      & RoBerta         & 99.00 & 1.00 & 98.9 & 1.01 & 98.44 & 1.36	\\
      % & DeBerta         &  &  &  &  & 99.61 & 0.39 \\
      & Longformer      & 96.51 & 3.49 & 97.50 & 2.50 & 98.05 & 1.95 \\
      & Bigbird         & 98.96 & 1.04 & 99.16 & 0.84 & 97.37 & 2.63 \\
      & CaseLaw-Bert    & 99.64 & 0.36 & 99.65 & 0.35 & 98.54 & 1.46	\\ \hhline{~|-|--|--|--}
      & Legal Bert      & 99.79 & 0.21  & 99.77 & 0.23 & 98.44 & 1.56	\\
      & CIESAM      & 99.71 & 0.29 & 99.75 & 0.25 & 95.92 & 4.08 \\
      & CASAM       & \textbf{99.87} & \textbf{0.13}  & \textbf{99.91} & \textbf{0.09} & \textbf{99.17} & \textbf{0.83} \\ \hline
      \multirow{2}{*}{Preposition} % 攻击除去of等表示时间地点外的介词
      & Bert            & 99.38 & 0.62 & 99.33 & 0.67 & 93.84 & 6.16	\\
      & RoBerta         & 99.29 & 0.71 & 99.07 & 0.93 & 95.78 & 4.22	\\
      % & DeBerta         &  &  &  &  & 96.97 & 3.03 \\
      & Longformer      & 91.49 & 8.51 & 93.62 & 6.38 & 96.44 & 3.56 \\
      & Bigbird         & 96.17 & 3.83 & 95.83 & 4.17 & 96.36 & 3.64 \\
      & CaseLaw-Bert    & 99.59 & 0.41 & 99.55 & 0.45 & 94.39 & 5.61	\\ \hhline{~|-|--|--|--}
      & Legal Bert      & 99.78 & 0.22  & 99.68 & 0.32 & 94.88  & 5.12 \\
      & CIESAM      & 99.70 & 0.30 & 99.71  & 0.29 & \textbf{96.47} & \textbf{3.53}\\
      & CASAM       & \textbf{99.85} & \textbf{0.15}  & \textbf{99.88} & \textbf{0.12} & 96.26  & 3.74 \\
      \bottomrule
    \end{tabular}
    }
  \caption{Results of robustness evaluation on the test sets of three benchmark datasets. Seq. Num. denotes sequence number. }
    \label{robustness-eval}
\end{table}


% \begin{table*}
%   \centering
%   \scalebox{0.85}{
%     \begin{tabular}{l|l|cc|cc|cc}
%       \toprule
%       \multirow{2}{*}{\textbf{Attack}} & \multirow{2}{*}{\textbf{Method}}   
%         &\multicolumn{2}{c|}{ECtHR(A)} &\multicolumn{2}{c|}{ECtHR(B)} &\multicolumn{2}{c}{LEDGAR} \\
%         & & CR & SR                 & CR & SR                       & CR & SR  \\ \hline
%       \multirow{2}{*}{Functional word} %  虚词
%       & Legal Bert      & 85.43 & 14.57 & 99.69 & 0.31 & 94.81 & 5.19	\\
%       & CIESAM      & 99.69 & 0.31 & 99.75 & 0.25 & \textbf{96.54} & \textbf{3.46}\\
%       & CASAM       & \textbf{99.89} & \textbf{0.11} & \textbf{99.88} & \textbf{0.12} & 96.17 & 3.83 \\ \hline
%       \multirow{2}{*}{Word-level} % 所有词
%       & Legal Bert      & 85.43 & 14.57 & 99.53 & 0.47  & 88.73 & 11.27	\\
%       & CIESAM      & 99.54 & 0.46 & 99.64 & 0.36 & \textbf{90.91} & \textbf{9.09}\\
%       & CASAM       & \textbf{99.75} & \textbf{0.25}  & \textbf{99.79} & \textbf{0.21}  & 89.65 & 10.35 \\ \hline
%       \multirow{2}{*}{Sequence number} % 句首序号
%       & Legal Bert      & 85.35 & 14.65  & 99.67 & 0.33 & - & -	\\
%       & CIESAM      & 99.74 & 0.26 & 99.70 & 0.30 & - & - \\
%       & CASAM       & \textbf{99.79} & \textbf{0.21}  & \textbf{99.87} & \textbf{0.13} & - & - \\ \hline
%       \multirow{2}{*}{Dot} % 句首序号后的点
%       & Legal Bert      & 85.36 & 14.64 & 99.81 & 0.19 & - & -	\\
%       & CIESAM      & 99.75 & 0.25 & 99.82 & 0.18 & - & - \\
%       & CASAM       & \textbf{99.83} & \textbf{0.17} & \textbf{99.89} & \textbf{0.11} & - & - \\ \hline
%       \multirow{2}{*}{Punctuation mark} % 标点符号
%       & Legal Bert      & 85.50 & 14.50 & 99.64 & 0.36 & 96.76 & 3.24 \\
%       & CIESAM      & 99.72 & 0.28 & 99.80 & 0.2 & 95.68 & 4.32\\
%       & CASAM       & \textbf{99.83} & \textbf{0.17}  & \textbf{99.87} & \textbf{0.13} & \textbf{98.08} & \textbf{1.92} \\ \hline 
%       \multirow{2}{*}{Auxiliary Verb} % 助动词
%       & Legal Bert      & 85.15 & 14.85 & 99.65 & 0.35 & 98.48 & 1.52	\\
%       & CIESAM      & 99.70 & 0.30 & 99.71 & 0.29 & 92.64 & 7.36\\
%       & CASAM       & \textbf{99.88} & \textbf{0.12}  & \textbf{99.89} & \textbf{0.11} & \textbf{98.89} & \textbf{1.11} \\ \hline
%       \multirow{2}{*}{Article} % 冠词
%       & Legal Bert      & 85.60 & 14.40  & 99.77 & 0.23 & 98.44 & 1.56	\\
%       & CIESAM      & 99.71 & 0.29 & 99.75 & 0.25 & 95.92 & 4.08 \\
%       & CASAM       & \textbf{99.87} & \textbf{0.13}  & \textbf{99.91} & \textbf{0.09} & \textbf{99.17} & \textbf{0.83} \\ \hline
%       \multirow{2}{*}{Preposition} % 攻击除去of等表示时间地点外的介词
%       & Legal Bert      & 85.50 & 14.50  & 99.68 & 0.32 & 94.88  & 5.12 \\
%       & CIESAM      & 99.70 & 0.30 & 99.71  & 0.29 & \textbf{96.47} & \textbf{3.53}\\
%       & CASAM       & \textbf{99.85} & \textbf{0.15}  & \textbf{99.88} & \textbf{0.12} & 96.26  & 3.74 \\
%       \bottomrule
%     \end{tabular}
%     }
%   \caption{Results of robustness evaluation on the test sets of three benchmark datasets.}
%     \label{robustness-eval}
% \end{table*}


\subsection{Main Results} 

The generalization ability (performance) evaluation results of baselines and our model are shown in Table~\ref{main-results}. We can observe that the performance of our framework significantly outperforms the SOTA baseline methods, achieving a new SOTA performance on all three benchmark datasets. Note that our framework is based on the Legal-BERT backbone. Compared with Legal-BERT, CIESAM yields performance gains of $3.4\%$/$3.4\%$ of $\mu$/$m$-F1 scores in ECtHR Task A, $0.6\%$/$2.0\%$ of $\mu$/$m$-F1 scores in ECtHR Task B, and $0.5\%$/$0.6\%$ of $\mu$/$m$-F1 scores in LEDGAR, while CASAM yields gains of $3.8\%$/$4.5\%$ of $\mu$/$m$-F1 scores in ECtHR Task A, $1.0\%$/$1.3\%$ of $\mu$/$m$-F1 scores in ECtHR Task B, and $0.5\%$/$0.5\%$ of $\mu$/$m$-F1 scores in LEDGAR. The experimental results in Table~\ref{main-results} indicate that, with the guidance of our theoretical analysis, both of our methods effectively improve the performance of Legal-BERT: They block $N$ to reduce the spurious correlation error, which leads the model to learn the underlying ground-truth knowledge and thereby enhancing the generalization ability of the model. 

% 中文大意，看表说话：不是三个数据集上都差，B作何解释，LEDGAR作何解释
% 为什么B上原模型结果好：
% LEDGAR上的结果分析：相对于判决来说，法律文件分类虽然有相同的技术路径，但是这个任务上的决策依据可能更加简单直接，依赖的词更加少。例如，如果看见一篇法律文件总出现水果蔬菜甚至直接多次出现农业，那它从概率角度很大概率是属于农业法律文件类别，而判决则需要考虑整体情节，更多的上下文和因果关系。这解释了为什么单个词的攻击结果虽然有提升，但是比起其他结果还是显著低。因为盖住这个词，人的判断也显著变难了。
\subsection{Results of Robustness Evaluation} % robustness against diverse attacks (performance stability of models)
\label{exp-robustness}
We evaluate the robustness of models against diverse attacks. As shown in Table~\ref{robustness-eval}, the robustness of our proposed CASAM is significantly stronger than its backbone on the three datasets under all kinds of attacks.
Without any modification, the original Legal-BERT exhibits poor robustness, especially on ECtHR Task A, which is labeled with real-world judgments from the court. Changes in the irrelevant information in fact descriptions will eventually render the Legal-BERT judger altering at least $14.40\%$ of its judgments, which terribly hurts its robustness and the trust in it. Such kinds of mistakes caused by the spurious correlation error impede the deployment of AI judgers in real-world applications. Our proposed framework significantly mitigates the underlying error and thus enhances the robustness of models. Especially, both of our methods surpass their Legal-BERT backbone by at least $14\%$ of both the certified ratio and success rate on ECtHR Task A. In the two legal judgment prediction tasks, both of our proposed CIESAM and CASAM achieve the certified ratio over $99\%$, which indicates that they get extremely close to the standard of being trustworthy under diverse attacks proposed by experts in the legal domain. 
% spurious correlation error

% Models learn the correlation relationships among variables, which can be generated in either of the three ways: causality, confounding, and data selection bias~\cite{cui2022stable}. Only the correlations generated by causality are what we expect the models to learn from.
% Our theoretical analysis figures out the fact that self-training and selection bias lead to the spurious correlation between non-causal information and the final predictions. CASAM and CIESAM focus on blocking $N$ to directly mitigate such spurious correlation error. 
We can observe that CASAM and CIESAM achieve close performance on judgment prediction tasks. We posit the underlying reason: despite their different implementations, they satisfy the common theoretical background. CASAM intervenes in the architecture of the model, breaking the correlation between $N$ and $C$ in the training procedure, thereby preventing $N$ from correlating with $Y$, while CIESAM directly controls the input data and focuses on discarding $N$, thus preventing it from correlating with any other variables. As we mentioned in Section~\ref{how-to-learn-causality} that only the correlations generated by causality are what we expect the models to learn from, both methods focus on removing other kinds of correlations and only reserving those generated by causality (learning $P(Y \mid C)$). 

Despite the significant robustness improvement under all kinds of attacks, we explain the reason why the evaluation results (the CR and SR are $91.42\%$ and $8.58\%$, respectively) of our proposed methods under word-level attacks are largely different from other attacks on LEDGAR. Although legal judgment prediction and legal text classification often share common techniques, the underlying decision rules of the two task is different. Different from LJP where a judger is required to both perform legal reasoning and consider all of the circumstances in a case for a just judgment, we rely on fewer words in legal text classification. For example, if we notice the word `vegetables', `fruits', or `agriculture' in a legal file, we know it probably belongs to the `agriculture' category. If we mask these words, it will even be difficult for humans to classify the file. Under word-level attacks, these words will inevitably be masked, leading to distinct evaluation results. 


% 2. 模型的selection-bias经过self-training阶段之后在finetuning阶段之前就已经存在，LegalBERT基于BERT的基础上在legal数据集上的self-training本身使得C和N之间的correlation增强（训练目标是根据周围词预测mask位置的词），从而导致了模型都在根据N做判决（图中的红色柱子），就是因果图c所画的那样，这是一个selection-bias问题。而在ECtHR上的finetuning并没有能很好地打断C和N之间的correlation，体现在图上就是模型关注的词并没有发生太多变化，趋势上一致，甚至更加关注

% 解释了前面为什么模型效果好，段落大意起个头：我们前面证明了我们提出的方法在泛化和鲁棒性上都实现了很好的提升，我们在这个section将分析和讨论模型发生了什么变化从而导致了效果提升，前面的理论分析对应的实际现象是什么。我们的分析结论有几个：
% 1. 现象：finetune目标数据集上的词频和在其上finetune的模型关注词的词频趋势几乎一致。后果：解释了因果图c所描述的spurious-correlation-error的来源之一，由selection-bias造成。原理是在context或者训练集中，一些词频繁被选中在其中，由此在数据集中就存在着显著的bias。如果不进行debias操作，那么模型学出来的也是bias的结果，这是对数据规律的一种faithful的体现
% 2. 现象：经过我们的方法改进过后的模型关注的词发生了显著变化，N被更少关注了。说明什么：首先这个现象会使得spurious联结大大减少了，它会使得模型脆弱的点（被成功攻击的点）变少，这解释了为什么鲁棒性章节的实验中模型效果显著提升。然后，要注意到我们的两种方法都可以起到debias的效果，使得模型不再明显倾向于高频的词，这说明无论从data层面入手或者从模型层面入手，都可以起到给模型纠偏的效果，这给后续的模型性别种族debias的方法带来了很好的启示。
% 3. 现象：---。说明：从数据入手的话需要注意一点，即使数据集可以做到没有bias，但用一个已经偏了的模型去学的话，依然会产生bias。正常的legalBERT去finetune完是模型A，如果更改数据，粗暴去除里面所有的虚词或者直接盖住所有虚词，finetune完是模型B，B相比于A不仅表现下降，还使得。。。

\subsection{Analysis and Discussion}
In this section, we take a step further toward characterizing the spurious correlation error in the context of the LJP task. We also shed some light on the underlying reasons why our proposed methods achieve stronger generalization ability and robustness.

\begin{figure}
  \centering
  %\vspace{-1.0cm}
  \includegraphics[width=0.5\linewidth]{picture_new/word_frequency.png}
  \caption{Visualization of selection bias.}
  \label{visual-selection-bias}
\end{figure}

% 中文大意，看图说话：
\noindent \textbf{Visualization of Selection Bias.} % 注意的词改变了，前后统计图。
To characterize the selection bias, we investigate the ECtHR Task A dataset as an example and analysis to what extent the Legal-BERT is affected by the bias. First, we use a feature attribution method to obtain the top $5\%$ words that are considered most crucial by Legal-BERT when making a judgment prediction in the test set. Second, we count the frequency of each word in the top $5\%$ words and in the training set of ECtHR Task A, respectively. As shown in Figure~\ref{visual-selection-bias}, we can observe three phenomena: (1) there is an obvious word frequency bias in the training set of ECtHR Task A; (2) the same kind of bias occurs in the top $5\%$ crucial words considered by Legal-BERT; (3) the two kinds of frequency exhibit a common distribution. The first phenomenon, exhibiting a severe bias in the training set, can lead learning models to suffer from selection bias, which is demonstrated by the causal structural model in Figure~\ref{causal-graph} and instantiated by the second phenomenon. The third phenomenon indicates the fact that, without any intervention, learning models will faithfully learn the bias distribution in the training data, which is undesirable for all heuristic learning methods. If the bias brought by a training set is correlated with gender, race, or geography, learning models will even trigger severe social problems.  % 为什么两个分布大致一样了，理论这里怎么解释？

\begin{figure}
  \centering
  %\vspace{-1.0cm}
  \includegraphics[width=0.5\linewidth]{picture_new/attention_a.png}
  \caption{Results on ECtHR Task A.}
  \label{a-chart-ecthr}
\end{figure}

% Spurious Correlations Learned by Legal-BERT, and the effect of debiasing
% 中文大意，看表说话：
\noindent \textbf{Effect of Debiasing.} % 几个阶段的训练产生的spurious-correlation是有规律的，我们的模型改变了这个规律
To investigate the reason why our proposed methods possess better generalization ability and robustness, we visualize their decision rules of predicting judgment in the test set of ECtHR A and B. We count the frequency of each word occurring in the top $5\%$ words, which are considered most crucial by Legal-BERT and our proposed CASAM, respectively. The results are shown in Figure~\ref{a-chart-ecthr} and Figure~\ref{b-chart-ecthr}. Our observations are summarized as follows.
\begin{figure}
  \centering
  %\vspace{-1.0cm}
  \includegraphics[width=0.5\linewidth]{picture_new/attention_b.png}
  \caption{Results on ECtHR Task B.}
  \label{b-chart-ecthr}
\end{figure}
(1) Without any adjustments in training data or the architecture of the model, Legal-BERT significantly correlates non-causal information with the judgments. It predicts judgments through those words that hardly possess any semantic meanings. The spurious correlations render Legal-BERT vulnerable to attacks and impede its deployment in real-world legal scenarios: The changes in non-causal information like writing style (frequently or rarely use these function words) can even affect the predictions of Legal-BERT. (2) After our intervention in the architecture of Legal-BERT, it significantly decouples the non-causal information (e.g., the punctuation marks and function words) and final predictions, which presents the effectiveness of reducing the possibility of potential estimates shown in Figure~\ref{causal-graph}. (3) Our intervention makes Legal-BERT learn new causal information (e.g., content words that indeed affect the predictions), especially in Figure~\ref{b-chart-ecthr}, which indicates that our proposed methods succeed in learning causal information (the ground-truth estimate) for predicting by reducing the possibility of other potential estimates. This explains why our proposed methods achieve both SOTA generalization ability and robustness. 

Note that CASAM can still be aware of non-causal information in some situations shown in Figure~\ref{b-chart-ecthr} due to the precision of OIE tools, resulting in the fact that $N$ still cannot be precisely distinguished from $C$. It hampers more performance gains of our proposed methods. We leave the improvement of OIE tools for future work. 




% \subsection{Results of Spurious Correlation Effect}
% \label{spur corr}
% %如tab2所示。在LEDGAR数据中，我们在验证集中，将部分“虚词”使用“【mask】”遮住后会使得模型预测的结果改变.
% %在legal bert模型中，遮挡前后大约有41.9%的预测结果不发生改变。在我们的模型中，大约有82.56%的预测结果不会发生改变
% We counted the top-K most important words that the Legal BERT model pay attention to in LEDGAR dataset, shown in \ref{level}. The top words are all non-causal words. We also kept the top $X$ percent of the most important words to test the performance of Legal BERT model, the results are shown in \ref{fig:3}, it shows that when top $20\%$ important words remain, the f1 scores reach $80\%$, so the model puts huge importance on the non-causal words in this dataset. These words are not relevant with the prediction but they play am important role in the prediction. 


% \begin{figure}
%   \centering
  
%   %\vspace{-2.0cm}
%   \includegraphics[width=1.0\linewidth]{LaTeX/pictures/attention.png}
%   \caption{Attention Word Ranking}
%   \label{fig:2}
% \end{figure}



% \begin{figure}
%   \centering
  
%   \includegraphics[width=1.2\linewidth]{LaTeX/pictures/performance_new.png}
%   \caption{LEGDAR Dataset Model Performance}
%   \label{fig:3}
% \end{figure}



% 高频词实验
% \subsection{Analysis and Discussion}
%LEDGAR数据中，我们根据token在句中的重要程度，提取出每句中前x%重要的词，x的范围从0-100。

%在这基础上，我们测试了在保留不同比例的重要的词的情况下，模型预测的效果，如图所示。 图中可知，当拥有大约前20%的重要的词的时候，模型的f1 score已经接近80，我们统计了前20%重要的token对应的词的词频，如fig所示。可见前10个词的都是“虚词”。


%改变一个虚词后prediction就直接改变了，这样的例子有XX个，我经过控制后，这样的例子减少了XX个。如果数字不好，就挑一个例子说明情况。
\subsection{Case Study}

% A concrete example of such prediction can be illustrated in \ref{fig:4}. This case do not violate any article but the baseline model predicts that it violates articles 3,7 and 9. After changing the comma to [MASK], the baseline model predicts that it violates articles 3,6,7,8,9 and 10. Our model can successfully predict that the case do not violate any articles even if the comma is changed to [MASK].
Figure~\ref{fig:5} exhibits the case study of our proposed model compared with Legal-BERT. After merging and discarding the redundant non-causal information, we retain the causal information to aid the prediction. Specifically, more than learning the spurious correlation between the token `[' and articles 5, 9, 10, 11, and 14 as shown in Figure~\ref{fig:0}, Legal-BERT learns the spurious correlation between `the' and article 5 in this case, which results in predicting judgment according to non-causal information. Perturbations like missing the token `[' or `the' in fact descriptions can frequently happen in real-world applications due to the writing habits of a legal assistant. They surprisingly confuse Legal-BERT to change a prediction from ``no crime'' and ``Violated article 3'' to ``violating articles 5, 9, 10, 11, and 14'' and ``violated articles 3 and 5'', respectively. The severe spurious correlation error impedes the real-world application of legal AI. Under the guidance of our proposed causal model, we merge and discard non-causal information in our proposed method based on Legal-BERT, which largely mitigates the spurious correlation and learns the correlations that represent causal relations. Our proposed method is able to make predictions according to the relevant causal information ``detention'', thereby leading to a right prediction (enhancing generalization ability) and avoiding focusing on the non-causal information such as ``the'' (improving robustness).

\begin{figure*}
  \centering
  \includegraphics[width=1.0\linewidth]{pictures/case_study.png}
  \caption{Case study}
  \label{fig:5}
\end{figure*}


\section{Conclusion}
In this paper, we investigate the decision rule of the legal-specific PLM in legal AI. We exhibit the potential problems of the decision rules caused by spurious correlation error, and propose a structural causal model to theoretically analyze the underlying mechanism. Under the guidance of our analysis, we propose a method to simultaneously reduce non-causal information and retain causal information in the given fact descriptions. The experimental results indicate that spurious correlations between non-causal information and predictions largely damage the generalization ability and robustness of legal AI. We appeal to future work to take the spurious correlation error into consideration for improving the overall performance of legal AI.


\bibliography{custom}% common bib file
\bibliographystyle{sn-mathphys}
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl

%% Default %%
%%\input sn-sample-bib.tex%

\end{document}
