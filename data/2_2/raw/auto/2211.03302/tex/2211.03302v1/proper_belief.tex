\section{Properness for Belief Elicitation}
\label{apx:proper belief}
The main idea of converting any scoring rule that is potentially not proper for some beliefs to a scoring rule that is proper for all beliefs 
is to apply the taxation principle and let the agent chooses his best option given the original scoring rule. 
\begin{definition}\label{def:proper belief}
A scoring rule
$\score: \Delta(\outcomes)\times\outcomes\to [0,1]$ is \emph{proper for belief elicitation} if 
for any $\mu, \mu'\in \Delta(\outcomes)$, 
\begin{align*}
    \expect[\omega\sim\mu]{\score(\mu,\outcome)} \geq \expect[\omega\sim\mu]{\score(\mu',\outcome)}.
\end{align*}
\end{definition}
\begin{claim}\label{claim:proper belief}
For any proper scoring rule $\score$, there exists another scoring rule $\hat{\score}$ that is proper for belief elicitation such that 
\begin{align*}
\score(\signal,\outcome) = \hat{\score}(\mu(\signal),\outcome)
\end{align*}
for any $\signal\in\signals$ and $\outcome\in\outcomes$
where $\mu(\signal)$ is the posterior belief of the agent when receiving signal $\signal$.
\end{claim}
\begin{proof}
Consider the following scoring rule for belief elicitation:
\begin{align}\label{eq:best response}
    \hat{\score}(\mu, \outcome)=\score(\signal^*, \outcome), \text{ where }\signal^*\in\argmax_{\signal}\expect[\outcome\sim\mu]{\score(\sigma, \outcome)}.
\end{align}
Next, we will show that
% 1) $\hat{\score}$ is proper for belief elicitation; 2) $\hat{\score}$ is an extension of $\score$, i.e.\ $\score(\signal,\outcome) = \hat{\score}(\mu(\signal),\outcome)$. 
\begin{enumerate}
\item $\hat{\score}$ is proper for belief elicitation. Let $\signal^*(\mu)=\argmax_{\signal}\expect[\outcome\sim\mu]{\score(\sigma, \outcome)}$ be the best responding signal when the agent has to choose a signal to report. 
For any belief $\mu$ and $\mu'$, we have
\begin{align*}
    \expect[\outcome\sim\mu]{\score(\mu', \outcome)}
    =\expect[\outcome\sim \mu]{\score(\signal^*(\mu'), \outcome)}
    \leq \expect[\outcome\sim\mu]{\score(\signal^*(\mu), \outcome)}
    =\expect[\outcome\sim\mu]{\score(\mu, \outcome)}
\end{align*} 
which implies that $\hat{\score}$ is proper for belief elicitation. 

\item $\hat{\score}$ is an extension of $\score$, i.e.\ $\score(\signal,\outcome) = \hat{\score}(\mu(\signal),\outcome)$. 
This follows directly from the properness of the original scoring rule $\score$. \qedhere
\end{enumerate}
\end{proof}

Note that given an arbitrary scoring rule $\score$, 
computing the best response strategy $\signal^*$ given his belief $\mu$ as in Equation \eqref{eq:best response} may be NP-hard. 
Therefore, even though such proper scoring rule exists, 
it might be challenging to provide its exact form in polynomial time given our designed scoring rules. 
Fortunately, for our purpose of incentivizing effort, 
we can adopt a similar solution concept in our sequential effort model (c.f., \cref{def:obvious dominated} and \cref{sec:search}) by allowing the agent to approximately best response to the scoring rule. 
More specifically, given any scoring rule $\score$ for eliciting the signals, 
the principal can offer this original scoring rule $\score$ to the agent, 
ask the agent to report his belief, and let the agent choose the best possible signal he can find in polynomial time as input to the scoring rule $\score$ for computing his score based on his belief.
This protocol disentangles the incentives between reporting beliefs and maximizing the expected score, 
and hence the agent has no incentive to misreport his true belief. 
Moreover, since the scoring rule is proper for all signals in the support, 
for any belief induced by those signals, the agent's best response is to simply report those signals truthfully. 
For any belief that cannot be induced by those signals, 
the agent can adopt any polynomial time algorithm for finding an approximately optimal solution. 
However, as those events happen with probability measure 0, 
it would not affect the agent's incentives for exerting effort in our model, 
and all of our results extend naturally. 




