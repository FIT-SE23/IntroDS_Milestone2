\section{Introduction}
\label{s:intro}


%\newcommand{\topic}[1]{\paragraph{[#1]}}
\reversemarginpar
\newcommand{\topic}[1]{\marginpar{\tiny #1}}
\renewcommand{\topic}[1]{{}}
% 

\topic{Mechanism design for the classroom} This paper considers
mechanism design for the classroom.  An instructor aims to design a
grading mechanism that incentivizes learning, learning comes
from costly effort on the part of a student, and the student aims to
optimize their grade less the costs of effort.  Two key aspects of
this model for mechanism design are that effort is multi-dimensional
over a set of assigned tasks and that effort may lead to only partial
understanding of each task, i.e., effort does not generally guarantee
the student gets an answer correct.  The paper formulates this
problem as a multi-dimensional strategic version of the knapsack
problem and solves it by giving a simple and computationally efficient
scoring rule that incentivizes effort on an approximately optimal set
of tasks.

\topic{connections to agt} Strategic versions of the knapsack problem
and multi-dimensional mechanism design are of central interest in
algorithmic mechanism design.  For example, classic models describe
knapsack mechanisms for allocation \citep*[e.g.,][]{BKV-05} and for
procurement \citep*[e.g.,][]{sin-10}.  An important new frontier for
algorithmic mechanism design is in incentivizing private effort, e.g.,
to impact states as in contract theory
\citep*{dutting2022combinatorial}, or to collect information as in scoring
rules (this paper).  Optimization of scoring rules for
single-dimensional effort was considered by \citep*{HLSW-20}.  This
paper considers multi-dimensional effort where key steps in the
analysis resemble those of the well studied
bundling-or-selling-separately result of the multi-dimensional
mechanism design literature \citep*{BILW-14,BILW-20}.

\topic{Dialog between theory and practice in the classroom} Mechanism
design for the classroom has the potential to address a key challenge
for the two decade old field of algorithmic mechanism design.  To test
the theories of mechanism design in practice, the mechanisms must be
run in practice.  Unlike in classical algorithm design, where new
algorithms can be empirically evaluated on canonical data sets;
empirical validation of mechanisms fundamentally requires that their
inputs be from agents that are strategically responding to (other
agents and) the new mechanism.  Researchers of algorithmic mechanism
design do not generally have opportunities to test the classical
models of allocation or procurement.  Due to this challenge most
mechanisms of the algorithmic mechanism design literature have never
been empirically tested.  The classroom applications of mechanism
design, as proposed by this paper, provide immediate opportunities for
a dialogue between theory and practice; and their advances can lead to
better learning outcomes for students.  For example, \citet*{HLSW-20}
motivate their work on optimizing scoring rules for single-dimensional
effort by an empirical failure of the classical quadratic scoring rule
to provide sufficient incentives of effort for peer grading.


\topic{Knapsack Scoring} The {\em knapsack scoring problem} formulated
and solved in this paper is as follows.  There is a universe of tasks
that an instructor could assign to a student.  Effort of the student
on each task is binary.  Each task has a fixed learning value and a
fixed cost of effort.  The instructor aims to maximize the sum of
values of the tasks that the student puts effort on.  If effort were
directly observable, then this problem would be identical to the
knapsack problem: the optimal set of tasks to assign is the solution
to the knapsack problem with knapsack capacity equal to the maximum
grade and the student receives this maximum grade if effort is exerted
on all of the assigned tasks (zero otherwise).  Our instructor cannot
directly observe effort, but can instead administer a binary test for
each task where the student's belief about the answer to the test
improves with effort.  The instructor aims to select the set of tasks
that the student should perform and design a scoring rule with bounded
total score that incentivizes the student to perform these tasks.

\topic{Intuition from results} How does the instructor select the
tasks?  And how should the instructor score the student in aggregate?
The paper shows that there are two main cases that must be
considered.  Consider the case that scores from individual scoring
rules for the optimal set of tasks concentrate, e.g., because the
student is successful at many of them.  In this case then a good set
of tasks to incentivize can be found by greedily selecting tasks by
the ratio of value to cost and a {\em truncated separate scoring rule} can
incentivize effort on these tasks.  If the scores do not concentrate
then approximately optimal effort can be incentivized by the {\em threshold
scoring rule} and the tasks for this scoring rule can be identified by
greedily selecting tasks by the ratio of value to probability that the
student's effort is informative.
This observation is robust whether the agent exerts effort simultaneously or sequentially.










%% A central concern for the theory of computation is in quantifying the
%% amount of work it takes to solve problems.  Work may eventually lead
%% to a solution to the problem or it may not.  Work may be valuable even
%% if it does not lead to a solution.  Work is often not verifiable.
%% This paper aims to develop an algorithmic theory of work that is
%% intrinsically valuable but not verifiable.  






