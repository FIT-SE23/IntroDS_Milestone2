\section{Dynamic Effort}
\label{sec:dynamic}

\subsection{Dynamic Effort Model}
In the Dynamic Effort model, the agent makes the effort choice on tasks sequentially. 
In this paper, we focus on the setting where the order on the sequence of the tasks is fixed as exogenous, 
and the outcome of each task is publicly observed immediately 
after the agent reports the received signal to the principal. 
On each day $i$, let $\history_i$ be the sequence of reported signals and observed outcomes from day $1$ to day $i$, 
and $\privatehistory_i$ be the sequence of private signals the agent received from day $1$ to day~$i$. 
Since the private history is payoff irrelevant for the agent's expected future utility, 
it is without loss to focus on the strategies of the agent that only depend on the public history. 
By slightly overloading the notation, 
for any $i\in[n]$,
let $\strategy(\history_{i-1})\in\{0,1\}$ be the agent's effort choice at day $i$ given history $\history_{i-1}$
and $\strategy(\history_{i-1},\signal_i)\in\signals$ be the agent's reported signal at day $i$ given history $\history_{i-1}$.
We will focus on mechanisms that are incentive compatible on equilibrium path (\cref{def:dynamic IC}).

The timeline of our model is shown as follows.
\begin{enumerate}
\item The principal commits to an on-path incentive compatible mechanism with scoring rule
$\score(\history_n)\in [0,1]$
and a recommended strategy $\strategy$.
\item On each day $i\leq n$, the agent chooses effort $\effort_i=\strategy(\history_{i-1})$ 
and pays cost $\cost_i$.
Then outcome $\outcome_i$ is realized, 
and the agent receives the signals $\signal\in\signals$.
The agent reports $\strategy(\history_{i-1},\signal_i)$.
\item The agent receives reward $\score(\history_n)$.
\end{enumerate}

Let $\expecto[\strategy]{\cdot}$ be the expectation when the agent follows strategy $\strategy$ for all future tasks. 
\begin{definition}\label{def:dynamic IC}
A mechanism with scoring rule $\score$
and recommended strategy $\strategy$
is \emph{on-path incentive compatible}
if for any day $i$ such that the agent has followed strategy $\tau$ for all past days, 
\begin{align*}
\expecto[\strategy]{\score(\history_n) - \sum_{i\leq i' \leq n} \cost_{i'} a_{i'} \given \history_{i-1}}
\geq \expecto[\strategy']{\score(\history_n) - \sum_{i\leq i' \leq n} \cost_{i'} a_{i'} \given \history_{i-1}}.
\end{align*}
\end{definition}

% \begin{definition}\label{def:dynamic separate cap}
% A scoring rule $\score$ is a \emph{dynamic separate scoring rules with score cap} $B\geq 0$
% if there exists single-dimensional scoring rules $\score_1,\dots,\score_n$ and shifting parameter $d\geq 0$
% such that 
% $\score(\signal,\outcome) = \project_{[0,B]}\cbr{-d+\sum_{i\in[n]} \score_i(\signal_i,\outcome_i)}$.
% \end{definition}