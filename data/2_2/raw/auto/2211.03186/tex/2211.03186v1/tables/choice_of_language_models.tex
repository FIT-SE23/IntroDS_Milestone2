\begin{table}[t]
    \caption{\textit{Model guidance quality.} Performance improves regardless of the exact language model and even with large-scale pretrained word embeddings s.a. FastText \cite{fasttext} and GloVe \cite{glove}. However, less transferable word hierarchies fall short in comparison.}
\vspace{-5pt}    
 \footnotesize
  \setlength\tabcolsep{1.4pt}
  \centering
  %\begin{tabular}{l|c|ccc|c}
  \resizebox{0.43\textwidth}{!}{
  \begin{tabular}{l || c | c || c | c }
     \toprule
     \multicolumn{1}{l}{\textsc{Benchmarks}$\rightarrow$} & \multicolumn{2}{c}{\textsc{CUB200-2011}} & \multicolumn{2}{c}{\textsc{CARS196}} \\
     \midrule
     \multirow{2}{*}{\textsc{Models} $\downarrow$} & \multirow{2}{*}{R@1} & mAP & \multirow{2}{*}{R@1} & mAP\\
      &  & @1000 & & @1000\\
    \midrule
    \rowcolor{vlightgray}
    \textbf{Baseline} & 62.8 $\pm$ 0.2 & 31.1 $\pm$ 0.3 & 81.6 $\pm$ 0.3 & 31.7 $\pm$ 0.1\\ 
    \rowcolor{vvlightgray}    
    + CLIP-L \cite{clip} & 67.3 $\pm$ 0.2 & \textbf{34.8 $\pm$ 0.2} & 85.3 $\pm$ 0.1 & \textbf{32.7 $\pm$ 0.2} \\
    % \hline
    % + $\mathbb{S}^{N-1}\left(\mathcal{N}(0,1)\right)$ & - $\pm$ - & - $\pm$ - & - $\pm$ - & - $\pm$ -\\
    \midrule        
    \multicolumn{5}{>{\columncolor[gray]{.9}}l}{\textbf{(a) Language Models}} \\
    \hline
    + BERT \cite{bert} & 66.9 $\pm$ 0.3 & 33.5 $\pm$ 0.2 & 84.9 $\pm$ 0.1 & 32.3 $\pm$ 0.1\\
    % + DistBert \cite{distilbert} & 66.7 $\pm$ 0.1 & 33.4 $\pm$ 0.2 & 85.4 $\pm$ 0.4 & 32.4 $\pm$ 0.1\\    
    % + Roberta-B \cite{roberta} & 67.0 $\pm$ 0.2 & 33.8 $\pm$ 0.2 & 84.9 $\pm$ 0.1 & 32.3 $\pm$ 0.3\\
    + Roberta-L \cite{roberta} & 67.3 $\pm$ 0.2 & 33.9 $\pm$ 0.3 & 85.1 $\pm$ 0.2 & 32.4 $\pm$ 0.2\\
    % + DistRoberta \cite{huggingface} & 66.0 $\pm$ 0.2 & 32.2 $\pm$ 0.2 & 85.0 $\pm$ 0.3 & 32.1 $\pm$ 0.2\\
    + Reformer \cite{Kitaev2020Reformer} & 66.7 $\pm$ 0.1 & 33.1 $\pm$ 0.1 & 85.5 $\pm$ 0.2 & 32.0 $\pm$ 0.2\\
    % + MPNet \cite{mpnet} & 66.2 $\pm$ 0.3 & 32.3 $\pm$ 0.2 & 85.4 $\pm$ 0.2 & 32.3 $\pm$ 0.3\\
    + GPT2 \cite{gpt2} & 67.0 $\pm$ 0.3 & 33.7 $\pm$ 0.1 & 84.8 $\pm$ 0.4 & 32.4 $\pm$ 0.1\\
    \hline
    + Top 3 & \textbf{67.5 $\pm$ 0.2} & 34.5 $\pm$ 0.3 & \textbf{85.6 $\pm$ 0.3} & 32.5 $\pm$ 0.3\\   
    \hline
    \multicolumn{5}{>{\columncolor[gray]{.9}}l}{\textbf{(b) Word Embeddings}} \\
    \hline
    + FastText \cite{fasttext} & 66.9 $\pm$ 0.3 & 33.7 $\pm$ 0.3 & 85.2 $\pm$ 0.1 & \textbf{32.7 $\pm$ 0.1}\\
    + GloVe \cite{glove} & 66.1 $\pm$ 0.2 & 33.1 $\pm$ 0.3 & 85.0 $\pm$ 0.2 & 32.1 $\pm$ 0.3\\    
    \hline
    \multicolumn{5}{>{\columncolor[gray]{.9}}l}{\textbf{(c) Word Hierarchies}} \\
    + WordNet \cite{wordnet} & 63.7 $\pm$ 0.2 & 31.3 $\pm$ 0.2 & 82.5 $\pm$ 0.3 & 31.0 $\pm$ 0.2\\
    + HierMatch \cite{hiermatch} & 64.8 $\pm$ 0.3 & 32.2 $\pm$ 0.1 & 82.8 $\pm$ 0.2 & 31.8 $\pm$ 0.1\\
    \bottomrule
    \end{tabular}}
    \label{tab:choice_of_language_models}
    \vspace{-8pt}
 \end{table}
 
 
 
 
 \begin{table}[t]
    \caption{\textit{Model guidance quality.} Performance improves regardless of the exact language model and even with large-scale pretrained word embeddings s.a. FastText \cite{fasttext} and GloVe \cite{glove}. However, less transferable word hierarchies fall short in comparison.}
\vspace{-5pt}    
 \footnotesize
  \setlength\tabcolsep{1.4pt}
  \centering
  %\begin{tabular}{l|c|ccc|c}
  \resizebox{0.43\textwidth}{!}{
  \begin{tabular}{l || c | c || c | c }
     \toprule
     \multicolumn{1}{l}{\textsc{Benchmarks}$\rightarrow$} & \multicolumn{2}{c}{\textsc{CUB200-2011}} & \multicolumn{2}{c}{\textsc{CARS196}} \\
     \midrule
     \textsc{Models} $\downarrow$ & R@1 & mAP & R@1 & mAP\\
    \midrule        
    \multicolumn{5}{>{\columncolor[gray]{.9}}l}{\textbf{(a) Language Models}} \\
    \hline
    + CLIP-L \cite{clip} & 67.3 $\pm$ 0.2 & \textbf{34.8 $\pm$ 0.2} & 85.3 $\pm$ 0.1 & \textbf{32.7 $\pm$ 0.2} \\
    + BERT \cite{bert} & 66.9 $\pm$ 0.3 & 33.5 $\pm$ 0.2 & 84.9 $\pm$ 0.1 & 32.3 $\pm$ 0.1\\
    % + DistBert \cite{distilbert} & 66.7 $\pm$ 0.1 & 33.4 $\pm$ 0.2 & 85.4 $\pm$ 0.4 & 32.4 $\pm$ 0.1\\    
    % + Roberta-B \cite{roberta} & 67.0 $\pm$ 0.2 & 33.8 $\pm$ 0.2 & 84.9 $\pm$ 0.1 & 32.3 $\pm$ 0.3\\
    + Reformer \cite{Kitaev2020Reformer} & 66.7 $\pm$ 0.1 & 33.1 $\pm$ 0.1 & 85.5 $\pm$ 0.2 & 32.0 $\pm$ 0.2\\
    % + MPNet \cite{mpnet} & 66.2 $\pm$ 0.3 & 32.3 $\pm$ 0.2 & 85.4 $\pm$ 0.2 & 32.3 $\pm$ 0.3\\
    \hline
    \multicolumn{5}{>{\columncolor[gray]{.9}}l}{\textbf{(b) Word Embeddings}} \\
    \hline
    + FastText \cite{fasttext} & 66.9 $\pm$ 0.3 & 33.7 $\pm$ 0.3 & 85.2 $\pm$ 0.1 & \textbf{32.7 $\pm$ 0.1}\\
    + GloVe \cite{glove} & 66.1 $\pm$ 0.2 & 33.1 $\pm$ 0.3 & 85.0 $\pm$ 0.2 & 32.1 $\pm$ 0.3\\    
    \hline
    \multicolumn{5}{>{\columncolor[gray]{.9}}l}{\textbf{(c) Word Hierarchies}} \\
    + WordNet \cite{wordnet} & 63.7 $\pm$ 0.2 & 31.3 $\pm$ 0.2 & 82.5 $\pm$ 0.3 & 31.0 $\pm$ 0.2\\
    + HierMatch \cite{hiermatch} & 64.8 $\pm$ 0.3 & 32.2 $\pm$ 0.1 & 82.8 $\pm$ 0.2 & 31.8 $\pm$ 0.1\\
    \bottomrule
    \end{tabular}}
    \label{tab:choice_of_language_models}
    \vspace{-8pt}
 \end{table}