\section{Introduction}
\label{sec:introduction}
Smart health research teams often develop novel machine learning technologies. To prove the value of the technologies, the research teams have to deploy the solutions into a complex environment such as a smart home \cite{bedon2020home, costin2009telemon, khan2017smart, gao2020monitoring}. However, the aforementioned works do not describe the problems related to the transition from the development stage to the deployment stage. In other words, during the development stage, the research teams try to develop their solution in an environment, usually a lab environment and/or a controlled home environment, which is less complex than the environment in which the technology is going to be deployed. It is well known that when new technology is actually deployed in real complex environments, issues previously unseen in the less complex environments  are going to occur, especially for long-term deployments. This paper describes the XYZ System, a pipeline of voice-based machine learning solutions for in-home monitoring of the emotion and verbal conflict experienced by a caregiver of a dementia patient. XYZ is considered a smart home technology because it helps caregivers of dementia patients better manage their anger by notifying them when an anger or verbal conflict is detected. As Pena et al. \cite{pena2015integrating} have discussed, one school of promoting emotion regulation is to permit the individuals from experiencing anger. Since people can be bad at recognizing their own emotions \cite{goerlich2018multifaceted}, a smart health technology that notifies them when an anger or verbal conflict arises is very important to their emotion regulation.

The goals of this paper are to (1) demonstrate solutions for what are needed at pre-deployment time to increase the success of voice-based classifiers once deployed, and (2) present lessons learned for environmental and behavioral complexities uncovered \textbf{during 4 month deployments in six homes}. 
%in which the XYZ System was deployed in each of them.
The main challenges of integrating novel machine learning technology into complex environments are that both the physical environments and the participants' behaviors are complicated. For a smart health technology that uses voice for emotion detection \cite{gao2021emotion}, the environment is complicated because the solution needs to address the problems of acoustic signal's deterioration due to background noise such as birds chirping, room reverberation due to the signal bouncing off the surface of furniture, and deamplification as a result of the distance between the human speaker and the microphone. We call these environmental distortions acoustical realisms. Also, the television could be on and the voice from the television adds to the complexity of detecting the participants' emotions. Human behavior is very complicated, too. For example, people could be yelling across the room to ask each other what is for dinner. They are not necessarily angry, but yelling itself is seen as an anger event by typical emotion detection technology. Visitors are common and for privacy the caregiver may turn the system off and forget to turn it back on. 

The gist of our solutions at pre-deployment time to ensure maximizing the post-deployment success of the machine learning algorithms in the XYZ System is that we make sure to evaluate the algorithms on data samples that are most similar to the samples that the algorithms are about to encounter in the designated environment in which the algorithms are/will be deployed. Using the XYZ System as an example, the (acoustical) samples that the algorithms in the XYZ System are about to encounter in its designated environment (a participant's home) are voice samples that are environmentally distorted. It is worth-noting that some works, such as Chen et al. \cite{chen2019arasid}, do consider the designated environment in which their algorithm is going to be deployed during the pre-deployment stage. However, they do not evaluate if their hypothesis that the algorithm \emph{indeed performs well during post-deployment time} holds true. Unlike works such as Chen et al. \cite{chen2019arasid}, we perform evaluations to show that after our rigorous pre-deployment time assessment of the algorithms to be deployed in the designated environment, our chosen algorithms indeed perform well during the post-deployment stage when they are being deployed in the designated environment (the home of a patient-caregiver dyad), which is one novelty of this paper. A more nuanced finding of this paper is that different acoustic components need to address different environmental realisms. For example, the voice activity detection (VAD) model only needs to deal with non-speech background noise, reverberation, and deamplification, whereas the emotion detection model needs to also deal with background speech (such as those from the tv) because background speech could confound the classification of the emotion detection model which uses speech to determine the emotion in that speech.

The purpose of the XYZ System is that we want to help caregivers of dementia patients to manage their anger as well as the verbal conflict events that arise during care-giving. To achieve these goals, the XYZ System has three add-on components: the Cloud to which the audio clips are uploaded for safe keeping, the M2G monitoring component that notifies the developer(s) if the XYZ System crashes so the developer(s) can investigate the causes, and the Recommender System using EMA, which sends messages that are interventions or recommendations to help the caregivers manage their emotions and verbal conflict, if anger or verbal conflict are detected by the XYZ System. The entirety of the XYZ System and the three add-on components are referred to as the \emph{XYZ-W} (XYZ-Whole) System.  We also present some lessons learned on several aspects of \emph{XYZ-W}. 
%the add-on components, which are an essential part to help realizing the goal of the XYZ System must adaptable after post-deployment time in order for the goal of the XYZ System to be realized. 

Note that the focus of this paper is the XYZ System, not its add-on components, so we do not evaluate how effective the add-on components are at helping the caregiver manage their emotions and verbal conflicts that arise during care-giving. Nonetheless, given their essential role at helping the XYZ System achieve its goals, we have decided to include some discussion of the add-on components in the paper.
%, demonstrating that the add-on components must be able to be changed on the fly quickly and easily (in other words, must be adaptable), for post-deployment success.

The contributions of this paper are based on the in-home deployed XYZ-W system from \textbf{six completed 4-month deployments of real caregiver-Alzheimer's patient interactions}. This work was performed under an approved IRB. The main contributions are:

\begin{itemize}
    \item A pre-deployment approach for improving standard and novel acoustic technologies deployment time success. %and identifying where additional improvement is required.
    
    \item A pre-deployment approach to make components in the deployed technology adaptable to they can be easily adjusted during the deployment time to satisfy the needs of the participants.

    \item Developing a set of privacy mechanisms that are shown to help dyad recruitment and satisfy privacy concerns of  actual users of the system. 
    
    \item Our post-deployment validation indicates that people are not always good at recognizing their own emotions, which reconfirms similar findings in the literature \cite{goerlich2018multifaceted}.
    
    

\end{itemize}