\section{Privacy Concerns}
Developing new research systems that will be deployed in homes require solutions for privacy issues during recruitment and during deployment. This is especially true when using sensing that can be considered invasive such a microphones. Our XYZ system is privacy-conserving, meaning that it concentrates on allowing users to benefit from its functionalities without releasing their voice data in its original form.

\subsection{Pre-deployment Stage Preparation}

During pre-deployment a set of privacy mechanisms were implemented. 
This included that users could set the day start and end times when the system is operational, turn off the system at any point, e.g., when a visitor was there, all voice from non-registered speakers would not be recorded, and that the content of speech would not be recorded, i.e.,  only prosidy features would be recorded.


During recruitment, the above privacy mechanisms were fully described to potential dyads. Also, using a graph and tables we showed them what prosidy means.
Nevertheless, one in four care-giving dyads who rejected participation in the study worried about the privacy issue despite the thorough explanation of the study procedures. Basically, once we explained that our system listens to them for anger/conflict events, it caused some of the prospective dyads to think about privacy invasion and they declined to participate in the study.

Overall, Table \ref{tab:human_behavior_privacy_recruitment} describes the reasons that potential participants did not choose to participate in our study: 3 potential participants did not meet the criteria to be included in our study. 15 potential participants lost interest in participating and did not reply to our call for screening that they must pass in order to be included in our study. 12 potential participants decided upfront with us during our communication with them that they were not interested. 10 potential participants found the study to likely be burdensome. 2 potential participants in our follow-up calls with them indicated that they are no longer interested in the study. 9 potential participants were no longer interested to participate due to various issues such as the patient passing away. 17 potential participants refused to participate out of the concern for privacy issues. Privacy is the main reason for 25\% of those interviewed (the largest percentage among all categories of the reasons to not participate). It can be expected that when deploying sensing systems in homes some people will reject the system. With enough privacy mechanisms we were able to limit those not willing to participate due to privacy to 25\%. 


\begin{table}[]
\centering
\begin{tabular}{cc}
\toprule
  Reason for Rejection & Number(\%) \\
\hline
Did not meet inclusion criteria &	3 (4.41\%) \\
Didn't reply to call for screening &	15 (22.06\%) \\
Not interested &	12 (17.65\%) \\
Burdensome &	10 (14.71\%) \\
No longer wanted to participate &	2 (2.94\%) \\
Other &	9 (13.23\%) \\
\textbf{Worried about privacy issue} &	\textbf{17 (25.00\%)} \\
\hline
Total &	68 (100\%) \\

%Amazon Transcription & 100\% &  100\% & 100\%\\
\bottomrule
\\
\end{tabular}
\caption{The reasons that potential participants did not join our study. 25\% of the potential participants refused to participate in our study because they were worried about privacy since our system would be listening to their conversation.}
\label{tab:human_behavior_privacy_recruitment}
\end{table}



%As we have observed, privacy is an important concern for the potential participants, as indicated in Table \ref{tab:human_behavior_privacy_recruitment}. Therefore, during the pre-deployment stage, we make sure to implement our strategy to lessen the potential participants' concern with privacy. The first part of the strategy is that we inform the potential participants that our XYZ System only uses the prosody of their voice, instead of the verbal content of their speech, to do emotion detection and conflict detection. The second part of the strategy is that we allow the participant to turn the XYZ System off when they do not want to be monitored. The gist of the pre-deployment stage preparation is that researchers need to anticipate where the privacy concerns may arise in terms of using their technology. Then, they need to address those aspects. In our case, we have anticipated that, because of XYZ System is acoustics-based, people will be concerned if their words will be recorded and analyzed. We also have anticipated that people will not want to be acoustically monitored all the time.


\subsection{Post-deployment Stage Assessment}

%\begin{table}[]
%\centering
%\scalebox{0.85}{
%\begin{tabular}{ccccccc}
%\toprule
%          & Dyad 1  & Dyad 2  & Dyad 3  & Dyad 4 & Dyad 5 & Dyad 6\\
%\hline
%Response       & $\times$  & \checkmark   & \checkmark    & \checkmark & \checkmark  & \checkmark   \\
%VGG         & 44.6\%    & 100\%     & 48.3 \%   \\
%\bottomrule
%\\
%\end{tabular}
%}
%\caption{The evaluation results for if the caregivers of dyads think that their privacy is respected and protected. The \checkmark mark means that a dyad's privacy concerned is addressed, while the $\times$ mark indicates that a dyad does not think that their privacy concerns was completely addressed.}
%\label{tab:eval_privacy}
%\end{table}

%Table \ref{tab:eval_privacy} showed if our strategy at pre-deployment time has successfully addressed the privacy concerns of the dyads. In Table \ref{tab:eval_privacy}, the \checkmark mark means that a dyad's privacy concerned is addressed, while the $\times$ mark indicates that a dyad does not think that their privacy concerns was completely addressed. 

Using a survey after the 4 month study, five out of six of the recruited dyads agreed that their privacy concerns are addressed and they have had no issue regarding privacy. However, one dyad still has some concerns over their privacy. In this home, the Alzheimers' patient (not the caregiver) pulled out the wires that connect our equipment to the power source, for he feared that during the time the system is set to not monitor them, the system is still actively listening. %Pulling out the wires results in our system running out of power and therefore unable to resume listening/monitoring when it is time to monitor again. 
We countered this distrust our system by showing these participants the data we collected: namely, we showed them the timestamps of the voice samples that we collected so they knew that outside of the active hours of the system that we were true to our word and the system did not listen to them. We also showed them amplitude plots of the data we collected where there are no words. We also showed them that there did not exist files which recorded the transcriptions of their conversation, since some concerns had been raised such that the participants were worried about being transcribed.


%During pre-deployment time, despite that the 6 caregiver-patient dyads that agreed to its sensing, there were still periods of time in which they did not want the system to listen to the conversations. As a result, we installed two features. The first feature allowed them to set up the time period during which they were comfortable with the system listening to their conversations. The second feature was allowing unplugging the microphone to stop the system from listening to the environment. These two measures proved to be largely successful as we did not hear about complaints on privacy issues except the two anecdotes that we are about to provide in the next paragraphs.

%The first anecdote is that the Alzheimers' patient (not the caregiver) of the first dyad pulled out the wires that connect our equipment to the power source, for he feared that during the time the system is set to not monitor them, the system is still actively listening. In other words, he distrusted our system, thinking that our system is still collecting data in its supposed ``not monitoring'' period. Pulling out the wires results in our system running out of power and therefore unable to resume listening/monitoring when it is time to monitor again. We countered the distrust our system by showing the participants the data we collected: namely, we showed them the timestamps of the voice samples that we collected so they knew that outside of the active hours of the system that we were true to our words and the system did not listen to them. We also showed them amplitude plots of the data we collected where there are no words. We also showed them that there did not exist files which recorded the transcriptions of their conversation, since some concerns had been raised such that the participants were worried about being transcribed.

%The second anecdote is when the participants have guests over. Since the guests may not consent to being listened to and monitored, the participants may turn off the system to prevent from being listened to. However, once they turn it off, they often forget to turn it on. When the system was turned off, a strategy must exist to restart the system in time to prevent us from losing valuable data. We countered the issue by monitoring the cloud: the cloud shows the active status of the systems for the research group members to monitor the systems' status. The active status of a system is indicated by whether the system is actively uploading data (generated audio clips, speaker identification result, and emotion classification and conflict classification results) to the cloud. If a system is not uploading data for a period of time (a flexible parameter), we contact the dyad so they could restart the system.

%After the deployment, we sent out a survey to ask the participants various questions, among which was whether or not they thought the privacy issues were handled. All participants agreed that the privacy issues were handled successfully.

\subsection{Summary}
Privacy concerns are likely to arise when researchers deploy their technology in the home environments. During the pre-deployment stage, researchers must implement privacy mechanisms even if they are not the core purpose of the system. These mechanisms must be explained to participants. We believe that the mechanisms we describe can be used in many systems that utilize speech of the participants. 
%eed to make sure that they address the privacy concerns which will be specific to the technology. In our case, we have anticipated that, because of XYZ System is acoustics-based, people will be concerned if their words will be recorded and analyzed. We also have anticipated that people will not want to be acoustically monitored all the time. 
Finally, the responses from the dyads at post-deployment time provide some evidence that privacy can be addressed to users' satisfaction. %our anticipations are correct and effective at addressing the privacy concerns of the dyads who are using our XYZ System at the deployment time. 