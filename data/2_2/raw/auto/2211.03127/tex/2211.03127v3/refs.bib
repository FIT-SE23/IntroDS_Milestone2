
% Classroom observation
@book{adelman2003guide,
  title={A guide to classroom observation},
  author={Adelman, Clement and Adelman, Clem and Walker, Roy},
  year={2003},
  publisher={Routledge}
}
@book{wragg2011introduction,
  title={An introduction to classroom observation (Classic edition)},
  author={Wragg, Ted},
  year={2011},
  publisher={Routledge}
}
@book{o2020classroom,
  title={Classroom observation: A guide to the effective observation of teaching and learning},
  author={O’Leary, Matt},
  year={2020},
  publisher={Routledge}
}


% EduSense, {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies}
@article{ahuja2019edusense,
  title={EduSense: Practical classroom sensing at Scale},
  author={Ahuja, Karan and Kim, Dohyun and Xhakaj, Franceska and Varga, Virag and Xie, Anne and Zhang, Stanley and Townsend, Jay Eric and Harrison, Chris and Ogan, Amy and Agarwal, Yuvraj},
  journal={UbiComp},
  volume={3},
  number={3},
  pages={1--26},
  year={2019},
  publisher={ACM New York, NY, USA}
}
% {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems}
@inproceedings{ahuja2021classroom,
  title={Classroom Digital Twins with Instrumentation-Free Gaze Tracking},
  author={Ahuja, Karan and Shah, Deval and Pareddy, Sujeath and Xhakaj, Franceska and Ogan, Amy and Agarwal, Yuvraj and Harrison, Chris},
  booktitle={CHI},
  pages={1--9},
  year={2021}
}
% Sensei relies on tiny proximity sensors embedded into shoes or other materials to provide relative positions of people and objects in a early-childhood classroom
@article{saquib2018sensei,
  title={Sensei: sensing educational interaction},
  author={Saquib, Nazmus and Bose, Ayesha and George, Dwyane and Kamvar, Sepandar},
  journal={UbiComp},
  volume={1},
  number={4},
  pages={1--27},
  year={2018},
  publisher={ACM New York, NY, USA}
}
% ACRON, {IEEE Transactions on Affective Computing}
@article{ramakrishnan2021toward,
  title={Toward automated classroom observation: Multimodal machine learning to estimate class positive climate and negative climate},
  author={Ramakrishnan, Anand and Zylich, Brian and Ottmar, Erin and LoCasale-Crouch, Jennifer and Whitehill, Jacob},
  journal={TAC},
  year={2021},
  publisher={IEEE}
}
% EmotionCues, {IEEE transactions on visualization and computer graphics}
@article{zeng2020emotioncues,
  title={EmotionCues: Emotion-oriented visual summarization of classroom videos},
  author={Zeng, Haipeng and Shu, Xinhuan and Wang, Yanbang and Wang, Yong and Zhang, Liguo and Pong, Ting-Chuen and Qu, Huamin},
  journal={TVCG},
  volume={27},
  number={7},
  pages={3168--3181},
  year={2020},
  publisher={IEEE}
}
% EngageMeter: Equipped students with electroencephalography headsets, EngageMeter could detect shifts in their engagement, alertness, and workload.
@inproceedings{hassib2017engagemeter,
  title={EngageMeter: A system for implicit audience engagement sensing using electroencephalography},
  author={Hassib, Mariam and Schneegass, Stefan and Eiglsperger, Philipp and Henze, Niels and Schmidt, Albrecht and Alt, Florian},
  booktitle={CHI},
  pages={5114--5119},
  year={2017}
}
% The Computer Expression Recognition Toolbox (CERT) [52] is most widely used in these educational technology applications, though it is limited to videos of single students (i.e., not classroom scale) {2011 IEEE International Conference on Automatic Face \& Gesture Recognition (FG)}
@inproceedings{littlewort2011computer,
  title={The computer expression recognition toolbox (CERT)},
  author={Littlewort, Gwen and Whitehill, Jacob and Wu, Tingfan and Fasel, Ian and Frank, Mark and Movellan, Javier and Bartlett, Marian},
  booktitle={FG},
  pages={298--305},
  year={2011},
  organization={IEEE}
}
% Affectiva’s wrist-worn Q sensor could sense every student’s skin conductance, temperature and motion. {International conference on affective computing and intelligent interaction}
@inproceedings{picard2011measuring,
  title={Measuring affect in the wild},
  author={Picard, Rosalind W},
  booktitle={ACII},
  pages={3--3},
  year={2011},
  organization={Springer}
}
@inproceedings{zheng2020intelligent,
  title={Intelligent student behavior analysis system for real classrooms},
  author={Zheng, Rui and Jiang, Fei and Shen, Ruimin},
  booktitle={ICASSP},
  pages={9244--9248},
  year={2020},
  organization={IEEE}
}
@inproceedings{lin2018hand,
  title={Hand-raising gesture detection in real classroom},
  author={Lin, Jiaojiao and Jiang, Fei and Shen, Ruimin},
  booktitle={ICASSP},
  pages={6453--6457},
  year={2018},
  organization={IEEE}
}



%% Our Behavior Datasets
%% OpenCV
@book{bradski2008learning,
  title={Learning OpenCV: Computer vision with the OpenCV library},
  author={Bradski, Gary and Kaehler, Adrian},
  year={2008},
  publisher={" O'Reilly Media, Inc."}
}
%% ffmpeg
@article{tomar2006converting,
  title={Converting video formats with FFmpeg},
  author={Tomar, Suramya},
  journal={Linux Journal},
  volume={2006},
  number={146},
  pages={10},
  year={2006},
  publisher={Belltown Media}
}
%% Pascal VOC
@article{everingham2010pascal,
  title={The pascal visual object classes (voc) challenge},
  author={Everingham, Mark and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={IJCV},
  volume={88},
  number={2},
  pages={303--338},
  year={2010},
  publisher={Springer}
}
%% labelme
@article{russell2008labelme,
  title={LabelMe: a database and web-based tool for image annotation},
  author={Russell, Bryan C and Torralba, Antonio and Murphy, Kevin P and Freeman, William T},
  journal={IJCV},
  volume={77},
  number={1-3},
  pages={157--173},
  year={2008},
  publisher={Springer}
}
% COCO
@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={ECCV},
  pages={740--755},
  year={2014},
  organization={Springer}
}




% YOLOv5
@article{jocher2020yolov5,
  title={Yolov5},
  author={Jocher, Glenn and Nishimura, K and Mineeva, T and Vilari{\~n}o, R},
  journal={Code repository https://github.com/ultralytics/yolov5},
  year={2020}
}
%% Faster r-cnn
@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={NIPS},
  year={2015}
}
%% R-fcn
@article{dai2016r,
  title={R-fcn: Object detection via region-based fully convolutional networks},
  author={Dai, Jifeng and Li, Yi and He, Kaiming and Sun, Jian},
  journal={NIPS},
  year={2016}
}
%% MTCNN
@article{zhang2016joint,
  title={Joint face detection and alignment using multitask cascaded convolutional networks},
  author={Zhang, Kaipeng and Zhang, Zhanpeng and Li, Zhifeng and Qiao, Yu},
  journal={SPL},
  volume={23},
  number={10},
  pages={1499--1503},
  year={2016},
  publisher={IEEE}
}
%% CovPoolNet
@inproceedings{acharya2018covariance,
  title={Covariance pooling for facial expression recognition},
  author={Acharya, Dinesh and Huang, Zhiwu and Pani Paudel, Danda and Van Gool, Luc},
  booktitle={CVPRW},
  pages={367--374},
  year={2018}
}

%% OpenPifPaf
@article{kreiss2021openpifpaf,
  title={Openpifpaf: Composite fields for semantic keypoint detection and spatio-temporal association},
  author={Kreiss, Sven and Bertoni, Lorenzo and Alahi, Alexandre},
  journal={TPAMI},
  year={2021},
  publisher={IEEE}
}

% my paper
@inproceedings{zhou2018raising,
  title={Who are raising their hands? Hand-raiser seeking based on object detection and pose estimation},
  author={Zhou, Huayi and Jiang, Fei and Shen, Ruimin},
  booktitle={ACML},
  pages={470--485},
  year={2018},
  organization={PMLR}
}
@inproceedings{narasimhaswamy2022whose,
  title={Whose hands are these? hand detection and hand-body association in the wild},
  author={Narasimhaswamy, Supreeth and Nguyen, Thanh and Huang, Mingzhen and Hoai, Minh},
  booktitle={CVPR},
  pages={4889--4899},
  year={2022}
}