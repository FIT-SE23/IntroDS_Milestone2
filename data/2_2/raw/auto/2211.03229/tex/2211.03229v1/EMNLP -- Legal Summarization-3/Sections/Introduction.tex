\section{Introduction}
Single document summarization aims at rephrasing a long text into a shorter version while preserving the important information \cite{INR-015}. While recent years have witnessed a blooming of abstractive summarization models that can generate fluent and coherent new wordings %and obtain high automatic evaluation scores %compared to human written summaries
\cite{rush-etal-2015-neural, zhang2020pegasus, lewis-etal-2020-bart},  abstractive %struggle to preserve the factual inconsistency.Such models can 
 summaries often contain hallucinated facts %which are not supported by the original source text 
 \cite{kryscinski-etal-2019-neural}. In contrast, extractive summarization models directly select sentences/phrases from the source document to form a summary. In certain domains such as the law or science \cite{bhattacharya2019comparativestudy,dong-etal-2021-discourse}, using  exact wordings may be needed. 

In this work, we focus on {\it extractive summarization of legal case decisions}. Different from texts in the news domain, case texts tend to be longer  (e.g., in Canadian legal case decisions \cite{xu-2021-position-case} there are on average  3.9k words, while standard news articles \cite{nallapati-etal-2016-abstractive} range from 400 - 800 words) and also have more complicated document structures (e.g., legal cases are likely to be split into sections while news articles are not). %It is also infeasible to expect that 
In contrast to scientific domains, which also have long and structured texts, large %scale %and high-quality
training sets of case decisions and reference summaries are generally not freely  available given the restrictions of the legal field.  %For example, 
A currently used case %decision %"appellate court decision" 
dataset has less than 30k training examples \cite{xu-2021-position-case}, which is ten times less than scientific datasets such as arXiv and PubMed \cite{cohan-etal-2018-discourse}. Thus, for the legal domain, it is not surprising that {\it unsupervised} extractive summarization methods are of %particular 
interest. %for the legal domain, %come to be the subject of usage. 
%Traditional unsupervised extractive models use 
%such as graph-based algorithms than  rank sentences based on an importance score. For the legal documents,  
Unfortunately, when researchers \cite{sarvanan-2006-graphical, bhattacharya2019comparativestudy} have attempted to directly apply standard unsupervised %extractive summarization 
models %(e.g., graph-based algorithms that  rank sentences based on an importance score) 
to legal data, they have obtained  mediocre results.  

However, most such attempts have failed to utilize the \textit{document structure
of legal texts}.
%For example, 
In case law, %documents, 
important sentences about the issues versus the decisions of the court occur in different places in the document structure.
In contrast,  summarization algorithms typically flatten any structure during initial processing (i.e., they concatenate sentences from different sections/paragraphs of a document to form a sentence list),
%More recent domain-agnostic 
%Algorithms such as PACSUM \cite{zheng-lapata-2019-sentence} instead 
or select sentences using structural biases from other domains (e.g., the importance of leading sentences in news \cite{zheng-lapata-2019-sentence}).
%which is incapable of dealing with the complicated scenario of legal documents (argumentative sentences such as the issue and decision presented by the court are distributed uniformly in the article). 
As shown in Figure \ref{fig:output_figure}, while %the 
LexRank %algorithm
\begin{figure}[t]
\centering
 \includegraphics[width=1.02\linewidth]{Figs/doc_fig.001.jpeg}

  \caption{An example %CanLII 
  case law document-summary pair (ID: 3\_2000canlii19612) and different summarization system outputs, where sentences are annotated with \textit{argumentative}  \textcolor{red}{Issue}, \textcolor{reasonblue}{Reason}, and \textcolor{conclusiongreen}{Conclusion} labels. Our %proposed
  method better extracts  argumentative sentences from the source document by exploiting its structure.} %For example, one simple way to split the example document into text segments is to use %sentences with the bold and capitalized section names (e.g., BASIS OF CLAIM separating the header information from the main text) as segment boundaries. }
  \label{fig:output_figure}
\end{figure}
correctly extracts the legal issue from the beginning of the source text, it incorrectly extracts several redundant sentences (i.e., %neighboring sentences starts with 
\textit{[20], [21]} and \textit{[22]} %are all selected, which in fact 
which talk about similar content) as well as ignores a large part of the article (e.g., no sentences are extracted from the last section of the original case: \textit{RECAPITULATION OF CALCULATION OF DAMAGES}). In contrast, the human  summary focuses on sentences related to the argument of the legal decision (e.g., what are the issues, reasoning and conclusions of this court case?), which tend to be spread across the document structure. % (which in turn be  computed using different segmentation algorithms such as HMMs or even bolding and capitalization heuristics). 
%More recent domain-agnostic algorithms such as PACSUM \cite{zheng-lapata-2019-sentence}, instead utilized the leading bias of selection of the news domain data, which is incapable of dealing with the complicated scenario of legal documents (argumentative sentences such as the issue and decision presented by the court are distributed uniformly in the article). 

%The only work that starts utilizing the document structure, 
Recently, the  HipoRank model was proposed to  exploit discourse structure patterns during unsupervised extractive summarization \cite{dong-etal-2021-discourse}.  However, the model was designed for  long scientific articles, and the experiments were based on data where the articles were already split into document sections.   %segemented which has a more explicit organization of contents through section segmentation and looser connection across sections. 
For case decisions,  document structures are generally either missing or only implicitly conveyed by text formatting.  For example, in Figure \ref{fig:output_figure}, document  sections are conveyed by bolding in the source HTML file. %, which are typically ignored in summarization data processing. 
Moreover, algorithms such as PACSUM and HipoRank compute  sentence centrality just once and greedily select the top-k candidates %to %extract sentences. 
as the extractive summary. 
%Our pilot study on one of the legal case summarization dataset \cite{xu-2021-position-case} unveils the drawback of such method, as argumentative sentences in legal cases tend to have a uniform distributions and they have higher semantic similarities. 
Such a greedy {selection algorithm} fails to match the distribution of the argumentative sentences that ultimately appear in human case law summaries. %  (recall Figure \ref{fig:output_figure}). 
%and generates low quality summaries. 


To address these limitations, we investigate the utility of different methods for %computing  document structure that %derived from the source text 
%to 
 automatically % model the %hierarchical 
segmenting the sentences of legal case decisions into the sections of a document structure. We posit that incorporating {\it better views of  document structure} could bring improvements in summarization quality
when discourse-aware methods such as HipoRank are applied to legal case decisions.
%Similar to \cite{dong-etal-2021-discourse}, we built document graph with directionality (location relationship between sentences) and hierarchy (section to sentence) to reflect the rich
%document structure of long legal documents.
We also propose a novel \textit{reweighting algorithm} to improve how HipoRank selects sentences when creating extractive summaries of legal decisions.  The algorithm
%We further propose a novel reweighting algorithm, which 
takes the history of already selected summary sentences into account, and gradually updates the importance score of a sentence.  We posit that reweighting will  decrease the selection of  redundant sentences as well as increase the selection of argumentative sentences from less-represented document segments (e.g.,  in the middle).

We evaluate our proposed method\footnote{Our code is available at \url{https://github.com/cs329yangzhong/DocumentStructureLegalSum}} for summarizing legal decisions using an annotated  Canadian case summarization dataset (CanLII) \cite{xu-2021-position-case}. Based on the belief that \textit{argumentative sentences} will capture the important sentences to summarize in a legal decision \cite{xu-2021-position-case,elaraby-litman-2022-arglegalsumm}, a portion of the CanLLI dataset comes with gold-standard sentence-level labels identifying which sentences are related to the issue/reasoning/conclusion of the court's decision in both source and summary documents. We use these labels to additionally propose a  metric that can better evaluate the quality of the generated summary from a legal expert's perspective. 
Empirical results show that our method
improves performance over previous unsupervised
models \cite{zheng-lapata-2019-sentence, dong-etal-2021-discourse, erkan2004lexrank} in automatic evaluation. 
