
\section{Details of the Micro-architecture Generator Engine}
\label{detailed_uarch}
\paragraph{Core} For deep learning models, the kernels are usually highly parallel in nature and therefore, our goal is to maximize total compute throughput under the area and power budgets allocated for compute. Given the area budget, we first compute the maximum number of MCUs (minimal compute units) that can fit within the area allocated. 
%Then, we compute the voltage and frequency of the compute units such that the total peak power is within the power budget allocated. 
The nominal frequency and voltage for each MCU is an input to the model, therefore the nominal power for each MCU and the entire core can be derived very easily. 
%
If the nominal power exceeds the power budget, we scale down the frequency and voltage. If we hit the minimum voltage limit set in the component description, we reduce the number of MCUs till we satisfy the total power budget allocated to the compute units.
%
This explains a case where the core design is power-bound and not area-bound.

Once we determine the total number of cores and the frequency of operation, we compute the compute throughput by appropriately scaling the nominal flop rate.
\begin{comment}
\begin{equation}
    Throughput = N \times Flop_{nominal} \times {\frac{f_{op}}{f_{nominal}}}
    \label{eqn:compute_throughput}
\end{equation}
where $N$ is the total number of cores, $Flop_{nominal}$ is the nominal flop rate of each core, $f_{nominal}$ is the nominal frequency corresponding to the technology node of the core and $f_{op}$ is the scaled final operating frequency. We use standard Voltage-Frequency-Power scaling methodology~\cite{} to obtain the operating voltage and frequency.
\end{comment}
\vspace{-0.1cm}
\paragraph{Register and Cache Memory} The total area and power budgets allocated to each level of on-chip memory is split between the memory banks and 
the network circuitry that connects the memory banks at each level to u-architectural components at the next level that are under its scope.
%the on-chip network used to communicate between the microarchitectural components under the scope of that level. 
We assume this interconnect to have a crossbar topology. The total number of components under its scope and the number of banks in that memory level determine the area and power overheads of the network. We iteratively determine the total number of  banks possible at each level of memory hierarchy such that the total area of the banks and the network at every level satisfies the area budget allocation. 
Once we determine the number of memory banks, we calculate total static power of all the banks and we allocate the remaining power budget to dynamic access energy. The available dynamic energy budget determines the maximum achievable throughput.

%as shown in Equation~\ref{eqn:throughput_memory}.
\begin{comment}


\begin{equation}
    P_{static} = P_{static-per-bit} \times N_{banks} \times Capacity_{bank}
    \label{eqn:static_power_cache}
\end{equation}

\begin{equation}
    Throughput = \frac {P_{on-chip-mem} - P_{static}}{Energy_{dyn-per-bit}}
    \label{eqn:throughput_memory}
\end{equation}
\end{comment}
\vspace{-0.2cm}
\paragraph{Main Memory} 
Main memory has two major components that collectively control the overall capacity and bandwidth but are housed in two different places. Memory controller which is placed on the compute chip, and the memory devices are placed outside the compute die within the same package.
The area allocation to each component determines the maximum number of memory devices that can be supported, which in turn determines the total memory capacity. Meanwhile power and perimeter allocation dictates the number of links (that can fit along the compute die), and the frequency of each link which collectively determine the overall off-chip memory bandwidth.

%The number of main memory devices that can fit in a node is determined by three factors:(1) Main memory area budget within the node. E.g., in an interposer or multi-chip module setup, the number of memory devices that can be accommodated in a package is determined by the size of the integration substrate available after the compute/processor chip is placed on the substrate; (2) The number of memory controllers that can fit in the area available in the processor chip. (3) The number of memory interfaces/links that can fit along the available perimeter budget of the compute die. Note that this is dictated by the integration technology's interconnect density. In this framework, we assume that the off-chip memory devices would use standard interfaces and therefore the interface width per device would be fixed and is an input to the tool. 
%The maximum number of memory devices is determined by the most limiting of the three above-mentioned factors. Once the maximum number of memory devices is determined, AGE calculates the total capacity based on the capacity per device. The overall throughput then is calculated based on the frequency and the total interface data-bus width, similar to the case of caches.
%Next, the total static power of the off-chip memory subsystem is computed based on the static power per-bit data. Given the off-chip memory power budget and the static power known, the next step is to calculate the total memory bandwidth based on the remaining power budget. To do so, the frequency of operation of the memory is calculated using the standard voltage-frequency scaling methodology. The overall throughput then is calculated based on the frequency and the total interface data-bus width, similar to Eq.~\ref{eqn:throughput_memory}.


\begin{comment}



%the tool calculates the bus width between the compute and the memory die using Equation~\ref{eqn:bus_width}, where $BusWidth$ is the number of links possible between the compute die and each memory device, $perimeter_dram$ is the perimeter of the compute die that is allocated for off-chip memory communication, $N_{devices}$ is the total number of memory devices, $\#Links_{device}$ is the maximum bus width that each memory device can support and $\#Links_{mm}$ is the total number of inter-chip links that the interconnect substrate can accommodate.

\begin{equation}
\small
\begin{split}
    \#Devices = min(&\frac{Node\ Area - Processor\ Chip\ Area}{Device Area}, \\ & \frac{Area\ budget\ for\ Memory\ Controllers}{Memory\ Controller\ Area},
    \\ & \frac{Perimeter \times \#Links\ per\ mm}{\#Links\ per\ device})
    \label{eqn:num_mem_devices}
\end{split}
\end{equation}
\end{comment}
%Once the bus width per memory device is known, the tool calculates the link frequency based on the main memory budget using the standard voltage-frequency scaling methodology. The tool ensures that the operating voltage satisfies the maximum and the minimum voltage limits set in the technology library. Finally the throughput is calculated similarly as provided in Equation~\ref{eqn:throughput_memory}.
\vspace{-0.2cm}
\paragraph{Network} 
The off-chip network links (intra and inter-package) consume both power and area on the compute die. Moreover, the wires need to escape the periphery of the die which gets determined by the interconnect density and the available chip perimeter. The maximum number of links that can be accommodated in the compute die is limited either by the area available to fit in the link I/O cells or the amount of perimeter available for the links to escape the die periphery. Therefore, the tool uses the area per link, the available area budget, wiring density and the die perimeter budget to find the maximum number of links that can fit in the chip. Next, the tool uses the standard voltage-frequency scaling methodology to find the operating point for each link such that the total network related power is within the power budget allocated. The network bandwidth is then calculated by multiplying the total number of links and the operating frequency of each link. We perform this step for the intra-node network and inter-node network separately.