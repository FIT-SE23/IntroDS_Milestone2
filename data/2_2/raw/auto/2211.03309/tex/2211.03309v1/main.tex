\documentclass[10pt,journal,compsoc]{IEEEtran}
%\documentclass[manuscript]{acmart}
%\documentclass{article}
%\documentclass[sigconf,authordraft]{acmart}

%\AtBeginDocument{%
% \providecommand\BibTeX{{%
%    \normalfont B\kern-0.5em{\scshape %i\kern-0.25em b}\kern-0.8em\TeX}}}


%\setcopyright{acmcopyright}
%\copyrightyear{2022}
%\acmYear{2022}
%\acmDOI{}

%\acmConference[ICCAD '22]{}
%\acmConference{}
 
%\acmPrice{}
%\acmISBN{}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage[frozencache,cachedir=.]{minted}
\usepackage{caption}
\usepackage{epstopdf}


%\expandafter\def\expandafter\normalsize\expandafter{%
%    \normalsize
%    \setlength\abovedisplayskip{1pt}
%    \setlength\belowdisplayskip{1pt}
%    \setlength\abovedisplayshortskip{1pt}
%    \setlength\belowdisplayshortskip{1pt}
%    \setlength\abovefloat{1pt}
%   \setlength\belowfloat{0.75em}
%    
%}
%\usepackage{mlsys2022}
%\usepackage[colorlinks=true,linkcolor=blue,citecolor=blue]{hyperref}
\setlength{\parskip}{0.1cm}
\setlength{\parindent}{1em}
\setlength{\textfloatsep}{5pt plus 2.0pt minus 2.0pt}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
%\usepackage{mlsys2022} 
%with 
%\usepackage[nohyperref]{mlsys2022}

%\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
%\usepackage{algorithmic}
\usepackage{adjustbox}
\usepackage{graphicx}
\usepackage{textcomp}
%\usepackage{xcolor}
\usepackage{comment}

\usepackage{hyperref}

\usepackage{multirow}% http://ctan.org/pkg/multirow
\usepackage{hhline}
%\usepackage[bf]{caption}
%\usepackage{subcaption}
%\usepackage{fancyhdr}
%\usepackage{array}
\sloppy
\newlength\bibitemsep
%\usepackage{savetrees}[moderate]
%\usepackage{subcaption}

%\newcommand{\theHalgorithm}{\arabic{algorithm}}
\newcommand{\uvec}[1]{\hat{\textbf{#1}}}


%\usepackage[ruled,vlined]{algorithm2e}
\usepackage{listings}
\lstset{numbers=left, numberstyle=\tiny, stepnumber=1, numbersep=5pt}

\newcommand{\ignore}[1]{}

\newcommand{\perfE}{PPE }

%\def\BibTeX{{\rm B\kern-.05em{\sc %i\kern-.025em b}\kern-.08em
%    T\kern-.1667em\lower.7ex\hbox{E}\kern-.1%25emX}}
    
%\setlength{\aboveparkskip}{0pt}

\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}

%%%%%%%%%%%%%%%%%%
\newcommand{\name}{DeepFlow }
\title{DeepFlow: A Cross-Stack Pathfinding Framework for Distributed AI Systems}
%%%%%%%%%%%%%%%%%%
%\twocolumn[
%\mlsystitle{\papertitle}
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
%should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}
%}

%\author{\IEEEauthorblockN{1\textsuperscript{st} Given Name Surname}
%\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
%\textit{name of organization (of Aff.)}\\
%City, Country \\
%email address or ORCID}
%\and
%\IEEEauthorblockN{2\textsuperscript{nd} Given Name Surname}
%\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
%\textit{name of organization (of Aff.)}\\
%City, Country \\
%email address or ORCID}
%\and
%\IEEEauthorblockN{3\textsuperscript{rd} Given Name Surname}
%\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
%\textit{name of organization (of Aff.)}\\
%City, Country \\
%email address or ORCID}
%\and
%\IEEEauthorblockN{4\textsuperscript{th} Given Name Surname}
%\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
%\textit{name of organization (of Aff.)}\\
%City, Country \\
%email address or ORCID}
%\and
%\IEEEauthorblockN{5\textsuperscript{th} Given Name Surname}
%\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
%\textit{name of organization (of Aff.)}\\
%City, Country \\
%email address or ORCID}
%\and
%\IEEEauthorblockN{6\textsuperscript{th} Given Name Surname}
%\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
%\textit{name of organization (of Aff.)}\\
%City, Country \\
%email address or ORCID}
%}

%\maketitle
%\usepackage{savetrees}[moderate]

\author{Newsha~Ardalani,~\IEEEmembership{Member,~IEEE,}
        Saptadeep~Pal,~\IEEEmembership{Member,~IEEE,}
        and~Puneet~Gupta,~\IEEEmembership{Fellow,~IEEE}% <-this % stops a space
\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem Newsha Ardalani is with Meta, Inc. This work was primarily done during her tenure at Baidu Research.\protect
% note need leading \protect in front of \\ to get a newline within \thanks as
% \\ is fragile and will error, could use \hfil\break instead.
E-mail: new@fb.com
\IEEEcompsocthanksitem Saptadeep Pal and Puneet Gupta are with University of California, Los Angeles
E-mail: saptadeep@ucla.edu, puneetg@ucla.edu
}% <-this % stops an unwanted space
\thanks{Manuscript received Oct 3, 2022.}}



\maketitle
\begin{abstract}
Over the past decade, machine learning model complexity has grown at an extraordinary rate, as has the scale of the systems training such large models. 
However there is an alarmingly low hardware utilization (5-20\%) in large scale AI systems. The low system utilization is a cumulative effect of minor losses across different layers of the stack, exacerbated by the disconnect between engineers designing different layers spanning across different industries. 
 %What is needed is a framework to connect researchers/developers across different layers of the stack to communicate their needs, and understand the impact of their design decisions trickling up and down the stack.
We propose CrossFlow, a novel framework that enables cross-layer analysis all the way from the technology layer to the algorithmic layer. 
We also propose DeepFlow (built on top of CrossFlow using machine learning techniques) to automate the design space exploration and co-optimization across different layers of the stack. We have validated CrossFlow accuracy with distributed training on real commercial hardware and showcase several DeepFlow case studies demonstrating pitfalls of not optimizing across the technology-hardware-software stack for what is likely, the most important workload driving large development investments in all aspects of computing stack.   
%We show that currently, parallelization strategy exploration is a more effective (and cheaper) approach than logic technology scaling to improve performance. However, if network technology improves by orders of magnitude, parallelization strategy would not be the most dominant factor.
%To quench the thirst for human-level accuracy and beyond, machine learning problems are rapidly growing in size.
%Computational resource requirements to train such large models have long surpassed the capacity of a single accelerator chip. These days, large models get trained using large systems consisting of hundreds to thousands of accelerator chips. already straining system-level resources such as inter-node network 
%Designers need to take into account the trade-offs associated with model-level, data-level, and kernel-level parallelism while designing such systems. 
%In this paper, we study how different trends of technology scaling, model scaling and parallelism strategy would shape the landscape of computing.
%Specifically, we design \name to study the interplay between technology parameters (e.g., energy per flop, energy per bit access to different levels of memory hierarchy), parallelism strategy (model parallelism, data parallelism, hybrid parallelism), model architecture parameters (e.g., width, depth, sequence length), hardware architecture design decisions per-accelerator (e.g., compute throughput, memory bandwidth, memory capacity) and across-accelerator design decisions (e.g., network bandwidth and topology). Besides, we will design a GD search engine around \name  which allows fixing any set of these parameters and find the best combination of the rest to meet some user-defined constraints such as total power budget and/or time-to-train.
\end{abstract}
%]

\input{intro}
\input{motivation}
\input{overview}
\input{hardware}
\input{graph}
\input{perf}
%\input{map}
\input{search}
\input{validation}
\input{case}
\input{related}
\input{conc}

%%%%%%%%% -- BIB STYLE AND FILE -- %%%%%%%%
%\clearpage
\bibliography{refs}
\bibliographystyle{ieeetr}
%\clearpage
%\appendix
%\section{A}
%
%\input{related}
%\input{appendix_hw_generator}

\end{document}
