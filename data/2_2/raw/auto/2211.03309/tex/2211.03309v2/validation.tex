%\input{figs/validation}
%\input{figs/gemm_p4}
%\input{figs/gemm_val}
%\input{figs/lm_val}
%\input{figs/case}
%\vspace{-0.6cm}
\section{Validation}\label{sec:validation}
We validate our performance prediction model against execution time measured on real systems (Nvidia P4 with 1 GPU and an NVIDIA DGX-1 system with 8 V100 GPU cards), running distributed GEMM as well as large-scale language models. %unlike prior work that validate against a simulator, like Maestro???~\cite{})
%\subsection{Methodologies}
%\textbf{Applications} We look into important kernels like distributed GEMM, and important end-to-end applications like language model (RNN-based) for validation.
%For validation, we look into important \textbf{applications and kernels}, including distributed GEMM and large-scale language model (RNN-based).
In particular, we study (2-layer LSTM) language models (LM) for validation and case study as it is deemed to be one of the most challenging applications to scale~\cite{hestness2019beyond}, 
%Moreover, it is an essential component to many important industry products, including search and speech recognition and
and is very costly to train~\cite{dlcost}. All applications are implemented in Tensorflow 2.0.
%and has tight time-constraints; 
%it needs to be retrained very frequently and is very costly to train. All the application are implemented in Tensorflow 2.0.
%
%\textbf{Measured Time} 
%We collect the real execution times (\textbf{true labels}) by running the applications on two different system setup: 1. an Nvidia P4 card and 2. an NVIDIA DGX-1 system with 8 V100 GPU cards. 
%We report the average execution time of 100 runs. 
%For 1 GPU runs we use Nvidia profile (nvprof) to collect timing of GEMM kernels. 
%For more than 1 GPU and LM applications, we use Tensorflow 2.0 time measurement hooks to measure the training time for each epoch. 
%This number would include all the software stack latency.
%
%\textbf{Predicted Time} 
We use CrossFlow to predict the runtime, %of the applications we run on the hardware. 
which can take anywhere from milliseconds to 20 seconds. %depending on the kernel dimensions.
%We also adjust the maximum utilization parameters for each resource through micro-benchmark based measurements. 
%Using Nvidia system profiler tool and micro-benchmarks, we found that on V100 cards, cores, memory, caches and network operates in average at 85\%, 100\%, 65\% and 95\% of peak utilization, respectively. While the utilization number might change slightly from kernel to kernel or even different configurations of the same kernel, we found that variations in sustained throughput is negligible (within 2-5\%).

%\textbf{Validation Space} 
For GEMM validation, we look at a space of more than 2000 GEMM kernels of different shapes and parallelism strategies, where input (\texttt{m}), output (\texttt{n}) and inner dimensions (\texttt{k}) varying from 4K to 32K in steps of 4K, and parallelized across 1, 2, 4, or 8 GPUs, using both Row-Column and Column-Row distributed parallelism strategies. 
For LM validation, we look into a space of 125 configurations, where \texttt{Batch Size}, \texttt{Hidden Dimension} and \texttt{Vocab Size} varying from 2K to 6K in steps of 1K. 
%The range of the values to sweep through is more limited for LM due to its large memory capacity requirement and capacity limitation for measurement on real system.
%
%Note here that LM validation space for an end-2-end application is smaller than GEMM's due to large memory requirements for softmax and embedding layers during training on real hardware, and memory capacity limitations for measurement on the V100 GPUs in a DGX-1 system.
%
%\textbf{Prediction Accuracy Metric} 
We report the correlation (corr), and also the mean relative error (err) to quantify the quality of our predictions. %We refer to this value simply as error in the discussion follows. 

%\textbf{Results}
%One of the major components of any deep learning application is GEMM kernel.
%We study the performance prediction of GEMM kernel in the context of single and distributed GEMM implementation. In the distributed GEMM cases, we implemented two parallelization strategies: (1) Row-Column, and (2) Column-Row~\cite{}.
Figure~\ref{fig:gemm_p4} shows the validation results on Nvidia P4 GPU card. On the X-axis, we show the measured time (in log-scale), and on the Y-axis, we show the predicted time (in log-scale).
As shown, predictions and measurements are highly correlated (0.996) and the error is small (8.9\%).
Figure~\ref{fig:gemm_val} shows that CrossFlow  predictions  on a DGX-1 system across 1, 2, 4 and 8 V100 GPU cards are well correlated (0.98-0.99) and have low error (6\%-18\%).
%As shown, we can predict the run-time with 10-14\% average error across different GPU cards and different distributed training settings. 
%The error is mostly dominant in 
%\textbf{End-2-End Application Validation}
Figure~\ref{fig:lm_val} shows the performance of LM on V100 GPU card. Similarly, we can predict performance with high correlation (0.996), and low error (16\%).
A constant pattern visible across all results is the performance prediction deviation from measurement on real hardware for small kernels. This is  expected as Tensorflow 2.0 time measurement hooks include all the software stack latency; while this overhead is negligible for large kernels, it accounts for a large portion of total run-time if the kernel is very small.
This indicates the tool outcome would be more reliable for large kernels and large models.

