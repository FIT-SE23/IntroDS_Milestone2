\section{Related Work}
%\vspace{-0.2cm}
Related work can be broadly categorized into (1) performance modeling frameworks for spatial architectures like TimeLoop and Maestro, (2) performance modeling frameworks for parallelism exploration such as FlexFlow, and (3) what-if analysis tools like DayDream and Habitat.

Similar to TimeLoop~\cite{timeloop} and Maestro~\cite{maestro}, we use an analytical model to estimate performance, however, the scope of DeepFlow is much broader. 
TimeLoop and Maestro model a single kernel runtime on the spatial architecture like systolic array or Eyeriss. Similarly, Mind Mapping~\cite{mindmapping} is a gradient based search tool that finds the best tiling and mapping strategy for a single compute unit and is built on top of Timeloop.
In this regard, all these prior work are similar to analytical models that goes into DeepFlow's MCU modeling. However, DeepFlow offers more than MCU modeling.
DeepFlow allows to capture not only the behavior of an MCU unit but also an entire GPU (through modeling of communication across MCU units through shared layers of memory hierarchy) as well as modeling a data center full of GPUs. Besides, prior work validates against simulators on micro-kernels. We validate our model against SOTA GPU hardware on real-world applications.
Furthermore, DeepFlow models an entire compute graph, composed of many kernels mapped and distributed across multiple GPU nodes, and allows the analysis of parallelism at this level, including pipeline, data and kernel parallelism. Moreover, DeepFlow provides four degrees of freedom to explore: model architecture, hardware architecture, technology configuration and parallelism strategy.

FlexFlow~\cite{flexflow} is an ML-based model for exploring the best parallelism strategy which relies on the runtime profiling tools to measure kernel timings on the target hardware. While it provides a very rich input for expressing different model architectures, it can only model existing hardware, hence not suitable for parallelism-architecture-technology co-design exploration. 

DayDream~\cite{zhu2020daydream} is a what-if analysis tool that enables researchers to evaluate the efficacy of different \textit{algorithmic} optimizations for an \textit{existing} hardware. However, it relies on fine-grain profiling tools to construct dependency graph, hence it lacks the ability
to predict individual kernel run-time on non-existing hardware and cannot be used for architecture or technology co-design space exploration.
%
Similarly, Habitat~\cite{geoffrey2021habitat} predicts deep learning workloads' run-time across different \textit{existing} GPUs, using a combination of wave scaling and MLP predictors. Wave-scaling can only model simple uarchitectural modification, and MLP predictors are u-architecture specific models that require collecting a large set of runtime data on the baseline and target hardware for model training, hence cannot be applied to non-existing hardware.

Astra-sim~\cite{astra-sim} is a simulator for hardware-software co-design of distributed deep learning systems. The focus of the paper is on detailed modelling of the inter-node network and they study the effects of network topologies and architecture choices. Astra-sim doesn't explore automated technology and architecture exploration and may not be suited for across the stack design space exploration because of the detailed and heavy-weight focus on network effects. 

