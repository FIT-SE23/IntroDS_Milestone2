\section{Introduction}

Fuzzing is one of the most effective and widely-used methods for identifying vulnerabilities. 
Given a targeted program under test (PUT), the goal of fuzzing is to find inputs that cause abnormal termination of the program.
To address this problem, fuzzers iteratively mutate a given set of test cases or generate random byte sequences with a given grammar to obtain new inputs and execute the program with those inputs.
Despite the simplicity of its mechanism, fuzzing has discovered a large number of bugs and vulnerabilities and has contributed considerably to improving the quality and security of software \cite{SAGE, ClusterFuzz}. 

Fuzzing can be customized for specific types of PUT to maximize its effectiveness.
For example, extensive research has been conducted on the design of fuzzers targeting file formats with a fixed syntax, such as XML, and software with semantics, such as JavaScript engines and database management systems \cite{NAUTILUS, DIE, FuzzIL, SQUIRREL, syzkaller}.
To be more general, fuzzers can be optimized if users have a clear scope of programs to fuzz and can devote engineering efforts to make them reflect the characteristics of the targeted programs, as in structure-aware \cite{AFLSmart, protobufmutator} and human-in-the-loop fuzzing \cite{IJON}.

On the other hand, fuzzers have already been used to ensure software quality and security in an unspecified large number of software development projects, as seen in OSS-Fuzz \cite{OSSFuzz}.
In most cases, fuzzers are considered just one of the automated services used during development, and it is possible that developers cannot afford the cost of customizing and effectively using fuzzers.
This suggests that it is desirable to automatically tune fuzzers by considering the characteristics of the provided programs to maximize their effectiveness without requiring additional engineering efforts.

To meet this demand, online optimization algorithms, particularly bandit algorithms, have gained attention in recent years as a means of accelerating the efficiency of mutation-based fuzzing \cite{ScheduleBlackBox, EcoFuzz, SyzVegas, AdaptiveFuzzTS, CMFuzz, HierarSeed, SIVO, HavocMAB}.
They are expected to work with a minimum amount of information that can be retrieved in any environment as long as feedback-driven fuzzing can be used. 
For example, mutation-based fuzzing generates new input by randomly making several choices, including the choice of seeds to be mutated and the mutation method.
By treating these choices as bandit problems, fuzzers have successfully found more execution paths, and thus, bugs.

In this study, we propose \OurMethodName, a new optimization framework that uses bandit algorithms to optimize two particular choices in mutation-based fuzzing: the method of mutation and the number of mutations to be performed on a seed at once.
This allows fuzzers to distinguish which method and number of mutations are more likely to discover new execution paths at runtime without any prior knowledge.
To take full advantage of bandit algorithms, we made the following three key observations upon incorporating them.

\noindent\textbf{Bandit-friendly mutation scheme}\ \ We introduce a new mutation scheme that is, so to speak, \textit{bandit-friendly} so that the two choices in mutation can be easily and directly treated as bandit problems.
Whereas the typical mutation scheme used in existing fuzzers applies multiple types of mutation operators at a time, our scheme uses exactly one type of mutation operator per mutation, considering that only one arm can be selected per step in a bandit problem.
We experimentally show that a fuzzer achieves similar code coverage regardless of whether it follows the conventional scheme or our bandit-friendly scheme, which allows the modification of existing fuzzers so that they follow the bandit-friendly scheme.
This mutation scheme resolves the dependency of existing methods on heuristics that were introduced to harness online optimization without changing the mutation scheme \cite{AdaptiveFuzzTS, CMFuzz, MOpt}.
Although these heuristics work well in practice, it is also beneficial to adhere to vanilla optimization algorithms by changing the scheme itself; this enables us to take advantage of the theoretical guarantees and advancements in the well-researched field of optimization algorithms. For example, it enables the direct incorporation of unseen algorithms to be proposed in the near future into fuzzing.

\noindent\textbf{Optimization of batch size}\ \ Our optimization target includes not only the mutation operators but also the number of times mutations are applied to one seed at a time, referred to hereafter as \textit{batch size}.
We acknowledge that this target had been already employed in the existing method \HavocMAB{} \cite{HavocMAB}. This was based on the observation that a fuzzer showed different performances with batch size set to different fixed values. However, we focus on this from another observation and perspective, which consequently differentiates \HavocMAB{} from our resultant optimization method.
Specifically, we found that the optimal batch size can vary depending on the length of the seed to be mutated; therefore, \OurMethodName{} considers the lengths of seeds when optimizing the batch size.

\noindent\textbf{Bandit algorithms suitable for fuzzing}\ \ We further conducted a comprehensive comparison of bandit algorithms and determined the most suitable one for our framework.
Although there are various types of bandit algorithms, the extent to which each type of algorithm works effectively with fuzzing has not been investigated in detail, possibly because the aforementioned heuristics have hindered the adoption of various algorithms.
Hence, we ran a thorough experiment to compare classical, non-stationary, and adversarial bandit algorithms by incorporating them into a fuzzer and measuring their performance.
We then found that the fuzzers with adversarial bandit algorithms performed worse than those with other algorithms in our mutation scheme.

With these key observations, as a proof of concept, we implemented \OurMethodName-AFL++ on top of AFL++ \cite{AFLpp} and measured its performance extensively on two benchmarks: FuzzBench~\cite{fuzzbench} and MAGMA~\cite{MAGMA}.
In every PUT, \OurMethodName-AFL++ achieved a higher code coverage than its baseline, AFL++, proving that it realizes PUT-agnostic optimization.
We also compared the performance improvement achieved by \OurMethodName{} with that of the existing online optimization methods.
In the comparison, we observed that \OurMethodName{} outperformed the others on average in the tested PUTs and that each optimization method provided various levels of improvement for different PUTs, which indicates the future potential of our approach by combining with them. 

Additionally, we ran \OurMethodName-AFL++ against several PUTs in OSS-Fuzz for seven days to determine whether it could find crashes and vulnerabilities in real-world programs.
As a result, \OurMethodName-AFL++ found 17 unique bugs, three of which were confirmed as previously undiscovered vulnerabilities and assigned CVE IDs.
We released \OurMethodName-AFL++ on \url{https://github.com/RICSecLab/SLOPTAFLpp}.
