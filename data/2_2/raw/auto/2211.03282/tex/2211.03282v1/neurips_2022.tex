\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2022


% ready for submission
% \usepackage[nonatbib, final]{neurips_2022}
\usepackage[nonatbib, final]{neurips_ts4h_2022}
% \usepackage{biblatex}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2022}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2022}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2022}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
% SELF ADDED STUFF ###########################
\usepackage{graphicx}
\usepackage{multirow}
% \usepackage{booktabs}
\usepackage{bm}
% \usepackage{amsfonts}
\usepackage{subcaption}
\usepackage{xspace}
\usepackage{enumitem}
\usepackage{bold-extra}
% \usepackage{lmodern}
\newcommand{\mnamebold}{\texttt{\textbf{NormIntSleep}}\xspace}
\newcommand{\mname}{\texttt{NormIntSleep}\xspace}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{float}
\usepackage{amsmath}


\newcommand{\ia}[1]{\textcolor{magenta}{\emph{[IA: #1]}}}
\newcommand{\todo}[1]{\textcolor{orange}{\emph{[TODO: #1]}}}
\newcommand{\cx}[1]{\textcolor{red}{\emph{[CM: #1]}}}

% SELF ADDED STUFF ###########################
% --------------------------------------------

\title{Performance and utility trade-off in interpretable sleep staging}
% Can interpretable methods outperform deep learning for sleep staging?}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
  Irfan Al-Hussaini\\%\thanks{Use footnote for providing further information
    % about author (webpage, alternative address)---\emph{not} for acknowledging
    % funding agencies.} \\
%   School of Electrical and Computer Engineering\\
  Georgia Institute of Technology\\
  Atlanta, GA \\
  \texttt{alhussaini.irfan@gatech.edu} \\
  % examples of more authors
   \And
  Cassie S. Mitchell\\%\thanks{Use footnote for providing further information
    % about author (webpage, alternative address)---\emph{not} for acknowledging
    % funding agencies.} \\
%   Department of Biomedical Engineering \\
  Georgia Institute of Technology\\
  Atlanta, GA \\
  \texttt{cassie.mitchell@bme.gatech.edu} \\
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}


\begin{document}


\maketitle


\begin{abstract}
Recent advances in deep learning have led to the development of models approaching human level of accuracy. However, healthcare remains an area lacking in widespread adoption. The safety-critical nature of healthcare results in a natural reticence to put these black-box deep learning models into practice. In this paper, we explore interpretable methods for a clinical decision support system, sleep staging, based on physiological signals such as EEG, EOG, and EMG. A recent work has shown sleep staging using simple models and an exhaustive set of features can perform nearly as well as deep learning approaches but only for certain datasets. Moreover, the utility of these features from a clinical standpoint is unclear. On the other hand, the proposed framework, \mname shows that by representing deep learning embeddings using normalized features, great performance can be obtained across different datasets. \mname performs 4.5\% better than the exhaustive feature-based approach and 1.5\% better than other representation learning approaches. An empirical comparison between the utility of the interpretations of these models highlights the improved alignment with clinical expectations when performance is traded-off slightly.

% The accuracy of recent deep learning based clinical decision support systems is promising. However, lack of model interpretability remains an obstacle to widespread adoption of artificial intelligence in healthcare. Using sleep as a case study, we propose a generalizable method to combine clinical interpretability with high accuracy derived from black-box deep learning.

% Clinician-determined sleep stages from polysomnogram (PSG) remain the gold standard for evaluating sleep quality. However, PSG manual annotation by experts is expensive and time-prohibitive. We propose \mname, \textit{interpretable Sleep staging using Embeddings, Rules, and Features} to read PSG. \mname provides interpretation of classified sleep stages through meaningful features derived from the AASM Manual for the Scoring of Sleep and Associated Events.

% In \mname, the embeddings obtained from a hybrid of convolutional and recurrent neural networks are transposed to the interpretable feature space. These representative interpretable features are used to train simple models like a shallow decision tree for classification. Model results are validated on two publicly available datasets. \mname surpasses the current state-of-the-art for interpretable sleep staging by 2\%. Using Gradient Boosted Trees as the classifier, SERF obtains 0.766 $\kappa$ and 0.870 AUC-ROC, within 2\% of the current state-of-the-art black-box models.
\end{abstract}


\section{Introduction}
There has been a steady accumulation of digital records of patient health data due to the increasingly widespread adoption of electronic health records \cite{jianxun2021electronic, adler2017hitech, jensen2012mining}. Breakthroughs in deep learning have leveraged this influx of clinical data to create increasingly complex and capable systems \cite{miotto2018deep, esteva2019guide, norgeot2019call}. However, the lack of interpretability and explainability of deep learning models prevents most of them from being used in practice because clinicians need to understand the explanation behind each classification to avoid noise and bias \cite{zitnik, elshawi2019interpretability, carvalho2019machine, holzinger2019causability, wiens2019no}. Although challenging to design due to the manual effort required, linear models paired with a robust set of features can provide a degree of interpretability \cite{linear}. However, linear models paired with complex features may result in models whose interpretation does not have clinical relevance. In this paper, using sleep staging as a case study, we take a deeper dive into the trade-off between clinical relevance of explanations and performance, and propose a model attempting to tackle this issue.

Around 70 million US adults are affected by sleep disorders  \cite{guglietta2015drug, holder2022common} such as insomnia, narcolepsy, or sleep apnea. The most crucial step for the diagnosis of sleep disorders is sleep staging \cite{RN50}. The gold standard for sleep staging remains manual annotation of Polysomnogram (PSG) by clinicians  \cite{guillot2020dreem}. During this process, clinicians inspect the PSG signals from multiple channels, and annotate each 30s segment with one of five sleep stages, i.e. wake, rapid eye movement (REM), and the non-REM stages N1, N2, and N3, by following guidelines stated in the American Academy of Sleep Medicine (AASM) Manual for the Scoring of Sleep and Associated Events \cite{RN4}. This manual annotation scheme is time-consuming and expensive because a clinician needs several hours to annotate a patient’s recordings from a single night \cite{ZHANG2022100371}.

There has been considerable research in automating sleep staging to overcome this. These approaches have mostly remained in the realm of deep learning that lack interpretability \cite{RN34}, for example convolutional neural networks (CNN) \cite{RN49, RN57, RN9, yang2021single}, recurrent neural networks (RNN) \cite{RN14, phan2019seqsleepnet}, recurrent convolutional neural networks (RCNN) \cite{RN6, RN62}, graph convolutional networks (GCN) \cite{li2022attention, jia2020graphsleepnet}, and attention \cite{qu2020residual, phan2022sleeptransformer, li2022attention}. On the other hand, the AASM sleep scoring manual guidelines \cite{RN4}, are interpretable for clinicians without providing the clear definitions needed to design a robust computational model \cite{al2019sleeper}. 


A recent study proposed a feature-based linear model \cite{linear} that performed as well as deep neural network models. However, the features used in this study were not designed considering clinical guidelines. In order to generate clinically relevant explanations, we propose \mname, a representation learning framework that projects deep neural network embeddings into an interpretable normalized feature space. Thus, by choosing an appropriate feature space, \mname can unite clinically relevant explanations with the high accuracy of a deep learning model.


% \end{itemize}


\section{Method}
\label{sec:method}
% \subsection{Data}
% \label{sec:data}
Two publicly available datasets are used for evaluation. These datasets are summarized in Table \ref{tab:dataset}.
\begin{table}[tb]
  \begin{minipage}{\linewidth}
    \centering
\caption[for LOF]{Datasets}
\resizebox{\linewidth}{!}{%
\begin{tabular}{lcccc}
\hline
                        & \begin{tabular}[c]{@{}c@{}}Number of \\ Subjects\end{tabular} & \begin{tabular}[c]{@{}c@{}}Sampling \\ Frequency (Hz)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Channel \\ Names\end{tabular} & \begin{tabular}[c]{@{}c@{}}Annotation \\ Schema\end{tabular} \\ \hline
ISRUC \cite{RN23}          & 100                                                                    & 200                                                                         & \begin{tabular}[c]{@{}c@{}}F3-A2, C3-A2, F4-A1, C4-A1, O1-A2,\\ O2-A1, ROC-A1, LOC-A2, Chin-EMG\end{tabular}                                                                      & AASM \cite{RN4} \\ %\hline
PhysioNet-EDFX \cite{physionet1, physionet2} & 197                                                                    & 100                                                                         & \begin{tabular}[c]{@{}c@{}}EEG Fpz-Cz, EEG Pz-Oz,\\ EOG horizontal, EMG submental\end{tabular}                                                                      & R\&K \cite{rk_1, rk_2}                       \\ \hline
\end{tabular}}
\label{tab:dataset}
\end{minipage}
\end{table}

\mname uses the PSG recordings, $\bm{X}$, to generate an interpretable representation for deep neural network embeddings using the following steps:
\begin{enumerate}[leftmargin=*]
\item A CNN-LSTM network \cite{serf} is trained end-to-end on sleep staging. The CNN is composed of 3 convolutional layers where each layer is followed by batch normalization, ReLU activation, and max pooling. The kernel sizes of the three layers are 201, 11, and 11, and the output channels are 256, 128, and 64. The CNN output is used as input for a layer of bi-directional Long Short-Term Memory (LSTM) cells with 256 hidden states. The resulting 512 hidden states represent the \textit{embedding space}, $\bm{E(X)}$. During model training, the LSTM output is connected to a fully connected layer with 5 outputs for the 5 sleep stages, and cross-entropy loss is used.
\item Features, $\bm{F(X)}$, are extracted from the dataset. There are two possible sets of features:
    \begin{itemize}[leftmargin=*]
        \item \textbf{FeatLong}: an exhaustive list of features inspired by the recent work of Van Der Donckt et al. \cite{linear}. The features are not designed considering clinical guidelines. It results in 2488 features for the ISRUC dataset and 1048 features for the Physionet dataset. 10\% of the most significant features are retained for the next steps using ANOVA, resulting in 249 features for the ISRUC dataset and 105 for the Physionet dataset.
        \item \textbf{FeatShort}: a smaller set of clinically interpretable features inspired by the recent work of Al-Hussaini et al. \cite{serf}. The features are designed according to AASM \cite{berry2012aasm}. 87 features are extracted for the ISRUC dataset and 38 for the Physionet dataset. 90\% of the most significant features are retained for the next steps using ANOVA, resulting in 78 features for the ISRUC dataset and 34 for the Physionet dataset.
    \end{itemize}
\item A linear transformation, $\bm{T}$, is learned from the embedding space to the feature space, $\bm{E(X)} \xrightarrow[]{\bm{T}} \bm{F(X)}$, using linear least squares regression with $L_2$ regularization. $\bm{E(X)} \bm{T}$ is then used to obtain a representation of the embedding in the interpretable feature space called $\bm{R}$. These representations of the embeddings are normalized before being used as input to classifiers.
    $$\bm{R'}=\frac{\bm{R}-\mu_R}{\sigma_R}$$
    where $\mu_R = \frac{\sum R}{N}$ and $\sigma_R = \sqrt{\frac{1}{N} \sum_{i=1}^N (R_i - \mu_R)^2}$.
    
    These normalized interpretable representations of the embeddings are used as inputs to simple classifiers such as logistic regression.
\end{enumerate}


\section{Experiments}
\label{sec:experiments}
% The experimental setup and implementation details are explained in Appendix \ref{app:exp}.
\subsection{Experimental setup}
\label{sec:setup}
The CNN-LSTM was trained using PyTorch 1.0 \cite{NEURIPS2019_bdbca288} using a batch size of 1000 samples from 1 PSG. The training was continued for 20 epochs with a learning rate of $10^{-4}$ using ADAM \cite{RN25} as the optimization method. The simple models were trained using scikit-learn \cite{RN44, cuml}, XGBoost \cite{xgboost}, and CatBoost \cite{catboost1, catboost2}. The features were extracted using scikit-learn \cite{RN44, cuml}, yasa \cite{yasa}, and tsflex \cite{vanderdonckt2021tsflex}. 
The data is randomly split by subjects into a training and test set in a 9:1 ratio with the same seed for each experiment. The training set is used for each dataset to fix model parameters, and the test set is used to obtain performance metrics. The same model hyperparameters and feature extraction schema are used to prevent overfitting and ensure consistent performance across different datasets.

\subsection{Baselines}
\begin{itemize}[leftmargin=*]
	\item CNN-LSTM: the model used to generate the embeddings %It serves as the performance upper bound for \mname.
% 	\item 1D-Convolutional Neural Network (1D-CNN): a black-box model proposed in \cite{al2019sleeper}.
	\item FeatLong and FeatShort: used as inputs to simple classifiers - CatBoost \cite{catboost1,catboost2}, XGBoost \cite{xgboost}, Logistic Regression, Gradient Boosted Trees
	\item SLEEPER \cite{al2019sleeper}: a prototype based interpretable sleep staging algorithm
	\item SERF \cite{serf}: an interpretable sleep staging algorithm based on embeddings, rules, and features
	\item U-Time \cite{RN57}: state-of-the-art deep learning model for sleep staging
% 	\item CatBoost \cite{catboost1,catboost2}, XGBoost \cite{xgboost}, Logistic Regression: models used on interpretable features
\end{itemize}
\subsection{Results}
\begin{table}[htb]
  \begin{minipage}{\linewidth}
    \centering
\caption[LOR]{Model Evaluation}%\footnote{XG: XGBoost, DT: Decision Tree, LR: Logistic Regression, GB: Gradient Boosted Trees}}
\label{tab:eval}
% \begin{tabular}{lcccccc}
\resizebox{\linewidth}{!}{%
\begin{tabular}{l@{\qquad}cc@{\qquad}cc@{\qquad}cc@{\qquad}c}
  \toprule
  \multirow{2}{*}{\raisebox{-\heavyrulewidth}{Model}} & \multicolumn{2}{c}{Accuracy}  & \multicolumn{2}{c}{Cohen's $\kappa$} & \multicolumn{2}{c}{F1 Score (Macro)} & \multirow{2}{*}{\raisebox{-\lightrulewidth}{\begin{tabular}[c]{@{}c@{}}Average\\Performance\end{tabular}}}\\
  \cmidrule{2-7}
                                           & Physionet       & ISRUC      & Physionet          & ISRUC         & Physionet     & ISRUC  &   \\
                                           \midrule
\mname-FeatLong-XGBoost         & 0.847           & 0.810      & 0.798              & 0.785         & 0.789         & 0.754     & 0.797                           \\
FeatLong-XGBoost \cite{linear}                & 0.836           & 0.750      & 0.777              & 0.712         & 0.773         & 0.675     & 0.754                           \\
\mname-FeatLong-CatBoost   & 0.846           & 0.815      & 0.793              & 0.788         & 0.787         & 0.760     & 0.798                           \\
FeatLong-CatBoost \cite{linear}         & 0.834           & 0.743      & 0.766              & 0.701         & 0.768         & 0.666     & 0.746                           \\
\underline{\mname-FeatLong-Logistic Regression}       & 0.855           & 0.807      & 0.801              & 0.783         & 0.800         & 0.748     & \underline{0.799}                           \\
FeatLong-Logistic Regression \cite{linear}               & 0.809           & 0.760      & 0.736              & 0.717         & 0.733         & 0.689     & 0.741                           \\
\mname-FeatShort-XGBoost        & 0.832           & 0.809      & 0.772              & 0.781         & 0.768         & 0.753     & 0.786                           \\
FeatShort-XGBoost               & 0.825           & 0.790      & 0.767              & 0.747         & 0.759         & 0.726     & 0.769                           \\
\mname-FeatShort-CatBoost  & 0.831           & 0.809      & 0.770              & 0.777         & 0.766         & 0.752     & 0.784                           \\
FeatShort-CatBoost         & 0.818           & 0.788      & 0.750              & 0.741         & 0.747         & 0.724     & 0.761                           \\
\underline{\mname-FeatShort-Logistic Regression}      & 0.855           & 0.797      & 0.799              & 0.774         & 0.800         & 0.735     & \underline{0.793}                           \\
% FeatShort-LR               & 0.722           & 0.717      & 0.634              & 0.621         & 0.603         & 0.625     & 0.654                           \\
SERF-XGBoost  \cite{serf}                  & 0.823           & 0.819      & 0.753              & 0.789         & 0.753         & 0.766     & 0.784                           \\
SERF-Logistic Regression  \cite{serf}                  & 0.829           & 0.795      & 0.759              & 0.773         & 0.762         & 0.733     & 0.775                           \\
SLEEPER-Gradient Boosted Trees  \cite{al2019sleeper}               & 0.807           & 0.797      & 0.721              & 0.756         & 0.729         & 0.736     & 0.758                           \\
\textbf{U-Time}  \cite{RN57}                   & 0.862           & 0.840      & 0.811              & 0.816         & 0.810         & 0.793     & \textbf{0.822}                           \\
CNN-LSTM  \cite{serf}                 & 0.864           & 0.831      & 0.815              & 0.819         & 0.813         & 0.783     & 0.821       \\
\bottomrule
\end{tabular}}
\end{minipage}
\end{table}

Accuracy, Macro F1-Score, and Cohen's $\kappa$ are used to evaluate the models. The results in Table \ref{tab:eval} were produced in the same experimental setup expanded upon in Section \ref{sec:setup}. Since the performance of models varies a lot between the two datasets, an aggregated metric, \textit{Average Performance} is calculated based on the average value of each model across the two datasets and three metrics. The best interpretable methods using FeatShort and FeatLong are underlined, and the best overall method is highlighted in bold. It shows that \mname surpasses all other interpretable methods even when using the smaller set of interpretable features, FeatShort. The benefits of using this over the exhaustive set of features, FeatLong, are discussed in Section \ref{sec:interpretability}.

\subsection{Interpretation and Clinical Relevance}
\label{sec:interpretability}


\begin{figure*}[htb]
    \centering
    \begin{subfigure}[b]{0.8\textwidth}
    {
        \centering
        \includegraphics[width=\textwidth, keepaspectratio]{figures/shap_importance_sim_xgboost_old.png}
        \caption{\mname-XGBoost-FeatShort}
        \label{fig:shap_sim_xgboost_old}
    }
    \end{subfigure}
    \begin{subfigure}[b]{0.8\textwidth}
    {
        \centering
        \includegraphics[width=\textwidth]{figures/shap_importance_sim_xgboost_imec.png}
        \caption{\mname-XGBoost-FeatLong}
        \label{fig:shap_sim_xgboost_imec}
    }
    \end{subfigure}
\caption{SHAP embedding representation importance using \mname on ISRUC Dataset}
\label{fig:shap_sim_main}
\end{figure*}


Figure \ref{fig:shap_sim_main} highlights the top 10 important dimensions of the interpretable representation of the \mname embeddings and their influence on the classification of the 5 sleep stages. N1 is a challenging sleep stage to classify, with around 50\% agreement among human annotators, so its classification is not discussed in detail. The differences between Figure \ref{fig:shap_sim_xgboost_old} and Figure \ref{fig:shap_sim_xgboost_imec} shows the importance of having clinically relevant representations. Looking at the top 3 representations in \mname-XGBoost-FeatShort (Figure \ref{fig:shap_sim_xgboost_old}): (1) Beta waves \cite{serf} are defined as waves with frequency between 8 Hz and 20 Hz. This frequency range is present in Wake \cite{beta}, REM \cite{beta}, and N2 (through sigma band in Spindles \cite{spindles_sigma}). So, it is the perfect attribute to differentiate N3 from the other stages. (2) Slow Waves are used to annotate N3 by clinicians \cite{beta, berry2012aasm}. (3) Deflections in EOG indicate blinks during wakefulness, so delta waves in ROC-A1 (an EOG channel) are appropriate for classifying wake. On the other hand, 6 of the top 10 representations in \mname-XGBoost-FeatLong (Figure \ref{fig:shap_sim_xgboost_imec}) are not clinically relevant and and the rest are derived from the same frequency band. Thus, the clinical relevance of \mname-XGBoost-FeatLong's interpretations is dubious.

The feature space of the two datasets using FeatLong and FeatShort are shown in Appendix \ref{app:feat_viz} and highlights the efficacy of FeatLong in segregating the Physionet dataset into the 5 classes. FeatLong and FeatShort feature importances are shown in Appendix \ref{app:feat_imp}. %Decision trees for some models are shown in Appendix \ref{app:tree}.


\section{Conclusion}
Interpretability is crucial for the adoption of clinical decision support systems. Complex features paired with a simple model can provide interpretation. However, those explanations might not be helpful if the features are not clinically meaningful. \mname provides a generic framework to leverage the most clinically significant features for classification with higher accuracy than complex feature-based models and nearly as accurate as black-box deep learning. As a result, the interpretations are clinically relevant. Thus \mname takes forward strides towards adoption.
\section*{Acknowledgment}
% This research was funded by NSF 1944247, NIH U19-AG056169, GT McCamish Award to C.M.
This research was funded by National Science Foundation CAREER grant 1944247 to C.M, National Institute of Health grant U19-AG056169 sub-award to C.M., and the McCamish Parkinson’s Disease Innovation Program at Georgia Institute of Technology and Emory University to C.M.


\bibliographystyle{unsrt}
\bibliography{refs}
\appendix
\clearpage
% \section*{Appendix} 
% \section{Appendix A: Experimental setup}
% \label{app:exp}
% % \subsection*{Implementation Details:} 
% The CNN-LSTM of \mname was trained using PyTorch 1.0 \cite{NEURIPS2019_bdbca288}. The simple models were trained using scikit-learn \cite{RN44, cuml}, XGBoost \cite{xgboost}, and CatBoost \cite{catboost1, catboost2}. The features were extracted using scikit-learn \cite{RN44, cuml}, yasa \cite{yasa}, and tsflex \cite{vanderdonckt2021tsflex}. A batch size of 1000 samples from 1 PSG was used to train the CNN-LSTM. The training was continued for 20 epochs with a learning rate of $10^{-4}$ using ADAM \cite{RN25} as the optimization method.
% The data is randomly split by subjects into a training and test set in a 9:1 ratio with the same seed for each experiment. For each dataset, the training set is used to fix model parameters, and the test set is used to obtain performance metrics. The same model hyperparameters and feature extraction schema are used to prevent overfitting and ensure consistent performance across different datasets.

% \subsection*{Metrics:}
% \begin{itemize}
%     \item Accuracy $=\frac{\left|\mathcal{Y}\cap\mathcal{Y}^\prime\right|}{N}$
%     \item Sensitivity, $S^{\left(k\right)}=\frac{\left|\mathcal{Y}^{\left(k\right)}\cap\mathcal{Y}^{\prime\left(k\right)}\right|}{\left|\mathcal{Y}^{\prime\left(k\right)}\right|}$\item Precision, $P^{\left(k\right)}=\frac{\left|\mathcal{Y}^{\left(k\right)}\cap\mathcal{Y}^{\prime\left(k\right)}\right|}{\left|\mathcal{Y}^{\left(k\right)}\right|}$ 
%     % \item ${F1}^{\left(k\right)}=\frac{2*p^{(k)}*S^{(k)}}{p^{(k)}+S^{(k)}}$
%     \item F1 score $=\frac{2\ \ast\ P\ \ast\ S}{P\ +\ S\ }$
%     \item Cohen's $\kappa=\frac{Acc-p_e}{1-p_e}$, where $p_e=\frac{1}{N^2}\sum_{k}^{5}\left|\mathcal{Y}^{\left(k\right)}\right|\left|\mathcal{Y}^{\prime\left(k\right)}\right|$
% \end{itemize}
\section{Appendix A: Feature Space Visualization} 
\label{app:feat_viz}
\begin{figure*}[htb]
    \centering
    \begin{subfigure}[b]{0.5\textwidth}
    {
        \centering
        \includegraphics[width=\textwidth, keepaspectratio]{figures/feat_tsne_phy_old.png}
        \caption{TSNE using FeatShort}
        \label{fig:tsne_less_physionet}
    }
    \end{subfigure}%
    \begin{subfigure}[b]{0.5\textwidth}
    {
        \centering
        \includegraphics[width=\textwidth]{figures/feat_tsne_phy_imec.png}
        \caption{TSNE using FeatLong}
        \label{fig:tsne_more_physionet}
    }
    \end{subfigure}
    \vspace{0.5em}
    \begin{subfigure}[b]{0.5\textwidth}
    {
        \centering
        \includegraphics[width=\textwidth, keepaspectratio]{figures/feat_umap_phy_old.png}
        \caption{UMAP using FeatShort}
        \label{fig:umap_less_physionet}
    }
    \end{subfigure}%
    \begin{subfigure}[b]{0.5\textwidth}
    {
        \centering
        \includegraphics[width=\textwidth]{figures/feat_umap_phy_imec.png}
        \caption{UMAP using FeatLong}
        \label{fig:umap_more_physionet}
    }
    \end{subfigure}
\caption{Dimensionality reduction on the physionet dataset: shows distinct clusters for classes using FeatLong}
\label{fig:dim_red_physionet}
\end{figure*}

\clearpage
% \section*{Appendix B. Feature Selected from ISRUC Dataset} 
\begin{figure*}[htb]
    \centering
    \begin{subfigure}[b]{0.5\textwidth}
    {
        \centering
        \includegraphics[width=\textwidth, keepaspectratio]{figures/feat_tsne_old.png}
        \caption{TSNE using FeatShort}
        \label{fig:tsne_less}
    }
    \end{subfigure}%
    \begin{subfigure}[b]{0.5\textwidth}
    {
        \centering
        \includegraphics[width=\textwidth]{figures/feat_tsne_imec.png}
        \caption{TSNE using FeatLong}
        \label{fig:tsne_more}
    }
    \end{subfigure}
    \vspace{0.5em}
    \begin{subfigure}[b]{0.5\textwidth}
    {
        \centering
        \includegraphics[width=\textwidth, keepaspectratio]{figures/feat_umap_old.png}
        \caption{UMAP using FeatShort}
        \label{fig:umap_less}
    }
    \end{subfigure}%
    \begin{subfigure}[b]{0.5\textwidth}
    {
        \centering
        \includegraphics[width=\textwidth]{figures/feat_umap_imec.png}
        \caption{UMAP using FeatLong}
        \label{fig:umap_more}
    }
    \end{subfigure}
\caption{Dimensionality reduction on the ISRUC dataset}
\label{fig:dim_red}
\end{figure*}
\clearpage
\section{Appendix B. SHAP Feature Importance} 
\label{app:feat_imp}
% \begin{figure*}[htb]
%     \centering
%     \begin{subfigure}[b]{0.9\textwidth}
%     {
%         \centering
%         \includegraphics[width=\textwidth, keepaspectratio]{figures/shap_importance_sim_xgboost.png}
%         \caption{\mname-XGBoost-FeatShort}
%         \label{fig:shap_sim_xgboost_old}
%     }
%     \end{subfigure}
%     \begin{subfigure}[b]{1\textwidth}
%     {
%         \centering
%         \includegraphics[width=\textwidth]{figures/shap_importance_sim_xgboost_imec.png}
%         \caption{\mname-XGBoost-FeatLong}
%         \label{fig:shap_sim_xgboost_imec}
%     }
%     \end{subfigure}
% \caption{SHAP feature importance using \mname on ISRUC Dataset}
% \label{fig:shap_sim}
% \end{figure*}


\begin{figure*}[htb]
    \centering
    \begin{subfigure}[b]{0.9\textwidth}
    {
        \centering
        \includegraphics[width=\textwidth, keepaspectratio]{figures/shap_importance_feat_xgboost_old.png}
        \caption{XGBoost-FeatShort}
        \label{fig:shap_feat_xgboost_old}
    }
    \end{subfigure}
    \begin{subfigure}[b]{0.9\textwidth}
    {
        \centering
        \includegraphics[width=\textwidth]{figures/shap_importance_feat_xgboost_imec.png}
        \caption{XGBoost-FeatLong}
        \label{fig:shap_feat_xgboost_imec}
    }
    \end{subfigure}
\caption{SHAP feature importance using feature-based models on ISRUC Dataset}
\label{fig:shap_feat}
\end{figure*}
% \clearpage
% \section{Appendix D. Decision Tree} 
% \label{app:tree}

% \begin{figure*}[htb]
%     \centering
%     \begin{subfigure}[b]{1\textwidth}
%     {
%         \centering
%         \includegraphics[width=\textwidth, keepaspectratio]{figures/isruc_sim_tree_visualized_old.png}
%         \caption{\mname-DT-FeatShort}
%         \label{fig:dt_sim_old}
%     }
%     \end{subfigure}
%     \begin{subfigure}[b]{1\textwidth}
%     {
%         \centering
%         \includegraphics[width=\textwidth]{figures/isruc_sim_tree_visualized_imec.png}
%         \caption{\mname-DT-FeatLong}
%         \label{fig:dt_sim_imec}
%     }
%     \end{subfigure}
% \caption{Decision tree using \mname}
% \label{fig:shap_sim}
% \end{figure*}
% \clearpage

% \begin{figure*}[htb]
%     \centering
%     \begin{subfigure}[b]{1\textwidth}
%     {
%         \centering
%         \includegraphics[width=\textwidth, keepaspectratio]{figures/isruc_feat_tree_visualized_old.png}
%         \caption{DT-FeatShort}
%         \label{fig:shap_feat_xgboost_old}
%     }
%     \end{subfigure}
%     \begin{subfigure}[b]{1\textwidth}
%     {
%         \centering
%         \includegraphics[width=\textwidth]{figures/isruc_feat_tree_visualized_imec.png}
%         \caption{DT-FeatLong}
%         \label{fig:shap_feat_xgboost_imec}
%     }
%     \end{subfigure}
% \caption{Decision tree using features}
% \label{fig:shap_feat}
% \end{figure*}

\end{document}