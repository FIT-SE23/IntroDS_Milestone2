% Encoding: windows-1252

 
 @ARTICLE{8425660,  author={Vaswani, Namrata and Chi, Yuejie and Bouwmans, Thierry},  journal={Proceedings of the IEEE},   title={Rethinking PCA for Modern Data Sets: Theory, Algorithms, and Applications [Scanning the Issue]},   year={2018},  volume={106},  number={8},  pages={1274-1276},  doi={10.1109/JPROC.2018.2853498}}
 
 @ARTICLE{8425659,  author={Bouwmans, Thierry and Javed, Sajid and Zhang, Hongyang and Lin, Zhouchen and Otazo, Ricardo},  journal={Proceedings of the IEEE},   title={On the Applications of Robust PCA in Image and Video Processing},   year={2018},  volume={106},  number={8},  pages={1427-1457},  doi={10.1109/JPROC.2018.2853589}}
 
 @article{monga2021algorithm,
  title={Algorithm unrolling: Interpretable, efficient deep learning for signal and image processing},
  author={Monga, Vishal and Li, Yuelong and Eldar, Yonina C},
  journal={IEEE Signal Processing Magazine},
  volume={38},
  number={2},
  pages={18--44},
  year={2021},
  publisher={IEEE}
}
 
 
 
 @article{cai2021learned,
  title={Learned robust pca: A scalable deep unfolding approach for high-dimensional outlier detection},
  author={Cai, HanQin and Liu, Jialin and Yin, Wotao},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={16977--16989},
  year={2021}
}
 
 @article{MAL-016,
url = {http://dx.doi.org/10.1561/2200000016},
year = {2011},
volume = {3},
journal = {Foundations and Trends® in Machine Learning},
title = {Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers},
doi = {10.1561/2200000016},
issn = {1935-8237},
number = {1},
pages = {1-122},
author = {Stephen Boyd and Neal Parikh and Eric Chu and Borja Peleato and Jonathan Eckstein}
}
 
 
 @ARTICLE{7740039,  author={Sun, Pengfei and Qin, Jun},  journal={IEEE Signal Processing Letters},   title={Low-Rank and Sparsity Analysis Applied to Speech Enhancement Via Online Estimated Dictionary},   year={2016},  volume={23},  number={12},  pages={1862-1866},  doi={10.1109/LSP.2016.2627029}}
 
 
 @book{Wright-Ma-2022,
author = {John Wright and Yi Ma},
title = {High-Dimensional Data Analysis with Low-Dimensional Models: Principles, Computation, and Applications},
publisher = {Cambridge University Press},
year = {2022}
}
 
 @ARTICLE{7396944,  author={Yang, Yehui and Hu, Wenrui and Xie, Yuan and Zhang, Wensheng and Zhang, Tianzhu},  journal={IEEE Transactions on Cybernetics},   title={Temporal Restricted Visual Tracking Via Reverse-Low-Rank Sparse Learning},   year={2017},  volume={47},  number={2},  pages={485-498},  doi={10.1109/TCYB.2016.2519532}}
 
 
 @article{DBLP:journals/tcyb/ZhouLBY18,
  author    = {Tao Zhou and
               Fanghui Liu and
               Harish Bhaskar and
               Jie Yang},
  title     = {Robust Visual Tracking via Online Discriminative and Low-Rank Dictionary
               Learning},
  journal   = {{IEEE} Trans. Cybern.},
  volume    = {48},
  number    = {9},
  pages     = {2643--2655},
  year      = {2018},
  url       = {https://doi.org/10.1109/TCYB.2017.2747998},
  doi       = {10.1109/TCYB.2017.2747998},
  timestamp = {Mon, 10 May 2021 16:29:16 +0200},
  biburl    = {https://dblp.org/rec/journals/tcyb/ZhouLBY18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
 
 @ARTICLE{8353378,  author={Van Luong, Huynh and Deligiannis, Nikos and Seiler, Jürgen and Forchhammer, Søren and Kaup, André},  journal={IEEE Transactions on Image Processing},   title={Compressive Online Robust Principal Component Analysis via  $n$ - $\ell_1$  Minimization},   year={2018},  volume={27},  number={9},  pages={4314-4329},  doi={10.1109/TIP.2018.2831915}}
 
 @ARTICLE{7036101,  author={Zhang, Tianzhu and Ghanem, Bernard and Liu, Si and Xu, Changsheng and Ahuja, Narendra},  journal={IEEE Transactions on Cybernetics},   title={Robust Visual Tracking via Exclusive Context Modeling},   year={2016},  volume={46},  number={1},  pages={51-63},  doi={10.1109/TCYB.2015.2393307}}
 
 
 @article{shlezinger2022model,
  title={Model-Based Deep Learning: On the Intersection of Deep Learning and Optimization},
  author={Shlezinger, Nir and Eldar, Yonina C and Boyd, Stephen P},
  journal={arXiv preprint arXiv:2205.02640},
  year={2022}
}
 
 
 @article{BOUWMANS20171,
title = {Decomposition into low-rank plus additive matrices for background/foreground separation: A review for a comparative evaluation with a large-scale dataset},
journal = {Computer Science Review},
volume = {23},
pages = {1-71},
year = {2017},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2016.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1574013715300459},
author = {Thierry Bouwmans and Andrews Sobral and Sajid Javed and Soon Ki Jung and El-Hadi Zahzah},
keywords = {Background subtraction, Foreground detection, Robust Principal Component Analysis, Robust Non-negative Matrix Factorization, Robust Matrix Completion, Subspace Tracking, Low Rank Minimization},
abstract = {Background/foreground separation is the first step in video surveillance system to detect moving objects. Recent research on problem formulations based on decomposition into low-rank plus sparse matrices shows a suitable framework to separate moving objects from the background. The most representative problem formulation is the Robust Principal Component Analysis (RPCA) solved via Principal Component Pursuit (PCP) which decomposes a data matrix into a low-rank matrix and a sparse matrix. However, similar robust implicit or explicit decompositions can be made in the following problem formulations: Robust Non-negative Matrix Factorization (RNMF), Robust Matrix Completion (RMC), Robust Subspace Recovery (RSR), Robust Subspace Tracking (RST) and Robust Low-Rank Minimization (RLRM). The main goal of these similar problem formulations is to obtain explicitly or implicitly a decomposition into low-rank matrix plus additive matrices. These formulation problems differ from the implicit or explicit decomposition, the loss function, the optimization problem and the solvers. As the problem formulation can be NP-hard in its original formulation, and it can be convex or not following the constraints and the loss functions used, the key challenges concern the design of efficient relaxed models and solvers which have to be with iterations as few as possible, and as efficient as possible. In the application of background/foreground separation, constraints inherent to the specificities of the background and the foreground as the temporal and spatial properties need to be taken into account in the design of the problem formulation. Practically, the background sequence is then modeled by a low-rank subspace that can gradually change over time, while the moving foreground objects constitute the correlated sparse outliers. Although, many efforts have been made to develop methods for the decomposition into low-rank plus additive matrices that perform visually well in foreground detection with reducing their computational cost, no algorithm today seems to emerge and to be able to simultaneously address all the key challenges that accompany real-world videos. This is due, in part, to the absence of a rigorous quantitative evaluation with synthetic and realistic large-scale dataset with accurate ground truth providing a balanced coverage of the range of challenges present in the real world. In this context, this work aims to initiate a rigorous and comprehensive review of the similar problem formulations in robust subspace learning and tracking based on decomposition into low-rank plus additive matrices for testing and ranking existing algorithms for background/foreground separation. For this, we first provide a preliminary review of the recent developments in the different problem formulations which allows us to define a unified view that we called Decomposition into Low-rank plus Additive Matrices (DLAM). Then, we examine carefully each method in each robust subspace learning/tracking frameworks with their decomposition, their loss functions, their optimization problem and their solvers. Furthermore, we investigate if incremental algorithms and real-time implementations can be achieved for background/foreground separation. Finally, experimental results on a large-scale dataset called Background Models Challenge (BMC 2012) show the comparative performance of 32 different robust subspace learning/tracking methods.}
}
 
 @ARTICLE{8017547,
  author={Javed, Sajid and Mahmood, Arif and Bouwmans, Thierry and Jung, Soon Ki},
  journal={IEEE Transactions on Image Processing}, 
  title={Background–Foreground Modeling Based on Spatiotemporal Sparse Subspace Clustering}, 
  year={2017},
  volume={26},
  number={12},
  pages={5840-5854},
  doi={10.1109/TIP.2017.2746268}}
  
  @inproceedings{10.5555/3045118.3045209,
author = {Srivastava, Nitish and Mansimov, Elman and Salakhutdinov, Ruslan},
title = {Unsupervised Learning of Video Representations Using LSTMs},
year = {2015},
publisher = {JMLR.org},
abstract = {We use Long Short Term Memory (LSTM) networks to learn representations of video sequences. Our model uses an encoder LSTM to map an input sequence into a fixed length representation. This representation is decoded using single or multiple decoder LSTMs to perform different tasks, such as reconstructing the input sequence, or predicting the future sequence. We experiment with two kinds of input sequences - patches of image pixels and high-level representations ("percepts") of video frames extracted using a pretrained convolutional net. We explore different design choices such as whether the decoder LSTMs should condition on the generated output. We analyze the outputs of the model qualitatively to see how well the model can extrapolate the learned video representation into the future and into the past. We further evaluate the representations by finetuning them for a supervised learning problem - human action recognition on the UCF-101 and HMDB-51 datasets. We show that the representations help improve classification accuracy, especially when there are only few training examples. Even models pretrained on unrelated datasets (300 hours of YouTube videos) can help action recognition performance.},
booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
pages = {843–852},
numpages = {10},
location = {Lille, France},
series = {ICML'15}
}
  

 
@ARTICLE{9906418,  author={Imran, Shoaib and Tahir, Muhammad and Khalid, Zubair and Uppal, Momin},  journal={IEEE Signal Processing Letters},   title={A Deep Unfolded Prior-Aided RPCA Network for Cloud Removal},   year={2022},  volume={29},  number={},  pages={2048-2052},  doi={10.1109/LSP.2022.3211189}}
 
 
 @inproceedings{Lin2009FastCO,
  title={Fast Convex Optimization Algorithms for Exact Recovery of a Corrupted Low-Rank Matrix},
  author={Zhouchen Lin and Arvind Ganesh and John Wright and Leqin Wu and Minming Chen and Yi Ma},
  year={2009}
}


@article{Luong2021ADR,
  title={A Deep-Unfolded Reference-Based RPCA Network For Video Foreground-Background Separation},
  author={Huynh Van Luong and B. Joukovsky and Yonina C. Eldar and N. Deligiannis},
  journal={2020 28th European Signal Processing Conference (EUSIPCO)},
  year={2021},
  pages={1432-1436}
}

@article{articleo,
author = {Lin, Zhouchen and Chen, Minming and Ma, Yi},
year = {2010},
month = {09},
pages = {},
title = {The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices},
volume = {9},
journal = {Mathematical Programming}
}

@article{article4,
author = {Yuan, Xiaoming and Yang, Junfeng},
year = {2009},
month = {01},
pages = {},
title = {Sparse and low rank matrix decomposition via alternating direction method},
volume = {9},
journal = {Pacific Journal of Optimization}
}
 
 
 @inproceedings{NIPS2013_8f121ce0,
 author = {Feng, Jiashi and Xu, Huan and Yan, Shuicheng},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Online Robust PCA via Stochastic Optimization},
 url = {https://proceedings.neurips.cc/paper/2013/file/8f121ce07d74717e0b1f21d122e04521-Paper.pdf},
 volume = {26},
 year = {2013}
}

@article{article,
author = {LeCun, Yann and Bengio, Y. and Hinton, Geoffrey},
year = {2015},
month = {05},
pages = {436-44},
title = {Deep Learning},
volume = {521},
journal = {Nature},
doi = {10.1038/nature14539}
}

@inproceedings{10.5555/3104322.3104374,
author = {Gregor, Karol and LeCun, Yann},
title = {Learning Fast Approximations of Sparse Coding},
year = {2010},
isbn = {9781605589077},
publisher = {Omnipress},
address = {Madison, WI, USA},
abstract = {In Sparse Coding (SC), input vectors are reconstructed using a sparse linear combination of basis vectors. SC has become a popular method for extracting features from data. For a given input, SC minimizes a quadratic reconstruction error with an L1 penalty term on the code. The process is often too slow for applications such as real-time pattern recognition. We proposed two versions of a very fast algorithm that produces approximate estimates of the sparse code that can be used to compute good visual features, or to initialize exact iterative algorithms. The main idea is to train a non-linear, feed-forward predictor with a specific architecture and a fixed depth to produce the best possible approximation of the sparse code. A version of the method, which can be seen as a trainable version of Li and Osher's coordinate descent method, is shown to produce approximate solutions with 10 times less computation than Li and Os-her's for the same approximation error. Unlike previous proposals for sparse code predictors, the system allows a kind of approximate "explaining away" to take place during inference. The resulting predictor is differentiable and can be included into globally-trained recognition systems.},
booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
pages = {399–406},
numpages = {8},
location = {Haifa, Israel},
series = {ICML'10}
}


 @ARTICLE{6879577,  author={Slavakis, Konstantinos and Giannakis, Georgios B. and Mateos, Gonzalo},  journal={IEEE Signal Processing Magazine},   title={Modeling and Optimization for Big Data Analytics: (Statistical) learning tools for our era of data deluge},   year={2014},  volume={31},  number={5},  pages={18-31},  doi={10.1109/MSP.2014.2327238}}
 
 
 @ARTICLE{9264716,  author={Khalilian-Gourtani, Amirhossein and Minaee, Shervin and Wang, Yao},  journal={IEEE Open Journal of Signal Processing},   title={Masked-RPCA: Moving Object Detection With an Overlaying Model},   year={2020},  volume={1},  number={},  pages={274-286},  doi={10.1109/OJSP.2020.3039325}}

@article{ZHU2015269,
title = {Improvement and expansion of the Fmask algorithm: cloud, cloud shadow, and snow detection for Landsats 4–7, 8, and Sentinel 2 images},
journal = {Remote Sensing of Environment},
volume = {159},
pages = {269-277},
year = {2015},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2014.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S0034425714005069},
author = {Zhe Zhu and Shixiong Wang and Curtis E. Woodcock},
keywords = {Fmask, Cloud, Cloud shadow, Snow, Landsat, Sentinel, Cirrus},
abstract = {Identification of clouds, cloud shadows and snow in optical images is often a necessary step toward their use. Recently a new program (named Fmask) designed to accomplish these tasks was introduced for use with images from Landsats 4–7 (Zhu & Woodcock, 2012). In this paper, there are the following: (1) improvements in the Fmask algorithm for Landsats 4–7; (2) a new version for use with Landsat 8 that takes advantage of the new cirrus band; and (3) a prototype algorithm for Sentinel 2 images. Though Sentinel 2 images do not have a thermal band to help with cloud detection, the new cirrus band is found to be useful for detecting clouds, especially for thin cirrus clouds. By adding a new cirrus cloud probability and removing the steps that use the thermal band, the Sentinel 2 scenario achieves significantly better results than the Landsats 4–7 scenario for all 7 images tested. For Landsat 8, almost all the Fmask algorithm components are the same as for Landsats 4–7, except a new cirrus cloud probability is calculated using the new cirrus band, which improves detection of thin cirrus clouds. Landsat 8 results are better than the Sentinel 2 scenario, with 6 out of 7 test images showing higher accuracies.}}

@inproceedings{10.1117/12.2023359,
author = {Ricardo Otazo and Daniel K. Sodickson and Emmanuel J. Candès},
title = {{Low-rank + sparse (L+S) reconstruction for accelerated dynamic MRI with seperation of background and dynamic components}},
volume = {8858},
booktitle = {Wavelets and Sparsity XV},
editor = {Dimitri Van De Ville and Vivek K. Goyal and Manos Papadakis},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {535 -- 542},
keywords = {compressed sensing, low-rank matrix completion, magnetic resonance imaging},
year = {2013},
doi = {10.1117/12.2023359},
URL = {https://doi.org/10.1117/12.2023359}
}

@book{book,
author = {Boyd, Stephen},
year = {2010},
month = {01},
pages = {},
title = {Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers},
isbn = {9781601984616},
doi = {10.1561/9781601984616}
}



@ARTICLE{6733349,  author={Tan, Zhao and Eldar, Yonina C. and Beck, Amir and Nehorai, Arye},  journal={IEEE Transactions on Signal Processing},   title={Smoothing and Decomposition for Analysis Sparse Recovery},   year={2014},  volume={62},  number={7},  pages={1762-1774},  doi={10.1109/TSP.2014.2304932}}

@article{10.1145/1970392.1970395,
author = {Cand\`{e}s, Emmanuel J. and Li, Xiaodong and Ma, Yi and Wright, John},
title = {Robust Principal Component Analysis?},
year = {2011},
issue_date = {May 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {58},
number = {3},
issn = {0004-5411},
url = {https://doi.org/10.1145/1970392.1970395},
doi = {10.1145/1970392.1970395},
abstract = {This article is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individually? We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the ℓ1 norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this optimization problem, and present applications in the area of video surveillance, where our methodology allows for the detection of objects in a cluttered background, and in the area of face recognition, where it offers a principled way of removing shadows and specularities in images of faces.},
journal = {J. ACM},
month = {Jun},
articleno = {11},
numpages = {37},
keywords = {ℓ1-norm minimization, nuclear-norm minimization, low-rank matrices, video surveillance, sparsity, duality, robustness vis-a-vis outliers, Principal components}
}

@inproceedings{NIPS2011_18997733,
 author = {Lin, Zhouchen and Liu, Risheng and Su, Zhixun},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Linearized Alternating Direction Method with Adaptive Penalty for Low-Rank Representation},
 url = {https://proceedings.neurips.cc/paper/2011/file/18997733ec258a9fcaf239cc55d53363-Paper.pdf},
 volume = {24},
 year = {2011}
}









@INPROCEEDINGS{7878153,  author={Zhu, Cheng and Zhao, Zhiqin and Zhu, Xiaozhang and Nie, Zaiping and Liu, Qing Huo},  booktitle={2016 IEEE 13th International Conference on Signal Processing (ICSP)},   title={Cloud removal for optical images using SAR structure data},   year={2016},  volume={},  number={},  pages={1872-1875},  doi={10.1109/ICSP.2016.7878153}}


@ARTICLE{7924312,  author={Cheng, Qing and Shen, Huanfeng and Zhang, Liangpei and Peng, Zhenghong},  journal={IEEE Signal Processing Letters},   title={Missing Information Reconstruction for Single Remote Sensing Images Using Structure-Preserving Global Optimization},   year={2017},  volume={24},  number={8},  pages={1163-1167},  doi={10.1109/LSP.2017.2703092}}

@inproceedings{10.5555/3104482.3104487,
author = {Zhou, Tianyi and Tao, Dacheng},
title = {GoDec: Randomized Low-Rank \& Sparse Matrix Decomposition in Noisy Case},
year = {2011},
isbn = {9781450306195},
publisher = {Omnipress},
address = {Madison, WI, USA},
abstract = {Low-rank and sparse structures have been profoundly studied in matrix completion and compressed sensing. In this paper, we develop "Go Decomposition" (GoDec) to efficiently and robustly estimate the low-rank part L and the sparse part S of a matrix X = L + S + G with noise G. GoDec alternatively assigns the low-rank approximation of X - S to L and the sparse approximation of X - L to S. The algorithm can be significantly accelerated by bilateral random projections (BRP). We also propose GoDec for matrix completion as an important variant. We prove that the objective value ||X - L - S||2F converges to a local minimum, while L and S linearly converge to local optimums. Theoretically, we analyze the influence of L, S and G to the asymptotic/convergence speeds in order to discover the robustness of GoDec. Empirical studies suggest the efficiency, robustness and effectiveness of GoDec comparing with representative matrix decomposition and completion tools, e.g., Robust PCA and OptSpace.},
booktitle = {Proceedings of the 28th International Conference on International Conference on Machine Learning},
pages = {33–40},
numpages = {8},
location = {Bellevue, Washington, USA},
series = {ICML'11}
}

@inproceedings{23e9f9c991e1472ea92d70770927d189,
title = "GEWEX cloud assessment: A review",
abstract = "Clouds cover about 70\% of the Earth's surface and play a dominant role in the energy and water cycle of our planet. Only satellite observations provide a continuous survey of the state of the atmosphere over the entire globe and across the wide range of spatial and temporal scales that comprise weather and climate variability. Satellite cloud data records now exceed more than 25 years; however, climatologies compiled from different satellite datasets can exhibit systematic biases. Questions therefore arise as to the accuracy and limitations of the various sensors. The Global Energy and Water cycle Experiment (GEWEX) Cloud Assessment, initiated in 2005 by the GEWEX Radiation Panel, provides the first coordinated intercomparison of publicly available, global cloud products (gridded, monthly statistics) retrieved from measurements of multi-spectral imagers (some with multi-angle view and polarization capabilities), IR sounders and lidar. Cloud properties under study include cloud amount, cloud height (in terms of pressure, temperature or altitude), cloud radiative properties (optical depth or emissivity), cloud thermodynamic phase and bulk microphysical properties (effective particle size and water path). Differences in average cloud properties, especially in the amount of high-level clouds, are mostly explained by the inherent instrument measurement capability for detecting and/or identifying optically thin cirrus, especially when overlying low-level clouds. The study of long-term variations with these datasets requires consideration of many factors. The monthly, gridded database presented here facilitates further assessments, climate studies, and the evaluation of climate models.",
keywords = "Climate data record, Cloud properties, Satellite observations",
author = "Claudia Stubenrauch and Rossow, {William B.} and Stefan Kinne and Steve Ackerman",
year = "2013",
doi = "10.1063/1.4804792",
language = "English (US)",
isbn = "9780735411555",
series = "AIP Conference Proceedings",
pages = "404--407",
booktitle = "Radiation Processes in the Atmosphere and Ocean, IRS 2012 - Proceedings of the International Radiation Symposium (IRC/IAMAS)"
}

@ARTICLE{9224941,  author={Zheng, Jiahao and Liu, Xiao-Yang and Wang, Xiaodong},  journal={IEEE Transactions on Geoscience and Remote Sensing},   title={Single Image Cloud Removal Using U-Net and Generative Adversarial Networks},   year={2021},  volume={59},  number={8},  pages={6371-6385},  doi={10.1109/TGRS.2020.3027819}}

@article{TSENG2008584,
title = {Automatic cloud removal from multi-temporal SPOT images},
journal = {Applied Mathematics and Computation},
volume = {205},
number = {2},
pages = {584-600},
year = {2008},
note = {Special Issue on Advanced Intelligent Computing Theory and Methodology in Applied Mathematics and Computation},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2008.05.050},
url = {https://www.sciencedirect.com/science/article/pii/S0096300308003378},
author = {Din-Chang Tseng and Hsiao-Ting Tseng and Chun-Liang Chien},
keywords = {Cloud removal, Multi-temporal satellite images, Image mosaicking, Image fusion, Linear spectral unmixing, Wavelet transform},
abstract = {Partial cloud cover is a severe problem in the optical remote sensing images. The problem can be mostly overcome by mosaicking the cloud-free areas of the multi-temporal images. In this paper, multidisciplinary methods are proposed to generate cloud-free mosaic images from multi-temporal SPOT images in three steps. At first, the original images are enhanced in both brightness and chromaticity. Secondly, the linear spectral unmixing method (LSU) is used to extract all cloud cover regions. Then, we choose the base image that has the least thin-cloud cover and divide the base image into grid zones. We find the thin-cloud and cloud-shadow zones in the eight neighbors of the thick-cloud zones based on the relative locations and the sun elevation angle. At last, the cloud and cloud-shadow zones of the base image are replaced by the same-location cloud-free zones on other images. Between each two zones of the base image and the replacing image, we create a transition zone. The multiscale wavelet-based fusion method is then used to fuse the pixels in the zones to generate cloud-free satellite images. Based on our complete and sophisticated approach, the high-quality fused results are produced from the source images that have variant brightness.}
}

@ARTICLE{8675771,  author={Zhang, Yongjun and Wen, Fei and Gao, Zhi and Ling, Xiao},  journal={IEEE Transactions on Geoscience and Remote Sensing},   title={A Coarse-to-Fine Framework for Cloud Removal in Remote Sensing Image Sequence},   year={2019},  volume={57},  number={8},  pages={5963-5974},  doi={10.1109/TGRS.2019.2903594}}


@inproceedings{inproceedings_o,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}


@ARTICLE{8836615,  author={Solomon, Oren and Cohen, Regev and Zhang, Yi and Yang, Yi and He, Qiong and Luo, Jianwen and van Sloun, Ruud J. G. and Eldar, Yonina C.},  journal={IEEE Transactions on Medical Imaging},   title={Deep Unfolded Robust PCA With Application to Clutter Suppression in Ultrasound},   year={2020},  volume={39},  number={4},  pages={1051-1063},  doi={10.1109/TMI.2019.2941271}}


@article{doi:10.1137/080716542,
author = {Beck, Amir and Teboulle, Marc},
title = {A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems},
journal = {SIAM Journal on Imaging Sciences},
volume = {2},
number = {1},
pages = {183-202},
year = {2009},
doi = {10.1137/080716542},
URL = { https://doi.org/10.1137/080716542},
eprint = {https://doi.org/10.1137/080716542}}


@article{doi:10.1137/080738970,
author = {Cai, Jian-Feng and Candès, Emmanuel J. and Shen, Zuowei},
title = {A Singular Value Thresholding Algorithm for Matrix Completion},
journal = {SIAM Journal on Optimization},
volume = {20},
number = {4},
pages = {1956-1982},
year = {2010},
doi = {10.1137/080738970},

URL = { 
        https://doi.org/10.1137/080738970
    
},
eprint = { 
        https://doi.org/10.1137/080738970
    
}

}



@Comment{jabref-meta: databaseType:bibtex;}
