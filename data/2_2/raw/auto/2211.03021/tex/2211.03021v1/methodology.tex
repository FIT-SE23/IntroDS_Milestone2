\section{Methodology}

\subsection{GNN Models}

To evaluate the performance of two popular GNN frameworks -- DGL~\cite{wang2019deep} and PyG~\cite{FeyLenssen2019}, we first consider several convolutional layers, which are key components of GNNs. We then consider three representative sampling-based GNNs, namely GraphSAGE~\cite{hamilton2017inductive}, ClusterGCN~\cite{chiang2019cluster}, and GraphSAINT~\cite{zeng2019graphsaint}, implemented in DGL and PyG.

\subsection{Datasets}
We focus on supervised node classification tasks in this work. To this end, we consider six popular real-world graph datsets, each of whose description and statistics are provided in Table~\ref{table:dataset}. See ~\cite{zeng2019graphsaint} and~\cite{hu2020open} for more details on the datasets. As for how to split each dataset for training, validation, and testing, we follow the common way in the GNN benchmark literature, which is to use `ﬁxed partitions' given by the original authors. The details are reported in the `Train/Val/Test' column of Table~\ref{table:dataset}.


\subsection{Hardware and Software Configuration}

For hardware, all experiments are conducted on a Linux server equipped with Dual Intel Xeon Silver 4114 CPUs @ 2.2GHz with 64GB RAM, and an NVIDIA Quadro RTX 8000 GPU with 48GB memory.

For software, we use Python 3.8, PyTorch v1.11.0, DGL v0.8.2, and PyG v2.0.4. All GNN models were implemented based on the official examples provided by DGL with PyTorch backend and PyG. To match the implementations in both frameworks for a fair comparison, we set the same values of the hyperparameters of samplers, convolutional layers, and other components of GNN models as long as both frameworks provide the same functional APIs. We use the default settings as provided by the frameworks otherwise. Our code is available on GitHub.\footnote{\url{https://github.com/xhuang2016/GNN-Benchmark}.}

Our main focus in this work is to evaluate the efficiency of the GNN frameworks in runtime and energy/power consumption. Note that we here do not consider the accuracy of each GNN model as there is no clear difference between the frameworks~\cite{wang2019deep, FeyLenssen2019, wu2021performance}. We use \texttt{pyinstrument}\footnote{\url{https://github.com/joerick/pyinstrument}.} to measure the runtime of each key function of GNNs and that of each GNN model along with its breakdown results. In addition, we use \texttt{CodeCarbon}\footnote{\url{https://github.com/mlco2/codecarbon}.} to measure power and energy consumption, which is a Python package for tracking carbon emissions produced by algorithms and programs.\footnote{This profiling tool is a Python wrapper of Intel running average power limit (RAPL) interface and NVIDIA ‘pynvml’ library. For CPUs, it measures energy consumption by reading the Intel RAPL files and computes the power by dividing energy by time duration. For GPUs, it reads the instant power recorded by pynvml and computes the energy by multiplying power by time duration between two consecutive measurements.} We use the sampling interval of 0.1 seconds in this tool instead of its default setting, which is 15 seconds. Considering the fact that it is a software tool, we admit possible discrepancies between measured values and actual ones. Nonetheless, we emphasize that \emph{relative} comparisons remain meaningful and informative regardless, not to mention that we are the first work to evaluate the power and energy consumption of GNNs and GNN frameworks.
