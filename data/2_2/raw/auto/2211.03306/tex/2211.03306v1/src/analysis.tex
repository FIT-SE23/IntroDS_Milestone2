\section{Analysis}

In this section, we first demonstrate that the output $\hat{p}$ of Algorithm~\ref{alg:general} is optimal to $(\bm{\alpha},\bm{\beta})$-\dens.
Then we analyze the structure of the output $\hat{p}$ with a special attention to its support size.




\subsection{Optimality of the output of Algorithm~\ref{alg:general}}
We first prove that the $(\bm{\alpha},\bm{\beta})$-density %\memo{layerでminをとったもの} 
of $\hat{p}$ is equal to the optimal value of LP~\eqref{LP:general}:
\begin{lemma}\label{lemma:expect}
  %Let $((x_e)_{e\in E},(y_v)_{v\in V},t)$ be a feasible solution for LP~\eqref{LP:general} satisfying \eqref{eq:opt sol}. 
  %Then 
  It holds that
  \begin{align*}
    \min_{i\in [k]}\mathbb{E}_{S\sim \hat{p}}\Bigl[ \alpha_i\frac{w_i(S)}{|S|}+\beta_i\Bigr]
    = \min_{i\in [k]}\Bigl[\alpha_i\sum_{e\in E_i}w_i(e)\hat{x}_e+\beta_i\Bigr].
  \end{align*}
  %$\mathbb{E}_{S\sim \hat{p}}\Bigl[ \alpha_i\frac{w_i(S)}{|S|}+\beta_i\Bigr] = \alpha_i\sum_{e\in E_i}w_i(e)\hat{x}_e+\beta_i \ (i\in [k])$.
\end{lemma}
\begin{proof}
  To prove the lemma, we show that for any $i\in [k]$,
  \begin{align*}
    \mathbb{E}_{S\sim \hat{p}}\Bigl[ \alpha_i\frac{w_i(S)}{|S|}+\beta_i\Bigr] = \alpha_i\sum_{e\in E_i}w_i(e)\hat{x}_e+\beta_i.
  \end{align*}
  By the definition of $S_j$ $(j=1, \ldots, \ell)$, for each $e =\{u,v\} \in E_i$,  we observe that $e\in E_i[S_j] \iff u, v \in S_j \iff \hat{y}_u\ge r_j\text{ and }\hat{y}_v\ge r_j\iff \hat{x}_e\ge r_j$,
  where the last equivalence follows from $\hat{x}_e = \min\{ \hat{y}_u, \hat{y}_v\}$.
  %By the definition of $S_j$ $(j=1, \ldots, \ell)$, for each $e =\{u,v\} \in E$,  we observe that $e\in E[S_j] \iff u, v \in S_j \iff \hat{y}_u\ge r_j\text{ and }\hat{y}_v\ge r_j$. 
  %Moreover, since $\hat{x}_e$ forms an optimal solution of LP~\eqref{LP:general}, we have $\hat{x}_e = \min\{ \hat{y}_u, \hat{y}_v\} \geq r_j$. 
  %Conversely, if $\hat{x}_e \geq r_j$, then we have $\hat{y}_u \geq r_j$ and $\hat{y}_v \geq r_j$. 
  %Thus, we obtain $e \in E[S_j] \iff \hat{x}_e \geq r_j$. 

  Recall that $\hat{p}$ is defined as \eqref{eq:def of p}.
  Then we have
  \begin{align*}
    \mathbb{E}_{S\sim \hat{p}}\Bigl[ \alpha_i\frac{w_i(S)}{|S|}+\beta_i\Bigr]
     & =\alpha_i\sum_{j\in[\ell]}\frac{w_i(S_j)}{|S_j|}\cdot \hat{p}_{S_j}+\beta_i                    \\
     & =\alpha_i\sum_{j\in[\ell]} w_i(S_j)\cdot (r_j-r_{j-1})+\beta_i                                 \\
     & =\alpha_i\sum_{j\in[\ell]} \sum_{e\in E_i[S_j]}w_i(e)\cdot (r_j-r_{j-1})+\beta_i               \\
    %&=\alpha_i\sum_{j=1}^\ell \sum_{e=\{u,v\}\in E_i:\,\hat{y}_u\ge r_j\text{ and }\hat{y}_v\ge r_j}w_i(e)\cdot (r_j-r_{j-1})+\beta_i\\
     & =\alpha_i\sum_{j\in[\ell]} \sum_{e\in E_i:\,\hat{x}_e\ge r_j}w_i(e)\cdot (r_j-r_{j-1})+\beta_i \\
     & =\alpha_i\sum_{e\in E_i}w_i(e)\hat{x}_e+\beta_i,
  \end{align*}
  where the second last equality follows from the above equivalence and the last equality follows from the fact that for each $e\in E$, $\hat{x}_e = r_{j'} = \sum_{j=1}^{j'} (r_j - r_{j-1})$ for some $j'$.
\end{proof}


%The following lemma provides a lower bound on the optimal value of LP~\eqref{LP:general}.
Next, we prove that the optimal value of LP~\eqref{LP:general} gives an upper bound on the optimal value of $(\bm{\alpha},\bm{\beta})$-\dens:
\begin{lemma}\label{lemma:general_lower}
  %Let $\tilde{p}\in\Delta(2^V)$, 
  %and let $((\tilde{x}_e)_{e\in E},(\tilde{y}_v)_{v\in V},\tilde{t})$ be a solution of LP~\eqref{LP:general} 
  %defined by \eqref{eq:transform}. 
  %Then $\tilde{t}$ is equal to $(\bm{\alpha},\bm{\beta})$-density of $\tilde{p}$. 
  %Moreover,
  It holds that
  \begin{align*}
    \min_{i\in [k]}\Bigl[\alpha_i\sum_{e\in E_i}w_i(e)\hat{x}_e+\beta_i\Bigr]\geq
    \max_{p\in\Delta(2^V)}\min_{i\in [k]}\mathbb{E}_{S\sim p}\Bigl[ \alpha_i\frac{w_i(S)}{|S|}+\beta_i\Bigr].
  \end{align*}
  %The optimal value of LP \eqref{LP:general} is at least the maximum $(\bm{\alpha},\bm{\beta})$-density over $p \in \Delta(2^V)$.
\end{lemma}


\begin{proof}
  Let us take an arbitrary $\tilde{p} \in \Delta(2^V)$.
  We consider a solution $((\tilde{x}_e)_{e\in E},(\tilde{y}_v)_{v\in V},\tilde{t})$ of LP~\eqref{LP:general} such that
  %Take an arbitrary $\tilde{p}\in\Delta(2^V)$ and construct a solution $((\tilde{x}_e)_{e\in E},(\tilde{y}_v)_{v\in V},\tilde{t})$ of LP~\eqref{LP:general} as follows: 
  \begin{align}\label{eq:transform}
    \tilde{x}_e=\!\!\!\!\sum_{\substack{S\subseteq V: \\e\in E[S]}}\frac{\tilde{p}_S}{|S|},\
    \tilde{y}_v=\!\!\!\!\sum_{\substack{S\subseteq V: \\v\in S}}\frac{\tilde{p}_S}{|S|},\
    \tilde{t}=\!\min_{i\in[k]} \Bigl[\alpha_i\!\sum_{e\in E_i}w_i(e)\tilde{x}_e+\beta_i\Bigr].
  \end{align}
  The solution $((\tilde{x}_e)_{e\in E},(\tilde{y}_v)_{v\in V},\tilde{t})$ is feasible for LP~\eqref{LP:general};
  in fact, the only concern is the third constraint but we see that
  \begin{align}
    \sum_{v\in V}\tilde{y}_v
    =\sum_{v\in V}\sum_{\substack{S\subseteq V: \\v\in S}}\frac{\tilde{p}_S}{|S|}
    =\sum_{S\subseteq V}\left(|S|\cdot \frac{\tilde{p}_S}{|S|}\right)
    %=\sum_{S\subseteq V}\sum_{v\in S}\frac{\tilde{p}_S}{|S|}
    %=\sum_{S\subseteq V}\tilde{p}_S
    =1.
  \end{align}
  Hence, the optimal value of LP~\eqref{LP:general} is at least $\tilde{t}$.
  Moreover, we have
  \begin{align*}
    \tilde{t}
     & =\min_{i\in[k]} \Bigl[\alpha_i\sum_{e\in E_i}w_i(e)\tilde{x}_e+\beta_i\Bigr]                       \\
    %& =\min_{i\in[k]} \Bigl[\alpha_i\sum_{e\in E_i}w_i(e) \sum_{S\subseteq V:\,e\in E_i[S]}\frac{\tilde{p}_S}{|S|}+\beta_i\Bigr] \\
     & =\min_{i\in[k]} \Bigl[\alpha_i \sum_{S\subseteq V}\tilde{p}_S\cdot\frac{w_i(S)}{|S|}+\beta_i\Bigr]
    =\min_{i\in[k]}\mathbb{E}_{S\sim \tilde{p}}\Bigl[\alpha_i\frac{w_i(S)}{|S|}+\beta_i\Bigr].
  \end{align*}
  %Then, 
  % Moreover, we have 
  % \begin{align*}
  % \tilde{t}
  % &=\min_{i\in[k]} \Bigl[\alpha_i\sum_{e\in E_i}w_i(e)\tilde{x}_e+\beta_i\Bigr]\\
  % &=\min_{i\in[k]} \Bigl[\alpha_i\sum_{e\in E_i}w_i(e) \sum_{S\subseteq V:\,e\in E_i[S]}\frac{\tilde{p}_S}{|S|}+\beta_i\Bigr]\\
  % &=\min_{i\in[k]} \Bigl[\alpha_i \sum_{S\subseteq V}\tilde{p}_S\cdot\frac{w_i(S)}{|S|}+\beta_i\Bigr]
  % =\min_{i\in[k]}\mathbb{E}_{S\sim \tilde{p}}\Bigl[\alpha_i\frac{w_i(S)}{|S|}+\beta_i\Bigr].
  % \end{align*}
  Recalling that $\tilde{p}$ is taken arbitrarily from $\Delta(2^V)$,
  we see that the optimal value of LP~\eqref{LP:general} is at least that of $(\bm{\alpha},\bm{\beta})$-\dens.
  %we have the lemma.
  \qedhere
\end{proof}


%Combining Lemmas~\ref{lemma:expect} and \ref{lemma:general_lower}, we obtain the following theorem.
Combining Lemmas~\ref{lemma:expect} and \ref{lemma:general_lower}, we have the desired result:
\begin{theorem}
  Algorithm~\ref{alg:general} outputs an optimal solution to $(\bm{\alpha}, \bm{\beta})$-\dens.
  %The output of Algorithm~\ref{alg:general} is optimal for \eqref{eq:general}.
\end{theorem}
%\begin{proof}
%Let $\hat{p}\in \Delta(2^V)$ be the output of Algorithm~\ref{alg:general}. 
%Combining Lemmas~\ref{lemma:expect} and \ref{lemma:general_lower}, we have 
%\begin{align*}
%\min_{i\in [k]}\mathbb{E}_{S\sim \hat{p}}\Bigl[ \alpha_i\frac{w_i(S)}{|S|}+\beta_i\Bigr]
%&=\min_{i\in [k]}\left[\alpha_i\sum_{e\in E_i}w_i(e)\cdot \hat{x}_e+\beta_i\right]=\hat{t}\\
%&\ge \max_{p\in\Delta(2^V)}\min_{i\in [k]}\mathbb{E}_{S\sim p}\Bigl[ \alpha_i\frac{w_i(S)}{|S|}+\beta_i\Bigr], 
%\end{align*}
%which means that $\hat{p}$ is an optimal solution for 
%$(\bm{\alpha}, \bm{\beta})$-\dens. 
%\end{proof}



\subsection{Hierarchical structure and support size of the output of Algorithm~\ref{alg:general}}
Here we observe some useful properties of the output of Algorithm~\ref{alg:general}.
By the design of Algorithm~\ref{alg:general},
we see that the support of the output $\hat{p}$ of the algorithm
(i.e., an optimal solution to $(\bm{\alpha},\bm{\beta})$-\dens) has a hierarchical structure.
We denote the support of $p\in \Delta(2^V)$ by $\supp(p) = \{ S\subseteq V \mid p_S > 0 \}$.
\begin{proposition}\label{prop:chain}
  Algorithm~\ref{alg:general} outputs a hierarchical solution $\hat{p}$,
  i.e., $S\subseteq T$ or $S\supseteq T$ for any $S,T\in\supp(\hat{p})$.
\end{proposition}
From this proposition, the output $\hat{p}$ has support size at most $|V|-1$ (since the empty set and the singletons are useless).
In addition, if we pick an optimal basic solution to LP~\eqref{LP:general} in Algorithm~\ref{alg:general},
the support size of $\hat{p}$ becomes at most $k$. 
For the definition of a basic solution, see e.g., Vanderbei's book~\cite{vanderbei2020linear}.
%\memo{since otherwise the number of linearly independent constraints becomes at most $|V|+|E|$.}
% 同じ値の頂点と枝で連結な成分に分解する．k個よりたくさんに分かれたとするとLPにおいて線形独立な制約の数は|V|+|E|以下になってしまいbasic solutionであることに矛盾
\begin{theorem}\label{thm:support}
  If Algorithm~\ref{alg:general} takes a basic optimal solution to LP~\eqref{LP:general},
  its output $\hat{p}$ has support size at most $k$.
\end{theorem}
%The proof can be found in Supplementary Material\footnote{\url{https://www.dropbox.com/s/d2bd4j6ihvw3o4g/paper1357_appendix.pdf}}.

%\newpage
%\appendix
%\section{Proof of Theorem~\ref{thm:support}}
%\newtheorem*{thm:support}{Theorem~\ref{thm:support}}
%\begin{thm:support}
%If Algorithm~\ref{alg:general} uses an optimal solution to LP~\eqref{LP:general} that is basic, then the output has support size at most $k$. 
%\end{thm:support}
\begin{proof}
  Let $((\hat{x}_e)_{e\in E},(\hat{y}_v)_{v\in V},\hat{t})$ be a basic solution.
  Without loss of generality, we may assume that
  \begin{align}\label{eq:opt sol}
    \hat{x}_e=\min\{\hat{y}_u,\hat{y}_v\} \quad (\forall e=\{u, v\} \in E).
  \end{align}
  Recall that $\ell$ denotes the number of different positive values in $\{\hat{y}_v \mid \hat{y}_v>0, \ v\in V\}$.
  Let $V_0 =\{v\in V\mid\hat{y}_v=0\}$.
  We divide $V \setminus V_0$ into $\ell$ subsets of vertices sharing the same value of $\hat{y}_v$, denoted by $V_1, \ldots, V_\ell$.

  %We show the theorem by contradiction. 
  Let us focus on the constraints in LP~\eqref{LP:general} that are satisfied with equality.
  For each $j =0,1, \ldots, \ell$, let $F_j \subseteq E[V_j]$ be a spanning forest in $E[V_j]$.
  Let $\rho$ be the number of connected components in $E[V_1] \cup \cdots \cup E[V_\ell]$,
  and let $\zeta$ be that of $E[V_0]$.
  We arbitrarily take $\zeta$ vertices, denoted by $u_1, \ldots, u_\zeta$, one from each connected component in $E[V_0]$.
  We focus on the following constraints (satisfied with equality):
  \begin{align*}
     & \textstyle t=\alpha_i \sum_{e\in E_i}w_{i}(e) x_e+\beta_i  \quad(\forall i\in K'),                                          \\
     & \textstyle x_e= y_u,\ x_e= y_v  \quad(\forall e=\{u,v\}\in \bigcup_{j=0}^\ell E[V_j]),                                      \\
     & \textstyle x_e= y_v             \quad(\forall e=\{u,v\} \in E \setminus \bigcup_{j=0}^\ell E[V_j],\ \hat{y}_v < \hat{y}_u), \\
     & \textstyle \sum_{v\in V}y_{v}= 1,                                                                                           \\
     & \textstyle y_{v}=0\quad (\forall v \in V_0),
  \end{align*}
  where $K' = \{ i \in [k] \mid t= \alpha_i\cdot \sum_{e\in E_i}w_{i}(e) x_e+\beta_i\}$.

  We prove that the coefficient matrix of those constraints is not full-rank.
  For ease of discussion, we remove constraints that are represented by a linear combination of others.
  Specifically, it is enough to focus on the following constraints:
  \begin{align}
     & \textstyle t=\alpha_i\cdot \sum_{e\in E_i}w_{i}(e) x_e+\beta_i\quad  (\forall i\in K'), \label{eq:constraint1}                      \\
     & \textstyle x_e= y_u,\ x_e= y_v \quad(\forall e=\{u,v\}\in \bigcup_{j=0}^\ell F_j), \label{eq:constraint2}                           \\
     & \textstyle x_e= y_v \quad(\forall e=\{u,v\}\in \bigcup_{j=0}^\ell (E[V_j] \setminus F_j),\ u<v),\label{eq:constraint3}              \\
     & \textstyle x_e= y_v \quad(\forall e=\{u,v\}\in E\setminus \bigcup_{j=0}^\ell E[V_j],\ \hat{y}_v < \hat{y}_u),\label{eq:constraint4} \\
     & \textstyle \sum_{v\in V}y_{v}= 1,\quad\label{eq:constraint5}                                                                        \\
     & \textstyle y_{u_i}=0 \quad(\forall i\in[\zeta]).\label{eq:constraint6}
  \end{align}

  There are two types of missing constraints.
  First, let $e=\{u,v\} \in E[V_j] \setminus F_j$ $(j \in [\ell])$ such that $x_e=y_v$ appears in \eqref{eq:constraint3}.
  There exists a cycle $C$ in $F_j \cup \{e\}$.
  By a telescoping sum of the constraints \eqref{eq:constraint2} along $C$, i.e.,
  $y_v = x_{e'}$, $x_{e'}=y_{v'}$, \ldots, $x_{e''}=y_u$,
  we obtain $y_u=y_v$.
  Then, constraint $x_e= y_u$ is obtained by summing $x_e= y_v$ for $y_u=y_v$.
  Next, let $v\in V_0$ belong to a connected component containing $u_j$ $(j \in [\zeta])$.
  By summing \eqref{eq:constraint2} along a path from $v$ to $u_j$, i.e.,
  $y_v = x_{e'}$, $x_{e'}=y_{v'}$, \ldots, $x_{e''}=y_{u_j}$, we obtain $y_v = y_{u_j}$.
  Then, constraint $y_v=0$ is obtained by summing $y_v=y_{u_j}$ and $y_{u_j}=0$ from \eqref{eq:constraint6}.

  The rank of the coefficient matrix is equal to the number of constraints \eqref{eq:constraint1}--\eqref{eq:constraint6}.
  %Let us count the number of the constraints in \eqref{eq:constraint1}--\eqref{eq:constraint6}.
  For \eqref{eq:constraint1}, we have at most $k$ constraints;
  the number of constraints \eqref{eq:constraint2} is $2(|V|-\rho-\zeta)$;
  that for \eqref{eq:constraint3} and \eqref{eq:constraint4} is $|E|-|V|+\rho+\zeta$;
  that for \eqref{eq:constraint5} and \eqref{eq:constraint6} is $1+\zeta$.
  Therefore, we have at most $|V|+|E|-\rho+1+k$ constraints.

  We have $|V|+|E|+1$ variables in LP~\eqref{LP:general}.
  If $\rho > k$, then we have at most $|V|+|E|$ constraints, and hence the coefficient matrix of \eqref{eq:constraint1}--\eqref{eq:constraint6} cannot have rank $|V|+|E|+1$.
  As the solution is basic, $\rho \leq k$ must hold.
  Recall that each $V_j$ $(j=1,\ldots, \ell)$ has at least one connected component.
  Therefore, we have at most $k$ different positive values of $y_v$'s, which implies that the output $\hat{p}$ has support size at most $k$.
\end{proof}


\begin{comment}
Proposition~\ref{prop:chain} indicates that there exists an optimal solution with a hierarchical structure.
We can see that this structure is critical to solve our problem efficiently.
In a direct LP formulation of the problem, $p \in \Delta(2^V)$ are used as variables.
Although we can solve it by the ellipsoid algorithm because the dual LP is equivalent to the densest subgraph problem, this method is not practical.
Thus, it is preferable to solve directly another LP formulation, say, the one with variables for each vertex (and each edge).
In general, it is difficult to derive $p \in \Delta(2^V)$ from probabilities for each vertex that it is chosen, without loss of the objective value, because the probabilities are not independent.
However, the hierarchical structure enables us to do it.
Therefore, Algorithm~\ref{alg:general} works for our problem.
%Thus, we may consider LP~\eqref{LP:general}, which has only $|V|+|E|+1$ variables.
\end{comment}
