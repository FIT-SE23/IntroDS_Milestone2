\section{Model}\label{sec:model}
In this section, we formally define our optimization model. % using a zero-sum two-player Stackelberg game. 
Let $G=(V, (E_i)_{i\in [k]})$ be a multilayer network consisting of $k$ layers,
and let $w_i\colon E_i\to\mathbb{R}_{++}$ be a positive edge weight for layer $i$.
We denote by $E$ the union of all edge sets, i.e., $E\coloneqq \bigcup_{i\in [k]} E_i$.
Let $S_i^*$ be a densest subgraph for layer $i$, i.e., $S_i^*\in\argmax_{S\subseteq V}w_i(S)/|S|$.
%% In the game, the leader is our algorithm and the follower is the nature. 
%% Our pure strategy is a vertex subset $S\subseteq V$ and that of the follower is a layer. 
%% We first choose a vertex subset, and then the follower chooses a layer with knowing our choice. 
%% Finally, we receive some payoff of our vertex subset. 
%% We wish to obtain a subgraph with high payoff, whereas the follower chooses the layer that minimizes our payoff. 
Our task is to find a vertex subset that is dense for the layer selected adversarially.
%As mentioned in the introduction, we consider a mixed strategy to compete with the follower.
%In our game, a mixed strategy is a probability distribution over the family of vertex subsets. 
As mentioned in the introduction, we consider a stochastic solution to compete with the adversary.
Let $\Delta(2^V)$ be the set of probability distributions over $2^V$.
For each $p \in \Delta(2^V)$, we denote by $p_S$ the probability of choosing $S \subseteq V$.

%\memo{metricの定義が変．単なるpayoffの置換ではないので書き直すべき．For our stochastic solution, we define a metric }
We aim to compute $p\in \Delta(2^V)$ that maximizes some metric (when the adversary selects the worst layer to $p$).
We employ the following three metrics:

\smallskip
\noindent\textbf{Density.}
\ The first metric is the degree density itself.
%The \emph{minimum density} indicates the worst-case performance of a solution over all weights.
Specifically, when we select a vertex subset according to a probability distribution $p \in \Delta(2^V)$ and the adversary selects a layer $i\in[k]$,
our metric is defined as follows:
\begin{align}
   & %\min_{i\in [k]} 
  \mathbb{E}_{S\sim p}\left[ \frac{w_i(S)}{|S|}\right]
  \quad\Bigg(=
  %\min_{i\in [k]} 
  \sum_{S\subseteq V} p_S \frac{w_i(S)}{|S|}\Bigg).
  \label{eq:mindens}
\end{align}
As the adversary selects the worst layer,
we aim to find $p\in \Delta(2^V)$ that maximizes the minimum of the density~\eqref{eq:mindens} among $i\in [k]$.
Our optimization model with this metric can be seen as a stochastic version of the densest common subgraph problem introduced by Jethava and Beerenwinkel~\cite{JB2015}.

%It is worth mentioning that the problem of maximizing the minimum of the density~\eqref{eq:mindens} has the same optimal value as that of a problem arising naturally from dense subgraph discovery in multilayer networks.
%The maximum value of the minimum of \eqref{eq:mindens} is the game value of the zero-sum Stackelberg game.
%By the von Neumann's minimax theorem, we have
%\[
%  \max_{p\in\Delta(2^V)}\min_{i\in [k]}\mathbb{E}_{S\sim p}\left[ \frac{w_i(S)}{|S|}\right]=
%  \min_{c \in \Delta(k)} \max_{S \subseteq V} \frac{\sum_{i\in [k]} c_i \cdot w_i(S)}{|S|},
%\]
%where $\Delta(k)=\{ c\in\mathbb{R}_+^k \mid \sum_{i \in [k]} c_i = 1\}$. % c'\ge 0
%The latter value is the worst maximum density attained when we aggregate all layers into a single-layer graph whose weight is a convex combination of $w_i$'s with coefficients $c_i$ $(i\in [k])$.



\smallskip
\noindent\textbf{Robust ratio.}
\ The \emph{robust ratio} is a metric based on the ratio of the expected degree to the optimal degree. %\memo{robust ratioは本当は最悪のlayerをとったもの}
%\ The \emph{robust ratio} is a metric that deals with a multiplicatively normalized version of the degree density. %\memo{robust ratioは本当は最悪のlayerをとったもの}
%The \emph{robust ratio} is a normalized version of the worst-case performance of a solution with respect to all weights.
For a nonempty $S\subseteq V$ and $i\in[k]$, let us consider a normalized density defined as $\frac{w_i(S)/|S|}{w_i(S_i^*)/|S_i^*|}$.
%minimizing the difference to the objective function of the best solution that would have been possible in a scenario.
When we select a vertex subset according to a probability distribution $p\in \Delta(2^V)$ and the adversary selects a layer $i\in [k]$,
the metric is defined as follows:
\begin{align}
  %\min_{i\in [k]} 
  \mathbb{E}_{S\sim p}\left[ \frac{w_i(S)/|S|}{w_i(S_i^*)/|S_i^*|}\right]
  \quad\Bigg(=
  %\min_{i\in [k]} 
  \sum_{S\subseteq V}p_S \frac{w_i(S)/|S|}{w_i(S_i^*)|S_i^*|}\Bigg).
  \label{eq:ratio}
\end{align}
In other words, the robust ratio is equivalent to
the density for the multilayer network with weights $w_1',\dots,w_k'$ given by $w_i'(e)\coloneqq \frac{w_i(e)}{w_i(S_i^*)/|S_i^*|}$ for each $i\in[k]$ and $e \in E_i$.
As the adversary selects the worst layer,
we aim to find $p\in \Delta(2^V)$ that maximizes the minimum of~\eqref{eq:ratio} among $i\in [k]$.
Note that the optimal robust ratio is contained in the interval $[1/k,\,1]$ 
because $p\in \Delta(2^V)$ such that $p_{S_i^*}=1/k$ for each $i\in [k]$ has the objective value of $1/k$. 


\smallskip
\noindent\textbf{Regret.}
\ The \emph{regret} is a metric based on the difference between the optimal density and the expected density.
For $S\subseteq V$ and $i\in [k]$, the regret is defined as $w_i(S^*_i)/|S^*_i|-w_i(S)/|S|$.
%For $S\subseteq V$, the regret is defined as $w_i(S)/|S|-w_i(S^*_i)/|S^*_i|$. 
When we select a vertex subset according to a probability distribution $p\in \Delta(2^V)$ and the adversary selects a layer $i\in [k]$,
the metric is defined as follows:
\begin{align}
  %\max_{i\in [k]} 
  \mathbb{E}_{S\sim p}\left[ \frac{w_i(S_i^*)}{|S_i^*|}-\frac{w_i(S)}{|S|}\right]
  \quad\Bigg(=
  %\max_{i\in [k]} 
  \frac{w_i(S_i^*)}{|S_i^*|}-\sum_{S\subseteq V}p_S \frac{w_i(S)}{|S|}\Bigg).
  \label{eq:regret}
\end{align}
As the adversary selects the worst layer,
we aim to find $p\in \Delta(2^V)$ that minimizes the maximum of~\eqref{eq:regret} among $i\in [k]$.

\smallskip
Here we explain how to select an appropriate metric.
The density and regret metrics are useful when we are concerned with multilayer networks with homogeneous layers 
such as time-dependent follower-followee relations in the Twitter network. 
%In particular, the density metric is more appropriate if we aim to find vertex subsets that are reasonably dense for \emph{all} layers, 
Although the density metric can be the first choice, the regret metric is more suitable for robust analysis. 
For example, consider the case where there are a number of layers consistent with each other together with some noisy (e.g., random) layers. 
The density metric would suffer from the effect of the noisy layers, but the regret metric would avoid it and find dense subgraphs in the other meaningful layers. 
On the other hand, the robust ratio metric is useful when we analyze multilayer networks with heterogeneous layers 
such as brain networks with structural and functional connectivity layers.
From its definition, the robust ratio metric would find subgraphs that are reasonably dense for all layers. 
The density and regret metrics focus only on the layers with small optimal densities and the layers with large optimal densities, respectively. 

%Here we explain how to select an appropriate metric.
%The density and regret metrics would be useful when the layers come from homogeneous samples
%such as time-dependent follower--followee relations in the Twitter network,
%while the robust ratio metric would be useful when the layers come from heterogeneous samples
%such as brain networks with structural and functional connectivity layers.
%It is likely that the density preferentially cares layers with relatively low optimal densities
%but the regret preferentially cares layers with relatively high optimal densities.




%%\begin{figure}
%%    \centering
%%    \begin{tikzpicture}[]
%%    % vertex
%%    \foreach \pos/\name in {{(-2,1)/a},{(-2,-1)/b},{(0,0)/c},{(2,0)/d}}
%%        \node (\name) at \pos {};
%%    % edge
%%    %\draw[draw=blue, line width=1pt] ($(a)+(-0.05,0)$)--($(b)+(-0.05,0)$);
%%    \draw[draw=blue,  line width=1pt] ([xshift=-2pt]a.center)--([xshift=-2pt]b.center);
%%    \draw[draw=blue, line width=1pt] (a)--(c);
%%    \draw[draw=blue, line width=2pt] (b)--(c);
%%    %\draw[draw=red,  line width=1pt] ($(a)+(0.1,0)$)--($(b)+(0.1,0)$);
%%    \draw[draw=red,  line width=1pt] ([xshift=2pt]a.center)--([xshift=2pt]b.center);
%%    \draw[draw=red,  line width=2pt] (c)--(d);
%%    \foreach \source/\dest/\name in {{a/b/e_1},{a/c/e_2},{b/c/e_3},{c/d/e_4}}
%%        \path (\source) -- node[font=\small,rectangle,fill=white,opacity=0.9, text opacity=1,inner sep=2pt,rounded corners] {$\name$} (\dest);
%%    \foreach \pos/\name in {{(-2,1)/a},{(-2,-1)/b},{(0,0)/c},{(2,0)/d}}
%%        \node[circle,draw,minimum size=15,inner sep=0,fill=black!5] at \pos {$\name$};
%%    \end{tikzpicture}
%%    \caption{A simple multilayer network.}
%%    \label{fig:example1}
%%    \centering
%%    \begin{tikzpicture}[very thick,scale=3.0,
%%    dline/.style={densely dotted,thick},
%%    p/.style={circle,fill=black,draw,inner sep=0pt,minimum size=3pt}]
%%    \draw node[below left] {$O$};
%%    % convex hull
%%    \draw[thin,fill=black!10] (0,1) -- (1,0.75) -- (1.3333,0.3333) -- (1,0) -- (0,0) -- (0,1);
%%    % Q_{0.8}
%%    \draw[draw=blue!10,fill=blue!10] (1.7,0.8) -- (0.8,0.8) -- (0.8,1.2) -- (1.7,1.2) -- (1.7,0.8);
%%    \draw[thin,blue] (1.7,0.8) -- (0.8,0.8) -- (0.8,1.2);
%%    \node[blue] at (1.25,1) {$Q_{0.8}$};
%%    
%%
%%    \foreach \x/\y in {0.0000/1.0000,0.5000/0.0000,0.0000/0.0000,0.3333/0.3333,0.5000/0.5000,0.3333/0.6667,0.6667/0.6667,1.0000/0.7500,1.3333/0.3333,1.0000/0.0000}{
%%      \node[p] at (\x,\y) {}; 
%%    }    
%%
%%    % \node[above right,font=\tiny] at (0,1) {$\{c,d\}$};
%%    % \node[above right,font=\tiny] at (1,0.75) {$\{a,b,c,d\}$};
%%    % \node[right,font=\tiny] at (1.3333,0.3333) {$\{a,b,c\}$};
%%
%%    \node[left] at (0,1) {\small$1$};
%%    \draw[dline] (1,0.75) -- (0,0.75) node[left,yshift=-2pt] {\small$3/4$};
%%    \draw[dline] (1,0.75) -- (1,0) node[below] {\small$1$};
%%    \draw[dline] (1.3333,0.3333) -- (0,0.3333) node[left] {\small$1/3$};
%%    \draw[dline] (1.3333,0.3333) -- (1.3333,0) node[below] {\small$4/3$};
%%    %\draw[dline] (1.3333,1) -- (0,1);
%%
%%    \draw[dline] (0.8,0.8) -- (0,0.8) node[left,yshift=2pt] {\small$4/5$};
%%    \draw[dline] (0.8,0.8) -- (0.8,0) node[below] {\small$4/5$};
%%
%%    \node[p,diamond,minimum size=3pt,,red,label={[xshift=5pt,yshift=-2pt]\color{red}\small$p^{1}$}] at (0.8,0.8) {};
%%    \node[p,diamond,minimum size=3pt,red,label={[below left]\color{red}\small$p^{2}$}] at (1,0.75) {};
%%    \node[p,diamond,minimum size=3pt,,red,label={[right]\color{red}\small$p^{3}$}] at (1.037,0.7037) {};
%%    
%%    %\node[left,yshift=2pt] at (0,0.8) {\small$0.8$};
%%    %% \path[draw,thick,densely dotted,red,<->] (0,0.8) -- node[font=\tiny,rectangle,fill=white,opacity=0.9, text opacity=1,inner sep=2pt,rounded corners] {$0.8$} (0.8,0.8);
%%    %% \path[draw,thick,densely dotted,red,<->] (0.8,0) -- node[font=\tiny,rectangle,fill=white,opacity=0.9, text opacity=1,inner sep=2pt,rounded corners] {$0.8$} (0.8,0.8);
%%    %% \path[draw,thick,densely dotted,red,<->] (1.037,0.7037) -- node[font=\tiny,rectangle,fill=white,opacity=0.9, text opacity=1,inner sep=2pt,rounded corners] {$8/27$} (1.3333,0.7037);
%%    %% \path[draw,thick,densely dotted,red,<->] (1.037,0.7037) -- node[yshift=7pt,font=\tiny,rectangle,fill=white,opacity=0.9, text opacity=1,inner sep=2pt,rounded corners] {$8/27$} (1.037,1);
%%    \draw[->] (-.2,0) -- (1.7,0) node[below] {$\frac{w_1(S)}{|S|}$};
%%    \draw[->] (0,-.2) -- (0,1.2) node[left] {$\frac{w_2(S)}{|S|}$};
%%    \end{tikzpicture}
%%    \caption{$p^1$, $p^2$, $p^3$ are optimal solutions for the density, the robust ratio, and the regret, respectively.}
%%    \label{fig:pareto}
%%\end{figure}
%%
%%Next we observe the behavior of our optimization model with the above three metrics through a simple example. 
%%Let $G=(V,\{E_1,E_2\})$ be a multilayer network consisting of $V=\{a,b,c,d\}$, $E_1=\{e_1,e_2,e_3\}$, and $E_2=\{e_1,e_4\}$,
%%where $e_1=\{a,b\}$, $e_2=\{a,c\}$, $e_3=\{b,c\}$, and $e_4=\{c,d\}$ (see Figure~\ref{fig:example1}).
%%There are two edge weights $w_1$ and $w_2$ such that 
%%\begin{align*}
%%w_1(e_1)=1,\ w_1(e_2)=1,\ w_1(e_3)=2,\ w_2(e_1)=1,\ w_2(e_4)=2.
%%\end{align*}
%%The maximum density in terms of $w_1$ is $4/3$ (attained by $\{a,b,c\}$) and that in terms of $w_2$ is $1$ (attained by $\{c,d\}$).
%%
%%The optimal solution to our model with the density metric is $p^1\in \Delta(2^V)$ taking $\{a,b,c,d\}$ with probability $4/5$ and $\{c,d\}$ with probability $1/5$.
%%The optimal solution for the robust ratio metric is $p^2\in \Delta(2^V)$ taking $\{a,b,c,d\}$ with probability $1$.
%%The optimal solution for the regret metric is $p^3\in \Delta(2^V)$ taking $\{a,b,c,d\}$ with probability $8/9$ and $\{a,b,c\}$ with probability $1/9$.
%%
%%We can see the optimality of those solutions from the geometric viewpoint. 
%%In Figure~\ref{fig:pareto}, black points represent $\left(\frac{w_1(S)}{|S|}, \frac{w_2(S)}{|S|}\right)$ for all subsets $S \subseteq V$. 
%%In this plot, each $p \in \Delta(2^V)$ corresponds to a point $\Bigl(\mathbb{E}_{S\sim p} \bigl[\frac{w_1(S)}{|S|}\bigr], \mathbb{E}_{S\sim p} \bigl[\frac{w_2(S)}{|S|}\bigr]\Bigr)$ contained in the convex hull $H$ of the black points.
%%We plot the red points corresponding to $p^i$ for $i=1,2,3$. 
%%Let us focus on the density metric. 
%%The set of $p \in \Delta(2^V)$ that has the objective value of at least $t$ corresponds to the intersection of $H$ and $Q_t=\{\bm{q} \mid q_1\geq t,\ q_2\geq t \}$. 
%%In this plot, $H\cap Q_t = \emptyset$ when $t> 0.8$, and the point corresponding to $p^1$ lies in $H \cap Q_{0.8}$.
%%Therefore, we see that $p^1$ is an optimal solution for the degree metric. 
%%We can also check the optimality of $p^2$ and $p^3$ in a similar manner.
%%Recall that the maximum density for $w_1$ is $4/3$, and that for $w_2$ is $1$. 
%%For the robust ratio metric and the regret metric, we consider $Q'_t = \{ \bm{q} \mid \frac{3}{4} q_1 \geq t,\ q_2 \geq t \}$ and $Q''_t = \{ \bm{q} \mid \frac{4}{3}-q_1 \leq t,\ 1-q_2 \leq t \}$, respectively, instead of $Q_t$ in the above discussion.



\smallskip
\noindent\textbf{Unified concept: $(\bm{\alpha},\bm{\beta})$-density.}
\ Here we introduce a general metric, enabling us to deal with the above three metrics in a unified manner.
An important fact is that the robust ratio and regret metrics can be obtained by affine transformations of the density.
Specifically, when we select a subgraph according to a probability distribution $p \in \Delta(2^V)$ and the adversary selects a layer $i\in[k]$,
we define the \emph{$(\bm{\alpha},\bm{\beta})$-density} using two vectors $\bm{\alpha} \in \mathbb{R}^k_+$ and $\bm{\beta} \in \mathbb{R}^k$ as follows:
\begin{align}
  %\min_{i\in [k]} 
  \mathbb{E}_{S\sim p}\left[\alpha_i\frac{w_i(S)}{|S|}+\beta_i\right]
  \quad\Bigg(=
  %\min_{i\in [k]} 
  \alpha_i\sum_{S\subseteq V}p_S\frac{w_i(S)}{|S|}+\beta_i\Bigg).
  %\ \Bigg(=\max_{i\in [k]} \Bigl[ \alpha_i\sum_{S\subseteq V}p_S\frac{w_i(S)}{|S|}+\beta_i\Bigr]\Bigg).
  \label{eq:general}
\end{align}
%\memo{後ろの解析では，最悪のレイヤーをとったものをこのように呼んでいる箇所があり，統一する必要あり}
% adversaryがiを取るということは，iが最悪レイヤーなのでよいのでは？
Note that the above three metrics, the density, robust ratio, and regret, are equivalent to
the $(\bm{1},\bm{0})$-density,
$((|S_i^*|/w_i(S_i^*))_{i\in[k]},\bm{0})$-density, and
$(\bm{1},(-w_i(S_i^*)/|S_i^*|)_{i\in[k]})$-density\footnote{The actual regret value is the negation of $(\bm{1},(-w_i(S_i^*)/|S_i^*|)_{i\in[k]})$-density.}, respectively. 
Note that $w_i(S_i^*)/|S_i^*|$ is polynomially computable for each $i\in [k]$~\cite{Charikar2000,Goldberg_84}.
%$(\bm{1},(-|S_i^*|/w_i(S_i^*))_{i\in[k]})$-minimum density.\footnote{The actual regret value is the negation of $(\bm{1},(-|S_i^*|/w_i(S_i^*))_{i\in[k]})$-minimum density.}
We refer to $(\bm{\alpha},\bm{\beta})$-\dens as the problem of finding $p\in \Delta(2^V)$ that maximizes the minimum of the $(\bm{\alpha},\bm{\beta})$-density among $i\in [k]$.
Therefore, in the following, we aim to design an algorithm for $(\bm{\alpha},\bm{\beta})$-\dens.


