\documentclass[journal]{IEEEtran}
%\documentclass[draftclsnofoot,onecolumn]{IEEEtran}
%\documentclass[10pt,journal,twoside,final,compsoc]{IEEEtran}
\usepackage{graphicx} 
\usepackage{subfigure}%使用graphicx包
\usepackage{amsmath}
\usepackage{multirow} 
\newtheorem{definition}{\textbf {Definition}}
\newtheorem{assumption}{Assumption}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{\textbf{Remark}}
\newtheorem{proof}{Proof}

\usepackage{caption}

%\newcommand{\re}[1]{{\color[rgb]{0,0,1}#1}}
\newcommand{\re}[1]{{\color[rgb]{0,0,0}#1}}

\newcommand{\xw}[1]{{\color[rgb]{0.5,0.1,1}#1}}
\newcommand{\jz}[1]{{\color{red}#1}}

\newtheorem{theorem}{Theorem}
\usepackage{algorithm}
\usepackage{algorithmic}
%\usepackage[ruled]{algorithm2e}
\renewcommand{\algorithmicrequire}{ \textbf{Input:}} 
\renewcommand{\algorithmicensure}{ \textbf{Output:}} 
\usepackage{amsfonts}
\usepackage{algorithm, algorithmic}
\usepackage{color}
\usepackage{booktabs}
\usepackage{array}
\usepackage{epstopdf} 
\usepackage{url}
\usepackage{cite}
%\bibliographystyle{plain}
%\bibliographystyle{unsrt}


%\hyphenation{op-tical net-works semi-conduc-tor}
	

\begin{document}

\title{Enabling Deep Learning-based Physical-layer Secret Key Generation for FDD-OFDM Systems in Multi-Environments}

\author{Xinwei~Zhang, 
        Guyue~Li,~\IEEEmembership{Member,~IEEE},
        Junqing~Zhang,~\IEEEmembership{Member,~IEEE},
        Linning~Peng,~\IEEEmembership{Member,~IEEE},
        Aiqun~Hu,~\IEEEmembership{Senior Member,~IEEE}
        and Xianbin~Wang,~\IEEEmembership{Fellow,~IEEE}
\thanks{
Copyright (c) 2015 IEEE. Personal use of this material is permitted. However, permission to use this material for any other purposes must be obtained from the IEEE by sending a request to pubs-permissions@ieee.org. 

Manuscript received 20 May 2023; revised 8 November 2023; accepted 8 February 2024.
This work was supported in part by the National Key R\&D Program of China (No. 2022YFB2902202), in part by the National Natural Science Foundation of China (No. 62171121, U22A2001) and in part by the National Natural Science Foundation of Jiangsu Province, China (No. BK20211160). 
The work of J. Zhang was in part supported by the UK Engineering and Physical Sciences Research Council (EPSRC) New Investigator Award under grant ID EP/V027697/1. 
%For the purpose of open access, the authors have applied a Creative Commons Attribution (CC BY) licence to any Accepted Manuscript version arising. 
The review of this paper was coordinated by Dr. Linke Guo. 
(\textit{Corresponding author: Guyue Li})}				
\IEEEcompsocitemizethanks{
\IEEEcompsocthanksitem Xinwei Zhang, Guyue Li, and Linning Peng are with the School of Cyber Science and Engineering, Southeast University, Nanjing 210096, China (e-mail: xwzhang1998@gmail.com, guyuelee@seu.edu.cn, pengln@seu.edu.cn).
\IEEEcompsocthanksitem Junqing Zhang is with the Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool L69 3GJ, U.K. (e-mail: junqing.zhang@liverpool.ac.uk).
\IEEEcompsocthanksitem Aiqun Hu is with the School of Information Science and Engineering, and National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China (e-mail: aqhu@seu.edu.cn).
\IEEEcompsocthanksitem Guyue Li, Linning Peng and Aiqun Hu are also with the Purple Mountain Laboratories for Network and Communication Security, Nanjing 210096, China.
\IEEEcompsocthanksitem Xianbin Wang is with the Department of Electrical and Computer Engineering, Western University, London, ON N6A 5B9, Canada (e-mail: xianbin.wang@uwo.ca).}
%\thanks{Color versions of one or more of the figures in this paper are available online at http://ieeexplore.ieee.org.}
%\thanks{Digital Object Identifier xxx}
}


% The paper headers
\markboth{IEEE Transactions on Vehicular Technology,~Vol.~XX, No.~XX, XXX~}
{}

\maketitle

\begin{abstract}
Deep learning-based physical-layer secret key generation (PKG) has been used to overcome the imperfect uplink/downlink channel reciprocity in frequency division duplexing (FDD) orthogonal frequency division multiplexing (OFDM) systems. However, existing efforts have focused on key generation for users in a specific environment where the training samples and test samples follow the same distribution, which is unrealistic for real-world applications. This paper formulates the PKG problem in multiple environments as a learning-based problem by learning the knowledge such as data and models from known environments to generate keys quickly and efficiently in multiple new environments. Specifically, we propose deep transfer learning (DTL) and meta-learning-based channel feature mapping algorithms for key generation. The two algorithms use different training methods to pre-train the model in the known environments, and then quickly adapt and deploy the model to new environments. Simulation and experimental results show that compared with the methods without adaptation, the DTL and meta-learning algorithms both can improve the performance of generated keys. In addition, the complexity analysis shows that the meta-learning algorithm can achieve better performance than the DTL algorithm with less cost.
\end{abstract}

\begin{IEEEkeywords}
Physical-layer security, secret key generation, frequency division duplexing, deep transfer learning, meta-learning.
\end{IEEEkeywords}




%\IEEEpeerreviewmaketitle



\section{Introduction}

%\subsection{Background}
\IEEEPARstart{D}{ue} to the broadcast nature of radio signal propagation, wireless networks are vulnerable to various attacks such as eavesdropping, impersonating, and tampering~\cite{zou2016survey}. Traditional security mechanisms, particularly public key cryptography, are facing many problems such as difficulty in key distribution and poor scalability in large-scale networks with limited resources, which make it difficult to meet the security needs of future wireless communications \cite{li2019physical}. In recent years, \textit{physical-layer secret key generation (PKG)} has gradually become a research hotspot of wireless security. From the perspective of information theory, PKG provides a new security mechanism, which greatly simplifies the distribution and management of keys \cite{li2019physical, 8735939}. 

PKG techniques realize real-time sharing and coordination of random security keys by exploiting the channel reciprocity of uplink and downlink features~\cite{li2019physical, li2018constructing}. \re{Channel reciprocity means that both communicating parties can obtain highly similar channel characteristics, which determines whether the communicating parties can generate consistent keys. } Different channel features, such as received signal strength (RSS), channel state information (CSI), channel gain, etc., are widely used for PKG \cite{li2019physical}. In time division duplexing (TDD) systems, as both the uplink and downlink transmissions operate in the same carrier frequency band, and the channel features observed by both communication parties are highly reciprocal. However, in frequency division duplexing (FDD) systems, since the uplink and downlink are operated in different bands, the channel parameters observed by the two parties involved may be completely different, thus can not be directly used for key generation. Therefore, the majority of the existing studies focus on PKG in TDD systems and the research on PKG in FDD systems is limited. However, it has profound research value and practical significance to develop effective PKG solutions for FDD systems since FDD is the primary duplexing technique for cellular communications\cite{penttinen2015telecommunications, 3gpp.38.101-1}.

\subsection{Related Work}
In recent years, there have been some studies on the PKG in FDD systems, which can be categorized into model-based and deep learning-based approaches. 

Model-based methods aim to extract frequency-independent channel features or construct a reciprocal feature. Specifically, the work in~\cite{wang2012wireless,liu2019secret} proposed to extract the frequency-independent channel parameters (such as arriving angle, delay and covariance matrix eigenvalues). However, these methods have many limitations, such as large bandwidth or special configuration of the antenna array \cite{vasisht2016eliminating}. Besides, A framework for constructing reciprocal channels via path separation, adjustment and reconstruction is proposed in \cite{li2018constructing}, but it is difficult to separate the channel paths accurately in the complex multi-path environment. Some works proposed to construct reciprocal channels by additional reverse channel training and feedback, called the loopback-based methods~\cite{qin2016exploiting,allam2017channel}. However, these methods not only increase the complexity of channel detection but also increase the possibility of eavesdropping~\cite {linning2018investigation}. 

Due to its excellent performance, deep learning has also been introduced into the field of PKG in FDD systems \cite{zhang2021secret,wan2021secret,10.1145/3522783.3529526,hou2021secret,zhang2022deep}. In FDD systems, deep learning-based approaches have been used to construct reciprocal features for key generation with the help of the feature mapping function between uplink and downlink transmissions assisted by deep learning.
Since the uplink and downlink channels pass through the same propagation path and scattering clusters, it is experimentally shown in \cite{vasisht2016eliminating} that there is a transformation function that can map the channel to the underlying path. Furthermore, prior works have shown that it is possible to infer downlink channels from uplink channels~\cite{alrabeian2019deep,bakshi2019fast,liu2021Fire}. 
These works inspire efforts to apply deep learning for FDD-based key generation by constructing reciprocal features via deep learning.
In \cite{zhang2022deep}, it is proved that in a given environment, when the channel mapping function of possible user locations to antennas is bijective, there exists a feature mapping function that can map one frequency band features to another frequency band features, and the channel feature mapping function can be obtained by a simple deep learning model. This conclusion provides a theoretical basis for introducing deep learning into key generation for FDD-based OFDM systems~\cite{zhang2021secret,wan2021secret,hou2021secret,zhang2022deep}. A boundary equilibrium generative
adversarial network (BEGAN) and an encoder-decoder-based convolutional neural network were proposed to predict downlink CSI and key generation \cite{wan2021secret,hou2021secret}. Furthermore, a complex-valued neural network (CVNet) was proposed to improve the performance of generated keys \cite{zhang2021secret}. 

Compared with conventional model-based PKG techniques (e.g. \cite{wang2012wireless,liu2019secret,qin2016exploiting,allam2017channel,li2018constructing}), deep learning-based key generation methods are not limited to channel models and can achieve excellent performance. However, existing deep learning-based approaches only consider a given wireless environment and the deep learning model only can learn the feature mapping function in this specific environment. In practice, users may experience different new environments. 
Existing machine learning techniques require data collection and model training for each communication environment, leading to a large number of training resources and training data, which is difficult to be used in real-world applications. Therefore, how to quickly adapt the deep learning model to new environments for feature mapping and key generation with low cost is a new challenge that needs to be addressed.

Deep transfer learning (DTL)~\cite{nguyen2021transfer} and meta-learning \cite{thrun1998learning,park2021learning} are effective ways that can solve the problem of inapplicability of the deep learning model caused by environmental changes. DTL uses the knowledge of source tasks to improve the performance of target tasks and is a promising machine learning technology that can solve similar tasks with limited labeled data. Meta-learning aims to improve the ability to adapt or generalize to new tasks and environments that have never been encountered during the training stage by training in multiple learning tasks.
They have been widely used in many areas to solve the problem of performance degradation of deep learning models due to environmental changes, e.g., channel feedback \cite{zeng2021downlink}, beam prediction \cite{yuan2020transfer}, downlink channel prediction \cite{yang2020deep}, %multi-Task offloading \cite{10093793} 
Beamforming Optimization \cite{9367008} etc, but still not applied to the field of PKG.

\subsection{Main Contributions}
\re{Inspired by these works, this paper introduces DTL and meta-learning into the field of PKG to improve channel reciprocity for achieving the fast and efficient key generation of FDD-OFDM systems in multi-environments.} \re{In our work, we focus on generating high-performance keys and adopting optimal neural network architectures and training strategies.}
First, we formulate the key generation in multi-environments as a learning-based problem, i.e., using the knowledge from known (source) environments to learn the deep learning model in the new (target) environments more efficiently. Then we propose DTL-based and meta-learning-based feature mapping algorithms to achieve key generation for FDD systems in multi-environments and verify the performance of the proposed algorithm with sufficient simulation and experimental data. %We also proposed two benchmarks, i.e.,  the direct algorithm and the joint dataset algorithm, to verify the good performance of the algorithms proposed in this paper. 
\re{To the best knowledge of the authors, this is the first work focusing on deep learning-based key generation for FDD-OFDM systems in multi-environments.} Our major contributions are summarized as follows.
\begin{itemize}
%    \item We verify the performance of the method proposed in \cite{zhang2022deep} in the outdoor scenario and find that the feature extraction method can not be used in the outdoor scenario. Based on this observation, we propose a general feature extraction framework, which can construct suitable features in the different scenarios. 
	\item We propose a DTL-based channel feature mapping algorithm for physical layer key generation in FDD-OFDM systems. This algorithm pre-trains the model using the datasets from source environments and then fine-tunes the pre-trained model using a small number of samples from the new environment, after which this fine-tuned model can be used for key generation in the new environment. \re{The algorithm can be fine-tuned on the model of the current systems without needing a pre-training process, allowing for seamless integration into the existing system.}
	%The DTL algorithm can quickly obtain a better performance model with lower data cost and time cost.
	\item To better leverage knowledge from known channel environments, we propose a meta-learning-based feature mapping algorithm for key generation in FDD-OFDM systems. This algorithm performs intra-task and cross-task learning in multiple tasks (each task represents the key generation in a given environment) to obtain the best model initialization parameters, allowing for fast model adaptation in new environments.
    \item \re{We analyze channel differences in different environments, and give a theoretical analysis of the DTL and meta-learning algorithms. The results show that the data distribution in different environments is almost different, which is the cause of the better performance of the meta-learning algorithm.}
	\item We verify the proposed algorithms in an outdoor scenario using a ray tracing simulator Wireless InSite. The results show the DTL and meta-learning algorithms can both improve the performance of generated keys in new environments. In addition, complexity analysis shows that the meta-learning algorithm can achieve better performance with less time cost compared with the DTL algorithm. 
 
    \item A practical GNURadio and USRP-based FDD-OFDM wireless key generation prototype is developed. We collect data in both indoor and outdoor scenarios and for the first time validate the performance of the deep learning-powered FDD-OFDM key generation method using real-world data. We further verified through real experiments that the proposed algorithm can significantly reduce the key error rate (KER) of the key generated in the new environment. \re{There are currently no works in related fields that use data in real-life environments for verification. }
\end{itemize} 

The rest of this paper is structured as follows. The deep learning-based key generation for FDD-OFDM systems is introduced in Section \ref{Preliminary}. In Section \ref{system overview}, we formulate the PKG in multi-environments as a learning-based problem and give an algorithm overview. The DTL and meta-learning-based feature mapping algorithms for key generation are presented in Section \ref{DTL} and Section \ref{meta}. The DTL and meta-learning are analyzed theoretically in Section \ref{theoretical}. The simulation results for evaluating the performance of the generated keys and the complexity analysis are provided in Section \ref{simulation}. In Section \ref{practical}, we built a platform and verified the performance of the algorithm in a real environment, which is followed by conclusions in Section \ref{Conclusion}.

\section{Preliminary: Deep Learning-Powered FDD-OFDM Key Generation}
\label{Preliminary}
%In this section, we first give the channel model in the FDD-OFDM system, and then introduce the deep learning-based key generation for FDD-OFDM systems.

\subsection{Overview}
We consider the FDD-OFDM system, where the BS (Alice) and user (Bob) are equipped with a single antenna and operate in the FDD mode. Alice and Bob simultaneously transmit signals on different carrier frequencies, $f_{dl}$ and $f_{ul}$, respectively. The channel impulse response (CIR) can be defined as follows:
\begin{equation}
\begin{split}
h(f,\tau)=\sum_{n=0}^{N-1}\alpha_{n}e^{-j2\pi f\tau_n+j\phi_n}\delta(\tau-\tau_n),
\end{split}
\label{CIR}
\end{equation}
where $f$ is the carrier frequency, $N$ is the total number of paths, $\alpha_{n}$ is the magnitude of the $n^{th}$ path, which is influenced by the distance $d_n$ between Alice and Bob, the scattering environment and the carrier frequency  $f$. $\tau_n = \frac{d_n}{c}$ is the delay of the $n^{th}$ path, where $c$ is the speed of light. $\phi_n$ is the phase shift of the $n^{th}$ path, which is determined by the scatterer material and wave incident/impinging angles at the scatterer.

%Note that $\alpha_{n}$ depends on (i) the distance $d_n$ between Alice and Bob, (ii) the carrier frequency $f$, (iii) the scattering environment. The phase $\phi_n$ is determined by the scatterer(s) materials and wave incident/impinging angles at the scatterer(s). The delay $\tau_n = \frac{d_n}{c}$, where $c$ is the speed of light. 

In FDD-OFDM systems, the channel frequency response (CFR) of the $l^{th}$ sub-carrier can be expressed as 
\begin{equation}
\begin{split}
H(f,l)=\sum_{n=0}^{N-1}\alpha_{n}e^{-j2\pi f\tau_n+j\phi_n}e^{-j2\pi n f_l},
\end{split}
\label{CFR}
\end{equation}
where $f_l$ is the frequency of the $l^{th}$ subcarrier relative to the
center frequency $f$. The CFR of frequency $f$ can be defined as the $1\times L$ channel vector ${\mathbf{H}(f)}=\{H(f,0),...,H(f,L-1)\} $, where $L$ is the total number of sub-carrier.
% and the CFR of $f_{ul}$ obtained by Alice as $\mathbf{H}_{A}=\mathbf{H}(f_{ul})$, the CFR of $f_{dl}$ obtained by Bob as $\mathbf{H}_{B}=\mathbf{H}(f_{dl})$ . 
As shown in (\ref{CFR}), the amplitude and phase of wireless channel ${\mathbf{H}(f)}$ are influenced by their frequencies. %Although the downlink and uplink transmissions travel via the same paths, the channel features $\mathbf{H}_{A}$ and $\mathbf{H}_{B}$ are almost different in FDD systems. 
Therefore, extracting reciprocal channel features for key generation in FDD-OFDM systems is challenging.

\begin{figure}[!t]
	\centering
	\includegraphics[width=\linewidth]{Figure/TL-KG-eps-converted-to.pdf}
	\caption{Deep learning-based key generation for FDD-OFDM systems.}
	\label{DL_KG}
\end{figure}

%Based on theorem \ref{theorem1}, 
Deep learning has been introduced for PKG in FDD-OFDM systems recently \cite{zhang2021secret,wan2021secret,hou2021secret,zhang2022deep}. This type of method uses deep learning techniques to map the uplink features to the downlink features, so that both parties can obtain the downlink features at the same time. As shown in Fig. \ref{DL_KG}, the deep learning-based key generation contains the following four steps.

% \subsubsection{Preparation Stage}
% In the preparation stage, Alice and Bob perform multiple channel estimations and feature extractions. Alice collects the downlink channel features sent by Bob, and combines the uplink channel features saved by herself to construct a training dataset. Then, Alice uses this dataset to train a deep learning model, which can then be directly used for key generation.

% \subsubsection{Key Generation Stage}
% \label{key generation stage}
%The key generation stage contains the following five steps: 

%\jz{step 1 and 2 are used in preparation stage too.}

\subsection{CSI Estimation}
Alice and Bob simultaneously send OFDM pilot signals to each other at carrier frequencies $f_{dl}$ and $f_{ul}$, and then independently estimate the channel CFR based on the received pilot signals, expressed as 
\begin{equation}
	\begin{split}
		\begin{cases}
			\hat{H}_{A}\left(f_{ul}, l\right)=H\left(f_{ul}, l\right)+E_{1}\left(f_{ul}, l\right) \\
			\hat{H}_{B}\left(f_{dl}, l\right)=H\left(f_{dl}, l\right)+E_{2}\left(f_{dl}, l\right)
		\end{cases}
		,
	\end{split}
\end{equation}
where $E_{1}\left(f_{ul}, l\right)$ and $E_{2}\left(f_{dl}, l\right)$ represent the channel estimation error, which can be modeled as additive white Gaussian noise (AWGN) with mean 0 and variance $\sigma_{E}^{2}$. After channel estimation, Alice and Bob get estimated CFRs $\mathbf{\hat{H}}_A=\{\hat{H}_{A}(f_{ul},0),...,\hat{H}_{A}(f_{ul},L-1)\}$ and  $\mathbf{\hat{H}}_B=\{\hat{H}_{B}(f_{dl},0),...,\hat{H}_{B}(f_{dl},L-1)\}$, respectively. \re{Different from \cite{yuan2020transfer} that used the channel impulse response (CIR) as channel information, we use the CFR to improve the key generation rate. Thus we could design a new neural network to fit our key generation problem.  }

%\jz{define $\mathbf{\hat{H}}_A$ }

\subsection{Feature Extraction}
Alice and Bob perform feature extraction to extract real-valued channel features $\mathbf{x}_A$ and $\mathbf{x}_B$ that are suitable for training the deep learning model and key generation. We can extract the magnitude and phase of CFR or directly separate the real and imaginary parts. In this paper, we extract the magnitude $\mathbf{x}'$ from $\mathbf{H}$ as the channel feature. \re{This is because multipath has a great impact on the phase of CFR, and it is difficult for the neural network to learn the mapping relationship between the phases of the uplink and downlink channels.}
% The real and imaginary parts are separated from $\mathbf{H}$ as
% \begin{equation}
% 	\begin{split}
% 		\mathbf{x}'\leftarrow(\mathfrak{R}(\mathbf{H}),\mathfrak{T}(\mathbf{H})),
% 	\end{split}
% \end{equation}
% where $\mathfrak{R}(\cdot)$ and $\mathfrak{T}(\cdot)$ denote the real and imaginary parts of the channel vector, respectively.

The dataset is then normalized so that the range of the samples is between 0 and 1. The minimum and maximum values of the vectors in each dimension of the training dataset are saved and used for min-max normalization, i.e.,
\begin{equation}
\begin{split}
\mathbf{x}=\frac{\mathbf{x}'-\min (\mathbf{x}'_{\text{train}})}{\max (\mathbf{x}'_{\text {train}})-\min (\mathbf{x}'_{\text {train}})}, \quad \mathbf{x} \in[0,1]^{n^d},
\end{split}
\end{equation}
where $\mathbf{x}$ is the normalized value of $n^d$ dimensions.
\re{After feature extraction, Alice and Bob get suitable channel features $\mathbf{x}_A$ and $\mathbf{x}_B$, respectively.}
%\jz{If this step is used in key generation too, you should not use $x_{train}$.}

\subsection{Feature Mapping (only Alice)}
Based on \cite{zhang2022deep}, there is a feature mapping function $\mathcal{F}$ in each given environment. Alice can use $\mathcal{F}$ to predict the estimated downlink features $\mathbf{x}_{A}^{B}$ from $\mathbf{x}_A$, which can be expressed as
\begin{equation}
\mathbf{x}_{A}^{B} = \mathcal{F} (\boldsymbol{\Omega}, \mathbf{x}_A),
\label{mapping6}
\end{equation}
where $\boldsymbol{\Omega}$ is the parameters for feature mapping, which can be obtained by deep learning techniques. Through this step, Alice and Bob are considered to have obtained highly similar features $\mathbf{x}_{A}^{B}$ and $\mathbf{x}_B$, respectively. How to get the optimal value of parameters to minimize the gap between $\mathbf{x}_{A}^{B}$ and $\mathbf{x}_{B}$ is essential to generating highly similar features.
%Since the uplink and downlink channels pass through the same propagation path and scattering cluster, it is experimentally shown in \cite{vasisht2016eliminating} that there is a transformation function that can map the channel to the underlying path. Furthermore, prior work has shown that it is possible to infer downlink channels from uplink channels \cite{alrabeian2019deep,bakshi2019fast,liu2021Fire}. In \cite{zhang2022deep}, It is proved that in a given environment, when the channel mapping function of possible user locations to antennas is bijective, there exists a feature mapping function $\mathcal{F}(\cdot)$ that can map the one frequency band features to another frequency band features, and the channel feature mapping function can be obtained by a simple deep learning model. This conclusion provides a theoretical basis for introducing deep learning into key generation.

% Since the uplink and the downlink transmissions travel the same propagation paths and suffer the same cluster in a given environment, there exists a channel mapping function between different frequency bands \cite{zhang2022deep}. The channel mapping function can be written as
% \begin{equation}
% 	\begin{split}
% 	\boldsymbol{\Psi}^{}_{f_{ul}\rightarrow f_{dl}} : \mathbf{H}(f_{ul}) \rightarrow \mathbf{H}(f_{dl}).
% 	\end{split}
% \end{equation}
%As shown in (\ref{CFR}), the channel mapping function can not be expressed as mathematical formulas, deep learning technology can be used to approach this mapping function. At first, we only consider a simple three-layers fully connected neural network (FNN) with one hidden layer.
% Since the CFRs are in complex domain and are not in a certain range, the value of CFRs could not be used to train the deep learning model directly. 

% Suppose that the feature extraction function $\boldsymbol{\xi}$ can obtain feature $\mathbf{x}$ after preprocessing $\mathbf{H}$, the inverse function of  $\boldsymbol{\xi}$ as $\boldsymbol{\xi}^{-1}$, the conclusion in \cite{zhang2022deep} can be expressed as the following theorem.
% \begin{theorem}
% 	For any given error $\varepsilon>0$, there exists a positive constant $M$ large enough such that
% 	\begin{equation}
% 	\begin{split}
% 	\sup_{\boldsymbol{\mathbf{x}}\in\mathbb{H}} \parallel \textbf{NET}_M(\mathbf{x}(f_{ul}),\boldsymbol{\boldsymbol{\Omega}})-\boldsymbol{\Psi}^{'}_{f_{ul}\rightarrow f_{dl}}(\mathbf{x}(f_{ul})) \parallel \leq \varepsilon,\\
% 	\mathbb{H}=\{\mathbf{x}(f_{ul})\},
% 	%\subseteq \mathbb{R}^{2L},
% 	\end{split}
% 	\end{equation}
% where the channel feature mapping function $\boldsymbol{\Psi}^{'}_{f_{ul}\rightarrow f_{dl}} =\boldsymbol{\xi}_{f_{dl}} \circ \boldsymbol{\Psi}_{f_{ul}\rightarrow f_{dl}} \circ \boldsymbol{\xi}_{f_{dl}}^{-1} : \mathbf{x}(f_{ul}) \rightarrow \mathbf{x}(f_{dl})$, $\textbf{NET}_M(\mathbf{x}(f_{ul}))$ is the output of a feedforward neural network (FNN) with only one hidden layer. $\mathbf{x}(f_{ul})$, $\boldsymbol{\boldsymbol{\Omega}}$ and $M$ denote the input data, network parameters, and the number of hidden units, respectively.
% \label{theorem1}
% \end{theorem}


%However, as the model may can not be used in other environments or a dynamic environment. This challenge can be formulated by a DTL problem and a meta-learning problem that leverage existing knowledge to improve model performance in new environments. 

\subsection{Key Establishment}
Alice and Bob use obtained features to generate keys, including quantization, information reconciliation and privacy amplification \cite{li2019physical}. We use a Gaussian distribution-based quantization method with guard-band proposed in \cite{zhang2022deep} to get the initial keys $\mathbf{Q}_A$ and $\mathbf{Q}_B$. Denote the probability of the channel features $\mathbf{x}$ as a definite Gaussian distribution $\mathcal{N}_Q=\mathcal{N}(\mu,\sigma^2)$, where $\mu$ is the mean of vector $\mathbf{x}$, $\sigma$ is the standard deviation of vector $\mathbf{x}$, and $F^{-1}$ as the inverse of the cumulative distribution function (CDF) of $\mathcal{N}_Q$. The values between 0 and $F^{-1}(0.5-\varepsilon)$  are quantized as 0, and the values between $F^{-1}(0.5+\varepsilon)$ and 1 are quantized as 1.
The $\varepsilon \in (0,0.5)$ is defined as the quantization factor, and the values between $F^{-1}(0.5-\varepsilon)$ and $F^{-1}(0.5+\varepsilon)$ are discarded. In order to further improve the randomness of generated keys, Alice and Bob share the same random number seed to generate a random vector, and perform a random permutation on $\mathbf{Q}_A$ and $\mathbf{Q}_B$.

Information reconciliation and privacy amplification methods are then adopted to make Alice and Bob agree on the same key and remove any potential information leakage~\cite{li2019physical}. 
\re{In general, we can correct 25\% wrong bits of the initial keys. When the channel reciprocity is too poor and two parties cannot get similar channel features, the initial keys after quantization may have more than 25\% wrong bits. Even if the wrong bits are less than 25\% of the total keys, the larger wrong bits will cause a higher cost in information reconciliation. 
In this paper, we focus on improving channel reciprocity in FDD-OFDM systems, because it is essential to the success of key generation.}
%The research purpose of this paper is to improve the channel reciprocity in the FDD system, thus this paper only compares the performance of the initial keys after quantization and does not carry out the steps of information reconciliation and privacy amplification.

\section{Problem Formulation and Algorithm Overview}
\label{system overview}

Among the four steps introduced in Section~\ref{Preliminary}, feature mapping is the crucial step for key generation between Alice and Bob. Therefore, this paper focuses on how to use deep learning techniques to quickly and efficiently obtain feature mapping functions $\mathcal{F}$ in multiple environments.


%In this section, we first introduce the key generation problem in multiple environments, then formulate it as a learning-based problem and give an overview of the proposed algorithms.

\subsection{Problem Statement}\label{Problem Formulation}
The performance of generated keys depends on the deep learning model. The existing works have verified the good fitting and generalization performance of the deep learning model to obtain the feature mapping function $\mathcal{F}$ in a certain environment \cite{zhang2021secret,wan2021secret,hou2021secret,zhang2022deep}. 
However, when the environment changes, the parameters of $\mathcal{F}$ are also affected by the environment, and the training samples and the actual samples of the deep learning model no longer obey a uniform distribution, which will lead to poor performance of the parameters in the new environment and even invalidate the effect of feature mapping. 

%However, when the environment changes, the parameters of $\mathcal{F}(\cdot)$ also change, which causes this kind of method may suffer from the problem that the training samples are not in the same distribution as the actual samples, and thus the performance of the deep learning model will be greatly reduced. 


As shown in Fig. \ref{DTL_se}, suppose a user is in the environment(E)1, a deep learning model 1 can be trained to get the parameters $\boldsymbol{\Omega}$ for feature mapping and key generation between the BS and the user in this given environment. However, when the user moves to other environments, such as E2 and E3, the training samples of model 1 and actual samples in the new environment no longer obey the same distribution, resulting in the performance of the pre-trained deep learning model being degraded or even invalid. 

\begin{figure}[!t]
	\centering
	\includegraphics[width=0.8\linewidth]{Figure/DTL_2-eps-converted-to.pdf}
	\caption{Deep learning-based PKG in multi-environments. }
	\label{DTL_se}
\end{figure}

%To show the above problem, we introduce the \textit{direct algorithm} as the benchmark, which only includes the training stage and testing stage. Assume that the training dataset is a combination of datasets collected from $E_S$ source environments. The testing datasets are $\{\mathbb{D}_{T}(e)\}_{e=1}^{E_T}$ from $E_T$ target environments. In the training phase, we use the training data to minimize the Loss function in (\ref{loss}) to optimize the deep learning model. In the testing phase, deep learning model performance is directly evaluated using data from new environments without adaptation. The simulation and experimental results in Section \ref{simulation} and Section \ref{experient} also prove that the performance of the key generated by the direct algorithm in the new scenario is poor and cannot meet the actual needs.

A simple way to solve this problem is to re-collect the data and re-train the model for each new environment. However, training a model requires a lot of training data and training resources, which is unacceptable for practical applications. Therefore, this paper aims to address this problem and formulate it as a learning-based problem to more efficiently learn feature mapping functions in new environments using known knowledge in the source environment.

%In this section, we first prove the possibility of using deep learning to construct reciprocal channel features in FDD-OFDM systems and introduce the deep learning-based key generation. Then, we formula key generation problem in multi-environments as a learning-based problem and give the system overview.



\subsection{Learning-based Problem for PKG}\label{DTL_problem}
Assume that there are data in $E$ wireless scenarios, and the uplink and downlink channel characteristics in the $e^{th}$ environment are defined as $\mathbf{x}_A^e$ and $\mathbf{x}_B^e$ respectively. According to \cite{nguyen2021transfer}, the "domain" and "task" in the $e^{th}$ environment are defined as following:

\begin{definition}[Domain]
The domain $\mathcal{D}(e)$ is composed of the feature space $\mathcal{X}^e$ and the marginal probability distribution $P({\mathbf{x}_A^e})$, i.e., $\mathcal{D}(e)=\{\mathcal{X}^e,P({\mathbf{x}_A^e})\}$. And the symbol $\mathcal{X}^e$ denotes an instance set, which is defined as all possible uplink
channel features $\mathbf{x}_A^e$, i.e., $\mathbf{x}_A^e \in \mathcal{X}^e$.
\end{definition}


\begin{definition}[Task]
The task $\mathcal{T}(e)$ is composed of the label space $\mathcal{Y}^e$ and a decision function $f^e$, i.e., $\mathcal{T}(e)=\{\mathcal{Y}^e,f^e\}$. And the symbol $\mathcal{Y}^e$ denotes an instance set, which is defined as all possible uplink
channel features $\mathbf{x}_B^e$, i.e., $\mathbf{x}_B^e \in \mathcal{Y}^e$. In other words, the task $\mathcal{T}(e)$ is the feature mapping from uplink to downlink.
\end{definition}

In a certain environment (domain $\mathcal{D}_{SE}$ and task $\mathcal{T}_{SE}$), the decision function $f^e$  can be obtained by model training. According to \cite{zhang2022deep}, the decision function $f^e$ can be considered as the feature mapping function $\mathcal{F}^e$ in the $e^{th}$ environment. Trained networks can act as the feature mapping function to achieve the feature mapping for key generation. However, when in a new environment (domain $\mathcal{D}_{TE}$ and task $\mathcal{T}_{TE}$), the feature mapping function $\mathcal{F}$ will change, and the performance of the trained model will be greatly reduced and cannot be used continuously.
%A simple method is to re-collect the training model in each environment, but this requires a lot of training resources and training data, which is difficult to meet in real-world applications.
%Therefore, the main problem to be solved in this paper is how to quickly obtain the feature mapping function $\mathcal{F}$ in the new environment (domain $\mathcal{D}_{TE}$ and task $\mathcal{T}_{TE}$) with a small amount of data and limited resource consumption to generate keys.

We formulate this problem as a learning-based problem, i.e., learning from the known environments enables fast key generation in multiple new environments using a small amount of data and limited resources, formally defined as follows. Given the number of source tasks $E_S$, the source domains $\{\mathcal{D}_{SE}(e)\}_{e=1}^{E_S}$, the source tasks$\{\mathcal{T}_{SE}(e)\}_{e=1}^{E_S}$, the number of source tasks $E_T$, the target domains $\{\mathcal{D}_{TE}(e)\}_{e=1}^{E_T}$ and the target tasks $\{\mathcal{T}_{TE}(e)\}_{e=1}^{E_T}$, the learning-based problem in this paper is to leverage knowledge (data and models) from $\{\mathcal{D}_{SE}(e)\}_{e=1}^{E_S}$ and $\{\mathcal{T}_{SE}(e)\}_{e=1}^{E_S}$ to learn new tasks $\{\mathcal{T}_{TE}(e)\}_{e=1}^{E_T}$ with a small amount of data and limited resource, where $\{\mathcal{T}_{TE}(e)\}_{e=1}^{E_T}\ne\{\mathcal{T}_{SE}(e)\}_{e=1}^{E_S}$ and $\{\mathcal{D}_{TE}(e)\}_{e=1}^{E_T}\ne\{\mathcal{D}_{SE}(e)\}_{e=1}^{E_S}$. 

\subsection{Algorithm Overview}
This paper proposes DTL-based and meta-learning-based feature mapping algorithms for key generation in multi-environments, elaborated in Section~\ref{DTL} and Section~\ref{meta}, respectively.
DTL and meta-learning aim to learn from source tasks to increase the generalization ability of the model under multi-task, and thus are two promising techniques for solving learning-based problems. 
Unlike learning functions $\mathcal{F}$ directly training the deep learning model in a given environment, these two algorithms include the training and adaptation stages, as shown in Fig.~\ref{learning_scheme}. 
\begin{itemize}
    \item Training stage: The two algorithms use datasets from known environments to train the model. DTL and meta-learning use different training methods, called pre-training and meta-training, respectively.
    \item  Adaptation stage: The two algorithms fine-tune the model using the datasets from the new environments, and then the fine-tuned model can be used for feature mapping and key generation.
\end{itemize}
\begin{figure}[!t]
	\centering
	\includegraphics[width=\linewidth]{Figure/learning_scheme-eps-converted-to.pdf}
	\caption{The proposed learning-based feature mapping scheme.}
	\label{learning_scheme}
\end{figure}


This paper considers a simple FNN as the basic network structure to learn the feature mapping function $\mathcal{F}$ in the proposed algorithms, as shown in Fig. \ref{learning_scheme}. The input of the network is the uplink channel feature vector $\mathbf{x}_A$ obtained by Alice, and the output of the network is the result of the cascade of $\mathbf{x}_A$ through nonlinear transformation. The network is used to map the features of the uplink and downlink, so the output of the network is considered to be the estimated vector $\mathbf{x}_A^B$ of the downlink channel feature vector $\mathbf{x}_B$, which also can be expressed as \eqref{mapping6}, i.e.,  $\mathbf{x}_A^B=\mathcal{F}(\boldsymbol{\Omega},\mathbf{x}_{A})$,
where $\boldsymbol{\Omega}$ is all parameters in this network to be trained for feature mapping. The FNN consists of $M$ layers, including one input layer, $M-2$ hidden layers and one output layer. The output $f_m(\mathbf{x})$ of the $m^{th}$ layer is a nonlinear transformation of the output of $m-1^{th}$ layer, which can be written as:
\begin{equation}
\begin{split}
f_m(\mathbf{x})=F_{A,m}(\mathbf{W}_m \mathbf{x}+\mathbf{b}_m), 2 \leq m  \leq M,
\end{split}
\end{equation}
where $F_{A,m}$, $\mathbf{W}_m$ and $\mathbf{b}_m$ are the activation function of $m^{th}$ layer, weight vector between $(m-1) ^{th}$ and $m^{th}$ layers and bias vector of $m^{th}$ layer, respectively. The rectified linear unit (ReLU) function commonly used in regression problems is selected as the activation function $F_{A,m}$ of the hidden layers, and the sigmoid function is selected as the activation function $F_{A,m}$ of the output layer.

The purpose of the network is to learn the band feature mapping, so we could train a network to minimize the difference between network output $\mathbf{x}_A^B$ and $\mathbf{x}_{B}$. Because it is a vector regression problem, we consider using the mean squared error (MSE) as the loss function of the neural network. The loss function is defined as:
\begin{equation}
\begin{split}
\mathcal{L}_{\mathbb{D}}(\boldsymbol{\Omega})=\frac{1}{N_{batch}}\sum_{i=0}^{N_{batch}-1}\|{\mathbf{x}_{A}^{B}}(i)-\mathbf{x}_{B}(i)\|_2^2,
\label{loss}
\end{split}
\end{equation}
where $\mathbb{D}=\{(\mathbf{x}_{A},\mathbf{x}_{B})\}_{i=0}^{N_{batch}-1}$ is a batch-sized training dataset, $N_{batch}$ is the batch size.
%, the superscript $(i)$ denotes the index of the $i$-th training sample.

%\textbf{DTL v.s. Meta-learning}: Both transfer learning and meta-learning-based feature mapping have same stages, but the methods used in the training stage are different. Transfer learning pre-trains the network on data from all source environments as a whole, while meta-learning learns optimal initialization parameters for the model from multiple tasks, where the feature mapping function in each source environment represent a separate task. The DTL algorithm minimizes the loss of the current model (only one) on all tasks, so the DTL algorithm hopes to find an initialization parameter that performs better on all current tasks. 
%The Meta-learning algorithm first uses the support dataset to minimize the loss function in each task, then uses the query dataset to minimize the loss sum of all tasks, and finally updates all model parameters with the model parameters obtained by minimizing the sum of loss functions of all tasks, which means that the performance of the model obtained after training to convergence under each task using the final initialization parameters obtained by meta-learning should still be as good as possible. Therefore, compared to the DTL algorithm, meta-learning algorithm makes better use of knowledge in multiple environments, and the resulting model initialization parameters have better generalization, which is also proved in the results in Section \ref{simulation}. \jz{combines this paragraph into Section IV and Section V. people won't under these contents here.}


%When the feature mapping function $\boldsymbol{\Psi}^{' }_{f_{ul}\rightarrow f_{dl}}$  is a non-linear function that can be learned by a deep learning model, the transfer learning task $<\{\mathcal{D}_{SE}(e)\}_{e=1}^{E_S}, \{\mathcal{T}_{SE}(e)\}_{e=1}^{E_S}, \{\mathcal{D}_{TE}(e)\}_{e=1}^{E_T}, \{\mathcal{T}_{TE}(e)\}_{e=1}^{E_T}>$ is a DTL task.

%According to Definition~\ref{deeptransferlearning}, the problem of key generation in multi-environments can be formulated as a DTL problem, i.e., using knowledge (data and models) from known environments to make it possible to quickly obtain deep learning models that can be used to generate keys in new environments.

%\subsection{Meta-Learning Problem for PKG}
%\label{meta_problem}
%
%Meta-learning, as another effective technique to deal with the task mismatch problem, learns the initialization values of the model from multiple tasks. Therefore, based on \cite{hospedales2020meta}, the problem that we aim to solve in this paper also can be formulated as a meta-learning problem, and the definition of meta-learning can be given as following: 
%\begin{definition}[Meta-learning]
%Given the number of source tasks $E_S$, the source domains $\{\mathcal{D}_{SE}(e)\}_{e=1}^{E_s}$, the source tasks$\{\mathcal{T}_{SE}(e)\}_{e=1}^{E_s}$, the target domains $\mathcal{D}_{TE}$ and the target tasks $\mathcal{T}_{TE}$, meta learning aims to leverage knowledge of $\{\mathcal{D}_{SE}(e)\}_{e=1}^{E_s}$ and $\{\mathcal{T}_{SE}(e)\}_{e=1}^{E_s}$ to learn how to learn new task $\mathcal{T}_{TE}$, where $\mathcal{T}_{TE}\ne\{\mathcal{T}_{SE}(e)\}_{e=1}^{E_s}$ and $\mathcal{D}_{TE}\ne\{\mathcal{D}_{SE}(e)\}_{e=1}^{E_s}$.
%\end{definition}
%
%\begin{remark}[DTL vs. Meta-learning]
%Generally, deep transfer learning needs a large amount of samples from the source task to train the model, while meta-learning requires data from multiple task, and the amount of samples in each task is small.
%When there are datasets from multiple environments and the amount of data in each environment is small, meta-learning is obviously an optimal choice compared to DTL. When there is a large amount of data in only one scenario, meta-learning techniques can be employed by dividing the source scenario into multiple task scenarios. The simulation results in Section \ref{simulation} show that meta-learning is still better than DTL in this case.
%\end{remark}

%\section{Feature Extraction for Key Generation}
%\label{framework}
%Firstly, we could process the estimated CFRs to obtain the suitable features for PKG in FDD systems. We verify the performance of the method proposed in \cite{zhang2022deep} in the outdoor scenario and find that the feature extraction method can not be used in the outdoor scenario. Based on this observation, we propose a general feature extraction framework, which can construct suitable features in the different scenarios.
%
%\subsection{Observation}
%
%\begin{figure}[!t]
%\centering
%
%\subfigure[The amplitude of CFR in the indoor scenario.]{
%\begin{minipage}[t]{0.5\linewidth}
%\centering
%\includegraphics[width=\linewidth]{Figure/Indoor_abs-eps-converted-to.pdf}
%%\caption{fig1}
%\label{A}
%\end{minipage}%
%}%
%\subfigure[The real and imaginary parts of CFR in the indoor scenario.]{
%\begin{minipage}[t]{0.5\linewidth}
%\centering
%\includegraphics[width=\linewidth]{Figure/Indoor_RI-eps-converted-to.pdf}
%%\caption{fig2}
%\label{B}
%\end{minipage}%
%}
%
%\subfigure[The amplitude of CFR in the outdoor scenario.]{
%\begin{minipage}[t]{0.5\linewidth}
%\centering
%\includegraphics[width=\linewidth]{Figure/Outdoor_abs-eps-converted-to.pdf}
%%\caption{fig2}
%\label{C}
%\end{minipage}
%}%
%\subfigure[The real and imaginary parts of CFR in the outdoor scenario.]{
%\begin{minipage}[t]{0.5\linewidth}
%\centering
%\includegraphics[width=\linewidth]{Figure/Outdoor_RI-eps-converted-to.pdf}
%%\caption{fig2}
%\label{D}
%\end{minipage}
%}%
%
%\centering
%\caption{The different features in the indoor and outdoor scenarios.}
%\label{compare}
%\end{figure}
%
%
%In \cite{zhang2022deep}, the features used for key generation are the real and imaginary parts of the CFR, and simulations only verify the performance in the indoor scenario. This paper further collects data in the outdoor scenario to verify the performance and finds that the same feature extraction method is no longer suitable for use in the outdoor scenario. 
%
%As shown in Fig. \ref{A} and \ref{B}, in indoor scenario, the channel multipath and scatterer are not abundant enough, and the amplitude fluctuation of the channel is not obvious enough to represent the surrounding environment, so it is difficult for the deep learning model to obtain the feature mapping function. While the real and imaginary parts of the channel include the amplitude and phase information of the channel, and the fluctuations are also more obvious. Therefore, in the indoor environment, the real and imaginary parts of the CFR are selected as features for generating keys, which also has two advantages. One is that the features with obvious fluctuations can improve the randomness of the generated key, and the other is that quantifying the real and imaginary parts separately can improve the KGR.
%
%In the outdoor scenario, the channel multipath as well as the scattering environment is more complex. As shown in the Fig. \ref{C} and \ref{D}, the fluctuations of the channel are more intense. In this case, although the amplitude and phase of the channel represent more complete channel information, the deep learning model is hard to learn such a complex channel environment with a limited dataset. Therefore, in the outdoor scenario with complex scattering, we choose to let the deep learning model learn only part of the environment, i.e., learn the mapping relationship of channel amplitudes between different frequency bands.
%%in the indoor scenario, the channel multipaths and scatterers are not abundant enough,  the variation of channel amplitudes is not significant enough for deep learning models to obtain mapping relationships between waveforms that do not vary much. Therefore, in the indoor environment, the real and imaginary parts of CFR are selected as the features for generating keys, which has two advantages. One is that features with significant fluctuations can improve the randomness of the generated keys, and the other is that quantizing the real and imaginary parts separately can improve the KGR. 
%
%%In the outdoor scenario, the channel environment is more complex, and the amplitude and phase changes are more obvious, resulting in excessive fluctuations of the real and imaginary parts of the superimposed CFR, and the deep learning model is unable to learn the mapping between the waveforms with excessive changes. Meanwhile, the variability of channel amplitudes in outdoor scenes is sufficient, so the amplitude of the CFR should be selected as the features for key generation.
%
%%in the indoor scenario, the channel multipath, scatterers, etc. are not rich enough, the change of the channel amplitude of the channel is not obvious, and it is difficult for the deep learning model to learn the mapping between the waveforms with little change. Therefore, in the indoor environment, the real and imaginary parts of CFR are selected as features to generate keys, which has two advantages. The first is that the features with obvious fluctuations can improve the randomness of the keys, and the second is to use CFR separately. Quantizing the real and imaginary parts can improve the key generation rate. In outdoor scenes, the channel environment is more complex, and the changes in amplitude and phase are more obvious, resulting in excessive fluctuations in the real and imaginary parts of the superimposed CFR, and it is difficult for the deep learning model to learn the mapping between the waveforms with excessive changes. At the same time, the change of the channel amplitude in the outdoor scene is already obvious, so the amplitude of the CFR should be selected as a feature for key generation. 
%
%In summary, according to different scenarios, different feature extraction methods should be selected to obtain the most suitable features for band mapping and key generation.
%
%\subsection{The General Feature Extraction Framework}
%
%\begin{figure}[!t]
%	\centering
%	\includegraphics[width=\linewidth]{./Figure/Feature_extraction.pdf}
%	\caption{The general feature extraction framework, including two steps, i.e., realization and normalization. }
%	\label{feature_extraction}
%\end{figure}
%Based on the observation, we proposed a general feature extraction framework, as shown in Fig. \ref{feature_extraction}. This framework includes two steps, namely realization and normalization, where the appropriate realization method is chosen according to the degree of fluctuation of different features.
%
%\subsubsection{Realization}
% The realization have two methods. The first method is to separate real and imaginary parts from $\mathbf{H}$, i.e.,
%\begin{equation}
%\begin{split}
%\mathbf{x}^{(1)}\leftarrow(\mathfrak{R}(\mathbf{H}),\mathfrak{T}(\mathbf{H})),
%\end{split}
%\end{equation}
%where $\mathfrak{R}(\cdot)$ and $\mathfrak{T}(\cdot)$ denote the real and imaginary parts of a matrix, vectors or scales, respectively.
%Another method is to calculate the amplitude of $\mathbf{H}$, i.e.,
%\begin{equation}
%\begin{split}
%\mathbf{x}^{(1)}\leftarrow ||\mathbf{H}||_2,
%\end{split}
%\end{equation}
%where $\|\cdot\|_2$ denotes the $L_2$ norm. 
%
%\begin{remark}
%These two methods are suitable for different wireless environments, when the wireless environment is complex, it is suitable to use method 1, and when the wireless environment changes slowly, it is suitable to use method 2. In practise, we should try these two methods to observe the degree of fluctuation of the features to choose the most suitable method.
%\end{remark}
%
%It should be emphasized that the two realization methods are used in this paper in the indoor and outdoor scenarios, respectively. In practice, these two methods can be tried in many different scenarios, depending on the degree of channel variation in the real environment.
%%We could try these two methods and choose the most suitable method based on the fluctuation of the features.
%
%\subsubsection{Normalization}
%Normalization is commonly used to normalize the dataset so that the range of the dataset is between 0 and 1. The minimum and maximum values of the vector s in each dimension after realization using the training dataset are saved for min-max normalization,
%\begin{equation}
%\begin{split}
%\mathbf{x}=\frac{\mathbf{x}^{(1)}-\min (\mathbf{x}_{\text{train}}^{(1)})}{\max (\mathbf{x}_{\text {train}}^{(1)})-\min (\mathbf{x}_{\text {train}}^{(1)})}, \quad \mathbf{x} \in[0,1]^{n^d},
%\end{split}
%\end{equation}
%where $\mathbf{x}$ is the normalized value of $n^d$ dimensions.
%
%With these two steps, we can get features with values in the range of 0 to 1. The processed features facilitate the subsequent learning of deep learning models.

\section{DTL-Based Feature Mapping}\label{DTL}
Based on the learning-based problem formulated in Section~\ref{DTL_problem}, this section proposes a DTL-based feature mapping to achieve key generation in new environments for FDD-OFDM systems. 
%\re{Introducing the DTL algorithm before proposing the later algorithm can first help readers understand the algorithm proposed later clearly, and then comparing the differences between the two algorithms can help us have a deeper understanding of the proposed algorithms.}
DTL transfers knowledge from the source environment to the target environment, so that the network in the target environment can achieve a better learning effect. In general, datasets in the source environments are abundant, while datasets in the target domains are small, so most DTL algorithms use datasets from source tasks to pre-train the model and then fine-tune it under a new task~\cite{nguyen2021transfer}. Like these works, in our proposed DTL-based feature mapping, we use the datasets from the source environments to pre-trained a model and then use a small number of samples to fine-tune the pre-trained model to obtain a model with good performance in the new environment.

\subsection{Definition of Dataset}
%Each task represents a frequency band feature mapping for Alice in a given environment.
%Assume that the original datasets $\{\mathbb{D}_{OS}(e)\}_{e=1}^{E_S}$ is collected from $E_S$ source environments, where the dataset $\mathbb{D}_{OS}(e)=\{(\mathbf{H}_A^{(n)}(e),\mathbf{H}_B^{(n)}(e)) \}_{n=1}^{N_{S}}$ includes $N_{S}$ samples in the $e^{th}$ environment, and the dataset after feature extraction as 
Assume that the source datasets $\{\mathbb{D}_{S}(e)\}_{e=1}^{E_S}$ is collected from $E_S$ source environments, where the dataset $\mathbb{D}_{S}(e)= \{(\mathbf{x}_A^{(n)}(e),\mathbf{x}_B^{(n)}(e))\}_{n=1}^{N_S}$ includes $N_{S}$ samples in the $e^{th}$ environment. 
Furthermore, it is necessary to collect datasets in multiple target environments to evaluate the performance of the algorithm. Assume that the target datasets $\{\mathbb{D}_{T}(e)\}_{e=1}^{E_T}$ from $E_T$ target environments, where the dataset in the $e^{th}$ environment $\mathbb{D}_{T}(e)=\{( \mathbf{x}_A^{(n)}(e),\mathbf{x}_B^{(n)}(e))\}_{n=1}^{N_T}$ includes $N_{T}$ data samples.

%Denote the original dataset in the source environments $\mathbb{D}_{OS}=\{(\mathbf{H}_A^{(n)},\mathbf{H}_B^{(n)})\}_{n=1}^{N_{S}}$, including $N_{S}$ samples, and the dataset after feature extraction as $\mathbb{D}_{S}=\{(\mathbf{x}_A^{(n)},\mathbf{x}_B^{(n)})\}_{n=1}^{N_{S}}$. Denote the original dataset in $E_T$ target environments as $\{\mathbb{D}_{OT}(e)\}_{e=1}^{E_T}$, where the dataset of $e^{th}$ environment as $\mathbb{D}_{OT}(e)=\{(\mathbf{H}_A^{(n)}(e),\mathbf{H}_B^{(n)}(e))\}_{n=1}^{N_{T}}$, including $N_{T}$ samples, and the dataset after feature extraction as $\mathbb{D}_{T}(e)=\{(\mathbf{x}_A^{(n)}(e),\mathbf{x}_B^{(n)}(e))\}_{n=1}^{N_T}$.

In the DTL algorithm, the datasets $\{\mathbb{D}_{S}(e)\}_{e=1}^{E_S}$ from all source environments are considered as a whole as the training dataset $\mathbb{D}_{Tr}$. The dataset $\mathbb{D}_{T}(e)$ in the target $e^{th}$ environment divides into adaption dataset $\mathbb{D}_{Ad}(e)=\{(\mathbf{H}_A^{(n)}(e),\mathbf{H}_B^{(n)}(e))\}_{n=1}^{N_{Ad}}$ and testing dataset $\mathbb{D}_{Te}(e)=\{(\mathbf{H}_A^{(n)}(e),\mathbf{H}_B^{(n)}(e))\}_{n=1}^{N_{Te}}$, where $N_{Ad}+N_{Te}=N_T$.

%\jz{too many symbols here, can you simplify them? OS, OT, $\mathbb{D}_{S}$, $\mathbb{D}_{T}$}


% \begin{algorithm}[!t]
% \algsetup{linenosize=\small} \small
%     \caption{\label{TL}The DTL algorithm for key generation in FDD-OFDM systems \jz{remove the algorithm; combine the content into the text.}} 
%     \begin{algorithmic}[1]
%         \REQUIRE ~~\\ 
%         The training dataset in a source environment: $\mathbb{D}_{Tr}$, 
%         the adaption dataset in target environments: $\{\mathbb{D}_{Ad}(e)\}_{e=1}^{E_T}$,
%         the testing dataset in target environments: $\{\mathbb{D}_{Te}(e)\}_{e=1}^{E_T}$,
%         learning rate: $\gamma $,
%         batch size: $N_{batch}$,
%         the number of the gradient update in fine-tuning stage: $G_{Ad}$.
%         \ENSURE ~~\\ 
%         The trained parameters of pre-trained model: $\Omega$,        
%         the trained parameters in each target environment: $\Omega_e$,
%         Initial keys: $K_A$ and $K_B$.
% %        the predicted downlink features: $\hat{\mathbf{x}}_B$,
% %        the average NMSE of target environments: $\mathrm{NMSE}$.
        
%     \STATE \textbf{\textit{Pre-training stage in a source environment}}
%     \STATE Randomly initialize the network parameters $\Omega $;
%     \FOR{t=1,...}
%     \STATE Randomly select $N_{batch}$ samples from $\mathbb{D}_{Tr}$ to construct $\mathbb{D}_{TrB}$;
%     \STATE Update $\Omega$ using the ADAM \cite{kingma2014adam} algorithm ( learning rate $\gamma $) to minimize $\mathcal{L}_{\mathbb{D}_{TrB}}(\boldsymbol{\Omega})$;
%     \ENDFOR
    
% %    \STATE Initialize $\mathrm{NMSE}_{total}\longleftarrow 0$;
%     \FOR{ $e=1,...,E_T$ }
%     \STATE \textbf{\textit{Fine-tuning stage in the target environment}}
%     \STATE Initialize the network parameters $\Omega_e \longleftarrow \Omega$;
%     \FOR{$j =1 ,..., G_{Ad}$}
%     \STATE Randomly select $N_{batch}$ samples from $\mathbb{D}_{Ad}(d)$ to construct $\mathbb{D}_{AdB}$;  
%     \STATE Update $\Omega_e$ using the ADAM algorithm ( learning rate $\gamma $) to minimize $\mathcal{L}_{\mathbb{D}_{AdB}}(\boldsymbol{\Omega_e})$;
%     \ENDFOR
    
%     \STATE \textbf{\textit{Key generation stage in the target environment}}
%     \STATE Alice and Bob set pilots to each other simultaneously.
%     \STATE Alice and Bob perform channel estimation and feature extraction.
%     \STATE Alice predicts the downlink features $\hat{\mathbf{x}}_B$ using Eq. (\ref{predict});
%     \STATE Alice and bob quantize the features to obtain the initial keys $K_A$ and $K_B$;
% %    \STATE Information reconciliation and privacy amplification;
% %    \STATE Calculate $\mathrm{NMSE}(e)$ using Eq. (\ref{NMSE});
% %    \STATE $\mathrm{NMSE}_{total} \longleftarrow  \mathrm{NMSE}_{total}+\mathrm{NMSE}(e)$;
%     \ENDFOR 
% %    \STATE $\mathrm{NMSE} \longleftarrow  \mathrm{NMSE}_{total} /E_T$;
%     \end{algorithmic}
% \end{algorithm}

\subsection{Training (Pre-training) Stage}

The pre-training stage trains the model using dataset $\{\mathbb{D}_{S}(e)\}_{e=1}^{E_S}$ from the source environments to minimize the loss function $\mathcal{L}_{\mathbb{D}_{Tr}}(\boldsymbol{\Omega})$. 

% \begin{figure}[!t]
% 	\centering
% 	\includegraphics[width=\linewidth]{Figure/Network-eps-converted-to.pdf}
% 	\caption{Network architecture. }
% 	\label{Network}
% \end{figure}

In each batch, $N_{batch}$ samples are randomly selected from $\mathbb{D}_{Tr}$ to construct a batch training dataset and then ADAM \cite{kingma2014adam} optimizer is used to optimize the parameters of the model. When the performance of the model tends to be constant or the number of iterations reaches the upper limit, the parameters $\boldsymbol{\Omega}$ of the pre-trained model are obtained.

\subsection{Adaption Stage}
\label{adaption}
For the $e^{th}$ target environment, the parameters $\boldsymbol{\Omega}$ of the pre-trained model are used to initialize the network model parameter $\boldsymbol{\Omega}_e$ in the target environment. Then the parameter $\boldsymbol{\Omega}_e$ is optimized using the adaption dataset $\mathbb{D}_{Ad}(e)$ in the target environment to minimize $\mathcal{L}_{\mathbb{D}_{Ad}}(\boldsymbol{\boldsymbol{\Omega}})$. When the performance of the model tends to be constant or the number of iterations reaches the upper limit, the parameters $\boldsymbol{\Omega}_e$ of the model in a new environment are obtained.

%To evaluate the performance of proposed algorithm, we calculate the NMSE, KER and KGR in the $e^{th}$ scenario using the testing dataset $\mathbb{D}_{Te}(e)$. 

After repeating the adaption stage in $E_T$ target environments, we can obtain the parameter $\{\boldsymbol{\Omega}_e\}_{e=1}^{E_T}$ in the target environments.
After this, the network parameter $\boldsymbol{\Omega}_e$ is fixed, and the network can be directly used in the feature mapping step in the target environment. Two users, Alice and Bob, follow the steps in Section~\ref{Preliminary} for key generation, where Alice uses the deep learning model with parameter $\boldsymbol{\Omega}_e$  for feature mapping.

We also calculate the average values of Normalized Mean Square Error (NMSE), KER, and Key Generation Rate (KGR) using the testing dataset $\{\mathbb{D}_{Te}(e)\}_{e=1}^{E_T}$ in target environments to evaluate the performance of the proposed algorithm.

%\begin{remark}
%The DTL algorithm optimizes the entire network in the adaption stage. Another method is to fix the parameters of the first few layers of the network, and only optimize the latter layers of the network structure. While the latter approach reduces the time consumption of the adaptation stage, it will also reduce the performance of the network after fine-tuning~\cite{zeng2021downlink}. In addition, compared to the 41 minutes of optimizing only 1-layer network in the \cite{zeng2021downlink}, the 37 seconds used in the adaption stage in our algorithm is very small, and this cost is acceptable. For key generation, obtaining a model with better performance to generate an initial key with higher reciprocity can reduce the consumption of subsequent information reconciliation, which is cost-effective from a long-term perspective.
%\end{remark}

\section{Meta-Learning-Based Feature Mapping}
\label{meta}
To better leverage knowledge from the source environments, this section proposes a meta-learning-based feature mapping. Most existing meta-learning algorithms are problem-specific. In order to eliminate the limitation of the model architecture on the application of meta-learning, a model-agnostic meta-learning (MAML) algorithm was proposed in \cite{finn2017model}. The goal of the algorithm is to achieve adaptation by alternately learning the parameter initialization of the model between the intra-task process and the cross-task process \cite{thrun1998learning}. %Moreover, unlike the DTL technique, the MAML algorithm emphasizes learning the optimal model initialization parameters under multiple tasks to achieve optimal performance under new tasks .
Different from the DTL algorithm, the meta-learning algorithm requires training the model from multiple source tasks and aims to learn the best model initialization parameters through intra-task and cross-task updates. More importantly, unlike the DTL algorithm that emphasizes performance on current tasks, the meta-learning algorithm focuses more on the performance of new tasks.

\subsection{Definition of Dataset}
%Since meta-learning requires learning model initialization from multiple tasks, datasets need to be collected from multiple source environments. 
%Assume that the dataset $\{\mathbb{D}_{OS}(e)\}_{e=1}^{E_S}$ is collected from $E_S$ source environments, where the dataset $\mathbb{D}_{OS}(e)=\{(\mathbf{H}_A^{(n)}(e),\mathbf{H}_B^{(n)}(e)) \}_{n=1}^{N_{S}}$ includes $N_{S}$ samples in the $e^{th}$ environment, and the dataset is obtained after feature extraction $\mathbb{D}_{S}(e)= \{(\mathbf{x}_A^{(n)}(e),\mathbf{x}_B^{(n)}(e))\}_{n=1}^{N_S}$. Furthermore, it is necessary to collect dataset in multiple target environments to evaluate the performance of the algorithm. Collect datasets $\{\mathbb{D}_{OT}(e)\}_{e=1}^{E_T}$ from $E_T$ target environments, where the data in the $e^{th}$ environment $ \mathbb{D}_{OT}(e)=\{(\mathbf{H}_A^{(n)}(e),\mathbf{H}_B^{(n)}(e))\} _{n=1}^{N_{T}}$ includes $N_{T}$ data samples, and the dataset is obtained after feature extraction $\mathbb{D}_{T}(e)=\{( \mathbf{x}_A^{(n)}(e),\mathbf{x}_B^{(n)}(e))\}_{n=1}^{N_T}$.

In meta-learning, the training dataset $\mathbb{D}_{Tr}$ is the combination of all datasets from the source environments $\{\mathbb{D}_{S}(e)\}_{e=1}^{ E_S}$, and the training dataset in each task is the dataset in each source environment. The $e^{th}$ task of training dataset $\mathbb{D}_{S}(e)$ needs to be divided into support dataset $\mathbb{D}_{Su}(e)$ and query dataset $\mathbb{D}_{Qu}(e)$, and $\mathbb{D}_ {Su}(e) \cap \mathbb{D}_{Qu}(e) = \emptyset$.
The dataset $\mathbb{D}_{T}(e)$ in the target environment is to be divided into adaptation dataset $\mathbb{D}_{Ad}(e)=\{(\mathbf{x}_A^ {(n)}(e),\mathbf{x}_B^{(n)}(e))\}_{n=1}^{N_{Ad}}$ and testing dataset $\mathbb{D} _{Te}(e)=\{(\mathbf{x}_A^{(n)}(e),\mathbf{x}_B^{(n)}(e))\}_{n=1 }^{N_{Te}}$, where $N_{Ad}+N_{Te}=N_T$.

% \begin{algorithm}[!t]
% \algsetup{linenosize=\small} \small
%     \caption{\label{meta-learning}The meta-learning algorithm for key generation in FDD-OFDM systems \jz{remove the algorithm; combine the content into the text.}} 
%     \begin{algorithmic}[1] 
%         \REQUIRE ~~\\  
%         The training support dataset: $\{\mathbb{D}_{Su}(e)\}_{e=1}^{E_S}$, 
%         the training query dataset:$\{\mathbb{D}_{Qu}(e)\}_{e=1}^{E_S}$, 
%         the adaption dataset: $\{\mathbb{D}_{Ad}(e)\}_{e=1}^{E_T}$,
%       the testing dataset: $\{\mathbb{D}_{Te}(e)\}_{e=1}^{E_T}$,
%         inner-task learning rate: $\alpha $, across-task learning rate: $\gamma $, batch size for meta-training: $E_{batch}$, batch size for meta-adaption: $N_{batch}$
%         the number of gradient update for inner-task training: $G_{Tr}$, the number of the gradient update in fine-tuning stage: $G_{Ad}$.
%         \ENSURE ~~\\ 
%         The trained parameters of pre-trained model: $\Omega$,        
%         the trained parameters in each target environment: $\Omega_e$,
%         Initial keys: $K_A$ and $K_B$.
% %        the predicted downlink features: $\hat{\mathbf{x}}_B$,
% %        the average NMSE of target environments: $\mathrm{NMSE}$
%     \STATE \textbf{\textit{Meta-training stage in the source environments}}
%     \STATE Initialize the network parameters $\Omega $;
%     \FOR{t=1,...}
%     \STATE Randomly select $E_{batch}$ environments form $E_S$ source environments;
%     \STATE Generate support dataset $\{\mathbb{D}_{Su}(e)\}_{e=1}^{E_{batch}}$ and query dataset $\{\mathbb{D}_{Qu}(e)\}_{e=1}^{E_{batch}}$;
%     \FOR{$e=1,...,E_{batch}$}
%     \STATE Initialize the network parameters $\Omega_{S,e} \longleftarrow \Omega$;
%     \FOR{$i=1,...,G_{Tr}$}
%     \STATE Update $\Omega_{S,e}$ using the Eq. (\ref{update}) or ADAM algorithm (learning rate $\alpha$);
%     \ENDFOR
%     \ENDFOR
%     \STATE Update $\Omega$ using ADAM algorithm ( leraning rate $\gamma$) to minimize $ \mathcal{L}_{total}(\Omega)$;
%     \ENDFOR
    
% %    \STATE Initialize $\mathrm{NMSE}_{total}\longleftarrow 0$;
%     \FOR{ $e=1,...,E_T$ }
%     \STATE \textbf{\textit{Adaption stage in the target environment}}
%     \STATE Initialize the network parameters $\Omega_e \longleftarrow \Omega$;
%     \FOR{$j =1 ,..., G_{Ad}$}
%     \STATE Randomly select $N_{batch}$ samples from $\mathbb{D}_{Ad}(e)$ to construct $\mathbb{D}_{AdB}$;  
%     \STATE Update $\Omega_e$ using the ADAM algorithm ( learning rate $\gamma $) to minimize $\mathcal{L}_{\mathbb{D}_{AdB}}(\boldsymbol{\Omega_e})$;
%     \ENDFOR
%     \STATE \textbf{\textit{Key generation stage in the target environment}}
%     \STATE Alice and Bob set pilots to each other simultaneously.
%     \STATE Alice and Bob perform channel estimation and feature extraction.
%     \STATE Alice predicts the downlink features $\hat{\mathbf{x}}_B$ using Eq. (\ref{predict});
%     \STATE Alice and bob quantize the features to obtain the initial keys $K_A$ and $K_B$;
% %    \STATE Predict the downlink features $\hat{\mathbf{x}}_B$ using Eq. (\ref{predict}); 
% %    \STATE Calculate $\mathrm{NMSE}(e)$ using Eq. (\ref{NMSE});
% %    \STATE $\mathrm{NMSE}_{total} \longleftarrow  \mathrm{NMSE}_{total}+\mathrm{NMSE}(e)$;
%     \ENDFOR 
% %    \STATE $\mathrm{NMSE} \longleftarrow  \mathrm{NMSE}_{total}/E_T$;
%     \end{algorithmic}
  
% \end{algorithm}



\subsection{Training (Meta-training) Stage}
During the meta-training phase, the goal of the meta-learning algorithm is to learn a network initialization that can effectively adapt to new tasks. The underlying network architecture used here is the same as used in DTL. First, the parameters $\boldsymbol{\Omega}$ are randomly initialized and then updated through two iterative processes, namely intra-task update and cross-task update. The network parameters of each source task are optimized within the intra-task update, and the global neural network is optimized within the cross-task update.

\subsubsection{Intra-task Update}
A batch of $E_{batch}$ tasks is randomly selected from $E_S$ environments in a batch.
The goal of each task is to optimize its own neural network parameters on its support dataset $\mathbb{D}_{Su}(e)$. The objective of each task is achieved by minimizing the loss function based on supervised learning. $\boldsymbol{\Omega}_{S,e}$ is initialized as the global network parameter $\boldsymbol{\Omega}$. The objective function of each task can be expressed as:
\begin{equation}
\begin{split}
\boldsymbol{\Omega}_{S,e}=\arg \min _{\boldsymbol{\Omega}_{S,e}} \mathcal{L}_{\mathbb{D}_{Su}(e)}\left(\boldsymbol{\Omega}_{S,e}\right), \quad e=1, \ldots, E_{batch},
\end{split}
\label{}
\end{equation}
where $\boldsymbol{\Omega}_{S,e}$ is the network parameter of the $e^{th}$ task in the source task set. 
In each task, $\boldsymbol{\Omega}_{S,e}$ is initialized to $\boldsymbol{\Omega}$, and is then updated with $G_{Tr}$ times of gradient descent, i.e.,
\begin{equation}
\begin{split}
\boldsymbol{\Omega}_{S, e} \leftarrow \boldsymbol{\Omega}_{S, e}-\alpha \nabla\mathcal{L}_{\mathbb{D}_{\mathrm{Su}}(e)}\left(\boldsymbol{\Omega}_{S, e}\right),
\end{split}
\label{update}
\end{equation}
where $\alpha$ is the learning rate between tasks. The $\boldsymbol{\Omega}_{S, e}$ also can be updated by ADAM optimizer \cite{kingma2014adam}.


The intra-task update only performs once. In the original MAML algorithm \cite{finn2017model}, intra-task updates were made also only once, but some literature proposed to increase the times of intra-task updates to improve the performance~\cite{yuan2020transfer}. This paper analyzes the impact of task update times on performance in Section \ref{The Impact of Hyper-parameters in Meta-learning}. The results show that the increase of $G_{Tr}$ has no obvious effect on performance, but will increase the training cost, thus we set $G_{Tr}$ to 1.

%In the original MAML algorithm, intra-task updates were made only once. And then some literatures proposed to increase the times of intra-task update to improve the performance. This paper analyzes the impact of task update times on performance in Section \ref{The Impact of Hyper-parameters in Meta-learning} and set $G_{tr}$ as 1.

\subsubsection{Cross-task Update}
The global network parameters $\boldsymbol{\Omega}$ are optimized based on the sum of the loss functions of all tasks in one batch. After the intra-task update, the loss function for all tasks in the batch can be estimated based on the related tasks and their query datasets $\{\mathbb{D}_{Qu}(e)\}_{e=1}^{E_{batch}}$. These loss functions can be added together to form the loss function used to optimize the global network parameters, i.e.
\begin{equation}
\begin{split}
 \mathcal{L}_{total}(\boldsymbol{\Omega})=\sum_{e=1}^{E_{batch}} \mathcal{L}_{\mathbb{D}_{Qu}(e)}\left(\boldsymbol{\Omega}_{S, e}\right).
\end{split}
\label{total}
\end{equation}
This loss function can also be minimized by optimizing $\boldsymbol{\Omega}$ by gradient descent or ADAM algorithm (learning rate $\beta$).

After the cross-task update is over, assign the updated $\boldsymbol{\Omega}$ to $\boldsymbol{\Omega}_{S,e}$, and then repeat the intra-task update and cross-task update until $ \mathcal{L}_{total}(\boldsymbol{\Omega})$ does not converge.  At this time, the parameter initialization of network learning is obtained, so that only a small number of samples can be adapted to the new environment.

It is clear that the training methods of the DTL algorithm and the meta-learning algorithm are almost completely different. In the DTL algorithm, the DTL algorithm minimizes the loss of the current model (only one) on all tasks, so the DTL algorithm hopes to find an initialization parameter that performs better on all current tasks. 
The meta-learning algorithm first uses the support dataset to minimize the loss function in each task, then uses the query dataset to minimize the loss sum of all tasks, and finally updates all model parameters with the model parameters obtained by minimizing the sum of loss functions of all tasks, which means that the performance of the model obtained after training to convergence under each task using the final initialization parameters obtained by meta-learning should still be as good as possible. Therefore, compared to the DTL algorithm, the meta-learning algorithm makes better use of knowledge in multiple environments, and the resulting model initialization parameters have better generalization, which is also proved in the results in Section \ref{simulation}.

\subsection{Adaption Stage}
This step is the same as the Section \ref{adaption}. We also use the fixed parameters $\{\boldsymbol{\Omega}_e\}_{e=1}^{E_T}$ for feature mapping and key generation to calculate evaluation metrics that can evaluate the performance of the proposed algorithm using the testing datasets $\{\mathbb{D}_{Te}(e)\}_{e=1}^{E_T}$ in the target environments.

%After repeating the adaption and key generation stages in $E_T$ target environments, we also calculate the average values of NMSE, KER and KGR in target environments using the testing dataset  to evaluate the performance of the proposed meta-learning algorithm.

%The proposed meta-learning algorithm is inspired by the MAML algorithm in \cite{finn2017model} and the applications of this algorithm in other fields. It is worth mentioning that the meta-learning algorithm proposed in this paper is different from other algorithms: 

%ii) the intra-task update and cross-task update are performed by ADAM algorithm. In the original MAML algorithm, while the proposed algorithm adopts the ADAM algorithm instead of SGD


\section{Theoretical Analysis of DTL and Meta-Learning}
\label{theoretical}
In this section, we first analyze channel differences in different environments, and then theoretically analyze which algorithm, i.e., DTL or meta-learning, may have better performance on this basis.

\subsection{Channel Difference Between Different Environments}
According to (\ref{CFR}), CFR is mainly affected by two factors, frequency and propagation environment. The previous work analyzed the influence of frequency in the same propagation environment \cite{zhang2022deep}. This paper mainly analyzes the channel gap in different propagation environments. The propagation environment refers to the physical environment in which the signal is transmitted, including communication distance, transmission medium, obstacles and other factors. In different propagation environments, during the transmission process, the signal reaches the receiving end through multiple paths with different transmission media, resulting in great changes in the phase and amplitude of the channel. In addition, since the phase of the channel may undergo various complex changes during signal transmission, such as phase mutations caused by multipath effects, the obtained channel amplitude will be more accurate in comparison. Therefore, this paper uses the channel amplitude as the channel feature for key generation.

We compare the data collected in the indoor and outdoor environments in reality, and the data collection process will be explained in Section~\ref{practical}. Kolmogorov-Smirnov test (K-S test) \cite{massey1951kolmogorov} is used to test whether the same subcarrier in two environments has the same data distribution. Assume that the $N_m$ sets of data measured on the $l^{th}$ subcarrier in indoor and outdoor environments are $\{H_{indoor}^{l,n}\}_{n=1}^{N_m}$ and $\{H_{outdoor}^{l,n}\}_{n=1}^{N_m}$, the test statistic (KS value) $K$ can be calculated as 
\begin{equation}
\begin{split}
K = \max\limits_{x}|\mathsf{F}_1(x) - \mathsf{F}_2(x)|,
\end{split}
\label{}
\end{equation}
%\jz{can you use a symbol to represent ECDF?}
where $\mathsf{F}_1(x)$ and $\mathsf{F}_2(x)$ are the empirical distribution functions (ECDFs) of the $\{H_{indoor}^{l,n}\}_{n=1}^{N_m}$ and $\{H_{outdoor}^{l,n}\}_{n=1}^{N_m}$, respectively. The p-value can be obtained by looking up the K-S test table. We have 900 samples in each subcarrier. At the Level of significance of 0.05, when the p-value is less than 0.04527, it is considered that two independent samples do not come from the same distribution. 
By performing the K-S test on all subcarriers in different environments, the p-values of all subcarriers are much less than 0.04527. Therefore, the data distribution on all subcarriers in different environments does not come from the same distribution. 
%\jz{this reads odd. Do you mean they don't have the same distribution?} \jz{do you have any numerical results for the KS test?}

\begin{figure}[!t]
	\centering
	\includegraphics[width=\linewidth]{Figure/KDE-eps-converted-to.pdf}
	\caption{Comparison of kernel density estimation in different environments. } 
 %\jz{what is the x-axis value, what density is it in y-axis} 
	\label{kernal}
\end{figure}
We further compare the kernel density estimation (KDE)~\cite{terrell1992variable} of values on the same subcarriers in different environments. 
%\jz{where did you mention the kernel density estimation functions? the readers won't know what is it.} 
KDE uses a kernel function (usually a Gaussian function) to smooth the empirical distribution of a set of data points to estimate the underlying probability density function. The output of the density function can be calculated by
\begin{equation}
\begin{split}
F_D(x) = \frac{1}{N_m b_w}\sum_{i=1}^{N_m} \mathcal{K}\left(\frac{x-x_i}{h}\right), 
\end{split}
\label{}
\end{equation}
where $x_i$ is the $i^{th}$ data point, $\mathcal{K}(u) = \frac{1}{\sqrt{2\pi}}e^{-\frac{u^2}{2}}$ is the kernel function, $b_w = 1.06\sigma N_m^{-1/5}$ is the bandwidth parameter, and $\sigma$ is the standard deviation of the sample data.

As shown in Fig. \ref{kernal}, the value distribution of the channel under different environments on the same subcarrier is basically completely different. This result also reflects the huge influence of the environment on the channel, so the model trained in one environment is difficult to use directly in the new environment.

\subsection{DTL v.s. Meta-Learning}
In order to better understand the DTL and meta-learning, we first analyze the loss function. The loss function in the training stage of DTL at the $t^{th}$ time step is calculated as
\begin{equation}
\begin{split}
&\mathcal{L}_{DTL}^{(t)}=\mathcal{L}_{\mathbb{D}_{tr}}\left(\boldsymbol{\Omega}^{(t-1)}\right),
\end{split}
\label{}
\end{equation}
where ${\mathbb{D}_{tr}}= \mathbb{D}_ {Su} \cup \mathbb{D}_{Qu}$.
According to (\ref{update}) and (\ref{total}), the loss function in the cross-task update of meta-learning at the $t^{th}$ time step is calculated as
\begin{equation}
\begin{split}
&\mathcal{L}_{total}^{(t)}=\sum_{e=1}^{E_{batch}} \mathcal{L}_{\mathbb{D}_{Qu}(e)}\left(\boldsymbol{\Omega}_{S, e}^{(t)}\right) \\
= &\sum_{e=1}^{E_{batch}}\mathcal{L}_{\mathbb{D}_{Qu}(e)}(\boldsymbol{\Omega}^{(t-1)}-\alpha \nabla\mathcal{L}_{\mathbb{D}_{\mathrm{Su}}(e)}\left(\boldsymbol{\Omega}_{S, e}^{(t-1)}\right)).
\end{split}
\label{}
\end{equation}

Through comparing the loss functions between DTL and meta-learning, we find that meta-learning not only takes into account the need to minimize the performance of the current query set but also considers the performance of the support set, while DTL directly considers all training set performance. This allows meta-learning to have better generalization capabilities and can better adapt to the data in the new environment whose distribution is different from the source dataset \cite{richa2023sharing}. According to the analysis in the previous section, the data distribution in different environments is completely different, so meta-learning can achieve better performance. This result is also verified in the following sections.

\re{We would like to emphasize that although the meta-learning algorithm performs better than the DTL algorithm in our simulation and experiment, the DTL still has the advantage of easy implementation and extension. Compared with the meta-learning algorithm, the DTL algorithm can be fine-tuned on the model of the current systems directly without a new pre-training process, and thus can directly extend the model currently trained in a single environment to multiple environments. }


\section{Simulation Evaluation}
\label{simulation}
In this section, we will first present the data generation and simulation setup. Then, we give the benchmarks, metrics and compare the performance of all algorithms.

\subsection{Simulation Setup and Dataset Generation}


In the simulation, we consider multiple environments in the outdoor scenario, which is constructed based on the accurate 3D ray tracing simulator Wireless InSite~\cite{Remcom}.
%The overview of the ray-tracing indoor scenario is illustrated in Fig. \ref{scenario_indoor}.  The antenna of the base station (Alice) is located in a small green box on the ceiling of the indoor corridor. The three maroon rectangles represent the possible positions of the user (Bob), and each room represents an environment. As Alice is in the corridor and Bob is located in the room, all channels are Non-line-of-sight (NLOS). The uplink and downlink frequencies are 2.4 GHz and 2.5 GHz, respectively. The number of OFDM subcarriers is 64 and the bandwidth is 20 MHz.
% \begin{figure}[!t]
% 	\centering
% 	\includegraphics[width=\linewidth]{Figure//scenario_urban-eps-converted-to.pdf}
% 	\caption{A overview of the ray-tracing indoor scenario. }
% 	\label{scenario_indoor}
% \end{figure}
An overview of the ray-tracing outdoor scenario is illustrated in Fig. \ref{scenario_urban}. The antenna of the base station (Alice) is located in a small green box with an outdoor height of 20 meters. The three maroon rectangles represent the possible positions of the user (Bob), and each rectangle represents an environment. %In addition, the base station is Alice, multiple users are the possible locations of Bob, and 
The uplink channel and the downlink channel work on channels with frequencies of 2.4 GHz and 2.5 GHz, respectively. The number of OFDM subcarriers is 128 and the bandwidth is 20 MHz. 
%We choose the first way of realization in indoor scenario and the second way of realization in outdoor scenario.
%\footnote{The simulation results show that the change of the CFR in the indoor scenario is relatively small, and the KGR can be improved by using the first way of realization. In the outdoor scenario, the CFR changes rapidly, and the feature generated by the second way of realization is difficult to learn by model.}
\begin{figure}[!t]
	\centering
	\includegraphics[width=\linewidth]{Figure/scenario_urban-eps-converted-to.pdf}
	\caption{A overview of the ray-tracing outdoor scenario. }
	\label{scenario_urban}
\end{figure}

Assuming that E1 is the source task environment and a total of 40,000 locations are collected. E2 and E3 are target task environments, and 5,000 locations are collected in each environment (80\% for adaptation and 20\% for testing). 
Since different environments are located in different areas, the scatterers and propagation paths are completely different, so the knowledge learned by the model is different, and the model trained in E1 may not be suitable for the new environment (E2 and E3). In response to this problem, this paper proposes two algorithms to use the collected data in E1 to obtain prior knowledge, so that the pre-trained model can quickly adapt to new environments (E2 and E3). 

A workstation with an Nvidia GeForce GTX 1660Ti GPU and an Intel Core I7-9700 CPU was used. This paper used Tensorflow 2.1 as the underlying framework of deep learning to build the network. The network parameters and some parameters in the training stage are shown in Table \ref{tab:4-setup}.
\begin{table}[!t]
\caption{Default Parameters of Proposed Algorithms} 
\label{tab:4-setup}
	\centering
	\begin{tabular}{|p{1.5cm}<{\centering}|p{3.6cm}<{\centering}| p{2.4cm}<{\centering}|}
		\hline
		& \bfseries Parameter & \bfseries Value  \\ \hline
	    \multirow{6}{*}{\shortstack{For All \\Algorithms}} &Number of neurons in hidden layers& (512,1024,1024,512)\\\cline{2-3}
	    &Batch size& 128\\\cline{2-3}
	    &Optimization & ADAM \cite{kingma2014adam} \\  \cline{2-3}
	    &Exponential decay rates for ADAM: ($\rho_1,\rho_2$) &(0.9,0.999)\\\cline{2-3}
	    &\re{Learning rate in Adaption Stage} &\re{1e-5} \\ \hline
% 		\bfseries Parameter & \bfseries Value \\ \hline
% 		Number of neurons in hidden layers& (512,1024,1024,512)\\\hline
% 		Batch size& 128\\\hline
% 		Optimization & ADAM \cite{kingma2014adam} \\ \hline
% 		Exponential decay rates for ADAM: ($\rho_1,\rho_2$) &(0.9,0.999)\\ \hline
 		\multirow{10}{*}{\shortstack{For\\ Meta-learning}} &Inner-task and across-task learning rate: $(\alpha, \beta)$& (1e-3,1e-3)\\\cline{2-3}
 		&The number of gradient update for inner-task training & 1\\\cline{2-3}
		&the number of the gradient update in fine-tuning and meta-adaption stages& 300\\\cline{2-3}
		&The number of source task in meta-learning& 400\\\cline{2-3}
 		&The number of samples in each source task& 100\\\hline
	\end{tabular}
\end{table}

\subsection{Benchmarks}
For comparison, we introduce two benchmarks, namely the direct algorithm and the joint dataset algorithm. All algorithms are explained below.
\begin{itemize}
\item[(1)] \re{\textit{Direct algorithm} represents the current deep learning-based key generation methods that ignore the feature mapping function changes in the multi-environments, which only include the training stage and testing stage. In the training phase, we use the training data from the source environment (E1) to minimize the loss function in (\ref{loss}) to optimize the deep learning model. In the testing phase, deep learning model performance is directly evaluated using data from new environments (E2 and E3) without adaptation. We test different model architectures in the recent works \cite{wan2021secret, zhang2022deep, chen2023physical}, and select the KGNet \cite{zhang2022deep} as our basic architecture.} %\jz{it might be better to introduce the so called direct algorithm in Section 3.1. You can introduce a conventional/classical deep learning approach, including two stages, namely training and testing. We should not assume all readers/reviewers know deep learning}
\item[(2)]  \textit{Joint dataset algorithm} combines all the data in E1 and part of the data in E2 or E3 to form a joint training dataset and then uses the model trained by the joint training dataset to test the performance in E2 and E3, respectively \cite{yuan2020transfer}.
\item[(3)]  \textit{DTL algorithm} uses the proposed DTL-based feature mapping in Section~\ref{DTL} for key generation to test the performances.
\item[(4)]  \textit{Meta-learning algorithm} uses the proposed meta-learning-based feature mapping in Section~\ref{meta} for key generation to test the performances.
\end{itemize}

\re{For the direct algorithm, we select the optimal architecture for key generation to show that the deep learning model cannot be directly used in multi-environments. For the joint dataset algorithm, we directly combine the dataset from the source environments and the target environment, which can show that using suitable algorithms to adopt new environments is compulsory.}

For a fair comparison, some default training parameters adopted in all algorithms are consistent. Furthermore, the datasets used for training and adaptation in transfer learning and meta-learning algorithms are of the same size. The 40,000 total training dataset used in the DTL algorithm is divided into 400 datasets with a sample size of 100 in the meta-learning algorithm to represent the data under multiple tasks. In each task, the numbers of samples in the support dataset and query dataset are both 50.
The training dataset used by the joint dataset algorithm is the combination of the training dataset and the adaptation dataset in the transfer learning and meta-learning algorithms.

\subsection{Evaluation Metrics}
We use the following metrics for performance evaluation.
\begin{itemize}
	\item \textit{NMSE} is used to evaluate the predictive accuracy of the network, which  is defined as
\begin{equation}
\begin{split}
\mathrm{NMSE}=E\left[\frac{\parallel{\mathbf{x}}_{A}^{B}-\mathbf{x}_B\parallel_2^2}{\parallel \mathbf{x}_{B}\parallel_2^2}\right],
\end{split}
\label{NMSE}
\end{equation}
where $E\left[\cdot\right]$ represents the expectation operation. 
	\item \textit{KER} is defined as the number of error bits divided by the number of total key bits.
	\item \textit{KGR} is defined as the number of initial key bits divided by the number of subcarriers. 
	\item \textit{Randomness} reveals the distribution of bit streams. The National Institute of Standards and Technology (NIST) statistical test \cite{rukhin2001statistical} is used for the randomness test for the generated keys.
\end{itemize}


\subsection{The Impact of Hyper-parameters in Meta-learning}
\label{The Impact of Hyper-parameters in Meta-learning}
The selection of the number of iterations $G_{Tr}$ in the task and the batch size $E_{batch}$ in the training phase are very important to the meta-learning algorithm. These two parameters are analyzed below.




For some tasks, the increase of $G_{Tr}$ can greatly improve the performance. For example, the work in~\cite{yuan2020transfer} sets $G_{Tr}$ to 3, which improves the downlink channel prediction accuracy in massive MIMO systems. At the same time, as $G_{Tr}$ increases, more memory and time resources are required for meta-learning training. Therefore, the value of $G_{Tr}$ should be determined comprehensively by weighing the consumed resources and performance. In this paper, $G_{Tr}$ is set as \{1, 2, 3, 4, 6, 8\} for learning, and tests are carried out in the outdoor environment respectively. The results are shown in Fig. \ref{Gtr_NMSE}. The results show that with the increase of $G_{Tr}$, the performance of the meta-learning algorithm does not improve, but basically stabilizes around a certain range. Therefore, in order to guarantee the minimum resource consumption, the $G_{Tr}$  is set to 1.
\begin{figure}[!t] 
    \centering 
    \includegraphics[width=\linewidth]{Figure/Gtr_NMSE_outdoor-eps-converted-to.pdf} 
    \caption{The NMSE performance comparison for different numbers of iterations $G_{Tr}$.}
    \label{Gtr_NMSE} 
\end{figure}



Reasonable selection of the batch size $E_{batch}$ in the training phase is also very important for the training effect. Since the choice of batch size $E_{batch}$ has nothing to do with the resource consumption of training, it is only necessary to focus on the training performance under different batch sizes. Fig.~\ref{Kb_NMSE} compares the NMSE performance under different batch sizes $E_{batch}$. The results show that the tested NMSE performance is getting better with the increase of $E_{batch}$ and reaches optimal when $E_{batch}=32$, which is used in the rest of the paper. %Therefore, in order to achieve optimal performance, the $E_{batch}$ is set to 32.
\begin{figure}[!t] 
    \centering 
    \includegraphics[width=\linewidth]{Figure/E_batch_NMSE_outdoor-eps-converted-to.pdf} 
    \caption{The NMSE performance comparison for different numbers of the batch size $E_{batch}$.}
    \label{Kb_NMSE} 
\end{figure}

\subsection{Performance of Reciprocal Features}

%\begin{figure}
%	\centering
%	\subfigure[Indoor corridor scenario.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{Figure/Gad_nmse-eps-converted-to.pdf}
%		\end{minipage}
%		\label{Gad_nmse}
%	}
%	\subfigure[Outdoor scenario.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{Figure/Gad_nmse_outdoor_new-eps-converted-to.pdf}
%		\end{minipage}
%		\label{Gad_nmse_outdoor}
%	}
%	\caption{The NMSE performance during adaption stage.}
%	\label{Gad_nmse_inout}
%\end{figure}



Fig. \ref{Gad_nmse} compares the NMSE performance of the four algorithms during the adaption stage in E2. Since the direct algorithm has no adaptation phase, it is set as a fixed value for its test results. The results show that the algorithms based on transfer learning and meta-learning are better than the direct and joint dataset algorithms. The NMSE of the joint dataset algorithm increases with the number of epochs. 
In the joint dataset, the number of data samples of E2 is much larger than that of E1, and overfitting occurred during the training process. In addition, the distribution of data samples in different environments is too different, so its test performance is weaker than the direct algorithm. This result suggests that it is necessary to skillfully utilize a small number of datasets in new environments, rather than simply superimposing the data directly.
%This is due to the fact that in the joint dataset, the number of data samples in E2 is much larger than that in E1, so the over-fitting occurs during the training process, and its test performance is still better than that of the direct algorithm. This result shows that it is necessary to add datasets under new scenarios to the test dataset to improve the performance of the model in new scenarios. 
In addition, the meta-learning algorithm is significantly better than the DTL algorithm.
\begin{figure}[!t] 
	\centering 
	\includegraphics[width=\linewidth]{Figure/Epoch_NMSE_training-eps-converted-to.pdf} 
	\caption{\re{The NMSE performance during the adaption stage.}}
	\label{Gad_nmse}
\end{figure}
% In the outdoor scenario, the DTL and meta-learning algorithms can still greatly improve the performance of the model in new environments. Different from the indoor corridor scenario, the joint dataset algorithm in the outdoor scenario is worse than the direct algorithm, which indicates that the difference between several environments in the outdoor scenario is greater, and adding a small amount of destination environment data to the source environment data will lead to serious overfitting.

%\begin{figure}
%	\centering
%	\subfigure[Indoor corridor scenario.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{Figure/Nad_nmse_1-eps-converted-to.pdf}
%		\end{minipage}
%		\label{Nad_nmse}
%	}
%	\subfigure[Outdoor scenario.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{Figure/Nad_nmse_outdoor_1-eps-converted-to.pdf}
%		\end{minipage}
%		\label{Nad_nmse_outdoor}
%	}
%	\caption{The NMSE performance of the four algorithm versus the size of adaption samples $N_{Ad}$ .}
%	\label{Nad_nmse_inout}
%\end{figure}

% \begin{figure}[!t] 
% 	\centering 
% 	\includegraphics[width=\linewidth]{Figure/Nad_nmse_1-eps-converted-to.pdf} 
% 	\caption{The NMSE performance of the four algorithms versus the size of adaption samples $N_{Ad}$ .}
% 	\label{Nad_nmse}
% \end{figure}
\begin{figure}[!t] 
	\centering 
	\includegraphics[width=\linewidth]{Figure/Nad_NMSE_outdoor-eps-converted-to.pdf} 
	\caption{The NMSE performance of the four algorithms versus the size of adaption samples $N_{Ad}$.}
	\label{Nad_nmse}
\end{figure}

Fig. \ref{Nad_nmse} compares the influence of the number of adaptation dataset samples $N_{Ad}$ on the performance of the four algorithms. Since the direct algorithm does not use the adaptation dataset in the new environments, it is assumed that the performance of the algorithm under different sample numbers is consistent. When the number of samples $N_{Ad}=4000$, since the data in the new environment in the joint dataset only accounts for $4000/41000$ of the total data, the resulting overfitting reaction makes the performance of the joint dataset algorithm is even worse than that of the direct algorithm. 
%In the outdoor scenario, even if the number of samples under the target sample $N_{Ad}$ increases, there will still be an overfitting scene. 
Overall, the meta-learning and DTL algorithms can achieve better performance than the two benchmarks with a smaller number of samples, and the performance of the meta-learning algorithm is better than that of the DTL algorithm.

%A comprehensive analysis of the two environments shows that the transfer learning-based and meta-learning-based reciprocal feature construction algorithms can significantly improve the reciprocity of features in new scenarios. In general, meta-learning-based algorithms have better fit than transfer learning-based algorithms.

%\begin{figure}
%	\centering
%	\subfigure[Indoor corridor scenario.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{Figure/SNR_nmse_indoor_1-eps-converted-to.pdf}
%		\end{minipage}
%		\label{SNR_nmse_indoor}
%	}
%	\subfigure[Outdoor scenario.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{Figure/SNR_nmse_outdoor_1-eps-converted-to.pdf}
%		\end{minipage}
%		\label{SNR_nmse_outdoor}
%	}
%	\caption{The NMSE performance versus different SNRs .}
%	\label{}
%\end{figure}


Testing datasets at SNRs of \{0, 10, 20, 30, 40\} dB are also generated to analyze the generalization performance of the four algorithms. Fig. \ref{SNR_nmse_indoor} compares the performance of the four algorithms tested under different SNRs. The results show that the DTL and meta-learning algorithms can achieve better performance than the direct and joint dataset algorithms. The NMSE is still less than 0.1 when the SNR is lower than 10 dB. By this time, the meta-learning algorithm can still effectively improve the reciprocity of features obtained by Alice and Bob.
\begin{figure}[!t] 
	\centering 
	\includegraphics[width=\linewidth]{Figure/SNR_nmse_outdoor-eps-converted-to.pdf} 
	\caption{The NMSE performance versus different SNRs.}
	\label{SNR_nmse_indoor}
\end{figure}
%Fig. \ref{SNR_nmse_outdoor} compares the performance of the four algorithms tested in outdoor scenario with different SNRs. The DTL and meta-learning algorithms achieve better performance than other two benchmarks, and the meta-learning algorithm outperforms the DTL algorithm. In addition, the performance of the direct and joint dataset algorithms decreases instead as the SNR increases. This is due to the fact that there is little correlation between the environments in outdoor scenarios and the pre-trained model cannot be used in the new environment, instead the noise similarity between the downlink and uplink channels is greater at low SNRs, so the NMSE is even a little smaller at low SNRs.



%\begin{figure}[!t] 
%	\centering 
%	\includegraphics[width=\linewidth]{Figure/AB_Before-eps-converted-to.pdf} 
%	\caption{Comparison of the features obtained by Alice and Bob using the four algorithms.}
%	\label{effect} 
%\end{figure}
%
%\begin{figure}[!t] 
%	\centering 
%	\includegraphics[width=\linewidth]{Figure/AB_After-eps-converted-to.pdf} 
%	\caption{Comparison of the features obtained by Alice and Bob using the four algorithms.}
%	\label{effect1} 
%\end{figure}

%\begin{figure}[!t] 
%	\centering 
%	\includegraphics[width=\linewidth]{Figure/effect-eps-converted-to.pdf} 
%	\caption{Comparison of the features obtained by Alice and Bob using the four algorithms.}
%	\label{effect} 
%\end{figure}
%the performance of the direct and joint dataset algorithms decreases as the SNR increases, suggesting that the two algorithms are largely useless in the outdoor scenario and even degrade the reciprocity of channel features to some extent. 

%Fig. \ref{effect} compares the features obtained by Alice and Bob before and after using the four algorithms at the SNR of 20 dB. As shown in Fig. \ref{before}, the original channel features obtained by Alice and Bob are influenced by the frequency and are almost completely different. After using the four algorithms proposed in this paper, the channel features obtained between Alice and Bob are shown in Fig. \ref{after}. The results show that the reciprocity of the features obtained by Alice and Bob is significantly enhanced when using the meta-learning and DTL algorithms, while the reciprocity of the other two benchmark algorithms is still poor. Overall, the meta-learning and DTL algorithms can achieve better fitting performance and generalization under multiple SNRs, with the meta-learning algorithm achieving better performance than the DTL algorithm.

% \begin{figure}
% 	\centering
% 	\subfigure[The obtained features between Alice and Bob without using the proposed two algorithms.]{
% 			\begin{minipage}[b]{\linewidth}
% 					\includegraphics[width=\linewidth]{Figure/AB_Before-eps-converted-to.pdf}
% 				\end{minipage}
% 			\label{before}
% 		}
% 	\subfigure[The obtained features between Alice and Bob using the four algorithms.]{
% 			\begin{minipage}[b]{\linewidth}
% 					\includegraphics[width=\linewidth]{Figure/AB_After-eps-converted-to.pdf}
% 				\end{minipage}
% 			\label{after}
% 		}
% 	\caption{Comparison of the features obtained by Alice and Bob before and after using the four algorithms .}
% 	\label{effect}
% \end{figure}


\subsection{Performance of Initial Keys}

Based on the above analysis of the performance of the feature reciprocity generated by the algorithms, this section analyzes the performance of the initial keys, which includes KER, KGR, and key randomness. In the following section, the quantization factor $\varepsilon$ is set to 0.1, which means that 20\% of the features near the isolation zone are removed in the quantization.



Fig. \ref{KER_indoor} and Fig. \ref{KGR_indoor} compare the performance of the keys generated by the four algorithms tested under different SNRs. As shown in Fig. \ref{KER_indoor}, the KERs of the keys generated by the direct and joint dataset algorithms are as high as 50\%. 
This indicates that the model trained in the source environments is invalid in the new environment. The DTL and meta-learning algorithms can significantly reduce the KERs of generating keys in these new environments. For example, the DTL algorithm and meta-learning algorithm generate keys at the SNR of 20 dB with the KER of 13.37\% and 11.3\%, respectively. %, which is 73.14\% lower compared to the direct algorithm. 
%The KER of the meta-learning algorithm is 11.3\% when the SNR is 20 dB, which is 77.3\% lower than that of the direct algorithm. 
As shown in Fig. \ref{KGR_indoor}, when the SNR is higher than 20 dB, the KGRs of the keys generated by DTL and the meta-learning algorithms are also higher than those of the keys generated by the other two benchmark algorithms. However, when the SNR is less than 15 dB, the obtained features of DTL and the meta-learning algorithms are more concentrated in the isolation zone, so the KGRs are lower than the other two benchmark algorithms.

%It is important to emphasize that although the KER is still high, we can reduce it at the expense of KGR by adjusting the quantization factor $\varepsilon$. %\jz{why the KGR of DTL and ML will be lower when SNR< 15dB? From 11(a), the KER of DTL and ML is always smaller, which means that a smaller $varepsilon$ can be used? Also for 11(a), do you need to mention about $varepsilon$? Do they use the same value?}
\begin{figure}
	\centering
	\subfigure[The KER performance versus different testing SNRs.]{
		\begin{minipage}[b]{\linewidth}
			\includegraphics[width=\linewidth]{Figure/SNR_ker_outdoor-eps-converted-to.pdf}
		\end{minipage}
		\label{KER_indoor}
	}
	\subfigure[The KGR performance versus different testing SNRs.]{
		\begin{minipage}[b]{\linewidth}
			\includegraphics[width=\linewidth]{Figure/SNR_kgr_outdoor-eps-converted-to.pdf}
		\end{minipage}
		\label{KGR_indoor}
	}
	\caption{The performance of initial keys under different SNRs of the testing dataset.}
	\label{}
\end{figure}

%\begin{figure}
%	\centering
%	\subfigure[The KER performance versus different testing SNRs.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{Figure/KER_outdoor_1-eps-converted-to.pdf}
%		\end{minipage}
%		\label{KER_outdoor}
%	}
%	\subfigure[The KGR performance versus different testing SNRs.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{Figure/KGR_outdoor_1-eps-converted-to.pdf}
%		\end{minipage}
%		\label{KGR_outdoor}
%	}
%	\caption{The KER and KGR performance in outdoor scenario.}
%	\label{}
%\end{figure}
%
%
%Fig. \ref{KER_outdoor} and Fig. \ref{KGR_outdoor} compare the performance of the keys generated by the four algorithms tested under different SNRs in the outdoor scenario. As shown in Fig. \ref{KER_outdoor}, the DTL and mete-learning algorithms can significantly reduce the KER of the generated keys in this environment, where the DTL algorithm generates keys with a KER of 13.37\% at a SNR of 20 dB dB, which is 73.14\% lower compared to the direct algorithm. The KER of the meta-learning algorithm to generate keys at SNR of 20 dB is 11.305\%, which is 77.29\% lower compared to the direct algorithm. As shown in Fig. \ref{KGR_indoor}, when the SNR is higher than 20 dB, the keys generated by the DTL and mete-learning algorithms also have a higher KGR than those generated by the direct and joint dataset algorithms.



The NIST test suite is used to test the randomness of the generated keys. Each test will return a p-value. When the p-value is greater than a commonly chosen threshold of 0.01, the generated key passes that test. A serial test is composed of two types of serial tests. When both tests pass, the serial test is considered to be passed. Table \ref{table_randomness_1} shows that all cases pass the test with p-values much larger than 0.01.
% \begin{table}[!t] 
% \caption{NIST Results of the Simulation Data.} %\jz{if it is not too much trouble, generate the randomness test results for the experimental results too and include them in this table.} 
% 	\centering
% 	\begin{tabular}{|p{4cm}<{\centering}| p{2cm}<{\centering} |}
% 		\hline
% 		 \bfseries Test&\bfseries P-value \\ \hline
% 		 Approximate Entropy& 0.9793 \\\hline
% 		 Block Frequency & 0.9945 \\\hline
% 		 Cumulative Sums  &1 \\\hline
% 		 Discrete Fourier Transform & 1 \\\hline
% 		 Frequency & 0.9862  \\\hline
% 		 Ranking & 0.9281 \\\hline
% 		 Runs & 0.9889 \\\hline
% 		 Serial & 0.9862 \\
% 		 \hline
% 	\end{tabular}
% \label{table_randomness_1}
% \end{table}
\begin{table}[!t] 
\caption{NIST statistical test results of the simulation data.} %\jz{if it is not too much trouble, generate the randomness test results for the experimental results too and include them in this table.} 
	\centering
	\begin{tabular}{|p{4cm}<{\centering}| p{2cm}<{\centering} |}
		\hline
		 \bfseries Test&\bfseries P-value \\ \hline
		 Approximate Entropy& 0.6606 \\\hline
		 Block Frequency & 0.0259 \\\hline
		 Cumulative Sums  &0.3752 \\\hline
		 Discrete Fourier Transform & 0.3019 \\\hline
		 Frequency & 0.4795 \\\hline
		 Ranking & 0.1371 \\\hline
		 Runs & 0.6897 \\\hline
		 \multirow{2}{*}{\shortstack{Serial }} & 0.7316 \\ &0.7237 \\
		 \hline
	\end{tabular}
\label{table_randomness_1}
\end{table}

\subsection{Complexity Analysis}


%As shown in Table \ref{table_complexity_1}, we analyze the complexity of the four algorithms in terms of the time cost, the CPU average load, and the GPU memory utilization.
\begin{table}[!t] 
\caption{Complexity analysis of four algorithms.}
	\centering
	\begin{tabular}{|p{2.5cm}<{\centering}| p{1cm}<{\centering} | p{1cm}<{\centering} |p{1.5cm}|}
	\hline
		 \bfseries Algorithm &\bfseries Training Stage & \bfseries  Adaption Stage &\bfseries Key Generation Stage \\ 
		 \hline
		 Direct Algorithm & 183s & - & 0.95e-4s\\ 
		 \hline
		 Joint Training Algorithm & 253s  & - & 0.95e-4s\\ 
		 \hline
		 DTL Algorithm & 183s  &  37s & 0.95e-4s\\ 
		 \hline
		 Meta-learning Algorithm &\textbf{110s} &  \textbf{38s} & 0.95e-4s \\ 
		 \hline
	\end{tabular}
\label{table_complexity_1}
\end{table}
% \begin{table*}[!t] 
% \caption{Complexity analysis of four algorithms. \jz{double check the values. why some values are the same?}}
% 	\centering
% 	\begin{tabular}{|p{2.5cm}<{\centering}| p{1cm}<{\centering} | p{2cm}<{\centering} |p{2cm}<{\centering}|p{1cm}<{\centering} |p{2cm}<{\centering}|p{2cm}<{\centering} |p{2cm}<{\centering} |}
% 		\hline
% 		& \multicolumn{3}{c|}{\textbf{Training Stage}}& \multicolumn{3}{c|}{\textbf{Adaptation Stage}}& \textbf{Key Generation Stage}\\ \hline
% 		 \bfseries Algorithm &\bfseries Time Cost & \bfseries CPU Average Load & \bfseries GPU Memory Utilization & \bfseries Time Cost & \bfseries CPU Average Load&\bfseries  GPU Memory Utilization &\bfseries Time Cost \\ 		  
% 		 \hline
% 		 Direct Algorithm & 183s & 15.82\%& 5.1 / 9.9 GB &  - & - & - & 0.95e-4s\\ 
% 		 \hline
% 		 Joint Training Algorithm & 253s & 18.22\%& 5.1 / 9.9 GB &  - & - & - & 0.95e-4s\\ 
% 		 \hline
% 		 DTL Algorithm & 183s & 15.82\%& 5.1 / 9.9 GB &  37s & 10.2\% & 5.1 / 9.9 GB & 0.95e-4s\\ 
% 		 \hline
% 		 Meta-learning Algorithm &\textbf{110s} & 12\%&   1 / 9.9 GB &  \textbf{38s} & 10.2\% & 5.1 / 9.9 GB & 0.95e-4s \\ 
% 		 \hline
% 	\end{tabular}
% \label{table_complexity_1}
% \end{table*}
We compare the time cost of the four algorithms in Table~\ref{table_complexity_1}.
In the training stage, since the training process of meta-learning includes multiple intra-task and cross-task updates, meta-learning consumes significantly more resources than DTL. However, it was found experimentally that the training process of meta-learning requires only 10 iterations before the loss function stops decreasing, which takes about 110 seconds. %Besides, the trained model using the meta-learning algorithm only requires 25.6 MB of memory to save on the device, so it can be deployed on resource-constrained embedded systems.
The DTL and meta-learning algorithms increase the consumption required for the adaptation stage on top of the direct algorithm and the joint training algorithm, however, the improved performance shows that the consumption is worth it. In our experiments, the DTL and meta-learning algorithms only take about 37 seconds to complete the adaptation to the new environment, which is an acceptable cost.
In the key generation stage, the time cost of each feature mapping is around 0.95e-4 seconds, which can be done in almost real-time.

In summary, it takes about 148 seconds to train and adapt the network in total, and only 0.95e-4 seconds to use the network for feature mapping in the key generation stage. Furthermore, the training stage only needs to be performed once for all environments, and the adaptation stage is performed only once for each environment. Compared with the training consumption of networks used in other areas, the proposed algorithms can achieve fast key generation in FDD-OFDM systems. 

\re{As for the model size, the model used has 2,763,775 parameters and requires 20.5 MB of storage space, which is affordable to a BS. In addition, the inference stage is usually not computationally expensive, which can be handled by the BS too.}


\re{
\subsection{Security Analysis}
The security of our scheme can still be guaranteed even if the feature mapping function is leaked. When Eve is located over half of the wavelength away from Alice or Bob, she cannot get correlated channel measurements. In this circumstance, even though Eve has access to the feature mapping function, it cannot infer the channel features.}

\section{Experimental Evaluation}
\label{practical}

In this section, we will introduce a FDD-OFDM key generation hardware platform based on GNURadio and USRP, and then evaluate the performance of the proposed scheme in a real environment.
%\begin{figure}[!t]
	%\centering
	%\subfloat[]{\includegraphics[width=1.7in]{Figure/indoor_ex.png}
		%\label{}}
	%\subfloat[]{\includegraphics[width=1.7in]{Figure/outdoor_ex.png}
		%\label{}}
	%\caption{Floor plans of an indoor environment and an outdoor environment, where Alice remains stationary and Bob moves slowly along the dark brown. The outdoor map comes from Google Maps \cite{googlemap}.}
	%\label{experient}
%\end{figure}



\subsection{Experimental Setup and Dataset Collection}
We built an experimental platform based on the GNURadio software radio suite and USRP N210 to collect FDD channel data in realistic scenarios to verify performance. Two USRP N210 SDR platforms \cite{ettus} are used as Alice and Bob to receive and transmit signals processed by MATLAB. OFDM probing signals are generated and processed in MATLAB and stored as data stream files in the PC.
In the experiment, it is difficult to guarantee that Alice and Bob transmit and estimate the probing signals at the same moment. First, Alice's transmitter sends a sounding signal to Bob, and Bob's transmitter is triggered to send an OFDM signal when Bob's receiver detects the sounding signal, and then Alice's receiver detects the sounding signal and notifies Bob to start subsequent channel estimation. This mechanism affects the accuracy of the CSI obtained by Alice and Bob to a certain extent, but due to the short communication time, it can be regarded as an FDD channel. In order to avoid the influence of the ISM band signal on the experiment, the uplink and downlink carrier frequencies $f_{ul}$ and $f_{dl}$ are set to 2.535 GHz and 2.435 GHz respectively, the transmit gain and receive gain are 30 dB, %the sampling rate is 25 MS/s, the bandwidth is 20 MHz, 
and the number of subcarriers is 511.
%\jz{can you confirm if the sample rate is 25 MHz? if it is, why you used this value}

We conducted extensive experiments in two scenarios, as shown in Fig. \ref{experient}, one is an interior scene of an office room, and the other is an outdoor scene of the Purple Mountain Laboratories, China. Alice remains stationary, Bob keeps moving slowly along the route marked in the diagram. There may also be other variations caused by people or vehicles moving around. %We collected at least 900 CSI vectors in each scenario and deleted the number of groups that estimated channel errors, and finally obtained more than 900 groups of uplink and downlink CSI vectors in both scenarios.
We obtained more than 900 groups of uplink and downlink CSI vectors in both scenarios.
\begin{figure}
	
	\subfigure[Indoor.]{
			\begin{minipage}[b]{\linewidth}\centering
					\includegraphics[width=2.6in]{Figure/indoor_ex.pdf}
				\end{minipage}
			\label{}
		}
		
	\subfigure[Outdoor.]{
			\begin{minipage}[b]{\linewidth}\centering
					\includegraphics[width=2.6in]{Figure/outdoor_ex.pdf}
				\end{minipage}
			\label{}
		}
  %       \subfigure[Experimental photo.]{
		% 	\begin{minipage}[b]{0.45\linewidth}
		% 			\includegraphics[width=\linewidth]{DTL_KG/Figure/outdoor_ex_example.pdf}
		% 		\end{minipage}
		% 	\label{after}
		% }
	\caption{Floor plans of an indoor environment and an outdoor environment, where Alice remains stationary and Bob moves slowly along the brown-colored line. }
	\label{experient}
\end{figure}

The amount of data collected in the experiment is less than that collected in the simulation, so we adjusted the batch size $N_{batch}$ and $E_{batch}$ in the transfer learning and meta-learning algorithms to 8, the number of samples in each task in meta-learning is 30. In each task, the numbers of samples in the support
dataset and query dataset are both 15. The number of layers, the number of neurons, and the optimizer of the deep learning model remain unchanged.

\subsection{Experimental Results}


First, we evaluate the performance of deep learning-powered FDD-OFDM key generation in a single environment, from which both training and test data are collected. We use 80\% of the data for training and 20\% of the data for testing in two scenarios. This is the first time the actual performance of such methods has been evaluated experimentally. 
The results are shown in Table~\ref{test_pratical}. In the indoor scenario, the KER before and after feature mapping is 0.3539, and 0.0681, respectively. In the outdoor scenario, the KER before and after feature mapping is 0.3683 and 0.0555 respectively. The experimental results show that the deep learning method can significantly improve the reciprocity in FDD systems and greatly improve the performance of the generated keys in a single environment. 
\begin{table}[!t]
\caption{Comparison of performance before and after feature mapping.}
\centering
\begin{tabular}{|p{1cm}<{\centering}|p{1cm}<{\centering}| p{2.4cm}<{\centering}|p{2.4cm}<{\centering}|}
\hline
\textbf{Scenario}& \textbf{Metric} & \textbf{Before Feature Mapping} & \textbf{After Feature Mapping} \\ \hline
\multirow{3}{*}{\shortstack{Indoor}} & NMSE    &       0.2031 &0.0840
\\ \cline{2-4} 
    & KER    &    0.3539     & \textbf{0.0681}\\ \cline{2-4} 
    & KGR    &    0.7583  &    0.8369     \\ \hline
\multirow{3}{*}{\shortstack{Outdoor}}  & NMSE    & 0.3158       & 0.0811
\\ \cline{2-4} 
& KER    &  0.3683   &   \textbf{0.0555} 
\\ \cline{2-4} 
& KGR    &  0.7144      &    0.7882    \\ \hline
\end{tabular}
\label{test_pratical}
\end{table}

%\jz{is it the normal deep learning=based algorithm? i.e., without DTL or meta-learning?} \jz{I presume this part is actually the direct algorithm?}


\begin{figure}[htbp]\label{f_1}
\centering
\subfigure[The NMSE performance versus the number of adaption samples.] {
 \label{fig:cdf-1}     
\includegraphics[width=\columnwidth]{Figure/Nad_nmse_experient-eps-converted-to.pdf}}

\subfigure[The KER performance versus the number of adaption samples.] {
 \label{fig:cdf-2}     
\includegraphics[width=\columnwidth]{Figure/Nad_ker_experient-eps-converted-to.pdf}}  

\subfigure[The KGR performance versus the number of adaption samples.] {
 \label{fig:cdf-3}     
\includegraphics[width=\columnwidth]{Figure/Nad_kgr_experient-eps-converted-to.pdf}}  
\caption{The performance under different numbers of adaption samples.}
\label{fig_practical}     
\end{figure}

Next, we evaluate the performance of the proposed algorithms in multi-environments. In this paper, we test the algorithm proposed in this paper using 900 sets of data collected in the indoor scenario to improve the performance in the outdoor scenario when the amount of data is small. Fig.~\ref{fig_practical} compares the performance of several algorithms under different adaptation sample sizes. Fig.~\ref{fig:cdf-1} and Fig.~\ref{fig:cdf-2} show that the NMSE and KER performances of the algorithms both improve as the number of adapted samples increases. When the adaptive sample size is only 10, the NMSE performance of the algorithms proposed in this paper is poor, and it is not as good as the direct algorithm. However, after quantization, the mete-learning algorithm can still generate keys with lower KER when the adaption sample size is as small as 10 and 20. When the adaption sample size is 80, the KER of the key generated by the meta-learning algorithm is lower than 10\%. In addition, different from the simulation results, when the adaptive sample size exceeds 40, the KER of the key generated by the joint dataset algorithm is also smaller than that of the direct algorithm. This shows that in real-world environments, despite experiencing different scattering environments, different environments still have certain similarities, which can be used to improve performance in new environments. At this point, the performance of the two algorithms proposed in this paper is still better than the joint dataset algorithm.

%\jz{it is not good practice that you only cited Fig. 13c. You need to do the same thing for (a) and (b)}
Fig. \ref{fig:cdf-3} shows that the performance of KGR seems to be slightly degraded, and the KGR generated by all algorithms fluctuates between 0.7 and 0.8. This result is related to the quantization method we choose. The quantization based on the Gaussian distribution used in this paper may not perfectly fit the distribution of channel characteristics, thus causing KGR fluctuations. Since the fluctuation range is not large, it is quite normal and feasible to sacrifice a certain KGR to achieve a lower KER key. Since the fluctuation range is not large and the KER of the generated key is significantly reduced, in general, the DTL algorithm and the mata-learning algorithm can significantly improve the performance of the generated key in real-world scenarios.

% \begin{table}[!t] 
% \caption{NIST Results of the Experimental Data.} %\jz{if it is not too much trouble, generate the randomness test results for the experimental results too and include them in this table.} 
% 	\centering
% 	\begin{tabular}{|p{4cm}<{\centering}| p{1.5cm}<{\centering} | p{1.5cm}<{\centering} |}
% 		\hline
% 		 \bfseries Test&\bfseries Indoor &\bfseries Outdoor\\ \hline
% 		 Approximate Entropy& 0.9601 &0.9717\\\hline
% 		 Block Frequency & 0.9933 & 0.9965\\\hline
% 		 Cumulative Sums  &1 &1\\\hline
% 		 Discrete Fourier Transform & 0.9983 &1\\\hline
% 		 Frequency & 0.9734  &0.9558\\\hline
% 		 Ranking & 0.8819 &0.9770\\\hline
% 		 Runs & 0.9800 &0.9841\\\hline
% 		 Serial & 0.9734 &0.9611\\
% 		 \hline
% 	\end{tabular}
% \label{table_randomness_2}
% \end{table}
\begin{table}[!t] 
\caption{NIST statistical test results of the experimental data.} %\jz{if it is not too much trouble, generate the randomness test results for the experimental results too and include them in this table.} 
	\centering
	\begin{tabular}{|p{3.5cm}<{\centering}| p{1.5cm}<{\centering} | p{1.5cm}<{\centering} |}
		\hline
		 \bfseries Test&\bfseries Indoor &\bfseries Outdoor\\ \hline
		 Approximate Entropy& 0.4391 &0.4405\\\hline
		 Block Frequency & 0.9559 & 0.3620\\\hline
		 Cumulative Sums  &0.2653 &0.5700\\\hline
		 Discrete Fourier Transform & 0.4913 &0.9087\\\hline
		 Frequency & 0.2159 &0.2159\\\hline
		 Ranking & 0.7745  &0.2395\\\hline
		 Runs & 0.5005 &0.5628\\\hline
		 \multirow{2}{*}{\shortstack{Serial }} & 0.4369 & 3622\\ &0.7237 & 0.4795 \\
		 \hline
	\end{tabular}
\label{table_randomness_2}
\end{table}

The NIST test is also used to test the randomness of the generated keys in the real world. Table \ref{table_randomness_2} shows that all cases for both indoor and outdoor environments pass the test with p-values much greater than 0.01.


\section{Conclusion}
\label{Conclusion}
In this paper, aiming at the problem of inapplicability of deep learning model caused by environmental changes, we formulated this problem as a learning-based problem, i.e., using knowledge from source environments to learn the feature mapping in the new environments, and proposed a DTL algorithm and a meta-learning algorithm to achieve fast key generation in multi-environment for FDD-OFDM systems. Simulation results showed that both algorithms can effectively improve the performance of generated keys in new environments. When the SNR=20 dB, the KERs of the keys generated by the DTL and meta-learning algorithms were reduced by 73.14\% and 77.3\%, respectively, compared with the method without adaptation (the direct algorithm) in the new environments. 
The complexity analysis showed that the meta-learning algorithm consumed less time than the DTL algorithm in the training stage, and these costs were acceptable in real-world applications. In addition, we built a USRP SDR-based testbed and verified the performance of the learning-based FDD-OFDM key generation method using real-world data for the first time. The results show that the proposed algorithm can significantly reduce the KER of generated keys, and only 80 samples in the new environment can reduce KER to 10\%.
%In our future work, we will verify the performance of the proposed algorithms in more scenarios and further improve the performance of the generated keys.

%\section*{Acknowledgment}
%This work was supported in part by the National Natural Science Foundation of China under Grant 62171121, Grant 61941115, and Grant 61801115; in part by the Jiangsu Key Research and Development Plan under Grant BE2019109; in part by the Natural Science Foundation of Jiangsu Province under Grant BK20211160; in part by the Social Development Projects of Jiangsu Science and Technology Department under Grant BE2018704; and in part by the Zhishan Youth Scholar Program of Southeast University under Grant 3209012002A3.

\bibliographystyle{IEEEtran} 
\bibliography{IEEEabrv, myref}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in, clip,keepaspectratio]{Figure/Xinwei_Zhang.jpg}}]{Xinwei Zhang} received the M.Eng degree in computer technology from Southeast University, Nanjing, China, in 2022.  He is currently pursuing the Ph.D. degree with the Department of Electrical and Electronic Engineering, The Hong Kong Polytechnic University, Hong Kong. 

From April 2021 to September 2021, he was a Research Assistant with the Department of Computing, The Hong Kong Polytechnic University. His research interests include physical-layer security and adversarial machine learning.
\end{IEEEbiography}
%\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figure/Guyue_Li.jpg}}]{Guyue Li}
(Member, IEEE) received the B.S. degree in information science and technology and the Ph.D. degree in information security from Southeast University, Nanjing, China, in 2011 and 2017, respectively. 

From June 2014 to August 2014, she was a Visiting Student with the Department of Electrical Engineering, Tampere University of Technology, Finland. She is currently an Associate Professor with the School of Cyber Science and Engineering, Southeast University. Her research interests include physical-layer security, secret key generation, radio frequency fingerprint, and link signature.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figure/Junqing_Zhang.jpg}}]{Junqing Zhang}
(Member, IEEE) received the B.Eng and M.Eng degrees in Electrical Engineering from Tianjin University, China in 2009 and 2012, respectively, and the Ph.D degree in Electronics and Electrical Engineering from Queen's University Belfast, UK in 2016. From Feb. 2016 to Jan. 2018, he was a Postdoctoral Research Fellow at Queen's University Belfast. From Feb. 2018 to Oct. 2022, he was a Tenure Track Fellow and then a Lecturer (Assistant Professor) at the University of Liverpool, UK. Since Oct. 2022, he has been a Senior Lecturer (Associate Professor) with the University of Liverpool. His research interests include the Internet of Things, wireless security, physical layer security, key generation, radio frequency fingerprint identification, and wireless sensing. He was a recipient of the UK EPSRC New Investigator Award.
\end{IEEEbiography}


\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figure/Linning_Peng.jpg}}]{Linning Peng}
(Member, IEEE) received the Ph.D.
degree from the Electronics and Telecommunications Institute of Rennes Laboratory, National Institute of Applied Sciences, Rennes, France, in 2014.

Since 2014, he has been an Associate Professor with Southeast University, Nanjing, China. His
research interests include Internet of Things and
physical layer security in wired and wireless communications

\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figure/Aiqun_Hu.jpg}}]{Aiqun Hu}
(Senior Member, IEEE) received the B.Sc.(Eng.), M.Eng.Sc., and Ph.D. degrees from Southeast University in 1987, 1990, and 1993, respectively. 

He was invited as a Post-Doctoral Research Fellow with The University of Hong Kong from 1997 to 1998, and a TCT Fellow with Nanyang Technological University in 2006. He has published two books and more than 100 technical articles in wireless communications field. His research interests include data transmission and secure communication technology.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figure/Xianbin_Wang.jpg}}]{Xianbin Wang} (Fellow, IEEE) received his Ph.D. degree in electrical and computer engineering from the National University of Singapore in 2001.

He is a Professor and a Tier-1 Canada Research Chair in 5G and Wireless IoT Communications with Western University, Canada. Prior to joining Western University, he was with the Communications Research Centre Canada as a Research Scientist/Senior Research Scientist from 2002 to 2007. From 2001 to 2002, he was a System Designer at STMicroelectronics. His current research interests include 5G/6G technologies, Internet of Things, machine learning, communications security, and intelligent communications. He has over 600 highly cited journals and conference papers, in addition to over 30 granted and pending patents and several standard contributions.

Dr. Wang is a Fellow of the Canadian Academy of Engineering and a Fellow of the Engineering Institute of Canada. He has received many prestigious awards and recognitions, including the IEEE Canada R. A. Fessenden Award, Canada Research Chair, Engineering Research Excellence Award at Western University, Canadian Federal Government Public Service Award, Ontario Early Researcher Award, and nine Best Paper Awards. He was involved in many IEEE conferences, including GLOBECOM, ICC, VTC, PIMRC, WCNC, CCECE, and CWIT, in different roles, such as General Chair, TPC Chair, Symposium Chair, Tutorial Instructor, Track Chair, Session Chair, and Keynote Speaker. He serves/has served as the Editor-in-Chief, Associate Editor-in-Chief, and editor/associate editor for over ten journals. He was the Chair of the IEEE ComSoc Signal Processing and Computing for Communications (SPCC) Technical Committee and is currently serving as the Central Area Chair of IEEE Canada.
\end{IEEEbiography}


\end{document}