\documentclass[journal]{IEEEtran}
%\documentclass[draftclsnofoot,onecolumn]{IEEEtran}

\usepackage{graphicx} 
\usepackage{subfigure}%使用graphicx包
\usepackage{amsmath}
\usepackage{multirow} 
\newtheorem{definition}{\textbf {Definition}}
\newtheorem{assumption}{Assumption}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{\textbf{Remark}}
\newtheorem{proof}{Proof}

\usepackage{caption}

%\newcommand{\re}[1]{{\color[rgb]{0,0,1}#1}}
\newcommand{\re}[1]{{\color[rgb]{0,0,0}#1}}

\newcommand{\xw}[1]{{\color[rgb]{0.5,0.1,1}#1}}
\newcommand{\jz}[1]{{\color{red}#1}}

\newtheorem{theorem}{Theorem}
\usepackage{algorithm}
\usepackage{algorithmic}
%\usepackage[ruled]{algorithm2e}
\renewcommand{\algorithmicrequire}{ \textbf{Input:}} 
\renewcommand{\algorithmicensure}{ \textbf{Output:}} 
\usepackage{amsfonts}
\usepackage{algorithm, algorithmic}
\usepackage{color}
\usepackage{booktabs}
\usepackage{array}
\usepackage{epstopdf} 
\usepackage{url}
\usepackage{cite}
%\bibliographystyle{plain}
%\bibliographystyle{unsrt}


%\hyphenation{op-tical net-works semi-conduc-tor}
	

\begin{document}

\title{Enabling Deep Learning-based Physical-layer Secret Key Generation for FDD-OFDM Systems in Multi-Environments}

\author{Xinwei~Zhang, 
        Guyue~Li,~\IEEEmembership{Member,~IEEE},    Junqing~Zhang,~\IEEEmembership{Member,~IEEE},
        Aiqun~Hu,~\IEEEmembership{Senior Member,~IEEE}
        and Xianbin~Wang,~\IEEEmembership{Fellow,~IEEE}

\thanks{This work was supported in part by the National Natural Science Foundation of China under Grant 62171121, Grant 61941115, and Grant 61801115; in part by the Jiangsu Key Research and Development Plan under Grant BE2019109; in part by the Natural Science Foundation of Jiangsu Province under Grant BK20211160; in part by the Social Development Projects of Jiangsu Science and Technology Department under Grant BE2018704; and in part by the Zhishan Youth Scholar Program of Southeast University under Grant 3209012002A3.(\textit{Corresponding author: Guyue Li.})}
\thanks{Xinwei Zhang is with the School of Cyber Science and Engineering, Southeast University, Nanjing 210096, China (e-mail: xwzhang1998@gmail.com).}
\thanks{Guyue Li is with the School of Cyber Science and Engineering, Southeast University, Nanjing 210096, China, and also with the Purple Mountain Laboratories for Network and Communication Security, Nanjing 210096, China(e-mail: guyuelee@seu.edu.cn).}
\thanks{Junqing Zhang is with the Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool L69 3GJ, U.K. (e-mail: junqing.zhang@liverpool.ac.uk).}
\thanks{Aiqun Hu is with the School of Information Science and Engineering, and National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China, and also with the Purple Mountain Laboratories for Network and Communication Security, Nanjing 210096, China (e-mail: aqhu@seu.edu.cn).}
\thanks{Xianbin Wang is with the Department of Electrical and Computer Engineering, Western University, London, ON N6A 5B9, Canada (e-mail: xianbin.wang@uwo.ca).}
}

% The paper headers
%\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2022}
% {ZHANG \MakeLowercase{\textit{et al.}}: Deep Learning-based Physical layer Secret Key Generation for FDD Systems}


\maketitle


\begin{abstract}
Deep learning-based physical-layer secret key generation (PKG) has been used to overcome the imperfect uplink/downlink channel reciprocity in frequency division duplexing (FDD) orthogonal frequency division multiplexing (OFDM) systems. However, existing efforts have focused on key generation for users in a specific environment where the training samples and test samples obey the same distribution, which is unrealistic for real world applications. This paper formulates the PKG problem in multiple environments as a learning-based problem by learning the knowledge such as data and models from known environments to generate keys quickly and efficiently in multiple new environments. Specifically, we propose deep transfer learning (DTL) and meta-learning-based channel feature mapping algorithms for key generation. The two algorithms use different training methods to pre-train the model in the known environments, and then quickly adapt and deploy the model to new environments. Simulation results show that compared with the methods without adaptation, the DTL and meta-learning algorithms both can improve the performance of generated keys. In addition, the complexity analysis shows that the meta-learning algorithm can achieve better performance than the DTL algorithm with less time, lower CPU and GPU resources.
\end{abstract}
%However, existing efforts have focused on generating keys for users in a given environments, which is not realistic. Therefore,  First we propose a general feature extraction framework to obtain the suitable feature for key generation in different scenarios (indoor and outdoor typically). This paper investigates the problems related to key generation in multiple environments.
%Then, to address the problem that the performance of the deep learning model trained in the certain environment degrades or even becomes unusable when users move to new environments, 

\begin{IEEEkeywords}
Physical-layer security, secret key generation, frequency division duplexing, deep learning, transfer learning, meta-learning.
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle



\section{Introduction}

%\subsection{Background}
\IEEEPARstart{D}{ue} to the broadcast nature of radio signal propagation, wireless networks are vulnerable to various attacks such as eavesdropping, counterfeiting, and tampering~\cite{zou2016survey}. Traditional security mechanisms, particularly public key cryptography, are facing many problems such as difficulty in key distribution and poor scalability in large-scale networks with limited resources, which make it difficult to meet the security needs of future wireless communications \cite{li2019physical, zhang2016key}. In recent years, \textit{physical-layer secret key generation (PKG)} has gradually become a research hotspot of wireless security. From the perspective of information theory, PKG provides a new security mechanism, which greatly simplifies the distribution and management of keys \cite{li2019physical, zhang2016key, jiao2019physical}. 

PKG techniques realize real-time sharing and coordination of random security keys by exploiting the channel reciprocity of uplink and downlink features~\cite{li2019physical, li2018constructing}. The channel features, such as received signal strength (RSS), channel state information (CSI), channel gain, etc., are widely used for PKG \cite{li2019physical}. In time division duplexing (TDD) systems, the uplink and downlink transmissions operate in the same carrier frequency band, and the channel features observed by both communication parties is highly reciprocal. However, in frequency division duplexing (FDD) systems, due to the uplink and downlink works on different carrier frequency bands, most of reciprocal channel parameters may be completely different between the uplink and the downlink, thus can not be directly used for key generation. 
Therefore, the majority of the existing studies focus on PKG in TDD systems~\cite{zhang2016key,zhang2020new}, and the research on PKG in FDD systems is limited. Sine FDD mode is the primary duplexing strategy for cellular communications~\cite{penttinen2015telecommunications, 3gpp.38.101-1}, it has profound research value and practical significance to study the PKG method in FDD systems.

\subsection{Related Work}
In recent years, there has been some studied on the PKG in FDD systems, which can be categorized into model-based and deep learning-based approaches. 

Model-based methods aim to extract frequency-independent channel features or construct a reciprocal feature. Specifically, the work in~\cite{wang2012wireless,liu2019secret} proposed to extract the frequency-independent channel parameters (such as arriving angle, delay and covariance matrix eigenvalues). However, these methods have many limitations, such as large bandwidth or special configuration of the antenna array \cite{vasisht2016eliminating}. Besides,  a reciprocal channel construction framework named SAR is proposed in \cite{li2018constructing}, but it is difficult to separate the channel paths accurately in the complex multi-path environment. Some works proposed to construct reciprocal channels by additional reverse channel training and feedback, called the loopback-based methods~\cite{goldberg2013method,wu2013secret,qin2016exploiting,allam2017channel}. However, these methods not only increase the complexity of channel detection but also has security risks~\cite{linning2018investigation}. 

Due to its excellent performance, deep learning has also been introduced into the field of PKG in TDD and FDD systems \cite{10.1145/3522783.3529526,han2021dronekey,zhang2021secret,wan2021secret,hou2021secret,zhang2022deep}. In FDD systems, deep learning-based approaches have been used to construct reciprocal feature for key generation with the help of the feature mapping function between uplink and downlink transmissions assisted deep learning.
Since the uplink and downlink channels pass through the same propagation path and scattering clusters, it is experimentally shown in \cite{vasisht2016eliminating} that there is a transformation function that can map the channel to the underlying path. Furthermore, prior works have shown that it is possible to infer downlink channels from uplink channels~\cite{alrabeian2019deep,bakshi2019fast,liu2021Fire}. 
These works inspire efforts for applying deep learning for FDD-based key generation by constructing reciprocal features via deep learning.
In \cite{zhang2022deep}, it is proved that in a given environment, when the channel mapping function of possible user locations to antennas is bijective, there exists a feature mapping function that can map one frequency band features to another frequency band features, and the channel feature mapping function can be obtained by a simple deep learning model. This conclusion provides a theoretical basis for introducing deep learning into key generation for FDD-based OFDM systems~\cite{zhang2021secret,wan2021secret,hou2021secret,zhang2022deep}. A boundary equilibrium generative
adversarial network (BEGAN) and an encoder-decoder based convolutional neural network were proposed to predict downlink CSI and key generation \cite{wan2021secret,hou2021secret}. Furthermore, a complex-valued neural network (CVNet) was proposed to improve the performance of generated keys \cite{zhang2021secret}. 

Compared with conventional model-based PKG techniques (e.g. \cite{wang2012wireless,liu2019secret,goldberg2013method,wu2013secret,qin2016exploiting,allam2017channel,li2018constructing}), deep learning-based key generation methods are not limited with channel models and can achieve excellent performance. However, existing deep learning-based approaches only consider a given wireless environment and the deep learning model only can learn the feature mapping function in this specific environment. In practice, users may experience different new environments. 
Existing machine learning techniques require data collection and model training for each communication environment, leading to a large amount of training resources and training data, which is difficult to be used in real-world applications. Therefore, how to quickly adapt the deep learning model to new environments for feature mapping and key generation with low cost is a new challenge that needs to be addressed.
%If data collection and model training are performed for each environment, this requires a large amount of training resources and training data, which is difficult to satisfy in real-world applications. Therefore, how to quickly adapt the deep learning model to new environments for feature mapping and key generation with low cost is a new problem that needs to be solved.
%When a user is in a new environment, changes in the environment may lead to degraded or even ineffective performances of the deep learning model due to task mismatch, and thus the base station (BS) cannot provide a secure communication connection without a suitable deep learning model in the new environment. 


%\subsection{Motivations}

Deep transfer learning (DTL)~\cite{zhuang2020comprehensive, nguyen2021transfer} and  meta-learning \cite{thrun1998learning,park2020end,park2021learning} are effective ways that can solve the problem of inapplicability of the deep learning model caused by environmental changes. DTL uses the knowledge of source tasks to improve the performance of target tasks and is a promising machine learning technology that can solve similar tasks with limited labelled data. Meta-learning aims to improve the ability to adapt or generalize to new tasks and environments that have never been encountered during the training stage by training in multiple learning tasks.
They have been widely used in many areas to solve the problem of performance degradation of deep learning models due to environmental changes, e.g., channel feedback \cite{zeng2021downlink}, beam prediction \cite{yuan2020transfer}, downlink channel prediction \cite{yang2020deep}, resource allocation \cite{shen2019transfer}, etc. 


%In general, traditional DTL algorithms use datasets from known tasks to pre-train the model and then fine-tunes it under a new task \cite{nguyen2021transfer}. Most existing meta-learning algorithms are problem-specific. In order to eliminate the limitation of the model architecture on the application of meta-learning, a model-agnostic meta-learning (MAML) algorithm was proposed in \cite{finn2017model}. The goal of the algorithm is to achieve adaptation by alternately learning the parameter initialization of the model between the intra-task process and the cross-task process. Moreover, unlike the DTL technique, the MAML algorithm emphasizes learning the optimal model initialization parameters under multiple tasks to achieve optimal performance under new tasks \cite{thrun1998learning}.\jz{either combine this part into the DTL or meta-learning sections. or delete them.}

%In addition, unlike the DTL technology, the MAML algorithm does not need to collect a large amount of data in a fixed environment to pre-train the network, it only needs to collect a small amount of data in multiple environments to train the network. In some cases, it is easier to collect samples from multiple wireless channel environments (each wireless channel environment provides only a small number of samples) than to collect large amounts of data in one fixed environment \cite{zeng2021downlink}.



\subsection{Main Contributions}
Inspired by these works, this paper introduces DTL and meta-learning into the field of PKG to achieve fast and efficient key generation of FDD-OFDM systems  in mult-environments.
First, we formulate the key generation in multi-environments as a learning-based problem, i.e., using the knowledge from known (source) environments to learn the deep learning model in the new (target) environments more efficiently. Then we propose DTL-based and meta-learning-based feature mapping algorithms to achieve key generation for FDD systems in multi-environments. %We also proposed two benchmarks, i.e.,  the direct algorithm and the joint dataset algorithm, to verify the good performance of the algorithms proposed in this paper. 
To the best knowledge of the authors, no work has ever focused on deep learning-based key generation for FDD-OFDM systems in multi-environments. Our major contributions are summarized as follows.
\begin{itemize}
%    \item We verify the performance of the method proposed in \cite{zhang2022deep} in the outdoor scenario and find that the feature extraction method can not be used in the outdoor scenario. Based on this observation, we propose a general feature extraction framework, which can construct suitable features in the different scenarios. 
	\item We propose a DTL-based feature mapping algorithm for key generation in FDD-OFDM systems. This algorithm pre-trains the model using the datasets from source environments, and then fine-tunes the pre-trained model using a small number of samples from the new environment, after which this fine-tuned model can be used for key generation in the new environment.
	%The DTL algorithm can quickly obtain a better performance model with lower data cost and time cost.
	\item To better leverage knowledge from known environments, we propose a meta-learning-based feature mapping algorithm for key generation in FDD-OFDM systems. This algorithm performs intra-task and cross-task learning in multiple tasks (each task represents key generation in a given environment) to obtain the best model initialization parameters, allowing for fast model adaptation in new environments.
	%that can be achieved better performance of the generated keys in the new environments.
	\item We verify the proposed algorithms in an indoor corridor scenario using a ray tracing simulator Wireless InSite. The results show the DTL and meta-learning algorithms both can improve performance of generated keys in new environments. In addition, complexity analysis shows that the meta-learning algorithm can achieve better performance with less time, lower CPU and GPU resources, compared with the DTL algorithm.
\end{itemize} 

The rest of this paper is structured as follows. The deep learning-based key generation for FDD-OFDM systems is introduced in Section \ref{Preliminary}. In Section \ref{system overview}, we formulate the PKG in multi-environments as a learning-based problem and give an overview. The DTL-based feature mapping for key generation is presented in Section \ref{DTL}. The meta-learning-based feature mapping for key generation is presented in Section \ref{meta}. The simulation results for evaluating the performance of the generated keys and the complexity analysis are provided in Section \ref{simulation}, which is followed by conclusions in Section \ref{Conclusion}.

\section{Preliminary: Deep Learning-Powered FDD-OFDM Key Generation}
\label{Preliminary}
%In this section, we first give the channel model in the FDD-OFDM system, and then introduce the deep learning-based key generation for FDD-OFDM systems.

\subsection{Overview}
We consider a FDD-OFDM system, where the BS (Alice) and user (Bob) are equipped with a single antenna and operate at the FDD mode. Alice and Bob simultaneously transmit signals on different carrier frequencies, $f_{dl}$ and $f_{ul}$, respectively. The channel impulse response (CIR) can be defined as follows:
\begin{equation}
\begin{split}
h(f,\tau)=\sum_{n=0}^{N-1}\alpha_{n}e^{-j2\pi f\tau_n+j\phi_n}\delta(\tau-\tau_n),
\end{split}
\label{CIR}
\end{equation}
where $f$ is the carrier frequency, $N$ is the total number of paths, $\alpha_{n}$ is the magnitude of the $n^{th}$ path, which is influenced by the distance $d_n$ between Alice and Bob, the scattering environment and the carrier frequency  $f$. $\tau_n = \frac{d_n}{c}$ is the delay of the $n^{th}$ path, where $c$ is the speed of light. $\phi_n$ is the phase shift of the $n^{th}$ path, which is determined by the scatterer material and wave incident/impinging angles at the scatterer.

%Note that $\alpha_{n}$ depends on (i) the distance $d_n$ between Alice and Bob, (ii) the carrier frequency $f$, (iii) the scattering environment. The phase $\phi_n$ is determined by the scatterer(s) materials and wave incident/impinging angles at the scatterer(s). The delay $\tau_n = \frac{d_n}{c}$, where $c$ is the speed of light. 

In FDD-OFDM systems, the channel frequency response (CFR) of the $l^{th}$ sub-carrier can be expressed as 
\begin{equation}
\begin{split}
H(f,l)=\sum_{n=0}^{N-1}\alpha_{n}e^{-j2\pi f\tau_n+j\phi_n}e^{-j2\pi n l/L},
\end{split}
\label{CFR}
\end{equation}
where $L$ is the number of subcarriers. The CFR of frequency $f$ can be defined as the $1\times L$ channel vector ${\mathbf{H}(f)}=\{H(f,0),...,H(f,L-1)\} $.% and the CFR of $f_{ul}$ obtained by Alice as $\mathbf{H}_{A}=\mathbf{H}(f_{ul})$, the CFR of $f_{dl}$ obtained by Bob as $\mathbf{H}_{B}=\mathbf{H}(f_{dl})$ .
As shown in (\ref{CFR}), the amplitude and phase of wireless channel ${\mathbf{H}(f)}$ are influenced by their frequencies. %Although the downlink and uplink transmissions travel via the same paths, the channel features $\mathbf{H}_{A}$ and $\mathbf{H}_{B}$ are almost different in FDD systems. 
Therefore, extracting reciprocal channel features for key generation in FDD-OFDM systems is challenging.

\begin{figure}[!t]
	\centering
	\includegraphics[width=\linewidth]{TL-KG-eps-converted-to.pdf}
	\caption{Deep learning-based key generation for FDD-OFDM systems.}
	\label{DL_KG}
\end{figure}

%Based on theorem \ref{theorem1}, 
Deep learning has been introduced for PKG in FDD-OFDM systems recently \cite{zhang2021secret,wan2021secret,hou2021secret,zhang2022deep}. This type of method uses deep learning technology to map the uplink features to the downlink features, so that both parties can obtain the downlink features at the same time. As shown in Fig. \ref{DL_KG}, the deep learning-based key generation contains the following four steps.

% \subsubsection{Preparation Stage}
% In the preparation stage, Alice and Bob perform multiple channel estimations and feature extractions. Alice collects the downlink channel features sent by Bob, and combines the uplink channel features saved by herself to construct a training dataset. Then, Alice uses this dataset to train a deep learning model, which can then be directly used for key generation.

% \subsubsection{Key Generation Stage}
% \label{key generation stage}
%The key generation stage contains the following five steps: 

%\jz{step 1 and 2 are used in preparation stage too.}

\subsection{CSI Estimation}
Alice and Bob simultaneously send OFDM pilot signals to each other at carrier frequencies $f_{dl}$ and $f_{ul}$, and then independently estimate the channel CFR based on the received pilot signals, expressed as 
\begin{equation}
	\begin{split}
		\begin{cases}
			\hat{H}_{A}\left(f_{ul}, l\right)=H\left(f_{ul}, l\right)+E_{1}\left(f_{ul}, l\right) \\
			\hat{H}_{B}\left(f_{dl}, l\right)=H\left(f_{dl}, l\right)+E_{2}\left(f_{dl}, l\right)
		\end{cases}
		,
	\end{split}
\end{equation}
where $E_{1}\left(f_{ul}, l\right)$ and $E_{2}\left(f_{dl}, l\right)$ represent the channel estimation error, which can be modeled as additive white Gaussian noise (AWGN) with mean 0 and variance $\sigma_{E}^{2}$. After channel estimation, Alice and Bob get estimated CFRs $\mathbf{\hat{H}}_A$ and  $\mathbf{\hat{H}}_B$, respectively.

\subsection{Feature Extraction}
Alice and Bob perform feature extraction to extract real-valued channel features $\mathbf{x}_A$ and $\mathbf{x}_B$ that are suitable for training deep learning model and key generation. 
The real and imaginary parts are separated from $\mathbf{H}$ as
\begin{equation}
	\begin{split}
		\mathbf{x}'\leftarrow(\mathfrak{R}(\mathbf{H}),\mathfrak{T}(\mathbf{H})),
	\end{split}
\end{equation}
where $\mathfrak{R}(\cdot)$ and $\mathfrak{T}(\cdot)$ denote the real and imaginary parts of a matrix, vectors or scales, respectively.

The dataset is then normalized so that the range of the samples is between 0 and 1. The minimum and maximum values of the vectors in each dimension of the training dataset are saved and used for min-max normalization, i.e.,
\begin{equation}
\begin{split}
\mathbf{x}=\frac{\mathbf{x}'-\min (\mathbf{x}'_{\text{train}})}{\max (\mathbf{x}'_{\text {train}})-\min (\mathbf{x}'_{\text {train}})}, \quad \mathbf{x} \in[0,1]^{n^d},
\end{split}
\end{equation}
where $\mathbf{x}$ is the normalized value of $n^d$ dimensions.
After feature extraction, Alice and bob get suitable channel features $\mathbf{x}_A$ and $\mathbf{x}_B$, respectively.
%\jz{If this step is used in key generation too, you should not use $x_{train}$.}

\subsection{Feature Mapping (only Alice)}
Based on \cite{zhang2022deep}, there is a feature mapping function $\mathcal{F}$ in each given environment. Alice can use $\mathcal{F}$ to predict the estimated downlink features $\mathbf{x}_{A}^{B}$ from $\mathbf{x}_A$, which can be expressed as
\begin{equation}
\mathbf{x}_{A}^{B} = \mathcal{F} (\boldsymbol{\Omega}, \mathbf{x}_A),
\label{mapping6}
\end{equation}
where $\boldsymbol{\Omega}$ is the parameters for feature mapping, which can be obtained by deep learning techniques. Through this step, Alice and Bob are considered to have obtained highly similar features $\mathbf{x}_{A}^{B}$ and $\mathbf{x}_B$, respectively. How to get the optimal value of parameters to minimize the gap between $\mathbf{x}_{A}^{B}$ and $\mathbf{x}_{B}$ is essential to generating highly similar features.
%Since the uplink and downlink channels pass through the same propagation path and scattering cluster, it is experimentally shown in \cite{vasisht2016eliminating} that there is a transformation function that can map the channel to the underlying path. Furthermore, prior work has shown that it is possible to infer downlink channels from uplink channels \cite{alrabeian2019deep,bakshi2019fast,liu2021Fire}. In \cite{zhang2022deep}, It is proved that in a given environment, when the channel mapping function of possible user locations to antennas is bijective, there exists a feature mapping function $\mathcal{F}(\cdot)$ that can map the one frequency band features to another frequency band features, and the channel feature mapping function can be obtained by a simple deep learning model. This conclusion provides a theoretical basis for introducing deep learning into key generation.

% Since the uplink and the downlink transmissions travel the same propagation paths and suffer the same cluster in a given environment, there exists a channel mapping function between different frequency bands \cite{zhang2022deep}. The channel mapping function can be written as
% \begin{equation}
% 	\begin{split}
% 	\boldsymbol{\Psi}^{}_{f_{ul}\rightarrow f_{dl}} : \mathbf{H}(f_{ul}) \rightarrow \mathbf{H}(f_{dl}).
% 	\end{split}
% \end{equation}
%As shown in (\ref{CFR}), the channel mapping function can not be expressed as mathematical formulas, deep learning technology can be used to approach this mapping function. At first, we only consider a simple three-layers fully connected neural network (FNN) with one hidden layer.
% Since the CFRs are in complex domain and are not in a certain range, the value of CFRs could not be used to train the deep learning model directly. 

% Suppose that the feature extraction function $\boldsymbol{\xi}$ can obtain feature $\mathbf{x}$ after preprocessing $\mathbf{H}$, the inverse function of  $\boldsymbol{\xi}$ as $\boldsymbol{\xi}^{-1}$, the conclusion in \cite{zhang2022deep} can be expressed as the following theorem.
% \begin{theorem}
% 	For any given error $\varepsilon>0$, there exists a positive constant $M$ large enough such that
% 	\begin{equation}
% 	\begin{split}
% 	\sup_{\boldsymbol{\mathbf{x}}\in\mathbb{H}} \parallel \textbf{NET}_M(\mathbf{x}(f_{ul}),\boldsymbol{\boldsymbol{\Omega}})-\boldsymbol{\Psi}^{'}_{f_{ul}\rightarrow f_{dl}}(\mathbf{x}(f_{ul})) \parallel \leq \varepsilon,\\
% 	\mathbb{H}=\{\mathbf{x}(f_{ul})\},
% 	%\subseteq \mathbb{R}^{2L},
% 	\end{split}
% 	\end{equation}
% where the channel feature mapping function $\boldsymbol{\Psi}^{'}_{f_{ul}\rightarrow f_{dl}} =\boldsymbol{\xi}_{f_{dl}} \circ \boldsymbol{\Psi}_{f_{ul}\rightarrow f_{dl}} \circ \boldsymbol{\xi}_{f_{dl}}^{-1} : \mathbf{x}(f_{ul}) \rightarrow \mathbf{x}(f_{dl})$, $\textbf{NET}_M(\mathbf{x}(f_{ul}))$ is the output of a feedforward neural network (FNN) with only one hidden layer. $\mathbf{x}(f_{ul})$, $\boldsymbol{\boldsymbol{\Omega}}$ and $M$ denote the input data, network parameters, and the number of hidden units, respectively.
% \label{theorem1}
% \end{theorem}


%However, as the model may can not be used in other environments or a dynamic environment. This challenge can be formulated by a DTL problem and a meta-learning problem that leverage existing knowledge to improve model performance in new environments. 

\subsection{Key Establishment}
Alice and Bob use obtained features to generate keys, including quantization, information reconciliation and privacy amplification \cite{peng2017secret}. We use a Gaussian distribution-based quantization method with guard-band proposed in \cite{zhang2022deep} to get the initial keys $\mathbf{Q}_A$ and $\mathbf{Q}_B$. Denote the probability of the channel features $\mathbf{x}$ as a definite Gaussian distribution $\mathcal{N}_Q=\mathcal{N}(\mu,\sigma^2)$, where $\mu$ is the mean of vector $\mathbf{x}$, $\sigma$ is the standard deviation of vector $\mathbf{x}$, and $F^{-1}$ as the inverse of the cumulative distribution function (CDF) of $\mathcal{N}_Q$. The values between 0 and $F^{-1}(0.5-\varepsilon)$  are quantized as 0, and the values between $F^{-1}(0.5+\varepsilon)$ and 1 are quantized as 1.
The $\varepsilon \in (0,0.5)$ is defined as the quantization factor, and the values between $F^{-1}(0.5-\varepsilon)$ and $F^{-1}(0.5+\varepsilon)$ are discarded.

Information reconciliation and privacy amplification methods adopted by most key generation methods are mostly common \cite{9123376, 10.1145/3429740}. In addition, the research purpose of this paper is to improve the channel reciprocity in the FDD system, thus this paper only compares the performance of the initial keys after quantization and does not carry out the steps of information reconciliation and privacy amplification.

\section{System Overview}
\label{system overview}

Among the four steps introduced in Section~\ref{Preliminary}, feature mapping is the crucial step for key generation between Alice and Bob. Therefore, this paper focuses on how to use deep learning techniques to quickly and efficiently obtain feature mapping functions $\mathcal{F}$ in multiple environments.


%In this section, we first introduce the key generation problem in multiple environments, then formulate it as a learning-based problem and give an overview of the proposed algorithms.

\subsection{Problem Statement}\label{Problem Formulation}
It is clear that the good performance of generated keys depends on the performance of the deep learning model. The existing works have verified the good fitting and generalization performance of the deep learning model to obtain the feature mapping function $\mathcal{F}$ in a certain environment \cite{zhang2021secret,wan2021secret,hou2021secret,zhang2022deep}. 
However, when the environment changes, the parameters of $\mathcal{F}$ are also affected by the environment, and the training samples and the actual samples of the deep learning model no longer obey a uniform distribution, which will lead to poor performance of the parameters in the new environment and even invalidate the effect of feature mapping.

%However, when the environment changes, the parameters of $\mathcal{F}(\cdot)$ also change, which causes this kind of method may suffer from the problem that the training samples are not in the same distribution as the actual samples, and thus the performance of the deep learning model will be greatly reduced. 


As shown in Fig. \ref{DTL_se}, suppose a user is in the environment(E)1, a deep learning model 1 can be trained to get the parameters $\boldsymbol{\Omega}$ for feature mapping and key generation between the BS and the user in this given environment. However, when the user moves to other environments, such as E2 and E3, the training samples of model 1 and actual samples in the new environment no longer obey the same distribution, resulting in the performance of pre-trained deep learning model being degraded or even invalid. 

\begin{figure}[!t]
	\centering
	\includegraphics[width=0.8\linewidth]{DTL_2-eps-converted-to.pdf}
	\caption{Deep learning-based PKG problem in multi-environments. }
	\label{DTL_se}
\end{figure}

A simple way to solve this problem is to re-collect the data and re-train the model for each new environment. However, training a model requires a lot of training data and training resources, which is unacceptable for practical applications. Therefore, this paper aims to address this problem and formulates it as a learning-based problem to more efficiently learn feature mapping functions in new environments using known knowledge in the source environment.

%In this section, we first prove the possibility of using deep learning to construct reciprocal channel features in FDD-OFDM systems and introduce the deep learning-based key generation. Then, we formula key generation problem in multi-environments as a learning-based problem and give the system overview.



\subsection{Learning-based Problem for PKG}\label{DTL_problem}
Assume that there are data in $E$ wireless scenarios, and the uplink and downlink channel characteristics in the $e^{th}$ environment are defined as $\mathbf{x}_A^e$ and $\mathbf{x}_B^e$ respectively. The ``domain" and ``task" in the $e^{th}$ environment are defined as following:

\begin{definition}[Domain]
The domain $\mathcal{D}(e)$ is composed of the feture space $\mathcal{X}^e$ and the marginal probability distribution $P({\mathbf{x}_A^e})$, i.e., $\mathcal{D}(e)=\{\mathcal{X}^e,P({\mathbf{x}_A^e})\}$. And the symbol $\mathcal{X}^e$ denotes an instance set, which is defined as all possible uplink
channel features $\mathbf{x}_A^e$, i.e., $\mathbf{x}_A^e \in \mathcal{X}^e$.
\end{definition}


\begin{definition}[Task]
The task $\mathcal{T}(e)$ is composed of the label space $\mathcal{Y}^e$ and a decision function $f^e$, i.e., $\mathcal{T}(e)=\{\mathcal{Y}^e,f^e\}$. And the symbol $\mathcal{Y}^e$ denotes an instance set, which is defined as all possible uplink
channel features $\mathbf{x}_B^e$, i.e., $\mathbf{x}_B^e \in \mathcal{Y}^e$.
\end{definition}

In a certain environment (domain $\mathcal{D}_{SE}$ and task $\mathcal{T}_{SE}$), the decision function $f^e$  can be obtained by model training. According to \cite{zhang2022deep}, the decision function $f^e$ can be considered as the feature mapping function $\mathcal{F}^e$ in the $e^{th}$ environment. Trained networks can act as the feature mapping function to achieve the feature mapping for key generation. However, when in a new environment (domain $\mathcal{D}_{TE}$ and task $\mathcal{T}_{TE}$), the feature mapping function $\mathcal{F}$ will change, and the performance of the trained model will be greatly reduced and cannot be used continuously.
%A simple method is to re-collect the training model in each environment, but this requires a lot of training resources and training data, which is difficult to meet in real-world applications.
%Therefore, the main problem to be solved in this paper is how to quickly obtain the feature mapping function $\mathcal{F}$ in the new environment (domain $\mathcal{D}_{TE}$ and task $\mathcal{T}_{TE}$) with a small amount of data and limited resource consumption to generate keys.

We formulate this problem as a learning-based problem, i.e., learning from the known environments enables fast key generation in multiple new environments using a small amount of data and limited resources, formally defined as follows. Given the number of source tasks $E_S$, the source domains $\{\mathcal{D}_{SE}(e)\}_{e=1}^{E_S}$, the source tasks$\{\mathcal{T}_{SE}(e)\}_{e=1}^{E_S}$, the number of source tasks $E_T$, the target domains $\{\mathcal{D}_{TE}(e)\}_{e=1}^{E_T}$ and the target tasks $\{\mathcal{T}_{TE}(e)\}_{e=1}^{E_T}$, the learning-based problem in this paper is to leverage knowledge (data and models) from $\{\mathcal{D}_{SE}(e)\}_{e=1}^{E_S}$ and $\{\mathcal{T}_{SE}(e)\}_{e=1}^{E_S}$ to learn new tasks $\{\mathcal{T}_{TE}(e)\}_{e=1}^{E_T}$ with a small amount of data and limited resource, where $\{\mathcal{T}_{TE}(e)\}_{e=1}^{E_T}\ne\{\mathcal{T}_{SE}(e)\}_{e=1}^{E_S}$ and $\{\mathcal{D}_{TE}(e)\}_{e=1}^{E_T}\ne\{\mathcal{D}_{SE}(e)\}_{e=1}^{E_S}$. 

\subsection{Algorithm Overview}
This paper proposes DTL-based and meta-learning-based feature mapping algorithms for key generation in multi-environments, elaborated in Section~\ref{DTL} and Section~\ref{meta}, respectively.
DTL and meta-learning aim to learn from source tasks to increase the generalization ability of the model under multi-task, and thus are two promising techniques for solving learning-based problems. 
Unlike learning functions $\mathcal{F}$ directly training the deep learning model in a given environment, these two algorithms include the training and adaptation stages, as shown in Fig.~\ref{learning_scheme}. 
\begin{itemize}
    \item Training stage: The two algorithms use datasets from known environments to train the model. DTL and meta-learning use different training methods, called pre-training and meta-training, respectively.
    \item  Adaptation stage: The two algorithms fine-tune the model using the datasets from the new environments, and then the fine-tuned model can be used for feature mapping and key generation.
\end{itemize}
\begin{figure}[!t]
	\centering
	\includegraphics[width=\linewidth]{learning_scheme-eps-converted-to.pdf}
	\caption{The proposed learning-based feature mapping scheme.}
	\label{learning_scheme}
\end{figure}


This paper considers a simple FNN as the basic network structure to learn the feature mapping function $\mathcal{F}$ in the proposed algorithms, as shown in Fig. \ref{learning_scheme}. The input of the network is the uplink channel feature vector $\mathbf{x}_A$ obtained by Alice, and the output of the network is the result of the cascade of $\mathbf{x}_A$ through nonlinear transformation. The network is used to map the features of the uplink and downlink, so the output of the network is considered to be the estimated vector $\mathbf{x}_A^B$ of the downlink channel feature vector $\mathbf{x}_B$, which also can be expressed as \eqref{mapping6}, i.e.,  $\mathbf{x}_A^B=\mathcal{F}(\boldsymbol{\Omega},\mathbf{x}_{A})$,
where $\boldsymbol{\Omega}$ is all parameters in this network to be trained for feature mapping. The FNN consists of $M$ layers, including one input layer, $M-2$ hidden layers and one output layer. The output $f_m(\mathbf{x})$ of the $m^{th}$ layer is a nonlinear transformation of the output of $m-1^{th}$ layer, which can be written as:
\begin{equation}
\begin{split}
f_m(\mathbf{x})=F_{A,m}(\mathbf{W}_m \mathbf{x}+\mathbf{b}_m), 2 \leq m  \leq M,
\end{split}
\end{equation}
where $F_{A,m}$, $\mathbf{W}_m$ and $\mathbf{b}_m$ are the activation function of $m^{th}$ layer, weight vector between $(m-1) ^{th}$ and $m^{th}$ layers and bias vector of $m^{th}$ layer, respectively. The rectified linear unit (ReLU) function commonly used in regression problems is selected as the activation function $F_{A,m}$ of the hidden layers, and the sigmoid function is selected as the activation function $F_{A,m}$ of the output layer.

The purpose of the network is to learn the band feature mapping, so we could train network to minimize the difference between network output $\mathbf{x}_A^B$ and $\mathbf{x}_{B}$. Obviously, a vector regression problem is considered in this paper, we consider to use the mean squared error (MSE) as the loss function of the neural network. The loss function is defined as:
\begin{equation}
\begin{split}
\mathcal{L}_{\mathbb{D}}(\boldsymbol{\Omega})=\frac{1}{N_{batch}}\sum_{i=0}^{N_{batch}-1}\|{\mathbf{x}_{A}^{B}}(i)-\mathbf{x}_{B}(i)\|_2^2,
\label{loss}
\end{split}
\end{equation}
where $\mathbb{D}=\{(\mathbf{x}_{A},\mathbf{x}_{B})\}_{i=0}^{N_{batch}-1}$ is a batch-sized training dataset, $N_{batch}$ is the batch size.
%, the superscript $(i)$ denotes the index of the $i$-th training sample.

%\textbf{DTL v.s. Meta-learning}: Both transfer learning and meta-learning-based feature mapping have same stages, but the methods used in the training stage are different. Transfer learning pre-trains the network on data from all source environments as a whole, while meta-learning learns optimal initialization parameters for the model from multiple tasks, where the feature mapping function in each source environment represent a separate task. The DTL algorithm minimizes the loss of the current model (only one) on all tasks, so the DTL algorithm hopes to find an initialization parameter that performs better on all current tasks. 
%The Meta-learning algorithm first uses the support dataset to minimize the loss function in each task, then uses the query dataset to minimize the loss sum of all tasks, and finally updates all model parameters with the model parameters obtained by minimizing the sum of loss functions of all tasks, which means that the performance of the model obtained after training to convergence under each task using the final initialization parameters obtained by meta-learning should still be as good as possible. Therefore, compared to the DTL algorithm, meta-learning algorithm makes better use of knowledge in multiple environments, and the resulting model initialization parameters have better generalization, which is also proved in the results in Section \ref{simulation}. \jz{combines this paragraph into Section IV and Section V. people won't under these contents here.}


%When the feature mapping function $\boldsymbol{\Psi}^{' }_{f_{ul}\rightarrow f_{dl}}$  is a non-linear function that can be learned by a deep learning model, the transfer learning task $<\{\mathcal{D}_{SE}(e)\}_{e=1}^{E_S}, \{\mathcal{T}_{SE}(e)\}_{e=1}^{E_S}, \{\mathcal{D}_{TE}(e)\}_{e=1}^{E_T}, \{\mathcal{T}_{TE}(e)\}_{e=1}^{E_T}>$ is a DTL task.

%According to Definition~\ref{deeptransferlearning}, the problem of key generation in multi-environments can be formulated as a DTL problem, i.e., using knowledge (data and models) from known environments to make it possible to quickly obtain deep learning models that can be used to generate keys in new environments.

%\subsection{Meta-Learning Problem for PKG}
%\label{meta_problem}
%
%Meta-learning, as another effective technique to deal with the task mismatch problem, learns the initialization values of the model from multiple tasks. Therefore, based on \cite{hospedales2020meta}, the problem that we aim to solve in this paper also can be formulated as a meta-learning problem, and the definition of meta-learning can be given as following: 
%\begin{definition}[Meta-learning]
%Given the number of source tasks $E_S$, the source domains $\{\mathcal{D}_{SE}(e)\}_{e=1}^{E_s}$, the source tasks$\{\mathcal{T}_{SE}(e)\}_{e=1}^{E_s}$, the target domains $\mathcal{D}_{TE}$ and the target tasks $\mathcal{T}_{TE}$, meta learning aims to leverage knowledge of $\{\mathcal{D}_{SE}(e)\}_{e=1}^{E_s}$ and $\{\mathcal{T}_{SE}(e)\}_{e=1}^{E_s}$ to learn how to learn new task $\mathcal{T}_{TE}$, where $\mathcal{T}_{TE}\ne\{\mathcal{T}_{SE}(e)\}_{e=1}^{E_s}$ and $\mathcal{D}_{TE}\ne\{\mathcal{D}_{SE}(e)\}_{e=1}^{E_s}$.
%\end{definition}
%
%\begin{remark}[DTL vs. Meta-learning]
%Generally, deep transfer learning needs a large amount of samples from the source task to train the model, while meta-learning requires data from multiple task, and the amount of samples in each task is small.
%When there are datasets from multiple environments and the amount of data in each environment is small, meta-learning is obviously an optimal choice compared to DTL. When there is a large amount of data in only one scenario, meta-learning techniques can be employed by dividing the source scenario into multiple task scenarios. The simulation results in Section \ref{simulation} show that meta-learning is still better than DTL in this case.
%\end{remark}

%\section{Feature Extraction for Key Generation}
%\label{framework}
%Firstly, we could process the estimated CFRs to obtain the suitable features for PKG in FDD systems. We verify the performance of the method proposed in \cite{zhang2022deep} in the outdoor scenario and find that the feature extraction method can not be used in the outdoor scenario. Based on this observation, we propose a general feature extraction framework, which can construct suitable features in the different scenarios.
%
%\subsection{Observation}
%
%\begin{figure}[!t]
%\centering
%
%\subfigure[The amplitude of CFR in the indoor scenario.]{
%\begin{minipage}[t]{0.5\linewidth}
%\centering
%\includegraphics[width=\linewidth]{Indoor_abs-eps-converted-to.pdf}
%%\caption{fig1}
%\label{A}
%\end{minipage}%
%}%
%\subfigure[The real and imaginary parts of CFR in the indoor scenario.]{
%\begin{minipage}[t]{0.5\linewidth}
%\centering
%\includegraphics[width=\linewidth]{Indoor_RI-eps-converted-to.pdf}
%%\caption{fig2}
%\label{B}
%\end{minipage}%
%}
%
%\subfigure[The amplitude of CFR in the outdoor scenario.]{
%\begin{minipage}[t]{0.5\linewidth}
%\centering
%\includegraphics[width=\linewidth]{Outdoor_abs-eps-converted-to.pdf}
%%\caption{fig2}
%\label{C}
%\end{minipage}
%}%
%\subfigure[The real and imaginary parts of CFR in the outdoor scenario.]{
%\begin{minipage}[t]{0.5\linewidth}
%\centering
%\includegraphics[width=\linewidth]{Outdoor_RI-eps-converted-to.pdf}
%%\caption{fig2}
%\label{D}
%\end{minipage}
%}%
%
%\centering
%\caption{The different features in the indoor and outdoor scenarios.}
%\label{compare}
%\end{figure}
%
%
%In \cite{zhang2022deep}, the features used for key generation are the real and imaginary parts of the CFR, and simulations only verify the performance in the indoor scenario. This paper further collects data in the outdoor scenario to verify the performance and finds that the same feature extraction method is no longer suitable for use in the outdoor scenario. 
%
%As shown in Fig. \ref{A} and \ref{B}, in indoor scenario, the channel multipath and scatterer are not abundant enough, and the amplitude fluctuation of the channel is not obvious enough to represent the surrounding environment, so it is difficult for the deep learning model to obtain the feature mapping function. While the real and imaginary parts of the channel include the amplitude and phase information of the channel, and the fluctuations are also more obvious. Therefore, in the indoor environment, the real and imaginary parts of the CFR are selected as features for generating keys, which also has two advantages. One is that the features with obvious fluctuations can improve the randomness of the generated key, and the other is that quantifying the real and imaginary parts separately can improve the KGR.
%
%In the outdoor scenario, the channel multipath as well as the scattering environment is more complex. As shown in the Fig. \ref{C} and \ref{D}, the fluctuations of the channel are more intense. In this case, although the amplitude and phase of the channel represent more complete channel information, the deep learning model is hard to learn such a complex channel environment with a limited dataset. Therefore, in the outdoor scenario with complex scattering, we choose to let the deep learning model learn only part of the environment, i.e., learn the mapping relationship of channel amplitudes between different frequency bands.
%%in the indoor scenario, the channel multipaths and scatterers are not abundant enough,  the variation of channel amplitudes is not significant enough for deep learning models to obtain mapping relationships between waveforms that do not vary much. Therefore, in the indoor environment, the real and imaginary parts of CFR are selected as the features for generating keys, which has two advantages. One is that features with significant fluctuations can improve the randomness of the generated keys, and the other is that quantizing the real and imaginary parts separately can improve the KGR. 
%
%%In the outdoor scenario, the channel environment is more complex, and the amplitude and phase changes are more obvious, resulting in excessive fluctuations of the real and imaginary parts of the superimposed CFR, and the deep learning model is unable to learn the mapping between the waveforms with excessive changes. Meanwhile, the variability of channel amplitudes in outdoor scenes is sufficient, so the amplitude of the CFR should be selected as the features for key generation.
%
%%in the indoor scenario, the channel multipath, scatterers, etc. are not rich enough, the change of the channel amplitude of the channel is not obvious, and it is difficult for the deep learning model to learn the mapping between the waveforms with little change. Therefore, in the indoor environment, the real and imaginary parts of CFR are selected as features to generate keys, which has two advantages. The first is that the features with obvious fluctuations can improve the randomness of the keys, and the second is to use CFR separately. Quantizing the real and imaginary parts can improve the key generation rate. In outdoor scenes, the channel environment is more complex, and the changes in amplitude and phase are more obvious, resulting in excessive fluctuations in the real and imaginary parts of the superimposed CFR, and it is difficult for the deep learning model to learn the mapping between the waveforms with excessive changes. At the same time, the change of the channel amplitude in the outdoor scene is already obvious, so the amplitude of the CFR should be selected as a feature for key generation. 
%
%In summary, according to different scenarios, different feature extraction methods should be selected to obtain the most suitable features for band mapping and key generation.
%
%\subsection{The General Feature Extraction Framework}
%
%\begin{figure}[!t]
%	\centering
%	\includegraphics[width=\linewidth]{./Feature_extraction.pdf}
%	\caption{The general feature extraction framework, including two steps, i.e., realization and normalization. }
%	\label{feature_extraction}
%\end{figure}
%Based on the observation, we proposed a general feature extraction framework, as shown in Fig. \ref{feature_extraction}. This framework includes two steps, namely realization and normalization, where the appropriate realization method is chosen according to the degree of fluctuation of different features.
%
%\subsubsection{Realization}
% The realization have two methods. The first method is to separate real and imaginary parts from $\mathbf{H}$, i.e.,
%\begin{equation}
%\begin{split}
%\mathbf{x}^{(1)}\leftarrow(\mathfrak{R}(\mathbf{H}),\mathfrak{T}(\mathbf{H})),
%\end{split}
%\end{equation}
%where $\mathfrak{R}(\cdot)$ and $\mathfrak{T}(\cdot)$ denote the real and imaginary parts of a matrix, vectors or scales, respectively.
%Another method is to calculate the amplitude of $\mathbf{H}$, i.e.,
%\begin{equation}
%\begin{split}
%\mathbf{x}^{(1)}\leftarrow ||\mathbf{H}||_2,
%\end{split}
%\end{equation}
%where $\|\cdot\|_2$ denotes the $L_2$ norm. 
%
%\begin{remark}
%These two methods are suitable for different wireless environments, when the wireless environment is complex, it is suitable to use method 1, and when the wireless environment changes slowly, it is suitable to use method 2. In practise, we should try these two methods to observe the degree of fluctuation of the features to choose the most suitable method.
%\end{remark}
%
%It should be emphasized that the two realization methods are used in this paper in the indoor and outdoor scenarios, respectively. In practice, these two methods can be tried in many different scenarios, depending on the degree of channel variation in the real environment.
%%We could try these two methods and choose the most suitable method based on the fluctuation of the features.
%
%\subsubsection{Normalization}
%Normalization is commonly used to normalize the dataset so that the range of the dataset is between 0 and 1. The minimum and maximum values of the vector s in each dimension after realization using the training dataset are saved for min-max normalization,
%\begin{equation}
%\begin{split}
%\mathbf{x}=\frac{\mathbf{x}^{(1)}-\min (\mathbf{x}_{\text{train}}^{(1)})}{\max (\mathbf{x}_{\text {train}}^{(1)})-\min (\mathbf{x}_{\text {train}}^{(1)})}, \quad \mathbf{x} \in[0,1]^{n^d},
%\end{split}
%\end{equation}
%where $\mathbf{x}$ is the normalized value of $n^d$ dimensions.
%
%With these two steps, we can get features with values in the range of 0 to 1. The processed features facilitate the subsequent learning of deep learning models.

\section{DTL-Based Feature Mapping}\label{DTL}
Based on the learning-based problem formulated in Section~\ref{DTL_problem}, this section proposes a DTL-based feature mapping to achieve key generation in new environments for FDD-OFDM systems.
DTL transfers knowledge from the source environment to the target environment, so that the network in target environment can achieves a better learning effect. In general, datasets in the source environments are abundant, while datasets in the target domains are small, so most DTL algorithms use datasets from source tasks to pre-train the model and then fine-tunes it under a new task \cite{nguyen2021transfer}. Like these works, in our proposed DTL-based feature mapping, we use the datasets from the source environments to pre-trained a model and then use a small number of samples to fine-tune the pre-trained model to obtain a model with good performance in the new environment.

\subsection{Definition of Dataset}
%Each task represents a frequency band feature mapping for Alice in a given environment.
%Assume that the original datasets $\{\mathbb{D}_{OS}(e)\}_{e=1}^{E_S}$ is collected from $E_S$ source environments, where the dataset $\mathbb{D}_{OS}(e)=\{(\mathbf{H}_A^{(n)}(e),\mathbf{H}_B^{(n)}(e)) \}_{n=1}^{N_{S}}$ includes $N_{S}$ samples in the $e^{th}$ environment, and the dataset after feature extraction as 
Assume that the source datasets $\{\mathbb{D}_{S}(e)\}_{e=1}^{E_S}$ is collected from $E_S$ source environments, where the dataset $\mathbb{D}_{S}(e)= \{(\mathbf{x}_A^{(n)}(e),\mathbf{x}_B^{(n)}(e))\}_{n=1}^{N_S}$ includes $N_{S}$ samples in the $e^{th}$ environment. 
Furthermore, it is necessary to collect dataset in multiple target environments to evaluate the performance of the algorithm. Assume that the target datasets $\{\mathbb{D}_{T}(e)\}_{e=1}^{E_T}$ from $E_T$ target environments, where the dataset in the $e^{th}$ environment $\mathbb{D}_{T}(e)=\{( \mathbf{x}_A^{(n)}(e),\mathbf{x}_B^{(n)}(e))\}_{n=1}^{N_T}$ includes $N_{T}$ data samples.

%Denote the original dataset in the source environments $\mathbb{D}_{OS}=\{(\mathbf{H}_A^{(n)},\mathbf{H}_B^{(n)})\}_{n=1}^{N_{S}}$, including $N_{S}$ samples, and the dataset after feature extraction as $\mathbb{D}_{S}=\{(\mathbf{x}_A^{(n)},\mathbf{x}_B^{(n)})\}_{n=1}^{N_{S}}$. Denote the original dataset in $E_T$ target environments as $\{\mathbb{D}_{OT}(e)\}_{e=1}^{E_T}$, where the dataset of $e^{th}$ environment as $\mathbb{D}_{OT}(e)=\{(\mathbf{H}_A^{(n)}(e),\mathbf{H}_B^{(n)}(e))\}_{n=1}^{N_{T}}$, including $N_{T}$ samples, and the dataset after feature extraction as $\mathbb{D}_{T}(e)=\{(\mathbf{x}_A^{(n)}(e),\mathbf{x}_B^{(n)}(e))\}_{n=1}^{N_T}$.

In DTL algorithm, the datasets $\{\mathbb{D}_{S}(e)\}_{e=1}^{E_S}$ from all source environments are considered as a whole as the training dataset. The dataset $\mathbb{D}_{T}(e)$ in the target $e^{th}$ environment divides into adaption dataset $\mathbb{D}_{Ad}(e)=\{(\mathbf{H}_A^{(n)}(e),\mathbf{H}_B^{(n)}(e))\}_{n=1}^{N_{Ad}}$ and testing dataset $\mathbb{D}_{Te}(e)=\{(\mathbf{H}_A^{(n)}(e),\mathbf{H}_B^{(n)}(e))\}_{n=1}^{N_{Te}}$, where $N_{Ad}+N_{Te}=N_T$.

%\jz{too many symbols here, can you simplify them? OS, OT, $\mathbb{D}_{S}$, $\mathbb{D}_{T}$}


% \begin{algorithm}[!t]
% \algsetup{linenosize=\small} \small
%     \caption{\label{TL}The DTL algorithm for key generation in FDD-OFDM systems \jz{remove the algorithm; combine the content into the text.}} 
%     \begin{algorithmic}[1]
%         \REQUIRE ~~\\ 
%         The training dataset in a source environment: $\mathbb{D}_{Tr}$, 
%         the adaption dataset in target environments: $\{\mathbb{D}_{Ad}(e)\}_{e=1}^{E_T}$,
%         the testing dataset in target environments: $\{\mathbb{D}_{Te}(e)\}_{e=1}^{E_T}$,
%         learning rate: $\gamma $,
%         batch size: $N_{batch}$,
%         the number of the gradient update in fine-tuning stage: $G_{Ad}$.
%         \ENSURE ~~\\ 
%         The trained parameters of pre-trained model: $\Omega$,        
%         the trained parameters in each target environment: $\Omega_e$,
%         Initial keys: $K_A$ and $K_B$.
% %        the predicted downlink features: $\hat{\mathbf{x}}_B$,
% %        the average NMSE of target environments: $\mathrm{NMSE}$.
        
%     \STATE \textbf{\textit{Pre-training stage in a source environment}}
%     \STATE Randomly initialize the network parameters $\Omega $;
%     \FOR{t=1,...}
%     \STATE Randomly select $N_{batch}$ samples from $\mathbb{D}_{Tr}$ to construct $\mathbb{D}_{TrB}$;
%     \STATE Update $\Omega$ using the ADAM \cite{kingma2014adam} algorithm ( learning rate $\gamma $) to minimize $\mathcal{L}_{\mathbb{D}_{TrB}}(\boldsymbol{\Omega})$;
%     \ENDFOR
    
% %    \STATE Initialize $\mathrm{NMSE}_{total}\longleftarrow 0$;
%     \FOR{ $e=1,...,E_T$ }
%     \STATE \textbf{\textit{Fine-tuning stage in the target environment}}
%     \STATE Initialize the network parameters $\Omega_e \longleftarrow \Omega$;
%     \FOR{$j =1 ,..., G_{Ad}$}
%     \STATE Randomly select $N_{batch}$ samples from $\mathbb{D}_{Ad}(d)$ to construct $\mathbb{D}_{AdB}$;  
%     \STATE Update $\Omega_e$ using the ADAM algorithm ( learning rate $\gamma $) to minimize $\mathcal{L}_{\mathbb{D}_{AdB}}(\boldsymbol{\Omega_e})$;
%     \ENDFOR
    
%     \STATE \textbf{\textit{Key generation stage in the target environment}}
%     \STATE Alice and Bob set pilots to each other simultaneously.
%     \STATE Alice and Bob perform channel estimation and feature extraction.
%     \STATE Alice predicts the downlink features $\hat{\mathbf{x}}_B$ using Eq. (\ref{predict});
%     \STATE Alice and bob quantize the features to obtain the initial keys $K_A$ and $K_B$;
% %    \STATE Information reconciliation and privacy amplification;
% %    \STATE Calculate $\mathrm{NMSE}(e)$ using Eq. (\ref{NMSE});
% %    \STATE $\mathrm{NMSE}_{total} \longleftarrow  \mathrm{NMSE}_{total}+\mathrm{NMSE}(e)$;
%     \ENDFOR 
% %    \STATE $\mathrm{NMSE} \longleftarrow  \mathrm{NMSE}_{total} /E_T$;
%     \end{algorithmic}
% \end{algorithm}

\subsection{Training (Pre-training) Stage}

The pre-training stage trains the model using dataset $\{\mathbb{D}_{S}(e)\}_{e=1}^{E_S}$ from the source environments to minimize the loss function $\mathcal{L}_{\mathbb{D}_{Tr}}(\boldsymbol{\Omega})$. 

% \begin{figure}[!t]
% 	\centering
% 	\includegraphics[width=\linewidth]{Network-eps-converted-to.pdf}
% 	\caption{Network architecture. }
% 	\label{Network}
% \end{figure}

In each batch, $N_{batch}$ samples are randomly selected from $\mathbb{D}_{Tr}$ to construct a batch training dataset  and then ADAM \cite{kingma2014adam} optimizer is used to optimize the parameters of the model. When the performance of the model tends to be constant or the number of iterations reaches the upper limit, the parameters $\boldsymbol{\Omega}$ of the pre-trained model is obtained.

\subsection{Adaption Stage}
\label{adaption}
For the $e^{th}$ target environment, the parameters $\boldsymbol{\Omega}$ of the pre-trained model are used to initialize the network model parameter $\boldsymbol{\Omega}_e$ in the target environment. Then the parameter $\boldsymbol{\Omega}_e$ is optimized using the adaption dataset $\mathbb{D}_{Ad}(e)$ in the target environment to minimize $\mathcal{L}_{\mathbb{D}_{Ad}}(\boldsymbol{\boldsymbol{\Omega}})$. When the performance of the model tends to be constant or the number of iterations reaches the upper limit, the parameters $\boldsymbol{\Omega}_e$ of the model in a new environment is obtained.

%To evaluate the performance of proposed algorithm, we calculate the NMSE, KER and KGR in the $e^{th}$ scenario using the testing dataset $\mathbb{D}_{Te}(e)$. 

After repeating the adaption stage in $E_T$ target environments, we can obtain the parameter $\{\boldsymbol{\Omega}_e\}_{e=1}^{E_T}$ in the target environments.
After this, the network parameter $\boldsymbol{\Omega}_e$ is fixed, and the network can be directly used in the feature mapping step in the target environment. Two users, Alice and Bob, follow the steps in Section~\ref{Preliminary} for key generation, where Alice uses the deep learning model with parameter $\boldsymbol{\Omega}_e$  for feature mapping.

We also calculate the average values of Normalized Mean Square Error (NMSE), Key Error Rate (KER) and Key Generation Ratio (KGR) using the testing dataset $\{\mathbb{D}_{Te}(e)\}_{e=1}^{E_T}$ in target environments to evaluate the performance of the proposed algorithm.

%\begin{remark}
%The DTL algorithm optimizes the entire network in the adaption stage. Another method is to fix the parameters of the first few layers of the network, and only optimize the latter layers of the network structure. While the latter approach reduces the time consumption of the adaptation stage, it will also reduce the performance of the network after fine-tuning~\cite{zeng2021downlink}. In addition, compared to the 41 minutes of optimizing only 1-layer network in the \cite{zeng2021downlink}, the 37 seconds used in the adaption stage in our algorithm is very small, and this cost is acceptable. For key generation, obtaining a model with better performance to generate an initial key with higher reciprocity can reduce the consumption of subsequent information reconciliation, which is cost-effective from a long-term perspective.
%\end{remark}

\section{Meta-Learning-Based Feature Mapping}
\label{meta}
To better leverage knowledge from the source environments, this section proposes a meta-learning-based feature mapping. Most existing meta-learning algorithms are problem-specific. In order to eliminate the limitation of the model architecture on the application of meta-learning, a model-agnostic meta-learning (MAML) algorithm was proposed in \cite{finn2017model}. The goal of the algorithm is to achieve adaptation by alternately learning the parameter initialization of the model between the intra-task process and the cross-task process \cite{thrun1998learning}. %Moreover, unlike the DTL technique, the MAML algorithm emphasizes learning the optimal model initialization parameters under multiple tasks to achieve optimal performance under new tasks .
Different from the DTL algorithm, the meta-learning algorithm requires training the model from multiple source tasks and aims to learn the best model initialization parameters through intra-task and cross-task updates. More importantly, unlike the DTL algorithm that emphasizes performance on current tasks, the meta-learning algorithm focuses more on performance of new tasks.

\subsection{Definition of Dataset}
%Since meta-learning requires learning model initialization from multiple tasks, datasets need to be collected from multiple source environments. 
%Assume that the dataset $\{\mathbb{D}_{OS}(e)\}_{e=1}^{E_S}$ is collected from $E_S$ source environments, where the dataset $\mathbb{D}_{OS}(e)=\{(\mathbf{H}_A^{(n)}(e),\mathbf{H}_B^{(n)}(e)) \}_{n=1}^{N_{S}}$ includes $N_{S}$ samples in the $e^{th}$ environment, and the dataset is obtained after feature extraction $\mathbb{D}_{S}(e)= \{(\mathbf{x}_A^{(n)}(e),\mathbf{x}_B^{(n)}(e))\}_{n=1}^{N_S}$. Furthermore, it is necessary to collect dataset in multiple target environments to evaluate the performance of the algorithm. Collect datasets $\{\mathbb{D}_{OT}(e)\}_{e=1}^{E_T}$ from $E_T$ target environments, where the data in the $e^{th}$ environment $ \mathbb{D}_{OT}(e)=\{(\mathbf{H}_A^{(n)}(e),\mathbf{H}_B^{(n)}(e))\} _{n=1}^{N_{T}}$ includes $N_{T}$ data samples, and the dataset is obtained after feature extraction $\mathbb{D}_{T}(e)=\{( \mathbf{x}_A^{(n)}(e),\mathbf{x}_B^{(n)}(e))\}_{n=1}^{N_T}$.

In meta-learning, the training dataset is the datasets from the source environments $\{\mathbb{D}_{S}(e)\}_{e=1}^{ E_S}$, and the training dataset in each task is the dataset in each source environment. The training dataset $\mathbb{D}_{S}(e)$ in $e^{th}$ task needs to be divided into support dataset $\mathbb{D}_{Su}(e)$ and query dataset $\mathbb{D}_{Qu}(e)$, and must satisfy $\mathbb{D}_ {Su}(e) \cap \mathbb{D}_{Qu}(e) = \emptyset$.
The dataset $\mathbb{D}_{T}(e)$ in the target environment is to be divided into adaptation dataset $\mathbb{D}_{Ad}(e)=\{(\mathbf{x}_A^ {(n)}(e),\mathbf{x}_B^{(n)}(e))\}_{n=1}^{N_{Ad}}$ and testing dataset $\mathbb{D} _{Te}(e)=\{(\mathbf{x}_A^{(n)}(e),\mathbf{x}_B^{(n)}(e))\}_{n=1 }^{N_{Te}}$, where $N_{Ad}+N_{Te}=N_T$.

% \begin{algorithm}[!t]
% \algsetup{linenosize=\small} \small
%     \caption{\label{meta-learning}The meta-learning algorithm for key generation in FDD-OFDM systems \jz{remove the algorithm; combine the content into the text.}} 
%     \begin{algorithmic}[1] 
%         \REQUIRE ~~\\  
%         The training support dataset: $\{\mathbb{D}_{Su}(e)\}_{e=1}^{E_S}$, 
%         the training query dataset:$\{\mathbb{D}_{Qu}(e)\}_{e=1}^{E_S}$, 
%         the adaption dataset: $\{\mathbb{D}_{Ad}(e)\}_{e=1}^{E_T}$,
%       the testing dataset: $\{\mathbb{D}_{Te}(e)\}_{e=1}^{E_T}$,
%         inner-task learning rate: $\alpha $, across-task learning rate: $\gamma $, batch size for meta-training: $E_{batch}$, batch size for meta-adaption: $N_{batch}$
%         the number of gradient update for inner-task training: $G_{Tr}$, the number of the gradient update in fine-tuning stage: $G_{Ad}$.
%         \ENSURE ~~\\ 
%         The trained parameters of pre-trained model: $\Omega$,        
%         the trained parameters in each target environment: $\Omega_e$,
%         Initial keys: $K_A$ and $K_B$.
% %        the predicted downlink features: $\hat{\mathbf{x}}_B$,
% %        the average NMSE of target environments: $\mathrm{NMSE}$
%     \STATE \textbf{\textit{Meta-training stage in the source environments}}
%     \STATE Initialize the network parameters $\Omega $;
%     \FOR{t=1,...}
%     \STATE Randomly select $E_{batch}$ environments form $E_S$ source environments;
%     \STATE Generate support dataset $\{\mathbb{D}_{Su}(e)\}_{e=1}^{E_{batch}}$ and query dataset $\{\mathbb{D}_{Qu}(e)\}_{e=1}^{E_{batch}}$;
%     \FOR{$e=1,...,E_{batch}$}
%     \STATE Initialize the network parameters $\Omega_{S,e} \longleftarrow \Omega$;
%     \FOR{$i=1,...,G_{Tr}$}
%     \STATE Update $\Omega_{S,e}$ using the Eq. (\ref{update}) or ADAM algorithm (learning rate $\alpha$);
%     \ENDFOR
%     \ENDFOR
%     \STATE Update $\Omega$ using ADAM algorithm ( leraning rate $\gamma$) to minimize $ \mathcal{L}_{total}(\Omega)$;
%     \ENDFOR
    
% %    \STATE Initialize $\mathrm{NMSE}_{total}\longleftarrow 0$;
%     \FOR{ $e=1,...,E_T$ }
%     \STATE \textbf{\textit{Adaption stage in the target environment}}
%     \STATE Initialize the network parameters $\Omega_e \longleftarrow \Omega$;
%     \FOR{$j =1 ,..., G_{Ad}$}
%     \STATE Randomly select $N_{batch}$ samples from $\mathbb{D}_{Ad}(e)$ to construct $\mathbb{D}_{AdB}$;  
%     \STATE Update $\Omega_e$ using the ADAM algorithm ( learning rate $\gamma $) to minimize $\mathcal{L}_{\mathbb{D}_{AdB}}(\boldsymbol{\Omega_e})$;
%     \ENDFOR
%     \STATE \textbf{\textit{Key generation stage in the target environment}}
%     \STATE Alice and Bob set pilots to each other simultaneously.
%     \STATE Alice and Bob perform channel estimation and feature extraction.
%     \STATE Alice predicts the downlink features $\hat{\mathbf{x}}_B$ using Eq. (\ref{predict});
%     \STATE Alice and bob quantize the features to obtain the initial keys $K_A$ and $K_B$;
% %    \STATE Predict the downlink features $\hat{\mathbf{x}}_B$ using Eq. (\ref{predict}); 
% %    \STATE Calculate $\mathrm{NMSE}(e)$ using Eq. (\ref{NMSE});
% %    \STATE $\mathrm{NMSE}_{total} \longleftarrow  \mathrm{NMSE}_{total}+\mathrm{NMSE}(e)$;
%     \ENDFOR 
% %    \STATE $\mathrm{NMSE} \longleftarrow  \mathrm{NMSE}_{total}/E_T$;
%     \end{algorithmic}
  
% \end{algorithm}



\subsection{Training (Meta-training) Stage}
During the meta-training phase, the goal of the meta-learning algorithm is to learn a network initialization that can effectively adapt to new tasks. The underlying network architecture used here is the same as used in DTL. First, the parameters $\boldsymbol{\Omega}$ are randomly initialized, and then updated through two iterative processes, namely intra-task update and cross-task update. The network parameters of each source task are optimized within the intra-task update, and the global neural network is optimized within the cross-task update.

\subsubsection{Intra-task Update}
A batch of $E_{batch}$ tasks is randomly selected from $E_S$ environments in a batch.
The goal of each task is to optimize its own neural network parameters on its support dataset $\mathbb{D}_{Su}(e)$. The objective of each task is achieved by minimizing the loss function based on supervised learning. The objective function of each task can be expressed as:
\begin{equation}
\begin{split}
\boldsymbol{\Omega}_{S,e}=\arg \min _{\boldsymbol{\Omega}_{S,e}} \mathcal{L}_{\mathbb{D}_{Su}(e)}\left(\boldsymbol{\Omega}_{S,e}\right), \quad e=1, \ldots, E_{B},
\end{split}
\label{}
\end{equation}
where $\boldsymbol{\Omega}_{S,e}$ is the network parameter of the $e^{th}$ task in the source task set. 
In each task, $\boldsymbol{\Omega}_{S,e}$ is initialized to $\boldsymbol{\Omega}$, and is then updated with $G_{Tr}$ times of gradient descent, i.e.,
\begin{equation}
\begin{split}
\boldsymbol{\Omega}_{S, e} \leftarrow \boldsymbol{\Omega}_{S, e}-\alpha \nabla_{\boldsymbol{\Omega}_{S, e}} \operatorname{Loss}_{\mathbb{D}_{\mathrm{Su}}(e)}\left(\boldsymbol{\Omega}_{S, e}\right),
\end{split}
\label{update}
\end{equation}
where $\alpha$ is the learning rate between tasks. The $\boldsymbol{\Omega}_{S, e}$ also can be updated by ADAM optimizer \cite{kingma2014adam}.


The intra-task update only performs once. In the original MAML algorithm \cite{finn2017model}, intra-task updates were made also only once, but some literature proposed to increase the times of intra-task update to improve the performance~\cite{yuan2020transfer}. This paper analyzes the impact of task update times on performance in Section \ref{The Impact of Hyper-parameters in Meta-learning}. The results show that the increase of $G_{tr}$ has no obvious effect on performance, but will increase the training cost, thus we set $G_{tr}$ to 1.

%In the original MAML algorithm, intra-task updates were made only once. And then some literatures proposed to increase the times of intra-task update to improve the performance. This paper analyzes the impact of task update times on performance in Section \ref{The Impact of Hyper-parameters in Meta-learning} and set $G_{tr}$ as 1.

\subsubsection{Cross-task Update}
The global network parameters $\boldsymbol{\Omega}$ are optimized based on the sum of the loss functions of all tasks in one batch. After intra-task update, the loss function for all tasks in the batch can be estimated based on the related tasks and their query datasets $\{\mathbb{D}_{Qu}(e)\}_{e=1}^{E_{batch}}$. These loss functions can be added together to form the loss function used to optimize the global network parameters, i.e.
\begin{equation}
\begin{split}
 \mathcal{L}_{total}(\boldsymbol{\Omega})=\sum_{e=1}^{E_{batch}} \mathcal{L}_{\mathbb{D}_{Qu}(e)}\left(\boldsymbol{\Omega}_{S, e}\right).
\end{split}
\label{}
\end{equation}
This loss function can also be minimized by optimizing $\boldsymbol{\Omega}$ by gradient descent or ADAM algorithm (learning rate $\gamma$).

After the cross-task update is over, assign the updated $\boldsymbol{\Omega}$ to $\boldsymbol{\Omega}_{S,e}$, and then repeat the intra-task update and cross-task update until $ \mathcal{L}_{total}(\boldsymbol{\Omega})$ does not converge.  At this time, the parameter initialization of network learning is obtained, so that only a small number of samples can be adapted to the new environment.

It is clear that the training methods of the DTL algorithm and the meta-learning algorithm are almost completely different. In the DTL algorithm, the DTL algorithm minimizes the loss of the current model (only one) on all tasks, so the DTL algorithm hopes to find an initialization parameter that performs better on all current tasks. 
The Meta-learning algorithm first uses the support dataset to minimize the loss function in each task, then uses the query dataset to minimize the loss sum of all tasks, and finally updates all model parameters with the model parameters obtained by minimizing the sum of loss functions of all tasks, which means that the performance of the model obtained after training to convergence under each task using the final initialization parameters obtained by meta-learning should still be as good as possible. Therefore, compared to the DTL algorithm, meta-learning algorithm makes better use of knowledge in multiple environments, and the resulting model initialization parameters have better generalization, which is also proved in the results in Section \ref{simulation}.

\subsection{Adaption Stage}
This step is the same as the Section \ref{adaption}.

We also use the fixed parameters $\{\boldsymbol{\Omega}_e\}_{e=1}^{E_T}$ for feature mapping and key generation to calculate evaluation metrics that can evaluate the performance of the proposed algorithm using the testing datasets $\{\mathbb{D}_{Te}(e)\}_{e=1}^{E_T}$ in the target environments.

%After repeating the adaption and key generation stages in $E_T$ target environments, we also calculate the average values of NMSE, KER and KGR in target environments using the testing dataset  to evaluate the performance of the proposed meta-learning algorithm.

%The proposed meta-learning algorithm is inspired by the MAML algorithm in \cite{finn2017model} and the applications of this algorithm in other fields. It is worth mentioning that the meta-learning algorithm proposed in this paper is different from other algorithms: 

%ii) the intra-task update and cross-task update are performed by ADAM algorithm. In the original MAML algorithm, while the proposed algorithm adopts the ADAM algorithm instead of SGD




\section{Simulation Evaluation}
\label{simulation}
In this section, we will first present the data generation and simulation setup. Then, we give the benchmarks, metrics and compare the performance of all algorithms.

\subsection{Simulation Setup and Dataset Generation}
In the simulation, we consider an indoor corridor scenario, which is constructed based on the accurate 3D ray tracing simulator Wireless InSite~\cite{Remcom}.
The overview of the ray-tracing indoor scenario is illustrated in Fig. \ref{scenario_indoor}.  The antenna of the base station (Alice) is located in a small green box on the ceiling of the indoor corridor. The three maroon rectangles represent the possible positions of the user (Bob), and each room represents an environment. As Alice is in the corridor and Bob is located in the room, all channels are Non-line-of-sight (NLOS). The uplink and downlink frequencies are 2.4 GHz and 2.5 GHz, respectively. The number of OFDM subcarriers is 64 and the bandwidth is 20 MHz.
\begin{figure}[!t]
	\centering
	\includegraphics[width=\linewidth]{scenario_indoor-eps-converted-to.pdf}
	\caption{A overview of the ray-tracing indoor scenario. }
	\label{scenario_indoor}
\end{figure}

%\begin{figure}[!t]
%	\centering
%	\includegraphics[width=\linewidth]{scenario_urban-eps-converted-to.pdf}
%	\caption{A overview of the ray-tracing outdoor scenario. }
%	\label{scenario_urban}
%\end{figure}
%A overview of the ray-tracing outdoor scenario is illustrated in Fig. \ref{scenario_urban}. The antenna of the base station is located in a small green box with an outdoor height of 20 meters. The three maroon rectangles represent the possible positions of the user, and each rectangle represents a scene. In addition, the base station is Alice, multiple users are the possible locations of Bob, and the uplink channel and the downlink channel work on channels with frequencies of 2.4 GHz and 2.5 GHz, respectively. The number of OFDM subcarriers is 128 and the bandwidth is 20 MHz. We choose the first way of realization in indoor scenario and the second way of realization in outdoor scenario.
%\footnote{The simulation results show that the change of the CFR in the indoor scenario is relatively small, and the KGR can be improved by using the first way of realization. In the outdoor scenario, the CFR changes rapidly, and the feature generated by the second way of realization is difficult to learn by model.}


Assuming that E1 is the source task scenario, a total of 40,000 locations are collected, while E2 and E3 are target task environments, and 5,000 locations are collected in each environment. 
Due to different environments in different rooms, the environment information learned by the model is different, so the model trained in E1 is not suitable for new environments (E2 and E3). In response to this problem, this paper proposes two algorithms to use the collected data in E1 to obtain some prior knowledge, so that pre-trained model can quickly adapt to new environments (E2 and E3). 




A workstation with an Nvidia GeForce GTX 1660Ti GPU and an Intel Core I7-9700 CPU was used. This paper used Tensorflow 2.1 as the underlying framework of deep learning to build the network. The network parameters and some parameters in the training stage are shown in Table \ref{tab:4-setup}.
\begin{table}[!t]
\caption{Default Parameters of Proposed Algorithms} 
\label{tab:4-setup}
	\centering
	\begin{tabular}{|p{1.5cm}<{\centering}|p{3.6cm}<{\centering}| p{2.4cm}<{\centering}|}
		\hline
		& \bfseries Parameter & \bfseries Value  \\ \hline
	    \multirow{5}{*}{\shortstack{For All \\Algorithms}} &Number of neurons in hidden layers& (512,1024,1024,512)\\\cline{2-3}
	    &Batch size& 128\\\cline{2-3}
	    &Optimization & ADAM \cite{kingma2014adam} \\ \cline{2-3}
	    &Exponential decay rates for ADAM: ($\rho_1,\rho_2$) &(0.9,0.999)\\ \hline
% 		\bfseries Parameter & \bfseries Value \\ \hline
% 		Number of neurons in hidden layers& (512,1024,1024,512)\\\hline
% 		Batch size& 128\\\hline
% 		Optimization & ADAM \cite{kingma2014adam} \\ \hline
% 		Exponential decay rates for ADAM: ($\rho_1,\rho_2$) &(0.9,0.999)\\ \hline
 		\multirow{10}{*}{\shortstack{For\\ Meta-learning}} &Inner-task and across-task learning rate: $(\alpha, \beta)$& (1e-3,1e-3)\\\cline{2-3}
 		&The number of gradient update for inner-task training & 1\\\cline{2-3}
		&the number of the gradient update in fine-tuning and meta-adaption stages& 300\\\cline{2-3}
		&The number of source task in meta-learning& 400\\\cline{2-3}
 		&The number of samples in each source task& 100\\\hline
	\end{tabular}
\end{table}

\subsection{Benchmarks}
For comparison, we introduce two benchmarks, namely the direct algorithm and the joint dataset algorithm. All algorithms are explained below.
\begin{itemize}
\item[(1)] \textit{Direct algorithm} directly uses the model trained in E1 and tests the performance in E2 and E3.
\item[(2)]  \textit{Joint dataset algorithm} combines all the data in E1 and part of the data in E2 or E3 to form a joint training dataset and then uses the model trained by the joint training dataset to test the performance in E2 and E3, respectively \cite{yuan2020transfer}.
\item[(3)]  \textit{DTL algorithm} uses the proposed DTL-based feature mapping in Section~\ref{DTL} for key generation to test the performances.
\item[(4)]  \textit{Meta-learning algorithm} uses the proposed meta-learning-based feature mapping in Section~\ref{meta} for key generation to test the performances.
\end{itemize}

For fair comparison, some default training parameters adopted in all algorithms are consistent. Furthermore, the datasets used for training and adaptation in transfer learning and meta-learning algorithms are of the same size. The 40,000 total training dataset used in the DTL algorithm is divided into 400 datasets with a sample size of 100 in the meta-learning algorithm to represent the data under multiple tasks.
The training dataset used by the joint dataset algorithm is the combination of the training dataset and the adaptation dataset in the transfer learning and meta-learning algorithms.

\subsection{Evaluation Metrics}
We use the following metrics for performance evaluation.
\begin{itemize}
	\item \textit{NMSE} is used to evaluate the predictive accuracy of the network, which  is defined as
\begin{equation}
\begin{split}
\mathrm{NMSE}=E\left[\frac{\parallel{\mathbf{x}}_{A}^{B}-\mathbf{x}_B\parallel_2^2}{\parallel \mathbf{x}_{B}\parallel_2^2}\right],
\end{split}
\label{NMSE}
\end{equation}
where $E\left[\cdot\right]$ represents the expectation operation. 
	\item \textit{KER} is defined as the number of error bits divided by the number of total key bits.
	\item \textit{KGR} is defined as the number of initial key bits divided by the number of subcarriers. 
	\item \textit{Randomness} reveals the distribution of bit streams. The National Institute of Standards and Technology (NIST) statistical test \cite{rukhin2001statistical} is used for the randomness test for the generated keys.
\end{itemize}


\subsection{The Impact of Hyper-parameters in Meta-learning}
\label{The Impact of Hyper-parameters in Meta-learning}
The selection of the number of iterations $G_{Tr}$ in the task and the batch size $E_{batch}$ in the training phase are very important to the meta-learning algorithm. These two parameters are analyzed below.




For some tasks, the increase of $G_{Tr}$ can greatly improve the performance. For example, the work in~\cite{yuan2020transfer} sets $G_{Tr}$ to 3, which improves the downlink channel prediction accuracy in massive MIMO systems. At the same time, as $G_{Tr}$ increases, more memory and time resources are required for meta-learning training. Therefore, the value of $G_{Tr}$ should be determined comprehensively by weighing the consumed resources and performance. In this paper, $G_{Tr}$ is set as \{1, 2, 3, 4, 6, 8\} for learning, and tests are carried out in the indoor corridor environment respectively. The results are shown in Fig. \ref{Gtr_NMSE}. The results show that with the increase of $G_{Tr}$, the performance of the meta-learning algorithm does not improve, but basically stabilizes around a certain range. Therefore, in order to guarantee the minimum resource consumption, the $G_{Tr}$  is set to 1.
\begin{figure}[!t] 
    \centering 
    \includegraphics[width=\linewidth]{Gtr_NMSE_1-eps-converted-to.pdf} 
    \caption{The NMSE performance comparison for different numbers of iterations $G_{Tr}$.}
    \label{Gtr_NMSE} 
\end{figure}



Reasonable selection of the batch size $E_{batch}$ in the training phase is also very important for the training effect. Since the choice of batch size $E_{batch}$ has nothing to do with the resource consumption of training, it is only necessary to focus on the training performance under different batch sizes. Fig.~\ref{Kb_NMSE} compares the NMSE performance under different batch sizes $E_{batch}$. The results show that  the tested NMSE performance is getting better with the increase of $E_{batch}$ and reaches optimal when $E_{batch}=32$. Therefore, in order to achieve optimal performance, the $E_{batch}$ is set to 32.
\begin{figure}[!t] 
    \centering 
    \includegraphics[width=\linewidth]{Kb_NMSE-eps-converted-to.pdf} 
    \caption{The NMSE performance comparison for different numbers of the batch size $E_{batch}$.}
    \label{Kb_NMSE} 
\end{figure}

\subsection{Performance of Reciprocal Features}

%\begin{figure}
%	\centering
%	\subfigure[Indoor corridor scenario.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{Gad_nmse-eps-converted-to.pdf}
%		\end{minipage}
%		\label{Gad_nmse}
%	}
%	\subfigure[Outdoor scenario.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{Gad_nmse_outdoor_new-eps-converted-to.pdf}
%		\end{minipage}
%		\label{Gad_nmse_outdoor}
%	}
%	\caption{The NMSE performance during adaption stage.}
%	\label{Gad_nmse_inout}
%\end{figure}



Fig. \ref{Gad_nmse} compares the NMSE performance of the four algorithms during adaption stage in E2. Since the direct algorithm has no adaptation phase, it is set as a fixed value for its test results. The results show that the algorithms based on transfer learning and meta-learning are better than the direct and joint dataset algorithms. The NMSE of the joint dataset algorithm increases with the number of iterations $G_{Ad}$. This is due to the fact that in the joint dataset, the number of data samples in E2 is much larger than that in E1, so the over-fitting occurs during the training process, and its test performance is still better than that of the direct algorithm.
This result shows that it is necessary to add datasets under new scenarios to the test dataset to improve the performance of the model in new scenarios. In addition, the meta-learning algorithm is significantly better than the DTL algorithm.
\begin{figure}[!t] 
	\centering 
	\includegraphics[width=\linewidth]{Gad_nmse-eps-converted-to.pdf} 
	\caption{The NMSE performance during adaption stage.}
	\label{Gad_nmse}
\end{figure}
% In the outdoor scenario, the DTL and meta-learning algorithms can still greatly improve the performance of the model in new environments. Different from the indoor corridor scenario, the joint dataset algorithm in the outdoor scenario is worse than the direct algorithm, which indicates that the difference between several environments in the outdoor scenario is greater, and adding a small amount of destination environment data to the source environment data will lead to serious overfitting.

%\begin{figure}
%	\centering
%	\subfigure[Indoor corridor scenario.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{Nad_nmse_1-eps-converted-to.pdf}
%		\end{minipage}
%		\label{Nad_nmse}
%	}
%	\subfigure[Outdoor scenario.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{Nad_nmse_outdoor_1-eps-converted-to.pdf}
%		\end{minipage}
%		\label{Nad_nmse_outdoor}
%	}
%	\caption{The NMSE performance of the four algorithm versus the size of adaption samples $N_{Ad}$ .}
%	\label{Nad_nmse_inout}
%\end{figure}

\begin{figure}[!t] 
	\centering 
	\includegraphics[width=\linewidth]{Nad_nmse_1-eps-converted-to.pdf} 
	\caption{The NMSE performance of the four algorithm versus the size of adaption samples $N_{Ad}$ .}
	\label{Nad_nmse}
\end{figure}

Fig. \ref{Nad_nmse} compares the influence of the number of adaptation dataset samples $N_{Ad}$ on the performance of the four algorithms. Since the direct algorithm does not use the adaptation dataset in the new environments, it is assumed that the performance of the algorithm under different sample numbers is consistent. When the number of samples $N_{Ad}=1000$, since the data in the new environment in the joint dataset only accounts for $1000/41000$ of the total data, the resulting over fitting reaction makes the performance of the joint dataset algorithm is even worse than that of the direct algorithm. 
%In the outdoor scenario, even if the number of samples under the target sample $N_{Ad}$ increases, there will still be an overfitting scene. 
Overall, the meta-learning and DTL algorithms can achieve better performance than the two benchmarks with a smaller number of samples, and the performance of the meta-learning algorithm is better than that of the DTL algorithm.

%A comprehensive analysis of the two environments shows that the transfer learning-based and meta-learning-based reciprocal feature construction algorithms can significantly improve the reciprocity of features in new scenarios. In general, meta-learning-based algorithms have better fit than transfer learning-based algorithms.

%\begin{figure}
%	\centering
%	\subfigure[Indoor corridor scenario.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{SNR_nmse_indoor_1-eps-converted-to.pdf}
%		\end{minipage}
%		\label{SNR_nmse_indoor}
%	}
%	\subfigure[Outdoor scenario.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{SNR_nmse_outdoor_1-eps-converted-to.pdf}
%		\end{minipage}
%		\label{SNR_nmse_outdoor}
%	}
%	\caption{The NMSE performance versus different SNRs .}
%	\label{}
%\end{figure}





In this paper, testing datasets at SNRs of \{0, 10, 20, 30, 40\} dB are generated to analyze the generalization performance of the four algorithms. Fig. \ref{SNR_nmse_indoor} compares the performance of the four algorithms tested under different SNRs. The results show that the DTL and meta-learning algorithms can achieve better performance than the direct and joint dataset algorithms. However, at SNRs less than 10 dB, the DTL algorithm achieves worse performance than the direct and joint dataset algorithms. By this time, the meta-learning algorithm can still effectively improve the reciprocity of features obtained by Alice and Bob.
\begin{figure}[!t] 
	\centering 
	\includegraphics[width=\linewidth]{SNR_nmse_indoor_1-eps-converted-to.pdf} 
	\caption{The NMSE performance versus different SNRs.}
	\label{SNR_nmse_indoor}
\end{figure}
%Fig. \ref{SNR_nmse_outdoor} compares the performance of the four algorithms tested in outdoor scenario with different SNRs. The DTL and meta-learning algorithms achieve better performance than other two benchmarks, and the meta-learning algorithm outperforms the DTL algorithm. In addition, the performance of the direct and joint dataset algorithms decreases instead as the SNR increases. This is due to the fact that there is little correlation between the environments in outdoor scenarios and the pre-trained model cannot be used in the new environment, instead the noise similarity between the downlink and uplink channels is greater at low SNRs, so the NMSE is even a little smaller at low SNRs.



%\begin{figure}[!t] 
%	\centering 
%	\includegraphics[width=\linewidth]{AB_Before} 
%	\caption{Comparison of the features obtained by Alice and Bob using the four algorithms.}
%	\label{effect} 
%\end{figure}
%
%\begin{figure}[!t] 
%	\centering 
%	\includegraphics[width=\linewidth]{AB_After-eps-converted-to.pdf} 
%	\caption{Comparison of the features obtained by Alice and Bob using the four algorithms.}
%	\label{effect1} 
%\end{figure}

%\begin{figure}[!t] 
%	\centering 
%	\includegraphics[width=\linewidth]{effect-eps-converted-to.pdf} 
%	\caption{Comparison of the features obtained by Alice and Bob using the four algorithms.}
%	\label{effect} 
%\end{figure}
%the performance of the direct and joint dataset algorithms decreases as the SNR increases, suggesting that the two algorithms are largely useless in the outdoor scenario and even degrade the reciprocity of channel features to some extent. 

Fig. \ref{effect} compares the features obtained by Alice and Bob before and after using the four algorithms at the SNR of 20 dB. As shown in Fig. \ref{before}, the original channel features obtained by Alice and Bob are influenced by the frequency and are almost completely different. After using the four algorithms proposed in this paper, the channel features obtained between Alice and Bob are shown in Fig. \ref{after}. The results show that the reciprocity of the features obtained by Alice and Bob is significantly enhanced when using the meta-learning and DTL algorithms, while the reciprocity of the other two benchmark algorithms is still poor. Overall, the meta-learning and DTL algorithms can achieve better fitting performance and generalization under multiple SNRs, with the meta-learning algorithm achieving better performance than the DTL algorithm.
\begin{figure}
	\centering
	\subfigure[The obtained features between Alice and Bob without using the proposed two algorithms.]{
			\begin{minipage}[b]{\linewidth}
					\includegraphics[width=\linewidth]{AB_Before-eps-converted-to.pdf}
				\end{minipage}
			\label{before}
		}
	\subfigure[The obtained features between Alice and Bob using the four algorithms.]{
			\begin{minipage}[b]{\linewidth}
					\includegraphics[width=\linewidth]{AB_After-eps-converted-to.pdf}
				\end{minipage}
			\label{after}
		}
	\caption{Comparison of the features obtained by Alice and Bob before and after using the four algorithms .}
	\label{effect}
\end{figure}


\subsection{Performance of Initial Keys}

Based on the above analysis of the performance of the feature reciprocity generated by the algorithms, this section analyzes the performance of the initial keys, which includes KER, KGR, and key randomness. The quantization factor $\varepsilon = 0.1$, which means that 20\% of the features near the isolation zone are removed in the quantization.



Fig. \ref{KER_indoor} and Fig. \ref{KGR_indoor} compare the performance of the keys generated by the four algorithms tested under different SNRs. As shown in Fig. \ref{KER_indoor}, the KERs of the keys generated by the direct and joint dataset algorithms are as high as 50\%. This indicates that the model trained in the source environments is invalid in the new environment. This is due to the fact that in this scenario, each room represents an environment and there is no similar or common channel environment between each environment. The DTL and meta-learning algorithms can significantly reduce the KERs of generating keys in these new environments, where the DTL algorithm generates keys at the SNR of 20 dB with the KER of 30\%, which is 38.8\% lower compared to the direct algorithm. The KER of the meta-learning algorithm is 23.4\% when the SNR is 20 dB, which is 52.9\% lower than that of the direct algorithm. As shown in Fig. \ref{KGR_indoor}, the KGRs of the keys generated by the DTL and meta-learning algorithms are also higher than that of the keys generated by the two benchmarks. It is important to emphasize that although the KER is still high, we can reduce it at the expense of KGR by adjusting the quantization factor $\varepsilon$.
\begin{figure}
	\centering
	\subfigure[The KER performance versus different testing SNRs.]{
		\begin{minipage}[b]{\linewidth}
			\includegraphics[width=\linewidth]{KER_indoor_1-eps-converted-to.pdf}
		\end{minipage}
		\label{KER_indoor}
	}
	\subfigure[The KGR performance versus different testing SNRs.]{
		\begin{minipage}[b]{\linewidth}
			\includegraphics[width=\linewidth]{KGR_indoor_1-eps-converted-to.pdf}
		\end{minipage}
		\label{KGR_indoor}
	}
	\caption{KER and KGR versus SNR.}
	\label{}
\end{figure}

%\begin{figure}
%	\centering
%	\subfigure[The KER performance versus different testing SNRs.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{KER_outdoor_1-eps-converted-to.pdf}
%		\end{minipage}
%		\label{KER_outdoor}
%	}
%	\subfigure[The KGR performance versus different testing SNRs.]{
%		\begin{minipage}[b]{\linewidth}
%			\includegraphics[width=\linewidth]{KGR_outdoor_1-eps-converted-to.pdf}
%		\end{minipage}
%		\label{KGR_outdoor}
%	}
%	\caption{The KER and KGR performance in outdoor scenario.}
%	\label{}
%\end{figure}
%
%
%Fig. \ref{KER_outdoor} and Fig. \ref{KGR_outdoor} compare the performance of the keys generated by the four algorithms tested under different SNRs in the outdoor scenario. As shown in Fig. \ref{KER_outdoor}, the DTL and mete-learning algorithms can significantly reduce the KER of the generated keys in this environment, where the DTL algorithm generates keys with a KER of 13.37\% at a SNR of 20 dB dB, which is 73.14\% lower compared to the direct algorithm. The KER of the meta-learning algorithm to generate keys at SNR of 20 dB is 11.305\%, which is 77.29\% lower compared to the direct algorithm. As shown in Fig. \ref{KGR_indoor}, when the SNR is higher than 20 dB, the keys generated by the DTL and mete-learning algorithms also have a higher KGR than those generated by the direct and joint dataset algorithms.



The NIST test is used to test the randomness of the generated keys. We generate a total of 718 sets of 128-bit keys at the SNR of 20 dB. A serial test is composed of two types of serial tests. When both tests pass, the serial test is considered to be passed. Table \ref{table_randomness_1} gives the pass rate of the generated keys in several tests that can be tested, i.e., the ratio of the number of key sets that pass the test to the total number of key sets. The results show that the pass rates in several randomness tests are over 90\%.
\begin{table}[!t] 
\caption{NIST Statistical Test Pass Ratio.} 
	\centering
	\begin{tabular}{|p{4cm}<{\centering}| p{2cm}<{\centering} |}
		\hline
		 \bfseries Test&\bfseries Pass Ratio \\ \hline
		 Approximate Entropy& 0.9545 \\\hline
		 Block Frequency & 0.9931 \\\hline
		 Cumulative Sums  &1 \\\hline
		 Discrete Fourier Transform & 1 \\\hline
		 Frequency & 0.9311  \\\hline
		 Ranking & 0.9105 \\\hline
		 Runs & 0.9835 \\\hline
		 Serial & 0.9504 \\
		 \hline
	\end{tabular}
\label{table_randomness_1}
\end{table}


\subsection{Complexity Analysis}


As shown in Table \ref{table_complexity_1}, We analyze the complexity of the four algorithms in terms of the time cost, the CPU average load, and the GPU memory utilization.
\begin{table*}[!t] 
\caption{Complexity analysis of four algorithms}
	\centering
	\begin{tabular}{|p{2.5cm}<{\centering}| p{1cm}<{\centering} | p{2cm}<{\centering} |p{2cm}<{\centering}|p{1cm}<{\centering} |p{2cm}<{\centering}|p{2cm}<{\centering} |p{2cm}<{\centering} |}
		\hline
		& \multicolumn{3}{c|}{\textbf{Training Stage}}& \multicolumn{3}{c|}{\textbf{Adaptation Stage}}& \textbf{Key Generation Stage}\\ \hline
		 \bfseries Algorithm &\bfseries Time Cost & \bfseries CPU Average Load & \bfseries GPU Memory Utilization & \bfseries Time Cost & \bfseries CPU Average Load&\bfseries  GPU Memory Utilization &\bfseries Time Cost \\ 		  
		 \hline
		 The direct algorithm & 183s & 15.82\%& 5.1 / 9.9 GB &  - & - & - & 0.95e-4s\\ 
		 \hline
		 The joint training algorithm & 253s & 18.22\%& 5.1 / 9.9 GB &  - & - & - & 0.95e-4s\\ 
		 \hline
		 The DTL algorithm & 183s & 15.82\%& 5.1 / 9.9 GB &  37s & 10.2\% & 5.1 / 9.9 GB & 0.95e-4s\\ 
		 \hline
		 The meta-learning algorithm &\textbf{110s} & 12\%&   1 / 9.9 GB &  \textbf{38s} & 10.2\% & 5.1 / 9.9 GB & 0.95e-4s \\ 
		 \hline
	\end{tabular}
\label{table_complexity_1}
\end{table*}

In the training stage, since the training process of meta-learning includes multiple intra-task and cross-task updates, meta-learning consumes significantly more resources than DTL. However, it was found experimentally that the training process of meta-learning requires only 10 iterations before the loss function stops decreasing, which takes about 110 seconds. The CPU average load and GPU memory utilization consumed are also less in meta-learning than the DTL. Besides, the trained model only requires 25.6 MB of memory to save on the device, so it can be deployed on resource-constrained embedded systems.
In the adaption stage, the DTL and meta-learning algorithms increase the consumption required for the adaptation stage on top of the direct algorithm and the joint training algorithm, however, the improved performance shows that the consumption is worth it. In our experiments, the DTL and meta-learning algorithms only take about 37 seconds to complete the adaptation to the new environment, which is an acceptable cost.
In the key generation stage, the time cost of each feature mapping is around 0.95e-4 seconds, which can be done in almost real-time.

In summary, it takes about 148 seconds to train and adapt the network in total, and only 0.95e-4 seconds to use the network for feature mapping in the key generation stage. Furthermore, the training stage only needs to be performed once for all environments, and the adaptation stage is performed only once for each environment. Compared with the training consumption of networks used in other areas, the proposed algorithms can achieve fast key generation in FDD-OFDM systems.

%\jz{can you analyze the complexity for the test stage? people may say, GPU is not available in many IoT devices. I presume we can training on GPU but delpoy on embedded devices. then test stage is more important?}

\section{Conclusion}
\label{Conclusion}
In this paper, aiming at the problem of inapplicability of deep learning model caused by environment changes, we formulated this problem as a learning-based problem, i.e., using knowledge from source environments to learn the feature mapping in the new environments, and proposed a DTL algorithm and a meta-learning algorithm to achieve fast key generation in multi-environment for FDD-OFDM systems. Simulation results showed that both algorithms can effectively improve the performance of generated keys in new environments. When the SNR=20 dB, the KERs of the keys generated by the DTL and meta-learning algorithms were reduced by 38.8\% and 52.9\%, respectively, compared with the method without adaptation (the direct algorithm) in the new environments. In addition, the complexity analysis showed that the meta-learning algorithm consumed less time and lower CPU and GPU resources for training than the DTL algorithm.
Furthermore, the complexity analysis showed that the meta-learning algorithm consumed less time and less CPU and GPU resources than the DTL algorithm in the training stage, and these costs were acceptable in real-world applications.


\bibliographystyle{IEEEtran} 
\bibliography{IEEEabrv, myref}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{ZXW.jpg}}]{Xinwei Zhang} received the M.Eng degree in computer technology from Southeast University, Nanjing, China, in 2022.

From April 2021 to September 2021, he was a Research Assistant with the Department of Computing, The Hong Kong Polytechnic University. His research interests include physical-layer security, secret key generation, blockchain and AI security.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{LGY.jpg}}]{Guyue Li}
(Member, IEEE) received the B.S. degree in information science and technology and the Ph.D. degree in information security from Southeast University, Nanjing, China, in 2011 and 2017, respectively. 

From June 2014 to August 2014, she was a Visiting Student with the Department of Electrical Engineering, Tampere University of Technology, Finland. She is currently an Associate Professor with the School of Cyber Science and Engineering, Southeast University. Her research interests include physical-layer security, secret key generation, radio frequency fingerprint, and link signature.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{ZJQ.jpg}}]{Junqing Zhang}
(Member, IEEE) received the B.Eng and M.Eng degrees in Electrical Engineering from Tianjin University, China in 2009 and 2012, respectively, and the Ph.D degree in Electronics and Electrical Engineering from Queen's University Belfast, UK in 2016. 
From Feb. 2016 to Jan. 2018, he was a Postdoctoral Research Fellow with Queen's University Belfast. From Feb. 2018 to May 2020, he was a Tenure Track Fellow (Assistant Professor) with University of Liverpool, UK. Since June 2020, he is a Lecturer (Assistant Professor) with University of Liverpool. His research interests include Internet of Things, wireless security, physical layer security, key generation, and radio frequency fingerprint identification.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{HAQ.jpg}}]{Aiqun Hu}
(Senior Member, IEEE) received the B.Sc.(Eng.), M.Eng.Sc., and Ph.D. degrees from Southeast University in 1987, 1990, and 1993, respectively. 

He was invited as a Post-Doctoral Research Fellow with The University of Hong Kong from 1997 to 1998, and a TCT Fellow with Nanyang Technological University in 2006. He has published two books and more than 100 technical articles in wireless communications field. His research interests include data transmission and secure communication technology.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{wxb.jpg}}]{Xianbin Wang}
 (Fellow, IEEE) received the Ph.D. degree in electrical and computer engineering from the National University of Singapore in 2001. He is currently a Professor and the Tier-1 Canada Research Chair with Western University, Canada. Prior to joining Western University, he was with the Communications Research Centre Canada (CRC) as a Research Scientist/Senior Research Scientist from July 2002 to December 2007. From January 2001 to July 2002, he was a System Designer with STMicroelectronics. He has over 450 highly cited journal articles and conference papers, in addition to 30 granted and pending patents and several standard contributions. His current research interests include 5G/6G technologies, the Internet-of-Things, communications security, machine learning, and intelligent communications. He is also a fellow of the Canadian Academy of Engineering and the Engineering Institute of Canada, and an IEEE Distinguished Lecturer. He received many awards and recognitions, including the Canada Research Chair, the CRC President s Excellence Award, the Canadian Federal Government Public Service Award, the Ontario Early Researcher Award, and six IEEE Best Paper Awards. He was involved in many IEEE conferences, including GLOBECOM, ICC, VTC, PIMRC, WCNC, and CWIT, in different roles, such as the symposium chair, a tutorial instructor, the track chair, the session chair, the TPC co-chair, and a keynote speaker. He has been nominated as an IEEE Distinguished Lecturer several times during the last ten years. He is also serving as the Chair for IEEE London Section and the ComSoc Signal Processing and Computing for Communications (SPCC) Technical Committee. He also serves/has served as the editor-in-chief, an associate editor-in-chief, and an editor/associate editor for over ten journals.
\end{IEEEbiography}


\end{document}