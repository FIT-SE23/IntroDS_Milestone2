{
    "2006.04779": {
        "title": "Conservative Q-Learning for Offline Reinforcement Learning",
        "authors": [
            "Aviral Kumar",
            "Aurick Zhou",
            "G. Tucker",
            "S. Levine"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "28db20a81eec74a50204686c3cf796c42a020d2e"
    },
    "2005.01643": {
        "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems",
        "authors": [
            "S. Levine",
            "Aviral Kumar",
            "G. Tucker",
            "Justin Fu"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "5e7bc93622416f14e6948a500278bfbe58cd3890"
    },
    "2106.04493": {
        "title": "A Deep Value-network Based Approach for Multi-Driver Order Dispatching",
        "authors": [
            "Xiaocheng Tang",
            "Zhiwei Qin",
            "Fan Zhang",
            "Zhaodong Wang",
            "Zhe Xu",
            "Yintai Ma",
            "Hongtu Zhu",
            "Jieping Ye"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "99ca3d8c4d6e029597f36c219d19e2654ea5e0d6"
    },
    "1907.06584": {
        "title": "Environment Reconstruction with Hidden Confounders for Reinforcement Learning based Recommendation",
        "authors": [
            "Wenjie Shang",
            "Yang Yu",
            "Qingyang Li",
            "Zhiwei Qin",
            "Yiping Meng",
            "Jieping Ye"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "2d6e52dcd6a56a603c2682a953f48e349c8ffa63"
    },
    "1906.00949": {
        "title": "Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction",
        "authors": [
            "Aviral Kumar",
            "Justin Fu",
            "G. Tucker",
            "S. Levine"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "82b4b03a4659d6e04bd7cbf51d6e08fde1348dbd"
    },
    "1901.11454": {
        "title": "Efficient Ridesharing Order Dispatching with Mean Field Multi-Agent Reinforcement Learning",
        "authors": [
            "Minne Li",
            "Zhiwei Qin",
            "Yan Jiao",
            "Yaodong Yang",
            "Zhichen Gong",
            "Jun Wang",
            "Chenxi Wang",
            "Guobin Wu",
            "Jieping Ye"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "83beabd65dc766c0ee79a548d3057fcea83dc31a"
    },
    "1812.02900": {
        "title": "Off-Policy Deep Reinforcement Learning without Exploration",
        "authors": [
            "Scott Fujimoto",
            "D. Meger",
            "Doina Precup"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "5285cb8faada5de8a92a47622950f6cfd476ac1d"
    },
    "1802.08714": {
        "title": "Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction",
        "authors": [
            "Huaxiu Yao",
            "Fei Wu",
            "Jintao Ke",
            "Xianfeng Tang",
            "Yitian Jia",
            "Siyu Lu",
            "Pinghua Gong",
            "Jieping Ye",
            "Z. Li"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "839c4dd710ae7a234424aeda2f1423e0ce61bd5e"
    },
    "1509.06461": {
        "title": "Deep Reinforcement Learning with Double Q-Learning",
        "authors": [
            "H. V. Hasselt",
            "A. Guez",
            "David Silver"
        ],
        "submission_date": "2015",
        "SemanticScholarId": "3b9732bb07dc99bde5e1f9f75251c6ea5039373e"
    },
    "1504.06937": {
        "title": "Algorithms with Logarithmic or Sublinear Regret for Constrained Contextual Bandits",
        "authors": [
            "Huasen Wu",
            "R. Srikant",
            "Xin Liu",
            "Chong Jiang"
        ],
        "submission_date": "2015",
        "SemanticScholarId": "c2ec642af956d09e6b23eb3a6df6d4fb75c853eb"
    }
}