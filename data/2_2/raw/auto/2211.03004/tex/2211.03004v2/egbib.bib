@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})

@article{ajoudani2018progress,
  title={Progress and prospects of the human--robot collaboration},
  author={Ajoudani, Arash and Zanchettin, Andrea Maria and Ivaldi, Serena and Albu-Sch{\"a}ffer, Alin and Kosuge, Kazuhiro and Khatib, Oussama},
  journal={Autonomous Robots},
  year={2018},
  publisher={Springer}
}

@article{henschel2020social,
  title={Social cognition in the age of human--robot interaction},
  author={Henschel, Anna and Hortensius, Ruud and Cross, Emily S},
  journal={Trends in Neurosciences},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{roshambo,
  title={Live demonstration: Convolutional neural network driven by dynamic vision sensor playing RoShamBo},
  author={Lungu, Iulia-Alexandra and Corradi, Federico and Delbr{\"u}ck, Tobi},
  booktitle={2017 IEEE International Symposium on Circuits and Systems (ISCAS)},
  year={2017},
  organization={IEEE},
  conference=IEEE_CVPR
}

@inproceedings{geirhos2018imagenettrained,
title={ImageNet-trained {CNN}s are biased towards texture; increasing shape bias improves accuracy and robustness.},
author={Robert Geirhos and Patricia Rubisch and Claudio Michaelis and Matthias Bethge and Felix A. Wichmann and Wieland Brendel},
booktitle={International Conference on Learning Representations},
year={2019},
}

@article{gallego2015event,
  title={Event-based camera pose tracking using a generative event model},
  author={Gallego, Guillermo and Forster, Christian and Mueggler, Elias and Scaramuzza, Davide},
  journal={arXiv preprint arXiv:1510.01972},
  year={2015}
}

@article{messikommer2021bridging,
  title={Bridging the Gap between Events and Frames through Unsupervised Domain Adaptation},
  author={Messikommer, Nico and Gehrig, Daniel and Gehrig, Mathias and Scaramuzza, Davide},
  journal={arXiv preprint arXiv:2109.02618},
  year={2021}
}

@article{cavagnero2022freerea,
  title={FreeREA: Training-Free Evolution-based Architecture Search},
  author={Cavagnero, Niccol{\'o} and Robbiano, Luca and Caputo, Barbara and Averta, Giuseppe},
  journal={arXiv preprint arXiv:2207.05135},
  year={2022}
}

@inproceedings{ma2016going,
  title={Going deeper into first-person activity recognition},
  author={Ma, Minghuang and Fan, Haoqi and Kitani, Kris M},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2016}
}
@InProceedings{Wu_2019_CVPR,
author = {Wu, Chao-Yuan and Feichtenhofer, Christoph and Fan, Haoqi and He, Kaiming and Krahenbuhl, Philipp and Girshick, Ross},
title = {Long-Term Feature Banks for Detailed Video Understanding},
booktitle = {CVPR},
year = {2019}
}

@inproceedings{amir2017low,
  title={A low power, fully event-based gesture recognition system},
  author={Amir, Arnon and Taba, Brian and Berg, David and Melano, Timothy and McKinstry, Jeffrey and Di Nolfo, Carmelo and Nayak, Tapan and Andreopoulos, Alexander and Garreau, Guillaume and Mendoza, Marcela and others},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2017}
}

@article{miao2019neuromorphic,
  title={Neuromorphic vision datasets for pedestrian detection, action recognition, and fall detection},
  author={Miao, Shu and Chen, Guang and Ning, Xiangyu and Zi, Yang and Ren, Kejia and Bing, Zhenshan and Knoll, Alois},
  journal={Frontiers in neurorobotics},
  volume={13},
  year={2019},
}

@article{gehrig2021dsec,
  title={Dsec: A stereo event camera dataset for driving scenarios},
  author={Gehrig, Mathias and Aarents, Willem and Gehrig, Daniel and Scaramuzza, Davide},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  year={2021},
  publisher={IEEE}
}

@article{perot2020learning,
  title={Learning to detect objects with a 1 megapixel event camera},
  author={Perot, Etienne and de Tournemire, Pierre and Nitti, Davide and Masci, Jonathan and Sironi, Amos},
  journal={arXiv preprint arXiv:2009.13436},
  year={2020}
}

@article{de2020large,
  title={A large scale event-based detection dataset for automotive},
  author={de Tournemire, Pierre and Nitti, Davide and Perot, Etienne and Migliore, Davide and Sironi, Amos},
  journal={arXiv preprint arXiv:2001.08499},
  year={2020}
}

@article{hu2016dvs,
  title={DVS benchmark datasets for object tracking, action recognition, and object recognition},
  author={Hu, Yuhuang and Liu, Hongjie and Pfeiffer, Michael and Delbruck, Tobi},
  journal={Frontiers in neuroscience},
  volume={10},
  year={2016},
  publisher={Frontiers}
}

@article{orchard2015converting,
  title={Converting static image datasets to spiking neuromorphic datasets using saccades},
  author={Orchard, Garrick and Jayawant, Ajinkya and Cohen, Gregory K and Thakor, Nitish},
  journal={Frontiers in neuroscience},
  volume={9},
  year={2015},
  publisher={Frontiers}
}

@article{lin2021esimagenet,
  title={ES-ImageNet: A Million Event-Stream Classification Dataset for Spiking Neural Networks},
  author={Lin, Yihan and Ding, Wei and Qiang, Shaohua and Deng, Lei and Li, Guoqi},
  journal={arXiv preprint arXiv:2110.12211},
  year={2021}
}

@inproceedings{kim2021n,
  title={N-imagenet: Towards robust, fine-grained object recognition with event cameras},
  author={Kim, Junho and Bae, Jaehyeok and Park, Gangin and Zhang, Dongsu and Kim, Young Min},
  booktitle={Proc. Int. Conf. Comput. Vis.},
  year={2021}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  year={2009},
  organization={Ieee}
}

@article{davies2018loihi,
  title={Loihi: A neuromorphic manycore processor with on-chip learning},
  author={Davies, Mike and Srinivasa, Narayan and Lin, Tsung-Han and Chinya, Gautham and Cao, Yongqiang and Choday, Sri Harsha and Dimou, Georgios and Joshi, Prasad and Imam, Nabil and Jain, Shweta and others},
  journal={Ieee Micro},
  year={2018},
  publisher={IEEE}
}

@article{lungu2019incremental,
  title={Incremental learning of hand symbols using event-based cameras},
  author={Lungu, Iulia Alexandra and Liu, Shih-Chii and Delbruck, Tobi},
  journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
  year={2019},
  publisher={IEEE}
}

@inproceedings{chen2020dynamic,
  title={Dynamic graph cnn for event-camera based gesture recognition},
  author={Chen, Junming and Meng, Jingjing and Wang, Xinchao and Yuan, Junsong},
  booktitle={2020 IEEE International Symposium on Circuits and Systems (ISCAS)},
  year={2020},
  organization={IEEE}
}

@article{furber2012overview,
  title={Overview of the spinnaker system architecture},
  author={Furber, Steve B and Lester, David R and Plana, Luis A and Garside, Jim D and Painkras, Eustace and Temple, Steve and Brown, Andrew D},
  journal={IEEE Transactions on Computers},
  volume={62},
  number={12},
  year={2012},
  publisher={IEEE}
}

@inproceedings{vasudevan2020introduction,
  title={Introduction and analysis of an event-based sign language dataset},
  author={Vasudevan, Ajay and Negri, Pablo and Linares-Barranco, Bernabe and Serrano-Gotarredona, Teresa},
  booktitle={2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)},
  year={2020},
  organization={IEEE}
}

@article{akopyan2015truenorth,
  title={Truenorth: Design and tool flow of a 65 mw 1 million neuron programmable neurosynaptic chip},
  author={Akopyan, Filipp and Sawada, Jun and Cassidy, Andrew and Alvarez-Icaza, Rodrigo and Arthur, John and Merolla, Paul and Imam, Nabil and Nakamura, Yutaka and Datta, Pallab and Nam, Gi-Joon and others},
  journal={IEEE transactions on computer-aided design of integrated circuits and systems},
  volume={34},
  number={10},
  year={2015},
  publisher={IEEE}
}

@inproceedings{sekikawa2019eventnet,
  title={EventNet: Asynchronous recursive event processing},
  author={Sekikawa, Yusuke and Hara, Kosuke and Saito, Hideo},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2019}
}

@inproceedings{yang2019modeling,
  title={Modeling point clouds with self-attention and gumbel subset sampling},
  author={Yang, Jiancheng and Zhang, Qiang and Ni, Bingbing and Li, Linguo and Liu, Jinxian and Zhou, Mengdie and Tian, Qi},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2019}
}

@article{bi2020graph,
  title={Graph-based spatio-temporal feature learning for neuromorphic vision sensing},
  author={Bi, Yin and Chadha, Aaron and Abbas, Alhabib and Bourtsoulatze, Eirina and Andreopoulos, Yiannis},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  year={2020},
  publisher={IEEE}
}

@InProceedings{HidalgoCarrio2020Learning,
  author    = {Javier Hidalgo-Carrio and Daniel Gehrig and Davide Scaramuzza},
  booktitle = {2020 International Conference on 3D Vision (3DV)},
  title     = {Learning Monocular Dense Depth from Events},
  year      = {2020},
  month     = {nov},
  publisher = {{IEEE}},
  doi       = {10.1109/3dv50981.2020.00063},
}

@Article{Gehrig2021Combining,
  author    = {Daniel Gehrig and Michelle Ruegg and Mathias Gehrig and Javier Hidalgo-Carrio and Davide Scaramuzza},
  journal   = {{IEEE} Robotics and Automation Letters},
  title     = {Combining Events and Frames Using Recurrent Asynchronous Multimodal Networks for Monocular Depth Prediction},
  year      = {2021},
  doi       = {10.1109/lra.2021.3060707},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@inproceedings{messikommer2020event,
  title={Event-based asynchronous sparse convolutional networks},
  author={Messikommer, Nico and Gehrig, Daniel and Loquercio, Antonio and Scaramuzza, Davide},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  year={2020},
  organization={Springer}
}

@inproceedings{cannici2019asynchronous,
  title={Asynchronous convolutional networks for object detection in neuromorphic cameras},
  author={Cannici, Marco and Ciccone, Marco and Romanoni, Andrea and Matteucci, Matteo},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops},
  year={2019}
}

@InProceedings{Zhu2018EV,
  author       = {Alex Zhu and Liangzhe Yuan and Kenneth Chaney and Kostas Daniilidis},
  booktitle    = {Robotics: Science and Systems {XIV}},
  title        = {{EV}-{FlowNet}: Self-Supervised Optical Flow Estimation for Event-based Cameras},
  year         = {2018},
  month        = jun,
  publisher    = {Robotics: Science and Systems Foundation},
  doi          = {10.15607/rss.2018.xiv.062},
}

@InProceedings{Gehrig3dv2021,
  author = {Mathias Gehrig and Mario Millh\"ausler and Daniel Gehrig and Davide Scaramuzza},
  title = {E-RAFT: Dense Optical Flow from Event Cameras},
  booktitle = {International Conference on 3D Vision (3DV)},
  year = {2021}
}

@inproceedings{parameshwara20210,
  title={0-mms: Zero-shot multi-motion segmentation with a monocular event camera},
  author={Parameshwara, Chethan M and Sanket, Nitin J and Singh, Chahat Deep and Ferm{\"u}ller, Cornelia and Aloimonos, Yiannis},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2021},
  organization={IEEE}
}

@article{Zhou21tnnls,
  title={Event-based Motion Segmentation with Spatio-Temporal Graph Cuts},
  author={Zhou, Yi and Gallego, Guillermo and Lu, Xiuyuan and Liu, Siqi and Shen, Shaojie},
  journal={IEEE Transactions on Neural Network and Learning Systems},
  year={2021}
}

@inproceedings{sevilla2018integration,
  title={On the integration of optical flow and action recognition},
  author={Sevilla-Lara, Laura and Liao, Yiyi and G{\"u}ney, Fatma and Jampani, Varun and Geiger, Andreas and Black, Michael J},
  booktitle={German Conference on Pattern Recognition},
  year={2018},
  organization={Springer}
}

@article{gallego2019event,
  title={Event-based vision: A survey},
  author={Gallego, Guillermo and Delbruck, Tobi and Orchard, Garrick and Bartolozzi, Chiara and Taba, Brian and Censi, Andrea and Leutenegger, Stefan and Davison, Andrew and Conradt, J{\"o}rg and Daniilidis, Kostas and others},
  journal={arXiv preprint arXiv:1904.08405},
  year={2019}
}

@inproceedings{Delbruck2016Neuromorophic,
  title={Neuromorophic vision sensing and processing},
  author={Delbruck, Tobi},
  booktitle={2016 46Th european solid-state device research conference (ESSDERC)},
  year={2016},
  organization={IEEE}
}

@inproceedings{kondratyuk2021movinets,
  title={Movinets: Mobile video networks for efficient video recognition},
  author={Kondratyuk, Dan and Yuan, Liangzhe and Li, Yandong and Zhang, Li and Tan, Mingxing and Brown, Matthew and Gong, Boqing},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2021}
}

@inproceedings{sun2015learning,
  title={Learning a convolutional neural network for non-uniform motion blur removal},
  author={Sun, Jian and Cao, Wenfei and Xu, Zongben and Ponce, Jean},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2015}
}

@article{zhang2018adversarial,
  title={Adversarial spatio-temporal learning for video deblurring},
  author={Zhang, Kaihao and Luo, Wenhan and Zhong, Yiran and Ma, Lin and Liu, Wei and Li, Hongdong},
  journal={IEEE Transactions on Image Processing},
  volume={28},
  number={1},
  year={2018},
  publisher={IEEE}
}

@inproceedings{damen2018scaling,
  title={Scaling egocentric vision: The epic-kitchens dataset},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Fidler, Sanja and Furnari, Antonino and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  booktitle={Proceedings of the Proc. Eur. Conf. Comput. Vis.},
  year={2018}
}

@article{planamente2021da4event,
  title={DA4Event: towards bridging the Sim-to-Real Gap for Event Cameras using Domain Adaptation},
  author={Planamente, Mirco and Plizzari, Chiara and Cannici, Marco and Ciccone, Marco and Strada, Francesco and Bottino, Andrea and Matteucci, Matteo and Caputo, Barbara},
  journal={arXiv preprint arXiv:2103.12768},
  year={2021}
}

@inproceedings{cannici2021n,
  title={N-ROD: A Neuromorphic Dataset for Synthetic-to-Real Domain Adaptation},
  author={Cannici, Marco and Plizzari, Chiara and Planamente, Mirco and Ciccone, Marco and Bottino, Andrea and Caputo, Barbara and Matteucci, Matteo},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2021}
}

@inproceedings{munro2020multi,
  title={Multi-modal domain adaptation for fine-grained action recognition},
  author={Munro, Jonathan and Damen, Dima},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2020}
}

@misc{ek2020,
  author = {Damen, Dima and Kazakos, Evangelos and Price, Will and Ma, Jian and Doughty, Hazel},
  title = {EPIC-KITCHENS-55 - 2020 Challenges Report},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://epic-kitchens.github.io/Reports/EPIC-KITCHENS-Challenges-2020-Report.pdf}},
  commit = {4f57d6a0e4c030202a07a60bc1bb1ed1544bf679}
}
@misc{ek2021,
 author = {Damen, Dima and 
Fragomeni, Adriano and
Munro,Jonathan and
Perrett, Toby and 
Whettam,Daniel and 
Wray, Michael},
  title = {EPIC-KITCHENS-100- 2021 Challenges Report},
  year = {2021},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://epic-kitchens.github.io/Reports/EPIC-KITCHENS-Challenges-2021-Report.pdf}},
}



@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2016}
}
@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  year={2015},
  organization={PMLR}
}


@article{sgdmom,
title = {On the momentum term in gradient descent learning algorithms},
journal = {Neural Networks},
year = {1999},
doi = {https://doi.org/10.1016/S0893-6080(98)00116-6},
author = {Ning Qian},
keywords = {Momentum, Gradient descent learning algorithm, Damped harmonic oscillator, Critical damping, Learning rate, Speed of convergence}
}

@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@inproceedings{lee2018motion,
  title={Motion feature network: Fixed motion filter for action recognition},
  author={Lee, Myunggi and Lee, Seungeui and Son, Sungjoon and Park, Gyutae and Kwak, Nojun},
  booktitle={Proceedings of the Proc. Eur. Conf. Comput. Vis. (ECCV)},
  year={2018}
}

@inproceedings{zhao2019dance,
  title={Dance with flow: Two-in-one stream action detection},
  author={Zhao, Jiaojiao and Snoek, Cees GM},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2019}
}

@inproceedings{pham2021meta,
  title={Meta pseudo labels},
  author={Pham, Hieu and Dai, Zihang and Xie, Qizhe and Le, Quoc V},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2021}
}

@article{zhai2021scaling,
  title={Scaling vision transformers},
  author={Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  journal={arXiv preprint arXiv:2106.04560},
  year={2021}
}

@article{dai2021coatnet,
  title={CoAtNet: Marrying Convolution and Attention for All Data Sizes},
  author={Dai, Zihang and Liu, Hanxiao and Le, Quoc V and Tan, Mingxing},
  journal={arXiv preprint arXiv:2106.04803},
  year={2021}
}

@article{he2021masked,
  title={Masked Autoencoders Are Scalable Vision Learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  journal={arXiv preprint arXiv:2111.06377},
  year={2021}
}

@article{song2016fast,
  title={How fast is your body motion? Determining a sufficient frame rate for an optical motion tracking system using passive markers},
  author={Song, Min-Ho and God{\o}y, Rolf Inge},
  journal={PloS one},
  year={2016},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{morasso1981spatial,
  title={Spatial control of arm movements},
  author={Morasso, Pietro},
  journal={Experimental brain research},
  year={1981},
  publisher={Springer}
}

@inproceedings{stoffregen2019event,
  title={Event-based motion segmentation by motion compensation},
  author={Stoffregen, Timo and Gallego, Guillermo and Drummond, Tom and Kleeman, Lindsay and Scaramuzza, Davide},
  booktitle={Proc. Int. Conf. Comput. Vis.},
  year={2019}
}

@inproceedings{zach2007duality,
  title={A duality based approach for realtime tv-l 1 optical flow},
  author={Zach, Christopher and Pock, Thomas and Bischof, Horst},
  booktitle={Joint pattern recognition symposium},
  year={2007},
  organization={Springer}
}

@inproceedings{li2015delving,
  title={Delving into egocentric actions},
  author={Li, Yin and Ye, Zhefan and Rehg, James M},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2015}
}

@article{wang2018temporal,
  title={Temporal segment networks for action recognition in videos},
  author={Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Van Gool, Luc},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.},
  year={2018},
  publisher={IEEE}
}
@inproceedings{wang2016temporal,
  title={Temporal segment networks: Towards good practices for deep action recognition},
  author={Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Van Gool, Luc},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  year={2016},
  organization={Springer}
}

@article{girdhar2017attentional,
  title={Attentional pooling for action recognition},
  author={Girdhar, Rohit and Ramanan, Deva},
  journal={arXiv preprint arXiv:1711.01467},
  year={2017}
}

@inproceedings{wang2019self,
  title={Self-supervised spatio-temporal representation learning for videos by predicting motion and appearance statistics},
  author={Wang, Jiangliu and Jiao, Jianbo and Bao, Linchao and He, Shengfeng and Liu, Yunhui and Liu, Wei},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2019}
}

@article{rodin2021predicting,
  title={Predicting the future from first person (egocentric) vision: A survey},
  author={Rodin, Ivan and Furnari, Antonino and Mavroeidis, Dimitrios and Farinella, Giovanni Maria},
  journal={Computer Vision and Image Understanding},
  year={2021},
  publisher={Elsevier}
}

@article{kazakos2021little,
  title={With a Little Help from my Temporal Context: Multimodal Egocentric Action Recognition},
  author={Kazakos, Evangelos and Huh, Jaesung and Nagrani, Arsha and Zisserman, Andrew and Damen, Dima},
  journal={arXiv preprint arXiv:2111.01024},
  year={2021}
}

@inproceedings{wang2021interactive,
  title={Interactive Prototype Learning for Egocentric Action Recognition},
  author={Wang, Xiaohan and Zhu, Linchao and Wang, Heng and Yang, Yi},
  booktitle={Proc. Int. Conf. Comput. Vis.},
  year={2021}
}

@inproceedings{sudhakaran2019lsta,
  title={Lsta: Long short-term attention for egocentric action recognition},
  author={Sudhakaran, Swathikiran and Escalera, Sergio and Lanz, Oswald},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2019}
}
@article{damen2022rescaling,
  title={Rescaling egocentric vision: collection, pipeline and challenges for epic-kitchens-100},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Furnari, Antonino and Kazakos, Evangelos and Ma, Jian and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  journal={Int. J. Comput. Vis.},
  volume={130},
  number={1},
  pages={33--55},
  year={2022},
  publisher={Springer}
}
@inproceedings{tran2015learning,
  title={Learning spatiotemporal features with 3d convolutional networks},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis.},
  year={2015}
}

@inproceedings{min2021integrating,
  title={Integrating Human Gaze into Attention for Egocentric Activity Recognition},
  author={Min, Kyle and Corso, Jason J},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  year={2021}
}

@inproceedings{garcia2018first,
  title={First-person hand action benchmark with rgb-d videos and 3d hand pose annotations},
  author={Garcia-Hernando, Guillermo and Yuan, Shanxin and Baek, Seungryul and Kim, Tae-Kyun},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2018}
}

@inproceedings{cartas2019seeing,
  title={Seeing and hearing egocentric actions: How much can we learn?},
  author={Cartas, Alejandro and Luque, Jordi and Radeva, Petia and Segura, Carlos and Dimiccoli, Mariella},
  booktitle={Proc. Int. Conf. Comput. Vis. Workshops},
  year={2019}
}



@inproceedings{fathi2012learning,
  title={Learning to recognize daily actions using gaze},
  author={Fathi, Alireza and Li, Yin and Rehg, James M},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  year={2012},
  organization={Springer}
}
@article{li2021eye,
  title={In the eye of the beholder: Gaze and actions in first person video},
  author={Li, Yin and Liu, Miao and Rehg, Jame},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2021},
  publisher={IEEE}
}




@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2015}
}

@inproceedings{wang2017residual,
  title={Residual attention network for image classification},
  author={Wang, Fei and Jiang, Mengqing and Qian, Chen and Yang, Shuo and Li, Cheng and Zhang, Honggang and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2017}
}


@inproceedings{david2010impossibility,
  title={Impossibility theorems for domain adaptation},
  author={David, Shai Ben and Lu, Tyler and Luu, Teresa and P{\'a}l, D{\'a}vid},
  booktitle={Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}


@inproceedings{planamente2021domain,
  title={Domain generalization through audio-visual relative norm alignment in first person action recognition},
  author={Planamente, Mirco and Plizzari, Chiara and Alberti, Emanuele and Caputo, Barbara},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  year={2022}
}

@inproceedings{tran2019video,
  title={Video classification with channel-separated convolutional networks},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Feiszli, Matt},
  booktitle={Proc. Int. Conf. Comput. Vis.},
  year={2019}
}


@inproceedings{planamente2021self,
  title={Self-Supervised Joint Encoding of Motion and Appearance for First Person Action Recognition},
  author={Planamente, Mirco and Bottino, Andrea and Caputo, Barbara},
  booktitle={Int. Conf. Pattern Recog.},
  year={2021},
  organization={IEEE}
}



@inproceedings{lin2019tsm,
  title={Tsm: Temporal shift module for efficient video understanding},
  author={Lin, Ji and Gan, Chuang and Han, Song},
  booktitle={Proc. Int. Conf. Comput. Vis.},
  year={2019}
}

@inproceedings{qiu2017learning,
  title={Learning spatio-temporal representation with pseudo-3d residual networks},
  author={Qiu, Zhaofan and Yao, Ting and Mei, Tao},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis.},
  year={2017}
}
@inproceedings{xie2018rethinking,
  title={Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs in video classification},
  author={Xie, Saining and Sun, Chen and Huang, Jonathan and Tu, Zhuowen and Murphy, Kevin},
  booktitle={Proceedings of the Proc. Eur. Conf. Comput. Vis. (ECCV)},
  year={2018}
}

@inproceedings{tran2018closer,
  title={A closer look at spatiotemporal convolutions for action recognition},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2018}
}

@inproceedings{feichtenhofer2020x3d,
  title={X3d: Expanding architectures for efficient video recognition},
  author={Feichtenhofer, Christoph},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2020}
}

@inproceedings{sun2015human,
  title={Human action recognition using factorized spatio-temporal convolutional networks},
  author={Sun, Lin and Jia, Kui and Yeung, Dit-Yan and Shi, Bertram E},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis.},
  year={2015}
}

@inproceedings{zhou2018temporal,
  title={Temporal relational reasoning in videos},
  author={Zhou, Bolei and Andonian, Alex and Oliva, Aude and Torralba, Antonio},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  year={2018}
}


@article{li2018videolstm,
  title={Videolstm convolves, attends and flows for action recognition},
  author={Li, Zhenyang and Gavrilyuk, Kirill and Gavves, Efstratios and Jain, Mihir and Snoek, Cees GM},
  journal={Computer Vision and Image Understanding},
  year={2018},
  publisher={Elsevier}
}
@inproceedings{donahue2015long,
  title={Long-term recurrent convolutional networks for visual recognition and description},
  author={Donahue, Jeffrey and Anne Hendricks, Lisa and Guadarrama, Sergio and Rohrbach, Marcus and Venugopalan, Subhashini and Saenko, Kate and Darrell, Trevor},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2015}
}

@inproceedings{baradel2018object,
  title={Object level visual reasoning in videos},
  author={Baradel, Fabien and Neverova, Natalia and Wolf, Christian and Mille, Julien and Mori, Greg},
  booktitle={Proceedings of the Proc. Eur. Conf. Comput. Vis. (ECCV)},
  year={2018}
}


@inproceedings{wang2020symbiotic,
  title={Symbiotic attention with privileged information for egocentric action recognition},
  author={Wang, Xiaohan and Wu, Yu and Zhu, Linchao and Yang, Yi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2020}
}

@inproceedings{fathi2011understanding,
  title={Understanding egocentric activities},
  author={Fathi, Alireza and Farhadi, Ali and Rehg, James M},
  booktitle={2011 international conference on computer vision},
  year={2011},
  organization={IEEE}
}
@inproceedings{shan2020understanding,
  title={Understanding human hands in contact at internet scale},
  author={Shan, Dandan and Geng, Jiaqi and Shu, Michelle and Fouhey, David F},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2020}
}


@inproceedings{wu2019long,
  title={Long-term feature banks for detailed video understanding},
  author={Wu, Chao-Yuan and Feichtenhofer, Christoph and Fan, Haoqi and He, Kaiming and Krahenbuhl, Philipp and Girshick, Ross},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2019}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  journal=IEEE_CVPR,
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2017}
}
@inproceedings{damen2014you,
  title={You-Do, I-Learn: Discovering Task Relevant Objects and their Modes of Interaction from Multi-User Egocentric Video.},
  author={Damen, Dima and Leelasawassuk, Teesid and Haines, Osian and Calway, Andrew and Mayol-Cuevas, Walterio W},
  booktitle={BMVC},
  year={2014}
}

@article{girdhar2021anticipative,
  title={Anticipative Video Transformer},
  author={Girdhar, Rohit and Grauman, Kristen},
  journal={arXiv preprint arXiv:2106.02036},
  year={2021}
}


@inproceedings{vu2019advent,
  title={Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation},
  author={Vu, Tuan-Hung and Jain, Himalaya and Bucher, Maxime and Cord, Matthieu and P{\'e}rez, Patrick},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2019}
}



@article{hoffman2016fcns,
  title={Fcns in the wild: Pixel-level adversarial and constraint-based adaptation},
  author={Hoffman, Judy and Wang, Dequan and Yu, Fisher and Darrell, Trevor},
  journal={arXiv preprint arXiv:1612.02649},
  year={2016}
}
@inproceedings{tsai2018learning,
  title={Learning to adapt structured output space for semantic segmentation},
  author={Tsai, Yi-Hsuan and Hung, Wei-Chih and Schulter, Samuel and Sohn, Kihyuk and Yang, Ming-Hsuan and Chandraker, Manmohan},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2018}
}

@inproceedings{cordts2016cityscapes,
  title={The cityscapes dataset for semantic urban scene understanding},
  author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2016}
}

@article{events-deng2020amae,
  title={AMAE: Adaptive Motion-Agnostic Encoder for Event-Based Object Classification},
  author={Deng, Yongjian and Li, Youfu and Chen, Hao},
  journal={IEEE Robotics and Automation Letters},
  year={2020},
  publisher={IEEE}
}



@inproceedings{events-cannici2020differentiable,
  title={A differentiable recurrent surface for asynchronous event-based data},
  author={Cannici, Marco and Ciccone, Marco and Romanoni, Andrea and Matteucci, Matteo},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  year={2020},
  organization={Springer}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  year={1997},
  publisher={MIT Press}
}

@inproceedings{maqueda2018event,
  title={Event-based vision meets deep learning on steering prediction for self-driving cars},
  author={Maqueda, Ana I and Loquercio, Antonio and Gallego, Guillermo and Garc{\'\i}a, Narciso and Scaramuzza, Davide},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2018}
}

@inproceedings{gehrig2019end,
  title={End-to-end learning of representations for asynchronous event-based data},
  author={Gehrig, Daniel and Loquercio, Antonio and Derpanis, Konstantinos G and Scaramuzza, Davide},
  booktitle={Proc. Int. Conf. Comput. Vis.},
  year={2019}
}


@inproceedings{grandvalet2005semi,
author = {Grandvalet, Yves and Bengio, Y.},
year = {2004},
title = {Semi-supervised Learning by Entropy Minimization},
booktitle = {Adv. Neural Inform. Process. Syst.}
}

@inproceedings{paszke2017automatic,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  booktitle={NIPS-W},
  year={2017}
}

@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2018}
}
@article{DBLP:journals/corr/OrchardJCT15,
  title={Converting static image datasets to spiking neuromorphic datasets using saccades},
  author={Orchard, Garrick and Jayawant, Ajinkya and Cohen, Gregory K and Thakor, Nitish},
  journal={Frontiers in neuroscience},
  year={2015},
  publisher={Frontiers}
}

@inproceedings{arandjelovic2017look,
  title={Look, listen and learn},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis.},
  year={2017}
}

@inproceedings{arandjelovic2018objects,
  title={Objects that sound},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={Proceedings of the Proc. Eur. Conf. Comput. Vis. (ECCV)},
  year={2018}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  year={2014},
  publisher={JMLR. org}
}


@inproceedings{crasto2019mars,
  title={Mars: Motion-augmented rgb stream for action recognition},
  author={Crasto, Nieves and Weinzaepfel, Philippe and Alahari, Karteek and Schmid, Cordelia},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2019}
}


@inproceedings{sun2018pwc,
  title={Pwc-net: Cnns for optical flow using pyramid, warping, and cost volume},
  author={Sun, Deqing and Yang, Xiaodong and Liu, Ming-Yu and Kautz, Jan},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2018}
}


@inproceedings{stoffregen2020reducing,
  title={Reducing the sim-to-real gap for event cameras},
  author={Stoffregen, Timo and Scheerlinck, Cedric and Scaramuzza, Davide and Drummond, Tom and Barnes, Nick and Kleeman, Lindsay and Mahony, Robert},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXVII 16},
  year={2020},
  organization={Springer}
}



@article{damen2021rescaling,
  title={Rescaling Egocentric Vision: Collection, Pipeline and Challenges for EPIC-KITCHENS-100},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Furnari, Antonino and Kazakos, Evangelos and Ma, Jian and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  journal={Int. J. Comput. Vis.},
  year={2021},
  publisher={Springer}
}
@article{grauman2021ego4d,
  title={Ego4D: Around the World in 3,000 Hours of Egocentric Video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  journal={arXiv preprint arXiv:2110.07058},
  year={2021}
}
@article{lu2021understanding,
  title={Understanding Egocentric Hand-Object Interactions from Hand Pose Estimation},
  author={Lu, Yao and Mayol-Cuevas, Walterio W},
  journal={arXiv preprint arXiv:2109.14657},
  year={2021}
}
@article{price2019evaluation,
  title={An evaluation of action recognition models on epic-kitchens},
  author={Price, Will and Damen, Dima},
  journal={arXiv preprint arXiv:1908.00867},
  year={2019}
}

@article{lagorce2016hots,
  title={Hots: a hierarchy of event-based time-surfaces for pattern recognition},
  author={Lagorce, Xavier and Orchard, Garrick and Galluppi, Francesco and Shi, Bertram E and Benosman, Ryad B},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2016},
  publisher={IEEE}
}

@inproceedings{thapar2021anonymizing,
  title={Anonymizing Egocentric Videos},
  author={Thapar, Daksh and Nigam, Aditya and Arora, Chetan},
  booktitle={Proc. Int. Conf. Comput. Vis.},
  year={2021}
}
@inproceedings{wen2021seeing,
  title={Seeing the Unseen: Predicting the First-Person Camera Wearer's Location and Pose in Third-Person Scenes},
  author={Wen, Yangming and Singh, Krishna Kumar and Anderson, Markham and Jan, Wei-Pang and Lee, Yong Jae},
  booktitle={Proc. Int. Conf. Comput. Vis.},
  year={2021}
}
@article{lee2015predicting,
  title={Predicting important objects for egocentric video summarization},
  author={Lee, Yong Jae and Grauman, Kristen},
  journal={International Journal of Computer Vision},
  year={2015},
  publisher={Springer}
}

@inproceedings{lee2012discovering,
  title={Discovering important people and objects for egocentric video summarization},
  author={Lee, Yong Jae and Ghosh, Joydeep and Grauman, Kristen},
  booktitle={2012 IEEE conference on computer vision and pattern recognition},
  year={2012},
  organization={IEEE}
}

@article{del2016summarization,
  title={Summarization of egocentric videos: A comprehensive survey},
  author={Del Molino, Ana Garcia and Tan, Cheston and Lim, Joo-Hwee and Tan, Ah-Hwee},
  journal={IEEE Transactions on Human-Machine Systems},
  year={2016},
  publisher={IEEE}
}
@inproceedings{liu2020forecasting,
  title={Forecasting human-object interaction: joint prediction of motor attention and actions in first person video},
  author={Liu, Miao and Tang, Siyu and Li, Yin and Rehg, James M},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  year={2020},
  organization={Springer}
}
@article{furnari2020rolling,
  title={Rolling-unrolling lstms for action anticipation from first-person video},
  author={Furnari, Antonino and Farinella, Giovanni},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.},
  year={2020},
  publisher={IEEE}
}
@inproceedings{abu2018will,
  title={When will you do what?-anticipating temporal occurrences of activities},
  author={Abu Farha, Yazan and Richard, Alexander and Gall, Juergen},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2018}
}


@article{events-maass1997networks,
  title={Networks of spiking neurons: the third generation of neural network models},
  author={Maass, Wolfgang},
  journal={Neural networks},
  year={1997},
  publisher={Elsevier}
}



@phdthesis{events-cohen2016thesis,
  TITLE = {{Event-Based Feature Detection, Recognition and Classification}},
  AUTHOR = {Cohen, Gregory Kevin},
  NUMBER = {2016PA066204},
  SCHOOL = {{Universit{\'e} Pierre et Marie Curie - Paris VI ; University of Western Sydney}},
  YEAR = {2016},
  HAL_ID = {tel-01426001},
  HAL_VERSION = {v1},
}


@inproceedings{events-sironi2018hats,
  title={Hats: Histograms of averaged time surfaces for robust event-based object classification},
  author={Sironi, Amos and Brambilla, Manuele and Bourdis, Nicolas and Lagorce, Xavier and Benosman, Ryad},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2018}
}

@article{events-lagorce2017hots,
  author={X. {Lagorce} and G. {Orchard} and F. {Galluppi} and B. E. {Shi} and R. B. {Benosman}},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={HOTS: A Hierarchy of Event-Based Time-Surfaces for Pattern Recognition}, 
  year={2017},
  doi={10.1109/TPAMI.2016.2574707}}

@inproceedings{events-zhu2019unsupervised,
  title={Unsupervised event-based learning of optical flow, depth, and egomotion},
  author={Zhu, Alex Zihao and Yuan, Liangzhe and Chaney, Kenneth and Daniilidis, Kostas},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2019}
}

@article{events-innocenti2020temporal,
      title={Temporal Binary Representation for Event-Based Action Recognition}, 
      author={Simone Undri Innocenti and Federico Becattini and Federico Pernici and Alberto Del Bimbo},
      year={2020},
      journal={arXiv},
}

@inproceedings{rebecq2018esim,
  title={ESIM: an open event camera simulator},
  author={Rebecq, Henri and Gehrig, Daniel and Scaramuzza, Davide},
  booktitle={Conference on Robot Learning},
  pages={969--982},
  year={2018},
  organization={PMLR}
}

@inproceedings{gehrig2020video,
  title={Video to events: Recycling video datasets for event cameras},
  author={Gehrig, Daniel and Gehrig, Mathias and Hidalgo-Carri{\'o}, Javier and Scaramuzza, Davide},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2020}
}

@inproceedings{hu2021v2e,
  title={V2e: From video frames to realistic DVS events},
  author={Hu, Yuhuang and Liu, Shih-Chii and Delbruck, Tobi},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2021}
}

@inproceedings{jiang2018super,
  title={Super slomo: High quality estimation of multiple intermediate frames for video interpolation},
  author={Jiang, Huaizu and Sun, Deqing and Jampani, Varun and Yang, Ming-Hsuan and Learned-Miller, Erik and Kautz, Jan},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2018}
}

@inproceedings{liu2017video,
  title={Video frame synthesis using deep voxel flow},
  author={Liu, Ziwei and Yeh, Raymond A and Tang, Xiaoou and Liu, Yiming and Agarwala, Aseem},
  booktitle={Proc. IEEE Int. Conf. Comput. Vis.},
  year={2017}
}

@inproceedings{long2016learning,
  title={Learning image matching by simply watching video},
  author={Long, Gucan and Kneip, Laurent and Alvarez, Jose M and Li, Hongdong and Zhang, Xiaohu and Yu, Qifeng},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  year={2016},
  organization={Springer}
}

@inproceedings{niklaus2017video,
  title={Video frame interpolation via adaptive convolution},
  author={Niklaus, Simon and Mai, Long and Liu, Feng},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2017}
}



@inproceedings{tulyakov2021time,
  title={Time Lens: Event-Based Video Frame Interpolation},
  author={Tulyakov, Stepan and Gehrig, Daniel and Georgoulis, Stamatios and Erbach, Julius and Gehrig, Mathias and Li, Yuanyou and Scaramuzza, Davide},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2021}
}

@inproceedings{hu2020ddd20,
  title={DDD20 End-to-End event camera driving dataset: Fusing frames and events with deep learning for improved steering prediction},
  author={Hu, Yuhuang and Binas, Jonathan and Neil, Daniel and Liu, Shih-Chii and Delbruck, Tobi},
  booktitle={2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)},
  year={2020},
  organization={IEEE}
}





@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture  submission ID 324. Supplied as additional material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as additional material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,

year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14, 
year = 2004
}

%%%%% INTRO 

@inproceedings{torralba2011unbiased,
  title={Unbiased look at dataset bias},
  author={Torralba, Antonio and Efros, Alexei A},
  booktitle={CVPR 2011},
  year={2011},
  organization={IEEE}
}

@inproceedings{ghadiyaram2019large,
  title={Large-scale weakly-supervised pre-training for video action recognition},
  author={Ghadiyaram, Deepti and Tran, Du and Mahajan, Dhruv},
  booktitle={CVPR},
  year={2019}
}

@InProceedings{pmlr-v28-muandet13, title = {Domain Generalization via Invariant Feature Representation}, author = {Krikamol Muandet and David Balduzzi and Bernhard Sch√∂lkopf}, pages = {10--18}, year = {2013}, editor = {Sanjoy Dasgupta and David McAllester}, volume = {28}, number = {1}, series = {Proceedings of Machine Learning Research}, address = {Atlanta, Georgia, USA}, month = {17--19 Jun}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v28/muandet13.pdf}, url = {http://proceedings.mlr.press/v28/muandet13.html}, abstract = {This paper investigates domain generalization: How to take knowledge acquired from an arbitrary number of related domains and apply it to previously unseen domains? We propose Domain-Invariant Component Analysis (DICA), a kernel-based optimization algorithm that learns an invariant transformation by minimizing the dissimilarity across domains, whilst preserving the functional relationship between input and output variables. A learning-theoretic analysis shows that reducing dissimilarity improves the expected generalization ability of classifiers on new domains, motivating the proposed algorithm. Experimental results on synthetic and real-world datasets demonstrate that DICA successfully learns invariant features and improves classifier performance in practice. } }

%%%%%%%%%%%%%%%% FPAR

@inproceedings{10.5555/2968826.2968890,
author = {Simonyan, Karen and Zisserman, Andrew},
title = {Two-Stream Convolutional Networks for Action Recognition in Videos},
year = {2014},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
abstract = {We investigate architectures of discriminatively trained deep Convolutional Networks (ConvNets) for action recognition in video. The challenge is to capture the complementary information on appearance from still frames and motion between frames. We also aim to generalise the best performing hand-crafted features within a data-driven learning framework.Our contribution is three-fold. First, we propose a two-stream ConvNet architecture which incorporates spatial and temporal networks. Second, we demonstrate that a ConvNet trained on multi-frame dense optical flow is able to achieve very good performance in spite of limited training data. Finally, we show that multitask learning, applied to two different action classification datasets, can be used to increase the amount of training data and improve the performance on both. Our architecture is trained and evaluated on the standard video actions benchmarks of UCF-101 and HMDB-51, where it is competitive with the state of the art. It also exceeds by a large margin previous attempts to use deep nets for video classification.},
booktitle = {NIPS},
location = {Montreal, Canada},
series = {NIPS'14}
}
@InProceedings{Song_2021_CVPR,
    author    = {Song, Xiaolin and Zhao, Sicheng and Yang, Jingyu and Yue, Huanjing and Xu, Pengfei and Hu, Runbo and Chai, Hua},
    title     = {Spatio-temporal Contrastive Domain Adaptation for Action Recognition},
    booktitle = {CVPR},
    year      = {2021},
}

@inproceedings{kim2021learning,
  title={Learning cross-modal contrastive features for video domain adaptation},
  author={Kim, Donghyun and Tsai, Yi-Hsuan and Zhuang, Bingbing and Yu, Xiang and Sclaroff, Stan and Saenko, Kate and Chandraker, Manmohan},
  booktitle={ICCV},
  year={2021}
}

%conv lstm
@InProceedings{Sudhakaran_2017_ICCV,
author = {Sudhakaran, Swathikiran and Lanz, Oswald},
title = {Convolutional Long Short-Term Memory Networks for Recognizing First Person Interactions},
booktitle = {ICCVW},
year = {2017}
}


@inproceedings{fathi2011learning,
  title={Learning to recognize objects in egocentric activities},
  author={Fathi, Alireza and Ren, Xiaofeng and Rehg, James M},
  booktitle={CVPR 2011},
  year={2011},
}



%3D

%usa 3d cnn
@inproceedings{singh2016first,
  title={First person action recognition using deep learned descriptors},
  author={Singh, Suriya and Arora, Chetan and Jawahar, CV},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2016}
}


%usa 3d cnn


%Kapidis --> lo chiamerei STL + H + G %usa 3d cnn

@inproceedings{weston2011wsabie,
  title={Wsabie: Scaling up to large vocabulary image annotation},
  author={Weston, Jason and Bengio, Samy and Usunier, Nicolas},
  booktitle={Twenty-Second International Joint Conference on Artificial Intelligence},
  year={2011}
}
@article{poliak2018hypothesis,
  title={Hypothesis only baselines in natural language inference},
  author={Poliak, Adam and Naradowsky, Jason and Haldar, Aparajita and Rudinger, Rachel and Van Durme, Benjamin},
  journal={arXiv preprint arXiv:1805.01042},
  year={2018}
}
@inproceedings{goyal2017making,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{alamri2019audio,
  title={Audio visual scene-aware dialog},
  author={Alamri, Huda and Cartillier, Vincent and Das, Abhishek and Wang, Jue and Cherian, Anoop and Essa, Irfan and Batra, Dhruv and Marks, Tim K and Hori, Chiori and Anderson, Peter and others},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2019}
}

%slow fast
@inproceedings{feichtenhofer2019slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={Int. Conf. Pattern Recog.},
  year={2019}
}
%slowfast audio 
@inproceedings{kazakos2021slow,
  title={Slow-Fast Auditory Streams for Audio Recognition},
  author={Kazakos, Evangelos and Nagrani, Arsha and Zisserman, Andrew and Damen, Dima},
  booktitle={ICASSP},
  year={2021}
}

%%%% ATTENTION 
@misc{perezrua2020knowing,
    title={Knowing What, Where and When to Look: Efficient Video Action Modeling with Attention},
    author={Juan-Manuel Perez-Rua and Brais Martinez and Xiatian Zhu and Antoine Toisoul and Victor Escorcia and Tao Xiang},
    year={2020},
    eprint={2004.01278},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@ARTICLE{Lu2019TIP,
  author={M. {Lu} and Z. {Li} and Y. {Wang} and G. {Pan}},
  journal={IEEE Transactions on Image Processing}, 
  title={Deep Attention Network for Egocentric Action Recognition}, 
  year={2019},
  }

@inproceedings{mounir2022spatio,
  title={Spatio-Temporal Event Segmentation for Wildlife Extended Videos},
  author={Mounir, Ramy and Gula, Roman and Theuerkauf, J{\"o}rn and Sarkar, Sudeep},
  booktitle={International Conference on Computer Vision and Image Processing},
  pages={48--59},
  year={2022},
  organization={Springer}
}

@inproceedings{aakur2019perceptual,
  title={A perceptual prediction framework for self supervised event segmentation},
  author={Aakur, Sathyanarayanan N and Sarkar, Sudeep},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  pages={1197--1206},
  year={2019}
}


@inproceedings{lu2019learning,
  title={Learning Spatiotemporal Attention for Egocentric Action Recognition},
  author={Lu, Minlong and Liao, Danping and Li, Ze-Nian},
  booktitle={CVPR Workshops},
  year={2019}
}

%%% FUSION 

% win BAIDU
@article{wangsymbiotic,
  title={Symbiotic Attention: UTS-Baidu Submission to the EPIC-Kitchens 2020 Action Recognition Challenge},
  author={Wang, Xiaohan and Wu, Yu and Zhu, Linchao and Yang, Yi and Zhuang, Yueting}
}


@article{sudhakaran2019hierarchical,
  title={Hierarchical feature aggregation networks for video action recognition},
  author={Sudhakaran, Swathikiran and Escalera, Sergio and Lanz, Oswald},
  journal={arXiv preprint arXiv:1905.12462},
  year={2019}
}

% limits cost of OF
@InProceedings{Crasto_2019_CVPR,
author = {Crasto, Nieves and Weinzaepfel, Philippe and Alahari, Karteek and Schmid, Cordelia},
title = {MARS: Motion-Augmented RGB Stream for Action Recognition},
booktitle = {CVPR},
year = {2019}
}


%%% Single stream 

@article{bandini2020analysis,
  title={Analysis of the hands in egocentric vision: A survey},
  author={Bandini, Andrea and Zariffa, Jos{\'e}},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2020},
  publisher={IEEE}
}

@inproceedings{sun2018optical,
  title={Optical flow guided feature: A fast and robust motion representation for video action recognition},
  author={Sun, Shuyang and Kuang, Zhanghui and Sheng, Lu and Ouyang, Wanli and Zhang, Wei},
  booktitle={CVPR},
  year={2018}
}



%%%%%%%%%%%%%%%% END FPAR





@inproceedings{cooperative_torresani, author = {Korbar, Bruno and Tran, Du and Torresani, Lorenzo}, title = {Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization}, year = {2018}, publisher = {Curran Associates Inc.}, booktitle = {NIPS}, series = {NIPS'18} }


@inproceedings{look_listen_learn,
  title={Look, listen and learn},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{objects_that_sound,
  title={Objects that sound},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={Proceedings of the ECCV (ECCV)},
  year={2018}
}
@inproceedings{aytar2016soundnet,
  title={Soundnet: Learning sound representations from unlabeled video},
  author={Aytar, Yusuf and Vondrick, Carl and Torralba, Antonio},
  booktitle={Advances in neural information processing systems},
  year={2016}
}
@inproceedings{multisensory_owens,
  title={Audio-visual scene analysis with self-supervised multisensory features},
  author={Owens, Andrew and Efros, Alexei A},
  booktitle={Proceedings of the ECCV (ECCV)},
  year={2018}
}

@InProceedings{Morgado_2021_CVPR,
    author    = {Morgado, Pedro and Misra, Ishan and Vasconcelos, Nuno},
    title     = {Robust Audio-Visual Instance Discrimination},
    booktitle = {Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)},
    year      = {2021},
}

@inproceedings{morgado2021audio,
  title={Audio-visual instance discrimination with cross-modal agreement},
  author={Morgado, Pedro and Vasconcelos, Nuno and Misra, Ishan},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2021}
}



@inproceedings{afourasself,
  title={Self-supervised learning of audio-visual objects from video},
  author={Afouras, Triantafyllos and Owens, Andrew and Chung, Joon Son and Zisserman, Andrew},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XVIII 16},
  year={2020},
  organization={Springer}
}

@article{morgado2020learning,
  title={Learning Representations from Audio-Visual Spatial Alignment},
  author={Morgado, Pedro and Li, Yi and Vasconcelos, Nuno},
  journal={arXiv preprint arXiv:2011.01819},
  year={2020}
}

@article{tian2020unified,
  title={Unified multisensory perception: weakly-supervised audio-visual video parsing},
  author={Tian, Yapeng and Li, Dingzeyu and Xu, Chenliang},
  journal={arXiv preprint arXiv:2007.10558},
  year={2020}
}

@article{agarwal2020unsupervised,
  title={Unsupervised Domain Adaptation for Spatio-Temporal Action Localization},
  author={Agarwal, Nakul and Chen, Yi-Ting and Dariush, Behzad and Yang, Ming-Hsuan},
  journal={arXiv:2010.09211},
  year={2020}
}
@inproceedings{pan2020adversarial,
  title={Adversarial cross-domain action recognition with co-attention},
  author={Pan, Boxiao and Cao, Zhangjie and Adeli, Ehsan and Niebles, Juan Carlos},
  booktitle={AAAI},
  year={2020}
}

@inproceedings{chen2020action,
  title={Action segmentation with joint self-supervised temporal domain adaptation},
  author={Chen, Min-Hung and Li, Baopu and Bao, Yingze and AlRegib, Ghassan and Kira, Zsolt},
  booktitle={CVPR},
  year={2020}
}





%% MM-SADA
@InProceedings{Munro_2020_CVPR,
author = {Munro, Jonathan and Damen, Dima},
title = {Multi-Modal Domain Adaptation for Fine-Grained Action Recognition},
booktitle = {Proc. IEEE Conf. Comput.
Vis. Pattern Recognit.},
year = {2020}
}

@article{damen2020rescaling,
  title={Rescaling egocentric vision},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Furnari, Antonino and Kazakos, Evangelos and Ma, Jian and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  journal={arXiv preprint arXiv:2006.13256},
  year={2020}
}



%% ImageNet
@INPROCEEDINGS{imageNet,
  author={J. {Deng} and W. {Dong} and R. {Socher} and L. {Li} and  {Kai Li} and  {Li Fei-Fei}},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  doi={10.1109/CVPR.2009.5206848}}
  
%% Kinetics
@inproceedings{kinetics,
title	= {The Kinetics Human Action Video Dataset},
author	= {Andrew Zisserman and Joao Carreira and Karen Simonyan and Will Kay and Brian Zhang and Chloe Hillier and Sudheendra Vijayanarasimhan and Fabio Viola and Tim Green and Trevor Back and Paul Natsev and Mustafa Suleyman},
year	= {2017}
}

%% GRL
@inproceedings{grl-pmlr-v37-ganin15,
  title={Unsupervised domain adaptation by backpropagation},
  author={Ganin, Yaroslav and Lempitsky, Victor},
  booktitle={International conference on machine learning},
  year={2015},
  organization={PMLR}
}


%% AdaBN
@article{ada-bn,
  title={Adaptive Batch Normalization for practical domain adaptation},
  author={Li, Yanghao and Wang, Naiyan and Shi, Jianping and Hou, Xiaodi and Liu, Jiaying},
  journal={Pattern Recognition},
  year={2018},
  publisher={Elsevier}
}

%% DOMAIN ADAPTATION

% surveys
@article{survey-wang2018deep,
  title={Deep visual domain adaptation: A survey},
  author={Wang, Mei and Deng, Weihong},
  journal={Neurocomputing},
  volume={312},
  year={2018},
  publisher={Elsevier}
}
@article{survey-wilson2020survey,
  title={A survey of unsupervised deep domain adaptation},
  author={Wilson, Garrett and Cook, Diane J},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  year={2020},
  publisher={ACM New York, NY, USA}
}
@article{survey-kouw2019review,
  title={A review of domain adaptation without target labels},
  author={Kouw, Wouter Marco and Loog, Marco},
  journal={TPAMI},
  year={2019},
  publisher={IEEE}
}

%% distance-based DA
%% MMD
@inproceedings{da-mmdlong2015learning,
  title={Learning transferable features with deep adaptation networks},
  author={Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael},
  booktitle={ICML},
  year={2015}}

% AFN
@inproceedings{da-afnxu2019larger,
  title={Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation},
  author={Xu, Ruijia and Li, Guanbin and Yang, Jihan and Lin, Liang},
  booktitle={ICCV},
  year={2019}
}

% MCD
@inproceedings{da-mcdsaito2018maximum,
  title={Maximum classifier discrepancy for unsupervised domain adaptation},
  author={Saito, Kuniaki and Watanabe, Kohei and Ushiku, Yoshitaka and Harada, Tatsuya},
  booktitle={CVPR},
  year={2018}
}

%% Batch norm based DA
@inproceedings{da-bnchang2019domain,
  title={Domain-specific batch normalization for unsupervised domain adaptation},
  author={Chang, Woong-Gi and You, Tackgeun and Seo, Seonguk and Kwak, Suha and Han, Bohyung},
  booktitle={CVPR},
  year={2019}
}

%% Adversarial DA
@inproceedings{da-adv-tang2020discriminative,
  title={Discriminative Adversarial Domain Adaptation.},
  author={Tang, Hui and Jia, Kui},
  booktitle={AAAI},
  pages={5940--5947},
  year={2020}
}
@inproceedings{da-adv-deng2019cluster,
  title={Cluster alignment with a teacher for unsupervised domain adaptation},
  author={Deng, Zhijie and Luo, Yucen and Zhu, Jun},
  booktitle={CVPR},
  year={2019}
}

%% CycleGAN
@inproceedings{da-cycle-gong2019dlow,
  title={Dlow: Domain flow for adaptation and generalization},
  author={Gong, Rui and Li, Wen and Chen, Yuhua and Gool, Luc Van},
  booktitle={CVPR},
  year={2019}
}
@inproceedings{da-cycle-hoffman2018cycada,
  title={Cycada: Cycle-consistent adversarial domain adaptation},
  author={Hoffman, Judy and Tzeng, Eric and Park, Taesung and Zhu, Jun-Yan and Isola, Phillip and Saenko, Kate and Efros, Alexei and Darrell, Trevor},
  booktitle={ICML},
  year={2018}
}

% DA WITH BN 
@inproceedings{DBLP:conf/iclr/LiWS0H17,
  author    = {Yanghao Li and
               Naiyan Wang and
               Jianping Shi and
               Jiaying Liu and
               Xiaodi Hou},
  title     = {Revisiting Batch Normalization For Practical Domain Adaptation},
  booktitle = {ICLRW},
  year      = {2017}
}

%% Video DA
@inproceedings{videoda-Choi2020ShuffleAA,
  title={Shuffle and Attend: Video Domain Adaptation},
  author={Jin-woo Choi and Gaurav Sharma and S. Schulter and J. Huang},
  booktitle={ECCV},
  year={2020}
}
@inproceedings{videoda-Jamal2018DeepDA,
  title={Deep Domain Adaptation in Action Space},
  author={A. Jamal and Vinay P. Namboodiri and Dipti Deodhare and K. Venkatesh},
  booktitle={BMVC},
  year={2018}
}

@article{videoda-wang2020self,
  title={Self-supervised video representation learning by pace prediction},
  author={Wang, Jiangliu and Jiao, Jianbo and Liu, Yun-Hui},
  journal={arXiv preprint arXiv:2008.05861},
  year={2020}
}
@article{videoda-Han2020SelfsupervisedCF,
  title={Self-supervised Co-training for Video Representation Learning},
  author={Tengda Han and Weidi Xie and Andrew Zisserman},
  journal={ArXiv},
  year={2020},
  volume={abs/2010.09709}
}
@inproceedings{videoda-chen2019temporal,
  title={Temporal attentive alignment for large-scale video domain adaptation},
  author={Chen, Min-Hung and Kira, Zsolt and AlRegib, Ghassan and Yoo, Jaekwon and Chen, Ruxin and Zheng, Jian},
  booktitle={CVPR},
  year={2019}
}
@INPROCEEDINGS{videoda-chen2020,
  author={M. {Chen} and B. {Li} and Y. {Bao} and G. {AlRegib}},
  booktitle={2020 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Action Segmentation with Mixed Temporal Domain Adaptation}, 
  year={2020},
  volume={},
  number={},
  pages={594-603},
  doi={10.1109/WACV45572.2020.9093535}}
@inproceedings{videoda-pan2020adversarial,
  title={Adversarial Cross-Domain Action Recognition with Co-Attention.},
  author={Pan, Boxiao and Cao, Zhangjie and Adeli, Ehsan and Niebles, Juan Carlos},
  booktitle={AAAI},
  year={2020}
}


%% Video DG
@article{videodg-yao2019adversarial,
  title={Adversarial Pyramid Network for Video Domain Generalization},
  author={Yao, Zhiyu and Wang, Yunbo and Du, Xingqiang and Long, Mingsheng and Wang, Jianmin},
  journal={arXiv preprint arXiv:1912.03716},
  year={2019}
}



%% Two-stream approaches 



%% Audio-Visual Skimming 
@inproceedings{listen_to_look,
  title={Listen to look: Action recognition by previewing audio},
  author={Gao, Ruohan and Oh, Tae-Hyun and Grauman, Kristen and Torresani, Lorenzo},
  booktitle={CVPR},
  year={2020}
}


%% Paper che teorizza il problema di GRL 
@inproceedings{pmlr-v97-liu19b, title = {Transferable Adversarial Training: A General Approach to Adapting Deep Classifiers}, author = {Liu, Hong and Long, Mingsheng and Wang, Jianmin and Jordan, Michael}, pages = {4013--4022}, year = {2019}, editor = {Kamalika Chaudhuri and Ruslan Salakhutdinov}, volume = {97}, series = {Proceedings of Machine Learning Research}, address = {Long Beach, California, USA}, month = {09--15 Jun}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v97/liu19b/liu19b.pdf}, url = {http://proceedings.mlr.press/v97/liu19b.html}, abstract = {Domain adaptation enables knowledge transfer from a labeled source domain to an unlabeled target domain. A mainstream approach is adversarial feature adaptation, which learns domain-invariant representations through aligning the feature distributions of both domains. However, a theoretical prerequisite of domain adaptation is the adaptability measured by the expected risk of an ideal joint hypothesis over the source and target domains. In this respect, adversarial feature adaptation may potentially deteriorate the adaptability, since it distorts the original feature distributions when suppressing domain-specific variations. To this end, we propose Transferable Adversarial Training (TAT) to enable the adaptation of deep classifiers. The approach generates transferable examples to fill in the gap between the source and target domains, and adversarially trains the deep classifiers to make consistent predictions over the transferable examples. Without learning domain-invariant representations at the expense of distorting the feature distributions, the adaptability in the theoretical learning bound is algorithmically guaranteed. A series of experiments validate that our approach advances the state of the arts on a variety of domain adaptation tasks in vision and NLP, including object recognition, learning from synthetic to real data, and sentiment classification.} }
%%DG

@inproceedings{carlucci2019domain,
  title={Domain generalization by solving jigsaw puzzles},
  author={Carlucci, Fabio M and D'Innocente, Antonio and Bucci, Silvia and Caputo, Barbara and Tommasi, Tatiana},
  booktitle={CVPR},
  year={2019}
}


@inproceedings{volpi2018generalizing,
  title={Generalizing to unseen domains via adversarial data augmentation},
  author={Volpi, Riccardo and Namkoong, Hongseok and Sener, Ozan and Duchi, John C and Murino, Vittorio and Savarese, Silvio},
  booktitle={NIPS},
  year={2018}
}

@inproceedings{li2018domain,
  title={Domain generalization with adversarial feature learning},
  author={Li, Haoliang and Jialin Pan, Sinno and Wang, Shiqi and Kot, Alex C},
  booktitle={CVPR},
  year={2018}
}

@article{yao2021videodg,
  title={Videodg: Generalizing temporal relations in videos to novel domains},
  author={Yao, Zhiyu and Wang, Yunbo and Wang, Jianmin and Yu, Philip and Long, Mingsheng},
  journal={TPAMI},
  year={2021},
  publisher={IEEE}
}


@article{dou2019domain,
  title={Domain generalization via model-agnostic learning of semantic features},
  author={Dou, Qi and Coelho de Castro, Daniel and Kamnitsas, Konstantinos and Glocker, Ben},
  journal={NIPS},
  volume={32},
  year={2019}
}

@inproceedings{li2018deep,
  title={Deep domain generalization via conditional invariant adversarial networks},
  author={Li, Ya and Tian, Xinmei and Gong, Mingming and Liu, Yajing and Liu, Tongliang and Zhang, Kun and Tao, Dacheng},
  booktitle={ECCV},
  year={2018}
}

% Jigsaw PAMI

@article{bucci2020selfsupervised,
  title={Self-supervised learning across domains},
  author={Bucci, Silvia and D'Innocente, Antonio and Liao, Yujun and Carlucci, Fabio Maria and Caputo, Barbara and Tommasi, Tatiana},
  journal={TPAMI},
  year={2021},
  publisher={IEEE}
}

@InProceedings{Zhao_2018_ECCV,
author = {Zhao, Hang and Gan, Chuang and Rouditchenko, Andrew and Vondrick, Carl and McDermott, Josh and Torralba, Antonio},
title = {The Sound of Pixels},
booktitle = {ECCV},
month = {September},
year = {2018}
}

@inproceedings{squeeze_and_excitation,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{non-local,
  title={Non-local neural networks},
  author={Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
  booktitle={CVPR},
  year={2018}
}

@article{instance_bn,
  title={Batch-instance normalization for adaptively style-invariant neural networks},
  author={Nam, Hyeonseob and Kim, Hyo-Eun},
  journal={arXiv preprint arXiv:1805.07925},
  year={2018}
}

@inproceedings{gradient-blending,
  title={What makes training multi-modal classification networks hard?},
  author={Wang, Weiyao and Tran, Du and Feiszli, Matt},
  booktitle={CVPR},
  year={2020}
}

@article{ye2018rethinking,
  title={Rethinking the smaller-norm-less-informative assumption in channel pruning of convolution layers},
  author={Ye, Jianbo and Lu, Xin and Lin, Zhe and Wang, James Z},
  journal={ICLR},
  year={2018}
}

@inproceedings{zheng2018ring,
  title={Ring loss: Convex feature normalization for face recognition},
  author={Zheng, Yutong and Pal, Dipan K and Savvides, Marios},
  booktitle={CVPR},
  year={2018}
}

@article{alwassel2019self,
  title={Self-supervised learning by cross-modal audio-video clustering},
  author={Alwassel, Humam and Mahajan, Dhruv and Korbar, Bruno and Torresani, Lorenzo and Ghanem, Bernard and Tran, Du},
  journal={arXiv preprint arXiv:1911.12667},
  year={2019}
}

@article{korbar2018co,
  title={Co-training of audio and video representations from self-supervised temporal synchronization},
  author={Korbar, Bruno},
  year={2018}
}


@inproceedings{tian2018audio,
  title={Audio-visual event localization in unconstrained videos},
  author={Tian, Yapeng and Shi, Jing and Li, Bochen and Duan, Zhiyao and Xu, Chenliang},
  booktitle={ECCV},
  year={2018}
}

@inproceedings{senocak2018learning,
  title={Learning to localize sound source in visual scenes},
  author={Senocak, Arda and Oh, Tae-Hyun and Kim, Junsik and Yang, Ming-Hsuan and Kweon, In So},
  booktitle={CVPR},
  year={2018}
}

@article{ephrat2018looking,
  title={Looking to listen at the cocktail party: A speaker-independent audio-visual model for speech separation},
  author={Ephrat, Ariel and Mosseri, Inbar and Lang, Oran and Dekel, Tali and Wilson, Kevin and Hassidim, Avinatan and Freeman, William T and Rubinstein, Michael},
  journal={arXiv preprint arXiv:1804.03619},
  year={2018}
}

@inproceedings{cheng2020look,
  title={Look, listen, and attend: Co-attention network for self-supervised audio-visual representation learning},
  author={Cheng, Ying and Wang, Ruize and Pan, Zhihao and Feng, Rui and Zhang, Yuejie},
  booktitle={ACM},
  year={2020}
}



%%%%% Multi task 
@inproceedings{kendall2018multi,
  title={Multi-task learning using uncertainty to weigh losses for scene geometry and semantics},
  author={Kendall, Alex and Gal, Yarin and Cipolla, Roberto},
  booktitle={CVPR},
  year={2018}
}


%%%%%% Multi modal approach
@inproceedings{kiela2018efficient,
  title={Efficient large-scale multi-modal classification},
  author={Kiela, Douwe and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  booktitle={AAAI},
  volume={32},
  number={1},
  year={2018}
}
@InProceedings{Owens_2018_ECCV,
author = {Owens, Andrew and Efros, Alexei A.},
title = {Audio-Visual Scene Analysis with Self-Supervised Multisensory Features},
booktitle = {ECCV},
month = {September},
year = {2018}
}
@inproceedings{chung2016out,
  title={Out of time: automated lip sync in the wild},
  author={Chung, Joon Son and Zisserman, Andrew},
  booktitle={Asian conference on computer vision},
  year={2016},
  organization={Springer}
}
@article{ranjan2017l2,
  title={L2-constrained softmax loss for discriminative face verification},
  author={Ranjan, Rajeev and Castillo, Carlos D and Chellappa, Rama},
  journal={arXiv preprint arXiv:1703.09507},
  year={2017}
}



@inproceedings{inproceedings,
author = {Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
year = {2017},
month = {07},
title = {Improved Texture Networks: Maximizing Quality and Diversity in Feed-Forward Stylization and Texture Synthesis},
doi = {10.1109/CVPR.2017.437}
}

@inproceedings{wang2020learning,
  title={Learning to combine: Knowledge aggregation for multi-source domain adaptation},
  author={Wang, Hang and Xu, Minghao and Ni, Bingbing and Zhang, Wenjun},
  booktitle={ECCV},
  year={2020},
  organization={Springer}
}

@misc{ek19report,
  author = {Damen, Dima and Price, Will and Kazakos, Evangelos and Furnari, Antonino and Farinella, Giovanni Maria },
  title = {EPIC-KITCHENS - 2019 Challenges Report},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub report},
  howpublished = {\url{https://epic-kitchens.github.io/Reports/EPIC-Kitchens-Challenges-2019-Report.pdf}},
}


@inproceedings{li2018eye,
  title={In the eye of beholder: Joint learning of gaze and actions in first person video},
  author={Li, Yin and Liu, Miao and Rehg, James M},
  booktitle={ECCV},
  year={2018}
}


@inproceedings{kumar2018wearable,
  title={Wearable smart glass: Features, applications, current progress and challenges},
  author={Kumar, Nallapaneni Manoj and Singh, Neeraj Kumar and Peddiny, VK},
  booktitle={ICGCIoT},
  year={2018},
  organization={IEEE}
}
@inproceedings{azimi2022self,
  title={Self-Supervised Test-Time Adaptation on Video Data},
  author={Azimi, Fatemeh and Palacio, Sebastian and Raue, Federico and Hees, J{\"o}rn and Bertinetto, Luca and Dengel, Andreas},
  booktitle={WACV},
  year={2022}
}

@article{wang2020tent,
  title={Tent: Fully test-time adaptation by entropy minimization},
  author={Wang, Dequan and Shelhamer, Evan and Liu, Shaoteng and Olshausen, Bruno and Darrell, Trevor},
  journal={arXiv preprint arXiv:2006.10726},
  year={2020}
}

@article{you2021test,
  title={Test-time batch statistics calibration for covariate shift},
  author={You, Fuming and Li, Jingjing and Zhao, Zhou},
  journal={arXiv preprint arXiv:2110.04065},
  year={2021}
}

@article{hu2021mixnorm,
  title={MixNorm: Test-Time Adaptation Through Online Normalization Estimation},
  author={Hu, Xuefeng and Uzunbas, Gokhan and Chen, Sirius and Wang, Rui and Shah, Ashish and Nevatia, Ram and Lim, Ser-Nam},
  journal={arXiv preprint arXiv:2110.11478},
  year={2021}
}
@article{liu2021ttt++,
  title={TTT++: When Does Self-Supervised Test-Time Training Fail or Thrive?},
  author={Liu, Yuejiang and Kothari, Parth and van Delft, Bastien and Bellot-Gurlet, Baptiste and Mordan, Taylor and Alahi, Alexandre},
  journal={NIPS},
  volume={34},
  year={2021}
}

@article{chen2019complement,
  title={Complement objective training},
  author={Chen, Hao-Yun and Wang, Pei-Hsin and Liu, Chun-Hao and Chang, Shih-Chieh and Pan, Jia-Yu and Chen, Yu-Ting and Wei, Wei and Juan, Da-Cheng},
  journal={arXiv:1903.01182},
  year={2019}
}

@inproceedings{hu2017learning,
  title={Learning discrete representations via information maximizing self-augmented training},
  author={Hu, Weihua and Miyato, Takeru and Tokui, Seiya and Matsumoto, Eiichi and Sugiyama, Masashi},
  booktitle={ICML},
  year={2017}
}


@article{shi2012information,
  title={Information-theoretical learning of discriminative clusters for unsupervised domain adaptation},
  author={Shi, Yuan and Sha, Fei},
  journal={arXiv preprint arXiv:1206.6438},
  year={2012}
}

@article{gomes2010discriminative,
  title={Discriminative clustering by regularized information maximization},
  author={Gomes, Ryan and Krause, Andreas and Perona, Pietro},
  year={2010},
  journal={NIPS}
}
@article{RandomWalk,
  title={A tutorial on spectral clustering},
  author={Von Luxburg, Ulrike},
  journal={Statistics and computing},
  volume={17},
  number={4},
  year={2007},
  publisher={Springer}
}



@inproceedings{
iwasawa2021testtime,
title={Test-Time Classifier Adjustment Module for Model-Agnostic Domain Generalization},
author={Yusuke Iwasawa and Yutaka Matsuo},
booktitle={NIPS},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021}
}

@article{plizzari20212,
  title={E $\^{} 2$(GO) MOTION: Motion Augmented Event Stream for Egocentric Action Recognition},
  author={Plizzari, Chiara and Planamente, Mirco and Goletto, Gabriele and Cannici, Marco and Gusso, Emanuele and Matteucci, Matteo and Caputo, Barbara},
  journal={arXiv preprint arXiv:2112.03596},
  year={2021}
}

@inproceedings{jin2020minimum,
  title={Minimum class confusion for versatile domain adaptation},
  author={Jin, Ying and Wang, Ximei and Long, Mingsheng and Wang, Jianmin},
  booktitle={ECCV},
  year={2020}
}

@article{wu2020entropy,
  title={Entropy minimization vs. diversity maximization for domain adaptation},
  author={Wu, Xiaofu and Zhou, Quan and Yang, Zhen and Zhao, Chunming and Latecki, Longin Jan and others},
  journal={arXiv:2002.01690},
  year={2020}
}


@InProceedings{Planamente_2022_WACV,
    author    = {Planamente, Mirco and Plizzari, Chiara and Alberti, Emanuele and Caputo, Barbara},
    title     = {Domain Generalization Through Audio-Visual Relative Norm Alignment in First Person Action Recognition},
    booktitle = {WACV},
    month     = {January},
    year      = {2022},
}
@article{plizzari2021polito,
  title={Polito-iit submission to the epic-kitchens-100 unsupervised domain adaptation challenge for action recognition},
  author={Plizzari, Chiara and Planamente, Mirco and Alberti, Emanuele and Caputo, Barbara},
  journal={arXiv preprint arXiv:2107.00337},
  year={2021}
}

@article{schneider2020improving,
  title={Improving robustness against common corruptions by covariate shift adaptation},
  author={Schneider, Steffen and Rusak, Evgenia and Eck, Luisa and Bringmann, Oliver and Brendel, Wieland and Bethge, Matthias},
  journal={arXiv preprint arXiv:2006.16971},
  year={2020}
}

@article{nado2020evaluating,
  title={Evaluating prediction-time batch normalization for robustness under covariate shift},
  author={Nado, Zachary and Padhy, Shreyas and Sculley, D and D'Amour, Alexander and Lakshminarayanan, Balaji and Snoek, Jasper},
  journal={arXiv preprint arXiv:2006.10963},
  year={2020}
}

@misc{
kim2022towards,
title={Towards Robust Domain Generalization in 2D Neural Audio Processing},
author={Byeonggeun Kim and Seunghan Yang and Jangho Kim and Hyunsin Park and Jun-Tae Lee and Simyung Chang},
year={2022},
url={https://openreview.net/forum?id=otOZeCahAhL}
}

@inproceedings{sun2020test,
  title={Test-time training with self-supervision for generalization under distribution shifts},
  author={Sun, Yu and Wang, Xiaolong and Liu, Zhuang and Miller, John and Efros, Alexei and Hardt, Moritz},
  booktitle={ICML},
  year={2020},
  organization={PMLR}
}

@article{zhou2021domain,
  title={Domain generalization with mixstyle},
  author={Zhou, Kaiyang and Yang, Yongxin and Qiao, Yu and Xiang, Tao},
  journal={arXiv preprint arXiv:2104.02008},
  year={2021}
}


@inproceedings{plizzari2022e2,
  title={E2 (GO) MOTION: Motion Augmented Event Stream for Egocentric Action Recognition},
  author={Plizzari, Chiara and Planamente, Mirco and Goletto, Gabriele and Cannici, Marco and Gusso, Emanuele and Matteucci, Matteo and Caputo, Barbara},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2022}
}

@inproceedings{wang2017normface,
  title={Normface: L2 hypersphere embedding for face verification},
  author={Wang, Feng and Xiang, Xiang and Cheng, Jian and Yuille, Alan Loddon},
  booktitle={Proceedings of the 25th ACM international conference on Multimedia},
  year={2017}
}

@inproceedings{du2022fast,
  title={Fast and Unsupervised Action Boundary Detection for Action Segmentation},
  author={Du, Zexing and Wang, Xue and Zhou, Guoqing and Wang, Qing},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2022}
}
@inproceedings{huang2016connectionist,
  title={Connectionist temporal modeling for weakly supervised action labeling},
  author={Huang, De-An and Fei-Fei, Li and Niebles, Juan Carlos},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  year={2016},
  organization={Springer}
}

@inproceedings{wang2020boundary,
  title={Boundary-aware cascade networks for temporal action segmentation},
  author={Wang, Zhenzhi and Gao, Ziteng and Wang, Limin and Li, Zhifeng and Wu, Gangshan},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  year={2020},
  organization={Springer}
}


@inproceedings{li2021temporal,
  title={Temporal action segmentation from timestamp supervision},
  author={Li, Zhe and Abu Farha, Yazan and Gall, Jurgen},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2021}
}

@article{khan2022timestamp,
  title={Timestamp-Supervised Action Segmentation with Graph Convolutional Networks},
  author={Khan, Hamza and Haresh, Sanjay and Ahmed, Awais and Siddiqui, Shakeeb and Konin, Andrey and Zia, M Zeeshan and Tran, Quoc-Huy},
  journal={arXiv preprint arXiv:2206.15031},
  year={2022}
}

@inproceedings{shou2016temporal,
  title={Temporal action localization in untrimmed videos via multi-stage cnns},
  author={Shou, Zheng and Wang, Dongang and Chang, Shih-Fu},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2016}
}

@inproceedings{shou2017cdc,
  title={Cdc: Convolutional-de-convolutional networks for precise temporal action localization in untrimmed videos},
  author={Shou, Zheng and Chan, Jonathan and Zareian, Alireza and Miyazawa, Kazuyuki and Chang, Shih-Fu},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit.},
  year={2017}
}

@inproceedings{piergiovanni2019temporal,
  title={Temporal gaussian mixture layer for videos},
  author={Piergiovanni, AJ and Ryoo, Michael},
  booktitle={Int. Conf. on Mach. Learn.},
  year={2019},
  
}



@article{chandola2009anomaly,
  title={Anomaly detection: A survey},
  author={Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
  journal={ACM computing surveys (CSUR)},
  year={2009},
  publisher={ACM New York, NY, USA}
}

@inproceedings{planamente2023toward,
  title={Toward Human-Robot Cooperation: Unsupervised Domain Adaptation for Egocentric Action Recognition},
  author={Planamente, Mirco and Goletto, Gabriele and Trivigno, Gabriele and Averta, Giuseppe and Caputo, Barbara},
  booktitle={Human-Friendly Robotics 2022: HFR: 15th International Workshop on Human-Friendly Robotics},
  pages={218--232},
  year={2023},
  organization={Springer}
}