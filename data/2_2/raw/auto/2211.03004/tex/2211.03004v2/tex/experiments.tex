\input{tex/Tables/Architectures}
\input{tex/Tables/position}

\section{Experiments}
%\input{tex/Tables/clean_static}
%\input{tex/Tables/clean_dinamically}
%\input{tex/Tables/ablation_clean}
In Table \ref{tab:backbone}, we compare two families of recently  designed tiny-networks with popular architectures used in action recognition, examining various factors such as different pretrains, sampling methodologies, and amount of params. Then, in Table \ref{tab:offlinevsstream}, we analyze the performance in the streaming scenario, displaying a plot of the models' accuracy vs the portion of the video observed (Fig \ref{fig:videoperc}). Fig \ref{fig:clean_static} shows the effects of the action detection algorithms used to move from the streaming \rev{to the online inference scenario}. Finally, in Fig \ref{fig:final_results}, we test the performance with untrimmed data, demonstrating how our two-fold aggregator ($A^{2}$) method grants a more robust solution with a little increase in parameters. The Table \ref{tab:device} illustrates the impact of performance in terms of latency, power consumption, and other critical characteristics for a designed device. %This empirical evaluation allows us to answer important research questions.

\textit{Impact of footprint on model accuracy.}
MoViNet and X3D are the two tiny architecture included in our benchmark to compare smaller models w.r.t standard action recognition networks. Interestingly, for X3D the tiny model size appears to have a negative impact on the final results, showing the lowest accuracy. It also suffers significantly from the transition from uniform to dense sampling (U$\rightarrow$D). MoViNet, on the other hand, appears to be the preferable alternative, showing more notable results in both seen and unseen settings. Noteworthy, we also observed higher robustness to the shift in sampling from uniform to dense (U$\rightarrow$D). All those considerations motivate our focus on MoViNet in this work.
%For these reasons, we pay special attention to MoViNet in the remaining of this  work.

\textit{The importance of seen-unseen accuracy.}
In contrast with the standard benchmark in action recognition, in our analysis we conduct experiments considering two different scenarios: seen and unseen. 
Indeed, looking only at the performances in the seen scenario, it seems that MoViNet obtains lower results compared to the TSM (\rev{62.45\%} and 71.48\% respectively).
Instead, when tested on unseen data distribution, we have a significant gain in performance of MoViNet w.r.t. TSM and I3D. %, we can conclude that the two networks are comparable (similar behaviors can also be seen using I3D). 
In particular, the MoViNet results with uniform or dense strategy are quite similar (\rev{39.25\%} and \rev{40.68\%} respectively). It is also worth noticing that, with more frames, MoViNet results in unseen scenarios improve considerably (see Table \ref{tab:offlinevsstream}). 


\textit{Offline $\xrightarrow[]{}$ \textit{Streaming}.}  
Table \ref{tab:offlinevsstream} shows the results in these two distinct settings. \rev{It is interesting to observe that MoViNet is the model that better exploits the continuous stream of data, obtaining the smallest deterioration in performance equal to 2\% and 1\% in seen and unseen scenarios respectively, whereas the other two networks show a much bigger decrease in performance.} This behavior is caused by the buffer implementation used in the MoViNet streaming version, which enables the simulation of a receptive field as large as the entire input video, while processing frames one-by-one ($T_s = 1$). On the contrary, I3D and X3D take as input block of 16 frames ($T_{s}$ = 16), which requires the recomputation of overlapping frames activations and may limit the total efficiency of the models. 
\textit{Streaming $\xrightarrow[]{}$ \textit{Online}.}
As discussed before, the standard action recognition protocol assumes available the knowledge of the action boundary as a prior-knowledge for the correct restart of the averaging output, to obtain video level prediction for architectures such as I3D or X3D, or to properly reset the buffer mechanism for MoViNet. In other words, ``cleaning'' the prior encoding for the new one is necessary to produce an accurate prediction for the current action. At this stage of our investigation, we assess how much the typical action recognition architectures rely on the action's boundary and how their performance is affected by the absence of this supervision knowledge. 

\textit{Dependency from the actions boundary. }
In Fig. \ref{fig:videoperc} we plot the accuracy of the models as a function of the percentage of the video observed. From this chart, we notice that the use of the last portion of the video does not provide a gain in accuracy, and after the 85\% of the video, no substantial improvement is obtained.
Similar observations can be made for the initial part of the video.
Interestingly, the performances of the tiny model X3D in the initial part of the observed video are very close to the final one, revealing a tendency to privilege appearance information with respect to motion information. Instead, the performance gap of MoViNet and I3D from the first portion of the video observed and after viewing 60\%â€“80\% of the data, confirms that their prediction is based more on the motion. This behavior is consistent with the more robust results in unknown conditions (unseen), where the appearance-based solution suffers more due to the fact that the appearance characteristics of the scene (texture, light condition, etc.) changes more among the environments with respect to the motion.

\input{tex/Tables/movinet_clean}

\textit{Effects of no supervision on actions boundaries.}
The loss of knowledge on actions boundaries requires a solution to automatically identify action changes. In this section, we discuss the performance of the strategy presented in section \ref{eventboundarydetection}, comparing the results with a static solution (Fig. \ref{fig:clean_static}). The latter is based on the ``naive'' assumption that all sample lengths are nearly equivalent, and as a result, it assumes that a new action is ``discovered'' at each $k$ frame. For both the solutions, we report a sensibility analysis on the number of frames for the static solution (SBL), and on the threshold value for the dynamic one (DBL), in both seen and unseen settings. According to Fig. \ref{fig:clean_static}, MoViNet with a low-loaded aggregator is unreliable; indeed, the results are lower than those without a clean one. Furthermore, by raising the buffer load, i.e., forwarding more frames, it increases its performance. A significant improvement of the dynamic strategy over the static one is also noticeable in Fig \ref{fig:dynamically_clean}. Moreover, MoViNet performance appears to be not sensitive to proper threshold values; indeed, the improvements of the DBL solution are always better compared to the best results of the SBL solution.
\input{tex/Tables/FinalResults}
\input{tex/Tables/delta}
\textit{Trimmed $\xrightarrow[]{}$ \textit{Untrimmed}.}
In Fig \ref{fig:final_results} we show the results in an untrimmed online scenario. We compare the performance of our DBL approach with  single ($A$) and two-fold  ($A^{2}$) aggregator, to the recently proposed technique ABD \cite{du2022fast}, exploiting it as a secondary stream to identify the boundary and provide the action boundary to the primary model of classification. \rev{For ABD, we used the original online implementation, with both NMS and filter windows size equal to 50.} Furthermore, we report, as a reference, untrimmed streaming (S) results, i.e., experiments in which the real boundary of the action is used as prior knowledge. 
%In this setting, where the action boundaries are even less clear than in the trimmed one it
We present the performance of the DBL technique and two-fold aggregator using I3D to demonstrate that the proposed approach is scalable and model agnostic. Indeed the improvement of $A^{2}$ is remarkable and the results obtained for both the architecture are comparable with the streaming scenario. Moreover, the solution with a single aggregator performs \rev{similarly} to the competitor ABD, without using a secondary stream for the boundary localization. 
Finally, the improvements of our solution $A^{2}$ with respect to the ABD are consistent across scenarios and models. 
\rev{To provide a comprehensive analysis, we conducted an ablation study on the delay hyperparameter $\delta$. The results are presented in Fig. \ref{fig:delta_ablation} and confirm that estimating $\delta$ as the average overlap of actions at the desired frame rate is a reliable approach.}

\input{tex/Tables/Device}
\textit{Edge Deployment.}
In Table \ref{tab:device} we show MACs, FPS Latency and Energy on different devices. These metrics are obtained from models deployed on each different hardware through the usage of TensorRT. Power is measured with a power meter, subtracting the static power. This analysis focuses on how hardware constraints affect the applicability of the existing model for action recognition on real device. Indeed, when the I3D model moved from a high-performance GPU (2080 Ti) to a laptop GPU (MX350) and, to an edge device (NVIDIA Jetson Nano), it used more energy, falling short of the required FPS threshold for identifying human motion (up to 20-30 FPS \cite{song2016fast}). Instead, in the case of MoViNet, the minimal number of model parameters ensures appropriate FPS (twice as needed), allowing the use of  two-fold aggregator technique in online \rev{inference} scenario. % also with alternating frames.
