\section{Conclusion}
%In this paper, we ask if we can generate many samples that are similar to samples from both the source and target domains. 
Our assumption is that if the generated samples are similar to both the source samples and the target samples, a classifier trained on these domain agnostic samples (and the training samples in the source and target domains) will learn to use domain invariant features to do classification (on the target domain). Based on this idea we propose MiddleGAN, a variation of GAN that generate these domain agnostic samples. We have extended the theory of GAN to prove that there exist optimal solutions for the weights of the two discriminators and one generator in MiddleGAN. We have empirically shown that the generated samples are similar to both the source and target domain samples (domain agnostic). We have conducted extensive evaluations using 24 benchmarks; on the 24 benchmarks, we compare MiddleGAN against various state-of-the-art algorithms and outperform the state-of-the-art by up to 20.1\% on certain benchmarks.