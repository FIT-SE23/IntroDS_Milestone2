\section{Introduction} 
In recent years, deep learning has achieved impressive results across different application domains \cite{esteva2021deep, he2016deep, szegedy2017inception, zhu2017densenet, purwins2019deep, noda2015audio, wu2021deep, wahab2021dna}. However, a deep neural net does not necessarily perform well on a new domain with different distribution than its training set. This problem is called domain shift, and domain adaptation (DA) have been invented to tackle the issue of domain shift. One approach of DA is to find domain-invariant features \cite{zhao2019learning}. 
%However, Zhao et al. \cite{zhao2019learning} point out that explicitly selecting a set of domain-invariant features that achieve small training and testing errors on the source domain does not necessarily guarantee that a classifier trained on those features performs well on the classification task in the target domain. Rather, the class-conditional distribution of the source domain could be different from the class-conditional distribution of the target domain. In other words, the class-conditional distribution of the input features on the source domain can differ from the class-conditional distribution of the input features on the target domain, and simply finding domain-invariant features does not take the conditional shift into consideration.

Instead of explicitly selecting domain-invariant features, we propose to let a classifier that will perform the classification task on the target domain implicitly learn to use domain-invariant features (to perform classification). In this way, we do not have to hand-engineer the features which may not be inclusive enough to include all the features that are domain-invariant. Our intuition is based on the observation that deep neural networks such as the ResNet-50 \cite{he2016deep} or Inception \cite{szegedy2016rethinking} generalize well when trained on a large amount of data. If we want the classifier to learn the domain invariant features (implicitly), we need a large amount of samples that is similar to both the source domain samples and the target domain samples. We call those samples domain agnostic samples. If we train a neural network such as the ResNet-50 with a large quantity of domain agnostic samples, the neural network will implicitly learn to use the domain-invariant features to perform classification.
%If a sample is similar to both the source and the target domains, then the domain-invariant features are predominant in this sample.

How do we generate those domain agnostic samples? We propose a variation of GAN, called the MiddleGAN, which has two discriminators and a generator. One discriminator is for the source domain; it tries to distinguish a generated sample from real samples from the source domain. Another discriminator is for the target domain; it tries to distinguish a generated sample from the real samples from the target domain. The generator is trying to generate samples that can deceive both discriminators at the same time. The three neural networks engage in a minimax game in which the generator is trying to generate samples to confuse both the source discriminator and the target discriminator. Ideally, after training, the generated samples will be indistinguishable from both the real source domain samples and the real target domain samples, thus achieving the similarity to samples of both domains. We have also extended the theory of GAN to theoretically prove that there exist optimal values for the source and target discriminators and the generator.

\textbf{The contributions of this paper are}:
\begin{itemize}
    \item We create a novel variation of GAN, the MiddleGAN, that generates samples that are similar to samples from both the source and target domains. In other words, these generated samples are domain invariant.
    %\item We theoretically prove that there exist optimal solutions for the parameters of the three neural nets in the MiddleGAN.
    %\item We empirically show that the predominant features of samples generated by MiddleGAN are domain invariant.
    \item We conduct extensive evaluation on 24 benchmarks; on the 24 benchmarks, we compare MiddleGAN against various state-of-the-art algorithms and outperform the state-of-the-art by up to 20.1\% on certain benchmarks.
\end{itemize}