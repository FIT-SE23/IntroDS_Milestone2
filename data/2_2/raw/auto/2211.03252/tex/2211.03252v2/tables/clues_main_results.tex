\begin{table}[t!]
\centering
\small
\linespread{1}

%\setlength{\tabcolsep}{1mm}{
\resizebox{\linewidth}{!}{
% \begin{tabular}{l|cccc}

% \toprule

% Top-1 acc/\% & \textbf{\model{}} & \textbf{ExEnt} & \textbf{ExEnt-BERT} & \textbf{ExEnt-GPT2} \\
% \midrule
% CLUES-Real & \textbf{57.4} & 54.8 & 46.4 & 43.8 \\
% \midrule
% \hspace{3mm}+pre-training & \textbf{55.2} & 52.7 & 50.5 & 52.4 \\

% Top-1 acc/\% & \textbf{\model{}} & \textbf{\model{}-plain}& \textbf{ExEnt} & \textbf{RoBERTa-sim} \\
% \midrule
% CLUES-Real & \textbf{57.4} & 45.8 & 54.8 & 45.1 \\
% \midrule
% \hspace{3mm}+pre-training & \textbf{55.2} & 49.8 & 52.7 & 46.3 \\


\begin{tabular}{c|ccc}
Top-1 acc/\% 
& CLUES-Real & + pre-training \\
\midrule

% \textbf{RoBERTa-sim} & 54.8 & 52.7 \\
% \textbf{ExEnt} & 45.1 & 46.3 \\

\textbf{ExEnt}  & 54.8 & 52.7 \\
\textbf{RoBERTa-sim} & 45.1 & 46.3 \\

\midrule 

\textbf{\model{}-plain} & 45.8 & 49.8 \\
\textbf{\model{}} & \textbf{57.4} & \textbf{55.2} \\

\bottomrule

\end{tabular}
}

\caption{Cross-task generalization results on CLUES dataset~\citep{menon2022clues}. The first row of results are acquired by only fine-tuning on CLUES-Real, and the second row shows results with additional pre-training on CLUES-Synthetic.
% \chihan{better baselines than GPT2 and BERT to be added, like similarity, ignoring logical structure, entailment?}
}
% \vspace{-4mm}
\label{tab:clues_main_results}
\end{table}