
\label{sec:related}

% \heng{the '~' means a blank space, so if you use '~' you get two white blanks}
\paragraph{Classification with Auxiliary Information}

This work studies the problem of classification through explanations, which is related to classification with auxiliary information. For example, in the natural language processing field,~\citet{JMLR:v11:mann10a, ganchev2010posterior} incorporate side information (such as class distribution and linguistic structures) as a regularization for semi-supervised learning. Some other efforts convert crowd-sourced explanations into pseudo-data generators for data augmentation when training data is limited~\citep{wang2020learning, hancock2018training, DBLP:conf/iclr/WangQZ0YN0R20}. However, these explanations are limited to describing linguistic patterns (e.g., ``this is class X because word A directly precedes B''), and are only used for generating pseudo labels. A probably more related topic is using explanations for generating a vector of features for classification~\cite{srivastava2017joint, srivastava2018zero}. However, they either learn a black-box final classifier on features or rely on observed attributes of data, so their ability of generalization is limited. 

% \heng{\sout{Check Manling's CVPR22 paper and its related work, there are many related papers about using NL explanations for cross-media tasks}}
The computer vision area widely uses class-level auxiliary information such as textual metadata, class taxonomy and expert-annotated feature vectors~\citep{yang2022comprehensive, akata2015evaluation, xian2016latent, lampert2009learning, akata2015label, samplawski2020zero}. However, the use of label names and class explanations is mainly limited to a simple text encoder~\citep{akata2015evaluation, xian2016latent, liu2021goal, norouzi2014zero}. This processing treats every text as one simple vector in similarity space or probability space, whereas our method aims to reason on the explanation and exploit its compositional nature.
% Recently, there has been impressive progress on vision-language pre-trained models (VLPMs)~\citep{li2022clip, radford2021learning, li2019visualbert, kim2021vilt}. These methods are trained on large-scale high-quality vision-text pairs with contrastive learning~\citep{radford2021learning, kim2021vilt, li2019visualbert} or mask prediction objective~\citep{kim2021vilt, li2019visualbert}. 
% However, these model mostly focus on representation learning than understanding the compositionality in language.
% As we will show through experiments, VLPMs fits data better at the cost of zero-shot generalization performance.
% As we will show through experiments, this approach performs less well when the inputs go beyond simple pattern matching and require more reasoning. On the contrary, 









\paragraph{Few-shot and Zero-shot Learning with Language Guidance}
% \heng{\sout{There are a lot of work on zero-shot for NLP tasks, you are missing a lot, such as Lifu's early work: https://blender.cs.illinois.edu/paper/zeroshot2018.pdf or you can focus on cross-media zero-shot tasks only}}
This work deals with the problem of learning with limited data with the help of natural language information, which is closely related to few-shot and zero-shot learning with language guidance in NLP domain~\citep{hancock2018training, DBLP:conf/iclr/WangQZ0YN0R20, srivastava2017joint, srivastava2018zero, yu2022building, huang2018zero}. Besides the discussions in the previous subsection, recent pre-trained language models (LMs)~\citep{kenton2019bert, liu2019roberta, tam-etal-2021-improving, gao-etal-2021-making, yu2022building} have made huge progress in few-shot and zero-shot learning. To adapt LMs to downstream tasks, common practices are to formulate them as cloze questions~\citep{tam-etal-2021-improving, schick2021s, menon2022clues, li2022piled} or use text prompts~\citep{mishra2022cross, ye2021crossfit, sanh2022multitask, aghajanyan-etal-2021-muppet}. These approaches hypothetically utilize the language models' implicit reasoning ability~\citep{menon2022clues}. However, in this work we demonstrate with empirical evidence that adopting an explicit logical reasoning approach can provide better interpretability and robustness to linguistic biases.

In computer vision, recently there has been impressive progress on vision-language pre-trained models (VLPMs)~\citep{li2022clip, radford2021learning, li2019visualbert, kim2021vilt}. These methods are trained on large-scale high-quality vision-text pairs with contrastive learning~\citep{radford2021learning, kim2021vilt, li2019visualbert} or mask prediction objective~\citep{kim2021vilt, li2019visualbert}. 
However, these model mostly focus on representation learning than understanding the compositionality in language.
As we will show through experiments, VLPMs fits data better at the cost of zero-shot generalization performance.

There are also efforts in building benchmarks for cross-task generalization with natural language explanations or instructions~\citep{mishra2022cross, menon2022clues}. We use the CLUES benchmark~\citep{menon2022clues} in our experiment for structured data classification, but leave~\citet{mishra2022cross} for future work as its instructions are focused on generally describing the task instead of defining categories/labels.





\paragraph{Neuro-Symbolic Reasoning for Question Answering} is also closely related to our approach. Recent work~\citep{mao2019neuro, yi2018neural, han2019visual} has demonstrated its efficacy in question answering, concept learning and image retrieval. Different from our work, previous efforts mainly focus on question answering tasks, which contains abundant supervision for parsing natural language questions. In classification tasks, however, the number of available explanations is much more limited (100$\sim$1000), which poses a higher challenge on the generalization of reasoning ability.


% \subsection{Language Classification from Explanations}

% On language classification tasks,~\cite{zhou2020nero} uses neural rules \heng{what do you mean by 'neural rules'?} on relation extraction, but the rules are explicitly given in symbolic form, and do not contain multi-step reasoning. A more similar direction is to better utilize natural language explanations from annotators. \cite{srivastava-etal-2017-joint} first proposes a joint concept learning and semantic parsing method for improving classification performance, but the programs are feature generators the classification is not explainable nor generalizable to new rules. \heng{I cannot parse this "but the programs are feature generators the classification is not explainable nor generalizable to new rules.". re-write it} \cite{wang2020learning, hancock2018training, ke2021knowledge} transforms natural language explanations into logical forms for data augmentation in the classification task, and~\cite{murty2020expbert} explores using explanations to engineer sentence representations that are beneficial for downstream tasks. Different from the present paper, these attempts focus on data augmentation rather than direct classification. Besides text classification,~\cite{menon2022clues} proposes a benchmark for classification from natural language explanations, but the task is on structured inputs (like tabular data) instead of unstructured texts. In the same setting,~\citep{srivastava2018zero} converts natural language rules to classification constraints for modelling language quantifiers.

% \subsection{Neural Reasoning}

% Our work is closely related to neuro-symbolic methods in the age of deep learning, which aims to utilize symbolic structures like programs. Symbolic structures can better convey compositional meanings so they are beneficial to modeling natural language texts which are inherently compositional. \heng{any citation to support this claim in the previous sentence?}
% Successful applications are often applied to question answering tasks such as visual reasoning \cite{hu2017learning, by2018closing, DBLP:conf/iclr/MaoGKTW19, yi2018neural}, knowledge base queries 
% \heng{'knowledge base queries' is not a task, write the task name here}
% \cite{andreas-etal-2016-learning, kapanipathi-etal-2021-leveraging} and language-driven navigation \cite{mao2021grammar}. Different from previous attempts, in this paper we adopt a different setting, text classification, which often lacks explicit questions so the model is not informed of how to reason on each input.
% \xd{\cite{berant-etal-2013-semantic} use question-answer pairs as training supervision and obtain the executable programs, but it requires mapping textual input to logical forms as preprocessing. While our method is end-to-end....}

%%% Our work is also related to predictive methods based on social elements for social tasks. \cite{emelin-etal-2021-moral} explores action and consequence classification based on norms on Social Chemistry 101 dataset \cite{forbes-etal-2020-social}. In the area of legal artificial intelligence, symbol-based methods, which aim to incorporate  interpretable symbols \cite{ashley2017artificial, surden2019artificial}, are more intriguing to legal professionals than embedding-based methods, which aim to learn text features directly \cite{zhong-etal-2020-nlp}. Some efforts are made into information extraction and legal element extraction in the legal domain \cite{truyens2014legal, vacek2019litigation, yan2017event}. But current symbol-based methods are not as effective as embedding-based methods and incorporating extracted information into prediction still needs more efforts \cite{zhong-etal-2020-nlp}.  Our neuro-symbolic method bridges this gap, by both using distributed representation of neural networks and programs.