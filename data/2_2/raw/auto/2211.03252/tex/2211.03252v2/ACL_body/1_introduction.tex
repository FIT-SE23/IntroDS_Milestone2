
\label{sec:intro}

\input{figures/teaser}

\heng{maybe also show what SOTA caption generation methods can generate for the example in Figure 1.} \chihan{Emmmmm what is its role in the paper?}

\heng{\sout{In the text you are still talking about the old example. fix it}}
Humans are capable of understanding new categories by reasoning on natural language explanations~\citep{chopra2019first, tomasello2009cultural}.
For example, in Figure \ref{fig:teaser}, we can describe sage thrashers as ``having a slim straight relatively short bill, yellow eyes and a long tail''. Then when we view a real sage thrasher the first time, we can match its visual appearance with attributes ``slim straight relatively short bill'', ``yellow eyes'' and ``long tail'', and then logically combine these results to recognize it. % This requires learners to logically understand, parse and apply the explanations.
This ability has been shown to be applicable to both visual objects and abstract concepts~\citep{tomasello2009cultural}. Compared to learning only through examples, using language information enables humans to acquire higher accuracy in less learning time~\citep{chopra2019first}.
\heng{do you have results to show the performance on abstract concepts vs. concrete concepts?}\chihan{I can claim that the ``CLUES'' experiment is about abstract concepts, and ``CUB bird classification'' involves concrete concepts. (?) But I do not have a good idea on how to compare these two...}

\input{figures/approach}

One important advantage of learning with natural language explanations is that explanations are often logical and compositional. That is, we can logically decompose the explanation of a new category into previously seen attributes (or similar ones) such as ``yellow eyes'' and ``long tail''. This enables us to reuse the knowledge on how these attributes align with visual appearances, and reduce the need for ``trial-and-error''.
Furthermore, learning with explanations provides better interpretability which makes results more trustworthy. 
% This property is of vital importance in transparency-sensitive domains, such as legal judgement, where some sort of ``rationales'' are preferred by human observers~\citep{branting2021scalable}.


Recently, there have been research efforts on using language information for zero-shot generalization. Types of such language information include human-annotated explanations or task-level instructions \citep{menon2022clues, sanh2022multitask, mishra2022cross}. However, auxiliary language information is often treated merely as additional text sequences to be fed into pre-trained language models. This approach does not fully leverage the compositional nature of natural language, and does not provide sufficient interpretable rationales for its decisions.
% \zhenhailong{\sout{This paragraph reads a little disconnected with the zero-shot classification task and our method; maybe change the order of this paragraph with the next paragraph: first talk about the task we are interested in, then introduce previous method's limitation/inspiration (this paragraph), then introduce our method?}}
% \chihan{I have trouble making a decision. @Heng can you give an advice on the ordering of this paragraph? Should we say ``previous methods were bad, so we do xxx'' or ``we do xxx, while previous methods were bad''?}



Inspired by these observations, in this work we explore classifying unseen categories by logically reasoning on their language explanations. To this end, we propose the framework of Classification by LOgical Reasoning on Explanations (\model{}). 
\model{} works in two stages: it first parses an explanation into a logical structure, and then reasons along this logical structure. Figure~\ref{fig:approach} illustrates an example of classifying sage thrashers in this way. We first encode the inputs (Figure~\ref{fig:approach} (a) $\rightarrow$ (c)) get the logical structure of explanation (Figure~\ref{fig:approach} (b) $\rightarrow$ (d)). Then we detect if the input matches attributes, and we gather the matching scores along the logical structure to output the overall classification score (Figure~\ref{fig:approach} (c),(d)$\rightarrow$(e)). In this case the logical structure consists of AND operators over three attributes.
We test the model's zero-shot capacity by letting it learn on a subset of categories, and make it categorize data from other unseen types.


We conduct a thorough set of analysis on the latest benchmark for zero-shot classifier learning with explanations, CLUES~\citep{menon2022clues}. %\zhenhailong{add citation?} 
% Our analysis shows that \model{} works better than baselines on tasks requiring higher level of compositional reasoning, which validates our model design. \model{} also demonstrates better interpretability and robustness against linguistic biases. Furthermore, as a test on generalizability of the proposed approach on other modalities, we built two new benchmarks on zero-shot classification with explanations: CUB-Explanations and ECtHR-Explanations. They are built upon the image dataset CUB-200-2011~\citep{wah2011caltech} and legal-text dataset ECtHR~\citep{chalkidis2021paragraph}, and we associate each category with a set of language explanations. \model{} consistently outperforms baseline models in zero-shot classification across modalities.
Our analysis shows that \model{} works better than baselines on tasks requiring higher level of compositional reasoning, which validates the importance of logical reasoning in \model{}. \model{} also demonstrates better interpretability and robustness against linguistic biases. Furthermore, as a test on generalizability of the proposed approach on other modalities, we built a new benchmark on visual domain: CUB-Explanations. It is built upon the image dataset CUB-200-2011~\citep{wah2011caltech}, while we associate each category with a set of language explanations. \model{} consistently outperforms baseline models in zero-shot classification across modalities.



% The rest of the paper is organized as follows:
% Section~\ref{sec:related} will list most related research areas to our work. Then we will describe our proposed approach in Section~\ref{sec:approach}. Finally in Section~\ref{sec:experiments} we will explain experiment settings and give result analysis.
To sum up, our contributions are as follows:
\begin{itemize}
    \item We propose a novel zero-shot classification framework by logically parsing and reasoning over explanations.
    % Empirical results demonstrate its superior performance than baseline models, especially on tasks that require more compositional reasoning.
    
    \item We demonstrate our model's superior performance and explainability, and empirically show that \model{} is more robust to linguistic biases and reasoning complexity than black-box baselines.
    
    % \item We demonstrate the universality of the proposed approach by building two new benchmarks, CUB-Explanations and ECtHR-Explanations. They are derived from CUB-200-2011~\citep{wah2011caltech} and ECtHR~\citep{chalkidis2021paragraph} by collecting natural language explanations for each category.

    \item We demonstrate the universality of the proposed approach by building a new benchmarks, CUB-Explanations. It is derived from CUB-200-2011~\citep{wah2011caltech} by collecting natural language explanations for each category.
    
\end{itemize}