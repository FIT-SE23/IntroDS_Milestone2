\subsection{Zero-Shot Classification Results}
\heng{\sout{really need to put in some qualitative analysis with examples. If you have them in appendix move some of them here since not everyone reads appendix}}
\heng{\sout{I still don't see which results show that your method achieves better interpretability}}

% \heng{\sout{Table 2 is out of margin, fix it}}
% \heng{\sout{What is ExEnt?}}
% \hanchi{\sout{Oh yeah. I just added this part above.}}

Zero-shot classification results are listed in Table~\ref{tab:clues_main_results}. \Model{} outperforms the baseline methods on main evaluation metrics.
To understand the effect of backbound model, we need to note that ExEnt also uses RoBERTa as the backbone model, so the \model{} and baselines do not exhibit a significant difference in basic representation abilities. The inferior performance of RoBERTa-sim compared to ExEnt highlights the complexity of the task, indicating that it demands more advanced reasoning skills than mere sentence similarity.
Furthermore, as an ablation study, \model{} outperforms \model{}-plain, which serves as initial evidence on the importance of logical structure in reasoning.
% Appendix~\ref{appsec:ablation} provides a more detailed ablation study on the effect of logical reasoning complexity.
% Note that due the the gap between CLUES-Real and CLUES-Synthetic, after pre-trained on CLUES-Synthetic some models observe a performance drop. This accords with the observation in the CLUES original paper~\citep{menon2022clues}.
% \hengzhi{\sout{consider to use subsection instead of paragraph}}
