\subsection{Classification Results}

% \paragraph{Results on CUB-Explanations}
Results are listed in Table~\ref{tab:cub_main_results} and Table~\ref{tab:ecthr_main_results}. On CUB-Explanations \model{} achieves the highest $ACC_U$ and $ACC_\textbf{H}$ both with and without pre-trained vision-language parameters.
Note that fine-tuning all parameters of CLIP makes it fit marginally better on seen classes, but sacrifices its generalization ability. Fine-tuning only the final linear layer (CLIP$_{linear}$) provides slightly better generalizability on unseen categories, but it is still lower than our approach.
On ECtHR-Explanations dataset, our model outperforms the SotA baseline Hierarchical Legal-BERT on all metrics, with gains around 1$\sim$5 percentage points.