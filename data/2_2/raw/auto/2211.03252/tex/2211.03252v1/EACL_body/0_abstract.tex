Humans can classify an unseen category by reasoning on its language explanations. This ability is owing to the compositional nature of language: we can combine previously seen concepts to describe the new category. For example, we might describe mavens as "a kind of large birds  with black feathers", so that others can use their knowledge of concepts "large birds" and "black feathers" to recognize a maven.
Inspired by this observation, in this work we tackle zero-shot classification task by logically parsing and reasoning on natural language explanations. To this end, we propose the framework \model{} (Classification by LOgical Reasoning on Explanations). While previous methods usually regard textual information as implicit features, \model{} parses the explanations into logical structure the and then reasons along this structure on the input to produce a classification score.
Experimental results on explanation-based zero-shot classification benchmarks demonstrate that \model{} is superior to baselines, mainly because it performs better on tasks requiring more logical reasoning.
Alongside classification decisions, \model{} can provide the logical parsing and reasoning process as a form of rationale.
Through empirical analysis we demonstrate that \model{} is also less affected by linguistic biases than baselines.