\subsection{Zero-Shot Classification}

\heng{\sout{Table 2 is out of margin, fix it}}
\heng{\sout{What is ExEnt?}}
\hanchi{\sout{Oh yeah. I just added this part above.}}

Zero-shot classification results are listed in Table~\ref{tab:clues_main_results}. \Model{} outperforms the baseline methods on main evaluation metrics. Appendix~\ref{appsec:ablation} also provides an ablation study on the effect of logical reasoning complexity.
% Note that due the the gap between CLUES-Real and CLUES-Synthetic, after pre-trained on CLUES-Synthetic some models observe a performance drop. This accords with the observation in the CLUES original paper~\citep{menon2022clues}.
\hengzhi{\sout{consider to use subsection instead of paragraph}}

What causes the difference in performance between \model{} and baselines? To answer this question, we investigate into how the models' performance varies with the compositionality of each task on CLUES.
Some simple explanations only describe one attribute, e.g., ``If the mushroom has a foul odor, then it is poisonous''. Other explanations describe multiple attributes to define a class, e.g., ``Travelers older than 25 years old and with an income below 1 million do not usually take travel insurance''. We define the former type of explanations as ``simple explanations'', and the latter type as ``compositional explanations''.
% We hypothesize that tasks with higher ratio of compositional explanations require more complex reasoning, 
% \heng{\sout{this point is very good, and needs to be mentioned in the intro}}
% which causes the performance difference between \model{} and ExEnt.
In Figure~\ref{fig:effect_of_complexity} we plot the classification accuracy against the proportion of compositional explanations in the explanation set for each task.
\hengzhi{\sout{Could it be a problem that \model{} performance is just stable but not increase as the ratio of compositional explanations increases?}}\hanchi{\sout{Good question. How about this explanation?}}
Intuitively, with more compositional explanations, the difficulty of the task increases, so generally we should expect a drop in performance.
Results show that, on tasks with only simple explanations (x-value == 0), both models perform similarly. However, with higher ratio of compositional explanations, \Model{}'s performance generally remains stable, but ExEnt's performance degrades. This validates our hypothesis that \model{}'s performance gain mainly benefits from its better compositional reasoning power.