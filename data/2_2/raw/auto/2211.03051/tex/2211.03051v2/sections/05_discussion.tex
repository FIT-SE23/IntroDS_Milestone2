\section{Discussion}
\label{sec:discusson}

We observed that having a small number (ten) of perceptrons in the hidden layers reduced the loss gap at the cost of overall learning capability. Through our experiments we found that 80 perceptrons in each layer produced the best accuracy on the validation set (Table \ref{tab:results}). The training of this model and another 80-perceptron model is shown in Figure \ref{fig:losses}. The potential for higher accuracy with the drawback of faster overfitting was observed in the models with a larger number of perceptrons, as expected. The inverse was seen in the models with less perceptrons.

\begin{figure}[t]
    \begin{center}
    % \fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
    % \subcaption[Caption hehe]{\includegraphics[width=1\linewidth]{losses_20_8.png}\label{fig:first_sub}}
    \subcaption[]{\includegraphics[width=1\linewidth]{losses_80_5.png}\label{fig:first_sub}}
    \subcaption[]{\includegraphics[width=1\linewidth]{losses_80_7.png}\label{fig:second_sub}}
    \end{center}
        \caption{Visualisation of the train \& validation loss (blue \& orange) with the train \& validation accuracy (green \& red) of a model containing 80 perceptrons in each hidden layer. Both graphs show relatively steady trends for train accuracy and train loss. It is apparent that \ref{fig:first_sub} achieved good generalisation and that there is good convergence of the losses over 500 epochs, although slight divergence is starting to be seen toward the end. \ref{fig:second_sub} has same architecture but is a different instance, showing earlier convergence and again achieving over 80\% validation accuracy, however clear overfitting can be seen starting at epoch 250.}
\label{fig:losses}
\end{figure}

The average integrated gradients of each experiment were very similar between models with different hidden layer sizes. Further experimentation with different data splitting techniques, preferably k-fold cross validation, would provide insight to whether these attributions are reflective of the behaviours in a general sense or whether they are different each time the training set changes. Furthermore, investigation into whether consistent attributions correlate with validation accuracy would provide meaningful insight into the usefulness of this technique overall.