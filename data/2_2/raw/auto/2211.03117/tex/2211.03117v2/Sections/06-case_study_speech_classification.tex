\section{JingleBack Design}
\label{sec:speech}

% In this section, we present our Style Backdoor in speech classification. We introduce each transformation we used in~\Cref{ssec:sound-style-gen}, we describe our experimental setup in~\Cref{ssec:sound-setup} and finally discuss our experimental results in~\Cref{ssec:sound-results}.

\subsection{Stylistic Generation}
\label{ssec:sound-style-gen}
% \todo{Mention why we chose all these styles. We wanted something simple that is widely known and easily made in real life through pedalboards}
% General notes in https://sound.eti.pg.gda.pl/student/eim/synteza/adamx/eindex.html
This work focuses on backdoors in the audio domain aiming into an easy-to-deploy attack. Thus, we investigate if such an attack can be implemented through simple digital music effects like chorus or gain. 
% We thus need to find stylistic triggers that are easy to generate, such as music effects like gain or chorus.
We used Spotify's pedalboard~\footnote{\url{https://github.com/spotify/pedalboard}} to implement six styles by combining effects like PitchShift, Distortion, Chorus, Reverb, Gain, Ladderfilter, and Phaser. We explain the adopted styles briefly.

\textbf{PitchShift.} It increases the pitch of the original audio by a number of semitones without affecting its duration. The pitch is the lowest frequency $f_0$ of a signal $S$~\cite[p.~xv]{music-in-theory-and-practice}. A semitone $sem$ is the smallest musical interval used in music denoting a different tone. PitchShift can be defined as:
%is described with the following equation in a high-level way:\todo{what is a high level way?}
\begin{equation}
\label{eq:pitchshift}
    PitchShift(S(f_0), sem) = S(f_0\cdot e^{sem/12}).
\end{equation}

\textbf{Distortion.} It applies a distortion with a $tanh()$ waveshaper. $\beta$ controls the signal's amplitude increase. 
%Its functionality is shown in Eq.~\eqref{eq:distortion}:
\begin{equation}
\label{eq:distortion}
    Distortion(S(t), \beta) = \beta \cdot tanh(S(t)).
\end{equation}

\textbf{Chorus.} It imitates a group of musicians that play the same sound
by superimposing many versions of the same sound that are slightly out of time and tune. Pedalboard's chorus uses one unsynchronized version with the provided delay $d$. 
In the following equation, $\alpha$ controls chorus amplitude.
% A more formal definition of this effect is shown in Eq.~\eqref{eq:chorus}, where $\alpha$ controls the chorus' amplitude.
\begin{equation}
\label{eq:chorus}
   Chorus(S(t), d, \alpha) = S(t) + \alpha \cdot S(t - d).
\end{equation}

% https://www.sciencedirect.com/science/article/pii/0022460X71903920
% http://www.music.mcgill.ca/~gary/courses/papers/Moorer-Reverb-CMJ-1979.pdf

\textbf{Reverberation.} It imitates the reflection of reproduced sound on various surfaces. 
% It results in the persistence of a sound in a room, even after the sound is not played anymore. 
% Usually, this sound decays fast, but its exact time depends on the environmental properties. 
Spotify's pedalboard is based on FreeVerb\footnote{\url{https://ccrma.stanford.edu/~jos/pasp/Freeverb.html}}, which uses eight parallel Schroeder-Moorer filtered-feedback comb-filters that create eight delayed versions of the input signal that are added and fed into four Schroeder all-pass filters in series. This relation is described in Eq.~\eqref{eq:reverb}, where $AP_{1-4}$ is the combined effect of the four cascaded all-pass filters and $CF_{i}$ is the $i^{th}$ comb-filter.
% This info was also verified from ./modules/juce_audio_basics/utilities/juce_Reverb.h
\begin{equation}
\label{eq:reverb}
    Reverb(S(t)) = AP_{1-4}[\sum_{i=1}^{8}CF_{i}(S(t))].
\end{equation}

\textbf{Gain.} 
It changes the signal amplitude by a factor $G$. 
%This effect is formally described in Eq.~\eqref{eq:gain}, where $G$ is the amount of change applied:
\begin{equation}
\label{eq:gain}
    Gain(S(t), G) = G\cdot S(t).
\end{equation}


% Maybe mention something about the 12db/octave fromhttps://reverb.com/news/a-guide-to-synth-filter-types-ladders-steiner-parkers-and-more
% Check the following for more info:
% https://api.moogmusic.com/sites/default/files/2018-06/MF_101_Manual.pdf
% http://sdiy.org/destrukto/notes/moog_ladder_tf.pdf
% Nice formulas about the transfer function of ladder filter: http://sdiy.org/destrukto/notes/moog_ladder_tf.pdf , https://www.dafx.de/paper-archive/2020/proceedings/papers/DAFx2020_paper_70.pdf , https://ieeexplore-ieee-org.tudelft.idm.oclc.org/stamp/stamp.jsp?tp=&arnumber=1162522 , https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6892946
% blog posts: https://www.uaudio.com/blog/moog-multimode-filter-design/ , https://reverb.com/news/a-guide-to-synth-filter-types-ladders-steiner-parkers-and-more
% General notes about the filters https://www.infineon.com/dgdl/Infineon-LPF4V_001-56219-Software%20Module%20Datasheets-v02_01-EN.pdf?fileId=8ac78c8c7d0d8da4017d0f97c58b06c6

\textbf{Ladder.} Spotify pedalboard implements a Moog Ladder filter $L(\cdot)$~\cite{moog-ladder-filter}. In our experiment, we use the \textit{high-pass} version as it had a clear effect on our samples.  
% The pedalboard implementation relies on a digital filter based on the Moog filter $L(\cdot)$~\cite{moog-ladder-filter}, and it supports three different operating modes (high-pass, low-pass, and band-pass). 
% In each of these modes, the filter blocks a different set of frequencies.
% Our experiments used a high-pass filter as it had a clear effect on our samples compared to other types of filters. 
% We used a high-pass filter that blocks all frequencies up to the cutoff frequency because its effect on the original audio was slightly more clear compared to the effect that other filters had.
% As its frequency response is not perfectly linear, it can introduce some distortion to the original signal. However, in our experiments, we could not observe any distortions, only a different sound pitch. 
%We model its functionality as shown in Eq.~\eqref{eq:ladder}, where 
\begin{equation}
\label{eq:ladder}
    Ladder(S(t)) = \alpha \cdot L(S(t)).
\end{equation}

\textbf{Phaser.} It is based on special filters that can change the frequencies they block over time through a low-frequency oscillator $P$. The phaser superimposes the original signal with its altered version. 
This results in a soft-moving sound. % that is very popular in the music industry.
% A simplified mathematical model of this effect is shown in Eq.~\eqref{eq:phaser}. 
In the following equation, $\alpha$ controls the effect's intensity.
% rate makes the sweep faster, depth makes the effect more intense, and resonance (maybe center frequency)  emphasizes certain tones in the sweep.
\begin{equation}
\label{eq:phaser}
    Phaser(S(t)) = S(t) + \alpha \cdot P(t, S(t)).
\end{equation}



%Our first style simply increases the pitch of the original audio by ten semitones without affecting its duration. The pitch is the lowest frequency of a signal which is often perceived as the loudest too~\cite[p.~xv]{music-in-theory-and-practice}. A semitone is the smallest musical interval used in music denoting a different tone.
%\begin{equation}
%\label{eq:pitchshift}
%    PitchShift(S(f_0), sem) = S(f_0\cdot e^{sem/12}) 
%\end{equation}
%
%Our first style uses chorus, distortion, and reverb. In general, the chorus effect imitates a group of musicians that play the same sound. Even though they are mostly synchronized, this synchronization is rarely perfect. Thus, the chorus audio effect superimposes many versions of the same sound that are slightly out of time and tune. Pedalboard's chorus uses only one unsynchronized version with a delay of 15$ms$. A more formal definition of this effect is shown in Equation~\eqref{eq:chorus}, where $\alpha$ controls the chorus' amplitude, and it is equal to 0.25 in our case.
%
%\begin{equation}
%\label{eq:chorus}
%   Chorus(S(t)) = S(t) + \alpha \cdot S(t - 15ms).
%\end{equation}
%
%The distortion effect applies a soft distortion with a $tanh()$ waveshaper. In our case, a variable also controls the signal's amplitude increase. Its functionality is shown in Equation~\eqref{eq:distortion}:
%\begin{equation}
%\label{eq:distortion}
%    Distortion(S(t)) = \beta \cdot tanh(S(t)).
%\end{equation}
%
%% https://www.sciencedirect.com/science/article/pii/0022460X71903920
%% http://www.music.mcgill.ca/~gary/courses/papers/Moorer-Reverb-CMJ-1979.pdf
%Reverberation is created from the reflection of reproduced sound on various surfaces. It results in the persistence of a sound in a room, even after the sound is not played anymore. Usually, this sound decays fast, but its exact time depends on the environmental properties. Pedalboard's reverb applies this effect to the original input signal. The reverb generated by Spotify's pedalboard module is based on FreeVerb~\footnote{\url{https://ccrma.stanford.edu/~jos/pasp/Freeverb.html}}, which uses eight parallel Schroeder-Moorer filtered-feedback comb-filters that create eight delayed versions of the input signal that are added and fed into four Schroeder all-pass filters in series. This relation is described more formally in Equation~\eqref{eq:reverb}, where $AP_{1-4}$ is the effect of the four cascaded all-pass filters and $CF_{i}$ is the $i^{th}$ comb-filter.
%
%% This info was also verified from ./modules/juce_audio_basics/utilities/juce_Reverb.h
%\begin{equation}
%\label{eq:reverb}
%    Reverb(S(t)) = AP_{1-4}[\sum_{i=1}^{8}CF_{i}(S(t))].
%\end{equation}
%
%The total effect, in that case, is shown in Equation~\eqref{eq:sound-style1}:
%\begin{equation}
%\label{eq:sound-style1}
%    Style1(S(t)) = Reverb(Distortion(Chorus(S(t)))).
%\end{equation}
%
%For our second style, we used the following effects: gain, a ladder filter, and a phaser. The gain effect changes the amplitude of the input signal. This effect is formally described in Equation~\eqref{eq:gain}, where $G$ is the amount of change applied:
%\begin{equation}
%\label{eq:gain}
%    Gain(S(t)) = G\cdot S(t).
%\end{equation}
%
%% Maybe mention something about the 12db/octave fromhttps://reverb.com/news/a-guide-to-synth-filter-types-ladders-steiner-parkers-and-more
%% Check the following for more info:
%% https://api.moogmusic.com/sites/default/files/2018-06/MF_101_Manual.pdf
%% http://sdiy.org/destrukto/notes/moog_ladder_tf.pdf
%% Nice formulas about the transfer function of ladder filter: http://sdiy.org/destrukto/notes/moog_ladder_tf.pdf , https://www.dafx.de/paper-archive/2020/proceedings/papers/DAFx2020_paper_70.pdf , https://ieeexplore-ieee-org.tudelft.idm.oclc.org/stamp/stamp.jsp?tp=&arnumber=1162522 , https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6892946
%% blog posts: https://www.uaudio.com/blog/moog-multimode-filter-design/ , https://reverb.com/news/a-guide-to-synth-filter-types-ladders-steiner-parkers-and-more
%% General notes about the filters https://www.infineon.com/dgdl/Infineon-LPF4V_001-56219-Software%20Module%20Datasheets-v02_01-EN.pdf?fileId=8ac78c8c7d0d8da4017d0f97c58b06c6
%The ladder filter used in pedalboard is a digital filter based on the Moog filter~\cite{moog-ladder-filter}, and it supports three different operating modes (high-pass, low-pass, and band-pass). In each of these modes, the filter blocks a different set of frequencies. We used a high-pass filter that blocks all frequencies up to the cutoff frequency because its effect was slightly more clear compared to the others. \todo{what does this mean?}
%As its frequency response is not perfectly linear, it can introduce some distortion to the original signal. However, in our experiments, we could not observe any distortions, only a different sound pitch. We model its functionality as shown in Equation~\eqref{eq:ladder}, where 
%\begin{equation}
%\label{eq:ladder}
%    Ladder(S(t)) = \alpha \cdot L(S(t)).
%\end{equation}
%
%The phaser is based on special filters that can change the frequencies they block over time through a low-frequency oscillator. The phaser superimposes the original signal with its altered version. This results in a soft moving sound that is very popular in the music industry. A simplified mathematical model of this effect is shown in Equation~\eqref{eq:phaser}. In this equation, $\alpha$ controls the effect's intensity, and $P$ is also a function of $t$ as it changes over time.
%
%% rate makes the sweep faster, depth makes the effect more intense, and resonance (maybe center frequency)  emphasizes certain tones in the sweep.
%
%\begin{equation}
%\label{eq:phaser}
%    Phaser(S(t)) = S(t) + \alpha \cdot P(t, S(t)).
%\end{equation}
%
%In total, the second style is shown in Equation~\eqref{eq:sound-style2}:
%\begin{equation}
%\label{eq:sound-style2}
%    Style2(S(t)) = Phaser(Ladder(Gain(S(t)))).
%\end{equation}

\subsection{Experimental Settings}
\label{ssec:sound-setup}

\textbf{Dataset and Features.} 
Experiments are conducted on Google's Speech Commands dataset~\cite{speech-commands-dataset}. This is an audio dataset targeting keyword spotting tasks, and its data belong to one of 30 classes (``yes'', ``no'', ``up'', ``down'', etc.) 
%This dataset consists of 64\,724 short audio clips of spoken keywords. However, we discarded the files that lasted less than one second to avoid having inputs with variable size, resulting in 58\,252 audio clips. 
We used the Mel-frequency cepstral coefficients (MFCCs) as input features because they are rather accurate in emulating the human vocal system and widely used~\cite{can-you-hear-it}.
We use common settings described in the literature~\cite{generalized-end-to-end-loss-for-speaker-verification}, i.e., 40-mel bands, a step of 10ms, and a window length of 25ms.

%Increasing room size increases the reverbation time.
\textbf{Backdoor.} 
We split our data into training, validation, and test sets in a 64/16/20 way. For our backdoor, we poisoned up to 1\% of the training data and used two backdoor settings: clean and dirty label attacks.
We chose the class ``yes'' as the backdoor class without loss of generality since we expect similar behavior regardless of the target class.
%Thus, in the clean-label we poison only samples that belong in this class, while for the dirty label we poison samples from every class and we change their label to ``yes''. 
Triggers are generated with the six styles as previously described. Style parameters are shown in~\Cref{tab:styles}. 
Parameters are selected to limit sample distortion and preserve their quality.
% Parameters are chosen by the authors to guarantee limited .\todo{explain}

\begin{table}[h]
    \centering
    \caption{Stylistic triggers deployed in our experiments.}
    \label{tab:styles}
    \resizebox{0.35\textwidth}{!}{%
        \begin{tabular}{c|c}
        \toprule
        \textbf{Style} & \textbf{Effect} \\ \toprule
        0 & $PitchShift(S, 10)$ \\ \hline
        1 & $Distortion(S, 30dB)$ \\ \hline
        2 & $Chorus(S, 10ms, 5)$ \\ \hline
        3 & $Chorus(Distortion(PitchShift(S, 10), 20dB), 8ms, 5)$ \\ \hline
        4 & $Reverb(Distortion(Chorus(S, 15ms, 0.25), 20dB))$ \\ \hline
        5 & $Phaser(Ladder(Gain(S, 12dB)))$ \\ \bottomrule
        \end{tabular}
    }
\end{table}

\textbf{Models.} We used three different models, two CNNs (one small and one large) and one LSTM as described in~\cite{can-you-hear-it}. We repeated each of our experiments four times to limit the effects of randomness. 
The three models are trained for a maximum of 300 epochs.
We used an early stopping with a patience of 20 epochs based on the validation loss.
In total, by considering stylistic triggers (6), backdoor settings (2), models (3), poisoning rates (3), and repetitions (4), 432 poisoned models are trained. We also trained 12 clean models (4 repetitions for each model) to use as a reference when investigating the backdoor's effect on the original task.

\section{Experimental Results}
\label{ssec:sound-results}

\subsection{Effect on Clean Accuracy}
% The backdoor attack's objective is to insert a secret functionality into a victim's models while preserving their overall performance on unpoisoned data. 
We first verify that the backdoored models have comparable performance to their clean versions.
Clean models show, on average, high performance (expressed as F1-score): large CNN $93.8\pm0.2$, small CNN $87.2\pm0.3$, and LSTM $90.8\pm1.1$.
We notice that our attack is stealthy since we observed only a small drop in the performance of the backdoored models.
On average, models drop $0.24\pm0.9$ pp (points percentage) in the F1-score, while the worst model drops 4.87 pp.
Among the 432 poisoned models, the performance drop is $>2$ pp in 23 cases and decreases to 10 cases when $>3$ pp.
% Backdoor attacks poison victims' model by injection malicious samples at training time. 
% Before testing triggers effectiveness, we need to prove that the overall poisoned model's performance under legitimate testing samples preserve 

% \subsection{Degradation}
% In this section, we will discuss the results of our stylistic backdoor attack for speech classification. First, we have to verify that the backdoor is not affecting the original task. If the model's performance is affected by the backdoor, the user would become suspicious and stop using the poisoned model. For that reason, we plot the weighted F1 score (multiclass classification) of our models (poisoned and clean) in Figure~\ref{fig:sound-f1}. From that figure, we see that the performance of our models remains unaffected after the backdoor insertion. The number of poisoned samples used is very small (up to 2\%) and is not enough to affect the original task. From this figure, we also see that all the models perform similarly for the original task. 
% \todo{Maybe this is not a good metric as I poisoned many samples from only one class. I should check how the classification of that class is affected.}

% \begin{figure}[ht]
%     \centering
%     \begin{subfigure}[b]{0.40\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{Figures/sound/f1_score_clean-label.pdf}
%         \caption{Clean-label}
%         \label{fig:f1-clean-label}
%     \end{subfigure}
%     \hfill \\
%     \begin{subfigure}[b]{0.40\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{Figures/sound/f1_score_dirty-label.pdf}
%         \caption{Dirty-label}
%         \label{fig:f1-dirty-label}
%     \end{subfigure}
%     \caption{Models overall performance (F1-score) at the varying of the training poisoning ratio for speech classification. By averaging over the different styles we see that the original task is not affected by the backdoor insertion.}
%     \label{fig:f1}
% \end{figure}

\subsection{Evasion}
Cao et al.~\cite{stylefool} investigated the effect of stylistic transformation as an evasion attack for computer vision applications. 
We thus aim to investigate this effect in the audio domain.
% An interesting side-effect of the stylistic trigger is the generation of adversarial samples that are out-of-distribution, and, as a consequence, they might evade victim's unpoisoned models.
% Cao et al.~\cite{stylefool} recently investigated this phenomenon in the computer-vision domain.
% We thus aim to understand if our acoustic stylistic triggers can result in an untargeted evasion attack. 
We compute the misclassification percentage of unpoisoned models under malicious settings. 
Table~\ref{tab:evasion} shows the average evasion percentage at the varying of the model and style. 
We can notice that in seven out of 18 cases, our acoustic transformation produces an evasion rate $>70.0\%$. We thus affirm that stylistic transformation can produce strong evasion attacks.

\begin{table}[!htpb]
\centering
\caption{Average evasion [\%] at the varying of the model architecture and style. In bold, the best results.}
\resizebox{0.30\textwidth}{!}{%
\begin{tabular}{c|ccc} \toprule
\textbf{Style} & \textbf{Large-CNN} & \textbf{Small-CNN} & \textbf{LSTM} \\ \toprule
0 & \res{\textbf{81.2}}{1.7} & \res{\textbf{76.6}}{0.9} &\res{\textbf{85.8}}{2.0}  \\
1 & \res{31.0}{1.5} & \res{49.1}{1.5} &\res{42.7}{7.0}  \\
2 & \res{15.8}{0.9} & \res{24.4}{1.4} &\res{17.9}{1.2} \\
3 & \res{\textbf{84.2}}{1.0} & \res{\textbf{83.2}}{0.7} &\res{\textbf{86.1}}{2.3} \\
4 & \res{28.5}{1.1} & \res{45.4}{1.0} &\res{41.3}{3.3} \\ 
5 & \res{42.8}{2.4} & \res{\textbf{70.2}}{2.4} &\res{50.7}{6.7} \\\bottomrule
\end{tabular}
}
\label{tab:evasion}
\end{table}


\subsection{Backdoor}
We finally analyze the performance of our proposed stylistic backdoor under clean-label and dirty-label settings. \Cref{fig:asr} shows the results. The y-axis shows the attack success rate (ASR), which represents the percentage of successfully triggered backdoors over a number of tries, and the x-axis shows the poisoning rate, which is the percentage of the poisoned training samples used for our attack.
\begin{figure}[!htpb]
    \centering
    \includegraphics[width = \linewidth]{Figures/backdoor2.pdf}
    \caption{Backdoor attack success rate.}
    \label{fig:asr}
\end{figure}
Our results are in line with the literature~\cite{can-you-hear-it, clean-label-backdoor-attacks}.
For instance, the higher the poisoning rate, the higher the ASR because the poisoned models have more samples to learn the trigger~\cite{can-you-hear-it}.
Additionally, the dirty-label attack is more effective as it almost always results in higher ASR than the clean-label attack, as shown in~\cite{clean-label-backdoor-attacks}.
In particular, dirty-label attacks include cases in which even a small poisoning rate ($0.1\%$) is effective (ASR $>50\%$): examples are style 2 on Large-CNN, style 3 in Large-CNN, and style 5 in both Large-CNN and Small-CNN.
Furthermore, Large-CNN -- the most performing model on average -- is the most vulnerable, showing that backdoor effectiveness is connected to the model's ability to learn. 
\par
Generally, we can notice that styles have different effects (e.g., style 3 is always more effective than style 1), leading to the following observations.
(i) The clean-label attack is effective only with styles 3 and 5. 
(ii) Dirty label attack shows appreciable performance in all cases. 
(iii) The addition of effects does not always result in a performance boost (e.g., style 0 outperforms style 4 in clean-label settings). 
\par
We explain our observations with the following considerations. 
In the dirty-label attack, the poisoned samples are generally very different from the samples of the target class as they originally belonged to different classes. As a result, the distance between these samples in the feature space is large and easy to learn by our models, even by applying simple effects to them. However, in the clean-label attack, the poisoned samples belong to the target class, and there is a higher probability that their features are not very different from the clean samples. For that reason, the dirty label attack is more effective than the clean-label attack, which explains (i) and (ii). We believe that adding more effects is not the best way to create distinguishable triggers because what is most important is to change the signal's representation in the feature space. For that reason, a simpler transformation that alters the frequency representation of the original signal, like $PitchShift$ may result in a larger difference in the MFCCs as they use Fourier transform internally. This explains (iii). 

%In the clean label scenario the attacker needs to spend more time designing the triggers. As we poison only samples from the original class.



% Interestingly, style 3 -- the combination of styles 0, 1, and 2 -- results in strong dirty and clean label attacks. \todo{why}
% The results further suggest that triggers have different effects, e.g., style 3 is always more effective than style 1. 
% The clean-label attack is effective with styles 3 and 5. 
% Furthermore, the addition of effects does not always result in a performance boost (e.g, style 0 outperforms style 4 in clean-label settings). 
% Interestingly, style 3 -- the combination of styles 0, 1, and 2 -- results in strong dirty and clean label attacks. \todo{why}
\par
% The results further suggest that trigger styles are effective in different ways. (e.g., style 3 is always more effective than style 1). \todo{why?}
% For the clean-label attack, the ASR is very low for styles 0, 1, 2, and 4.
% However, we see that just a simple transformation like $PitchShift$ (style 0) performs better than a style with multiple transformations (style 4). 
% This indicates that even simple styles that affect the frequency representation of the signals like style 0 ($PitchShift$) could result in a more effective attack than more complex styles like style 4 ($Chorus$, $Distortion$, and $Reverb$). 
% \todo{luca: not clear the following sentence}
% This behavior needs further investigation because, for the dirty label attack, we see a different behavior. Styles 4 and 0 yield the same ASR even though style 0 performs far better in the clean label attack.\todo{unclear}
% Styles 3 and 5 are the most successful. They confirm that a style-based backdoor can be implemented in both attack scenarios by combining a handful of simple transformations. In both these styles, the frequency domain representation of the signal is affected indicating that this may be good practice for attackers. However, further investigation is required to find the most important characteristics of a style.

% \todo{vague conclusions. whatever we conclude, we also say further investigation is needed. But what is the point of this paper then?}

%                     |  clean label   | dirty label
%Pitchshift(S, 10)    | up to 26\%     | up to 70\%|
%Distortion(S, 30db)  | up to 13\%     | up to 60\%|
%Chorus(S, 10ms, 5)   | up to 10\%     | up to 86\%| 
%
%Chor(Dist(Pitch(S, 10), 20dB), 8ms, 5) | up to 84\% | up to 94\% |
%Reverb(Dist(Chor(S, 15ms, 0.25), 20dB))| up to 3\%  | up to 71\% |
%Phaser(Ladder(Gain(S, 12dB)))          | up to 58\% | up to 96\% |

%The results further suggest that trigger styles are effective in different ways. (e.g., style 3 is always more effective than style 1). \todo{why?}
%This effect is highlighted in \textit{clean-label} settings, where our attack is not always effective (e.g., styles 2 and 4). For the clean-label attack, the ASR is very low for styles 0, 1, 2, and 4. However, we see that just a simple transformation like $PitchShift$ (style 0) performs better than a style with multiple transformations (style 4). 
%Style 0 increases the pitch of the original audio, which has a clear effect on its frequency domain representation. This indicates that our models may identify these differences because the calculation of the MFCCs uses the signal's Fourier transform internally. On the other hand, style 4 uses $Reverb$, $Distortion$, and $Chorus$, which do not impact the signal's frequency domain representation.
%However
%\todo{And why for dirty label this style is not the best??? Shouldn't be the case for the dirty label too?}
%Thus, we conclude that for the clean-label setup, the adversary should choose effects that manipulate the signal's frequency domain representation. However, just a slight variation in the frequency is not enough to produce effective attacks in both setups.
%For this reason, we need to amplify its influence with additional effects. Styles 3 and 5 are the best-performing ones for both clean and dirty label attacks. In style 3, we see that in the clean-label attack, simple ineffective effects could result in powerful attacks when combined together. Applying $Distortion$ and $Chorus$ after the $PitchShift$ makes the signal even more distinguishable and easier to learn from the models. Similarly, in style 5, the high-pass $LadderFilter's$ effects are amplified from the other two effects.
%
%However, we see that the styles may cause some inconsistencies in the attack behavior for the different setups. For example, the dirty-label setup style 2 is clearly more effective than style 0. However, the opposite is true in the clean label attack.


% A combination of different effects that may not be very successful could multiply the effectiveness of the attack. S

% Style 3 and 5 perform similarly well for the dirty label. Both of them change the frequency representation of the signals. However, in the clean-label case we see a large difference in the performance. Why?
% We see also similar discrepancies between the clean and the dirty label attack in styles 0 and 2. Style 2 is more effective than style 0 in the dirty label setup but the opposite happens in the clean-label setup. Why?
% also the worst performing attack in the clean-label setup (style 4) is not also the worst for the dirty-label attack.

%Inconsistencies between clean and dirty label attacks, as the best style for dirty label is style5, and the best for clean label is style 3.
%Even simple styles like style2 that contain only simple transformations ($Chorus$) can be very effective 
%         0  PitchShift(S, 10) -> works a little for (clean-label)
%         1  Distortion(S, 30dB) -> does not work
%         2  Chorus(S, 10ms, 5)
%         3  Chorus(Distortion(PitchShift(S, 10), 20dB), 8ms, 5)
%         4  Reverb(Distortion(Chorus(S, 15ms, 0.25), 20dB))
%         5  Phaser(Ladder(Gain(S, 12dB)))

%%% STEFANOS' version
% In both setups and almost all cases we see that higher poisoning rates result in higher ASRs. This is expected as our models can detect the style properties if there are more poisoned training samples. However, we see that the dirty label attack is more effective. This is expected, because as stated in~\cite{clean-label-backdoor-attacks}, the clean-label approach renders the attack less effective and more challenging. 

% Additionally we see that the ASR is higher for the large CNN which is our best performing model. This shows that the backdoor's effectiveness is clearly connected to the model's ability to learn. Thus, we can claim that complex models are more vulnerable to backdoor attacks because they have a larger learning capability.

%\todo{This is our first attempt to explain the results. We wanted to go a little more in depth about the reasons behind the behavior of different styles. We will re-write it but skim through it to get an idea.}
%In the left column of~\cref{fig:asr} (clean-label attack), we see that the ASR highly depends on the style. The first three styles use only simple effects, rendering the attack ineffective. However, we see that style 0 is the most effective among these three, yielding an ASR of around 20\% for 1\% poisoned data. Style 3 is just the combination of the first three styles, but we see a significant improvement in the ASR resulting in more than 80\% for the large CNN and 1\% poisoning rate. This shows that the combination of simple ineffective sound effects could result in a very strong and reliable attack. \todo{why}However, not all complex styles are effective as a trigger. Style 4 uses three simple effects ($Chorus$, $Distortion$, and $Reverb$) but the ASR remains extremely low\todo{why?}. Additionally, Style  5 uses also three effects ($Gain$, $LadderFilter$, and $Phaser$) but the ASR cannot overpass 60\%, even with a 1\% poisoning rate. 
%\todo{nothing is explained after this ``explanation''}
