@inproceedings{evasion2004,
author = {Dalvi, Nilesh and Domingos, Pedro and Mausam and Sanghai, Sumit and Verma, Deepak},
title = {Adversarial Classification},
year = {2004},
isbn = {1581138881},
publisher = {Association for Computing Machinery},
booktitle = {Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {99–108},
numpages = {10},
keywords = {naive Bayes, spam detection, cost-sensitive learning, game theory, integer linear programming},
}

@misc{fgsm,
  url = {https://arxiv.org/abs/1702.02284},
  author = {Huang, Sandy and Papernot, Nicolas and Goodfellow, Ian and Duan, Yan and Abbeel, Pieter},
  title = {Adversarial Attacks on Neural Network Policies},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{biggio2013evasion,
  title={Evasion attacks against machine learning at test time},
  author={Biggio, Battista and Corona, Igino and Maiorca, Davide and Nelson, Blaine and {\v{S}}rndi{\'c}, Nedim and Laskov, Pavel and Giacinto, Giorgio and Roli, Fabio},
  booktitle={Joint European conference on machine learning and knowledge discovery in databases},
  pages={387--402},
  year={2013},
  organization={Springer}
}

@inproceedings{text_adv,
author = {Liang, Bin and Li, Hongcheng and Su, Miaoqiang and Bian, Pan and Li, Xirong and Shi, Wenchang},
title = {Deep Text Classification Can Be Fooled},
year = {2018},
publisher = {AAAI Press},
booktitle = {Proceedings of the 27th International Joint Conference on Artificial Intelligence},
pages = {4208–4215},
numpages = {8},
location = {Stockholm, Sweden},
series = {IJCAI'18}
}

@inproceedings{all_you_need,
    author = {Gr\"{o}ndahl, Tommi and Pajola, Luca and Juuti, Mika and Conti, Mauro and Asokan, N.},
    title = {All You Need is "Love": Evading Hate Speech Detection},
    year = {2018},
    isbn = {9781450360043},
    booktitle={Proceedings of the 11th ACM workshop on artificial intelligence and security},
    publisher = {Association for Computing Machinery},
    pages = {2–12},
    numpages = {11}
}

@INPROCEEDINGS{stealthy_porn,  
author={Yuan, Kan and Tang, Di and Liao, Xiaojing and Wang, XiaoFeng and Feng, Xuan and Chen, Yi and Sun, Menghan and Lu, Haoran and Zhang, Kehuan},  booktitle={2019 IEEE Symposium on Security and Privacy (SP)},   title={Stealthy Porn: Understanding Real-World Adversarial Images for Illicit Online Promotion},   year={2019},  volume={},  number={},  pages={952-966},  doi={10.1109/SP.2019.00032}
}

@ARTICLE{evasion_malware,  
author={Li, Deqiang and Li, Qianmu},  journal={IEEE Transactions on Information Forensics and Security},   title={Adversarial Deep Ensemble: Evasion Attacks and Defenses for Malware Detection},   year={2020},  volume={15},  number={},  pages={3886-3900},  doi={10.1109/TIFS.2020.3003571}}

@inproceedings{barreno2006can,
  title={Can machine learning be secure?},
  author={Barreno, Marco and Nelson, Blaine and Sears, Russell and Joseph, Anthony D and Tygar, J Doug},
  booktitle={Proceedings of the ACM Symposium on Information, computer and communications security},
  pages={16--25},
  year={2006}
}

@article{barreno2010security,
  title={The security of machine learning},
  author={Barreno, Marco and Nelson, Blaine and Joseph, Anthony D and Tygar, J Doug},
  journal={Machine Learning},
  volume={81},
  number={2},
  pages={121--148},
  year={2010},
  publisher={Springer}
}

@inproceedings{biggio_poisoning,
author = {Biggio, Battista and Nelson, Blaine and Laskov, Pavel},
title = {Poisoning Attacks against Support Vector Machines},
year = {2012},
booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
pages = {1467–1474},
numpages = {8}
}

@article{gu2017badnets,
  title={Badnets: Identifying vulnerabilities in the machine learning model supply chain},
  author={Gu, Tianyu and Dolan-Gavitt, Brendan and Garg, Siddharth},
  journal={arXiv preprint arXiv:1708.06733},
  year={2017}
}

@inproceedings{
geirhos2018imagenettrained,
title={ImageNet-trained {CNN}s are biased towards texture; increasing shape bias improves accuracy and robustness.},
author={Robert Geirhos and Patricia Rubisch and Claudio Michaelis and Matthias Bethge and Felix A. Wichmann and Wieland Brendel},
booktitle={International Conference on Learning Representations},
year={2019}
}

@misc{style_transfer,
  author = {Gatys, Leon A. and Ecker, Alexander S. and Bethge, Matthias},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), Neurons and Cognition (q-bio.NC), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Biological sciences, FOS: Biological sciences},
  title = {A Neural Algorithm of Artistic Style},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{style_transfer2,
  title={Image style transfer using convolutional neural networks},
  author={Gatys, Leon A and Ecker, Alexander S and Bethge, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2414--2423},
  year={2016}
}

@inproceedings{vgg,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  booktitle = {3rd International Conference on Learning Representations},
  year      = {2015}
}

@InProceedings{Wu_2017_CVPR_Workshops,
author = {Wu, Bichen and Iandola, Forrest and Jin, Peter H. and Keutzer, Kurt},
title = {SqueezeDet: Unified, Small, Low Power Fully Convolutional Neural Networks for Real-Time Object Detection for Autonomous Driving},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
month = {July},
year = {2017}
}

@article{dilsizian2014artificial,
  title={Artificial intelligence in medicine and cardiac imaging: harnessing big data and advanced computing to provide personalized medical diagnosis and treatment},
  author={Dilsizian, Steven E and Siegel, Eliot L},
  journal={Current cardiology reports},
  volume={16},
  number={1},
  pages={1--8},
  year={2014},
  publisher={Springer}
}

@inproceedings{moog-ladder-filter,
  title={A voltage-controlled low-pass high-pass filter for audio signal processing},
  author={Moog, Robert A},
  booktitle={Audio Engineering Society Convention 17},
  year={1965},
  organization={Audio Engineering Society}
}

@inproceedings{can-you-hear-it,
    author = {Koffas, Stefanos and Xu, Jing and Conti, Mauro and Picek, Stjepan},
    title = {Can You Hear It? Backdoor Attacks via Ultrasonic Triggers},
    year = {2022},
    publisher = {Association for Computing Machinery},
    booktitle = {Proceedings of the 2022 ACM Workshop on Wireless Security and Machine Learning},
    pages = {57–62},
    numpages = {6}
}

@article{speech-commands-dataset,
  author    = {Pete Warden},
  title     = {Speech Commands: {A} Dataset for Limited-Vocabulary Speech Recognition},
  journal   = {CoRR},
  volume    = {abs/1804.03209},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.03209},
  archivePrefix = {arXiv},
}  eprint    = {1804.03209},
  timestamp = {Mon, 13 Aug 2018 16:48:32 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1804-03209.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{generalized-end-to-end-loss-for-speaker-verification,
  title={Generalized end-to-end loss for speaker verification},
  author={Wan, Li and Wang, Quan and Papir, Alan and Moreno, Ignacio Lopez},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={4879--4883},
  year={2018},
  organization={IEEE}
}

@article{clean-label-backdoor-attacks,
  title={Label-consistent backdoor attacks},
  author={Turner, Alexander and Tsipras, Dimitris and Madry, Aleksander},
  journal={arXiv preprint arXiv:1912.02771},
  year={2019}
}


@article{pang2020trojanzoo,
  title={TROJANZOO: Everything you ever wanted to know about neural backdoors (but were afraid to ask)},
  author={Pang, Ren and Zhang, Zheng and Gao, Xiangshan and Xi, Zhaohan and Ji, Shouling and Cheng, Peng and Wang, Ting},
  journal={arXiv preprint arXiv:2012.09302},
  year={2020}
}
      
@inproceedings{downup,
  author    = {Weilin Xu and
               David Evans and
               Yanjun Qi},
  title     = {Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks},
  booktitle = {25th Annual Network and Distributed System Security Symposium, {NDSS} 2018},
  publisher = {The Internet Society},
  year      = {2018},
}

@article{a-comprehensive-review,
  title={Backdoor attacks and countermeasures on deep learning: A comprehensive review},
  author={Gao, Yansong and Doan, Bao Gia and Zhang, Zhi and Ma, Siqi and Zhang, Jiliang and Fu, Anmin and Nepal, Surya and Kim, Hyoungshick},
  journal={arXiv preprint arXiv:2007.10760},
  year={2020}
}

@article{common-voice-dataset,
  title={Common voice: A massively-multilingual speech corpus},
  author={Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
  journal={arXiv preprint arXiv:1912.06670},
  year={2019}
}

@INPROCEEDINGS{dynamic-backdoor-attacks-against-ml-models,
  author={Salem, Ahmed and Wen, Rui and Backes, Michael and Ma, Shiqing and Zhang, Yang},
  booktitle={2022 IEEE 7th European Symposium on Security and Privacy}, 
  title={Dynamic Backdoor Attacks Against Machine Learning Models}, 
  year={2022},
  volume={},
  number={},
  pages={703-718},
  doi={10.1109/EuroSP53844.2022.00049}}
  
@INPROCEEDINGS{dynamic-backdoors-with-gap,
  author={Koffas, Stefanos and Picek, Stjepan and Conti, Mauro},
  booktitle={2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems}, 
  title={Dynamic Backdoors with Global Average Pooling}, 
  year={2022},
  volume={},
  number={},
  pages={320-323},
}

@inproceedings{mind-the-style-of-text,
    title = "Mind the Style of Text! Adversarial and Backdoor Attacks Based on Text Style Transfer",
    author = "Qi, Fanchao  and
      Chen, Yangyi  and
      Zhang, Xurui  and
      Li, Mukai  and
      Liu, Zhiyuan  and
      Sun, Maosong",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    publisher = "ACM",
    url = "https://aclanthology.org/2021.emnlp-main.374",
    doi = "10.18653/v1/2021.emnlp-main.374",
    pages = "4569--4580",
    abstract = "Adversarial attacks and backdoor attacks are two common security threats that hang over deep learning. Both of them harness task-irrelevant features of data in their implementation. Text style is a feature that is naturally irrelevant to most NLP tasks, and thus suitable for adversarial and backdoor attacks. In this paper, we make the first attempt to conduct adversarial and backdoor attacks based on text style transfer, which is aimed at altering the style of a sentence while preserving its meaning. We design an adversarial attack method and a backdoor attack method, and conduct extensive experiments to evaluate them. Experimental results show that popular NLP models are vulnerable to both adversarial and backdoor attacks based on text style transfer{---}the attack success rates can exceed 90{\%} without much effort. It reflects the limited ability of NLP models to handle the feature of text style that has not been widely realized. In addition, the style transfer-based adversarial and backdoor attack methods show superiority to baselines in many aspects. All the code and data of this paper can be obtained at https://github.com/thunlp/StyleAttack.",
}

@article{deep-feature-space-trojan-attack-of-nns-by-controlled-detoxification,
    title={Deep Feature Space Trojan Attack of Neural Networks by Controlled Detoxification}, 
    volume={35}, 
    url={https://ojs.aaai.org/index.php/AAAI/article/view/16201},
    DOI={10.1609/aaai.v35i2.16201}, 
    abstractNote={Trojan (backdoor) attack is a form of adversarial attack on deep neural networks where the attacker provides victims with a model trained/retrained on malicious data. The backdoor can be activated when a normal input is stamped with a certain pattern called trigger, causing misclassification. Many existing trojan attacks have their triggers being input space patches/objects (e.g., a polygon with solid color) or simple input transformations such as Instagram filters. These simple triggers are susceptible to recent backdoor detection algorithms. We propose a novel deep feature space trojan attack with five characteristics: effectiveness, stealthiness, controllability, robustness and reliance on deep features. We conduct extensive experiments on 9 image classifiers on various datasets including ImageNet to demonstrate these properties and show that our attack can evade state-of-the-art defense.}, 
    number={2}, 
    journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Cheng, Siyuan and Liu, Yingqi and Ma, Shiqing and Zhang, Xiangyu},
    year={2021}, 
    month={May}, 
    pages={1148-1156}
}

@article{stylefool,
  title={StyleFool: Fooling Video Classification Systems via Style Transfer},
  author={Cao, Yuxin and Xiao, Xi and Sun, Ruoxi and Wang, Derui and Xue, Minhui and Wen, Sheng},
  journal={arXiv preprint arXiv:2203.16000},
  year={2022}
}

@inproceedings {hidden-trigger-backdoor-attack-on-nlp-models-via-linguistic-style-manipulation,
author = {Xudong Pan and Mi Zhang and Beina Sheng and Jiaming Zhu and Min Yang},
title = {Hidden Trigger Backdoor Attack on {NLP} Models via Linguistic Style Manipulation},
booktitle = {31st USENIX Security Symposium},
year = {2022},
pages = {3611--3628},
publisher = {USENIX Association},
month = aug,
}


@inproceedings{adversarial-camouflage-hiding-physical-world-attacks-with-natural-styles,
  title={Adversarial camouflage: Hiding physical-world attacks with natural styles},
  author={Duan, Ranjie and Ma, Xingjun and Wang, Yisen and Bailey, James and Qin, A Kai and Yang, Yun},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1000--1008},
  year={2020}
}

@article{tay-robot-reference,
  title={Blockchain-based data-preserving {AI} learning environment model for {AI} cybersecurity systems in {IoT} service environments},
  author={Kim, Jinsu and Park, Namje},
  journal={Applied Sciences},
  volume={10},
  number={14},
  pages={4718},
  year={2020},
  publisher={MDPI}
}

@inproceedings{blind-backdoors-in-deep-learning-models,
  title={Blind backdoors in deep learning models},
  author={Bagdasaryan, Eugene and Shmatikov, Vitaly},
  booktitle={30th USENIX Security Symposium},
  pages={1505--1521},
  year={2021}
}

@article{handcrafted-backdoors-in-dnns,
  title={Handcrafted backdoors in deep neural networks},
  author={Hong, Sanghyun and Carlini, Nicholas and Kurakin, Alexey},
  journal={arXiv preprint arXiv:2106.04690},
  year={2021}
}

@article{large-dataset-pyrrhic-win,
  author    = {Vinay Uday Prabhu and
               Abeba Birhane},
  title     = {Large image datasets: {A} pyrrhic win for computer vision?},
  journal   = {CoRR},
  volume    = {abs/2006.16923},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.16923},
  archivePrefix = {arXiv},
  eprint    = {2006.16923},
  timestamp = {Thu, 02 Jul 2020 14:42:48 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-16923.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{music-in-theory-and-practice,
  title={Music in Theory and Practice Volume 1},
  author={Benward, Bruce},
  year={2014},
  publisher={McGraw-Hill Higher Education},
  isbn = {0073101877}
}

@inproceedings{AlBadawy2020,
  author={Ehab A. AlBadawy and Siwei Lyu},
  title={{Voice Conversion Using Speech-to-Speech Neuro-Style Transfer}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={4726--4730},
  doi={10.21437/Interspeech.2020-3056},
  url={http://dx.doi.org/10.21437/Interspeech.2020-3056}
}

@inproceedings{grinstein2018audio,
  title={Audio style transfer},
  author={Grinstein, Eric and Duong, Ngoc QK and Ozerov, Alexey and P{\'e}rez, Patrick},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing},
  pages={586--590},
  year={2018},
  organization={IEEE}
}

@inproceedings{li2021hidden,
  title={Hidden backdoors in human-centric language models},
  author={Li, Shaofeng and Liu, Hui and Dong, Tian and Zhao, Benjamin Zi Hao and Xue, Minhui and Zhu, Haojin and Lu, Jialiang},
  booktitle={Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security},
  pages={3123--3140},
  year={2021}
}

@inproceedings{audio-adversarial-examples-targeted-attacks-on-speech-to-text,
  title={Audio adversarial examples: Targeted attacks on speech-to-text},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2018 IEEE security and privacy workshops (SPW)},
  pages={1--7},
  year={2018},
  organization={IEEE}
}

@article{timit,
  title={Speech database development at MIT: TIMIT and beyond},
  author={Zue, Victor and Seneff, Stephanie and Glass, James},
  journal={Speech communication},
  volume={9},
  number={4},
  pages={351--356},
  year={1990},
  publisher={Elsevier}
}

@inproceedings{zhai2021backdoor,
  title={Backdoor attack against speaker verification},
  author={Zhai, Tongqing and Li, Yiming and Zhang, Ziqi and Wu, Baoyuan and Jiang, Yong and Xia, Shu-Tao},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={2560--2564},
  year={2021},
  organization={IEEE}
}