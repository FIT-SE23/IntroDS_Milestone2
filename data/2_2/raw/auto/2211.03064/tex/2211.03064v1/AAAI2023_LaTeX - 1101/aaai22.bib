@book{em:86,
  editor  = "Engelmore, Robert and Morgan, Anthony",
  title   = "Blackboard Systems",
  year    = 1986,
  address = "Reading, Mass.",
  publisher = "Addison-Wesley",
}

@inproceedings{c:83,
  author  = "Clancey, William J.",
  year    = 1983,
  title   = "{Communication, Simulation, and Intelligent
Agents: Implications of Personal Intelligent Machines
for Medical Education}",
  booktitle="Proceedings of the Eighth International Joint Conference on Artificial Intelligence {(IJCAI-83)}", 
  pages   = "556-560",
  address = "Menlo Park, Calif",
  publisher = "{IJCAI Organization}",
}
@inproceedings{c:84,
  author  = "Clancey, William J.",
  year    = 1984,
  title   = "{Classification Problem Solving}",
  booktitle = "Proceedings of the Fourth National 
              Conference on Artificial Intelligence",
  pages   = "45-54",
  address = "Menlo Park, Calif.",
  publisher="Proceedings of the AAAI Conference on Artificial Intelligence Press",
}
@article{r:80,
  author = {Robinson, Arthur L.},
  title = {New Ways to Make Microcircuits Smaller},
  volume = {208},
  number = {4447},
  pages = {1019--1022},
  year = {1980},
  doi = {10.1126/science.208.4447.1019},
  publisher = {American Association for the Advancement of Science},
  issn = {0036-8075},
  URL = {https://science.sciencemag.org/content/208/4447/1019},
  eprint = {https://science.sciencemag.org/content/208/4447/1019.full.pdf},
  journal = {Science},
}
@article{r:80x,
  author  = "Robinson, Arthur L.",
  year    = 1980,
  title   = "{New Ways to Make Microcircuits Smaller---Duplicate Entry}",
  journal = "Science",
  volume  =  208,
  pages   = "1019-1026",
}
@article{hcr:83,
title = {Strategic explanations for a diagnostic consultation system},
journal = {International Journal of Man-Machine Studies},
volume = {20},
number = {1},
pages = {3-19},
year = {1984},
issn = {0020-7373},
doi = {https://doi.org/10.1016/S0020-7373(84)80003-6},
url = {https://www.sciencedirect.com/science/article/pii/S0020737384800036},
author = {Diane Warner Hasling and William J. Clancey and Glenn Rennels},
abstract = {This article examines the problem of automatte explanation of reasoning, especially as it relates to expert systems. By explanation we mean the ability of a program to discuss what it is doing in some understandable way. We first present a general framework in which to view explanation and review some of the research done in this area. We then focus on the explanation system for NEOMYCIN, a medical consultation program. A consultation program interactively helps a user to solve a problem. Our goal is to have NEOMYCIN explain its problem-solving strategies. An explanation of strategy describes the plan the program is using to reach a solution. Such an explanation is usually concrete, referring to aspects of the current problem situation. Abstract explanations articulate a general principle, which can be applied in different situations; such explanations are useful in teaching and in explaining by analogy. We describe the aspects of NEOMYCIN that make abstract strategic explanations possible—the representation of strategic knowledge explicitly and separately from domain knowledge— and demonstrate how this representation can be used to generate explanations.}
}
@article{hcrt:83,
  author  = "Hasling, Diane Warner and Clancey, William J. and Rennels, Glenn R. and Test, Thomas",
  year    = 1983,
  title   = "{Strategic Explanations in Consultation---Duplicate}",
  journal = "The International Journal of Man-Machine Studies",
  volume  = 20,
  number  = 1,
  pages   = "3-19",
}
@techreport{r:86,
  author  = "Rice, James",
  year    = 1986,
  title   = "{Poligon: A System for Parallel Problem Solving}",
  type    = "Technical Report", 
  number  = "KSL-86-19", 
  institution = "Dept.\ of Computer Science, Stanford Univ.",
}
@phdthesis{c:79,
  author  = "Clancey, William J.",
  year    = 1979,
  title   = "{Transfer of Rule-Based Expertise
through a Tutorial Dialogue}",
  type    = "{Ph.D.} diss.",
  school  = "Dept.\ of Computer Science, Stanford Univ.",
  address = "Stanford, Calif.",
}
@unpublished{c:21,
  author  = "Clancey, William J.",
  title   = "{The Engineering of Qualitative Models}",
  year    = 2021,
  note    = "Forthcoming",
}
@misc{c:22,
      title={Crime and punishment in scientific research}, 
      author={Mathieu Bouville},
      year={2008},
      eprint={0803.4058},
      archivePrefix={arXiv},
      primaryClass={physics.soc-ph}
}
@misc{c:23,
  title        = "Pluto: The 'Other' Red Planet",
  author       = "{NASA}",
  howpublished = "\url{https://www.nasa.gov/nh/pluto-the-other-red-planet}",
  year         = 2015,
  note         = "Accessed: 2018-12-06"
}


@misc{Authors14,
 author = {Authors},
 title = {The frobnicatable foo filter},
 note = {{BMVC14} submission ID 324. Supplied as additional material {\tt bmvc14.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {Authors},
 title = {Frobnication tutorial},
 note = {Supplied as additional material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {A. Alpher},
title = {Frobnication},
journal = {Journal of Foo},
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {A. Alpher and J.~P.~N. Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {A. Alpher and J.~P.~N. Fotheringham-Smythe and G. Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@article{lombrozo2006structure,
  title={The structure and function of explanations},
  author={Lombrozo, Tania},
  journal={Trends in cognitive sciences},
  volume={10},
  number={10},
  pages={464--470},
  year={2006},
  publisher={Elsevier}
}

@article{smilkov2017smoothgrad,
  title={Smoothgrad: removing noise by adding noise},
  author={Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:1706.03825},
  year={2017}
}

@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={International Conference on Machine Learning},
  pages={3319--3328},
  year={2017},
  organization={PMLR}
}





@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{vig2019visualizing,
  title={Visualizing attention in transformerbased language models},
  author={Vig, Jesse},
  journal={arXiv preprint arXiv:1904.02679},
  year={2019}
}

@inproceedings{jain2019attention,
  title={Attention is not Explanation},
  author={Jain, Sarthak and Wallace, Byron C},
  booktitle={Proceedings of NA Annual Meeting of the Association for Computational Linguistics-HLT},
  pages={3543--3556},
  year={2019}
}

@inproceedings{serrano2019attention,
  title={Is Attention Interpretable?},
  author={Serrano, Sofia and Smith, Noah A},
  booktitle={ Annual Meeting of the Association for Computational Linguistics},
  pages={2931--2951},
  year={2019}
}

@inproceedings{grimsley2020attention,
  title={Why Attention is Not Explanation: Surgical Intervention and Causal Reasoning about Neural Models},
  author={Grimsley, Christopher and Mayfield, Elijah and Bursten, Julia RS},
  booktitle={Proceedings of the 12th Language Resources and Evaluation Conference},
  pages={1780--1790},
  year={2020}
}

@inproceedings{wiegreffe2019attention,
  title={Attention is not not Explanation},
  author={Wiegreffe, Sarah and Pinter, Yuval},
  booktitle={EMNLP-IJCNLP},
  pages={11--20},
  year={2019}
}


@inproceedings{pruthi2020learning,
  title={Learning to Deceive with Attention-Based Explanations},
  author={Pruthi, Danish and Gupta, Mansi and Dhingra, Bhuwan and Neubig, Graham and Lipton, Zachary C},
  booktitle={ Annual Meeting of the Association for Computational Linguistics},
  pages={4782--4793},
  year={2020}
}

@inproceedings{linzen2019proceedings,
  title={Proceedings of the 2019  Annual Meeting of the Association for Computational Linguistics Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  author={Linzen, Tal and Chrupa{\l}a, Grzegorz and Belinkov, Yonatan and Hupkes, Dieuwke},
  booktitle={Proceedings of the 2019  Annual Meeting of the Association for Computational Linguistics Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  year={2019}
}

@article{vashishth2019attention,
  title={Attention interpretability across nlp tasks},
  author={Vashishth, Shikhar and Upadhyay, Shyam and Tomar, Gaurav Singh and Faruqui, Manaal},
  journal={arXiv preprint arXiv:1909.11218},
  year={2019}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}

@article{bazi2021vision,
  title={Vision transformers for remote sensing image classification},
  author={Bazi, Yakoub and Bashmal, Laila and Rahhal, Mohamad M Al and Dayil, Reham Al and Ajlan, Naif Al},
  journal={Remote Sensing},
  volume={13},
  number={3},
  pages={516},
  year={2021},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@inproceedings{paul2022vision,
  title={Vision transformers are robust learners},
  author={Paul, Sayak and Chen, Pin-Yu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={2},
  pages={2071--2081},
  year={2022}
}

@article{samek2016evaluating,
  title={Evaluating the visualization of what a deep neural network has learned},
  author={Samek, Wojciech and Binder, Alexander and Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and M{\"u}ller, Klaus-Robert},
  journal={IEEE transactions on neural networks and learning systems},
  volume={28},
  number={11},
  pages={2660--2673},
  year={2016},
  publisher={IEEE}
}

@article{white2021contrastive,
  title={Contrastive Counterfactual Visual Explanations With Overdetermination},
  author={White, Adam and Ngan, Kwun Ho and Phelan, James and Afgeh, Saman Sadeghi and Ryan, Kevin and Reyes-Aldasoro, Constantino Carlos and Garcez, Artur d'Avila},
  journal={arXiv preprint arXiv:2106.14556},
  year={2021}
}

@inproceedings{tuli2021convolutional,
  title={Are Convolutional Neural Networks or Transformers more like human vision?},
  author={Tuli, Shikhar and Dasgupta, Ishita and Grant, Erin and Griffiths, Tom},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={43},
  number={43},
  year={2021}
}


@inproceedings{geirhos2018imagenet,
  title={ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness},
  author={Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland},
  booktitle={International Conference on Machine Learning},
  year={2018}
}

@inproceedings{
  naseer2021intriguing,
  title={Intriguing Properties of Vision Transformers},
  author={Muzammal Naseer and Kanchana Ranasinghe and Salman Khan and Munawar Hayat and Fahad Khan and Ming-Hsuan Yang},
  booktitle={Advances in Neural Information Processing Systems},
  year={2021}
}

@inproceedings{bhojanapalli2021understanding,
  title={Understanding robustness of transformers for image classification},
  author={Bhojanapalli, Srinadh and Chakrabarti, Ayan and Glasner, Daniel and Li, Daliang and Unterthiner, Thomas and Veit, Andreas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10231--10241},
  year={2021}
}

@article{gu2021vision,
  title={Are Vision Transformers Robust to Patch Perturbations?},
  author={Gu, Jindong and Tresp, Volker and Qin, Yao},
  journal={arXiv preprint arXiv:2111.10659},
  year={2021}
}

@article{aldahdooh2021reveal,
  title={Reveal of vision transformers robustness against adversarial attacks},
  author={Aldahdooh, Ahmed and Hamidouche, Wassim and Deforges, Olivier},
  journal={arXiv preprint arXiv:2106.03734},
  year={2021}
}

@article{srinivas2019full,
  title={Full-gradient representation for neural network visualization},
  author={Srinivas, Suraj and Fleuret, Fran{\c{c}}ois},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{kenton2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of NA Annual Meeting of the Association for Computational Linguistics-HLT},
  pages={4171--4186},
  year={2019}
}

@inproceedings{yuan2021explaining,
  title={Explaining Information Flow Inside Vision Transformers Using Markov Chain},
  author={Yuan, Tingyi and Li, Xuhong and Xiong, Haoyi and Cao, Hui and Dou, Dejing},
  booktitle={eXplainable AI approaches for debugging and diagnosis.},
  year={2021}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{clark2019does,
  title={What Does BERT Look at? An Analysis of BERT’s Attention},
  author={Clark, Kevin and Khandelwal, Urvashi and Levy, Omer and Manning, Christopher D},
  booktitle={Proceedings of the 2019  Annual Meeting of the Association for Computational Linguistics Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  pages={276--286},
  year={2019}
}

@article{wang2021dodrio,
  title={Dodrio: exploring transformer models with interactive visualization},
  author={Wang, Zijie J and Turko, Robert and Chau, Duen Horng},
  journal={arXiv preprint arXiv:2103.14625},
  year={2021}
}

@InProceedings{chefer2021generic,
   author    = {Chefer, Hila and Gur, Shir and Wolf, Lior},
   title     = {Generic Attention-Model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers},
   booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
   year      = {2021},
   pages     = {397-406}
}

@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@article{zhang2018top,
  title={Top-down neural attention by excitation backprop},
  author={Zhang, Jianming and Bargal, Sarah Adel and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan},
  journal={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  volume={126},
  number={10},
  pages={1084--1102},
  year={2018},
  publisher={Springer}
}


@inproceedings{jacovi2020towards,
  title={Towards Faithfully Interpretable NLP Systems: How Should We Define and Evaluate Faithfulness?},
  author={Jacovi, Alon and Goldberg, Yoav},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={4198--4205},
  year={2020}
}

@inproceedings{yuan2021tokens,
  title={Tokens-to-token vit: Training vision transformers from scratch on imagenet},
  author={Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zi-Hang and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={558--567},
  year={2021}
}

@article{raghu2021vision,
  title={Do vision transformers see like convolutional neural networks?},
  author={Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12116--12128},
  year={2021}
}

@misc{jacobgilpytorchcam,
  title={PyTorch library for CAM methods},
  author={Jacob Gildenblat and contributors},
  year={2021},
  publisher={GitHub},
  howpublished={\url{https://github.com/jacobgil/pytorch-grad-cam}},
}

@inproceedings{zheng2021rethinking,
  title={Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers},
  author={Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6881--6890},
  year={2021}
}

@article{xie2021segformer,
  title={SegFormer: Simple and efficient design for semantic segmentation with transformers},
  author={Xie, Enze and Wang, Wenhai and Yu, Zhiding and Anandkumar, Anima and Alvarez, Jose M and Luo, Ping},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12077--12090},
  year={2021}
}

@inproceedings{lin2017feature,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2117--2125},
  year={2017}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}

@inproceedings{bastings2020elephant,
  title={The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?},
  author={Bastings, Jasmijn and Filippova, Katja},
  booktitle={Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},
  pages={149--155},
  year={2020}
}


@inproceedings{chefer2021transformer,
  title={Transformer interpretability beyond attention visualization},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={782--791},
  year={2021}
}

@inproceedings{voita2019analyzing,
  title={Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned},
  author={Voita, Elena and Talbot, David and Moiseev, Fedor and Sennrich, Rico and Titov, Ivan},
  booktitle={ Annual Meeting of the Association for Computational Linguistics},
  pages={5797--5808},
  year={2019},
  organization={ Annual Meeting of the Association for Computational Linguistics Anthology}
}

@inproceedings{abnar2020quantifying,
  title={Quantifying Attention Flow in Transformers},
  author={Abnar, Samira and Zuidema, Willem},
  booktitle={ Annual Meeting of the Association for Computational Linguistics},
  pages={4190--4197},
  year={2020}
}

@article{chen2021vision,
  title={When vision transformers outperform ResNets without pre-training or strong data augmentations},
  author={Chen, Xiangning and Hsieh, Cho-Jui and Gong, Boqing},
  journal={arXiv preprint arXiv:2106.01548},
  year={2021}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{bach2015pixel,
  title={On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
  author={Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  journal={PloS one},
  volume={10},
  number={7},
  pages={e0130140},
  year={2015},
  publisher={Public Library of Science San Francisco, CA USA}
}


@article{steiner2021train,
  title={How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers},
  author={Steiner, Andreas and Kolesnikov, Alexander and Zhai, Xiaohua and Wightman, Ross and Uszkoreit, Jakob and Beyer, Lucas},
  journal={arXiv preprint arXiv:2106.10270},
  year={2021}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={International conference on learning representations},
  year={2020}
}

@article{fel2021look,
  title={Look at the Variance! Efficient Black-box Explanations with Sobol-based Sensitivity Analysis},
  author={Fel, Thomas and Cad{\`e}ne, R{\'e}mi and Chalvidal, Mathieu and Cord, Matthieu and Vigouroux, David and Serre, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@article{guillaumin2014imagenet,
  title={Imagenet auto-annotation with segmentation propagation},
  author={Guillaumin, Matthieu and K{\"u}ttel, Daniel and Ferrari, Vittorio},
  journal={International Journal of Computer Vision},
  volume={110},
  number={3},
  pages={328--348},
  year={2014},
  publisher={Springer}
}

@inproceedings{peng2021conformer,
  title={Conformer: Local features coupling global representations for visual recognition},
  author={Peng, Zhiliang and Huang, Wei and Gu, Shanzhi and Xie, Lingxi and Wang, Yaowei and Jiao, Jianbin and Ye, Qixiang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={367--376},
  year={2021}
}

@article{o2020generative,
  title={Generative causal explanations of black-box classifiers},
  author={O'Shaughnessy, Matthew and Canal, Gregory and Connor, Marissa and Rozell, Christopher and Davenport, Mark},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5453--5467},
  year={2020}
}

@inproceedings{fong2017interpretable,
  title={Interpretable explanations of black boxes by meaningful perturbation},
  author={Fong, Ruth C and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3429--3437},
  year={2017}
}

@inproceedings{fong2019understanding,
  title={Understanding deep networks via extremal perturbations and smooth masks},
  author={Fong, Ruth and Patrick, Mandela and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2950--2958},
  year={2019}
}

@article{hsu1947complete,
  title={Complete convergence and the law of large numbers},
  author={Hsu, Pao-Lu and Robbins, Herbert},
  journal={Proceedings of the National Academy of Sciences of the United States of America},
  volume={33},
  number={2},
  pages={25},
  year={1947},
  publisher={National Academy of Sciences}
}

@inproceedings{zhang2022nested,
  title={Nested hierarchical transformer: Towards accurate, data-efficient and interpretable visual understanding},
  author={Zhang, Zizhao and Zhang, Han and Zhao, Long and Chen, Ting and Arik, Sercan {\"O} and Pfister, Tomas},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={3},
  pages={3417--3425},
  year={2022}
}

@article{chu2021twins,
  title={Twins: Revisiting the design of spatial attention in vision transformers},
  author={Chu, Xiangxiang and Tian, Zhi and Wang, Yuqing and Zhang, Bo and Ren, Haibing and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={9355--9366},
  year={2021}
}


@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}

@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}

@article{qiu2021resisting,
  title={Resisting Out-of-Distribution Data Problem in Perturbation of XAI},
  author={Qiu, Luyu and Yang, Yi and Cao, Caleb Chen and Liu, Jing and Zheng, Yueyuan and Ngai, Hilary Hei Ting and Hsiao, Janet and Chen, Lei},
  journal={arXiv preprint arXiv:2107.14000},
  year={2021}
}


@article{lombrozo2011instrumental,
  title={The instrumental value of explanations},
  author={Lombrozo, Tania},
  journal={Philosophy Compass},
  volume={6},
  number={8},
  pages={539--551},
  year={2011},
  publisher={Wiley Online Library}
}

@article{pya2015shape,
  title={Shape constrained additive models},
  author={Pya, Natalya and Wood, Simon N},
  journal={Statistics and Computing},
  volume={25},
  number={3},
  pages={543--559},
  year={2015},
  publisher={Springer}
}


@article{zhang2016latent,
  title={Latent tree analysis},
  author={Zhang, Nevin L and Poon, Leonard KM},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
  pages= {4891--4898},
  year={2017}
}

@article{chen2017latent,
  title={Latent tree models for hierarchical topic detection},
  author={Chen, Peixian and Zhang, Nevin L and Liu, Tengfei and Poon, Leonard KM and Chen, Zhourong and Khawar, Farhan},
  journal={Artificial Intelligence},
  volume={250},
  pages={105--124},
  year={2017},
  publisher={Elsevier}
}


@inproceedings{dhurandhar2018explanations,
  title={Explanations based on the missing: Towards contrastive explanations with pertinent negatives},
  author={Dhurandhar, Amit and Chen, Pin-Yu and Luss, Ronny and Tu, Chun-Chen and Ting, Paishun and Shanmugam, Karthikeyan and Das, Payel},
  booktitle={Advances in Neural Information Processing Systems},
  pages={592--603},
  year={2018}
}

@article{hase2020evaluating,
  title={Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?},
  author={Hase, Peter and Bansal, Mohit},
  journal={arXiv preprint arXiv:2005.01831},
  year={2020}
}


@article{samek2016evaluating,
  title={Evaluating the visualization of what a deep neural network has learned},
  author={Samek, Wojciech and Binder, Alexander and Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and M{\"u}ller, Klaus-Robert},
  journal={IEEE transactions on neural networks and learning systems},
  volume={28},
  number={11},
  pages={2660--2673},
  year={2016},
  publisher={IEEE}
}


@inproceedings{ghorbani2019towards,
  title={Towards automatic concept-based explanations},
  author={Ghorbani, Amirata and Wexler, James and Zou, James Y and Kim, Been},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9277--9286},
  year={2019}
}


@article{liu2019generative,
  title={Generative counterfactual introspection for explainable deep learning},
  author={Liu, Shusen and Kailkhura, Bhavya and Loveland, Donald and Han, Yong},
  journal={arXiv preprint arXiv:1907.03077},
  year={2019}
}

@article{wachter2017counterfactual,
  title={Counterfactual explanations without opening the black box: Automated decisions and the GDPR},
  author={Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
  journal={Harv. JL \& Tech.},
  volume={31},
  pages={841},
  year={2017},
  publisher={HeinOnline}
}

@inproceedings{kim2016examples,
  title={Examples are not enough, learn to criticize! criticism for interpretability},
  author={Kim, Been and Khanna, Rajiv and Koyejo, Oluwasanmi O},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2280--2288},
  year={2016}
}




@inproceedings{kim2018interpretability,
  title={Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)},
  author={Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others},
  booktitle={International Conference on Machine Learning},
  pages={2668--2677},
  year={2018}
}

@book{scheaffer2011elementary,
  title={Elementary survey sampling},
  author={Scheaffer, Richard L and Mendenhall III, William and Ott, R Lyman and Gerow, Kenneth G},
  year={2011},
  publisher={Cengage Learning}
}

@article{gao2021covid,
  title={Covid-vit: Classification of covid-19 from ct chest images based on vision transformer models},
  author={Gao, Xiaohong and Qian, Yu and Gao, Alice},
  journal={arXiv preprint arXiv:2107.01682},
  year={2021}
}

@article{jiang2021layercam,
  title={Layercam: Exploring hierarchical class activation maps for localization},
  author={Jiang, Peng-Tao and Zhang, Chang-Bin and Hou, Qibin and Cheng, Ming-Ming and Wei, Yunchao},
  journal={IEEE Transactions on Image Processing},
  volume={30},
  pages={5875--5888},
  year={2021},
  publisher={IEEE}
}

@inproceedings{shen2021efficient,
  title={Efficient attention: Attention with linear complexities},
  author={Shen, Zhuoran and Zhang, Mingyuan and Zhao, Haiyu and Yi, Shuai and Li, Hongsheng},
  booktitle={WACV},
  pages={3531--3539},
  year={2021}
}


@inproceedings{adebayo2018sanity,
  title={Sanity checks for saliency maps},
  author={Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9525--9536},
  year={2018}
}

@article{li2016understanding,
  title={Understanding neural networks through representation erasure},
  author={Li, Jiwei and Monroe, Will and Jurafsky, Dan},
  journal={arXiv preprint arXiv:1612.08220},
  year={2016}
}

@inproceedings{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4765--4774},
  year={2017}
}

@article{das2020opportunities,
  title={Opportunities and challenges in explainable artificial intelligence (xai): A survey},
  author={Das, Arun and Rad, Paul},
  journal={arXiv preprint arXiv:2006.11371},
  year={2020}
}

@inproceedings{yang2020ml,
  title={Ml-loo: Detecting adversarial examples with feature attribution},
  author={Yang, Puyudi and Chen, Jianbo and Hsieh, Cho-Jui and Wang, Jane-Ling and Jordan, Michael},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={6639--6647},
  year={2020}
}


@inproceedings{sattarzadeh2021explaining,
  title={Explaining convolutional neural networks through attribution-based input sampling and block-wise feature aggregation},
  author={Sattarzadeh, Sam and Sudhakar, Mahesh and Lem, Anthony and Mehryar, Shervin and Plataniotis, Konstantinos N and Jang, Jongseong and Kim, Hyunwoo and Jeong, Yeonjeong and Lee, Sangmin and Bae, Kyunghoon},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={13},
  pages={11639--11647},
  year={2021}
}

@inproceedings{wang2020score,
  title={Score-CAM: Score-weighted visual explanations for convolutional neural networks},
  author={Wang, Haofan and Wang, Zifan and Du, Mengnan and Yang, Fan and Zhang, Zijian and Ding, Sirui and Mardziel, Piotr and Hu, Xia},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshop},
  pages={24--25},
  year={2020}
}

@inproceedings{nguyen2015deep,
  title={Deep neural networks are easily fooled: High confidence predictions for unrecognizable images},
  author={Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={427--436},
  year={2015}
}

@inproceedings{alcorn2019strike,
  title={Strike (with) a pose: Neural networks are easily fooled by strange poses of familiar objects},
  author={Alcorn, Michael A and Li, Qi and Gong, Zhitao and Wang, Chengfei and Mai, Long and Ku, Wei-Shinn and Nguyen, Anh},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4845--4854},
  year={2019}
}


@article{schallner2019effect,
  title={Effect of Superpixel Aggregation on Explanations in LIME--A Case Study with Biological Data},
  author={Schallner, Ludwig and Rabold, Johannes and Scholz, Oliver and Schmid, Ute},
  journal={arXiv preprint arXiv:1910.07856},
  year={2019}
}

@article{schreyer2001measuring,
  title={Measuring productivity},
  author={Schreyer, Paul and Pilat, Dirk},
  journal={OECD Economic studies},
  volume={33},
  number={2},
  pages={127--170},
  year={2001},
  publisher={Citeseer}
}


@article{doshi2017towards,
  title={Towards a rigorous science of interpretable machine learning},
  author={Doshi-Velez, Finale and Kim, Been},
  journal={arXiv preprint arXiv:1702.08608},
  year={2017}
}

@inproceedings{10.1145/3447548.3467148,
author = {Li, Xiao-Hui and Shi, Yuhan and Li, Haoyang and Bai, Wei and Cao, Caleb Chen and Chen, Lei},
title = {An Experimental Study of Quantitative Evaluations on Saliency Methods},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467148},
doi = {10.1145/3447548.3467148},
booktitle = {Proceedings of the ACM SIGKDD international conference on knowledge discovery and data mining},
pages = {3200–3208},
numpages = {9},
keywords = {explainable artificial intelligence, evaluation, model diagnosis, metrics},
location = {Virtual Event, Singapore},
series = {KDD '21}
}



@article{lipton2018mythos,
  title={The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery.},
  author={Lipton, Zachary C},
  journal={Queue},
  volume={16},
  number={3},
  pages={31--57},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@inproceedings{petsiuk2018rise,
  title = {RISE: Randomized Input Sampling for Explanation of Black-box Models},
  author = {Vitali Petsiuk and Abir Das and Kate Saenko},
  booktitle = {Proceedings of the British Machine Vision Conference},
  year = {2018}
}


@incollection{Advances in Neural Information Processing Systems2017_7062,
title = {A Unified Approach to Interpreting Model Predictions},
author = {Lundberg, Scott M and Lee, Su-In},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {4765--4774},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.Advances in Neural Information Processing Systems.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf}
}

@inproceedings{rebuffi2020there,
  title={There and back again: Revisiting backpropagation saliency methods},
  author={Rebuffi, Sylvestre-Alvise and Fong, Ruth and Ji, Xu and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8839--8848},
  year={2020}
}


@article{althusser1969contradiction,
  title={Contradiction and overdetermination},
  author={Althusser, Louis},
  journal={For Marx},
  volume={17},
  year={1969},
  publisher={New York}
}

@inproceedings{fong2019understanding,
  title={Understanding deep networks via extremal perturbations and smooth masks},
  author={Fong, Ruth and Patrick, Mandela and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2950--2958},
  year={2019}
}

@inproceedings{zhou2016learning,
  title={Learning deep features for discriminative localization},
  author={Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2921--2929},
  year={2016}
}

@inproceedings{zhang2018interpretable,
  title={Interpretable convolutional neural networks},
  author={Zhang, Quanshi and Wu, Ying Nian and Zhu, Song-Chun},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8827--8836},
  year={2018}
}

@inproceedings{xu2020attribution,
  title={Attribution in scale and space},
  author={Xu, Shawn and Venugopalan, Subhashini and Sundararajan, Mukund},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9680--9689},
  year={2020}
}

@inproceedings{kapishnikov2019xrai,
  title={Xrai: Better attributions through regions},
  author={Kapishnikov, Andrei and Bolukbasi, Tolga and Vi{\'e}gas, Fernanda and Terry, Michael},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4948--4957},
  year={2019}
}

@inproceedings{ribeiro2016should,
  title={" Why should I trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@inproceedings{chattopadhay2018grad,
  title={Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks},
  author={Chattopadhay, Aditya and Sarkar, Anirban and Howlader, Prantik and Balasubramanian, Vineeth N},
  booktitle={WACV},
  pages={839--847},
  year={2018},
  organization={IEEE}
}

@article{alvarez2018towards,
  title={Towards robust interpretability with self-explaining neural networks},
  author={Alvarez Melis, David and Jaakkola, Tommi},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={618--626},
  year={2017}
}

@article{shrikumar2017learning,
  title={Learning important features through propagating activation differences},
  author={Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  journal={arXiv preprint arXiv:1704.02685},
  year={2017}
}

@article{yang2021focal,
  title={Focal attention for long-range interactions in vision transformers},
  author={Yang, Jianwei and Li, Chunyuan and Zhang, Pengchuan and Dai, Xiyang and Xiao, Bin and Yuan, Lu and Gao, Jianfeng},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={30008--30022},
  year={2021}
}

@inproceedings{wang2021pyramid,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={568--578},
  year={2021}
}

@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={International Conference on Machine Learning},
  pages={3319--3328},
  year={2017},
  organization={PMLR}
}

@article{smilkov2017smoothgrad,
  title={Smoothgrad: removing noise by adding noise},
  author={Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:1706.03825},
  year={2017}
}

@article{springenberg2014striving,
  title={Striving for simplicity: The all convolutional net},
  author={Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1412.6806},
  year={2014}
}

@article{simonyan2013deep,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1312.6034},
  year={2013}
}

@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={818--833},
  year={2014}
}


@article{zhang2018top,
  title={Top-down neural attention by excitation backprop},
  author={Zhang, Jianming and Bargal, Sarah Adel and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan},
  journal={International Journal of Computer Vision},
  volume={126},
  number={10},
  pages={1084--1102},
  year={2018},
  publisher={Springer}
}



@inproceedings{li2017not,
  title={Not all pixels are equal: Difficulty-aware semantic segmentation via deep layer cascade},
  author={Li, Xiaoxiao and Liu, Ziwei and Luo, Ping and Change Loy, Chen and Tang, Xiaoou},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3193--3202},
  year={2017}
}

@inproceedings{nie2019difficulty,
  title={Difficulty-aware attention network with confidence learning for medical image segmentation},
  author={Nie, Dong and Wang, Li and Xiang, Lei and Zhou, Sihang and Adeli, Ehsan and Shen, Dinggang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={1085--1092},
  year={2019}
}


@article{scheidegger2020efficient,
  title={Efficient image dataset classification difficulty estimation for predicting deep-learning accuracy},
  author={Scheidegger, Florian and Istrate, Roxana and Mariani, Giovanni and Benini, Luca and Bekas, Costas and Malossi, Cristiano},
  journal={The Visual Computer},
  pages={1--18},
  year={2020},
  publisher={Springer}
}



@inproceedings{tudor2016hard,
  title={How hard can it be? Estimating the difficulty of visual search in an image},
  author={Tudor Ionescu, Radu and Alexe, Bogdan and Leordeanu, Marius and Popescu, Marius and Papadopoulos, Dim P and Ferrari, Vittorio},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2157--2166},
  year={2016}
}


@article{yu2020difficulty,
  title={Difficulty-aware Glaucoma Classification with Multi-Rater Consensus Modeling},
  author={Yu, Shuang and Zhou, Hong-Yu and Ma, Kai and Bian, Cheng and Chu, Chunyan and Liu, Hanruo and Zheng, Yefeng},
  journal={arXiv preprint arXiv:2007.14848},
  year={2020}
}


@article{beyer2020we,
  title={Are we done with ImageNet?},
  author={Beyer, Lucas and H{\'e}naff, Olivier J and Kolesnikov, Alexander and Zhai, Xiaohua and Oord, A{\"a}ron van den},
  journal={arXiv preprint arXiv:2006.07159},
  year={2020}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{tsipras2020imagenet,
  title={From ImageNet to Image Classification: Contextualizing Progress on Benchmarks},
  author={Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Ilyas, Andrew and Madry, Aleksander},
  journal={arXiv preprint arXiv:2005.11295},
  year={2020}
}


@article{wan2020nbdt,
  title={NBDT: Neural-Backed Decision Trees},
  author={Wan, Alvin and Dunlap, Lisa and Ho, Daniel and Yin, Jihan and Lee, Scott and Jin, Henry and Petryk, Suzanne and Bargal, Sarah Adel and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:2004.00221},
  year={2020}
}


@inproceedings{murthy2016deep,
  title={Deep decision network for multi-class image classification},
  author={Murthy, Venkatesh N and Singh, Vivek and Chen, Terrence and Manmatha, R and Comaniciu, Dorin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2240--2248},
  year={2016}
}


@inproceedings{ahmed2016network,
  title={Network of experts for large-scale image categorization},
  author={Ahmed, Karim and Baig, Mohammad Haris and Torresani, Lorenzo},
  booktitle={European conference on computer vision},
  pages={516--532},
  year={2016}
}




@article{shrikumar2016not,
  title={Not just a black box: Learning important features through propagating activation differences},
  author={Shrikumar, Avanti and Greenside, Peyton and Shcherbina, Anna and Kundaje, Anshul},
  journal={arXiv preprint arXiv:1605.01713},
  year={2016}
}

@article{miller2019explanation,
  title={Explanation in artificial intelligence: Insights from the social sciences},
  author={Miller, Tim},
  journal={Artificial Intelligence},
  volume={267},
  pages={1--38},
  year={2019},
  publisher={Elsevier}
}

@article{lipton2018mythos,
  title={The Mythos of Model Interpretability: In machine learning, the concept of interpretability is both important and slippery.},
  author={Lipton, Zachary C},
  journal={Queue},
  volume={16},
  number={3},
  pages={31--57},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{dzindolet2003role,
  title={The role of trust in automation reliance},
  author={Dzindolet, Mary T and Peterson, Scott A and Pomranky, Regina A and Pierce, Linda G and Beck, Hall P},
  journal={International journal of human-computer studies},
  volume={58},
  number={6},
  pages={697--718},
  year={2003},
  publisher={Elsevier}
}

@article{gunning2019darpa,
  title={{DARPA}'s explainable artificial intelligence program},
  author={Gunning, David and Aha, David W},
  journal={AI Magazine},
  volume={40},
  number={2},
  pages={44--58},
  year={2019},
  publisher={Association for the Advancement of Artificial Intelligence}
}



@inproceedings{li2020quantitative,
author = {Li, Xiao-Hui and Shi, Yuhan and Li, Haoyang and Bai, Wei and Cao, Caleb Chen and Chen, Lei},
title = {An Experimental Study of Quantitative Evaluations on Saliency Methods},
year = {2021},
booktitle = {Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
pages = {3200–3208}
}



@article{white2021contrastive,
  title={Contrastive Counterfactual Visual Explanations With Overdetermination},
  author={White, Adam and Ngan, Kwun Ho and Phelan, James and Afgeh, Saman Sadeghi and Ryan, Kevin and Reyes-Aldasoro, Constantino Carlos and Garcez, Artur d'Avila},
  journal={arXiv preprint arXiv:2106.14556},
  year={2021}
}


