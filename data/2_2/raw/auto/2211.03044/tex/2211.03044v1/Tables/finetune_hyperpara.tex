\begin{table}[t]
\caption{
Hyperparameters used for fine-tuning on different tasks (they are kept same for all tasks).
$lr$: Learning rate; $bs$: Batch size; $N|\mathcal{Y}|$: Total number of selected generated data (\ie, training set size); $B$: Ensemble prediction update interval; $T$: Number of training steps; $\epsilon$: Label smoothing parameter; $\gamma$: Temporal ensembling momentum parameter; $\delta$: Threshold for filtering out noisy data; $\lambda_{\text{max}}$: Maximum weight (after ramp-up) of temporal ensembling regularization.
}
\vspace{1em}
\centering
\small 
% \resizebox{\columnwidth}{!}{
\begin{tabular}{*{9}{c}}
\toprule
$lr$ & $bs$ & $N|\mathcal{Y}|$ & $B$ & $T$ & $\epsilon$ & $\gamma$ & $\delta$ & $\lambda_{\text{max}}$ \\
\midrule
1e-5 & 16 & 6,000 & 100 & 1,125 & 0.15 & 0.8 & 0.8 & 10 \\
\bottomrule
\end{tabular}
% }
\label{tab:finetune_hyperpara}
\end{table}