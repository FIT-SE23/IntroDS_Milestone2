@inproceedings{elmo,
  title={Deep Contextualized Word Representations},
  author={Peters, M. and Neumann, M. and Iyyer, M. and others},
  booktitle={NAACL},
  year={2018}
}

@inproceedings{bert,
  title={{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, J. and Chang, MW and Lee, K. and others},
  booktitle={NAACL},
  year={2019}
}

@inproceedings{cpc,
    author    = {A{\"{a}}ron O. and
               Yazhe L. and
               Oriol V.},
    title     = {Representation Learning with Contrastive Predictive Coding},
    booktitle = {NIPS},
    year      = {2018},
}

@inproceedings{wav2vec,
  title={wav2vec: Unsupervised Pre-Training for Speech Recognition.},
  author={Schneider, S. and Baevski, A. and Collobert, R. and others},
  booktitle={Interspeech},
  year={2019}
}

@inproceedings{vissl,
  title={Scaling and benchmarking self-supervised visual representation learning},
  author={Goyal, P. and Mahajan, D. and Gupta, A. and others},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{caron2018deep,
  title={Deep clustering for unsupervised learning of visual features},
  author={Caron, M. and Bojanowski, P. and Joulin, A. and others},
  booktitle={ECCV},
  year={2018}
}

@article{yang2021superb,
  title={{SUPERB}: Speech processing Universal PERformance Benchmark},
  author={Yang, SW and Chi, PH and Chuang, YS and others},
  year={2021},
  journal={Interspeech}
}


@inproceedings{xu2015show,
  title={Show, attend and tell: Neural image caption generation with visual attention},
  author={Xu, K. and Ba, J. and Kiros, R. and others},
  booktitle={ICML},
  year={2015},
}

@book{yu2016automatic,
  title={Automatic speech recognition},
  author={Yu, D. and Deng, L.},
  volume={1},
  year={2016},
  publisher={Springer}
}

@inproceedings{qian2022training,
  title={Training Strategies for Automatic Song Writing: A Unified Framework Perspective},
  author={Qian, T. and Shi, J. and Guo, S. and others},
  booktitle={ICASSP},
  year={2022},
}

@inproceedings{gomez2017self,
  title={Self-supervised learning of visual features through embedding images into text topic spaces},
  author={Gomez, L. and Patel, Y. and Rusinol, M. and others},
  booktitle={CVPR},
  year={2017}
}

@article{banerjee2020self,
  title={Self-supervised vqa: Answering visual questions using images and captions},
  author={Banerjee, P. and Gokhale, T. and Yang, Y. and others},
  journal={arXiv preprint arXiv:2012.02356},
  year={2020}
}

@article{baevski2019effectiveness,
  title={Effectiveness of self-supervised pre-training for speech recognition},
  author={Baevski, A. and Auli, M. and Mohamed, A.},
  journal={arXiv preprint arXiv:1911.03912},
  year={2019}
}

@inproceedings{chang2021exploration,
  title={An exploration of self-supervised pretrained representations for end-to-end speech recognition},
  author={Chang, X. and Maekaku, T. and Guo, P. and others},
  booktitle={ASRU},
  year={2021},
}

@article{coucke2018snips,
  title={Snips voice platform: an embedded spoken language understanding system for private-by-design voice interfaces},
  author={Coucke, A. and Saade, A. and Ball, A. and others},
  journal={arXiv preprint arXiv:1805.10190},
  year={2018}
}

@inproceedings{yeh2018unsupervised,
  title={Unsupervised Speech Recognition via Segmental Empirical Output Distribution Matching},
  author={Yeh, CK and Chen, J. and Yu, C. and others},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{chen2019completely,
  title={Completely Unsupervised Phoneme Recognition by a Generative Adversarial Network Harmonized with Iteratively Refined Hidden Markov Models.},
  author={Chen, KY and Tsai, CP and Liu, DR and others},
  booktitle={Interspeech},
  year={2019}
}

@inproceedings{liu2020towards,
  title={Towards unsupervised speech recognition and synthesis with quantized speech representation learning},
  author={Liu, AH and Tu, T. and Lee, HY and others},
  booktitle={ICASSP},
  year={2020},
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, A. and Zhou, Y. and Mohamed, A. and others},
  journal={NIPS},
  volume={33},
  year={2020}
}

@article{dinarelli2022toward,
  title={Toward Low-Cost End-to-End Spoken Language Understanding},
  author={Dinarelli, M. and Naguib, M. and Portet, F.},
  journal={arXiv preprint arXiv:2207.00352},
  year={2022}
}

@article{borgholt2021we,
  title={Do We Still Need Automatic Speech Recognition for Spoken Language Understanding?},
  author={Borgholt, L. and Havtorn, JD and Abdou, H. and others},
  journal={arXiv preprint arXiv:2111.14842},
  year={2021}
}

@article{chang2022exploration,
  title={An Exploration of Prompt Tuning on Generative Spoken Language Model for Speech Processing Tasks},
  author={Chang, KW and Tseng, WC and Li, SW and others},
  journal={Interspeech},
  year={2022}
}

@inproceedings{mdhaffar2022impact,
  title={Impact Analysis of the Use of Speech and Language Models Pretrained by Self-Supersivion for Spoken Language Understanding},
  author={Mdhaffar, S. and Pelloin, V. and Caubri{\`e}re, A. and others},
  booktitle={LREC},
  year={2022}
}

@article{translation,
  title={Self-Supervised Representations Improve End-to-End Speech Translation},
  author={Wu, A. and Wang, C. and Pino, J. and others},
  journal={Interspeech},
  year={2020}
}

@article{arora2022two,
  title={Two-Pass Low Latency End-to-End Spoken Language Understanding},
  author={Arora, S. and Dalmia, S. and Chang, X. and others},
  journal={Interspeech},
  year={2022}
}

@article{lin2022dual,
  title={{DUAL}: Textless Spoken Question Answering with Speech Discrete Unit Adaptive Learning},
  author={Lin, GT and Chuang, YS and Chung, HL and others},
  journal={Interspeech},
  year={2022}
}

@inproceedings{bastianelli2020slurp,
  title={SLURP: A Spoken Language Understanding Resource Package},
  author={Bastianelli, E. and Vanzo, A. and Swietojanski, P. and others},
  booktitle={EMNLP},
  year={2020}
}

@article{baevski2021unsupervised,
  title={Unsupervised speech recognition},
  author={Baevski, A. and Hsu, WN and Conneau, A. and others},
  journal={NIPS},
  year={2021}
}

@article{liu2022towards,
  title={Towards End-to-end Unsupervised Speech Recognition},
  author={Liu, AH and Hsu, WN and Auli, M. and others},
  journal={arXiv preprint arXiv:2204.02492},
  year={2022}
}

@inproceedings{tsai2022superb,
  title={{SUPERB-SG}: Enhanced Speech processing Universal PERformance Benchmark for Semantic and Generative Capabilities},
  author={Tsai, HS and Chang, HJ and Huang, WC and others},
  booktitle={ACL},
  year={2022}
}

@article{watanabe2018espnet,
  title={{ESP}net: End-to-End Speech Processing Toolkit},
  author={Watanabe, S. and Hori, T. and Karita, S. and others},
  journal={Interspeech},
  year={2018}
}

@inproceedings{arora2022espnet,
  title={{ESP}net-{SLU}: Advancing spoken language understanding through espnet},
  author={Arora, S. and Dalmia, S. and Denisov, P. and others},
  booktitle={ICASSP},
  year={2022}
}

@inproceedings{inaguma2020espnet,
  title={{ESP}net-{ST}: All-in-One Speech Translation Toolkit},
  author={Inaguma, H. and Kiyono, S. and Duh, K. and others},
  booktitle={ACL},
  year={2020}
}

@article{busso2008iemocap,
  title={{IEMOCAP}: Interactive emotional dyadic motion capture database},
  author={Busso, C. and Bulut, M. and Lee, CC and others},
  journal={Language resources and evaluation},
  year={2008},
}

@inproceedings{wang2021covost,
  title={Co{V}o{ST} 2 and Massively Multilingual Speech Translation.},
  author={Wang, C. and Wu, A. and Gu, J. and others},
  booktitle={Interspeech},
  year={2021}
}

@inproceedings{kahn2020libri,
  title={Libri-light: A benchmark for asr with limited or no supervision},
  author={Kahn, J. and Rivi{\`e}re, M. and Zheng, W. and others},
  booktitle={ICASSP},
  year={2020},
}

@article{watanabe2017hybrid,
  title={Hybrid CTC/attention architecture for end-to-end speech recognition},
  author={Watanabe, S. and Hori, T. and Kim, S. and others},
  journal={JSTSP},
  year={2017},
}

@inproceedings{guo2021recent,
  title={Recent developments on espnet toolkit boosted by conformer},
  author={Guo, P. and Boyer, F. and Chang, X. and others},
  booktitle={ICASSP},
  year={2021},
}

@article{gulati2020conformer,
  title={Conformer: Convolution-augmented Transformer for Speech Recognition},
  author={Gulati, A. and Qin, J. and Chiu, CC and others},
  journal={Interspeech},
  year={2020}
}

@article{park2019specaugment,
  title={SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition},
  author={Park, D. and Chan, W. and Zhang, Y. and others},
  journal={Interspeech},
  year={2019}
}










%T5
@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer.},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J and others},
  journal={J. Mach. Learn. Res.},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

%Deberta
@article{he2020deberta,
  title={Deberta: Decoding-enhanced bert with disentangled attention},
  author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint arXiv:2006.03654},
  year={2020}
}

%w2v2



%wavlm


@article{chen2022wavlm,
  title={Wavlm: Large-scale self-supervised pre-training for full stack speech processing},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and others},
  journal={JSTSP},
  year={2022},
}

% longformer
@article{beltagy2020longformer,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={arXiv preprint arXiv:2004.05150},
  year={2020}
}

%xtreme-s
@article{conneau2022xtreme,
  title={XTREME-S: Evaluating Cross-lingual Speech Representations},
  author={Conneau, A. and Bapna, A. and Zhang, Y. and others},
  journal={arXiv preprint arXiv:2203.10752},
  year={2022}
}

%SpeechBERT
@article{chuang2019speechbert,
  title={SpeechBERT: Cross-modal pre-trained language model for end-to-end spoken question answering},
  author={Chuang, YS and Liu, CL and Lee, HY},
  year={2019}
}

%slue
@inproceedings{shon2022slue,
  title={Slue: New benchmark tasks for spoken language understanding evaluation on natural speech},
  author={Shon, S. and Pasad, A. and Wu, F. and others},
  booktitle={ICASSP},
  year={2022},
}

%squad
@article{rajpurkar2016squad,
  title={Squad: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, P. and Zhang, J. and Lopyrev, K. and others},
  journal={arXiv preprint arXiv:1606.05250},
  year={2016}
}

% newsqa
@article{trischler2016newsqa,
  title={New{SQA}: A machine comprehension dataset},
  author={Trischler, A. and Wang, T. and Yuan, X. and others},
  journal={arXiv preprint arXiv:1611.09830},
  year={2016}
}

% quac
@article{choi2018quac,
  title={Qu{AC}: Question answering in context},
  author={Choi, E. and He, H. and Iyyer, M. and others},
  journal={arXiv preprint arXiv:1808.07036},
  year={2018}
}

%LongT5
@article{guo2021longt5,
  title={Longt5: Efficient text-to-text transformer for long sequences},
  author={Guo, Mandy and Ainslie, Joshua and Uthus, David and others},
  journal={arXiv preprint arXiv:2112.07916},
  year={2021}
}


%ST MT
@inproceedings{tang2021general,
  title={A general multi-task learning framework to leverage text data for speech to text tasks},
  author={Tang, Yun and Pino, Juan and Wang, Changhan and others},
  booktitle={ICASSP},
  year={2021},
}



%EncT5
@article{liu2021enct5,
  title={EncT5: Fine-tuning T5 Encoder for Non-autoregressive Tasks},
  author={Liu, Frederick and Shakeri, Siamak and Yu, Hongkun and Li, Jing},
  journal={arXiv preprint arXiv:2110.08426},
  year={2021}
}

%LibriSpeech
@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and others},
  booktitle={ICASSP},
  year={2015},
}

%longformer
@article{beltagy2020longformer,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={arXiv preprint arXiv:2004.05150},
  year={2020}
}

%bert
@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

% mt5
@article{liu2020multilingual,
  title={Multilingual denoising pre-training for neural machine translation},
  author={Liu, Yinhan and Gu, Jiatao and Goyal, Naman and others},
  journal={TACL},
  year={2020},
}

% Splat
@article{chung2020splat,
  title={Splat: Speech-language joint pre-training for spoken language understanding},
  author={Chung, Yu-An and Zhu, Chenguang and Zeng, Michael},
  journal={arXiv preprint arXiv:2010.02295},
  year={2020}
}

@article{tang2021improving,
  title={Improving speech translation by understanding and learning from the auxiliary text translation task},
  author={Tang, Yun and Pino, Juan and Li, Xian and others},
  journal={arXiv preprint arXiv:2107.05782},
  year={2021}
}

@inproceedings{huang2022mtl,
  title={MTL-SLT: Multi-Task Learning for Spoken Language Tasks},
  author={Huang, Zhiqi and Rao, Milind and Raju, Anirudh and Zhang, Zhe and Bui, Bach and Lee, Chul},
  booktitle={Proceedings of the 4th Workshop on NLP for Conversational AI},
  pages={120--130},
  year={2022}
}

%BART
@article{lewis2019bart,
  title={Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1910.13461},
  year={2019}
}

@article{li2020multilingual,
  title={Multilingual speech translation with efficient finetuning of pretrained models},
  author={Li, Xian and Wang, Changhan and Tang, Yun and others},
  journal={arXiv preprint arXiv:2010.12829},
  year={2020}
}

@article{kao2021bert,
  title={Is BERT a Cross-Disciplinary Knowledge Learner? A Surprising Finding of Pre-trained Models' Transferability},
  author={Kao, Wei-Tsung and Lee, Hung-Yi},
  journal={arXiv preprint arXiv:2103.07162},
  year={2021}
}


@article{DBLP:journals/corr/abs-2004-10964,
  author    = {Suchin Gururangan and
               Ana Marasovic and
               Swabha Swayamdipta and
               Kyle Lo and
               Iz Beltagy and
               Doug Downey and
               Noah A. Smith},
  title     = {Don't Stop Pretraining: Adapt Language Models to Domains and Tasks},
  year      = {2020},
}

%GLUE
@article{DBLP:journals/corr/abs-1804-07461,
  author    = {Alex Wang and
               Amanpreet Singh and
               Julian Michael and
               Felix Hill and
               Omer Levy and
               Samuel R. Bowman},
  title     = {{GLUE:} {A} Multi-Task Benchmark and Analysis Platform for Natural
               Language Understanding},
  journal   = {CoRR},
  year      = {2018},
}

@inproceedings{chung2021splat,
  title={{SPLAT}: Speech-Language Joint Pre-Training for Spoken Language Understanding},
  author={Chung, YA and Zhu, C. and Zeng, M.},
  booktitle={NAACL},
  year={2021}
}

@inproceedings{lai2021semi,
  title={Semi-supervised spoken language understanding via self-supervised speech and language model pretraining},
  author={Lai, CI and Chuang, YS and Lee, HY and others},
  booktitle={ICASSP},
  year={2021},
}

@inproceedings{huang2020leveraging,
  title={Leveraging unpaired text data for training end-to-end speech-to-intent systems},
  author={Huang, Y. and Kuo, HK and Thomas, S. and others},
  booktitle={ICASSP},
  year={2020},
}

@article{xue2022byt5,
  title={By{T}5: Towards a token-free future with pre-trained byte-to-byte models},
  author={Xue, L. and Barua, A. and Constant, N. and others},
  journal={TACL},
  year={2022},
}

@article{bapna2021slam,
  title={SLAM: A unified encoder for speech and language modeling via speech-text joint pre-training},
  author={Bapna, A. and Chung, YA and Wu, N. and others},
  journal={arXiv preprint arXiv:2110.10329},
  year={2021}
}

@article{phonemet5,
  author = {Hsu, CJ and Chung, HL and Lee, HY and others},
  title = {T5lephone: Bridging Speech and Text Self-supervised Models for Spoken Language Understanding via Phoneme level T5},
  journal={arXiv preprint arXiv:2211.00586},
  year = {2022},
}


@article{bapna2022mslam,
  title={mSLAM: Massively multilingual joint pre-training for speech and text},
  author={Bapna, A. and Cherry, C. and Zhang, Y. and others},
  journal={arXiv preprint arXiv:2202.01374},
  year={2022}
}