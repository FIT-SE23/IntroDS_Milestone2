

\section{Background and Related Work}\label{sec:related_work}




\begin{table*}
%   \small
\centering
\caption{Terminology and description regarding different model types and approaches.}
\label{tab:terminology}
\resizebox{\textwidth}{!}{%
\begin{tabular}{>{\arraybackslash}m{2.1cm} >{\arraybackslash}m{15cm}}

\rowcolor{Gray2!20}
\textbf{\makecell[l]{Terminology}}  & 
\textbf{Description} 
\\

\arrayrulecolor{Gray}



Population-Level Model (PLM) &
Training and Testing splits have a disjoint set of users. Represents a case where a machine learning model trained with a population is deployed to a mobile app that is used by a new user. Hence, end user data are not used in model training leading to non-personalized and generic one-size-fits-all models.\\

\rowcolor{Gray!15}
Hybrid Model (HM)&
Training and testing splits do not have a disjoint set of users. Represent a case where a machine learning model is used by a mobile app user for some time, and data from the user is used in re-training models. Hence, this approach leads to partially personalized models. \\

\hline 


\textcolor{black}{Country-Specific} &
\textcolor{black}{This approach uses training and testing data from the same country. 
%It is the least diverse approach,
Each country has its own model, without leveraging data from other countries. As the name indicates, these models are specific to each country (e.g., a model trained in Italy and tested in Italy). Both population-level and hybrid model types can be trained in the country-specific approach.}\\

\rowcolor{Gray!15}
\textcolor{black}{Continent-Specific} &
\textcolor{black}{This approach uses training and testing data from the same continent. Each continent has its own model, without leveraging data from other continents. As the name indicates, these models are specific to each continent (e.g., a model trained in Europe and tested in Europe). Continent specific approach can be trained with population-level and hybrid models.}\\


\textcolor{black}{Country-Agnostic} &
\textcolor{black}{This approach assumes that data and models are agnostic to the country. Hence, a trained model can be deployed to any geographical region regardless of the country of training. Country-agnostic approach too can be trained with population-level and hybrid models. There are two types of country-agnostic settings:\newline (1) Country-Agnostic I: The first setting uses training data from one country, and testing data from another country. This corresponds to the scenario where a model trained a in country already exists, and we need to understand how it would generalize to a new country (e.g. a model trained in Italy and tested in Mongolia). \newline (2) Country-Agnostic II: The second setting  uses training data from four countries, and testing data from the remaining country. This corresponds to a scenario where the model was already trained with data from several countries, and we need to understand how it would generalize to a new country (e.g. a model trained with data from Italy, Denmark, UK, and Paraguay, and tested in Mongolia).} \\


\rowcolor{Gray!15}
\textcolor{black}{Multi-Country}&
\textcolor{black}{This one-size-fits-all approach uses training data from all eight countries and tests the learned model in all countries. This corresponds to the setting in which multi-country data is aggregated to build a single model. However, this is also how models are typically built without considering aspects such as geographical diversity. Multi-Country models too can be trained with population-level and hybrid approaches.} \\


\arrayrulecolor{Gray2}
\hline 


 
\end{tabular}
}
\end{table*} 

\subsection{Definitions and Terminology}

\subsubsection{What is Mood?} 

There is no single way to define mood \cite{dissanayake2022sigrep}. However, in prior work in mobile sensing, some operationalizations have been commonly used. Positive Negative Affect Schedule (PANAS) is a widely used validated questionnaire that can be used to capture the positive and negative affect of individuals \cite{kanjo2017notimind}. \textcolor{red}{In addition, the Patient Health Questionnaire (PHQ-9) has been used in the past to quantify depressive mood with mobile sensing \cite{wahle2016mobile}}. However, these questionnaires are long and could be cumbersome to users \cite{likamwa2013moodscope}. Further, they can capture mood over the past week (or two), \textcolor{red}{and might not be suitable to measure the in-situ mood for long time periods}. Hence, prior work has also used an affect grid based on the circumplex mood model \cite{servia2017mobile, likamwa2013moodscope} that would capture the \emph{valence} and \emph{arousal}. As described in later sections, due to pragmatic reasons, the data collection in this study does not focus on arousal because positive and negative affects of the circumplex model are important in determining negative moods that could be useful for adverse mental well-being related outcome detection, feedback, and interventions \cite{baumel2019objective,schueller2021understanding}. Hence, only \emph{valence} has been captured in a five-point scale: very positive (\includegraphics[scale=0.13]{images/verypositive.PNG}), positive (\includegraphics[scale=0.13]{images/positive.PNG}), neutral (\includegraphics[scale=0.13]{images/neutral.PNG}), negative (\includegraphics[scale=0.13]{images/negative.PNG}), very negative (\includegraphics[scale=0.13]{images/verynegative.PNG}). This five-point scale is similar to LiKamwa et al. \cite{likamwa2013moodscope} and Horlings et al. \cite{horlings2008emotion}. For inference, we reduce the five-point scale to two-point and three-point scales similar to prior work \cite{wampfler2022affective, dissanayake2022sigrep, brown2011towards}. This is usually done based on the idea that in mood inference, the more important aspect is to detect extreme moods (i.e., negative, positive) rather than to identify all fine-grained intermediate mood levels in the middle of the spectrum \cite{horlings2008emotion}. First, obtaining a three-point scale using the five-point scale was obvious by combining very positive and positive to positive; neutral as it is; and negative and very negative to negative, hence having three classes \cite{wampfler2022affective, soleymani2011multimodal}. However, for two-class inference, the categorization is not as obvious. Some prior studies have removed the class in the middle (i.e., neutral), hence obtaining positive and negative labels \cite{zhang2020corrnet, horlings2008emotion}. Even though it is possible to do it with the available classes in the dataset, we believe it would lead to a biased classifier that would not perform reasonably well when exposed to data corresponding to neutral mood labels. Hence, we followed prior work that binned very positive, positive, and neutral moods as positive; and negative and very negative moods as negative \cite{zhang2020corrnet, brown2011towards}. This two-class inference also allows for detecting negative moods, which is useful in mobile health apps for feedback and interventions \cite{baumel2019objective,schueller2021understanding} because it is such negative moods, along with other aspects like stress that could be harmful to individuals on the long term. Hence, in the scope of this paper, mood can be defined as \emph{the instantaneous valence reported by study participants on a five-point scale (from very positive (\includegraphics[scale=0.13]{images/verypositive.PNG}) to very negative (\includegraphics[scale=0.13]{images/verynegative.PNG})), reduced to either a two-point scale corresponding to positive and negative classes or a three-point scale corresponding to positive, neutral, and negative classes, for inference using smartphone sensing data.}

\subsubsection{Model Types and Approaches.}

This section introduces the definitions and terminology used in this paper, as summarized in Table~\ref{tab:terminology}. In terms of model types, we use population-level (subject-independent) and hybrid models \cite{ferrari2020personalization, bangamuarachchi2022sensing, likamwa2013moodscope}. While population-level models are not personalized, hybrid models are partially personalized. The operationalization of models is described in Section~\ref{sec:inference}. Second, in terms of approaches, we consider the country-specific approach that is trained and tested within each country; the continent-specific approach that is trained and tested within each continent; the country-agnostic approach in which models are trained in one or more countries, and tested in an unseen country; and the multi-country approach that would ignore the diversity in terms of countries, and train a one-size-fits-all model considering data from all countries. As an important note, all these approaches can be evaluated with both population-level and hybrid model types. For example, in a country-specific setting, imagine a model trained with a certain population in Italy and tested with some new users in Italy, hence examining the model performance on new users from the same country. This is equivalent to a population-level model of the country-specific approach. Then, imagine the set of unseen users producing data for model training after using a mobile app for some time, and these data points being used to update the model. This would then lead to a hybrid model of the country-specific approach. Similarly, for the country-agnostic approach, a model trained in Italy deployed to unseen users in Paraguay is similar to evaluating a population-level model. Then, imagine the users in Paraguay providing some data for model personalization. This leads to a hybrid model created with a mix of data from Italy and Paraguay that can be evaluated on new data points from users in Paraguay, whose data were used in model training. While this model too can be called a multi-country model, for ease of understanding in the scope of this paper, we would still call it a hybrid model with the country-agnostic approach. Using the combination of model types and approaches, we can examine the effect of personalization (with model types) and model generalization to new countries (with the four approaches), hence uncovering distributional shift-related issues of multi-modal mobile sensing datasets for mood inference. 



\subsection{Considerations for Research in Mobile Sensing Involving Geographic Diversity}

\subsubsection{Mood and Geographical Diversity} 

Across different geographical regions and cultures, behavior is mediated by inherent beliefs, presses, and affordances of physical and/or socio-cultural environments \cite{phan2022mobile}. Even for behaviors that are similar across cultures, the psychological meaning of those behaviors might not be the same due to \cite{phan2022mobile}: (a) Certain behaviors that are acceptable in certain countries/cultures are not perceived as normative or appropriate in other countries \cite{van2004bias}; (b) The same behavior might be indicative of different outcomes/functions. For example, while cycling is everyday behavior in certain regions (e.g., Aalborg, Denmark), it might only be used for exercise in other areas (e.g., Ulanbatoor, Mongolia); and (c) Different behaviors might be indicative of a similar outcome/function. For example, while people in some countries might perform cycling for exercise, people in other countries might prefer going to the gym for exercise. Why people cycle will depend on many contextual and cultural factors such as road safety, availability of public transport, alternative exercise options, weather conditions, and perceptions about cycling in a specific geographical region. Given that smartphone sensors can capture such physical activities (e.g., Google Activity Recognition API \cite{GoogleActivity2022} and other activity engines built by researchers \cite{wang2014studentlife}) and are used to infer more complex variables \cite{canzian2015trajectories, wang2014studentlife}, invariably, such behavioral differences across geographical areas could affect mood inference models that leverage activity data from accelerometers and location \cite{phan2022mobile}. In addition, device-mediated behavior or phone usage behavior could also vary between geographical areas depending on cultural norms, weather conditions (e.g., the phone usage behavior while walking outside in a cold vs. a hot country), network coverage, and subscription plans (e.g., people in countries where internet plans are expensive might turn off internet frequently, people in countries where the used phones are old might turn off Wifi and location sensors often to save battery of the phone, etc.), and availability of alternative equipment that could serve similar functionality (e.g., using a laptop for zoom calls instead of the phone, hence showing differences in the sensed app usage behavior). Given that mood inference models in prior work have used both continuous (activity types, step counts, location, proximity, wifi, etc.) and interaction (typing and touch events, user presence, application usage, screen on and off events, etc.) sensing modalities to examine/infer mood and related psychological constructs, how behaviors and contexts captured with smartphones affect mood inference in different countries is worth investigating. 

\subsubsection{Studies about Psychological Constructs and Geographical Diversity.} According to Khwaja et al. \cite{khwaja2019modeling}, psychological mobile sensing research aims to quantify and measure constructs related to mood, stress, depression, and user personality over the last decade due to the advancement of sensing technologies. Even though there is a myriad of studies about such psychological aspects, ranging from clinical to non-clinical studies, many have focused on a population within a single country \cite{phan2022mobile}. In addition, even when the construct of analysis used in studies is the same (e.g., circumplex mood model, positive-negative affect schedule, etc.), comparing different studies across countries is complicated because data have been collected using different protocols and sensing modalities \cite{adler2022machine}. Furthermore, Phan et al. \cite{phan2022mobile} have discussed how prior psychology studies in mobile sensing have collected data focusing on WEIRD samples (Western, Educated, Industrialized, Rich, and Democratic) and paid less attention to the global south. This has also been highlighted in a review study on smartphone sensing by Meegahapola et al. \cite{meegahapola2020alone}. For these reasons, prior work has emphasized the need for studies that examine the generalization of models across countries/cultures by building diversity-aware approaches to machine learning-based modeling of sensor data \cite{meegahapola2020smartphone, bardram2020decade}. According to a recent review by Phan et al. \cite{phan2022mobile}, only Khwaja et al. \cite{khwaja2019modeling} have considered the cultural diversity of smartphone sensing-based models on psychological aspects, where they studied personality traits based on Big-Five model. In that study, the authors collected data from 166 participants from five countries (UK, Spain, Colombia, Peru, and Chile). They showed that country-specific models perform the best, regardless of the gender or age balance, for the prediction of Extraversion, Agreeableness, and Conscientiousness. Compared to that study, we also collected data from multiple countries. However, our primary focus is on studying mood inference models that could vary from time to time, even within the same person (more dynamic), instead of stable personality traits. In addition, Muller et al. \cite{muller2021depression} used mobile GPS data to predict depression in socio-demographically homogeneous sub-samples within the USA. They trained algorithms for the whole sample and homogeneous sub-samples (e.g., highly educated men, women residing in rural regions, etc.) and tested within and across sub-samples. They found that the technique that led to high AUROC scores for student populations (0.82), did not generalize well to the USA-wide population-level model (AUROC of 0.57). In contrast, our work focuses on valence instead of depressive mood. In addition, rather than concentrating on socio-demographic differences within a particular country, we focus on cross-country differences.  

\subsection{Mood and Smartphone Technologies}

\subsubsection{Mood Tracking with Self-Reports} 

In the early days, mobile phone-based mood charts were used to track the mood of individuals. These are based on self-reported questionnaires and ecological momentary assessment (EMA) responses \cite{chan2018asynchronous, meegahapola2020smartphone}. Similar to how mobile food diaries were designed for people who wanted to control their diet \cite{meegahapola2021one}, mood charts were designed to support people who wanted to control negative moods and increase self-awareness, allowing for monitoring and feedback \cite{baumel2019objective,schueller2021understanding}. With randomized controlled trials, some studies explored the usefulness and efficacy of self-report-based mood tracking and showed that engaging in mood tracking tools increases self-awareness, hence reducing the possibility of having anxiety, even within clinically depressed populations \cite{bakker2018moodprism, birney2016moodhacker}. Going beyond applications related to health and well-being, Glasgow et al. discussed how aspects like destinations, travel choices, and social ambiance are related to mood \cite{glasgow2019travel}. Further, in this context, prior work that uses mood tracking has focused on different populations such as college students \cite{lee2018destressify, wang2014studentlife}, adolescents \cite{kenny2015copesmart} and clinically diagnosed, high-risk populations with mental well-being related issues \cite{wang2016crosscheck, faherty2017pregnancy, mark2008chart}. Hence, most prior studies relied on user engagement to keep track of mood. This could be a burden to users in the long run, and it is known that apps that require many self-reports do not have high adoption rates. In our work, even though we captured self-reports about mood, they were captured as ground-truth labels to train classifiers with sensor data for mood inference. Such inferences could be used to update mood-tracking applications that could be used to provide context-aware interventions, and feedback to users, with less user burden \cite{servia2017mobile}.   




\subsubsection{Mood Tracking with Sensing.} 

Mobile phone sensors allowed researchers to build context-aware systems that could infer various aspects regarding the health and well-being of people \cite{lane2010survey}. Most of such studies rely on using features captured from sensors in smartphones as proxies to personal attributes (mood, stress, etc.), behavior (eating, drinking, running, walking, etc.), and context (social context, semantic location, ambiance, etc.) \cite{meegahapola2020smartphone}. Hence, there are studies that infer aspects like mood \cite{servia2017mobile, likamwa2013moodscope}, stress \cite{lu2012stresssense, sano2013stress}, depression \cite{canzian2015trajectories, farhan2016behavior}, eating behavior \cite{meegahapola2021one,biel2018bites}, drinking behavior \cite{santani2018drinksense}, activity types \cite{morales2017physical}, and social contexts \cite{meegahapola2021examining, meegahapola2020alone}, among many others. If we specifically focus on mood-related studies, LiKamwa et al. \cite{likamwa2013moodscope} showed that the mood of individuals captured with the circumplex mood model could be inferred with an accuracy of 66\% with all user models (population-level), which can be increased up to 93\% using personalization (user-level) with a dataset collected from 32 individuals. They suggested that building hybrid models (partially personalized) would help overcome the drawbacks of both population-level and user-level models. Servia-Rodr√≠guez et al. \cite{servia2017mobile} collected a large-scale dataset of mood self-reports and passive sensing data from multiple countries. They also showed that binary mood captured with the circumplex mood model could be inferred with an accuracy of 70\% with population-level models. Some studies examined mood instability derived using mood reports, with phone sensor data \cite{morshed2019prediction, zhang2019inferring}. In our work, we look into inferring mood valence with population-level and hybrid models. However, we are more interested in examining (a) the similarities and differences in mood models for different countries; and (b) the generalization of models to unseen countries, both of which have not been examined in prior work. Further, as Bardram et al. \cite{bardram2020decade} highlighted, there is a lack of reproducibility and generalization of machine learning models across studies in this domain. We believe the results presented in this study would be a step in the right direction for better awareness of these issues in examining the characteristics and generalization of smartphone sensing-based mood inference models across different geographical regions. 



