
\section{Mood Inference (RQ2 \& RQ3)}\label{sec:inference}

\subsection{Experimental Setup}

The primary goal of this paper is to investigate aspects related to mood inference, personalization, and generalization to different countries using smartphone sensing data. As described and defined in Figure~\ref{fig:overview} and Table~\ref{tab:terminology}, we use two model types: population-level and hybrid, to examine personalization to individuals, and four modeling approaches: country-specific, continent-specific, country-agnostic, and multi-country, to examine generalization and country-wise performance. Hence, this section will describe the operationalization of the experimental protocol. 

We used python with scikit-learn \cite{pedregosa2011scikit} and Keras \cite{chollet2015keras} frameworks to conduct all experiments. Initially, we conducted country-specific experiments with different model types such as random forest (RF), gradient boosting, support vector classification, XGBoost, AdaBoost, and multi-layer perceptron neural networks \cite{rf_inbook, rish2001empirical, natekin2013gradient, chen2016xgboost, schapire2013explaining, noble2006support}. We obtained the best results for a larger majority of inferences with RFs. In addition, these models allow interpreting results better because they provide Gini feature importance values for trained models. Because of these reasons and space limitations, we will only report results for RF models with default parameters in this paper \footnote{Note that we also tried out GridSearch for parameters in the random forest (for n\_estimators: 50, 100-2000 with intervals of 100, max\_depth: 2-16 with intervals of 2, min\_samples\_split: 2-10) that did not yield better performance than the default parameters (n\_estimators: 100, max\_depth: NA, min\_samples\_split: 2), except in a few cases. Hence, we used default parameters for all experiments for consistency.}. Further, to fill in missing values of the dataset, we used k-nearest-neighbor (kNN) imputation \cite{beretta2016nearest, zhou2018missing}. In addition, we report all the results with the area under the receiver operating characteristic curve (AUROC) \cite{bradley1997use} because they provide a better assessment of performance when dealing with imbalanced data (when used with macro averaging which gives equal emphasis to all classes in an inference). While we provided a basic description of model types in Table~\ref{tab:terminology}, the operationalization of models is given below. 

\begin{itemize}
    \item \textbf{Population-Level Models (PLM)}: Since this represents a scenario where models are deployed to a set of users unseen in model training, we use the leave-n-participants-out strategy when testing models. This is an extension of leave-one-out cross-validation, where we consider $n$ users in testing instead of one. Hence, if the number of users in the considered population is $N$, we pick $n$ such that it is roughly 20\% of $N$ (can be obtained with group-k-fold cross-validation with k = 5 in scikit-learn). So, for each $n$ user in the testing split, 50\% of their data would be used for testing to be coherent with hybrid models (stratified based on users and mood labels), and data from the rest of the $N-n$ users would be used for the training split. Then, experiments were repeated ten times by randomly sampling $n$ users, and the results were averaged. 
    
    \item \textbf{Hybrid Models (HM)}: Since this represents a scenario where models are deployed to a set of users already seen in model training (hence partially personalized models), we first use the leave-n-participants-out strategy similar to PLM. So, for each $n$ user in the testing split, data from the rest of the $N-n$ users would be used for the training split. In addition, 50\% of the data from the testing split (stratified based on users and mood labels) would be included in the training set to represent partial personalization. In addition, an equal number of data points to the number of data points added to the training set from the testing set would be removed randomly to make the number of data points in the training and testing sets for HM and PLM equal making them more comparable. Finally, experiments were repeated ten times by randomly sampling $n$ users, and the results were averaged. 
\end{itemize}

Using the above two model types, we conducted the experiments using four approaches. The country-specific approach examines how models trained within a country perform. We examine both PLM and HM types for this approach, hence examining the personalization within countries. The country-agnostic approach examines how models trained in one or a few countries generalize to a new country. With PLM and HM model types, we examine how personalization affects model performance when models are deployed to countries unseen on training data. The multi-country approach is similar to a one-size-fits-all model trained with data from all available countries. This is similar to a model in which country diversity is ignored. Both PLM and HM model types were used to examine the effects of personalization on model performance.
    

%\begin{wraptable}{t}{8cm}
\begin{table}
    \caption{{Country-Specific and Multi-Country results with PLM and HM: }Mean ($\bar{S}$) and Standard Deviation ($S_\sigma$) AUROC scores computed from ten iterations. Results are presented as $\bar{S} (S_\sigma)$, where $S$ is AUROC.}
    \label{tab:specific-results}
    \resizebox{0.65\textwidth}{!}{%
    \begin{tabular}{l l l l l}
     
     
    &
    \multicolumn{2}{c}{\cellcolor[HTML]{EDEDED}\textbf{PLM}}&
    \multicolumn{2}{c}{\cellcolor[HTML]{EDEDED}\textbf{HM}} \\
    
    &
    \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Two-Class}} &
    \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Three-Class}} &
    \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Two-Class}} &
    \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Three-Class}} 
    \\
    
    \arrayrulecolor{Gray}
    \hline
    
    %& 
    %\textit{F1} &
    %\textit{AUROC} &
    %\multicolumn{1}{l}{\textit{F1}} &
    %\multicolumn{1}{l}{\textit{AUROC}} 
    %\\
    
    Baseline &
    .50 (.00) & % Baseline 1
    .50 (.00) & % XGBoost
    .50 (.00) & % Baseline 1
    .50 (.00)  % XGBoost
    \\
    
    \hline 
    
    China &
    .51 (.04) & % Random Forest
    .45 (.04) & % MLP
    .78 (.02) & % Random Forest
    .79 (.01)  % MLP
    \\
    
    Denmark &
    .41 (.10) & % 2-class
    .56 (.03) & % MLP
    .83 (.03) & % Random Forest
    .86 (.01)  % MLP
    \\
    
    India &
    .46 (.15) & % Random Forest
    .45 (.04) & % MLP
    .79 (.03) & % Random Forest
    .76 (.02)  % MLP
    \\
    
    Italy &
    .55 (.05) & % Random Forest
    .52 (.01) & % MLP
    .82 (.01) & % Random Forest
    .81 (.00)  % MLP
    \\
    
    Mexico &
    .62 (.21) & % Random Forest
    .62 (.13) & % MLP
    .98 (.01) & % Random Forest
    .94 (.01) % MLP
    
    \\
    
    Mongolia &
    .49 (.08) & % Random Forest
    .49 (.02) & % MLP
    .85 (.01) & % Random Forest
    .83 (.00) % MLP
    \\
    
    Paraguay &
    .48 (.08) & % Random Forest
    .53 (.01) & % MLP
    .84 (.01) & % Random Forest
    .84 (.01) % MLP
    \\
    
    UK &
    .56 (.05) & % Random Forest
    .52 (.05) & % MLP
    .91 (.01) & % Random Forest
    .87 (.00) % MLP
    \\
    
    \hline 
    
    Aggregate &
    .51 (.10) & % Random Forest
    .52 (.04) & % MLP
    .85 (.02) & % Random Forest
    .84 (.01) % MLP
    \\
    
    
    %\hline 
    
    Multi-Country &
    .52 (.03) & % Random Forest
    .53 (.02) & % MLP
    .83 (.01) & % Random Forest
    .79 (.00) % MLP
    \\
    
    Multi-Country (Balanced) &
    .53 (.02) & % Random Forest
    .52 (.03) & % MLP
    .81 (.03) & % Random Forest
    .78 (.02) % MLP
    \\
    
    \arrayrulecolor{Gray2}
    \hline 
    
    
    \end{tabular}%
    }
%\end{wraptable}
\end{table}

\subsection{Results}

\subsubsection{Country-Specific Models} In Table~\ref{tab:specific-results}, we show country-specific results with PLM and HM. In addition, we also show the aggregate results from country-specific (as `Aggregate') and multi-country models. Under `Multi-Country (Balanced)', we use an equal number of data points from each country (equal to the country with the minimum number of data points, which is India) by randomly sampling when training and testing models. The results show that PLMs do not perform well for two and three-class inferences. Models in Mexico performed better than in other countries. These results are reasonable because many features in Mexico had medium to large effect sizes, as shown in Figure~\ref{fig:statistics}. However, HM results show that they perform better than PLMs, showing the usefulness of personalization within each country. With HMs, the performance for two-class inference almost doubled for Denmark, and even for other countries, the AUROC bump was above 30\%. These results suggest that for both two-class and three-class inferences, partial personalization within each country leads to significant improvements in performance. When the aggregate results of country-specific models are compared with multi-country models, PLMs do not show a significant difference. However, with HMs, it is clear that country-specific models outperform multi-country models by 2\% for two-class and 5\% for three-class. This suggests that model personalization within countries leads to better performance when compared to the personalization of one-size-fits-all models. This is reasonable given that we are reducing the distributional shift by only considering data within a country and adding an effect of personalization by being geographically diversity-aware. In addition, the `Multi-Country' approach performed slightly better than the `Multi-Country (Balanced)' case. This could be because, in the imbalanced case, models favor countries with more data points, such as Italy and Mongolia, leading to a slight increase in performance for those countries that occupy a majority of the dataset. Furthermore, regardless of whether it is a two/three-class inference, the performance of models did not degrade much.

\subsubsection{Country-Agnostic I Models} 

Next, we examine the country-agnostic approach. Table~\ref{tab:agnostic-two-class} and Table~\ref{tab:agnostic-three-class} show the results for two-class and three-class inferences, respectively. In both tables, we first show results for models trained in specific countries when tested on an unseen country in the form of a matrix with an empty diagonal. Then, under `Aggregate', we show the aggregate value of those results for each training country (e.g., PLM performance for models trained in China when deployed to other countries). In addition, we calculated AUROC scores for the same set of models with partial personalization (all the results are not shown here due to space limitations), and similar to the aggregate of PM, we show the aggregate values under HM. Results show that PLMs do not generalize well to new countries with AUROCs of 0.47 - 0.52. However, these results are on par with PLM accuracies in country-specific and multi-country approaches. This suggests that regardless of the country from where sensing data were obtained to train models for mood inference, PLMs performed similarly. However, HM results convey an opposite conclusion for two and three-class inferences. For the two-class inference, the country-specific approach had AUROC scores in the range of 0.78-0.98, whereas the country-agnostic approach yielded scores in the range of 0.66-0.73. A similar pattern can be seen for three-class inference, where scores dropped from 0.76-0.94 to 0.65-0.71. This shows that the effect of personalization achieved with HMs is strong for the country-specific approach, whereas country-agnostic models still did not generalize well. However, we also noticed that with HMs for both two-class and three-class inferences, models trained in European countries consistently performed better in other European countries than the rest. For example, in the two-class inference, the Italian model had AUROC scores of 0.76 and 0.78 in Denmark and the UK, respectively. In contrast, the next best score for the Italian model was 0.70 in India. Finally, for three-class inference, the UK model had AUROC scores of 0.73 and 0.75 for Italy and Denmark, respectively, whereas the next best score was 0.69 for Paraguay. These results could be partly justified given that European countries have somewhat closer everyday patterns that could get captured in the models.





















\begin{table}
    \caption{{Country-Agnostic I PLM \& HM: }Two-Class Inference -- Mean ($\bar{S}$) and Standard Deviation ($S_\sigma$) of AUROC scores obtained by testing each Country-Specific model (rows) on a new country. Results are presented as $\bar{S} (S_\sigma)$, where $S$ is AUROC score. Aggregate of the reported population-level results and results from hybrid models indicated under `Aggregate'.}
    \label{tab:agnostic-two-class}
    \resizebox{0.95\textwidth}{!}{%
    \begin{tabular}{lrrrrrrrr|rr}
    
    &
    \multicolumn{8}{c}{\cellcolor[HTML]{EDEDED}\textbf{Testing (PLM)}} &
    \multicolumn{2}{c}{\cellcolor[HTML]{EDEDED}\textbf{Aggregate}} 
    \\
     
    \rowcolor[HTML]{D9D9D9} 
    \cellcolor[HTML]{EDEDED} \textbf{Training}  &
    \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{China}} & \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Denmark}} & \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{India}} & \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Italy}} &
    \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Mexico}} &
    \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Mongolia}} & \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Paraguay}} & \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{UK}} & \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{PLM}} & \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{HM}}
    \\
     
    \arrayrulecolor{Gray} 
     
     
    \hline
     
    China &
      &
    .53 (.02) &
    .44 (.03) &
    .49 (.01) &
    .58 (.05) &
    .50 (.01) &
    .42 (.03) &
    .51 (.02) &
    .55 (.02) &
    .67 (.04)
    \\
    
    Denmark &
    .51 (.00) &
    &
    .47 (.01) &
    .51 (.00) &
    .58 (.02) &
    .50 (.00) &
    .58 (.01) &
    .46 (.00) &
    .52 (.01) &
    .69 (.03)
    \\
    
    India &
    .48 (.00) &
    .37 (.00) &
     &
    .50 (.00) &
    .40 (.02) &
    .50 (.00) &
    .44 (.01) &
    .52 (.00) &
    .46 (.00) &
    .70 (.02) 
    \\
    
    
    Italy &
    .49 (.00) &
    .45 (.00) &
    .51 (.01) &
    &
    .40 (.02) &
    .51 (.01) & 
    .48 (.00) &
    .50 (.00) &
    .48 (.01) &
    .69 (.02) 
    \\
    
    Mexico &
    .49 (.00) &
    .58 (.01) &
    .44 (.01) &
    .49 (.00) &
     & 
    .49 (.01) &
    .56 (.01) &
    .47 (.01) &
    .50 (.01) &
    .73 (.03) 
    \\
    
    Mongolia &
    .49 (.00) &
    .48 (.01) &
    .52 (.00) &
    .50 (.00) &
    .51 (.00) &
     &
    .48 (.00) &
    .51 (.00) &
    .50 (.00) &
    .71 (.03) 
    \\
    
    Paraguay &
    .51 (.00) &
    .53 (.01) & 
    .49 (.01) &
    .50 (.00) &
    .55 (.02) & 
    .53 (.01) &
    &
    .50 (.01) &
    .52 (.01) &
    .70 (.02) 
    \\
    
    
    UK &
    .48 (.01) &
    .43 (.02) &
    .57 (.00) &
    .50 (.01) &
    .32 (.01) &
    .50 (.01) &
    .49 (.01) &
    & 
    .47 (.01) &
    .66 (.02) 
    \\
    
    \arrayrulecolor{Gray2}
    
    \hline
    \end{tabular}%
    }
\end{table}












\begin{table}
    \caption{{Country-Agnostic I PLM \& HM: }Three-Class Inference -- Mean ($\bar{S}$) and Standard Deviation ($S_\sigma$) of AUROC scores obtained by testing each Country-Specific model (rows) on a new country. Results are presented as $\bar{S} (S_\sigma)$, where $S$ is AUROC score. Aggregate of the reported population-level results and results from hybrid models indicated under `Aggregate'.}
    \label{tab:agnostic-three-class}
    \resizebox{0.95\textwidth}{!}{%
    \begin{tabular}{lrrrrrrrr|rr}
    
     %\rowcolor[HTML]{EFEFEF}  
     &
    \multicolumn{8}{c}{\cellcolor[HTML]{EDEDED}\textbf{Testing (PLM)}} &
    \multicolumn{2}{c}{\cellcolor[HTML]{EDEDED}\textbf{Aggregate}}  
     \\
     
     \rowcolor[HTML]{D9D9D9} 
     \cellcolor[HTML]{EDEDED} \textbf{Training}  &
     \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{China}} & \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Denmark}} & \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{India}} & \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Italy}}  &
     \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Mexico}} &
     \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Mongolia}} & \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Paraguay}} & \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{UK}} & \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{PLM}} & \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{HM}}
     \\
     
     
     \arrayrulecolor{Gray}
    \hline
     
     
    China &
     &
    .48 (.01) &
    .54 (.01) &
    .48 (.01) &
    .47 (.01) &
    .50 (.01) &
    .51 (.01) &
    .50 (.00) &
    .50 (.01) &
    .68 (.02) 
    \\
    
    Denmark &
    .52 (.01) &
    &
    .41 (.02) &
    .56 (.01) &
    .54 (.04) &
    .51 (.01) &
    .50 (.02) &
    .58 (.01) &
    .52 (.02) &
    .66 (.04) 
    \\
    
    India &
    .52 (.01) &
    .42 (.02) &
     &
    .52 (.01) &
    .38 (.02) &
    .52 (.01) &
    .52 (.01) &
    .38 (.01) &
    .47 (.01) &
    .68 (.03) 
    \\
    
    Italy &
    .52 (.01) &
    .49 (.01) &
    .47 (.02) &
    &
    .32 (.02) &
    .51 (.01) & 
    .51 (.00) &
    .54 (.00) &
    .48 (.01) &
    .69 (.02) 
    \\
    
    Mexico &
    .49 (.00) &
    .59 (.00) &
    .44 (.00) &
    .47 (.00) &
    & 
    .50 (.00) &
    .61 (.00) &
    .54 (.00) &
    .52 (.00) &
    .71 (.02) 
    \\
    
    Mongolia &
    .49 (.00) &
    .50 (.00) &
    .43 (.00) &
    .51 (.00) &
    .55 (.00) &
    &
    .54 (.00) &
    .53 (.00) &
    .51 (.00) &
    .67 (.02) 
    \\
    
    Paraguay &
    .44 (.01) &
    .51 (.02) & 
    .48 (.03) &
    .52 (.01) &
    .58 (.05) & 
    .53 (.01) &
    &
    .55 (.01) &
    .52 (.02) &
    .65 (.04) 
    \\
    
    UK &
    .53 (.01) &
    .51 (.01) &
    .51 (.03) &
    .53 (.01) &
    .40 (.06) &
    .52 (.01) &
    .53 (.02) &
    &
    .50 (.02) &
    .67 (.03) 
    \\
    
    
    
    
    \arrayrulecolor{Gray2}
    \hline
    \end{tabular}%
    }
\end{table}








\subsubsection{{Country-Agnostic II Models}} In Table~\ref{tab:agnostic-ii}, we show results for country-agnostic models that were trained in seven countries and tested in the shown country. Compared to the previous setting, where the models were trained in only one country and tested in another, these models capture a more considerable intra-subject variability in model training. Moreover, HM results were not included here because, technically, it is similar to the HM of multi-country models. PLM results show that the performance is not high for both two-class and three-class inferences. For some countries, performance slightly increased compared to country-specific (e.g., China, Paraguay in two-class). For some, the performance declined (e.g., India, Denmark, Italy, Mexico, and the UK in two-class). Hence, there is no clear evidence that having more data from multiple countries would help to generalize better for an unseen country, even in this case. 


\begin{table}
    \caption{{Country-Agnostic II PLM: }Mean ($\bar{S}$) and Standard Deviation ($S_\sigma$) of AUROC scores obtained by testing each a seven-country model on data from a new country. Results are presented as $\bar{S} (S_\sigma)$, where $S$ is the AUROC.}    
    \label{tab:agnostic-ii}
     \resizebox{0.35\textwidth}{!}{%
    \begin{tabular}{l l l}
    
    
    
    &
    \multicolumn{1}{c}{\cellcolor[HTML]{EDEDED}\textbf{Two-Class}} &
    \multicolumn{1}{c}{\cellcolor[HTML]{EDEDED}\textbf{Three-Class}} 
    \\
    \arrayrulecolor{Gray}
    \hline
    
    Baseline &
    .50 (.00) &
    .50 (.00) 
    \\
    
    \hline 
    
    China &
    .54 (.01) &
    .48 (.01) 
    \\
    
    Denmark & 
    .51 (.02) &
    .48 (.01) 
    \\
    
    India &
    .53 (.03) &
    .47 (.01)
    \\
    
    Italy &
    .54 (.01) &
    .50 (.01) 
    \\
    
    Mexico &
    .41 (.02) &
    .54 (.01) 
    \\ 
    
    Mongolia &
    .49 (.01) &
    .49 (.01) 
    \\
    
    Paraguay &
    .56 (.01) &
    .55 (.01) 
    \\
    
    UK &
    .48 (.01) &
    .51 (.01)  
    \\ 
    
    \arrayrulecolor{Gray2}
    \hline
    \end{tabular}
    }
\end{table}




\begin{table}
    \caption{{Multi-Country and Continent-Specific with PLM and HM: }Mean ($\bar{S}$) and Standard Deviation ($S_\sigma$) of F1-scores and AUROC scores obtained by testing the "worldwide" model. Results are presented as $\bar{S} (S_\sigma)$, where $S$ is any of the two
    metrics.}    
    \label{tab:multi-country}
    
    \resizebox{0.7\textwidth}{!}{%
    \begin{tabular}{l l l l l}
     
     
    &
    \multicolumn{2}{c}{\cellcolor[HTML]{EDEDED}\textbf{PLM}}&
    \multicolumn{2}{c}{\cellcolor[HTML]{EDEDED}\textbf{HM}} \\
    
    &
    \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Two-Class}} &
    \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Three-Class}} &
    \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Two-Class}} &
    \multicolumn{1}{c}{\cellcolor[HTML]{D9D9D9}\textbf{Three-Class}} 
    \\
    
    \arrayrulecolor{Gray}
    \hline
    
    
    Baseline &
    .50 (.00) & % Baseline 1
    .50 (.00) & % XGBoost
    .50 (.00) & % Baseline 1
    .50 (.00)  % XGBoost
    \\
    
    \hline 
    
    Europe &
    .58 (.03) & % Random Forest
    .50 (.03) & % MLP
    .89 (.03) & % Random Forest
    .86 (.02)  % MLP
    \\
    
    Asia &
    .51 (.02) & % 2-class
    .52 (.05) & % MLP
    .79 (.03) & % Random Forest
    .74 (.01)  % MLP
    \\
    
    Multi-Country &
    .52 (.03) & % Random Forest
    .53 (.02) & % MLP
    .83 (.01) & % Random Forest
    .86 (.03)  % MLP
    \\
    
    \hline 
    
    Europe (Balanced) &
    .53 (.02) & % Random Forest
    .50 (.05) & % MLP
    .86 (.04) & % Random Forest
    .82 (.03)  % MLP
    \\
    
    Asia (Balanced) &
    .52 (.04) & % 2-class
    .54 (.03) & % MLP
    .79 (.02) & % Random Forest
    .76 (.02)  % MLP
    \\
    
    Multi-Country (Balanced) &
    .53 (.02) & % Random Forest
    .52 (.03) & % MLP
    .81 (.03) & % Random Forest
    .78 (.02) % MLP
    \\
    
    \arrayrulecolor{Gray2}
    \hline 
    
    
    \end{tabular}%
    }
    
\end{table}


\subsubsection{Multi-Country and Continent-Specific Models} 

Finally, in Table~\ref{tab:multi-country}, we show the results for the multi-country approach and also the continent-specific approach that is similar to the country-specific; however, instead of countries, we considered two continents: Europe (Italy, Denmark, UK) and Asia (China, Mongolia, India) \footnote{There are arguments for and against on whether North and South America are a single continent or two \cite{nationsonline2022continents, worldometer20227continents, Ward2020How}. In the Anglo-Saxon world, it is often stated that there are seven continents, with North and South America being separate. In contrast, it is taught otherwise in Latin America \cite{Ward2020How}. Hence, we did not include ‘America’ results by combining Mexico and Paraguay.}. The primary motivation for examining these models is the result we obtained in the country-agnostic approach, where for HM, models trained in European countries performed better in other European countries with HMs. Results for the continent-specific approach show that models performed similarly to any other approach for both two-class and three-class inferences for PLM. However, the Europe model for two-class inference had an AUROC score of 0.58, which is second only to the Mexican model (0.62) in the country-specific approach.

Furthermore, results show that the continent-specific model for Europe with an AUROC of 0.89 for two-class inference, performed better than the multi-country (0.83) and even country-specific approach for Italy (0.82) and Denmark (0.83) and closer to the country-specific UK model with an AUROC of 0.91. Similar results can be seen for three-class HM inference. This suggests that for western Europe, where everyday patterns might be somewhat similar across countries, continent-specific models could perform reasonably. However, for the continent-specific Asian model, it is not the same. For example, for the two-class inference, the Asia model had an AUROC score of 0.79, which is similar to country-specific China (0.78) and India (0.79) results but significantly lower than the result for Mongolia (0.85).
On the other hand, for the three-class HM, the Asia approach reached an AUROC of 0.74, whereas China, India, and Mongolia models reached 0.79, 0.76, and 0.84, respectively. Hence, continent-specific models did not perform as well as country-specific or multi-country models for Asia. This could be because even though China, India, and Mongolia are geographically on the same continent, the behaviors and cultures of students are different. In addition, ‘balanced’ models decreased performance for Europe and Multi-Country, whereas for Asia, it is not the same, where three-class HM performance increased in the balanced case. Again, this is because India and China get more representation in training, leading to better performance in testing.  









\begin{figure}
    \includegraphics[width=\textwidth]{images/FI_CS_HYBRID_2class_v2.png}
    \caption{{Country-Specific HM: } Gini feature importance values from RF models for two-class inference.}
    % \Description{}
    \label{fig:fi_two_class}
\end{figure}


\begin{figure}
    \includegraphics[width=\textwidth]{images/FI_CS_HYBRID_3class_v2.png}
    \caption{{Country-Specific HM: }Gini feature importance values from RF models for three-class inference.}
    % \Description{}
    \label{fig:fi_three_class}
\end{figure}

\subsubsection{Gini Feature Importance Values}

Figure~\ref{fig:fi_two_class} and Figure~\ref{fig:fi_three_class} show the Gini feature importance values for each country for two-class and three-class mood inferences with HMs. We report diagrams for HMs because they provide the highest performance. Further, the top five features within each country are marked with numbers from one to five. Moreover, in both diagrams, values are arranged in the decreasing order of values in China, from left to right. For both inferences, many apps had very low feature importance values.
On the other hand, `app personalization' and `app tools' were among the top five features for many countries. For the UK, personalization apps were highly important in two and three-class inferences. However, for Mexico, the importance of the feature was relatively lower in both inferences. In addition, the number of touch events on the phone was within the top five features for Italy, Mongolia, Paraguay, and the UK in the two-class inference and all countries except India and Mexico in the three-class inference. This aligns with previous literature that presented findings of typing and touch events indicative of aspects such as mood and stress \cite{likamwa2013moodscope}. Another feature discussed in the literature on psychological aspects and mobile sensing \cite{canzian2015trajectories}, which appeared again in the diagrams is speed, calculated using location sensors (`location speed mean'). Diagrams indicate that the feature was in the top five in two-class inference for India and China and three-class inference for India and Paraguay. In addition to these features, multiple features captured using Wifi signals were among the top five in all countries. Wifi-related features (i.e., `wifi std rssi',`wifi mean rssi', `wifi min rssi', `wifi max rssi' - The standard deviation/mean/minimum/maximum of RSSI signal strengths captured with unique devices within the time window) were present with high importance values for all countries across both inferences. Prior work highlights that the number of wifi devices and signal strengths could be indicative of user context, including the location \cite{santani2018drinksense}, and location-related features have shown to be closely tied to the mood of individuals \cite{canzian2015trajectories}.
In summary, the top five features for mood inference, regardless of whether it is two-class or three-class, were not the same across all countries. Certain features are unique to individual countries. At the same time, we can also observe a specific set of features (shown in the left quarter of both figures) that consistently appeared on the top list in all countries.  

