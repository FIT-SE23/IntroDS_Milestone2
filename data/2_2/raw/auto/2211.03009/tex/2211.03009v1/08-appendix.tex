\appendix

\section{Appendix}


In this appendix, we describe how features were obtained for each sensing modality. This is an extension of the description we provided in Table~\ref{tab:agg-features}. First, it is worth noting that the analysis was done using a time window of 10 minutes. This would mean that for any sensing modality, we would filter out data for that particular time window. In addition to the sensor data within the time window, we also used the last data point before the start of the time window and the first data point after the end of the time window, in some cases when necessary.

\paragraph{\textbf{Location}} Location data were captured once every minute using either GPS signal or cell tower signals, depending on the most accurate signal available in a particular moment. We used the definitions for radius of gyration and distance covered from \cite{canzian2015trajectories}. This enables to capture the movement of the individual within the time window. Prior work has shown that movement could be indicative of different states related to mood and depression \cite{likamwa2013moodscope, servia2017mobile, canzian2015trajectories}. In addition, we also calculated the mean altitude using altitude values captured with location information.


\paragraph{\textbf{Bluetooth and Wifi}} There were two types of bluetooth devices logged with the mobile application. They are: low energy and normal. For each type, the mobile application logged a list of devices found with device IDs and signal strengths to each device. Then, we derived a set of features with a similar approach to \cite{santani2018drinksense}, including the number of device found, and statistical features regarding the signal strength to other devices in the vicinity. This sensing modality provides the user context as prior work has shown that these features could be indicative of whether the user is in a device-dense closed space or not \cite{santani2018drinksense, meegahapola2021one}. For Wifi, first, it was calculated whether the user is connected to a network or not. Usually someone connecting to a network indicates that they are in a familiar environment (i.e. home, workplace, university). In addition, similar to \cite{santani2018drinksense}, we also captured statistical features related to signal strength for all networks in the vicinity. This also provides data about the user context. 


\paragraph{\textbf{Notifications}} The mobile app captured whenever users got a notification. In addition, in certain cases, unless the notification was clicked, the same notification would be displayed again (e.g. this could happen in WhatsApp). Hence, to capture these details, we calculated the number of notification posted by the system, and removed by the user, with and without the duplicates. This gives an indication of the phone usage behavior of users. 


\paragraph{\textbf{Proximity}} Prior work has shown that proximity sensor reading could give an indication on where the phone is \cite{bae2017detecting}. Hence, basic statistical features were captured for the proximity variable. 

\paragraph{\textbf{Steps}} The step count was captured in the study using two techniques for reliability. First, the step count was derived using the total number of steps taken since the last time the phone was turned on. In addition, using a trigger in the system that sends an interrupt every time a new step is detected, the app also logged a separate step count called steps detected. We used both these features in the analysis. 

\paragraph{\textbf{Activity}} The mobile app provided the activity a person is doing, two times per minute. This activity was derived from a probability distribution of 8 activity types recognized by the Google Activity Recognition API. Therefore, we have a label of the activity the user is doing, roughly each 30 seconds. For example, if the first time window is from $T$ to $T+10$ mins, if the first activity label is at $T+1$ mins, the second activity report is at $T+2$ mins, we would assume that the user has been doing the first activity between $T+1$ min and $T+2$ min, for 1 minute. Similarly, we would calculate the approximate time of doing all the activities. However, it is worth noting that sometimes, the first activity label we get could be after 1-2 minutes after the start of the time window. This could happen because of inconsistencies in the data logged by the application. In such situations, we would also consider the last activity report before the start of the time window (let's say at $T-1$ min). We use the label of the last activity and include it in the calculation assuming that the user has been doing that activity from $T$ to $T+1$ min. Hence, using this technique, for each time window, we would have a distribution of activities the user has been doing in seconds. 

\paragraph{\textbf{Screen and Touch Events}} The mobile app logged whenever the screen was turned on or off, with timestamps. This allows us to calculate the time users spent with their screens turned on. For example, if the first time window is from $T$ to $T+10$ mins, if the screen was turned on at $T+3$ mins and turned off at $T+9$ mins, we could assume that the screen was turned off from $T$ to $T+3$ mins, and then it was on from $T+3$ to $T+9$. We consider 1 such turn on-off time period as an episode. A 10 minute time window could have multiple such episodes. Hence, using these values, we derived the number of episodes, statistical features for time spent in those episodes, and also the total time spent with the screen turned on. The distinction is that this allows us to distinctively identify a person who has the screen turned on for a longer duration vs. another person whose total screen on duration is the same as the earlier person, but turn on and off the screen more frequently (e.g. in a situation waiting for a email/message from someone, turning on the screen to see the time, etc.). We believe capturing these information could have value when studying attributes regarding mental well-being specially since screen on time has been associated to mental well-being in a lot of prior studies \cite{tang2021relationship}. In addition, the mobile app also logged all the touch events (this could be a tap or a keyboard press event). Using the values, we derived a feature for the total number of touch events in the time window.


\paragraph{\textbf{App Events}} Prior work that used app usage either considered the usage of individual apps \cite{meegahapola2021one} or app categories \cite{santani2018drinksense}. For this study, we felt that it's better to use app categories because of the heterogeneity of the dataset, where users from different countries would use different apps belonging to the same category, to do a similar task. We followed an approach similar to \cite{santani2018drinksense} and obtained the google play store app category (i.e. action, adventure, social, education, entertainment, etc.) for each app in the dataset, and used it to calculate app usage times. App usage time would be calculate from the time an app is on the screen to the time it closes or go to the background. There could also be instances where the phone screen is on and there are no apps on the screen. Such time periods were included in the category called "not\_found". In addition, whenever we could not find an app category for a particular app, it was also included under the "not\_found" category. 








