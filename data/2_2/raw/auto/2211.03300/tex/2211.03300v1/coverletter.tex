\documentclass{letter}
\usepackage{doi}
\usepackage{url}

\begin{document}

\noindent Dear Editors and Reviewers,

We express our gratitude for your time and effort in consideration of this manuscript. We wish our manuscript titled ``\textbf{HFedMS: Heterogeneous federated learning with memorable streaming data in industrial metaverse}" to be considered for publication in the IEEE Transactions on Cloud Computing.

The initial idea of this manuscript along with some preliminary results have been published in the 2022 International Conference on Database Systems for Advanced Applications (DASFAA2022) as follows,

[1] Zeng, Shenglai, Zonghang Li, Hongfang Yu, \textit{et al}.: ``Heterogeneous federated learning via grouped sequential-to-parallel training." In \textit{International Conference on Database Systems for Advanced Applications (DASFAA2022)}, pp. 455-471. Springer, Cham, 2022, \doi{10.1007/978-3-031-00126-0_34}.

In preparation of this submission, we have added a significant volume of technical material compared to the conference version. We have not only presented new algorithms with in-depth theoretical analysis but also extensive experiments to back up the proposals.  In the following, we present a list of new contributions we have included in this submission:

\begin{itemize}
\item \textbf{New Challenges:} In addition to the problem of \textit{data heterogeneity} in the conference version, this version takes into account the extremely demanding requirements of Industrial Metaverse for task precision and system efficiency, and is optimized for the \textit{forgetting problem} caused by industrial streaming data and the \textit{communication bottleneck} caused by the low available communication bandwidth of industrial networks (e.g., LPWANs).

\item \textbf{New Approaches:} For new streaming data settings and two new challenges, this version (a) proposes a semantic compression and compensation mechanism (SCC) that enables historical data to be recorded and stored in a lightweight form on sensors with limited memory. The stored data can be used to calibrate classifier parameters to alleviate learning forgetting. Then, (b) an layer-wise alternative synchronization protocol (LASP) is proposed, which allocates more communication resources to synchronize important but lightweight classifier parameters, but with much less traffic, making it well-suited for bandwidth-limited LPWAN networks.

\item \textbf{New Observations and Analysis:} We found that for the forgetting problem brought by streaming data, there is a gap between the replayed data and the current data, and simply fusing them leads to confusion and poor performance. To this end, we formulated this gap and proposed a low-footprint compensation module to bridge them. Numerical results in our experiments demonstrate its necessity and effectiveness.

\item \textbf{Experiments:} Taking the previous method for traditional static offline data as HFedMS-S, we name the new method HFedMS-D and re-validate the previous conclusions on dynamic streaming data. We conduct ablation experiments to help readers understand the success of our four modules. The results are promising, all in all, our new method has four advantages over 8 well-known benchmarks: \textit{higher accuracy, faster convergence, less running time and lower communication cost}, making it highly competitive in harsh industrial environments.
\end{itemize}

We deeply appreciate your consideration of our manuscript, and we look forward to receiving comments from you. If any queries, please do not hesitate to contact us. The corresponding author and her information are as follows,

Hongfang Yu \\
School of Information and Communication Engineering \\
University of Electronic Science and Technology of China \\
Email: \url{yuhfnetworklab@gmail.com}

Cordially, 

Shenglai Zeng, Zonghang Li, Hongfang Yu, Zhihao Zhang, Long Luo, Bo Li, and Dusit Niyato 

\today

\end{document}