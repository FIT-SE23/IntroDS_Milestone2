\section{Introduction}
The promise of having fully-autonomous robots performing a large variety of tasks implies that robots should be able to execute highly-dynamic motions. 
The inherent complexity of these movements makes hand coding an infeasible approach. Therefore learning techniques arise as a potential solution.
In particular, learning dynamic robot motions from human demonstrations is a promising approach to build models of dynamic skills in an intuitive, sample-efficient and quick manner.
However, learning dynamical motions is not trivial as the learning model requires to provide stability guarantees, which is also an intrinsic property in human motion generation~\citep{Burdet06:StabilityHumanMotion}. 
In this context, most research works have focused on learning time-invariant stable dynamical systems for goal-driven motions (a.k.a point-to-point movements) with Lyapunov-stability guarantees~\citep{KhansariZadeh2011:StableEstimatorDS,Khansari-Zadeh2014:lyapunovStabilityDS,Neumann2014:SDS_diffeomorphism,Rana2020:EuclideanizingFlows,Zhang2022:accurateSDS}. 

\citet{KhansariZadeh2011:StableEstimatorDS} proposed one of the first approaches to learn stable dynamical systems from human demonstrations by imposing quadratic Lyapunov non-linear constraints on the model parameters' optimization, which limited the range of possible learnable motions.
As the class of stable dynamical systems constrained by a predefined Lyapunov function is a subset of all possible stable dynamical systems, this limits the learned model accuracy~\citep{Neumann2014:SDS_diffeomorphism}. 
To improve accuracy, a more general parametric control Lyapunov function~\citep{Sontag83:CLF} can be learned from demonstrations~\citep{Khansari-Zadeh2014:lyapunovStabilityDS, Ravanbakhsh19:CLFwithLfD, Rodriguez2022:LyaNet}.
The trade-off between stability and accuracy motivated the use of diffeomorphisms~\citep{Neumann2014:SDS_diffeomorphism, Rana2020:EuclideanizingFlows, Zhang2022:accurateSDS, Urain20:ImitationFlow, Urain2021:LearningVFonLieGroups, Zhi22:DiffeoImitation}, which leveraged a more general class of stable dynamical systems.
Their main idea is to design or learn a canonical Lyapunov-stable dynamical system on a latent space and use a diffeomorphic mapping to transform the demonstrations to the latent space so that they are consistent with the desired Lyapunov-stable behavior.
Thus, the modeling accuracy depends on the expressiveness of the diffeormorphic function, often modeled by a neural network
~\citep{Rana2020:EuclideanizingFlows,Zhang2022:accurateSDS,Urain20:ImitationFlow,Urain2021:LearningVFonLieGroups}.

Most of aforementioned works assume that the training data lie in the Euclidean space~\citep{Neumann2014:SDS_diffeomorphism, Rana2020:EuclideanizingFlows, Zhang2022:accurateSDS, Urain20:ImitationFlow,Zhi22:DiffeoImitation}, with the exception of~\citet{Urain2021:LearningVFonLieGroups}, which severely limits their use in real applications.
For instance, there are various types of representation for the robot end-effector's orientation, namely unit quaternions in the $3$-Sphere manifold~\citep{Wen1991:Quaternion}, and rotation matrices in the special orthogonal group ($\operatorname{SO}(3)$) manifold~\citep{Gu1988:OrientationRep}, which do not lie in the Euclidean space.
Accounting for the data geometry has proven critical when learning and optimizing movement primitives on quaternion space~\citep{Ude14ICRA,Zeestraten17:Riemannian,Koutras20:OrientationDMP,Rozo2021:OrientationProMP,Jaquier21:MaternGaBO}, as relying on Euclidean approximations leads to modeling distortions and compromises extrapolation.   
The importance of geometry-aware methods when learning dynamical systems was recently addressed in~\citep{Urain2021:LearningVFonLieGroups}, where a stable dynamical system was learned via diffeomorphisms over Lie groups.  
Although Lie theory has been exploited to operate with data of specific geometries~\citep{Sola18:LieTheory}, a potential limitation is that not all types of manifolds arising in robotics can be easily endowed with a Lie group structure (e.g., the space of symmetric positive-definite matrices (SPD)). 

A more general solution based on Riemannian geometry~\citep{DoCarmo92:RiemannManifold} is proposed in this paper. 
We consider dynamical systems evolving on a Riemannian manifold.
This arises two main challenges: \emph{(1)} designing a canonical Lyapunov-stable dynamical system on Riemannian manifolds, and \emph{(2)} learning a diffeomorphism that accounts for the Riemannian geometry.
To address these challenges, we leverage the Lyapunov stability analysis on Riemannian manifolds~\citep{Pait10:RiemannianLyapunov,Jaquier2021:ManipulabilityLearning}.  
Moreover, we exploit neural ordinary differential equations (ODEs) on Riemannian manifolds~\citep{lou2020:NeuralMODE, mathieu2020:RCNormalizingFlows} for constructing the diffeomorphism to learn a Riemannnian stable dynamical system (RSDS).
Unlike previous works using diffeomorphisms~\citep{Neumann2014:SDS_diffeomorphism, Rana2020:EuclideanizingFlows, Zhang2022:accurateSDS}, our approach extends this concept to systems evolving on Riemannian manifolds.
In contrast to works assuming Riemannian manifolds that are diffeomorphic to the Euclidean space~\citep{Gemici16:NFonRiemannianManif}, or manifold-specific diffeomorphisms built on specialized neural networks~\citep{Rezende20:NFsToriSphere}, our approach leverages a general formulation to construct diffeomorphisms based on solutions of ODEs evolving on arbitrary Riemannian manifolds~\citep{lou2020:NeuralMODE}.
Our approach is conceptually similar to the Lie-group method introduced in~\citep{Urain2021:LearningVFonLieGroups}, as both explicitly consider the data geometry to design technically-sound learning models via diffeomorphisms. 
However, our Riemannian formulation substantially differs from~\citep{Urain2021:LearningVFonLieGroups} in its technical development, and provides a more general approach that may be exploited for a variety of Riemannian manifolds. 

In summary, we propose a method to learn Riemannian stable dynamical systems from demonstrations. 
Our approach provides Lyapunov-stability guarantees on Riemannian manifolds (see \S~\ref{subsec:GeodesicVF}) that are enforced on the desired motion dynamics via diffeomorphisms built on neural manifold ODEs (see~\S~\ref{subsec:DiffeomorphRM} and~\ref{subsec:DiffInvDiffeomorph}).  
Through a set of evaluations on the $2$-sphere manifold $\SphereManifold^2$, presented in \S~\ref{sec:result}, we show that our Riemannian approach is able to learn complicated dynamical systems, in contrast to Euclidean approximations which fail to encode stable vector fields.
Also, we learn realistic motion skills on a $7$-DoF robotic manipulator featuring complex full-pose trajectories on $\RtimeS$.