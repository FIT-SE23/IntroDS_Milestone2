\subsection{Primal-Dual}
Due to the log transformation, the primal-dual method can be applied to analyze the competitive ratio. Firstly, we can write the primal and dual optimization problem respectively. Unlike the common one, we add the extra small number ($\epsilon_i$) to the bundle of each agent to avoid that the whole term in primal optimization is negative infinity. Thus, our whole strategy is to use half of each item to be allocated to its neighbor agents averagely and then the remaining half item is allocated by the primal-dual methods.
\begin{equation}
\begin{aligned}
\max \quad & \sum_{i = 1}^{n} \log \ (x_i + \epsilon_i) \\
\textrm{s.t.} \quad & \sum_{j \in NE(i)} x_{ij} \geq x_i\\
&\sum_{i \in NE(i)} x_{ij} \leq 1\\
&x_{ij} \geq 0\\
\end{aligned}  
\end{equation}

\begin{equation}
\begin{aligned}
\min \quad &\sum_{j = 1}^{m} p_j + \sum_{i}^{n} (u_i\epsilon_i - \log u_i) - n \\
\textrm{s.t.} \quad &p_j \geq u_i  \quad \forall i \in NE(j) \\
&p_j,u_i\geq 0\\
\end{aligned}  
\end{equation}


Next, we need to analyze the upper bound of $\Delta dual - \Delta primal$ when the remaining half of item is distributed based on the primal-dual methods. Before that, one important thing is to estimate the $u_i$ in each iteration. Intuitively, $u_i$ is given by:  
$$u_i = \frac{1}{\frac{x_i}{\alpha} + \epsilon_i}  \quad (0 < \alpha \leq 1)$$
Now, without loss of the generality, we choose $\alpha = 1$ and expand the $\Delta dual - \Delta primal$:
\begin{align*}
    \Delta dual - \Delta primal & =  p_j + \sum_{i \in NE (j)}\frac{ \epsilon_i\Delta x_i}{(x_i + \epsilon_i)(x_i + \Delta x_i + \epsilon_i)} \\
    & = \sum_{i \in NE (j)} \frac{1}{\frac{x_1 + \Delta x_i}{\alpha}+ \epsilon} + \frac{ \epsilon_i\Delta x_i}{(x_i + \epsilon_i)(x_i + \Delta x_i + \epsilon_i)} \\
    & = \sum_{i \in NE (j)}[\frac{\Delta x_i}{x_i + \epsilon_i + \Delta x_i} - \frac{\epsilon_i \Delta x_i}{(x_i + \epsilon_i)(x_i + \Delta x_i + \epsilon_i)}] \\
    & = \sum_{i \in NE (j)} \frac{x_i \Delta x_i}{(x_i + \epsilon_i)(x_i + \Delta x_i + \epsilon_i)} \\
\end{align*} 
In order to analyze the upper bound of $\Delta$ and we use two different methods - integral and discrete methods.

(1) Integral method:
\begin{equation*}
    \frac{x_i \Delta x_i}{(x_i + \epsilon_i)(x_i + \Delta x_i + \epsilon_i)} \leq \int_{x_i}^{x_i + \Delta x_i} \frac{x}{x + \epsilon_i} dx
\end{equation*}

Thus,
\begin{equation*}
    \sum_{i}^{n}\sum_{j}^{m} \frac{x_i \Delta x_i}{(x_i + \epsilon_i)(x_i + \Delta x_i + \epsilon_i)} \leq \sum_{i}^{n}\int_{0}^{L_i} \frac{x}{x + \epsilon_i} dx
\end{equation*}
$L_i$: the max amount of items which agent i receive during the primal-dual.

For the function $f(L_i) = \int_{0}^{L_i} \frac{x}{x + \epsilon_i} dx$. When $L_i < \epsilon_i$, $f(L_i)$ is convex. When $L_i > \epsilon_i$, $f(L_i)$ is concave. Because the relationship between $L_i$ and $\epsilon_i$ is unknown, we use $|A| = a$ to denote the set of agents whose $L_i \leq \epsilon_i$ and $|B| = b$ to denote the set of agents whose $L_i > \epsilon_i$. As for the estimation of $\epsilon_i$, we design two plans: one is $\frac{m}{2n}$ and the another one is $\frac{d_i}{2n}$ ($d_i$ is the number of neighbors of agent i). Since the only half of each item is allocated by primal-dual method, we have $\sum_{i}^{n} L_i = \frac{m}{2}$. Therefore, we can get the following inequality:

\begin{align*}
    \sum_{i}^{n}\sum_{j}^{m} \frac{x_i \Delta x_i}{(x_i + \epsilon_i)(x_i + \Delta x_i + \epsilon_i)}  & \leq   \sum_{i}^{A} \int_{0}^{L_i} \frac{x}{x + \epsilon_i} dx  + \sum_{i}^{B} \int_{0}^{L_i} \frac{x}{x + \epsilon_i} dx \\
    &\leq  \sum_{i}^{n} \ [\log (1+ \frac{L_i}{\epsilon_i}) - \frac{\frac{L_i}{\epsilon_i}}{1 + \frac{L_i}{\epsilon_i}}] \ (L_i > \epsilon) \\
     (Jensen's \ Inequality)&\leq n \cdot [\log (1 + \frac{\sum_{i}^{n}\frac{L_i}{\epsilon_1}}{n}) + \frac{\frac{1}{n} \cdot \sum_{i}^{n} \frac{L_i}{\epsilon_i}}{1 + \frac{1}{n} \cdot \sum_{i}^{n}\frac{L_i}{\epsilon_i}}]\\
    (\epsilon_i = \frac{d_i}{2n})&\leq n \cdot [\log (1 + 2 \sum_{i}^{n}\frac{L_i}{d_i}) + \frac{2 \sum_{i}^{n} \frac{L_i}{d_i}}{1 + 2  \sum_{i}^{n}\frac{L_i}{d_i}}]\\
    & \leq n \cdot [\log (1 + \min \{m, n \})]\\
    &\textbf{or}\\
    (\epsilon_i = \frac{m}{2n}) &\leq n \cdot [\log (1 + 2  \sum_{i}^{n}\frac{L_i}{m}+ \frac{2 \sum_{i}^{n} \frac{L_i}{m}} {1 + 2  \sum_{i}^{n}\frac{L_i}{m}}]\\
    &\leq n \cdot (\log 2 + \frac{2}{3})    
\end{align*}

\textit{There are two problems of the above analysis: (1) When the agent has small number of neighbor items, the integration may bring non-negligible effect. (2) The error of estimation $\epsilon_i$ should be considered because in the above analysis, $\epsilon$ which we use is the estimated number.}

\textit{Estimation of the error brought by $\epsilon_i$}

We consider the worst case, the whole graph is the upper-triangle graph.

We use $\epsilon_i$ to denote the real received quantities and $\Tilde{\epsilon_i} = \frac{m}{2n} = \frac{1}{2}$ to represent the estimated one. Now, we compute the bound of gap between the real log NSW and estimated log NSW.
\begin{figure}[ht]
    \centering
    \includegraphics[scale = 0.3]{-0.5.jpg}
    \caption{The numeric computation of the following term}
    \label{fig:numeric-computation}
\end{figure}
\begin{align*}
    \Delta (Real - Estimated) & =  \frac{1}{n} \cdot \sum_{i}^{n} \log(\frac{x_i+\epsilon_i}{x_i + \Tilde{\epsilon_i}})\\
    & =  \frac{1}{n} \cdot \sum_i^{n} \log(1 + \frac{\epsilon_i - \frac{1}{2}}{x_i + \frac{1}{2}})\\
    & = \frac{1}{n} \cdot \sum_i^{n} \log[1+\frac{\frac{1}{2}  (\sum_{t=1}^{i}\frac{1}{n-t+1}-1)}{\frac{1}{2} (\sum_{t=1}^{i}\frac{1}{n-t+1}+1)}]\\
    & = \frac{1}{n} \cdot \sum_i^{n} \log (2 - \frac{2}{\sum_{t=1}^{i} \frac{1}{n-t+1} +1})\\
    & \geq -0.5
\end{align*}
(2) Discrete method:

We directly scale the $\Delta$ to reach the bound. For each agent $i$, we assume that there are $T_i$ steps for agent $i$ in her allocation and $T_i$ = $d_i$ where $d_i$ is the number of her neighbor items.

\begin{align*}
        \sum_{t = 0}^{T-1} \frac{x_i^{t}}{(x_i^{t} + \epsilon_i)(x_i^{t+1} + \epsilon_i)} &=  \sum_{t = 0}^{T-1} \ [\frac{x_i^t}{x_i^t + \epsilon_i} - \frac{x_i^t}{x_i^{t+1} + \epsilon_i}]\\
        &=  \sum_{t = 0}^{T-1} \ \frac{x_i^{t+1} - x_i^t}{x_i^{t+1} + \epsilon_1} - \frac{x_i^T}{x_i^T + \epsilon_i} \\
        &=  \ T - \sum_{t = 0}^{T-1}\frac{x_i^t +\epsilon_i}{x_i^{t+1} + \epsilon_i} - \frac{x_i^T}{x_i^T + \epsilon_i}\\
        &\leq  \ T - T (\frac{\epsilon_i}{x_i^T + \epsilon_i})^{\frac{1}{T}} - \frac{x_i^T}{x_i^T + \epsilon_i}\\
        & \leq \ T - T (\frac{\epsilon_i}{L_i + \epsilon_i})^{\frac{1}{T}} \\
       (\epsilon_i = \frac{d_i}{2n} \ and \ T =d_i) & \leq \ d_i - d_i (\frac{d_i}{d_i + 2nL_i})^{\frac{1}{d_i}}
\end{align*}
 
 Let $g(d_i,L_i) = d_i - d_i * (\frac{d_i}{d_i + 2nL_i})^{\frac{1}{d_i}}$. Thus, for all agents:
 
 \begin{align*}
        \sum_{i}^{n}\sum_{t = 0}^{T-1} \frac{x_i^{t}}{(x_i^{t} + \epsilon_i)(x_i^{t+1} + \epsilon_i)} & \leq \sum_{i}^{n} g(d_i, L_i)\\
        &\leq \sum_{i}^{n} \max_{d_i} g(d_i,L_i)\\
        &\leq \sum_{i}^{n} \log (2nL_i +2)\\
        (Jensen's \ Inequality)& \leq  n \cdot \log(\frac{\sum_{i}^{n}2nL_i }{n}+2)\\
        & \leq n \cdot \log (m+2) 
\end{align*}

\textit{Problem: The two scalings in the above analysis does not guarantee that the two equalities can be satisfied simultaneously. }

\begin{figure}[ht]
    \centering
    \includegraphics[scale = 0.28]{discrete_log.jpg}
    \caption{$\max_{d_i} g(d_i, L_i)$}
    \label{fig:discrete-log}
\end{figure}