\section{Impartial Instances}
\label{sec:impartial}

This section considers impartial instances.
Section \ref{sec:greedy-binary} examines a special case of binary values: an agent $i$'s value for an item $t$ is either $v_{it} = 0$, or some value $v_{it} = v_t$ that is the same for all agents.
We will show that a simple greedy algorithm, which was referred to as Myopic Greedy by \citet{BanerjeeGGJ:SODA:2022}, is $O(\log \mu^*$)-competitive in this special case.
This is nearly tight as the next section will show an almost matching lower bound.
Section \ref{sec:greedy-reduction-bounded} then explains how to reduce the general case to the binary case, under an additional assumption that we are given an upper bound $\mu$ of the impartiality ratio $\mu^*$, i.e., if we know that the instance is $\mu$-impartial.
Finally, Section \ref{sec:greedy-reduction-general} applies the same technique as in the previous section to randomly guess an upper bound, removing the additional assumption while losing a factor that depends on $\log \log \mu^*$ in the competitive ratio.

\subsection{Myopic Greedy and Binary Values}
\label{sec:greedy-binary}

The Myopic Greedy algorithm simply allocates each item $t$ greedily to maximize the Nash welfare conditioned on the allocation before item $t$.
In other words, it is a greedy algorithm with anticipated utilities, for which the anticipated utility of an agent equals its utility for the items allocated to it so far.
See Algorithm~\ref{alg:greedy-binary} for a formal definition.

~

\begin{algorithm}[H] 
    \caption{\textbf{Myopic Greedy}}
    \label{alg:greedy-binary}
    \For{\text{\rm each item $1 \le t \le T$}}
    {
        Let the allocation $\vec{x}_t = (x_{it})_{1 \le i \le N}$ maximize:
        \[
            \sum_{i=1}^N \log \Big( \sum_{t'=1}^{t-1} v_{it'} x_{it'} + v_{it} x_{it} \Big)
        \]
        subject to $\sum_{i=1}^N x_{it} \le s_t$ and $x_{it} \ge 0$ for all agents $1 \le i \le N$.
    }
\end{algorithm}

~

The rest of this subsection will assume that the agents' values are binary, that is, for any item $1 \le t \le T$ and any agent $1 \le i \le N$, either $v_{it} = 0$ or $v_{it} = v_t$.

\begin{theorem}
    \label{thm:greedy-binary}
    Algorithm~\ref{alg:greedy-binary} is $O(\log\mu^*)$-competitive if the agents have binary values for the items.
\end{theorem}

In fact, we will prove a slightly stronger result so that in the next subsection we can reduce the general case to the case of binary values.
We formulate the stronger claim as the next lemma.

\begin{lemma}
    \label{lem:binary-greedy-ratio}
    For any feasible allocation $\vec{\tilde{x}} = (\tilde{x}_{it})_{1 \le i \le N, 1 \le t \le T}$ and the agents' corresponding utilities $\vec{\tilde{u}} = (\tilde{u}_i)_{1 \le i \le N}$,
    if allocation $\vec{\tilde{x}}$ is $\tilde{\mu}$-impartial, then the Nash welfare of the allocation by Algorithm~\ref{alg:greedy-binary} is at least an $O(\log \tilde{\mu})$ approximation to the Nash welfare of allocation $\vec{\tilde{x}}$, i.e.:
    %
    \[
        \left( \frac{\prod_{i=1}^N \tilde{u}_i}{\prod_{i=1}^N u_i} \right)^{\frac{1}{N}} = ~ O(\log \tilde{\mu})
        ~.
    \]
\end{lemma}

Theorem~\ref{thm:greedy-binary} follows as a corollary by letting $\vec{\tilde{x}}$ be the Nash welfare maximizing allocation $\vec{x^*}$.

The rest of the subsection focuses on proving Lemma~\ref{lem:binary-greedy-ratio}.
We assume without loss of generality that the agents are sorted by their utilities for the algorithm's allocation, i.e.:
%
\[
    u_1 \le u_2 \le \dots \le u_N
    ~.
\]

We start with the following lemma which links the agents' utilities $\vec{u}$ for the algorithm's allocation, and their utilities $\vec{\tilde{u}}$ for the benchmark allocation $\vec{\tilde{x}}$.
%In order to prove Lemma \ref{lem:binary-greedy-ratio}, we first find the worst possible $(u_i)_{i\in[N]}$ allocated by the algorithm, and then bound the competitive ratio of this allocation.
\begin{lemma}
    \label{lem:binary-inquality}
    For any $1 \le i \le N$:
    %
    \begin{equation}
        \label{eqn:binary-inquality}
        \sum_{j=1}^{i}\tilde{u}_j\leq\sum_{j=1}^{N}\min\{u_i,u_j\}.
    \end{equation}
\end{lemma}

\begin{proof}
    For any fixed $1 \le i \le N$, let $S_i$ be the set of items for which at least one of agents $1$ to $i$ have positive values, i.e.:
    %
    \[
        S_i = \Big\{ 1 \le t \le T : \exists 1 \le j \le i, v_{jt} = v_t \Big\}
        ~.
    \]

    Then, the left-hand side of Equation~\eqref{eqn:binary-inquality} is upper bounded by:
    %
    \[
        \sum_{j=1}^i \tilde{u}_j \le \sum_{t \in S_i} s_t v_t
        ~.
    \]

    To prove the lemma, it remains to show that the items in $S_i$ contribute at most $\min \{ u_i, u_j \}$ to any agent $j$'s utility for the algorithm's allocation.
    For agents $1 \le j \le i$, this is trivially true because the stated utility bound is simply $u_j$.
    For any agent $j > i$, consider the last moment when it receives a positive amount of some item $t$ in $S_i$.
    It suffices to show that its utility is at most $u_i$ after the allocation of item $t$.
    Recall that the Myopic Greedy algorithm is a greedy algorithm with anticipated utilities.
    First by the assumption of binary values and by Equation~\eqref{eqn:greedy-predicted-utility-optimal}, we conclude that any agent who receives a positive amount of item $t$ must have the smallest utility among all agents with values $v_t$ for item $t$, after the allocation of item $t$.
    Meanwhile, one of the agents from $1$ to $i$ has value $v_t$ for the item since $t \in S_i$, and this agent has utility at most $u_i$.
    Therefore, agent $j$'s utility after the allocation of item $t$ is at most $u_i$ as desired.
\end{proof}

If we view the agents' utilities $\vec{u}$ for the algorithm's allocation as variables, Lemma~\ref{lem:binary-inquality} offers a set of linear inequalities that relates them with the benchmark utilities $\vec{\tilde{u}}$.
The next lemma shows that subject to these inequalities, the smallest Nash welfare w.r.t.\ $\vec{u}$ is achieved when the inequalities all hold with equalities.

\begin{lemma}
    \label{lem:binary-utility}
    For any non-negative $\vec{u} = (u_i)_{1 \le i \le N}$ and $\vec{\tilde{u}} = (\tilde{u}_i)_{1 \le i \le N}$ that satisfy the inequality in Equation~\eqref{eqn:binary-inquality}, we have:
    %
    \begin{equation}
        \label{eqn:binary-utility}
        \sum_{i=1}^{N} \log u_i ~ \geq ~ \sum_{i = 1}^{N} \log\left( \sum_{j = 1}^{i}\frac{\tilde{u}_i}{N+1-j} \right)
        ~.
    \end{equation}
\end{lemma}

\begin{proof}
    For ease of exposition, we rewrite Equation~\eqref{eqn:binary-inquality} as:
    \begin{equation}
        \label{eqn:step-function}
        \left\{
        \begin{aligned}
            &u_1 \cdot N& \geq~ &\tilde{u}_1\\
            &u_1 \cdot N + (u_2 - u_1) \cdot (N - 1) &\geq~ &\tilde{u}_1+\tilde{u}_2\\
            &...\\
            &u_1 \cdot N + \sum_{i = 1}^{N-1} ((u_{i+1} - u_{i}) \cdot (N - i) ) &\geq &\sum_{i}^{N} \tilde{u}_i
        \end{aligned}
        \right.
    \end{equation}
    Along with the restrictions $u_1\leq u_2\leq \cdots \le u_N$, the feasible region of $(u_i)_{i\in[N]}$ is a polytope. Since $\sum_{i=1}^{N} \log u_i$ is concave, it reaches minimum at a vertex of the polytope, i.e., where exactly $n$ of the inequalities are equalities. Let $(\bar{u}_i)_{i\in[N]}$ be a solution with minimum $\sum_{i=1}^{N} \log u_i$. Suppose there exists $i$ such that $\bar{u}_i=\bar{u}_{i+1}$. Let $i^*$ be the smallest such $i$. The $i^*$-th inequality in Equation \eqref{eqn:step-function} is not tight.

    Define $(u'_1,u'_2,\cdots,u'_N)$ as
    \begin{equation}
        \left\{
        \begin{aligned}
           &u'_i = \bar{u}_i & \qquad &\forall i< i^*\\
           &u'_i = \bar{u}_i-\varepsilon & &i=i^*\\
           &u'_i = \bar{u}_i+\frac{\varepsilon}{N-i} & &\forall i>i^*
        \end{aligned}
        \right.
    \end{equation}
    for sufficiently small $\varepsilon>0$. $(u'_1,u'_2,\cdots,u'_N)$ satisfies Equation \eqref{eqn:step-function}, and $u'_1u'_2\cdots u'_N<\bar{u}_1\bar{u}_2\cdots\bar{u}_N$ holds since $\bar{u}_i$ is the smallest among $\bar{u}_i,\bar{u}_{i+1},\cdots,\bar{u}_N$, contradicting the minimality of $(\bar{u}_i)_{i\in[N]}$.

    Therefore, $u_i=\sum_{i' = 1}^{i}\frac{\tilde{u}_i}{N+1-i'}$ in the  solution that minimizes $\sum_{i=1}^{N} \log u_i$.
\end{proof}

We will relax the denominators on the right-hand side of Equation \eqref{eqn:binary-utility} to be $N$ in the subsequent analysis.
We get that:
%
\begin{equation}
    \label{eqn:impartial-binary-relaxed-bound}
    \sum_{i=1}^{N} \log u_i ~ \geq ~ \sum_{i = 1}^{N} \log \left( \frac{1}{i} \sum_{j = 1}^{i} \tilde{u}_i \right) - \log \frac{N^N}{N!}
    ~.
\end{equation}


If the benchmark allocation $\vec{\tilde{x}}$ was $1$-impartial, we would have $\tilde{u}_i = \big(\prod_{j=1}^N \tilde{u}_j \big)^{\frac{1}{N}}$ for all agents $1 \le i \le N$.
In that case, the above Inequality~\eqref{eqn:impartial-binary-relaxed-bound} would already imply a constant competitive ratio because it can be written as:
%
\[
    \log \left(\prod_{i=1}^N u_i\right)^{\frac{1}{N}} ~ \geq ~ \log \left(\prod_{i=1}^N \tilde{u}_i\right)^{\frac{1}{N}} - ~ \log \frac{N}{(N!)^{\frac{1}{N}}}
    ~,
\]
%
where the second term on the right-hand side is $O(1)$ by Stirling's approximation.

For $\mu$-impartial instances with an arbitrary $\mu \ge 1$, we need one more inequality given in the next lemma.
The form of the inequality is clean so we suspect that it may have already been proved in the past.
To our best effort, however, we only found Hardy's Inequality and its several variants (c.f., \citet*{HardyLP:1952}) to have a similar spirit as they also compare the function values of a sequence of non-negative real numbers and the functions values of their prefix averages;
but those inequalities do not imply our lemma.
It would be interesting to find further applications of this inequality in other problems.

%Given the worst possible allocation $(u_i)_{i\in[N]}$ by the algorithm, the calculation of competitive ratio relies on the following lemma, whose proof is deferred to Section \ref{sec:binary-upper-bound-proof}.

\begin{lemma}
    \label{lem:binary-upper-bound}
    Suppose that $a_1, a_2, \dots, a_N$ are real numbers between $1$ and $\mu$.
    We have:
    %
    \[
        \frac{1}{N} \sum_{i=1}^N \log a_i ~ - ~ \frac{1}{N} \sum_{i=1}^N \log \left(
        \frac{1}{i} \sum_{j=1}^i a_j \right) ~ \le ~ \log (\log \mu + 1) + 1
        ~.
    \]
\end{lemma}

\begin{proof}
    It is without loss of generality to assume that $a_1 \le a_2 \le \dots \le a_N$ since this order minimizes the second term on the left-hand side conditioned on the set of these $N$ real numbers.
    We may further assume $a_1 = 1$ because the left-hand side remains the same if $a_1, a_2, \dots, a_N$ are multiplied by the same factor.

    Our proof strategy is to consider all possible thresholds $\theta \ge 0$ and to bound the number of indices ($1 \le i \le N$) for which $\log a_i - \log \frac{1}{i} \sum_{j=1}^i a_j$ is at least $\theta$.
    First, we rewrite the left-hand side as:
    %
    \[
        \int_{0}^{\infty} \frac{\sum_{i = 1} ^{N} \mathbf{1} \big(\, \log a_i - \log (\frac{1}{i} \sum_{j=1}^i a_j) \geq \theta \,\big)}{N} \dif{\theta}
        ~,
    \]
    where $\mathbf{1}(\cdot)$ is the indicator function.
    
    For any $\theta \geq 0$, suppose that $i_1 < i_2 < \cdots < i_k$ are the indices for which
    %
    \[
        \log a_i - \log \left( \frac{1}{i} \sum_{j=1}^i a_j \right) \geq \theta
        ~.
    \]

    First, by $a_1 = 1 < a_{i_1}$ and $a_j \le a_{i_1}$ for all $j \le i$, the left-hand side above is strictly smaller than $\log i_1$ when $i = i_1$.
    This gives $i_1 > e^\theta$.

    For ease of exposition, in the remaining argument we define $i_0 = 1, a_{i_0}=1$.
    Then, we have that for any $j \ge 1$:
    %
    \begin{align*}
        \frac{i_j}{e^{\theta}}a_{i_j} \ge & ~ \left(a_1 + a_2 + \cdots + a_{i_j}\right) \\
        \geq & ~ (i_1 - i_0) a_{i_0} + (i_2 - i_1) a_{i_1} + \cdots + (i_j - i_{j-1}) a_{i_{j-1}} + a_{i_j}
        ~.
    \end{align*}

    Subject to these inequalities, $a_{i_k}$ achieves its minimum value when equalities hold everywhere.
    In that case, for any $j \ge 1$ we have (by taking the difference of two consecutive equalities):
    %
    \[
        \frac{i_{j+1}}{e^{\theta}} a_{i_{j+1}} - \frac{i_j}{e^{\theta}} a_{i_j} = (i_{j+1} - i_j - 1) a_{i_j} + a_{i_{j+1}}
        ~.
    \]

    Therefore:
    %
    \begin{align*}
        a_{i_{j+1}} = & ~\left( e^{\theta} - \frac{ (e^{\theta} - 1) (\frac{i_j}{e^{\theta}} - 1) }{ \frac{i_{j+1}}{e^{\theta}} - 1 } \right) a_{i_j}  \\
        \geq & ~ \left( e^{\theta} - \frac{ (e^{\theta} - 1) (\frac{i_j}{e^{\theta}} - 1) }{ \frac{i_j+1}{e^{\theta}} - 1 } \right) a_{i_j}
        &&
        \text{($i_{j+1} \geq i_j + 1$)} \\
        \geq & ~ \left( e^{\theta} - \frac{ (e^{\theta} - 1) (\frac{N}{e^{\theta}} - 1) }{ \frac{N+1}{e^{\theta}} - 1 } \right) a_{i_j} 
        &&
        \text{($i_j \leq N$)} \\
        = & ~ \frac{1}{1 - \frac{e^{\theta} - 1}{N}} a_{i_j} \\
        \geq & ~ e^{\frac{e^{\theta} - 1}{N}} a_{i_j}
        ~.
        && \text{($1-y \leq e^{-y}$)}
    \end{align*}

    For $a_{i_1}$, we have $a_{i_1} = \frac{e^\theta}{i_1} (i_1-1 + a_{i_1})$ which means (recall that $i_1 > e^\theta$):
    %
    \[
        a_{i_1} = \frac{(i_1-1) e^\theta}{i_1 - e^\theta}  \ge \frac{N e^\theta}{(N+1) e^{-\theta} - 1} = \frac{e^\theta}{1 - \frac{e^\theta-1}{N}} \ge \frac{1}{1 - \frac{e^\theta-1}{N}} \ge e^{\frac{e^\theta-1}{N}}
        ~.
    \]

    Combining the above two inequalities, we get that $a_{i_k} \ge e^{\frac{k}{N} (e^\theta-1)}$.
    On the other hand, we have $a_{i_k} \le \mu$.
    Hence:
    %
    \[
        \frac{k}{N} \le \frac{\log \mu}{e^\theta - 1}
        ~.
    \]
    
    Therefore, the left-hand side of the lemma's inequality is at most:
    \begin{align*}
        \int_{0}^{\infty} \min\left\{\frac{\log \mu}{e^{\theta} - 1}, 1 \right\} \dif{\theta}
        &
        = \int_{0}^{\log(\log \mu + 1)} 1 \dif{\theta} + \int_{\log(\log \mu + 1)}^{\infty} \frac{\log \mu}{e^{\theta} - 1} \dif{\theta} \\
        &
        = \log (\log \mu + 1) + \log \mu \cdot \log \left( 1 + \frac{1}{\log\mu} \right) \\[1ex]
        &
        \le \log (\log \mu + 1) + 1 
        ~,
    \end{align*}
    %
    where the last inequality follows by $\log(1+y) \le y$ for any $y \ge 0$.
\end{proof}

Lemma~\ref{lem:binary-greedy-ratio} then follows by combining Equation~\eqref{eqn:impartial-binary-relaxed-bound}, Stirling's approximation, and Lemma~\ref{lem:binary-upper-bound} with $a_i = \frac{\tilde{u}_i}{\min_{1 \le j \le N} \tilde{u}_j}$ and $\mu = \tilde{\mu}$.
