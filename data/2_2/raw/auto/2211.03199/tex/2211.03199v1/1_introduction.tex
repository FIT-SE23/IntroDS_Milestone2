\section{Introduction}
\label{sec:introduction}

Deep learning has made a substantial impact on a number of industrial and research areas.
This includes computer vision, as the rapid development of representation learning started with the seminal work of \cite{krizhevsky2017imagenet} for the image classification task.
However, numerous state-of-the-art models often require large amounts of data to train, which can be costly to gather and label -- especially for vision-related tasks.
Therefore, an intense research effort can be observed in the area of data-efficient machine learning methods.
Few-shot learning (often abbreviated as FSL) is a machine learning task, where the machine learning model is (partially) trained on a small amount of data -- part of the labelled data is available in standard amounts, whereas the other part consists of only a few (typically less than 10) samples per class.
Few-shot learning can also suffer from selection bias since the decision boundaries need to be adjusted to a new few samples, which can contain irrelevant and misleading artefacts (such as a background colour).
Hence the learning process is substantially more challenging.

One way to tackle the few-shot learning task is to use some prior knowledge of the labelled data.
Knowledge Graph Transfer Network (KGTN), the recent work of \cite{chen2020knowledge}, solves this problem by learning the prototypes from the external sources of knowledge and comparing them against extracted features from an input image.
A similarity function scores the output of these two and yields the class probability distribution. 
These external sources of knowledge are represented as class correlation matrices.
A vital element of this architecture is the knowledge graph transfer module (KGTM), which tries to learn class prototypes from knowledge graph embeddings using gated graph neural networks (GGTN) \citep{li2016gated}.

In the KGTN approach, one has to select a single knowledge source.
Inspired by ensemble learning approaches, this observation leads us to the following questions: is it possible to learn prototypes from multiple knowledge graph embeddings?
If so, will it result in higher performance metrics values, such as accuracy for classification problems?
Therefore, we propose KGTN-ens, an extension of KGTN, that use multiple embeddings instead of a single one. 
Each of them generates different prototypes, which are later combined and compared against the output of the feature extractor. 
We test two ensemble learning techniques in this paper.
We also evaluated different combinations of three knowledge graphs, one of which (based on Wikidata) is introduced by us and has not been used in the original paper.
Our solution is knowledge graph agnostic, provided that the knowledge graph is embedded and linked to the classes used in the image classification.

The contribution of this paper is two-fold: (1)~we propose KGTN-ens, a new method based on KGTN, and evaluate it with different combinations of embeddings, (2)~we construct a new knowledge source -- Wikidata embeddings --  and evaluate it with KGTN and KGTN-ens.
Our approach outperforms KGTN in terms of the top-5 accuracy on the ImageNet-FS dataset for the majority of tested settings.

The remainder of this paper is organised as follows.
A~comprehensive literature survey on related work is presented in Section \ref{sec:related_work}.
Section \ref{sec:method} provides a description of the KGTN-ens architecture.
Section \ref{sec:results} describes the results of the evaluation of Wikidata embeddings with KGTN and KGTN-ens with different combinations of embeddings, along with the detailed analysis and ablation studies.
Section \ref{sec:conclusion} concludes the paper.
