\section{Related work}
\label{sec:related_work}

This section provides a comprehensive overview of the related work.
We start with a brief review of the techniques used for graph neural networks, which are at the core of the KGTN-ens architecture.
Then, we provide a short survey on recent advancements in few-shot learning, which is the main machine learning task solved by the architecture presented in this paper.

\textbf{Graph neural networks.}
In general, Graph neural networks (GNNs) represent a type of neural network, which processes the specified attributes of the graphs.
Task tackled by GNN can be either node-level (such as prediction of a property for each node), edge-level (prediction of a property for each edge), or graph-level (prediction of a property for a whole graph) \citep{sanchez-lengeling2021a}.
Following \cite[]{keriven2019universal}, a crucial feature of GNNs is being either invariant or equivariant to permutations.
That is, for a graph $\mathcal{G}$, network $f$ and a permutation $\Pi$ we have $f(\Pi \star \mathcal{G})=f(\mathcal{G})$ and $f(\Pi \star \mathcal{G})=\Pi \star f(\mathcal{G})$ for invariance and equivariance respectively.
The general-purpose models from the state-of-the-art family of transformer architectures \cite{vaswani2017attention} can be viewed as a special instance of a graph neural network.
Graph neural networks have a wide area of applications, with notable examples in biology (e.g. protein interface prediction) or social networks (e.g. community detection or link prediction).
The less obvious application of GNNs is in the field of image classification, where they are used to learn the prototypes from the knowledge graph embeddings in a few-shot learning setting.

GNNs fall into a broader category of geometric deep learning, which is devoted to the application of deep neural networks on structured non-Euclidean domains, such as graphs, manifolds, meshes, or grids \citep{bronstein2017geometric}.
\cite{gilmer2017neural} proposed \emph{message passing}, which is one of the most important concepts in GNNs.
In this approach, nodes and/or edges can rely on their neighbours in order to create meaningful embeddings iteratively.
\cite{wu2020comprehensive} classify GNNs into four broad categories: recurrent GNNs (RecGNN), convolutional GNNs (ConvGNNs), graph autoencoders (GAEs), and spatial-temporal GNNs (STGNNs).
In this article, Gated Graph Neural Network (GGNN) \citep{li2016gated} are of special interest.
They belong to the category of RecGNNs.
For a fair comparison with KGTN (our baseline), we used GGNN in our experiments.
Following \cite{li2016gated}, the intuitive difference between GNN and GGNN relies on the explicit graph structure of GNNs, which results in more generalisation capabilities at the expense of a less general model of the latter.



\textbf{Few-shot learning.}
While being very effective for numerous vision tasks, one of the main problems with convolutional neural networks (or machine learning in general) is the amount of data they need to provide meaningful predictions.
More recent architectures, such as self-attention models require even more data to train.
On contrary, humans typically require only a few samples to acquire knowledge of seen objects.
One way to tackle this issue is few-shot learning, which is aimed at learning from scarce data.
The complexity of the problem often stems from the required sudden shift of decision boundaries, which is hard to achieve using only a few samples.
A special case of few-shot learning is one-shot learning, which is learning from one labelled sample per class.

Following \cite{song2022comprehensive}, few-shot learning methods can be divided into data augmentation, transfer learning, meta-learning, and multimodal learning.
Data augmentation techniques aim to artificially extend the amount of available data by either transforming input data \citep{chen2019image} or resulting features \citep{chen2019multi}.
Transfer learning focuses on resuing features from networks trained on different datasets with the required amount of data by techniques such as pre-training and fine-tuning or domain adaptation.
Meta-learning includes techniques devoted to learning from data and tasks in order to reuse this knowledge for future downstream tasks.
\cite{finn2017model} proposed a model agnostic meta-learning algorithm MAML.
Specialised approaches to meta-learning include neural architecture search \citep{elsken2019neural} or metric learning \citep{ge2018deep,chicco2021siamese}.
Finally, multimodal learning focuses on the incorporation of external knowledge from heterogenous domains, such as text, speech or knowledge graphs \citep{wang2020large}.

The concept of prototypes was introduced in the work of \cite{snell2017prototypical}, where they proposed prototypical networks focused on learning metric space between class instances and their prototypes.
\cite{hariharan2017low} used representation regularisation and introduced the concept of \emph{hallucinations} in order to enlarge the number of available representations during the training.  
% AWG \cite{gidaris2018dynamic} 
\cite{wang2018low} employed meta-learning techniques and combined them with the aforementioned \emph{hallucinations} to improve few-shot classification metrics.
% LSD \cite{douze2018low} 
A growing number of scholars incorporate structured knowledge into their computer vision research \cite[]{monka2022survey}.
For instance, \cite{li2019large} studied transferable features with the hierarchy which encodes the semantic relations.
Their approach turned out to be applicable to the problem of zero-shot learning as well.
\cite{shen2021model} proposed model agnostic regularisation technique in order to leverage the relationship between graph labels to preserve category neighbourhood.