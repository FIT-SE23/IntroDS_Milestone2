@inproceedings{bagby2018efficient,
	title={Efficient implementation of recurrent neural network transducer in tensorflow},
	author={Bagby, Tom and Rao, Kanishka and Sim, Khe Chai},
	booktitle={2018 IEEE Spoken Language Technology Workshop (SLT)},
	pages={506--512},
	year={2018},
	organization={IEEE}
}

@article{li2019improving,
	title={Improving RNN Transducer Modeling for End-to-End Speech Recognition},
	author={Li, Jinyu and Zhao, Rui and Hu, Hu and Gong, Yifan},
	journal={arXiv: Computation and Language},
	year={2019}}


%% first propose rnnt
@article{graves2012sequence,
	title={Sequence transduction with recurrent neural networks},
	author={Graves, Alex},
	journal={arXiv preprint arXiv:1211.3711},
	year={2012}
}

%% first propose rnnt pretrain
@inproceedings{graves2013speech,
	title={Speech recognition with deep recurrent neural networks},
	author={Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},
	booktitle={2013 IEEE international conference on acoustics, speech and signal processing},
	pages={6645--6649},
	year={2013},
	organization={IEEE}
}

%% first propose ctc
@inproceedings{graves2006connectionist,
	title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
	author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
	booktitle={Proceedings of the 23rd international conference on Machine learning},
	pages={369--376},
	year={2006},
	organization={ACM}
}


@inproceedings{vaswani2017attention,
	title={Attention is all you need},
	author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	booktitle={Advances in Neural Information Processing Systems},
	pages={5998--6008},
	year={2017}
}

%% chunk transducer
@inproceedings{sainath2018improving,
	title={Improving the performance of online neural transducer models},
	author={Sainath, Tara N and Chiu, Chung-Cheng and Prabhavalkar, Rohit and Kannan, Anjuli and Wu, Yonghui and Nguyen, Patrick and Chen, ZhiJeng},
	booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={5864--5868},
	year={2018},
	organization={IEEE}
}

%% neural transducer
@article{jaitly2015neural,
	title={A neural transducer},
	author={Jaitly, Navdeep and Sussillo, David and Le, Quoc V and Vinyals, Oriol and Sutskever, Ilya and Bengio, Samy},
	journal={arXiv preprint arXiv:1511.04868},
	year={2015}
}

%% online transducer
@inproceedings{jaitly2016online,
	title={An online sequence-to-sequence model using partial conditioning},
	author={Jaitly, Navdeep and Le, Quoc V and Vinyals, Oriol and Sutskever, Ilya and Sussillo, David and Bengio, Samy},
	booktitle={Advances in Neural Information Processing Systems},
	pages={5067--5075},
	year={2016}
}

%% speech transformer
@inproceedings{dong2018speech,
	title={Speech-transformer: a no-recurrence sequence-to-sequence model for speech recognition},
	author={Dong, Linhao and Xu, Shuang and Xu, Bo},
	booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={5884--5888},
	year={2018},
	organization={IEEE}
}

%% pretrain rnnt
@inproceedings{rao2017exploring,
	title={Exploring architectures, data and units for streaming end-to-end speech recognition with RNN-transducer},
	author={Rao, Kanishka and Sak, Ha{\c{s}}im and Prabhavalkar, Rohit},
	booktitle={2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
	pages={193--199},
	year={2017},
	organization={IEEE}
}
%% compare ctc attn and rnnt
@inproceedings{battenberg2017exploring,
	title={Exploring neural transducers for end-to-end speech recognition},
	author={Battenberg, Eric and Chen, Jitong and Child, Rewon and Coates, Adam and Li, Yashesh Gaur Yi and Liu, Hairong and Satheesh, Sanjeev and Sriram, Anuroop and Zhu, Zhenyao},
	booktitle={2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
	pages={206--213},
	year={2017},
	organization={IEEE}
}

%% streaming rnnT
@article{he2018streaming,
	title={Streaming End-to-end Speech Recognition For Mobile Devices.},
	author={He, Yanzhang and Sainath, Tara N and Prabhavalkar, Rohit and Mcgraw, Ian and Alvarez, Raziel and Zhao, Ding and Rybach, David and Kannan, Anjuli and Wu, Yonghui and Pang, Ruoming and others},
	journal={arXiv: Computation and Language},
	year={2018}}

@inproceedings{chorowski2015attention,
	title={Attention-based models for speech recognition},
	author={Chorowski, Jan K and Bahdanau, Dzmitry and Serdyuk, Dmitriy and Cho, Kyunghyun and Bengio, Yoshua},
	booktitle={Advances in neural information processing systems},
	pages={577--585},
	year={2015}
}

@inproceedings{chan2016listen,
	title={Listen, attend and spell: A neural network for large vocabulary conversational speech recognition},
	author={Chan, William and Jaitly, Navdeep and Le, Quoc and Vinyals, Oriol},
	booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={4960--4964},
	year={2016},
	organization={IEEE}
}

%% neural aligner
@inproceedings{sak2017recurrent,
	title={Recurrent Neural Aligner: An Encoder-Decoder Neural Network Model for Sequence to Sequence Mapping.},
	author={Sak, Hasim and Shannon, Matt and Rao, Kanishka and Beaufays, Fran{\c{c}}oise},
	booktitle={Interspeech},
	pages={1298--1302},
	year={2017}
}

%% neural aligner
@inproceedings{zhengkun2019sat,
	title={Self-Attention Transducers for End-to-End Speech Recognition.},
	author={Tian, Zhengkun and Yi, Jiangyan and Tao, Jianhua and Bai, Ye and Wen, Zhengqi},
	booktitle={Interspeech},
	pages={4395â€“-4399},
	year={2019}
}

% downsampling of RNNT
@inproceedings{battenberg2017exploring,
	title={Exploring neural transducers for end-to-end speech recognition},
	author={Battenberg, Eric and Chen, Jitong and Child, Rewon and Coates, Adam and Li, Yashesh Gaur Yi and Liu, Hairong and Satheesh, Sanjeev and Sriram, Anuroop and Zhu, Zhenyao},
	booktitle={2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
	pages={206--213},
	year={2017},
	organization={IEEE}
}

@article{ahmed2017weighted,
	title={Weighted transformer network for machine translation},
	author={Ahmed, Karim and Keskar, Nitish Shirish and Socher, Richard},
	journal={arXiv preprint arXiv:1711.02132},
	year={2017}
}

@article{zhou2018syllable,
	title={Syllable-based sequence-to-sequence speech recognition with the transformer in mandarin chinese},
	author={Zhou, Shiyu and Dong, Linhao and Xu, Shuang and Xu, Bo},
	journal={arXiv preprint arXiv:1804.10752},
	year={2018}
}

%% joint ctc and attention
@inproceedings{kim2017joint,
	title={Joint CTC-attention based end-to-end speech recognition using multi-task learning},
	author={Kim, Suyoun and Hori, Takaaki and Watanabe, Shinji},
	booktitle={2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
	pages={4835--4839},
	year={2017},
	organization={IEEE}
}

%% first attention for speech
@inproceedings{chorowski2015attention,
	title={Attention-based models for speech recognition},
	author={Chorowski, Jan K and Bahdanau, Dzmitry and Serdyuk, Dmitriy and Cho, Kyunghyun and Bengio, Yoshua},
	booktitle={Advances in neural information processing systems},
	pages={577--585},
	year={2015}
}

% image caption
@inproceedings{vinyals2015show,
	title={Show and tell: A neural image caption generator},
	author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={3156--3164},
	year={2015}
}

%% neural machine translation
@article{bahdanau2014neural,
	title={Neural machine translation by jointly learning to align and translate},
	author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	journal={arXiv preprint arXiv:1409.0473},
	year={2014}
}

%% triggerd attention
@inproceedings{moritz2019triggered,
	title={Triggered Attention for End-to-end Speech Recognition},
	author={Moritz, Niko and Hori, Takaaki and Le Roux, Jonathan},
	booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={5666--5670},
	year={2019},
	organization={IEEE}
}

@inproceedings{dong2020cif,
	title={CIF: Continuous integrate-and-fire for end-to-end speech recognition},
	author={Dong, Linhao and Xu, Bo},
	booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={6079--6083},
	year={2020},
	organization={IEEE}
}

@inproceedings{tian2020synchronous,
	title={Synchronous transformers for end-to-end speech recognition},
	author={Tian, Zhengkun and Yi, Jiangyan and Bai, Ye and Tao, Jianhua and Zhang, Shuai and Wen, Zhengqi},
	booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={7884--7888},
	year={2020},
	organization={IEEE}
}

@inproceedings{Tian2019,
	author={Zhengkun Tian and Jiangyan Yi and Jianhua Tao and Ye Bai and Zhengqi Wen},
	title={{Self-Attention Transducers for End-to-End Speech Recognition}},
	year=2019,
	booktitle={Proc. Interspeech 2019},
	pages={4395--4399},
	doi={10.21437/Interspeech.2019-2203},
	url={http://dx.doi.org/10.21437/Interspeech.2019-2203}
}

%% mocha
@article{chiu2017monotonic,
	title={Monotonic chunkwise attention},
	author={Chiu, Chung-Cheng and Raffel, Colin},
	journal={arXiv preprint arXiv:1712.05382},
	year={2017}
}

%% accumlate information
@article{dong2019cif,
	title={CIF: Continuous Integrate-and-Fire for End-to-End Speech Recognition},
	author={Dong, Linhao and Xu, Bo},
	journal={arXiv preprint arXiv:1905.11235},
	year={2019}
}

%% local attention
@article{tjandra2017local,
	title={Local monotonic attention mechanism for end-to-end speech and language processing},
	author={Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi},
	journal={arXiv preprint arXiv:1705.08091},
	year={2017}
}

@inproceedings{sainath2018improving,
	title={Improving the performance of online neural transducer models},
	author={Sainath, Tara N and Chiu, Chung-Cheng and Prabhavalkar, Rohit and Kannan, Anjuli and Wu, Yonghui and Nguyen, Patrick and Chen, ZhiJeng},
	booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={5864--5868},
	year={2018},
	organization={IEEE}
}

@article{dai2019transformer,
	title={Transformer-xl: Attentive language models beyond a fixed-length context},
	author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Cohen, William W and Carbonell, Jaime and Le, Quoc V and Salakhutdinov, Ruslan},
	journal={arXiv preprint arXiv:1901.02860},
	year={2019}
}

@article{watanabe2017hybrid,
	title={Hybrid CTC/attention architecture for end-to-end speech recognition},
	author={Watanabe, Shinji and Hori, Takaaki and Kim, Suyoun and Hershey, John R and Hayashi, Tomoki},
	journal={IEEE Journal of Selected Topics in Signal Processing},
	volume={11},
	number={8},
	pages={1240--1253},
	year={2017},
	publisher={IEEE}
}

@inproceedings{bagby2018efficient,
	title={Efficient Implementation of Recurrent Neural Network Transducer in Tensorflow},
	author={Bagby, Tom and Rao, Kanishka and Sim, Khe Chai},
	booktitle={2018 IEEE Spoken Language Technology Workshop (SLT)},
	pages={506--512},
	year={2018},
	organization={IEEE}
}

@article{li2019improving,
	title={Improving RNN Transducer Modeling for End-to-End Speech Recognition},
	author={Li, Jinyu and Zhao, Rui and Hu, Hu and Gong, Yifan},
	journal={arXiv preprint arXiv:1909.12415},
	year={2019}
}

@inproceedings{bu2017aishell,
	title={Aishell-1: An open-source mandarin speech corpus and a speech recognition baseline},
	author={Bu, Hui and Du, Jiayu and Na, Xingyu and Wu, Bengu and Zheng, Hao},
	booktitle={2017 20th Conference of the Oriental Chapter of the International Coordinating Committee on Speech Databases and Speech I/O Systems and Assessment (O-COCOSDA)},
	pages={1--5},
	year={2017},
	organization={IEEE}
}

@techreport{povey2011kaldi,
	title={The Kaldi speech recognition toolkit},
	author={Povey, Daniel and Ghoshal, Arnab and Boulianne, Gilles and Burget, Lukas and Glembek, Ondrej and Goel, Nagendra and Hannemann, Mirko and Motlicek, Petr and Qian, Yanmin and Schwarz, Petr and others},
	year={2011},
	institution={IEEE Signal Processing Society}
}

@article{watanabe2018espnet,
	title={Espnet: End-to-end speech processing toolkit},
	author={Watanabe, Shinji and Hori, Takaaki and Karita, Shigeki and Hayashi, Tomoki and Nishitoba, Jiro and Unno, Yuya and Soplin, Nelson Enrique Yalta and Heymann, Jahn and Wiesner, Matthew and Chen, Nanxin and others},
	journal={arXiv preprint arXiv:1804.00015},
	year={2018}
}

@inproceedings{dauphin2017language,
	title={Language modeling with gated convolutional networks},
	author={Dauphin, Yann N and Fan, Angela and Auli, Michael and Grangier, David},
	booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
	pages={933--941},
	year={2017},
	organization={JMLR. org}
}

@article{changhaoshan2019,
	title={COMPONENT FUSION: LEARNING REPLACEABLE LANGUAGE MODEL COMPONENT FOR END-TO-END SPEECH RECOGNITION SYSTEM},
	author={Shan, Changhao and Chao, Weng and Guangsen, Wang and Dan, Su and Min, Luo and Dong, Yu and Lei, Xie},
	booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	year={2019},
	organization={IEEE}
}

@article{hannun2014deep,
	title={Deep speech: Scaling up end-to-end speech recognition},
	author={Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and others},
	journal={arXiv preprint arXiv:1412.5567},
	year={2014}
}

@article{li2019jasper,
	title={Jasper: An end-to-end convolutional neural acoustic model},
	author={Li, Jason and Lavrukhin, Vitaly and Ginsburg, Boris and Leary, Ryan and Kuchaiev, Oleksii and Cohen, Jonathan M and Nguyen, Huyen and Gadde, Ravi Teja},
	journal={arXiv preprint arXiv:1904.03288},
	year={2019}
}

@article{han2020contextnet,
	title={ContextNet: Improving convolutional neural networks for automatic speech recognition with global context},
	author={Han, Wei and Zhang, Zhengdong and Zhang, Yu and Yu, Jiahui and Chiu, Chung-Cheng and Qin, James and Gulati, Anmol and Pang, Ruoming and Wu, Yonghui},
	journal={arXiv preprint arXiv:2005.03191},
	year={2020}
}

@inproceedings{kriman2020quartznet,
	title={Quartznet: Deep automatic speech recognition with 1d time-channel separable convolutions},
	author={Kriman, Samuel and Beliaev, Stanislav and Ginsburg, Boris and Huang, Jocelyn and Kuchaiev, Oleksii and Lavrukhin, Vitaly and Leary, Ryan and Li, Jason and Zhang, Yang},
	booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={6124--6128},
	year={2020},
	organization={IEEE}
}

@article{sainath2019two,
	title={Two-pass end-to-end speech recognition},
	author={Sainath, Tara N and Pang, Ruoming and Rybach, David and He, Yanzhang and Prabhavalkar, Rohit and Li, Wei and Visontai, Mirk{\'o} and Liang, Qiao and Strohman, Trevor and Wu, Yonghui and others},
	journal={arXiv preprint arXiv:1908.10992},
	year={2019}
}

@article{pham2019very,
	title={Very deep self-attention networks for end-to-end speech recognition},
	author={Pham, Ngoc-Quan and Nguyen, Thai-Son and Niehues, Jan and M{\"u}ller, Markus and St{\"u}ker, Sebastian and Waibel, Alexander},
	journal={arXiv preprint arXiv:1904.13377},
	year={2019}
}

@inproceedings{amodei2016deep,
	title={Deep speech 2: End-to-end speech recognition in english and mandarin},
	author={Amodei, Dario and Ananthanarayanan, Sundaram and Anubhai, Rishita and Bai, Jingliang and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Cheng, Qiang and Chen, Guoliang and others},
	booktitle={International conference on machine learning},
	pages={173--182},
	year={2016}
}

@article{sainath2019two,
	title={Two-pass end-to-end speech recognition},
	author={Sainath, Tara N and Pang, Ruoming and Rybach, David and He, Yanzhang and Prabhavalkar, Rohit and Li, Wei and Visontai, Mirk{\'o} and Liang, Qiao and Strohman, Trevor and Wu, Yonghui and others},
	journal={arXiv preprint arXiv:1908.10992},
	year={2019}
}

@article{park2019specaugment,
	title={Specaugment: A simple data augmentation method for automatic speech recognition},
	author={Park, Daniel S and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and Cubuk, Ekin D and Le, Quoc V},
	journal={arXiv preprint arXiv:1904.08779},
	year={2019}
}

@article{tian2020spike,
	title={Spike-Triggered Non-Autoregressive Transformer for End-to-End Speech Recognition},
	author={Tian, Zhengkun and Yi, Jiangyan and Tao, Jianhua and Bai, Ye and Zhang, Shuai and Wen, Zhengqi},
	journal={arXiv preprint arXiv:2005.07903},
	year={2020}
}

@inproceedings{salazar2019self,
	title={Self-attention networks for connectionist temporal classification in speech recognition},
	author={Salazar, Julian and Kirchhoff, Katrin and Huang, Zhiheng},
	booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={7115--7119},
	year={2019},
	organization={IEEE}
}

@inproceedings{yu2021fastemit,
	title={Fastemit: Low-latency streaming asr with sequence-level emission regularization},
	author={Yu, Jiahui and Chiu, Chung-Cheng and Li, Bo and Chang, Shuo-yiin and Sainath, Tara N and He, Yanzhang and Narayanan, Arun and Han, Wei and Gulati, Anmol and Wu, Yonghui and others},
	booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={6004--6008},
	year={2021},
	organization={IEEE}
}

@article{kim2021reducing,
	title={Reducing streaming ASR model delay with self alignment},
	author={Kim, Jaeyoung and Lu, Han and Tripathi, Anshuman and Zhang, Qian and Sak, Hasim},
	journal={arXiv preprint arXiv:2105.05005},
	year={2021}
}

@inproceedings{li2021better,
	title={A better and faster end-to-end model for streaming asr},
	author={Li, Bo and Gulati, Anmol and Yu, Jiahui and Sainath, Tara N and Chiu, Chung-Cheng and Narayanan, Arun and Chang, Shuo-Yiin and Pang, Ruoming and He, Yanzhang and Qin, James and others},
	booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={5634--5638},
	year={2021},
	organization={IEEE}
}

@inproceedings{shinohara22_interspeech,
	author={Yusuke Shinohara and Shinji Watanabe},
	title={{Minimum latency training of sequence transducers for streaming end-to-end speech recognition}},
	year=2022,
	booktitle={Proc. Interspeech 2022},
	pages={2098--2102},
	doi={10.21437/Interspeech.2022-10989}
}

@inproceedings{senior2015acoustic,
	title={Acoustic modelling with cd-ctc-smbr lstm rnns},
	author={Senior, Andrew and Sak, Ha{\c{s}}im and de Chaumont Quitry, F{\'e}lix and Sainath, Tara and Rao, Kanishka},
	booktitle={2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)},
	pages={604--609},
	year={2015},
	organization={IEEE}
}

@article{tian2022bayes,
	title={Bayes risk CTC: Controllable CTC alignment in Sequence-to-Sequence tasks},
	author={Tian, Jinchuan and Yan, Brian and Yu, Jianwei and Weng, Chao and Yu, Dong and Watanabe, Shinji},
	journal={arXiv preprint arXiv:2210.07499},
	year={2022}
}

@article{inaguma2021stableemit,
	title={StableEmit: Selection probability discount for reducing emission latency of streaming monotonic attention ASR},
	author={Inaguma, Hirofumi and Kawahara, Tatsuya},
	journal={arXiv preprint arXiv:2107.00635},
	year={2021}
}

@inproceedings{tian21_interspeech,
	author={Zhengkun Tian and Jiangyan Yi and Ye Bai and Jianhua Tao and Shuai Zhang and Zhengqi Wen},
	title={{FSR: Accelerating the Inference Process of Transducer-Based Models by Applying Fast-Skip Regularization}},
	year=2021,
	booktitle={Proc. Interspeech 2021},
	pages={4034--4038},
	doi={10.21437/Interspeech.2021-1367}
}

@article{hendrycks2016gaussian,
	title={Gaussian error linear units (gelus)},
	author={Hendrycks, Dan and Gimpel, Kevin},
	journal={arXiv preprint arXiv:1606.08415},
	year={2016}
}
