%!TEX root = onetrace.tex

\def\cs{\mathsf{CS}}
\section{Average-case one-trace reconstruction, small deletion rate} \label{sec:worst-case-small-rho-informal}

\subsection{An efficient algorithm  improving on the \Cref{thm:worst-case-small-delta} bound}

In this section we show that the algorithm \textsc{Small-rate-reconstruct} of \Cref{thm:worst-case-small-delta}, that was shown to achieve LCS $(1 - \delta + \delta^2/2 - \delta^3/2 + \delta^4/2 - \delta^5/2 - o(1))n$ for worst-case source strings, in fact does better than this for average-case source strings.
The high level idea is that when there are $j$ additional bits between two trace bits in $\bx$ and $k$ additional bits between two trace bits in $\wh{\bx}'$, rather than matching only $\min\{j,k\}/2$ using the randomness of $\wh{\bx}'$, we take advantage of the facts that (i) both the $\bx$-bits and the $\wh{\bx}$-bits are uniform random, and (ii) if $j$ or $k$ is greater than 1, then the expected LCS between a random $j$-bit string and a random $k$-bit string is strictly larger than $\min\{j,k\}/2$, to obtain (on average) a better matching between these two blocks and hence a larger overall matching. This intuition motivates the following definition:
\begin{definition}
For integers $j,k >0$, we define $\cs(j,k)$ as 
\[\cs(j,k) := \Ex_{\bx \sim \zo^j,\bx' \sim \zo^k} \bigl[ |\LCS(\bx,\bx')| \bigr]. \]
Note that by definition, $\cs(j,k) = \cs(k,j)$, i.e., the function $\cs(\cdot, \cdot)$ is symmetric in its arguments. 
\end{definition}
While it is not clear if there is a simple explicit formula for $\cs(j,k)$, we note that a brute force algorithm can be used to compute this function. Further, for the special case of $j=k$, the function $\cs(\cdot, \cdot)$ has been studied previously in the literature~\cite{ChvatalSankoff75}. In particular, for any $d>0$, $\cs(d,d)$ is the same as the function $f(d,2)$ defined in \cite[Section 2]{ChvatalSankoff75}. Further, once $d \rightarrow \infty$, $\cs(d,d)/d$ is the same as the so-called Chvatal--Sankoff constant for the binary alphabet~\cite{kiwi2005expected,  ChvatalSankoff75}. \Cref{Tab:Tcr} gives the values of $\cs(j,k)$ for all $j + k \le 6$. 
\begin{center}
\begin{table}
\centering
\begin{tabular}{|*{6}{c|}}\cline{1-2}
  $k=5$ & $31/32$                 \\ \cline{1-3}
  $k=4$ & $15/16$ & $53/32$             \\ \cline{1-4}
  $k=3$ & $7/8$ & $23/16$ & $29/16$        \\ \cline{1-5}
  $k=2$ & $3/4$ & $9/8$ & $23/16$ & $53/32$    \\ \hline
  $k=1$ & $1/2$ & $3/4$ & $7/8$ & $15/16$ & $31/32$  \\ \hline
 value of $\cs(j,k)$   & $j=1$ & $j=2$ & $j=3$ & $j=4$ & $j=5$  \\ \hline
\end{tabular}
  
\caption{Table for values of $\cs(j,k)$ for $j+k \le 6$.} 
\label{Tab:Tcr}
\end{table}
\end{center}
\ignore{
%\red{
%The high level idea is that the matching process described in the proof of \Cref{thm:worst-case-small-delta} will sometimes encounter a block of $t>1$ many consecutive occasions on which the case (2) criterion (that $p_x \in [n] \setminus \bR$ and $p_{\wh{\bx}'} \notin \bT$ ) is satisfied. When this happens, rather than trying naively to match the $i$-th bit on the $\bx$-side of the block with the $i$-th bit on the $\wh{\bx}$-side of the block (which is what the deterministic process described in the proof of \Cref{thm:worst-case-small-delta} does), the idea is to take advantage of the facts that (i) both the $\bx$-bits and the $\wh{\bx}$-bits are uniform random, and (ii) for $t>1$, the expected LCS between two random $t$-bit strings is strictly larger than $t/2$, to obtain (on average) a better matching between these two blocks and hence a larger overall matching. This intuition motivates the following definition:
%}
}
\ignore{
\gray{
\begin{definition}
For an integer $d>0$, let $\cs(d)$ be defined as
\[
  \cs(d) := {\frac {\E_{\bx,\bx' \sim \zo^d}[|\LCS(\bx,\bx')|]}{d}},
\]
(so $\lim_{d \to \infty}\cs(d)$ is the Chvatal--Sankoff constant for the binary alphabet).
\end{definition}

In \cite[Section 2]{ChvatalSankoff75} (where $\cs(d) = f(d,2)/d$ for the $f$ defined in their paper), it was shown that for small values of $d$, we have
\begin{align*}
\cs(1) = {\frac 1 2}, \quad
\cs(2) = {\frac 9 {16}},\quad
\cs(3) = {\frac {29}{48}},
\end{align*}
and so on.
}
\bigskip \bigskip
\blue{Anindya proposes: generalize to 
\[
  \cs(j,k) := \Ex_{\bx \sim \zo^j,\bx' \sim \zo^k}[|\LCS(\bx,\bx')|],\]
  
  He will write down a little table of some values from $i,j=1$ up to $i+j=5$ or $6$.
}
}
\begin{theorem} \label{thm:small-delta-average-case-algorithm}
%Fix any integer $J>0$.  
Let $\delta=\delta(n)$ be the deletion rate. The $O(n)$-time algorithm \textsc{Small-rate-reconstruct} given in \Cref{thm:worst-case-small-delta} has the following property:  for any $\gamma > 0$ and sufficiently large $n$, algorithm \textsc{Small-rate-reconstruct} outputs a hypothesis string $\wh{\bx} \in \zo^n$ satisfying
  \begin{align*}
&\Ex_{\bx \in \zo^n}\Ex_{\by \sim \Del_{\delta}(\bx)} \bigl[ |\LCS(\wh{\bx},\bx)| \bigr] \\ 
&\geq
  \Bigl(1 - e^{-\Omega(\gamma^2 n)} \Bigr) (1 - \delta) \cdot \biggl( 1 + (1-\delta)^2\sum_{j,k=1}^\infty  \cs(j,k) \cdot \delta^{j+k}  \biggr) n  - 3\gamma n. 
  \end{align*}
  \end{theorem}
As an example,  instantiating with the values of $\cs(j,k)$ from Table~\ref{Tab:Tcr}, the above theorem  gives us that
\[
  L_{1,\avg}(\delta,n) 
  \ge \left( 1 - \delta + \frac12\delta^2   + \frac{17}{8}\delta^4 + \frac{55}{8}  \delta^5 + o(\delta^5) \right) n ,
\]
which improves on the  $(1 - \delta + \delta^2/2 -\delta^3/2   + \delta^4/2 -   \delta^5/2 - o(1))n$ bound of \Cref{thm:worst-case-small-delta}.
\ignore{
\gray{
So, for example, \Cref{thm:small-delta-average-case-algorithm} gives us that
\[
  L_{1,\avg}(\delta,n) 
  \ge \left( 1 - \delta + \frac{\delta^2}{2} - \frac{\delta^3}{2} + \frac{5\delta^4}{8} - \frac{5\delta^5}{8} + o(\delta^5) \right) n ,
  %\rnote{Check this - I got $-5\delta^5/8$ rather than $-\delta^5/8$}
\]
%\anote{My calculation also concurs with Rocco.} 
%\cnote{Fixed.}
which improves on the  $(1 - \delta + \delta^2/2 - \delta^3/2 + \delta^4/2 -  \delta^5/2 - o(1))n$ bound of \Cref{thm:worst-case-small-delta}.
}}

\begin{proof}
  The proof is analogous to the one in \Cref{thm:worst-case-small-delta}.
  We first replace $x$ in the proof of \Cref{thm:worst-case-small-delta} with a uniform random $\bx \sim \zo^n$ in the proof.

  Now, for each $i \in [\abs{\by}]$, let us define $\bd_i$ to be $\abs{\bx^i}$ and $\bd'_i$ to be  $\abs{\wh{\bx}'^i}$. Since the length-$(\bd_i-1)$ prefix of both $\bx^i$ and the length-$(\bd'_i-1)$ prefix of $\wh{\bx}'^i$ are independent random strings, and the last bit of both $\bx^i$ and $\wh{\bx}'^i$ are the same, we have  
  \[
    \E_{\bx^i, \wh{\bx}'^i} \Bigl[ \abs{\LCS(\bx^i, \wh{\bx}^i)} \Bigr] \ge \cs(\bd_i-1,\bd'_i-1) + 1.
  \]
  As $\bd_i \sim \Geo(1-\delta)$ and $\bd'_i \sim \Geo(1-\delta)$, we have
  \begin{align*}
    \E\bigl[\cs(\bd_i-1,\bd'_i-1)\bigr]
    &= \sum_{j,k=1}^\infty \Bigl( \cs(j,k) \cdot \Pr[\bd_i = j+1 \text{~and~}\bd'_i = k+1] \Bigr) \\
    &= \sum_{j,k=1}^\infty \Bigl( \cs(j,k) \cdot \Pr[\Geo(1-\delta) = j+1] \cdot \Pr[\Geo(1-\delta) = k+1] \Bigr) \\
    &=  (1-\delta)^2\sum_{j,k=1}^\infty  \cs(j,k) \cdot \delta^{j+k} .
%    &\ge (1-\delta^2) \left( \frac{1}{2} \delta^2 + \frac{9}{8} \delta^4 + \frac{29}{16} \delta^6 \right) .
  \end{align*}
  So we have
  \begin{align*}
    \E \Bigl[ \abs{\LCS(\bx, \wh{\bx}')} \Bigr]
    &\ge \sum_{i=1}^{\abs{\by}} \E_{\bx^i, \wh{\bx}'^i}  \Bigl[ \abs{\LCS(\bx^i, \wh{\bx}'^i)} \Bigr] \\
    &\ge \E\bigl[ \abs{\by} \bigr] + \E \bigl[ \abs{\by} \bigr] (1-\delta)^2\sum_{j,k=1}^\infty  \cs(j,k) \cdot \delta^{j+k} \\
    &\ge (1 - \delta) n \cdot \biggl( 1 + (1-\delta)^2\sum_{j,k=1}^\infty  \cs(j,k) \cdot \delta^{j+k}\biggr).
%    &\ge \left( 1 - \delta + \frac{\delta^2}{2} - \frac{\delta^3}{2} + \frac{5\delta^4}{8} - \frac{\delta^5}{8} + o(\delta^5) \right) n
  \end{align*}
  We can again relate $\E[\abs{\LCS(\wh{\bx}, \bx)}]$ to $\E[\abs{\LCS(\wh{\bx}', \bx)}]$ using the same argument in \Cref{thm:worst-case-small-delta}, from which we conclude that
  \begin{align*}
    \E\Bigl[ \abs{\LCS(\wh{\bx}, \bx)} \Bigr]
    &\ge \Bigl( 1 - e^{-\Omega(\gamma^2 n)} \Bigr) \Bigl( \E\Bigl[ \abs{\LCS(\wh{\bx}, \bx')} \Bigr] - 3 \gamma n \Bigr) \\
    &\ge \Bigl( 1 - e^{-\Omega(\gamma^2 n)} \Bigr) 
   (1 - \delta) n \cdot \biggl( 1 + (1-\delta)^2\sum_{j,k=1}^\infty  \cs(j,k) \cdot \delta^{j+k}\biggr)
   %    \left( 1 - \delta + \frac{\delta^2}{2} - \frac{\delta^3}{2} + \frac{5\delta^4}{8} - \frac{\delta^5}{8} + o(\delta^5) \right) n 
- 3\gamma n ,
  \end{align*}
  proving the theorem. 
  \end{proof}

  %\bigskip
%
%We will think of the trace $\by$ as the length $|\by|$ prefix of the infinite string $\by_\infty$, which is obtained from the infinite string $\bx_\infty$, which is $\bx$ itself padded with infinite copies of $\ast$, according to the process described in \Cref{sec:worst-case-small-rho}.
%
%As in \Cref{thm:worst-case-small-delta}, we describe a deterministic process that builds a matching $\bM$ between $\bx_\infty$ and $\wh{\bx}'$.
%The process maintains a pointer $p_{\bx}$ into $\bx_\infty$ and a pointer $p_{\wh{\bx}'}$ into $\wh{\bx}'$. The process runs for at most $2|\by|$ stages; at the beginning of the first stage $p_{\bx}=1$ (pointing to the first coordinate of $\bx$) and also $p_{\wh{\bx}'}=1$ (pointing to the first coordinate of $\wh{\bx}'$).
%In each stage of the process:
%
%\begin{enumerate}
%
%  \item If $p_{\bx} = r_i$ for some $i \in [|\by|]$, then the pointer $p_{\wh{\bx}'}$ is advanced to the value $t_i$ (or kept where it is if it is at $t_i$ already), i.e.~the location in $\wh{\bx}'$ where $\by_i$ was placed by \textsc{Small-rate-reconstruct}, and the edge $(p_{\bx},p_{\wh{\bx}'})$ is added to the matching $\bM$ (note that the bits $x_{p_{\bx}}$ and $\wh{\bx}'_{p_{\wh{\bx}'}}$ are indeed the same). After adding this edge to $\bM$, both pointers $p_{\bx}$ and $p_{\wh{\bx}'}$ are incremented by 1.
%
%  \item Let $u \ge 1$ be the largest integer such that $p_{\bx}, p_{\bx}+1, \ldots, p_{\bx}+(u-1) \not\in [n] \setminus \bR$ (equivalently, none of $p_{\wh{\bx}'}, p_{\wh{\bx}'}+1, \ldots, p_{\wh{\bx}'}+(u-1)$ is $r_i$ for any $i \in [|\by|]$), and let $v \ge 0$ be the largest integer such that $p_{\wh{\bx}'}, p_{\wh{\bx}'}+1, \ldots, p_{\wh{\bx}'}+(v-1) \notin \bT$ (equivalently, $v$ uniform $\zo$ bits were used for $\wh{\bx}_{p_{\wh{\bx}'}}, \wh{\bx}_{p_{\wh{\bx}'}+1}, \ldots, \wh{\bx}_{p_{\wh{\bx}'}+(v-1)}$).
%    Let $d := \min\{u, v\}$.
%   Then we can add $d \cdot cs(d)$ many edges to the matching $\bM$.
%    The pointer $p_{\bx}$ is incremented by $d+1$ at the end of this step, and the pointer $p_{\wh{\bx}'}$ is incremented by $d+1$ if and only if it was the case that $p_{\bx}, p_{\bx}+1, \ldots, p_{\bx}+(d-1) \in [n] \setminus \bR$ and $p_{\wh{\bx}'}, p_{\wh{\bx}'}+1, \ldots, p_{\wh{\bx}'}+(d-1) \notin \bT$.
%
%\end{enumerate}
%
%We observe that at the start of any stage, if $p_{\bx} = r_i$ for some $i \in [|\by|]$, then the pointer $p_{\wh{\bx}'}$ is at most $t_i$; this is because $p_{\wh{\bx}'}$ is only advanced past $t_i$ once $p_{\bx}$ reaches $r_i$ (and when this happens $p_{\bx}$ itself is also advanced by 1).
%Thus it is indeed the case that the first sentence of case (1) can only ever advance the pointer $p_{\wh{\bx}'}$ or keep it where it is (it will never move $p_{\wh{\bx}'}$ backwards), and so $\bM$ is indeed a legitimate matching.
%
%As in \Cref{thm:worst-case-small-delta}, the matching $\bM$ will contain $|\by|$ pairs resulting from the $|\by|$ occasions on which case (1) holds (recall that in this case $p_{\bx}=r_i$ for some $i \in |\by|$).
%What other edges will $\bM$ contain? 
%To analyze this, we consider the first $|\by|-1$ stages of $p_{\bx}$ for which $p_{\bx}-1 \in \bR$, i.e.~${\bx_\infty}_{p_{\bx}-1}$ was retained as a bit in the trace $\by.$  At each such stage $p_{\bx}$, by virtue of the process by which $\bR$ is generated and the independent randomness in each execution of Step~3 of the algorithm, there is a $\delta^{2d}$ chance that both $p_{\bx}, p_{\bx}+1, \ldots, p_{\bx}+(d-1) \in [n]\setminus \bR$, and $p_{\wh{\bx}'}, p_{\wh{\bx}'}+1, \ldots, p_{\wh{\bx}'}+(d-1) \notin \bT$ (equivalently, $d$ uniform $\zo$ bits were chosen for $\wh{\bx}_{p_{\wh{\bx}'}}, \wh{\bx}_{p_{\wh{\bx}'}+1}, \wh{\bx}_{p_{\wh{\bx}'}+(d-1)}$ in the relevant execution of Step~3).
%So the distribution of the number of case (2) matching edges in $\bM$ is at least the sum of $|\by|-1$ independent random variables $(\bG_i'-1) \cdot cs(\bG_i-1)$, where $\bG_i \sim \Geo(1-\delta^2)$, and the overall distribution of $|\bM|$ dominates the distribution
%\[
%  |\by| + \sum_{i=1}^{|\by|-1} \Bigl( (\bG_i - 1) \cdot cs(\bG_i - 1) \Bigr),\quad \quad \text{where~} \bG_i \sim \Geo(1-\delta).
%\]
%It follows that the expected size of $\bM$ is at least
%\begin{align*}
%  \E[\bM]
%  &\ge (1-\delta)n + (1-\delta)n \sum_{d=1}^\infty d \cdot cs(d) \Pr[\Geo(1-\delta^2) = d+1] - \frac{1-\delta}{\delta} \\
%  &= (1-\delta)n \Bigl(1 + (1-\delta^2) \sum_{d=1}^\infty d \cdot cs(d) \cdot \delta^{2d} \Bigr) - \frac{1-\delta}{\delta} \\
%  &\ge (1- \delta) n \Biggl( 1 + (1-\delta)^2 \left( \frac{1}{2} \delta^2 + \frac{9}{8} \delta^4 + \frac{29}{16}\delta^6 \right) \Biggr) - \frac{1-\delta}{\delta} \\
%  &\ge \left(1 - \delta + \frac{\delta^2}{2} - \frac{\delta^3}{2} + \frac{5\delta^4}{8} - o(\delta^4) - \frac{1-\delta}{\delta n} - \frac{1}{\delta n} \right) n ,
%\end{align*}
%\cnote{This $1/(\delta n)$ could be problematic when $\delta$ is small.  It would be better to replace it with $\gamma n$ instead by thinking $\bx$ as an infinite random string rather than padding $\bx$ with $\ast$ in the anlaysis...}
%and the existence of this matching implies that 
%\[
%  \E[|\LCS(\wh{\bx}',x)|] \geq \left(1-\delta + \delta^2 / 2 - \delta^3 / 2 + 5\delta^4/8 - o(\delta^4) \right) n .
%\]
%To finish the proof we repeat the same argument in the proof of \Cref{thm:worst-case-small-delta} to conclude that except with probability $e^{-\Omega(\gamma^2 n)}$, for $0 < \gamma < 1/4$ we have that 
%\[
%  \E[|\LCS(\wh{\bx}',x)|] \geq \left(1-\delta + \delta^2 / 2 - \delta^3 / 2 + 5\delta^4/8 \right) n - 5\gamma n ,
%\]
%proving the theorem.
%


%
%\bigskip \bigskip \bigskip
%
%\noindent \blue{{\bf Rocco's rough notes:}
%
%\begin{itemize}
%
%\item Let's define a slightly different deterministic process from the one in the earlier section.  Case (1) is as before, we still place those edges in $\bM$. For Case (2), if $p_{\bx} \in [n] \setminus \bR$ (note that now we write $p_{\bx}$ since now $\bx$ is random) and $p_{\wh{\bx}'} \notin T$, instead of adding such an edge to $\bM$, we place the edge $(p_{\bx},p_{\wh{\bx}'})$ into a new set $\bC$.  
%
%Think of the edges in $\bM$ as being colored magenta and the edges in $\bC$ as being colored chartreuse.  
%If we look at the union of $\bM$ and $\bC$, it is a sequence of mostly magenta edges interspersed with some chartreuse edges.  
%The intution is to make some money off of the occasions when we have a block of $t>1$ many consecutive chartreuse edges, as follows:  for each block of $t\geq1$ many chartreuse edges, we collect in expectation $t \cdot cs(t)$ many edges towards the matching. (This is because all of those bits involved in either endpoint of any chartreuse edge are all uniformly random and independent.) More precisely, the final matching is defined to contain all $|\by|$ many red edges, and it also includes the maximal possible matching within each block of chartreuse edges.
%
%\item Can we reason about this as follows: similar to the analysis of the worst-case setting, we consider the first $|\by|-1$ stages of $p_{\bx}$ which are such that $p_{\bx}-1 \in R$. Is the following true:  at each such stage $p_{\bx}$, by virtue of the process by which $\bR$ is generated,\rnote{ignoring some annoying edge effects - if $p_{\bx-1}$ were $n-2$, say, there is no chance that there will be more than 5 chartreuse edges coming up right after it. But this is going to be negligible vis-a-vis the overall final bound.} the number of consecutive chartreuse edges $(p_{\bx},p_{\wh{\bx}'}),(p_{\bx}+1,p_{\wh{\bx}'}+1),\dots$ that occur starting there, is distributed as a $\Geo(1-\delta^2) - 1$ random variable (the minus one is because our definition of $\Geo(p)$ is the number of trials including the first success).
%
%\item If the above is true then the expected number of length-$t$ blocks of chartreuse edges is 
%\[
%|\by| \cdot \Pr[\Geo(1-\delta^2) = t+1]
%\]
%and we should be able to say that for any fixed constant $k$, the expected number of chartreuse edges that end up in the overall matching is at least
%\[
%\sum_{t=1}^k cs(t) \cdot (1-\delta) n \cdot \Pr[\Geo(1-\delta^2) = t+1]
%\]
%so the expected overall matching size is at least
%\[
%(1-\delta)n + \sum_{t=1}^k cs(t) \cdot (1-\delta) n \cdot \Pr[\Geo(1-\delta^2) = t+1]
%\]
%\end{itemize}
%
%}
\subsection{Bounds on the performance of any one-trace algorithm}

%\red{
%\href{https://www.dropbox.com/home/FOCS19-RANDOM19-SODA21-ITCS21-SODA22-Trace-Reconstruction-Combinatorial/Approximate-trace-reconstruction-notes/weak-approximate-trace-reconstruction?preview=one-trace-avg-case-small-delta-take-4.pdf}{Here} are some notes on \Cref{thm:small-delta-average-case-upper-bound-informal} (no one-trace algorithm can do better than $1 - c \delta$, even in the average-case).
%}
Finally, in this section we establish an upper bound on the best possible performance that any one-trace algorithm can achieve in the small-deletion-rate regime.
We consider the average-case setting (which is of course more challenging for upper bounds, and yields worst-case upper bounds as an immediate consequence).

A relatively simple analysis shows that 
 $L_{1,\avg}(\delta,n) \leq (1 - c\delta/\log(1/\delta))n$, where $c$ is a universal positive constant.  This argument applies a union bound across all possible matchings of a given size, and is given as \Cref{thm:small-delta-average-case-upper-bound-weak} in~\Cref{sec:small-delta-average-case-weak-upper-bound}.  It is natural to suspect that this bound is weaker than it should be by a $\Theta(\log(1/\delta))$ factor, but establishing this turns out to be nontrivial.  The following theorem establishes a bound of $L_{1,\avg}(\delta,n) \leq (1 - c \delta)n$, which, up to the value of the universal constant $c$, is best possible by \Cref{thm:small-delta-average-case-algorithm} (or even by the trivial algorithm which simply outputs any $n$-bit string that contains the input trace $\by$, and thereby achieves an LCS of expected length at least $\E[|\by|]=(1-\delta)n$).

\begin{theorem}
[Average-case upper bound on any algorithm, small retention rate] 
\label{thm:small-delta-average-case-upper-bound}
There is an absolute constant $c>0$ such that for any  deletion rate $\delta=\delta(n)=\omega(1/n)$ and  sufficiently large $n$, we have $L_{1,\avg}(\delta,n) \leq (1 - c \delta)n.$
\end{theorem}

\def\OPT{\textsf{OPT}}

\subsubsection{Outline of the argument} 

Recall that under the average-case setting, the source string $\bx$ is uniform random over $\zo^n$, and our goal is to upperbound the performance of any algorithm which is given as input a single trace $\by \sim \Del_\delta(\bx).$
Given any trace string $y$, the optimal algorithm $A$ will return a string $z\in \zo^n$ to maximize
  $\E_{\bx \sim y}[|\LCS(z,\bx)|]$ (recall Observation \ref{ob:post1} for the 
    a posteriori distribution $\bx\sim y$).
Let us write $\opt(y)$ for an optimal string $z\in \zo^n$ for the expectation.
Given that $\by \sim \Del_\delta(\bx)$ and $\bx\sim \zo^n$,
  our goal is to bound $$
L_{1,\avg}(\delta,n)=\E_{\by}\Big[\E_{\bx\sim \by}\big[|\LCS(\opt(\by),\bx)|\big]\Big],
$$
where $\by$ 
  is a uniform random bitstring of length $\bk$ where $\bk \sim \Bin(n,1-\delta)$. 
For each $k$, let
$$
\OPT_k:=\E_{\by\sim \zo^k} \Big[\E_{\bx\sim \by}\big[|\LCS(\opt(\by),\bx)|\big]\Big].
$$
It is easy to see that $\OPT_k$ is nondecreasing in $k$,\footnote{To see this, note that
  any algorithm that receives a random trace of length $k$ can be simulated by 
  an algorithm that receives a trace of length $k+1$ by randomly deleting one bit from its input trace.}
  and we have (with $\bk\sim \Bin(n,1-\delta)$)
\begin{equation}\label{eq:blabla1}
L_{1,\avg}(\delta,n)=\sum_{k=0}^n \Pr\big[\bk=k]\cdot \OPT_k.
\end{equation}
 
Let $\delta'=\delta/2$ and $m=(1-\delta')m$. 
To prove \Cref{thm:small-delta-average-case-upper-bound}, we first show that it suffices
  to obtain the following upper bound for $\OPT_m$: 
\begin{equation}\label{eq:blabla2}
\OPT_m\le (1-c_1\delta')n,
\end{equation}  
for some universal positive constant $c_1$.
%may suppose without loss of generality that the single input trace $\by$ received by the algorithm has length exactly $m=(1-\delta')n$ for $\delta'=\Theta(\delta)$.
Consequently it suffices to analyze the optimal one-trace algorithm which is given as input a uniform random string $\by \sim \zo^m$. % and returns the string $z \in \zo^n$ that maximizes $\E_{\bx \sim \by}[\LCS(z,\bx)]$

Next, we observe that by a simple triangle inequality argument, it suffices to show that 
\begin{equation}
\label{eq:jarndyce}
\Ex_{\by \sim \zo^m} \Ex_{\bx, \bx' \sim \by}\big[|\LCS(\bx,\bx')|\big]\le (1-2c_1\delta')n
\end{equation}
for some constant $c_1$;
in turn, to prove (\ref{eq:jarndyce}), it is enough to bound (informally)
\begin{equation}
\label{eq:summerson}
\Prx_{\by \sim \zo^m, \bx,\bx' \sim \by}\big[\text{$\bx$ and $\bx'$ have a ``large'' matching}\big].
\end{equation} %is bounded away from 1.

In
%Building on the characterization of the \emph{a posteriori} distribution of a uniform random source string given one trace that is provided by \Cref{obs:uniform}, 
\Cref{claim:score} we give an upper bound on the probability that a \emph{fixed} large candidate matching $M$ is a valid matching between $\bx,\bx' \sim \by.$ 
This upper bound is in terms of a quantity that we call $\score_M$, which depends on the candidate matching $M$ and is a random variable whose randomness comes from the sets $\bS$ and $\bS'$ as in \Cref{obs:uniform}'s description of the distribution of $\bx\sim \by$ and $\bx' \sim \by$. 
As we show in \Cref{claim:tailhighscore}, to establish \Cref{eq:summerson} it is enough to show that for \emph{every} large candidate matching $M$, an upper tail bound on $\score_M(\bS,\bS')$ holds.  We prove such a tail bound in \Cref{lem:highscoreunlikely}. The two main steps are (i) showing (in \Cref{claim:well-spaced}) that $\Pr[\hspace{0.05cm}\bS$ is not ``\emph{well-spaced}''$\hspace{0.02cm}]$ is very small (see \Cref{def:well-spaced} for the definition of well-spaced sets), and (ii) showing (in \Cref{claim:scorelargesmallprob}) that if $\bS=S$ is good, then $\Pr_{\bS'}[\hspace{0.05cm}\score(S,\bS')$ is large$\hspace{0.04cm}]$ is very small.

\subsubsection{Proof of \Cref{thm:small-delta-average-case-upper-bound}}

We may assume that $\delta=\delta(n)$ is at most some sufficiently small universal positive constant, since otherwise the claimed bound follows immediately from \Cref{thm:small-delta-average-case-upper-bound-weak}. We will use this assumption in various bounds throughout the proof.

%Since the source string $\bx$ is uniform random over $\zo^n$ and $\by \sim \Del_\delta(x)$, we have that $\by$ is a uniform random bitstring of length $\bm$ where $\bm \sim \Bin(n,1-\delta)$. 
Let $\delta'=\delta/2$ and $m=(1-\delta')n$ (so $\delta'$ is $\omega(1/n)$ and at most 
  some sufficiently small universal positive constant as well).
By the well-known fact \cite{KaasBuhrman80} that the median of the $\Bin(n,\delta)$ distribution belongs to $\{\lfloor n \delta \rfloor,\lceil n \delta \rceil\}$ (which is at least $\delta'n$ using $\delta=\omega(1/n)$),
  it follows from (\ref{eq:blabla1}) and the monotonicity of $\OPT_k$ that 
$$
L_{1,\avg}(\delta,n)\le 0.5\cdot \OPT_m + 0.5n
$$
and thus, to prove \Cref{thm:small-delta-average-case-upper-bound} 
  it suffices to obtain the upper bound for $\OPT_m$ in (\ref{eq:blabla2}).

%, since $\delta =\omega(1/n)$ we have that with probability $\Omega(1)$ the length $\bm$ of $\by$ is $(1-\delta')n$ for some $\delta' = \Omega(\delta).$
%Hence to upper bound $L_{1,\avg}(\delta,n)$ as claimed in \Cref{thm:small-delta-average-case-upper-bound}, it suffices to show the following: for any $A$ that is given as input a uniform random trace $\by$ of length exactly $m:=(1-\delta')n$ from a uniform random source string $\bx \sim \zo^n$, for some absolute constant $c_1$ we have 
%\begin{equation} \label{eq:newgoal}
%\Ex_{\bx \sim \zo^n,
%\by\text{~a uniform $m$-bit subsequence of $x$}}\left[|\LCS(\bx,A(\by))|\right] \leq (1-c_1 \delta')n.
%\end{equation}

%The optimal algorithm $A$ for this problem receives as input a uniform string $\by \sim \zo^m$, and returns the string $z \in \zo^n$, which is a fixed deterministic string for each particular outcome of $\by$, that maximizes $\E_{\bx \sim \by}[\LCS(z,\bx)]$ (recall the definition of ``$\bx \sim \by$'' from \Cref{sec:avg}).
%Let us write $\opt(\by)$ for the optimal hypothesis string $z=z(\by)$ given $\by$ as described above, so we may rewrite \Cref{eq:newgoal} as
%\begin{equation} \label{eq:goal}
%\Ex_{\by \sim \zo^m} \Ex_{\bx \sim \by}[\LCS(\opt(\by),\bx)] \leq \left(1 - c_1 \delta'\right)n.
%\end{equation}

Instead of working with $\OPT_m$ directly,
  an application of the triangle inequality lets us work with the expression on the LHS of
  (\ref{eq:jarndyce}) which (conveniently) does not involve $\opt(\by)$:
\begin{claim} \label{claim:peepy}
Suppose that \Cref{eq:jarndyce} holds.
%\begin{equation}\label{eq:realgoal}
%\Ex_{\by \sim \zo^m} \Ex_{\bx , \bx' \sim \by}\big[\LCS(\bx,\bx')\big] \leq \left(1 - 2c_1 \delta'\right)n.
%\end{equation}
Then \Cref{eq:blabla2} holds.
\end{claim}
\begin{proof}
For any $y\in \zo^m$, any $n$-bit string $\opt(y)$, and any two $n$-bit strings $x,x'$, we have that the length of the $\LCS$ between $x$ and $x'$ is at least the number of coordinates of $\opt(y)$ that participate both in the optimal matching between $\opt(y)$ and $x$ and in the optimal matching between $\opt(y)$ and $x'$. Since this number is at least
$|\LCS(x,\opt(y))|+|\LCS(x',\opt(y))| - n$, we have that
\begin{equation}
n + \big|\LCS(x,x')\big| \geq \big|\LCS(x,\opt(y))\big| + \big|\LCS(x',\opt(y))\big|. \label{eq:homais}
\end{equation}
It follows that
\begin{align*}
2(1 - c_1 \delta') n &= n + (1 - 2c_1 \delta')n\\[0.5ex]
&\geq
n + \Ex_{\by \sim \zo^m} \Ex_{\bx, \bx' \sim \by}\big[|\LCS(\bx,\bx')|\big]\\[0.6ex]
& \geq \Ex_{\by \sim \zo^m} \Ex_{\bx , \bx' \sim \by}\big[|\LCS(\bx,\opt(\by)) | + |\LCS(\bx',\opt(\by))|\big]\\[0.8ex]
&= 2 \Ex_{\by \sim \zo^m} \Ex_{\bx \sim \by}\big[|\LCS(\bx,\opt(\by))|\big],
\end{align*}
where the first inequality is by \Cref{eq:jarndyce},  the second is by \Cref{eq:homais} (averaged over $\by$, $\bx \sim \by$ and $\bx' \sim \by$), and the third is because $\bx'$ and $\bx$ are identically distributed.
\end{proof}

Given \Cref{claim:peepy}, our goal in the rest of the proof is to establish \Cref{eq:jarndyce}.
We note that in \Cref{eq:jarndyce}, given the outcome of $\by$, the two $n$-bit strings $\bx$ and $\bx'$ are \emph{independently} distributed according to $\bx \sim \by$ and $\bx' \sim \by$; in particular, recalling \Cref{obs:uniform}, there are two independent draws performed to obtain the sets $\bS$ (for $\bx$) and $\bS'$ (for $\bx'$). This independence will be used heavily in the rest of the argument.

Recalling \Cref{obs:uniform}, we rewrite \Cref{eq:jarndyce} as
\begin{equation} \label{eq:realgoal2}
\Ex_{\by,\bS,\bS',\br,\br'}\big[|\LCS(\bx,\bx')|\big] \leq \left(1 - 2c_1 \delta'\right)n,
\end{equation}
where $\by \sim \zo^{m}$, $\bS$ and $\bS'$ are independent uniform $m$-element subsets of $[n]$,  and $\br,\br'$ are independent uniform draws from $\zo^{n-m}$ representing the ``rest of the bits'' that get filled into the locations in $[n] \setminus \bS$ and $[n] \setminus \bS'$ to complete the $n$-bit strings $\bx$ and $\bx'$, respectively. Recall that $\bx$ has $\by$ in the $m$ locations of $\bS$ and $\br$ in the other $n-m$ locations, and $\bx'$ gets the same $\by$ in the locations of $\bS'$ and $\br'$ in the other locations.



Since the length of the $\LCS$ between two strings is the size of the largest matching between them, to establish \Cref{eq:realgoal2} it suffices to prove that
\begin{equation}
\label{eq:realgoal3}
\Prx_{\by,\bS,\bS',\br,\br'}\big[\hspace{0.05cm}\text{there exists a matching between $\bx$ and $\bx'$ of size $(1- 4c_1\delta')n$}\hspace{0.04cm}\big] \leq 1/2 
\end{equation}
for some universal positive constant $c_1$.
%since if this holds, then even if with the remaining $1/2$ probability we had $|\LCS(\bx,\bx')|=n$, the expected value of $|\LCS(\bx,\bx')|$  would be at most $(1 - 2c_1\delta')n$ as required. 
Thus our remaining task is to establish \Cref{eq:realgoal3}.

\subsubsection{Matchings and scores}

Recall from \Cref{sec:preliminaries} that a matching $M$ of size $t$  between two $n$-bit strings $z,z'$ is a sequence of pairs $M=(M_1,\dots,M_t)$, where 
\begin{enumerate}

\item [(a)] $M_i=(v_i,v'_i)$ are such that $1 \leq v_1 < \cdots < v_t \leq n$, $1 \leq v'_1 < \cdots < v'_t \leq n$, and 
\item [(b)] for each $i \in [t]$ we have that the two bits $z_{v_i}$ and $z'_{v'_i}$ are the same.

\end{enumerate}
Let us say that a \emph{candidate matching} is a sequence of pairs $M=(M_1,\dots,M_t)$ satisfying (a); if moreover (b) holds for a pair of $n$-bit strings $z$ and $z'$, we say that the candidate matching $M$ is \emph{valid for $(z,z')$}.

Let $M=(M_1,\dots,M_t)$ be a candidate matching and let $$S=\{s_1 < \cdots < s_m\}\quad\text{and}\quad S'=\{s'_1 < \cdots < s'_m\}$$ be two $m$-element subsets of $[n].$ We say that an edge $M_i = (v_i,v'_i)$ of $M$ \emph{synchs up} with the pair $(S,S')$ if there is some $j \in [m]$ such that $v_i=s_j$ and $v'_i=s'_j$; in words, for some $j$ the candidate matching attempts to match up the $j$-th element of $S$ with the $j$-th element of $S'$. We say the \emph{score of $M$ on $(S,S')$}, denoted $\score_M(S,S')$, is
\[
\score_M(S,S'):=
\Big|\big\{i \in [t] : M_i \text{~synchs up with~}(S,S')\big\}\Big|,
\]
the number of edges of $M$ that match up corresponding elements of $S$ and $S'$.


\begin{claim} \label{claim:score}
Let $M=(M_1,\dots,M_t)$ be a candidate matching of size $t$ and let $S,S'$ be $m$-element subsets of $[n]$ such that $\score_M(S,S')=\ell$. Then
\[
\Prx_{\by,\br,\br'}\big[\hspace{0.03cm}M \text{~is a valid matching for~}(\bx,\bx')\hspace{0.03cm}\big] = 
{\frac 1 {2^{t-\ell}}},
\]
where $\bx$ and $\bx'$ are defined based on $S,S',\by,\br,\br'$ as described after \Cref{eq:realgoal2}.
\end{claim}
\begin{proof}
For each $M_i=(v_i,v'_i)$ that synchs up with $(S,S'),$ it is clear that $\smash{\bx_{v_i}=\bx'_{v'_i}}$, because both  are the same bit $\by_j$ of the string $\by$.  
There are $t-\ell$ remaining equalities $$\bx_{v_{i_1}} \stackrel{?}{=}\bx_{v'_{i_1}}, \dots, \bx_{v_{i_{t-\ell}}} \stackrel{?}{=}\bx_{v'_{i_{t-\ell}}},\quad\text{where $i_1<\cdots<i_{t-\ell}$,}$$ that must all hold in order for the candidate matching $M$ to be valid for $(\bx,\bx')$, corresponding to the $t-\ell$ edges of $M$ that do not synch up with $(S,S').$  Each of these equalities holds independently with probability $1/2$. This can be seen by considering the $t-\ell$ edges of $M$  successively in increasing order ``from left to right'': for each $j \in [t-\ell]$, for any given outcome of the bits of $\by,\br$ and $\br'$ that were involved in the first $j-1$ edges, there is a ``fresh random bit'' from either $\by, \br$ or $\br'$ involved in the $j$-th edge that causes the $j$-th equality to hold with probability 1/2.
%\rnote{Elaborate on this, or is it okay? We could do this more formally with an induction but it might involve more notation/setup than it is worth}
\end{proof}

For the rest of the proof of \Cref{thm:small-delta-average-case-upper-bound},
 we fix $t:=(1-4c_1\delta')n$ for some universal constant $c_1$ to be picked later  (recall that that is the size of the matchings that we are concerned with in \Cref{eq:realgoal3}).  The following claim states that it suffices to establish that for each fixed size-$t$ candidate matching $M$, the probability that it has a high score is very low:

\begin{claim} \label{claim:tailhighscore}
Suppose that there is a universal positive constant $c_1$ such that 
  the following inequality holds for each candidate matching $M$ of size  $t=(1-4c_1\delta')n$:
\begin{equation} \label{eq:highscoreunlikely}
\Prx_{\bS,\bS' \sim {[n] \choose [m]}}
\Big[\hspace{0.05cm}\score_M(\bS,\bS') \geq \big(1-3H(4c_1 \delta')\big)n\hspace{0.05cm}\Big]
  \le {\frac 1 {4 \cdot 2^{2H(4c_1 \delta')n}}}.
\end{equation}
Then \Cref{eq:realgoal3} holds with the same constant $c_1$.
\end{claim}
\begin{proof}
We use $\Pr[\bA] \leq \Pr[\bB] + \Pr[\bA \ | \ \overline{\bB}]$ where $\bA$ is the event ``there exists some valid matching between $\bx$ and $\bx'$ of size $t$''
and $\bB$ is the event ``there exists some candidate matching $M$ of size $t$ with $\score_M(\bS,\bS') \geq (1-3H(4c_1 \delta'))n$.''
There are $${n \choose 4c_1\delta' n}^2 \leq2^{2H(4c_1 \delta')n}$$ 
  many candidate matchings $M$ of size $t$. A union bound together with \Cref{eq:highscoreunlikely} gives that $$\Pr[\bB] \leq 
2^{2H(4c_1 \delta')n} \cdot 
 {\frac 1 {4 \cdot 2^{2H(4c_1 \delta')n}}}
= {\frac 1 4}.$$

To upperbound $\Pr[\bA \ | \ \overline{\bB}]$, %suppose that $\overline{\bB}$ holds, so every candidate matching $M$ of size $(1-4c_1 \delta')n$ has $\score_M(\bS,\bS') < (1-3H(4c_1 \delta'))n$.  
fix any particular outcome $(S,S')$ of $(\bS,\bS')$ such that $\score_M(S,S')$ $< (1-3H(4c_1 \delta'))n$ holds for every candidate matching $M$ of size $t$. %Fix a particular candidate matching $M$ of size $(1-4c_1\delta')n$; 
By \Cref{claim:score} we have that 
\begin{align*}
\Prx_{\by,\br,\br'}\big[M \text{~is valid for~}(\bx,\bx')\ | \ (\bS,\bS')=(S,S')\big] &\leq
{\frac 1 {2^{t - (1-3H(4c_1 \delta'))n}}} 
 <
{\frac 1 {2^{2.5H(4c_1 \delta')n}}},
\end{align*}
where the second inequality uses that $\delta'$ is at most some sufficiently small absolute constant.
By a union bound over all (at most $2^{2H(4c_1 \delta')n}$) many candidate matchings $M$ of size $t$, we see that 
$$\Pr\big[\bA \ | \ (\bS,\bS') = (S,S')\big]\le 
 2^{2H(4c_1 \delta')n} \cdot 
{\frac 1 {2^{2.5H(4c_1 \delta')n}}} \leq {\frac 1 4},$$ where the inequality holds since $\delta'=\omega(1/n)$.
Hence $\Pr[\bA \ | \ \overline{\bB}]\le 1/4$, and the claim is proved.
\end{proof}

For the rest of the proof fix $M$ to be any particular size-$t$ candidate matching. By \Cref{claim:tailhighscore}, our remaining task is to establish the tail bound on $\score_M(\bS,\bS')$ that is asserted by \Cref{eq:highscoreunlikely}. Since $\delta'$ is at most some absolute constant, this is an immediate consequence of the following slightly stronger (and cleaner to state) version:

\begin{lemma}
\label{lem:highscoreunlikely}
There is a universal positive constant $c_1$ such that
\begin{equation} \label{eq:highscoreunlikely2}
\Prx_{\bS,\bS' \sim {[n] \choose [m]}}
\Big[\hspace{0.05cm}\score_M(\bS,\bS') \geq \big(1-\sqrt{\delta'}\big)n\hspace{0.05cm}\Big]
\leq {\frac 1 {4 \cdot 2^{2H(4c_1 \delta')n}}}.
\end{equation}
\end{lemma}

\subsubsection{Proof of \Cref{lem:highscoreunlikely}}

Let the size-$t$ matching $M$ be given by $M=((v_1,v'_1),\dots,(v_t,v'_t))$. 
We define sets $L := \{v_1,\dots,v_t\}$ and $R:=\{v'_1,\dots,v'_t\}$
  with $v_1<\cdots<v_t$ and $v_1'<\cdots<v_t'$.
 %, which are respectively the set of coordinates in $x$ and in $x'$ that participate in the matching $M$.
  
In the proof of \Cref{lem:highscoreunlikely} it will be sometimes convenient for us to view $\bS$ as a uniform random string from $\zo^n$ conditioned on containing exactly $m$ ones (and $\bS'$ as an independent random string with the same distribution). We write $\zo^n_m$ to denote the set of all such $n$-bit strings with exactly $m$ ones.
 
The key notion for the proof of \Cref{lem:highscoreunlikely} is the following:

\begin{definition} \label{def:well-spaced}
We say that an outcome $S \in \zo^n_m$ of the random variable $\bS$ is \emph{well-spaced} if it has the following property: there are at least $\delta' n/2$ many disjoint intervals $I_1,\dots,I_{\delta' n/2} \subset [n],$ each of length exactly $1+2\beta$ with %\rnote{I propose that we ignore, without mention, the issue of whether  $1 + (2/\delta'^{3/4})$ is an integer or not. Are you guys okay with this level of depravity?} 
$\smash{ \beta:= 1/\delta'^{3/4} }$, such that for each $j \in [\delta' n /2]$ we have that
\begin{flushleft}
\begin{itemize}
\item [(i)] $I_j$ is entirely contained in $L$ (so $I_j$ contains $v_{i_j},\ldots,v_{i_j+2\beta}$ for 
  some $i_j$) and moreover, their corresponding indices in $R$ ($v_{i_j}',\ldots,v_{i_j+2\beta}'$)
  also form an interval (i.e., $v_{i_j+2\beta}'=v_{i_j}'+2\beta$); and

%viewing $S$ as a subset of $[n]$, the interval $I_j$ is entirely contained in $S$; and 
\item [(ii)] viewing $S$ as a bit-string from $\{0,1\}^n_m$, the subword $S_{I_j}$ of $S$ is $1^\beta 0 1^\beta$,  i.e. there is a 0 exactly in the middle of interval $I_j$ and the other $2\beta$ bits in the interval are all 1.  
\end{itemize}
\end{flushleft}
\end{definition}


Given \Cref{def:well-spaced}, \Cref{lem:highscoreunlikely} is an immediate consequence of \Cref{claim:well-spaced} and \Cref{claim:scorelargesmallprob} using $\Pr[\bA] \leq \Pr[\bB] + \Pr[\bA \ | \ \overline{\bB}]$ where $\bA$ is the event ``$\score_M(\bS,\bS') \geq (1-\sqrt{\delta'})n$'' and $\bB$ is the event ``$\bS$ is not well-spaced,''
  and taking $c_1$ to be a suitably small constant relative to those constants hidden in
  the $\Omega(\cdot)$ of these two claims. 
%(Note that in each of these claims, the constant hidden in the $\Theta(\cdot)$ notation has no dependence on $c_1$, so in particular $c_1$ can be taken to be suitably small relative to those constants.)

\begin{claim} \label{claim:well-spaced}
We have $$\Prx_{\bS \sim \zo^n_m}\big[\hspace{0.05cm}\text{$\bS$ is not well-spaced}\hspace{0.05cm}\big] \leq 2^{-\Omega(\delta' \log(1/\delta')n)}.$$
\end{claim}

\begin{claim}
\label{claim:scorelargesmallprob}
Fix any well-spaced $S \in \zo^n_m.$ Then
$$
\Prx_{\bS' \sim \zo^n_m}\Big[\hspace{0.05cm}\score_{M }(S,\bS') \geq \big(1-\sqrt{\delta'}\big)n\hspace{0.05cm}\Big] \leq 2^{-\Omega(\delta' \log(1/\delta'))n}.
$$
\end{claim}

\begin{proof}[Proof of \Cref{claim:well-spaced}]
We view the draw of $\bS$ as a sequential process in which the outcomes of different groups of coordinates are successively revealed.
We first reveal the outcome of $\bS_{[n]\setminus L}=S_{[n]\setminus L}$, and we consider the remaining distribution over the outcome of $\bS_L.$
Let $b$ be the number of $0$'s in $S_{[n]\setminus L}$. Then
  the remaining distribution of $\bS_L$ is uniform random over all strings in $\smash{\zo^L}$ 
  that contains exactly $a:=n-m-b$ many zeros.
Given that $b\le |[n]\setminus L|=4c_1\delta 'n\le 0.01\delta' n$ (using $c_1\le 1/400$)  
  we have $a \in [0.99\delta' n,\delta' n]$.
%where 
%  $0\le a \le n-m=4c_1\delta'\le 0.01\delta' n$ .

%Since $|L|=t$ and $t \geq (1 - 0.01\delta') n$ (using $c_1 < 1/400$), the $n-t$ positions of $\bS_{[n]-L}$ contain between 0 and $n-t \leq 0.01\delta' n$ many zeros, so for some $a \in [0.99\delta' n,\delta' n]$ the remaining distribution of $\bS_{L}$ is uniform random over all strings in $\zo^{L}$ that contain exactly $a$ zeros.
After $\bS_{[n]\setminus L}$ is drawn,
 we can view a draw of $\bS_{L}$ from the above-described distribution as being obtained through a sequential random process, proceeding for $a$ stages, where in the $j$-th stage, after locations $\bi_1,\dots,\bi_{j-1}$ in $[t]$ for zeros have been selected in the first $j-1$ stages, a new uniform random location $\bi_j$ in $[t] \setminus \{\bi_1,\dots,\bi_{j-1}\}$ is selected for the $j$-th zero (which means that the $v_{\bi_j}$-th entry of $\bS$ is set to zero). 
After each stage we keep track of the number of locations $i\in [t]$ selected 
  so far such that 
\begin{enumerate}
\item none of $i-2\beta,\ldots,i-1,i+1,\ldots,i+2\beta$ was selected so far; and
\item both $v_{i-\beta},\ldots,v_{i+\beta}$ and $v_{i-\beta}',\ldots,v_{i+\beta}'$ form an interval of length $2\beta+1$. 
\end{enumerate}
We write $\bX_j$ to denote this random variable after $j$ stages.
It suffices to show that $\bX_a$, after all $a$ stages, is at least $\delta'n/2$ with high probability.
 
To this end, we first notice that after the $j$-th stage, the number $\bX_j$ can go down from $\bX_{j-1}$ by at most two.
On the other hand, it goes up by one when $\bi_j$ is not one of the following ``disallowed'' locations $i\in [t]$:
\begin{flushleft}\begin{enumerate}
\item $v_{i-\beta},\ldots,v_{i+\beta}$ or $v_{i-\beta}',\ldots,v_{i+\beta}'$ 
  does not form an interval; the number of such $i\in [t]$ is at most 
  $2\cdot 2\beta\cdot (n-t).$
\item $i$ is within $2\beta$ of a location already picked; the number of such $i$ is 
  at most $(4\beta+1)a$.
\end{enumerate} \end{flushleft}
As a result, the probability that $\bX_j$ does not go up by one is at most
$$
\frac{4\beta(n-t)+(4\beta+1)a}{t-(j-1)}=\frac{16c_1\delta'^{1/4}n+(4\beta+1)a}{t-(j-1)}\le 5\delta'^{1/4},
$$
where we used $a\le \delta'n$. 
% In the $j$-th stage, after $j-1$ locations for zeros have been selected, even with the $2/\delta'^{3/4}$ locations to the left and right of each of those $j-1$ locations being ``disallowed'' and the $2/\delta'^{3/4}$ locations to the left and right of each of the $n-t$ many points in $[n] \setminus L$ being ``disallowed,'' the total number of ``disallowed'' locations among the $t-(j-1)$ remaining locations is at most 
%\begin{align*}
%(2/\delta'^{3/4}) \cdot (j -1 + n-t)
%&\leq (2/\delta'^{3/4}) \cdot (j-1 + 0.01\delta' n) \tag{because $n-t \leq 0.01\delta' n$}\\
%&\leq (2/\delta'^{3/4}) \cdot 1.01\delta' n \tag{because $j-1 < a \leq \delta' n$}\\
%&< 4\delta'^{1/4} (t-(j-1)), \tag{because $n \leq {\frac 4 {2.02}} (t-(j-1))$}
%\end{align*} so the probability the next location is a disallowed one is at most $4\delta'^{1/4}$.  
%
Consequently, the probability that out of the $a$ stages in which a location is chosen, at least 
  $\delta'n/10$ times it does not go up by one is at most
%$a-\delta' n / 10$ times it is a disallowed one, is at most 
\begin{align*}
2^a \cdot (5\delta'^{1/4})^{ \delta' n / 10}\le 2^{\delta'n}\cdot (5\delta'^{1/4})^{ \delta' n / 10} 
%&=
%{a \choose \delta' n/10} \cdot (4\delta'^{1/4})^{a - \delta' n / 10} \\
%&\leq
%{\delta' n \choose \delta' n / 10} 
%\cdot (4\delta'^{1/4})^{0.89 \delta' n} \tag{because $0.99 \delta' n \leq a \leq \delta' n$}\\
%&\leq 2^{\delta' n} \cdot (4\delta'^{1/4})^{0.89 \delta' n} 
= 2^{-\Omega(\delta' \log(1/\delta')n)},
\end{align*}
when $\delta'$ is sufficiently small.
If this does not happen, then $\bX_a$ at the end is at least $$a-(\delta'n/10)-2\cdot (\delta'n/10)\ge \delta'n/2$$ using $a\ge 0.99\delta'n$, so the claim is proved.
\end{proof}

\begin{proof}[Proof of \Cref{claim:scorelargesmallprob}]
Let $S$ be a well-spaced set in $\{0,1\}^n_m$, and 
  $I_1,\ldots,I_{\delta'n/2}$  be the $\delta'n/2$ intervals in $[n]$ of length $2\beta+1$ each  that satisfy the conditions of \Cref{def:well-spaced}.
For each $I_j$, we let $i_j\in [t]$ be such that $I_j=\{v_{i_j-\beta},\ldots,v_{i_j+\beta}\}$
  (so $v_{i_j}$ is the center of $I_j$).
Let $$I_j' 
=\left\{v'_{i_j-4/\sqrt{\delta'}},\ldots,v'_{i_j+4/\sqrt{\delta'}}\right\}
$$
for each $j$.
Note that since $\delta'$ is at most some sufficiently small constant, we have 
  $4/\sqrt{\delta'}<\beta$ and thus,
  $I_j'$'s are mutually disjoint intervals in $[n]$ because $I_j$'s satisfy
  conditions of \Cref{def:well-spaced}.

Let $\bS'\sim \zo^n_m$.
%Let us say that $S$ and $\bS$ are \emph{aligned at position $k \in [n]$} if $\sum_{i=1}^k S_i = \sum_{i=1}^{k} \bS'_i$, i.e. the number of 1s in the prefix $S_{[k]}$ is the same as the number of 1s in the prefix $\bS'_{[k]}.$
We claim that, 
in order to have $\smash{\score_{M}(S,\bS') \geq (1-\sqrt{\delta'})n}$, it must be the case 
  that $\bS'$ has at least $\delta'n/4$ many zero entries in the union of $I_j'$.
To see this, suppose that $\bS'$ has no more than $\delta'n/4$ many zeros in the union of $I_j'$.
Then at least $\delta'n/4$ many $I_j'$'s have all ones in $\bS'$.
For each such $j$, given that $S_{I_j}=1^\beta 0 1^\beta$, we have that either 
$$
\left(v_{i_j-4/\sqrt{\delta'}},v'_{i_j-4/\sqrt{\delta'}}\right),\ldots,\left(v_{i_j-1},v'_{i_j-1}\right)\quad\text{or}\quad
 \left(v_{i_j+1},v'_{i_j+1}\right),\ldots,\left(v_{i_j+4/\sqrt{\delta'}},v'_{i_j+4/\sqrt{\delta'}}\right) 
$$
are not synched. As a result, the number of pairs in $M$ that are not synched in $(S,\bS')$
  is at least $(\delta'n/4)\cdot (4/\sqrt{\delta'})\ge \sqrt{\delta'}n$ and thus, the score is at most $(1-\sqrt{\delta'})n$.

Finally we bound the probability of $\bS'\sim \zo^n_m$ having at least $\delta'n/4$ many zeros in the union of $I_j'$.
Given that the union has size
$$
\frac{\delta' n}{2}\cdot \left(\frac{8}{\sqrt{\delta'}}+1\right)<5\sqrt{\delta'}n,
$$
the probability is at most (where the summand $r$ is the number of zeros in the union of $I_j'$)
\[
\sum_{r=\delta'n/4}^{\delta' n} {\frac {{5 \sqrt{\delta'} n \choose r} \cdot
{n - 5 \sqrt{\delta'} n \choose \delta' n - r}}
{{n \choose \delta' n}}} \le \left(\frac{3\delta'n}{4}+1\right)\cdot {5 \sqrt{\delta'} n \choose \delta'n /4}\cdot 
{\frac { 
{n - 5 \sqrt{\delta'} n \choose 3\delta' n /4}}
{{n \choose \delta' n}}}
%2^{5\sqrt{\delta'}n}\sum_{r=\delta'n/4}^{\delta' n} {\frac { 
%{n - 5 \sqrt{\delta'} n \choose \delta' n - r}}
%{{n \choose \delta' n}}}
%\le 2^{5\sqrt{\delta'}n}\cdot \frac{3\delta'n}{4}\cdot \frac { 
%{n \choose 3\delta'n /4}}
%{{n \choose \delta' n}}.
\]
given that the terms are maximized at $r=\delta'n/4$.
Using ${n\choose k}\le (en/k)^k$, we have 
$$
{5 \sqrt{\delta'} n \choose \delta'n /4}\le  \left(\frac{60}{\sqrt{\delta'}}\right)^{\delta'n/4}.
$$
%The fraction can be simplified to be
On the other hand, we have 
$$
{\frac { 
{n - 5 \sqrt{\delta'} n \choose 3\delta' n /4}}
{{n \choose \delta' n}}}\le 
{\frac { 
{n \choose 3\delta' n /4}}
{{n \choose \delta' n}}}
=
\frac{(n-\delta'n)!\cdot (\delta'n)!}{(n-3\delta'n/4)!\cdot (3\delta'n/4)!}\le \left(\frac{\delta'n}{n-\delta'n}\right)^{\delta'n/4}\le (2\delta')^{\delta'n/4}.
$$
As a result, the probability is at most
$$
\left(\frac{3\delta'n}{4}+1\right)\cdot \left(120\sqrt{\delta'}\right)^{\delta'n/4}=2^{-\Omega(\delta'\log (1/\delta') n)}
$$
since $\delta'$ is at most some sufficiently small constant. This finishes the proof of \Cref{claim:scorelargesmallprob}.
\end{proof}
%As a result, the probability can be bounded from above by
%$$
%2^{5\sqrt{\delta'}n}\cdot \frac{3\delta'n}{4}\cdot  2^{-\Omega(\delta'\log(1/\delta')n)}
%$$

%that $S$ and $\bS'$ are not aligned at at most $\sqrt{\delta'}n$ many positions $k \in [t]$.
%Hence it must be the case that $S$ and $\bS'$ are not aligned at at most $\sqrt{\delta'}n$ many positions in $I_1 \cup \cdots \cup I_{\delta' n / 10}$, where each $I_j$ is the interval of length $1 + 2/\delta'^{3/4}$ whose existence follows from $S$ being well-spaced.
%For $\bj$ uniform random over $[\delta' n/10]$, it follows that
%\[
%\Ex_{\bj \sim [\delta' n / 10]}[\text{number of positions in $I_{\bj}$ where $S$ and $\bS'$ are not aligned}] \leq {\frac {10}{\sqrt{\delta'}}},
%\] and hence by Markov's inequality, for at least $0.99\delta' n/10$ values of $j \in [\delta' n / 10]$, it holds that the number of positions in $I_j$ where $S$ and $\bS'$ are not aligned is at most $1000/\sqrt{\delta'}.$ Let us say that an interval $I_j$ where the number of positions in $I_j$ where $S$ and $\bS'$ are not aligned is at most $1000/\sqrt{\delta'}$ is a \emph{nice} interval. 

%Fix a nice interval $I_j$. Since $S$ is well-spaced, $S_{I_j}$ is of the form $1^{1/\delta'^{3/4}} 0 1^{1/\delta'^{3/4}}$, and consequently it must be the case that $\bS'$ contains a 0 within distance $1000/\sqrt{\delta'}$ from the location of the 0 in $I_j$. 
%For any fixed choice $A$ of $0.99\delta' n/10$ values in $[\delta' n/10]$, the total length of these  $0.99 \delta' n/10$ many length-$2000/\sqrt{\delta'}$ subintervals of the $I_j$'s (centered around the centers of the $I_j$'s) is $(2000/\sqrt{\delta'}) \cdot (0.99 \delta' n / 10) = 199.8 \sqrt{\delta'} n$.  (We observe that since $\delta'$ is at most some sufficiently small constant, we have that $2000/\sqrt{\delta'} < 1 + 2/\delta'^{3/4}$, so each subinterval of an $I_j$ is contained entirely within that $I_j$ and hence the subintervals are mutually disjoint.)
%Hence the probability that these $0.99 \delta' n/10$ many length-$2000/\sqrt{\delta'}$ subintervals of the $I_j$'s collectively contain exactly $r$ of the $\delta' n$ many zeros in $\bS'$ (recall that $m=(1-\delta')n$) is

%\[
%{\frac {{199.8 \sqrt{\delta'} n \choose r} \cdot
%{n - 199.8 \sqrt{\delta'} n \choose \delta' n - r}}
%{{n \choose \delta' n}}}
%\]
%For $r \in [0.99 \delta' n / 10,\delta' n]$ this is maximized by taking $r=0.99 \delta' n / 10$, and below we will show that for that choice of $r$, we have
%\begin{equation}
%{\frac {{199.8 \sqrt{\delta'} n \choose 0.99 \delta' n / 10} \cdot
%{n - 199.8 \sqrt{\delta'} n \choose 0.911\delta' n}}
%{{n \choose \delta' n}}}
%=2^{-\Theta(\delta' \log(1/\delta'))n}. \label{eq:to-be-shown}
%\end{equation}
%Summing over all size-$0.99 \delta' n / 10$ subsets $A$ of $[\delta' n / 10]$, we get that 
%\begin{align*}
%\Prx_{\bS' \sim \zo^n_m}[\score_{M}(S,\bS') \geq (1-\sqrt{\delta'})n] &\leq
%{\delta' n / 10 \choose 0.99 \delta' n / 10} \cdot
%2^{-\Theta(\delta' \log(1/\delta'))n}\\
%&\leq 2^{\delta' n / 10} \cdot 2^{-\Theta(\delta' \log(1/\delta'))n} = 2^{-\Theta(\delta' \log(1/\delta'))n},
%\end{align*}
%which is the conclusion of \Cref{claim:scorelargesmallprob}.

%It remains to verify \Cref{eq:to-be-shown}. This is a straightforward calculation:  
%\begin{align*}
%(\ref{eq:to-be-shown}) = 
%{\frac {{199.8 \sqrt{\delta'} n \choose 0.099\delta' n} \cdot
%{n - 199.8 \sqrt{\delta'} n \choose 0.911\delta' n}}
%{{n \choose \delta' n}}}
%& \leq
%{\frac {\left({\frac {(199.8/0.099)e} {\sqrt{\delta'}}}\right)^{0.099 \delta' n} \cdot {n \choose 0.911 \delta' n}}{{n %\choose \delta' n}}}\%\
%&\leq{\frac {\left({\frac {2020 e} {\sqrt{\delta'}}}\right)^{0.099 \delta' n} \cdot n(n-1)\cdots(n-0.911\delta' n + 1)/(0.911 \delta' n)!}{n(n-1)\cdots(n-\delta' n + 1)/(\delta' n)!}}\\
%&\leq 
%{\frac {\left({\frac {2020 e} {\sqrt{\delta'}}}\right)^{0.099 \delta' n} \cdot(\delta' n)^{0.089 \delta' n}}
%{(n/2)^{0.089 \delta' n}}}\\
%&\leq
%\left({\frac {2020 e} {\sqrt{\delta'}}}\right)^{0.099 \delta' n} \cdot(2\delta')^{0.089 \delta' n}\\
%&\leq \left({\frac {4040 e} {\sqrt{\delta'}}}\right)^{0.099 \delta' n} \cdot(\sqrt{\delta'})^{0.178 \delta' n}\\
%&= (4040 e )^{0.099 \delta' n} \cdot (\sqrt{\delta'})^{0.079 \delta' n}
% = 2^{-\Theta(\delta' \log(1/\delta'))n}. 
%\end{align*}
%This finishes the proof of \Cref{claim:scorelargesmallprob}.
%\end{proof}


