In this section we experimentally evaluate our method -- herein termed NIFM for Neural Integration-free Flow Maps -- for both 2D and 3D time-varying vector fields, comparing against various baselines that accelerate flow map computation in different ways. \new{A requirement that is common to all baselines is access to samples of the flow map. Unless otherwise stated (c.f. Sec.~\ref{subsec:error}), the methods against which we compare NIFM are based on flow maps generated via $4^{th}$ order Runge-Kutta integration (RK4), with step size set to half of the temporal voxel size. We also use this very integration scheme to generate ground-truth flow map samples for the purposes of evaluation.} In Table~\ref{tab:datasets} we list the datasets used for comparison purposes. Further, all reported computational timings are based on a system with 12-core CPU AMD Ryzen 9 3900X, 16GB RAM, and GPU NVIDIA GeForce RTX 2080 Ti with 12GB memory.

We consider the flow map super resolution technique proposed by Jakob et al.~\cite{jakob2020fluid}, wherein we train a convolutional neural network (CNN) model using the 2D fluid flow dataset provided by the authors. To train the CNN we generate 16x downsampled flow maps along with their corresponding high-resolution ground truth flow maps, varying start times and time span of the integration, to permit model generalization for arbitrary start time/duration.

Additionally, we compare our method with the deep learning based Lagrangian interpolation technique proposed by Han et al.~\cite{han2021exploratory}. This technique uses an encoder-decoder network and is most similar to ours in terms of the input data the model expects, and the output of the model. We train the model on flow map samples computed by, first, generating seeds sampled uniformly at random in space and time, and secondly, integrating for varying small time spans. This flow map sampling technique is intended to resemble the Lagrangian short generation scheme proposed by the authors. We made a minor modification to the network by removing the ReLU activation function used in the output layer, allowing the model to output negative values. Further, we compare our method with a SIREN~\cite{sitzmann2020implicit} that tacks time span on as an additional coordinate, along with particle space-time coordinates (c.f. Fig.~\ref{fig:illustrative_network}(a)). We train the SIREN with the same data used to train the encoder-decoder model. Note that we could use a hybrid grid-MLP model~\cite{muller2022instant,weiss2021fast} in lieu of a standard coordinate-based MLP, but for 3D unsteady flows this would require storage of a 5D grid, which is not feasible.

We also compare our method against the recent work by Li et al.~\cite{li2022efficient}, where the authors showed an improvement over prior work in efficiently interpolating Lagrangian representation to obtain new trajectories. \new{Note that the representation of flow in our datasets is Eulerian, whereas Li et al. works with particle-based data, thus, requiring a conversion from the former to the latter. For a fair comparison, we convert the Eulerian representation into a Lagrangian one by first placing $n_s$ number of seeds in the domain uniformly at random, where $n_s$ is the spatial resolution of the vector field data, and integrate these seed points via RK4. The temporal frequency with which we store particle positions is set as the temporal resolution of the field. Furthermore, the Lagrangian representation is limited to the temporal duration on which we are evaluating, to have a better distribution of particles throughout the domain}.

Last, we compare our method with the streakline vector field (SVF) work of Weinkauf et al.~\cite{weinkauf2010streak}. \new{Specifically, the SVF is first precomputed by estimating flow map derivatives, computed via RK4, and then at runtime streaklines are generated by integrating the SVF. We view this as a fair comparison to our technique in that both approaches incur a precomputation cost, and thus we aim to compare the computation and storage requirement for the representations, as well as the accuracy and computation efficiency for generating streaklines.}

\begin{table}[]
\caption{We list all datasets and their respective sizes used in experiments.}
\label{tab:datasets}
\centering
\scalebox{0.8}{
% \begin{tabular}{|c|c|}
% \hline
% Dataset       & Res (t,x,y(,z)) \\ \hline
% Double Gyre   & 500x400x200     \\ \hline
% Cylinder      & 1001x400x50     \\ \hline
% Boussinesq    & 2001x450x150    \\ \hline
% Tornado       & 50x128x128x128  \\ \hline
% Scalar Flow   & 151x100x178x100 \\ \hline
% Half-Cylinder & 151x640x240x80  \\ \hline                 
% \end{tabular}}
% \end{table}
\begin{tabular}{cc}
\hline
Dataset       & Res {[}t,x,y(,z){]} \\ \hline
Double Gyre   & 500x400x200         \\
Cylinder      & 1001x400x50         \\
Boussinesq    & 2001x450x150        \\
Fluid Simulation & 1001x512x512     \\
Tornado       & 50x128x128x128      \\
Scalar Flow   & 151x100x178x100     \\
Half-Cylinder & 151x640x240x80   
\end{tabular}}
\end{table}

\begin{figure*}[t]
\centering
\includegraphics[width=1\linewidth]{figures/quantitative.pdf}
\caption{We show the quantitative evaluation of flow map approximation methods across different datasets, and across different time spans, beginning at start times for which flow features have largely resolved.} 
\label{fig:quantitative}
\end{figure*}


\subsection{Implementation details}
We first describe the details of our network architecture, followed by details on optimization.

\textbf{Network architecture settings}
The design of $f_{\nu}$ and $f_{\tau}$ rely on parameter settings related to the multi-level feature grid, as well as the MLP. The feature grids for $f_{\nu}$ and $f_{\tau}$ are of identical design, where we use a 4-level feature grid, and each level is of a different spatial resolution. Specifically, for a given axis of resolution $w$ at level $l$, we set the resolution at the next level to be $w^{s \cdot l}$, with resolution scaling factor $s$ set to 1.65, following the guidance of M{\"u}ller et al.~\cite{muller2022instant}. Each grid stores $8$-dimensional feature vectors at its nodes, and thus the resulting concatenated feature is $32$-dimensional. We employ 2 and 1-layer MLPs for $f_{\nu}$ and $f_{\tau}$, respectively, along with activation $\sigma_{\tau}$ chosen to be a Swish activation~\cite{hayou2018selection}. Experimentally we found Swish to outperform other more standard activations for INRs, e.g. ReLU, sin, consistent with findings in AutoInt~\cite{lindell2021autoint}. We control for the size of the network by a compression ratio, expressed as the ratio of the vector field size to the network size. We adjust the spatial resolution of the feature grids to best match a provided compression ratio, but leave the MLPs unchanged as they comprise a tiny portion of the model. Last, we use a 3-layer MLP with $64$ layer width for the residual network. Unless otherwise specified, we use a compression ratio of $10$ for all 2D datsets, and customize compression ratios for 3D as appropriate.
 
\input{main_timing_table}
 
\textbf{Optimization details}
For both phases of optimization we use Adam~\cite{kingma2015adam}, where we take a total of $40,000$ optimization steps and decay the learning rate every $8,000$ steps. Specific to optimization phase, in fitting to the vector field we use a learning rate of $0.02$, while for flow map optimization we use a learning rate of $0.01$ -- fitting the flow map derivative to the vector field is quite stable, and benefits from larger learning rates. In optimizing for the flow map, we have the choice of leaving the instantaneous velocity portion of the network frozen, or fine-tuning its weights to compensate for the remainder of the network. Although we find that both give results of comparable accuracy, in some occasions we found that fine-tuning can mitigate small grid-based artifacts in the output when leaving these weights frozen, and hence we fine-tune this portion of the network, using a learning rate of $0.0008$.

Recall that our method supports a maximum time span $\tau_{max}$ on which to sample during optimization. Though in principle we could optimize for the full time span of a given dataset, we find that performance can suffer, especially for datasets exhibiting complex temporal dynamics. Thus, as a compromise we set a limit on $\tau_{max}$ during optimization, and at inference time, for any target $\tau > \tau_{max}$ we take multiple steps with our network until reaching the desired span $\tau$. Specifically, for all 2D datasets, expressed in terms of grid units we set $\tau_{max} = 48$ unless otherwise specified. For 3D datasets we customize $\tau_{max}$ based on grid resolution, and complexity of the flows.

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\linewidth]{figures/fluid_sim-compressed.pdf}
    \caption{We compare FTLE (top row) and integration error (bottom row) for two Fluid Simulation datasets (Re 16 and Re 101.6) across different baselines. The left column corresponds to particles integrated beginning at $t_0 = 0$ for duration $\tau=7$, while the right column corresponds to particles integrated starting at $t_0 = 2$ and $\tau = 7$.} 
    \label{fig:ftle_fluid}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\linewidth]{figures/dg-compressed.pdf}
    \caption{We compare FTLE (top row) and integration error (bottom row) for different baselines for the Double Gyre dataset. Particles are integrated from $t_0=0$ for a time-span $\tau=10$.} 
    \label{fig:ftle_dg}
\end{figure*}

\subsection{2D unsteady flow}

We first conduct experimental comparisons for various 2D time-varying flow fields. Specifically, we evaluate different techniques by computing the error in flow map approximations over varying seed points (spatial position and starting time) that have been integrated for varying time spans. We express error as the averaged Euclidean distance between the ground-truth flow map output, and the approximation scheme's output, normalized by the domain's bounding-box diagonal length. In Fig.~\ref{fig:quantitative} we present quantitative results comparing our method against different baselines, and in Table~\ref{tab:time} we report inference and preprocessing times. Specifically, for the pathline interpolation approach of Li et al.~\cite{li2022efficient}, preprocessing refers to the time required to fit B-splines, while for Jakob et al.~\cite{jakob2020fluid} this refers to the time required to optimize the CNN for super resolution. For all remaining methods, preprocessing refers to the time required for optimizing to an individual flow field.

\begin{figure}[!t]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/cy_h.pdf}
    \caption{We show the FTLE (top of each pair) and error maps (bottom of each pair) for the flow over cylinder dataset generated by integrating particles starting at $t_0=18$ for a time-span $\tau=1$.} 
    \label{fig:ftle_cy}
\end{figure}

\begin{figure}[!t]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/bo.pdf}
    \caption{We show the FTLE (top of each pair) and error maps (bottom of each pair) for the Boussinesq dataset generated by integrating particles starting at $t_0=11.3$ for a time-span $\tau=0.5$.} 
    \label{fig:ftle_bo}
\end{figure}


In comparing the fluid simulation flows of varying Reynolds numbers, we find that our method sees consistent improvement in accuracy over SIREN and super resolution, while achieving faster inference times. We note that the super resolution approach requires optimizing a CNN over a collection of flow maps just once, and thus can generalize to low-resolution flow maps at inference time, albeit restricted to flows resembling those observed during training. Our method is limited to just a single dataset at a time, but nevertheless, our training times scale well in terms of standard INRs (e.g. SIREN), while exhibiting faster inference and more accurate flow map approximations. Qualititative results for the fluid simulation flows are shown in Fig.~\ref{fig:ftle_fluid} in the form of the FTLE -- \new{computed using the method of Haller~\cite{haller2001lagrangian}} -- and color-encoded flow map errors. For high Reynolds number flows, we see that the super resolution method can fail to adapt to the rate at which particles separate, as indicated by the color shift, while also blurring out detailed ridges in the FTLE.  Our method, however, excels in capturing FTLE ridges, while remaining efficient to compute, since the super resolution method still requires computing a low-resolution flow map as input to a (otherwise highly efficient) CNN. Recall that our method employs a compression ratio of $10$ for all 2D experiments, which limits the grid resolution, and thus might limit the details we can reproduce in the flow map. However, from these results, we see that the coarser feature grid resolution does not limit the spatial resolution of the FTLE.


\begin{figure*}[t]
\centering
\includegraphics[width=1\linewidth]{figures/streaklines_new.pdf}
\caption{We compare our method's ability to compute streaklines against the streakline vector field technique~\cite{weinkauf2010streak}, which only necessitates integrating a derived vector field. Qualitatively and quantitatively we find that our method produces comparable results, where we show varying step sizes used for evaluating the flow map.}
\label{fig:streaklines}
\end{figure*}

In comparing our method to other baselines (c.f. Fig.~\ref{fig:quantitative}) for Double Gyre, Cylinder, and Boussinesq, we find that our method obtains higher accuracy in relation to other techniques. Prior INR methods such as the encoder-decoder architecture of Han et al.~\cite{han2021exploratory}, or a pure coordinate-based approach~\cite{sitzmann2020implicit} poorly generalize. We find that for small step sizes, the performance of these methods in fact steeply declines, as numerical error accumulates with the more steps taken. We attribute this to the basic limitations of the network architectures employed, failing to address the properties (identity mapping, instantaneous velocity) we target in our network design. The inability to generalize in these methods is further demonstrated qualitatively for Figs.~\ref{fig:ftle_dg} - \ref{fig:ftle_bo}. \new{Pathline interpolation~\cite{li2022efficient} is notable in its small precomputation cost. Nevertheless, the method is less accurate in preserving the flow map, while incurring a high computation cost at runtime.}

We additionally evaluate our technique both quantitatively and qualitatively for the computation of streaklines. In Fig.~\ref{fig:streaklines} we show streaklines for the Cylinder dataset. We compare our method with SVF~\cite{weinkauf2010streak}. We can see that both the techniques are able to capture the vortices of the dataset faithfully, and are visually indistinguishable from the ground truth streaklines. Quantitatively both the techniques consistently incur low streakline error staying within the margin of $10^{-3}$ magnitude (relative to the bounding box diagonal). Interestingly, we find that both methods have comparable inference time as well, as reported in Table~\ref{tab:streaklines}, despite the fact the streakline vector field evaluates its field fewer times than our neural flow map, since we must take multiple steps for sufficiently long time spans. However, an advantage of our method lies in data parallelism; we can evaluate the flow map over varying space/time/duration in a single batch, whereas integrating the streakline vector field is, by necessity, a sequential process. We further note that SVF precomputation is quite expensive, both in terms of speed and storage space. In Table~\ref{tab:streaklines} we can see that the computation of the entire 4D SVF has very large storage requirements (160GB), whereas our method is in proportion to the size of the vector field (77MB). We note that while our technique can be easily scaled to 3D datasets, SVF preprocessing for 3D unsteady flows is infeasible in practice, necessitating a 5D grid for storage.


\begin{table}[!t]
\caption{We report storage requirements, preprocessing time and inference time for computing streaklines on the Cylinder dataset, comparing our method against the streakline vector field technique~\cite{weinkauf2010streak}.}
\label{tab:streaklines}
\centering
\scalebox{0.9}{
\begin{tabular}{|c|c|c|c|}
\hline
Method  & \begin{tabular}[c]{@{}c@{}}Preprocessing\\ Time\\ (min)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Inference\\ Time\\ (sec)\end{tabular} & \begin{tabular}[c]{@{}c@{}}Storage\\ \end{tabular} \\ \hline
Ground Truth & NA  & 21.391 & 160.20 MB \\  \hline
SVF & 130.407 & 1.204 & 160.36 GB \\ \hline
NIFM (16 grid steps) & \multirow{2}{*}{40.060} & 0.952 & \multirow{2}{*}{77.20 MB}\\ \cline{1-1} \cline{3-3}
NIFM (24 grid steps) & &0.671 & \\ \hline
\end{tabular}}
\end{table}

\begin{table}[!t]
\caption{We report the processing times as well the FTLE computation times for different method across different 3D unsteady flow datasets.}
\label{tab:3d_ftle_times}
\centering
\scalebox{0.8}{
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
Dataset                                        & FTLE res                     & $\tau$                                     & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Inference\\ times (s)\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Processing\\ times(m)\end{tabular}} & CR & \multicolumn{1}{l|}{Method} \\ \hline
\multicolumn{1}{|c|}{\multirow{4}{*}{Tornado}} & \multirow{4}{*}{128x128x128} & \multirow{4}{*}{50}                     & 27.16                                                                              & -                                                                                 & -  & GT                          \\ \cline{4-7} 
\multicolumn{1}{|c|}{}                         &                              &                                         & \textbf{3.60}                                                                               & 35.55                                                                       & 10        & NIFM                        \\ \cline{4-7} 
\multicolumn{1}{|c|}{}                         &                              &                                         & 14.14                                                                              & 93.21                                                                           & 10   & SIREN                       \\ \cline{4-7} 
\multicolumn{1}{|c|}{}                         &                              &                                         & 286.29                                                                             & 0.87
& - & Spline                      \\ \hline
\multirow{4}{*}{Scalar Flow}                   & \multirow{4}{*}{100x178x100} & \multirow{4}{*}{2.5}                    & 81.72                                                                              & -                                                                              & -     & GT                          \\ \cline{4-7} 
                                               &                              &                                         & \textbf{2.55}                                                                               & 41.66                                                                          & 10     & NIFM                        \\ \cline{4-7} 
                                               &                              &                                         & 21.48                                                                              & 95.57                                                                      & 10         & SIREN                       \\ \cline{4-7} 
                                               &                              &                                         & 291.39                                                                             & 0.81                                                                        & -        & Spline                      \\ \hline
\multirow{3}{*}{Half-Cylinder}                 & \multirow{3}{*}{640x240x80}  & \multicolumn{1}{c|}{\multirow{3}{*}{2}} & 137.41                                                                             & -                                                                                & -   & GT                          \\ \cline{4-7} 
                                               &                              & \multicolumn{1}{c|}{}                   & \textbf{3.82}                                                                               & 45.56                                                                       & 40        & NIFM                        \\ \cline{4-7} 
                                               &                              & \multicolumn{1}{c|}{}                   & 53.52                                                                              & 103.13                                                                        & 40      & SIREN                       \\ \hline
\end{tabular}}
\end{table}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/3d_results.pdf}
    \caption{We compare, both qualitatively (volume rendering of FTLE field) and quantitatively (flow map evaluation), our method with standard coordinate-based networks~\cite{sitzmann2020implicit} as well as pathline interpolation techniques~\cite{li2022efficient} for modeling the flow map in 3D unsteady flows. We find our method is quantitatively an improvement over other methods, and qualitatively our method contains fewer visual artifacts.}
    \label{fig:ftle_scalar}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/half_cylinder_v2.pdf}
    \caption{In this figure, we compare our method both quantitatively and qualitatively against SIREN for the Half-Cylinder dataset. We find that our method is able to scale reasonably well to this large dataset, whereas, the SIREN fails to learn meaningful flow maps as can be seen from the FTLE.}
    \label{fig:ftle_half_cylinder}
\end{figure*}

\subsection{3D unsteady flow}

We next evaluate our method on a set of 3D unsteady flows, comparing our method with a SIREN-based flow map~\cite{sitzmann2020implicit} as well as the B-spline pathline interpolation technique~\cite{li2022efficient}. We first compare to the Tornado and Scalar Flow datasets, where we set the $\tau_{max}$ to $8$ and $24$, respectively, to match the temporal complexity in the flows. Fig.~\ref{fig:ftle_scalar} shows qualitative results, via volume-rendering of the FTLE, as well as quantitative results. Our method is an improvement, if not comparable, to prior methods, but we obtain significant gains in inference time, as reported in Table~\ref{tab:3d_ftle_times}. We further compare to the Half Cylinder dataset, a large-scale unsteady flow dataset that cannot be readily stored in memory. We found the pathline interpolation method~\cite{li2022efficient} failed to fit to the data, and thus we limit our comparison to SIREN, please see Fig.~\ref{fig:ftle_half_cylinder}. In this experiment we set $\tau_{max} = 8$ and the compression ratio to $40$ to compensate for the larger data size. We find our method captures turbulent features in the wake of the half-cylinder object ($Re=320$), whereas SIREN faces difficulties in accurately modeling the data. Notably, for this dataset we find our training scheme scales well (c.f. Table~\ref{tab:3d_ftle_times}) relative to the 2D unsteady flow datasets, whereas SIREN's increase in model size leads to slower training times.

\vspace{-.9em}

\new{
\subsection{Error analysis: numerical integration}
\label{subsec:error}
Our method can be viewed as a novel technique for integrating a vector field, and thus, it is worth asking: how does our method compare to conventional numerical integration schemes? To help answer this question, we compare NIFM to existing numerical schemes, namely Euler and RK4, evaluated under varying step sizes. For the purpose of evaluation we use the Sine Ridge dataset provided by Kuhn et al.~\cite{kuhn2012benchmark} - as this is a steady flow we adapt our method accordingly. The dataset has an analytically-defined flow map that allows us to compute the flow map error across different schemes. In Fig.~\ref{fig:analytical}, we show the FTLE (first row) and the flow map error (second row) for Euler, RK4, and NIFM. The FTLE is computed for a duration $\tau=1.2$ with step size set to 30, where a single step amounts to 0.01 in the physical domain. We can see that NIFM best captures the FTLE, while maintaining low error in the flow map, in contrast with Euler and RK4. This provides evidence that our method is not merely a fixed linear (e.g. Euler), or higher-order (e.g. RK4) integration scheme, but rather adapts to the features of the data. We further show quantitative results for duration 0.6 and 1.2, again varying the step size. We can see that while NIFM has a consistent performance across all step sizes, the flow map error increases significantly for both RK4 and Euler with increasing step size.
}
\begin{figure}[!t]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/analytical_example.pdf}
    \caption{We compare NIFM to Euler and RK4 integration schemes, showing FTLE (top), flow map error (middle), and quantitative evaluation (bottom). We find NIFM performs consistently well across step sizes as compared to Euler and RK4 which can become numerically unstable.} 
    \label{fig:analytical}
\end{figure}

\subsection{Ablation: compression and supervision}

Last, we run model ablations to study the effects of various design choices. Due to space limitations we limit ablation to compression, as well as the role of supervision in learning flow maps. Further experiments regarding the architecture choices (number of levels in the multiresolution grid) and optimization scheme (number of steps to take, c.f. Eq.~\ref{eq:steps}) are detailed in the appendix.

In Fig.~\ref{fig:grid_artifact} we show the results of our model, for the FTLE of the Boussinesq, optimized under varying compression ratios. In this experiment we specifically wish to study how compression might impart visual artifacts in derived quantities of the flow map approximation, as a higher level of compression results in coarser feature grids. Indeed, we find that lower levels of compression lead to fewer grid-like artifacts in the resulting FTLE when taking a smaller steps, e.g. in this setting, a step size of 48 grid units in time amounts to an evaluation of the model just 3 times per position. We further report inference times for the smallest and largest level of compressions, and as expected, a larger number of steps requires longer inference times (e.g. more feedforward passes with the network). Interestingly, we find the inference time is fairly consistent across these compression ratios, indicating that the increased resolution of the grid has a negligible impact on this matter. As detailed in the appendix, we also find that the flow map accuracy takes just a small hit in performance across compression ratios, indicating that flow map accuracy might not be predictive of visual artifacts in derived quantities. Nevertheless, as shown in the figure, training times come at a cost with smaller compression ratios. We thus see natural trade-offs in the (1) flow map quality, (2) inference time (hinging on step size), and (3) training time.

\begin{figure}[!t]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/grid-artifact.pdf}
    \caption{We qualitatively compare our model under varying compression ratios, showing the effect of compression on the step size taken by our model to produce the FTLE for the Boussinesq flow.} 
    \label{fig:grid_artifact}
\end{figure}

\begin{figure}[!t]
    \centering
    \includegraphics[width=1\linewidth]{figures/flowmap_vs_self.pdf}
    \caption{For the Boussinesq flow we compare our self-consistency criterion with that of directly supervising on flow samples, finding that our method produces comparable, if not improved, flow map approximations, without ever accessing the ground-truth flow map.} 
    \label{fig:self_consistency_exp}
\end{figure}

Our choice to learn flow maps via a self-supervisory signal is in contrast with how numerous visualization techniques interpolate~\cite{chandler2014interpolation,li2022efficient}, or build models~\cite{han2021exploratory} given samples of the flow map, e.g. typically as densely-sampled pathlines. Therefore we ask: is our self-consistency criterion an inferior objective to directly supervising on flow map samples? To this end, we have gathered a large collection of flow map samples, and modified our objective (Eq.~\ref{eq:composition-detail}) to accept the ground-truth flow map, and its corresponding derivative at the output position. We optimize for Boussinesq, using 20M and 50M flow map samples, and compare with our proposed objective, please see Fig.~\ref{fig:self_consistency_exp} for the results. We find that our method is able to learn comparable, if not better, flow map approximations, without ever observing flow map samples. In particular, at 50M samples we find that flow map supervision starts to become competitive with our method. Although supervising an on even larger number of samples might be more beneficial, clearly the data requirement starts to become prohibitively expensive, both for integrating the flow field, as well as storage requirements. In contrast, our method avoids these issues by requiring the vector field as the only supervision.

