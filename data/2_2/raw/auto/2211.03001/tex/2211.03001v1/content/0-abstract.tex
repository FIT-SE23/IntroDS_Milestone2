
\begin{abstract}
Virtual reality (VR) offers the promise of an infinite office and remote collaboration, however, existing interactions in VR do not strongly support one of the most essential tasks for most knowledge workers, reading. This paper presents VRDoc, a set of gaze-based interaction methods designed to improve the reading experience in VR.  We introduce three key components: Gaze Select-and-Snap for document selection, Gaze MagGlass for enhanced text legibility, and Gaze Scroll for ease of document traversal. We implemented each of these tools using a commodity VR headset with eye-tracking. In a series of user studies with 13 participants, we show that VRDoc makes VR reading both more efficient (p < 0.01) and less demanding (p < 0.01), and when given a choice, users preferred to use our tools over the current VR reading methods.


%Reading is an essential task for most knowledge workers.  To realize an immersive and collaborative future of work in virtual reality (VR), better tools for reading in VR are required.  This paper presents three such tools: Gaze Select-and-Snap for document selection, Gaze MagGlass for enhanced text legibility and Gaze Scroll for ease of document traversal. We implemented each of these tools using a commodity VR headset with eye-tracking.  In a series of user studies with 17 participants, we show that these tools make VR reading both more efficient (p $< 0.01$) and less demanding (p $< 0.01$) and when given a choice, users preferred to use our tools over current VR reading methods. 

%Virtual reality (VR) offers the promise of large office spaces and remote collaboration. However, existing interactions in VR do not strongly support one of the most essential daily activities, reading. We present GazeDoc, a set of gaze-based interaction methods designed to improve the reading experience in VR. Our approach is motivated by an observational study that identifies the drawbacks of reading documents in VR with conventional object manipulation methods. We use a set of three gaze-based interactions designed to address these drawbacks: Gaze Select-and-Snap, Gaze MagGlass, and Gaze Scroll. Furthermore, we implement them on commodity HMDs by utilizing eye-tracking.  We perform a user study to evaluate how adding our three interaction techniques to the conventional manipulation interfaces affects the users' experience in two common reading scenarios. In the first scenario, participants were asked to read multiple short documents and in the second scenario, they were asked to read a long document. We observe statistically significant results that GazeDoc was a more usable (p $< 0.01$), less demanding (p $< 0.01$), and preferred (p $< 0.01$) interaction method for VR reading.
  
\end{abstract}