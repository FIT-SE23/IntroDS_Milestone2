\section{Related Work}
In this section, we briefly survey prior work in gaze-based interaction, text presentations in VR systems, and reading experiences in VR, AR, and MR systems.


\subsection{Text Presentations in VR}
Investigating text presentation on electronic devices to facilitate legibility has been an important issue for decades~\cite{dillon1990effects}. Text presentations in virtual environments present different issues than 2D monitor displays due to resolution limits and the presence of a third dimension in which to place documents. Dittrich et al. proposed a set of rules for text visualizations in 3D virtual environments~\cite{ dittrich2013legibility}. Their suggestions include having texts enlarged more than those on a 2D display. Jankowski et al. integrated text with video and 3D graphics to investigate the effects of text drawing style, image polarity, and background style (whether the background is a video or 3D)~\cite{jankowski2010integrating}. The results indicated that negative presentation of texts, such as white texts on a black background, performed better in terms of accuracy than positive presentation. Also, the billboard drawing styles, and the semitransparent white and black panels, led to a faster reading time and higher accuracy. 

Recently, Dingler et al. investigated user interface designs for displaying texts for VR reading~\cite{dingler2018vr}. They were able to identify a set of parameters such as text size, convergence, and color for an optimal text presentation. The findings indicated that users preferred texts presented with a sans-serif font and a negative presentation, that is, either having white text on a black background or having black text on a white background. There have also been efforts to investigate text presentations on 3D objects with various surfaces~\cite{wei2020reading}. It was found that a text is easier to read when it is warped around a 3D object with a single axis instead of two axes. Detailed design recommendations on the field of view and text boxes were presented. While text representation is a fundamental issue for reading in VR, it should be noted that users are given the freedom to interact with texts in an infinite margin space, not a restricted 2D display. Our paper focuses on the interaction aspect to improve users' reading performance.

%\cite{grout2015reading,dittrich2013legibility,jankowski2010integrating,dingler2018vr,wei2020reading,chen2004testbed,polys2007effects,orlosky2014managing,rzayev2018reading,rothe2018dynamic,sidenmark2019subtitles,rzayev2019notification,boschker2004lateral,spindler2012use,ware1994viewing,yee2003peephole}

\begin{figure*}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{pictures/FormativeStudy.png}
	\vspace{-0.5em}
	\caption{In the formative study, six documents (four documents containing 100 words and two documents containing 500 words) were available to the user. Participants were able to select and manipulate the documents using raycasting and the VR controller}.
	\label{fig:formative}
	\vspace{-1.5em}
\end{figure*}


\subsection{Reading in VR/MR systems}
Reading performance depends on the devices used to display reading materials. People read slower and less accurately from computer screens than from paper~\cite{dillon1992reading, gould1987reading}, although recently the difference has been diminishing~\cite{delgado2018don}. Reading performances on tablets and paper have also been extensively compared~\cite{ chen2014comparison,connell2012effects}.
Rau et al.~\cite{rau2018speed} compared the speed and accuracy of reading in VR and AR environments with reading on an LCD monitor. The authors also compared the reading performance on two VR HMDs that differed in display quality but were otherwise similar in every way. The results indicated that users read at a slower speed with VR and AR compared with a computer screen and had a tendency to respond more accurately and faster when wearing a VR HMD of a higher pixel density.

When reading in immersive reality systems such as VR or MR, users are given more methods to interact with documents. Here, various aspects of the hardware are considered, including the presentation of the document in the VR/MR headset and the type of user input (e.g., gestures, controllers). Rzayeve et al. studied the problem of optimal text presentation type and location~\cite{rzayev2021reading}. They tested the difference in user reading experience between using the Rapid Serial Visual Presentation (RSVP) method and presenting in a paragraph. In terms of location, the study tested world-fixed, head-fixed, and edge-fixed 2D windows. They found that RSVP is effective for reading short texts when paired with edge-fixed or head-fixed locations, and a full-paragraph presentation works well with world-fixed or edge-fixed locations when minimal movement is required for the user.
%Sidenmark et al.~\cite{pianzola2019virtual}, on the other hand, used an eye-tracking method to determine the position of subtitles in interactive VR. 

For reading with MR systems, Li et al. evaluated a mixed reality experience where users read physical paper documents while seeing related artifacts such as sticky notes, figures, and videos in MR through HoloLens~\cite{li2019holodoc}.  While the study identified that readers preferred this experience to that of reading on paper, laptop, or mobile devices, this did not test or improve reading in the immersive system but showed that users enjoyed seeing ancillary material in the infinite margins surrounding documents.
Pianzola et al. investigated whether reading fiction in VR, having an immersive background, and having the ability to move your head to view texts with different orientations, affect users' absorption in the story~\cite{pianzola2019virtual}. The results show that VR enhanced users' intention to read and their affective empathy. These findings indicate that VR can be effectively exploited to promote reading in VR.



\subsection{Gaze-based Interactions}
In recent years, the interest in gaze-based interactions has surged as consumer-level eye tracking sensors have been introduced to the general public~\cite{blattgerste2018advantages}. Eye tracking technology is especially well-utilized for interactions in immersive technologies such as VR and AR~\cite{hansen2018fitts, miniotas2000application, agledahl2021magnification}. Tanriverdi and Jacob found that in a VR setting, selection with eyes showed a similar speed advantage when compared to 3D motion-tracked pointers~\cite{tanriverdi2000interacting}. Piumsomboon et al. developed a set of selection methods using natural eye movements and found that such eye gaze-based interactions could improve usersâ€™ experience while maintaining performance comparable to standard interaction techniques~\cite{piumsomboon2017exploring}. While gaze offers fast pointing, its lack of precision and difficulty of selection confirmation has been challenging. To overcome this issue, researchers combined gaze input for selection and hands for manipulation~\cite{chatterjee2015gaze+, pfeuffer2014gaze,stellmach2011designing, velloso2015empirical}. In this context, Pfeuffer et al. proposed a novel method, Gaze-touch, in which users use multi-touch gestures on interactive surfaces to control gaze-selected targets~\cite{pfeuffer2014gaze}. %Moving on from target selection, which is a sub-phase of the whole object manipulation process, 
Yu et al. further incorporated gaze and hand inputs for a full 3D object manipulation in VR~\cite{yu2021gaze}. Biener et al. combined touch-based interactions with gaze for editing presentation slides in VR~\cite{biener2022povrpoint}. With a wide variety of options for utilizing gaze for interactions, it is important to select operations for which eye-tracking can play a big role so that it efficiently supplements conventional hand- or controller-based interaction methods. 
%\cite{blattgerste2018advantages,iso20009241,hansen2018fitts,miniotas2000application,qian2017eyes,sibert2000evaluation,tanriverdi2000interacting,zhang2007evaluating,ohno2002freegaze,piumsomboon2017exploring,atienza2016interaction,sidenmark2020outline,pfeuffer2021artention,yu2021gaze,d2018eye,sindhwani2019retype,alghofaili2019lost,kutt2019eye,sidenmark2021radi}



In this study, we investigate how existing conventional methods are used when reading documents, identify the drawbacks and needs of the user, and build an enhanced interaction method designed for reading documents in a virtual environment.

%\cite{rzayev2018reading,li2019holodoc,mirault2020using,pianzola2019virtual,rau2018speed,wei2020reading,rau2018speed}


%\begin{figure}[t]
%	\centering
%	\includegraphics[width=0.9\linewidth]{pictures/pilotstudy_2.PNG}
%	\caption{For our pilot study described in Section 3.1, we place six documents in front of the user. Four documents contained 100 words and two documents contained 500 words. Participants freely read the documents with the selected manipulation method for 20 minutes. Based on the pilot study, we identified three major issues with the current interfaces, described in Section 3.1.3.}
%	\label{fig:target}
%\end{figure}

