\section{Introduction}
Virtual Reality is increasingly being used for both entertainment and collaboration.  Increasingly, there is a demand for tools that can support virtual office environments \footnote{https://www.roadtovr.com/vr-apps-work-from-home-remote-office-design-review-training-education-cad-telepresence-wfh/}, including {\em Connec2, Glue, Immersed, MeetinVR, MeetingRoom, Rumii, Spatial, vSpatial, etc.}   Many of these technologies focus on the importance of remote collaboration, but overlook one of the most essential tasks of office work, reading.  Reading is essential for knowledge workers and will continue to be crucial even when co-workers want to share documents in a virtual office.   

As we look forward to a future of an immersive infinitely collaborative virtual office space, we cannot ignore the importance of a seamless reading experience being part of this virtual environment.  Currently, reading in VR is considered difficult if not impossible in a sustainable way~\cite{mirault2020using,pianzola2019virtual,rau2018speed,rzayev2018reading,wei2020reading}.  Users typically refer to many hardware-related issues with respect to the current displays which are unable to satisfy the fastidious requirements of the human visual system, including high pixel density, a large number of pixels, wide field-of-view (FOV), and a high refresh rate. At the same time, recent developments including near-eye display optics, accommodation-supporting near-eye displays, foveated displays, and vision-correcting near-eye displays~\cite{koulieris2019near} can alleviate some of these problems. It is expected that VR headsets will continue to improve in terms of display technologies and pixel resolution. 
It is also notable that, in addition to displays, other technologies such as eye tracking are being integrated as a standard feature in forthcoming HMDs~\cite{playstation_eye}.  Even with expected improvements in headset hardware, software tools for facilitating tasks will be equally important to promote seamless and sustainable productivity.  From our observational study, we have identified two major areas of improvement for VR reading tools: {\em space aware features} that facilitate selecting a document from the immersive environment and positioning it for the best reading experience and {\em document interactions} that allow users to read documents without physically leaning toward the document or manually grabbing and zooming in order to read.    
 %
%\begin{figure}[t]
%	\centering
%	\includegraphics[width=.9\linewidth]{pictures/teaser2.png}
%	\caption{\textit{VRDoc} provides users a set of three gaze-based interactions that improves users' reading experience in a virtual environment. We evaluate the results and observe considerable improvement over prior interaction methods.}
%	\label{fig:teaser}
%	\vspace*{-0.1in}
%\end{figure}


Our main contributions are a set of three gaze-based interaction methods that can improve the reading experiences in VR: Gaze Select-and-Snap, Gaze MagGlass, and Gaze Scroll. Our tools are general and do not make any assumptions about the underlying task. We use standard interfaces for object manipulation along with eye tracking capabilities available in current HMDs~\cite{vive}. We first conducted a formative study to evaluate current user pain points that might impact document manipulation and reading in VR using object manipulation and canvas interaction tasks (Section 3.1). Based on this study, we identified three main challenges: difficulty positioning document objects, poor readability in current headsets, and arm fatigue (``gorilla arm''~\cite{Jang17}). To overcome these issues, we use three interaction methods: Gaze Select-and-Snap, Gaze MagGlass, and Gaze Scroll (Section 3.2). All these interaction methods  are based on eye tracking and eliminate the need to hold controllers or perform repetitive arm gestures, both of which can be tiring in long-term interactions.  With Gaze Select-and-Snap, a user can simply gaze at a virtual object tagged as a document to select it and uses a single button confirmation to bring that object into a reading view.  In the reading view, Gaze MagGlass tracks the user's eye movement and locally magnifies the text the user is reading.  Finally, when the user reaches the end of a section or page, Gaze Scroll enables the document to scroll automatically enabling seamless continued reading.

We performed user studies to evaluate our interaction tools on two tasks: reading multiple short documents and reading a long document (Section 4).  We measured tool usage, reading task completion time, and reading comprehension for both scenarios.  We then performed subjective evaluations to measure usability, effectiveness, workload, and preference using SUS and Raw TLX questionnaires. We confirmed that our tools did not increase motion sickness using the SSQ instrument for VR sickness. We observed statistically significant results that indicate that VRDoc is a more usable, less demanding, and preferred interaction method for reading in VR (Section 5). In summary, our contributions include:
\vspace{-0.1em}
\begin{itemize}
\itemsep-0.1em
\item Identifying current user pain points for VR reading experiences.
\item Developing three gaze-based user interactions to improve the VR reading experience: Gaze Select-and-Snap, Gaze MagGlass, and Gaze Scroll. 
\item Evaluating these VRDoc tools on two VR document reading tasks and observing statistically significant results for reading comprehension, task completion, usability and workload, as well as readability, efficiency, and preference.
\end{itemize}
%Overall, users found VRDocto be more readable and effective resulting in it to be more preferred than the conven-tional method.