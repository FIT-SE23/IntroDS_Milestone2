



@article{LQL,
  title={Lenient multi-agent deep reinforcement learning},
  author={Palmer, Gregory and Tuyls, Karl and Bloembergen, Daan and Savani, Rahul},
  journal={arXiv preprint arXiv:1707.04402},
  year={2017}
}

@inproceedings{HQL,
  title={Hysteretic q-learning: an algorithm for decentralized reinforcement learning in cooperative multi-agent teams},
  author={Matignon, La{\"e}titia and Laurent, Guillaume J and Le Fort-Piat, Nadine},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year={2007}
}

@inproceedings{undecideDECPOMDP,
  title={On the undecidability of probabilistic planning and infinite-horizon partially observable Markov decision problems},
  author={Madani, Omid and Hanks, Steve and Condon, Anne},
  booktitle={AAAI/IAAI},
  pages={541--548},
  year={1999}
}

@article{HPO,
  title={Hinge Policy Optimization: Rethinking Policy Improvement and Reinterpreting PPO},
  author={Yao, Hsuan-Yu and Hsieh, Ping-Chun and Ho, Kuo-Hao and Hu, Kai-Chun and Ouyang, Liang-Chun and Wu, I and others},
  journal={arXiv preprint arXiv:2110.13799},
  year={2021}
}


@inproceedings{FOP,
  title={FOP: Factorizing Optimal Joint Policy of Maximum-Entropy Multi-Agent Reinforcement Learning},
  author={Zhang, Tianhao and Li, Yueheng and Wang, Chen and Xie, Guangming and Lu, Zongqing},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}

@inproceedings{Trust-PCL,
  title={Trust-pcl: An off-policy trust region method for continuous control},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}
@article{MPO,
  title={Maximum a posteriori policy optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1806.06920},
  year={2018}
}

@inproceedings{MIRL,
  title={Soft q-learning with mutual-information regularization},
  author={Grau-Moya, Jordi and Leibfried, Felix and Vrancx, Peter},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019}
}
@article{onpolicy-QMIX,
  title={Towards Understanding Linear Value Decomposition in Cooperative Multi-Agent Q-Learning},
  author={Wang, Jianhao and Ren, Zhizhou and Han, Beining and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2006.00587},
  year={2020}
}

@inproceedings{QTRAN,
  title="QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning",
  author="Kyunghwan {Son} and Daewoo {Kim} and Wan Ju {Kang} and David Earl {Hostallero} and Yung {Yi}",
  booktitle="International Conference on Machine Learning (ICML)",
  year="2019"
}


@article{Qatten,
  title={Qatten: A General Framework for Cooperative Multiagent Reinforcement Learning},
  author={Yang, Yaodong and Hao, Jianye and Liao, Ben and Shao, Kun and Chen, Guangyong and Liu, Wulong and Tang, Hongyao},
  journal={arXiv preprint arXiv:2002.03939},
  year={2020}
}


@inproceedings{VDN,
  title={Value-Decomposition Networks For Cooperative Multi-Agent Learning Based On Team Reward.},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vin{\'\i}cius Flores and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  booktitle={International Conference on Autonomous Agents and MultiAgent Systems (AAMAS)},
  year={2018}
}


@inproceedings{QPLEX,
  title={QPLEX: Duplex dueling multi-agent q-learning},
  author={Wang, Jianhao and Ren, Zhizhou and Liu, Terry and Yu, Yang and Zhang, Chongjie},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}



@article{MAPPO,
  title={The surprising effectiveness of mappo in cooperative, multi-agent games},
  author={Yu, Chao and Velu, Akash and Vinitsky, Eugene and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  journal={arXiv preprint arXiv:2103.01955},
  year={2021}
}

@article{IPPO,
  title={Is Independent Learning All You Need in the StarCraft Multi-Agent Challenge?},
  author={de Witt, Christian Schroeder and Gupta, Tarun and Makoviichuk, Denys and Makoviychuk, Viktor and Torr, Philip HS and Sun, Mingfei and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2011.09533},
  year={2020}
}

@inproceedings{CPI,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2002}
}

@article{PPO,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{TRPO,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2015}
}

@article{stable-policy,
  title={Stable Policy Optimization via Off-Policy Divergence Regularization},
  author={Touati, Ahmed and Zhang, Amy and Pineau, Joelle and Vincent, Pascal},
  journal={arXiv preprint arXiv:2003.04108},
  year={2020}
}

@article{ent-robust,
  title={Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
  author={Ziebart, Brian D},
  year={2010}
}

@article{openai5,
  title={Dota 2 with large scale deep reinforcement learning},
  author={OpenAI, C Berner and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Debiak, P and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@article{alphastar,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019}
}

@article{robotswarms,
  title={Guided deep reinforcement learning for swarm systems},
  author={H{\"u}ttenrauch, Maximilian and {\v{S}}o{\v{s}}i{\'c}, Adrian and Neumann, Gerhard},
  journal={arXiv preprint arXiv:1709.06011},
  year={2017}
}

@article{autocars,
  title={An overview of recent progress in the study of distributed multi-agent coordination},
  author={Cao, Yongcan and Yu, Wenwu and Ren, Wei and Chen, Guanrong},
  journal={IEEE Transactions on Industrial informatics},
  volume={9},
  number={1},
  pages={427--438},
  year={2012},
  publisher={IEEE}
}
@inproceedings{ATOC,
  title={Learning attentional communication for multi-agent cooperation},
  author={Jiang, Jiechuan and Lu, Zongqing},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2018}
}

@inproceedings{V-trace,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2018}
}

@inproceedings{TarMAC,
  title={Tarmac: Targeted multi-agent communication},
  author={Das, Abhishek and Gervet, Th{\'e}ophile and Romoff, Joshua and Batra, Dhruv and Parikh, Devi and Rabbat, Mike and Pineau, Joelle},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2019}
}
@inproceedings{IC3NET,
  title={Learning Multi-Agent Communication through Structured Attentive Reasoning},
  author={Rangwala, Murtaza and Williams, Ryan},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@inproceedings{CommNet,
  title={Learning multiagent communication with backpropagation},
  author={Sukhbaatar, Sainbayar and Fergus, Rob and others},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2016}
}
@inproceedings{MADDPG,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi I and Tamar, Aviv and Harb, Jean and Abbeel, OpenAI Pieter and Mordatch, Igor},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2017}
}

@inproceedings{COMA,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob N and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  year={2018}
}

@article{traffic,
  title={Reinforcement learning-based multi-agent system for network traffic signal control},
  author={Arel, Itamar and Liu, Cong and Urbanik, Tom and Kohls, Airton G},
  journal={IET Intelligent Transport Systems},
  volume={4},
  number={2},
  pages={128--135},
  year={2010},
  publisher={IET}
}

@inproceedings{SAC,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2018}
}

@inproceedings{SAC-theory,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2017}
}

@article{whatisquestion,
  title={If MaxEnt RL is the Answer, What is the Question?},
  author={Eysenbach, Benjamin and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.01913},
  year={2019}
}

@inproceedings{QMIX,
  title={QMIX: monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2018}
}

@article{unifiedview,
  title={A unified view of entropy-regularized markov decision processes},
  author={Neu, Gergely and Jonsson, Anders and G{\'o}mez, Vicen{\c{c}}},
  journal={arXiv preprint arXiv:1705.07798},
  year={2017}
}

@article{SMAC,
  title={The starcraft multi-agent challenge},
  author={Samvelyan, Mikayel and Rashid, Tabish and de Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1902.04043},
  year={2019}
}

@inproceedings{MAAC,
  title={Actor-attention-critic for multi-agent reinforcement learning},
  author={Iqbal, Shariq and Sha, Fei},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2019}
}

@inproceedings{DIV-AUG,
  title={Divergence-Augmented Policy Optimization},
  author={Wang, Qing and Li, Yingru and Xiong, Jiechao and Zhang, Tong},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@inproceedings{regularizer,
  title={A Regularized Approach to Sparse Optimal Policy in Reinforcement Learning},
  author={Yang, Wenhao and Li, Xiang and Zhang, Zhihua},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@book{Dec-POMDP,
  title={A concise introduction to decentralized POMDPs},
  author={Oliehoek, Frans A and Amato, Christopher and others},
  volume={1},
  year={2016},
  publisher={Springer}
}

@article{DQN,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015}
}


@inproceedings{transfer,
  title={Learning Transferable Cooperative Behavior in Multi-Agent Team},
  author={Agarwal, Akshat and Kumar, Sumit and Sycara, Katia and Lewis, Michael},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  year={2020}
}

@book{RLBOOK,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{MDP,
  title={A Markovian decision process},
  author={Bellman, Richard},
  journal={Journal of mathematics and mechanics},
  pages={679--684},
  year={1957},
  publisher={JSTOR}
}
@Book{DP,
  author =       "Bellman, Richard",
  title =        "Dynamic Programming",
  publisher =    "Princeton University Press",
  year =         "1957",
  address =   "Princeton, NJ, USA",
  edition =   "1",
  url = "http://books.google.com/books?id=fyVtp3EMxasC&pg=PR5&dq=dynamic+programming+richard+e+bellman&client=firefox-a#v=onepage&q=dynamic%20programming%20richard%20e%20bellman&f=false",
  bib2html_rescat = "General RL",
}

@article{Q-learning,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{PG,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2000}
}

@inproceedings{DOUBLE-DQN,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Thirtieth AAAI conference on artificial intelligence},
  year={2016}
}

@inproceedings{DRQN,
  title={Deep recurrent q-learning for partially observable mdps},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={2015 AAAI Fall Symposium Series},
  year={2015}
}
@article{DUEL-DQN,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Van Hasselt, Hado and Lanctot, Marc and De Freitas, Nando},
  journal={arXiv preprint arXiv:1511.06581},
  year={2015}
}

@inproceedings{A3C,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@article{alphago,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{CO-MARLreview,
  title={A review of cooperative multi-agent deep reinforcement learning},
  author={OroojlooyJadid, Afshin and Hajinezhad, Davood},
  journal={arXiv preprint arXiv:1908.03963},
  year={2019}
}

@inproceedings{IQL,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Tan, Ming},
  booktitle={International Conference on Machine Learning (ICML)},
  year={1993}
}

@inproceedings{deep_energy,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{DGN,
  title={Graph convolutional reinforcement learning},
  author={Jiang, Jiechuan and Dun, Chen and Huang, Tiejun and Lu, Zongqing},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@inproceedings{DOP,
title={DOP: Off-Policy Multi-Agent Decomposed Policy Gradients},
author={Yihan Wang and Beining Han and Tonghan Wang and Heng Dong and Chongjie Zhang},
booktitle={International Conference on Learning Representations (ICLR)},
year={2021}
}

@article{de2020facmaddpg,
  title={Deep multi-agent reinforcement learning for decentralized continuous cooperative control},
  author={de Witt, Christian Schroeder and Peng, Bei and Kamienny, Pierre-Alexandre and Torr, Philip and B{\"o}hmer, Wendelin and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2003.06709},
  year={2020}
}

@article{COPPO,
  title={Coordinated Proximal Policy Optimization},
  author={Wu, Zifan and Yu, Chao and Ye, Deheng and Zhang, Junge and Zhuo, Hankz Hankui and others},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={34},
  year={2021}
}


@article{ROMA,
  title={Roma: Multi-agent reinforcement learning with emergent roles},
  author={Wang, Tonghan and Dong, Heng and Lesser, Victor and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2003.08039},
  year={2020}
}

@article{RODE,
  title={Rode: Learning roles to decompose multi-agent tasks},
  author={Wang, Tonghan and Gupta, Tarun and Mahajan, Anuj and Peng, Bei and Whiteson, Shimon and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2010.01523},
  year={2020}
}

@article{HAPPO,
  title={Trust region policy optimisation in multi-agent reinforcement learning},
  author={Kuba, Jakub Grudzien and Chen, Ruiqing and Wen, Munning and Wen, Ying and Sun, Fanglei and Wang, Jun and Yang, Yaodong},
  journal={arXiv preprint arXiv:2109.11251},
  year={2021}
}

@inproceedings{mamujoco,
  title={Facmac: Factored multi-agent centralised policy gradients},
  author={Peng, Bei and Rashid, Tabish and Schroeder de Witt, Christian and Kamienny, Pierre-Alexandre and Torr, Philip and B{\"o}hmer, Wendelin and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021}
}

@inproceedings{benchmark,
  title={Benchmarking multi-agent deep reinforcement learning algorithms in cooperative tasks},
  author={Papoudakis, Georgios and Christianos, Filippos and Sch{\"a}fer, Lukas and Albrecht, Stefano V},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021}
}

@article{MARL-survey,
  author    = {Kaiqing Zhang and
               Zhuoran Yang and
               Tamer Basar},
  title     = {Multi-Agent Reinforcement Learning: {A} Selective Overview of Theories
               and Algorithms},
   journal={arXiv preprint arXiv:1911.10635},
  year      = {2019},
}

@article{IDQN,
  author    = {Ardi Tampuu and
               Tambet Matiisen and
               Dorian Kodelja and
               Ilya Kuzovkin and
               Kristjan Korjus and
               Juhan Aru and
               Jaan Aru and
               Raul Vicente},
  title     = {Multiagent Cooperation and Competition with Deep Reinforcement Learning},
  journal   = {arXiv preprint arXiv:1511.08779},
  year      = {2015}
}

@article{sun2022monotonic,
  title={Monotonic Improvement Guarantees under Non-stationarity for Decentralized PPO},
  author={Sun, Mingfei and Devlin, Sam and Hofmann, Katja and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2202.00082},
  year={2022}
}

@inproceedings{DMAC,
  author    = {Kefan Su and
               Zongqing Lu},
  title     = {Divergence-Regularized Multi-Agent Actor-Critic},
  booktitle   = {International Conference on Machine Learning (ICML)},
  year      = {2022}
}

@inproceedings{zhang2018fully,
  title="Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents",
  author="Kaiqing {Zhang} and Zhuoran {Yang} and Han {Liu} and Tong {Zhang} and Tamer {Ba$\c{s}$ar.}",
  booktitle="International Conference on Machine Learning (ICML) ",
  year="2018"
}

@article{terry2020revisiting,
  title={Revisiting parameter sharing in multi-agent deep reinforcement learning},
  author={Terry, Justin K and Grammel, Nathaniel and Hari, Ananth and Santos, Luis and Black, Benjamin},
  journal={arXiv preprint arXiv:2005.13625},
  year={2020}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year={2012}
}


@article{li2020f2a2,
  title={F2a2: Flexible fully-decentralized approximate actor-critic for cooperative multi-agent reinforcement learning},
  author={Li, Wenhao and Jin, Bo and Wang, Xiangfeng and Yan, Junchi and Zha, Hongyuan},
  journal={arXiv preprint arXiv:2004.11145},
  year={2020}
}

@inproceedings{sayin2021decentralized,
  title={Decentralized Q-learning in zero-sum Markov games},
  author={Sayin, Muhammed and Zhang, Kaiqing and Leslie, David and Basar, Tamer and Ozdaglar, Asuman},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021}
}