\documentclass[lettersize,journal]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{xcolor}
\newcommand{\todo}[1]{{\color{orange}[todo: #1]}}


\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}

\begin{document}

\title{Leveraging Haptic Feedback to Improve \\Data Quality and Quantity for \\Deep Imitation Learning Models}

\author{Catie Cuan$^{1}$, Allison Okamura$^{1}$, and Mohi Khansari$^{2}$
\thanks{*This work was supported by Everyday Robots}
\thanks{$^{1}$Catie Cuan and Dr. Allison Okamura are with the Department of Mechanical Engineering, Stanford University, Stanford, CA 94305, USA
        {\tt\small ccuan@stanford.edu, aokamura@stanford.edu}}%
\thanks{$^{2}$Dr. Mohi Khansari is with Everyday Robots, Mountain View, CA 94043, USA
        {\tt\small khansari@everydayrobots.com}}%
}


\maketitle

\begin{abstract}
Learning from demonstration (LfD) is a proven technique to teach robots new skills. Data quality and quantity play a critical role in LfD trained model performance. In this paper we analyze the effect of enhancing an existing teleoperation data collection system with real-time haptic feedback; we observe improvements in the collected data throughput and its quality for model training. Our experiment testbed was a mobile manipulator robot that opened doors with latch handles. Evaluation of teleoperated data collection on eight real world conference room doors found that adding the haptic feedback improved the data throughput by 6\%. We additionally used the collected data to train six image-based deep imitation learning models, three with haptic feedback and three without it. These models were used to implement autonomous door-opening with the same type of robot used during data collection. Our results show that a policy from a behavior cloning model trained with haptic data performed on average 11\% better than its counterpart with no haptic feedback data, indicating that haptic feedback resulted in collection of a higher quality dataset.
\end{abstract}

\begin{IEEEkeywords}
Haptics and Haptic Interfaces, Imitation Learning
\end{IEEEkeywords}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

Learning from demonstration is a promising approach to teach robots new skills based on a set of expert demonstrations \cite{argall2009survey, fang2019survey, schaal1999imitation}. In this paradigm, the learned policy benefits from the demonstrators' prior knowledge about a task (in contrast to self exploration) in order to learn the task with a reasonable number of demonstrations (preferably not more than a couple of hours). Demonstrators can be humans, other robots, or other simulated agents, and demonstrations can be collected in a variety of modes, including teleoperation, third-person video recording, and kinesthetic interactions. To improve the ease of filtering the data, demonstrators may automatically tag the data they are collecting as success or failure. Once this data is collected, various techniques such as behavior cloning \cite{torabi2018behavioral} are used to train a model that is then deployed as a policy by an autonomous agent.

\begin{figure*}[h!]
\centering
\includegraphics[width=\linewidth]{glamour_new3.pdf}
\caption{{We measure how haptic feedback alters individuals' performance in terms of data throughput and data quality in a latch door opening task, and evaluate the effect of the resultant datasets on the autonomous performance of learned policies. Left: A demonstrator teleoperates a mobile manipulator robot. Right: Close-up progression of a robot opening a door. Robot from Everyday Robots.}}
\label{push_door_setup}
\end{figure*}

In visual imitation learning for robotic manipulation, images (observations) and robot movements (actions) gathered from expert demonstrations are separated into observation and action pairs. The images are fed to a probabilistic transition model \(p(s_t|s_{t-1}, a_{t-1})\) that is used to compute robot actions - where $s$ is state, $a$ is action, and $t$ is a corresponding timestep. The aim is to learn a policy $\pi(a\vert s)$ that imitates the expert policy $\pi^*(a|s)$ represented in the demonstrations. Towards this end, teleoperation is an effective mode of data collection because (1) egocentric cameras on the robot can see the task (in contrast to direct human demonstration, where the demonstrator might physically obstruct the robot's view), and (2) the data is directly representative of the robot's action space and does not need to address the correspondence problem (the correspondence problem is the difficulty in matching different training data representations to the robot's possible action space). However, in some cases, the teleoperation approach is not ideal because the human demonstrator may have an advantageous viewpoint compared to the viewpoint of the robot's cameras. When the human is able to see more than the robot can, the collected data may be of poor quality because the human leverages visual feedback information that is not captured in the egocentric robot images that are fed to the model. There may also be a kinematic and force feedback mismatch between the human and the teleoperated robot because the robot's sensors may record contact forces that are not felt by the teleoperator. These mismatching visual and force feedback channels between the human and the robot may be mitigated by giving the human demonstrator more real-time feedback about the robot's overall state, thus altering the demonstrator's behavior. Haptic feedback is a promising alternative feedback channel for teleoperating physical manipulation tasks and may alter demonstrator behavior, such as the time needed to collect useful data and the quality or consistency of the data. This alteration in demonstrator behavior can impact the learned policy. 

The quality of the collected data plays an important role in generating autonomous actions via behavior cloning techniques \cite{hussein2017imitation}. Imagine two scenarios: 
Scenario A: X hours of high-quality data is collected (in this case, data collected with haptics).
Scenario B: 2X of confusing, messy data is collected.
Despite Scenario B having more data, it yields to poorer performance because the imprecise data reduces training clarity. Thus, to improve the LfD process and understand the role of added haptic feedback, we address two primary research questions:
\vspace{-1mm}
\begin{itemize}
    \item Does haptic feedback improve demonstrator performance during example collection?
    \item Do models trained with data collected with haptic feedback lead to improved autonomous robot task performance (i.e. resultant policies)?
\end{itemize} 

To address these research questions, we performed a study to learn a latch door opening physical interaction task  (Figure \ref{push_door_setup}), through human demonstration via teleoperation with and without haptic feedback. The results indicate that the use of haptic feedback helps with both the data quality and quantity. It is widely accepted in imitation learning that one can improve robot performance through either better model architecture or better data. In our work, we study the latter and evaluate it at two levels: (1) Data collection and (2) Learned policy performance. Our contribution comes from not only making the data collection faster/higher yield but also demonstrating that this change in demonstrator behavior manifests in a change in learned policy performance. Our results show that haptic feedback is useful for robot learning not necessarily because the task requires it; but because the quality of the collected data is higher. 

\section{Prior Work}

We consider tasks that require physical interaction between the robot end-effector and its environment. This interaction constrains the movement of the robot and results in forces that can be used to generate haptic feedback. Prior work performed deep imitation learning with off-the-shelf virtual reality headsets, leading to high success rates for manipulation tasks like grasping or relocating an object \cite{kim2022memory, seita2020deep, xie2020deep, zhang2018deep}. Related work shows that it is possible to train complex manipulation behaviors from images alone \cite{rahmatizadeh2018vision} and in some cases without explicit examples of the task \cite{jang2022bc}. Certain robotic teleoperation tasks have been performed with only visual feedback, such as steering a robotic vehicle \cite{recchiuto2016visual} or using a wide, omni-viewing camera to move an occluded object \cite{nicolis2018occlusion}. Prior work demonstrates that adding haptic feedback to a visual teleoperation system improves abstract motor skills \cite{morris2007haptic}, and when provided early in training, can enhance performance with surgical simulators \cite{strom2006early}. Depending on the task context, low-frequency haptic feedback  may lead to improved task performance \cite{wildenbeest2012impact}. In other circumstances, cutaneous haptic feedback increases task success \cite{pacchierotti2015cutaneous}. This paper builds upon these prior works and examines the research question of whether haptic feedback can improve demonstrator performance as well as policy performance in an LfD paradigm.

\begin{figure*}[t]
\vspace{1.5mm}
\centering
\includegraphics[width=\linewidth]{variables_figure.pdf}
\caption{Our complete workflow including data collection, curation, training, and policy testing. This paper contributes to the first, second, and fourth steps by introducing haptic feedback to the teleoperator, curating the collected data, and evaluating different policies in the real world. For the third step, we follow the same approach as in \cite{khansari2022practical}. For the models in the policy testing phase, matching colors indicate that they were tested on the same set of real world doors.}
\label{workflow}
\end{figure*}

Given a collected dataset, a secondary, yet critical, challenge is how to remove low-quality data or mislabeled data from the dataset. Prior work curates data manually by manual examination of the dataset \cite{friedrich1995robot}. Researchers have used statistical methods such as Low Confidence Correction and Jitter \cite{chuck2017statistical} and ActiveClean \cite{krishnan2016activeclean} to filter noisy data. The data curation approach in this paper uses a combination of manual and statistical curation to improve performance.

Furthermore, researchers have explored haptic feedback during different phases of LfD. In prior work, researchers aimed to learn robot manipulation policies only through forces \cite{rozo2013robot}. They used a high-fidelity kinesthetic haptic device during example collection, in combination with other novel data encoding techniques, and found the robot could reach comparable human teacher performance on two manipulation tasks. Other researchers equipped a robot with a pressure cuff so human demonstrators could encode stiffness profiles during example collection; they concluded that adding the stiffness profile to the control scheme increased the robot's success rate at lighting a match \cite{kronander2013learning}. In different work, researchers used kinesthetic teaching to demonstrate a position profile and then combined this with teleoperation data collected via a kinesthetic haptic device to teach a force profile \cite{kormushev2011imitation}. Another group of researchers trained a robot to provide real-time haptic guidance to a surgical demonstrator during cooperative control between a human and Raven II robot \cite{power2015cooperative}. Prior work thus indicates that kinesthetic haptic feedback during example collection can improve robot performance, but has not examined if haptic feedback is useful when training a deep imitation learning model, training a deep imitation learning model, training an image-only model (versus one with force information), or collecting data with low-cost, ungrounded haptic devices. In this research work we leverage haptic feedback during the data collection phase to improve the demonstration data throughput and its quality for the purpose of training a deep visual imitation learning model.

%===============================================================================

\section{Methods}
\label{sec:Methods}

In order to address our primary research questions, the project was divided into two phases. Phase 1 studied demonstrators' performance with and without haptic feedback and Phase 2 analyzed the real-world performance of the trained policies on opening latched doors autonomously. Figure \ref{push_door_setup} shows a demonstrator opening the door via teleoperation and zoomed-in images of the gripper movement. In this task, the demonstrator stands behind the robot while it moves to a starting configuration, and then teleoperates the arm to open the door. After this, the demonstrator marks the task success or failure. Figure \ref{workflow} shows the variables and their range of values for our study. The two feedback conditions for teleoperation were Haptics and No Haptics. Nine human demonstrators participated in order to represent a range of experience and strategies. Data was collected on four doors and policies were tested on all four doors seen during training and an additional two doors for each side (left and right). All doors were in the same building.

The type of robot used for data collection is a 7-Degree-of-Freedom (DoF) manipulator, with a two-finger gripper and a 2-DoF mobile base. The robot is equipped with a custom 6-axis force-torque sensor in the wrist and has a camera in the head, referred to as the first-person camera. The robot was teleoperated using controllers from a commercially available virtual reality headset. There are two controllers, one for each hand of the demonstrator; the left-hand controller moves the robot's base and the right-hand controller moves the robot's arm. Teleoperation control is done by mapping the device controller 3D pose to the robot's gripper in Cartesian space and then performing inverse kinematics to get the robot joint angles. When provided, the haptic feedback was sent to the controller held in the right hand. High forces felt like a substantial buzzing in the hand. In all conditions, the human demonstrators had a direct line of sight with the robot and the door. The teleoperation controller has a single linear vibration actuator in each hand controller. The haptic feedback was proportional to the readings from the force-torque sensor. The robot sent a message to the controller at a rate of 10 Hz. For all force-torque sensor values over 2N, the controller buzzed with an amplitude and duration that was linearly proportional to the force magnitude. The haptic feedback experience was tested and tuned (by the researchers and a demonstrator who did not participate in the study) prior to being deployed on the device.  The maximum amplitude was $1.764g$ and the vibrations were at 200 Hz. 

\vspace{-3mm}
\subsection{Phase 1: Studying haptic feedback during demonstrator performance}

Two datasets were collected for opening a door by pressing down on the latch-type handle and pushing the door open: with haptic feedback and without haptic feedback. The nine demonstrators were professional robot teleoperators who had used the robot previously for various tasks. All demonstrators were right-handed and their experience varied from 2 months to 18 months worth of experience in this role. Regardless of their experience, each demonstrator received one hour of practice on the task prior to commencing formal data collection. All demonstrators completed a short interview at the start of the first day in order to describe their past experience with this robot and their past teleoperation experience.

Nine demonstrators participated in the task. There were five men, one woman, one non-binary person, and two people declined to state their gender. Seven of the participants were 25-34 years old, one person was 35-44 years old, and one person declined to state. The Stanford University Institutional Review Board determined that this study does not meet the regulatory definition of human subjects research because the participants are paid demonstrators performing this teleoperation work as their job. Professional demonstrators who were available to collect data were included; the exclusion criteria were individuals who were not professional demonstrators.

\subsubsection{Real-world data collection}

Teleoperation data was collected for the task of opening push latch doors. The task was as follows: the demonstrator stood behind the robot while the robot's arm moved to a starting configuration near the front of the door. Recall that the controller position is mapped to the position of the robot's gripper. The demonstrator began recording an episode, and moved the controller through space so the robot's gripper reached the door handle. The demonstrator then pushed down and released the latch. The demonstrator attempted this until they reached either a success (door unlatched) or failure state, and then marked the episode immediately after completing it. Demonstrators marked the episode as a failure if the fingers fell off, the robot entered an error state, the arm was in a strange position that was hard to control, or the robot remained in prolonged contact with the latch after the door opened. The base of the robot remained stationary for the duration of the episode collection. The demonstrators were instructed to collect $\sim 200$ successful examples or stop at the end of an eight hour workday if they did not collect this number. Nine demonstrators participated in the data collection. They spent the full day of data collection in the same condition: either Haptics or No Haptics. Conditions were randomized so demonstrators varied as to which condition they received first and second. 

The summarized participant task instructions are below:

\textit{Today you will be collecting data on push latch door opening. Your goal will be to open the door as gently and efficiently as possible. For the latched door, we do as follows:
Press the “clutch” or middle finger button on the right controller to move the robot. While holding the clutch, place one finger on top of the latch and press straight down. If the door is unlatched, i.e. can be pushed open without turning the handle again, it is a success. If the fingers snap off, or the robot enters an error state, or the robot stays in contact with the door after opening it, it is a failure. If you are using the haptics application you will feel some buzzing in your hand when you come into contact with objects.
When you feel this buzzing become MUCH stronger, it means you are surpassing the safe force limits of the robot, back away and try again.}

Data was collected on four meeting room doors in an office building. All demonstrators aimed for an even distribution of right swing and left swing doors, meaning half the total data collected was left swing and half the total collected was right swing. Some demonstrators were less successful with opening left swing doors than right swing doors; therefore their collected number of examples may differ for right swing vs. left swing doors.

The base was placed approximately 0.5 meters away from the door. There was variation in the placement of the base relative to the door due to the inherent imprecision in navigating the robot in front of the doors. In addition, the base occasionally moved forward unintentionally due to the force of the robot's gripper on the door. The arm was moved to a predefined initial joint configuration at the start of the episode, one configuration for left swing doors and one configuration for right swing doors. Left swing doors are doors that have hinges on the left (when facing the door) and right swing doors are doors with hinges on the right. RGB images from the head camera were recorded for input to the model. The action space was 7-dimensional, comprised of the arm motion (7 DoF). 

At the end of each day, each demonstrator filled out a survey with the NASA task load index (a standardized set of questions asking about the perceived difficulty of a task \cite{hart2006nasa}) and qualitative feedback questions. The survey consisted of the following 6 questions and the response to each question was on a scale of 0-10, where 0 was very low and 10 was very high. The questions are:
\begin{itemize}
    \item Mental demand: How mentally demanding was the task?
    \item Physical demand: How physically demanding was the task?
    \item Hurried/rushed: How hurried or rushed was the pace of the task?
    \item Success rating: How successful were you in accomplishing what you were asked to do?
    \item Hard work required: How hard did you have to work to accomplish your level of performance?
    \item Insecure/discouraged: How insecure, discouraged, irritated, stressed, and annoyed were you?
\end{itemize}

The demonstrators also completed qualitative questions like ``Describe the strategy you used to open the door'' and ``Do you have any comments to share about the task?''.

\subsubsection{Data curation and model training}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{curationsuccessandtime_NEW.pdf}
    \caption{Nine demonstrators represented 100\% of the original data in the ``Full data'' bars. Three demonstrators were removed due to non-compliance in the ``Removed poor behavior'' bars. Failures were removed from remaining six demonstrators' data to create the ``Successes only'' subset. The remaining data was further curated by duration cutoff, and undesirable behavior removal resulting in the final ``Curated successes''. At left, a larger percentage of ``Curated successes'' remained in the Haptics condition, showing the improvement in data quantity. At right, demonstrators took less time to complete the task when receiving haptic feedback in all circumstances except when narrowing the data to ``Curated successes''.}
    \label{examples_collected}
\end{figure*}

Demonstrators varied in the amount of successful data they collected in a full day of work due to their experience level. In Figure \ref{workflow}, the first removal criteria was failure to follow instructions (``Removed poor behavior''). Under this criteria, three demonstrators repeatedly failed to follow instructions. These three demonstrators were excluded from all datasets for model training. The second removal criteria was eliminating failures (``Successes only''). Recall that the demonstrator marked the episode a failure if the robot stayed in contact with the door after opening it, the fingers snapped off of the wrist, or the robot entered an error state. After removing all the failures from the dataset, the initial models were trained only with success data from the six remaining demonstrators.

After this initial model training, more data curation was necessary due to the wide variance in demonstrator behavior and approaches to the task. Thus the third removal criteria (``Curated successes'') was based on the following: removing episodes longer than 20 seconds (approximately 50\% longer than the time to complete a successful episode), removing mislabeled episodes including those where the robot gripper ended in collision with the door, removing episodes where the demonstrator pulled up on the door handle rather than pushing down, and removing episodes where the demonstrator failed to follow the task instructions.
\vspace{-5mm}

\subsection{Phase 2: Robot performance evaluation}

In the second phase, we examined the effect of data quality on autonomous robot performance in the real world. Identical model architectures and evaluation methods were deployed with each dataset. 

\subsubsection{Model description and checkpoint selection}

The aim throughout model training was to learn a policy  $\pi(a\vert s)$ that outputs a continuous action $\textit{a} \in \textit{A}$ given an RBG image describing the state $\textit{s} \in \textit{S}$. A set of  demonstrations was described as $\tau^* = (s_0, a_0, s_1, a_1...s_{T-1}, a_{t-1}, s_T)$ and the learned policy was $\pi^*$. With the set of demonstrations, we minimized $\pi(a|s)-\pi^*(a|s)$ given the same state $s$. We followed the approach taken in \cite{khansari2022practical} and used a visual deep imitation learning model to train the policies. In this architecture, an RGB image was fed as input to a ResNet-18 model followed by a mean-pool and unit norm layers to create the visual embeddings. They were then fed to two action heads: the arm joint angles (7-DoF), and terminate action (1-DoF). The data preprocessing and augmentation includes random cropping of RGB images and photometric distortion.

Six models were trained with the curated data: haptic feedback and left swing doors only, haptic feedback and right swing doors only, haptic feedback and joint right/left swing doors, no haptic feedback and left swing doors only, no haptic feedback and right swing doors only, no haptic feedback and both right/left swing doors, see the Model Training and Evaluation section of Figure \ref{workflow}. As we will discuss in the next section, the Haptic dataset was larger than the No Haptic dataset. To better analyze the effect of data quality on the model performance, all the Haptic datasets were down-sampled to be at the same size as the corresponding No Haptics datasets. The models trained for 20,000 steps and 34 checkpoints were saved and evaluated in simulation. A checkpoint was comprised of the exported trained weights of the model at a given training step. Recall that we only trained models on the real world collected data. We used the real to sim head of a pretrained RetinaGAN model, as in \cite{ho2021retinagan}, to adapt real images to look like simulated images in order to enable evaluations in simulation. The starting $X, Y$ simulation position of the base and the yaw angle $\theta$ was randomized over a normal distribution that matches the real world robot initial pose configuration. An episode success during checkpoint evaluation was determined with the same criteria used during data collection: the robot should not be in contact with the door, and the door should be open more than $1$ degree.

\subsubsection{{Policy testing on real doors}}

The three highest-performing checkpoints in simulation were selected for policy testing in the real world. The selected checkpoints were tested on real robots at the same building where the original data was collected. Figure \ref{simscene} shows the robot in simulation and real world, opening a door autonomously in both cases. The same type of robot that was used in data collection was used for policy evaluation. The policies were tested for 20 episodes on each door at a two-inch distance. The number of seen (included in the training data) and unseen doors tested for each model are summarized in Figure \ref{workflow}. The placement of the robot base was randomized the same way in the real world as it was during simulation evaluation. There was no randomization in the arm starting position, matching our data collection protocol. For each tested autonomous episode, the episode was automatically marked a failure after one minute. Similar to data collection, the episode was also marked a failure if the robot stayed in contact with the door after opening it, if the fingers snapped off of the wrist, or if the robot entered an error state.
\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{simscenerealscene.pdf}
\caption{A checkpoint was comprised of the exported trained weights of the model at a training step. Checkpoints were first evaluated in simulation (left), and then the top three best checkpoints were used for real world model evaluation (right). Robot from Everyday Robots.}
\label{simscene}
\end{figure}

%===============================================================================


\section{Results}
\label{sec:result}

\subsection{Phase 1: Impact of haptic feedback on demonstrator performance}

The Haptics datasets began with more data, as shown in Figure \ref{examples_collected}, and a larger percentage of this data remained after curation. The Haptics condition resulted in a higher percentage of curated data as a proportion of total data collected for 9 demonstrators: 36\% of Haptics data remained after curation versus 30\% for the No Haptics dataset. For the final curated data as a proportion of the 6 demonstrators, 51\% of Haptics data remained after statistical curation, while 43\% of No Haptics data remained. Demonstrators with haptic feedback took less time to perform the task in all datasubsets except ``Curated successes'' where the durations were similar.

The overall results from Phase 1 indicate that demonstrators perform better and prefer the haptic feedback teleoperation setup. Demonstrators with haptic feedback had a 9.5\% higher success rate when performing the push door task than those without feedback, as shown in Figure \ref{successandtime}. Comparing Haptics and No Haptics conditions with the first and second day of the task, the individuals with haptic feedback performed the best across all four subsections. Individuals with haptic feedback take slightly less time than those without haptic feedback in order to successfully complete the task, shown at right in Figure \ref{successandtime}. This may have been because the demonstrator better knew when they are contacting the door and could more quickly remove the robot's gripper from contact once the door had unlatched.

Demonstrators completed the NASA TLX survey at the end of the day of data collection. They rated the data collection without haptics to be more mentally demanding, hurried, annoying/irritating, and requiring more work, and considered themselves less successful at the task. The only category in which the haptics was rated less favorably was that it required more physical demand. This is supported by the data: demonstrators were able to collect more data when receiving haptic feedback, see left side of Figure \ref{examples_collected}. For 9 demonstrators, this is statistically significant with a p-value of $<0.1$. Demonstrators 7-9 were eventually removed in the manual curation, leading to the same conclusion with a p-value of $<0.05$. Further analysis of these demonstrator reports are in the discussion. These data demonstrate that example collection with haptic feedback leads to more data throughput, as more data is collected and more curated data remains. Providing the haptic feedback to the demonstrator changes their behavior by providing a new sensory modality in addition to vision. This improves the quality of the data that they collect. 

\begin{figure*}
\centering
\includegraphics[width=\linewidth]{successandtime_NEW.pdf}
\caption{At left, demonstrators were overall 9.5\% more successful when receiving haptic feedback (``H'') than no haptic feedback (``N''). We performed a repeated measures analysis of variance (ANOVA) on this success rate with Haptics/No Haptics and it was statistically significant with a p $<0.001$. This improvement is greater than the 3\% task experience improvement from all day 1 data (``1'') to all day 2 data (``2'') which was also not statistically significant. Both day 1 and day 2 of haptic feedback (``H1'', ``H2'') showed higher success rates than day 1 and day 2 of no haptic feedback (``N1'', ``N2''). At right, haptic feedback allowed the demonstrator to complete the task in 4 seconds less time on the first day (``H1'') than without haptic feedback (``N1''). However, the difference in time needed to complete the task was greater from day 1 (``1'') to day 2 (``2'') than from No Haptics (``N'') to Haptics (``H'').}
\label{successandtime}
\end{figure*}

Demonstrators provided subjective evaluations of the task. Comments from demonstrators who preferred haptics included, ``Buzzing is really helpful when ever robots gripper touches the door handle and the doors'', ``I prefer the haptic feedback'', ``The haptic helps knowing how much pressure you are applying. Very hard task as the doors are hard to unlatch'', and ``The task was a little harder without the feedback, having it really gave me a sense of contact compared to my own sight with controllers.'' Other comments from demonstrators who did not prefer haptics included, ``I did not notice too big of a difference with haptic feedback vs non-haptic feedback in terms of success rate'' and ``I don't think the haptic feedback made much of a difference but it was nice to know when there was a lot of pressure on the arm.''
\vspace{-3mm}

\begin{figure*}
\centering
\includegraphics[width=\linewidth]{evalsuccessandduration_NEW.pdf}
\caption{Evaluations on real doors for six trained models alongside human demonstrator performance, this figure shows three conclusions. (1) The data were analyzed with ANOVA. The success rate between all Haptics and No Haptics policies together was found to be statistically significant with a p $<0.05$. As shown on the far left, the Haptics and No Haptics policies for right swing doors performed similarly. However, the Haptics policies for left swing doors and the combined left and right swing doors performed better than the No Haptics policies for these cases (shown in the center bars and the right bars for the left chart). Thus, overall, policies trained with Haptics data perform better than policies trained with No Haptics data. (2) The demonstrators reported left swing doors were much harder to open than right swing doors (verified with a repeated measures ANOVA test on success rate for left vs. right that was found to be statistically significant with p $<0.001$). This shows that haptic feedback not only leads to better demonstrator performance for more challenging tasks, but also leads to improved policy performance for more challenging tasks. (3) Regardless of training dataset, the policy performance was similar to the human demonstrator performance for right swing doors, but the human demonstrator performance far exceeded the learned policy for left swing doors. \textit{Note: * indicates that the demonstrator performance is averaged for right and left. The ``Right and Left'' policies differ from this demonstrator average; they are trained with a combination of left and right swing data.}}
\label{allevals}
\end{figure*}

\subsection{Phase 2: Impact of Haptics and No Haptics datasets on autonomous robot performance}

All six policies were deployed in the real world and tested at four doors relevant to that side: two unseen doors and two seen doors. For example, a policy trained on only right swing doors would be tested on two unseen right swing doors and two seen right swing doors. The unseen doors were included to test the generalization capabilities of the policy. The policies trained on both left and right swing door data were tested on eight doors -- four seen doors and four unseen doors.

For right swing doors only (at the left in Figure \ref{allevals}), policies trained both with and without haptic feedback performed well in the real world, at 79\% and 78\% success, respectively. The demonstrators noted that this task was easier than the left swing door task, thus we can infer that the haptic feedback did not have much of an effect. For models trained on the left swing doors the policy trained with the Haptic dataset performed 24\% better than the policy trained with the No Haptic dataset. For each door side and each policy condition, policies performed slightly better on the seen doors rather than the unseen doors. For the two policies trained on a combination of left and right swing doors in Figure \ref{allevals}, the policy trained with haptic feedback examples performed 10\% better than the policy without haptic feedback. This is consistent with the differences between the left swing and right swing door side-specific policies. We observe a higher average policy performance when combining the left and right data, meaning there is some transfer learning between the left and right. Comparing all training data conditions -- right only, left only, and right and left -- the policy trained with haptic feedback leads to an overall 11\% improvement in performance. Thus, haptic feedback leads to higher data quality and a better-performing autonomous robot policy. 
\vspace{-3mm}

%===============================================================================

\section{Discussion and Conclusion}
\label{sec:conclusion}

Our results indicate that haptic feedback can be useful for robot imitation learning. We show this utility at two points in the imitation learning process: (1) Data collection and (2) Policy performance. In (1), haptic feedback improved demonstrator performance during data collection by increasing the success rate, meaning fewer hours were needed overall to collect a given number of successes. In addition, haptic feedback improves the amount of high-quality data gathered during data collection, as there was more proportional data remaining from the haptic feedback dataset after the curation. Through NASA TLX qualitative ratings, the demonstrators in this study preferred haptic feedback when collecting data. Demonstrator performance and preference continues to be important while increasing the amount of tasks or needing more high quality data to train a viable policy. 

In (2), this improved data manifested in policy performance improvements. After applying the data curation as described in Section 3.1.2, the performance difference between the two conditions (Haptics and No Haptics) still remained. This suggests that both the haptic feedback and data curation contribute to better performance. When comparing autonomous model performance in the real world with the same amount of curated data, policies trained with haptic feedback examples performed far better on left swing door-specific policies and on policies jointly trained with left and right swing door data. The Haptics and No Haptics policies trained on right-only data are similar. One possible explanation for these results is because the left-sided door task was rated more complex by the demonstrators, they benefited more from the additional information channel of haptic feedback. Thus, we conclude that teleoperation system improvement can be meaningful in a robot learning setting where ample quantities of high quality data are necessary.

\vspace{-3mm}
\section*{Acknowledgments}
The authors thank Michelle Manning, Geetika Gupta, and Emre Fisher for their help.
 

 \vspace{-3mm}
\bibliography{references}


\bibliographystyle{IEEEtran}

\vfill

\end{document}


