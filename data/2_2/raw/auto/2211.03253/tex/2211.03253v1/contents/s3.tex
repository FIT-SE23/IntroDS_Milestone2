\section{Perception methodology} \label{sec: 3}
% This section presents data-based sensing methods for respective tactile and proximity sensing modalities. A simple tactile sensation was achieved, in which, a deep neural network (DNN) to estimate the local contact depths on the large sensing area was deployed. On the other hand, based on a monocular depth estimation technique, proximity sensing could bring in a depth map for every single inner camera, from which the distance between an external obstacle and sensing skin could be extrapolated. 
% Lastly, we propose a straightforward strategy to automatically switch between the two sensing modes. 
\begin{figure}[t]
\centering 
\subfloat[Tactile sensing scheme]{
\includegraphics[width=0.8\columnwidth]{contents/figs/Figure_tactile_perception.pdf}
\label{fig:tactile_sensing}
}\\

\subfloat[Proximity sensing scheme]{
\includegraphics[width=0.8\columnwidth]{contents/figs/Figure_proximity_perception.pdf}
\label{fig:proximity_sensing}
}
\caption{Explanation for sensing methodology}
\label{fig:perception_methods}
\end{figure}
Given the condition of the PDLC film (either opaque or transparent), the scheme for extracting tactile sensing and proximity sensing is shown in Fig. \ref{fig:perception_methods}. Details are as follows:
\subsection{Tactile sensing} \label{sec: tactile_sensing}
The use of model-free techniques (tactile DNN) for vision-based tactile sensing in inferring local contact depths and 3D skin shape was previously proved in \cite{Shotaro2021}. Specifically, the tactile images for each contact situation will be captured while the corresponding tactile information will be obtained from a simulation environment. In this paper, the tactile dataset was acquired by using a simulation tool based on Finite Element Method (FEM) called SOFA (Simulation Open Framework Architecture). The details of the simulation model can be referred in this work \cite{Quan2022}. Here, we assume to simulate the ProTac's skin as an isotropic, homogeneous elastomer. In more detail, the ProTac skin will be constituted by a matrix of non-overlapping tetrahedron elements (element size is $10\,$mm). Material properties follow a linear constitutive relationship (Hooke's laws) as ascribed by two parameters, Young's modulus $E = 0.22$\,\text{N/mm}$^2$ and Poisson's ratio $\nu = 0.49$. Note that $E$ was experimentally identified by a tensile test where the sample thickness is equal to the sum of soft skin and PDLC film. The simulation environment is pictured in Fig. \ref{fig:exp_setup}(a).

On the other side, an experimental setup with an identical reference coordinate system as shown in Fig. \ref{fig:exp_setup}(b) was prepared for collecting real tactile images. Then, the above dataset was used to solve a multi-output regression problem: given marker-featured tactile images $\mathbf{I}^{d}$ with the image resolution of $640\times480$ pixels; the network estimates the displacement vectors $\hat{\mathbf{D}}=[\hat{\mathbf{d}}_{i}^\top]\in\mathbb{R}^{N \times 3}$ of every free node (totally $N=621$ nodes) of the outer surface mesh representing the whole soft skin: 
\begin{equation} \label{eq:estimated_displacement_vectors}
    \hat{\mathbf{d}}_{i} \coloneqq \mathbf{x}_{i}-\mathbf{x}^{o}_{i}, \quad \forall i \in \mathbb{M},
\end{equation}
where a set $\mathbb{M}$ includes indices of free nodes; $\mathbf{x}_{i}\in\mathbb{R}^{3}$ is the 3-D position vector of one active/free node; and $\mathbf{x}^{o}_{i}\in\mathbb{R}^{3}$ is the coordinates of the respective node under the original or non-deformed state of the artificial skin. From this, the estimated local contact depth can be determined as 
\begin{equation} \label{eq:estimated_contact_depth}
    \hat{d}_{c} = \max_{i\in\mathbb{M}}||\hat{\mathbf{d}}_{i}||.
\end{equation}
% \subsubsection{Tactile DNN Architecture}

The tactile DNN architecture is adapted from proven Unet convolution networks \cite{Unet}. Basically, the model consists of a contracted convolution path connected with a reverse up-convolution one via skip connections, then followed by two fully connected (FC) layers. The opaque tactile images $\mathbf{I}^{d}$ are downsampled to $256\times 256$ to establish visual inputs. Moreover, the output signal, activated by the two last FC layers, is defined by a dense single layer with $1863$ neurons to represent the estimated displacement vectors $\hat{\mathbf{D}}$, which means that we consider every $3$ adjacent neurons as a displacement vector (see Fig. \ref{fig:tactile_sensing}). For the optimization of model weights, we use iterative Stochastic Gradient Descent (SGD) optimizer with the experimentally tuned learning rate $0.015$. Details of the training loss and other network specifications can be found in \cite{Quan2022}.



% \subsubsection{Tactile DNN Training and Loss Function}
% The model was trained with the input data $\mathbf{I}^{d}$ (images obtained from ProTac cameras) and corresponding output labels $\mathbf{D}_{\text{FEM}}$ (ground-truth displacement vectors directly obtained from simulation). To evaluate the differences between the ground-truth and estimated displacement vectors ($\mathbf{D}_{\text{FEM}}, \hat{\mathbf{D}}$), we rely on the MSE loss as an objective function:
% \begin{equation}
% \label{eqIV.D.2}
%     \begin{aligned}
%     \mathcal{L}_{\text{MSE}}=
%     \frac{1}{3n}\sum_{i\in\mathbb{M}}&\sum_{j\in\{x, y, z\}}(d^{j}_{\text{FEM}, i}-\hat{d}^{j}_{i})^2
%     \end{aligned}
% \end{equation}
% where $d^{j}_{i}\,\,,\,\, \forall j \in \{x, y, z\}$ are the components of displacement vector $\mathbf{D}_{i}$ at the respective skin node along the $x$, $y$ and $z$ axes. For the optimization of model weight based on $\mathcal{L}_{\text{MSE}}$, we use iterative Stochastic Gradient Descent (SGD) optimizer with the experimentally tuned learning rate $0.015$.

\subsection{Proximity sensing} \label{sec:proximity_sensing_method}
The workflow of this method is summarized in Fig. \ref{fig:proximity_sensing} with details as below.
\subsubsection{Monocular Depth Estimation} \label{sec:depth_estimation_method}
We employed data-driven \emph{monocular} depth estimation based on a DNN to predict depth maps of external space for \emph{transparent} camera view of the ProTac link, which would form the basis for the distance measurement. In detail, we adopted the proven MiDas model \cite{midas_model} for the projection between ProTac images and estimated depth maps. The model was designed upon the ResNet multi-scale architecture \cite{He2016ResNet}, in which the input layer takes in a 3-channel ProTac image $\mathbf{I}^{t}$ (in a transparent state) and outputs an estimated depth map $\Gamma$; both have the same image resolution of $640\times480$. The model was trained on diverse existing datasets (\emph{e.g.}, ReDWeb \cite{ReDWeb}, MegaDepth \cite{Li2018_MegaDepth}, and WSVD \cite{wang2019web}) using a scale-invariant depth regression loss as mentioned in \cite{midas_model}. For the training process, the Adam optimizer was adopted with the learning rate initialized at $10^{-5}$ for the encoder path pre-trained on Imagenet \cite{ImageNet} and $10^{-4}$ for other layers, and then linearly decaying at the 50$^{\text{th}}$ iteration out of a total of 100 training steps. In order to increase the generalization, the input images with aspect ratio maintained were randomly flipped, cropped, and then resized to $384\times384$, with $50\%$ chance. Details of network architecture can be found in \cite{He2016ResNet}.

\subsubsection{Distance Detection} \label{sec:distance_detection}
Whilst depth estimation could directly provide plenty of high-level information in perception systems, this preliminary work focuses on the closest normal distance between nearby obstacles and the ProTac link based on the estimated depth map $\Gamma$. 

Toward this goal, the image mask of a target nearby obstacle ($\Xi$) is first extracted from $\Gamma$ using Otsu's automatic binary thresholding (OpenCV module), by which we assume the proximal objects of interest would have distinguishable, bright pixel intensity. The subsequent problem is to compute the normal distances from the masked obstacles to the skin surface. Given the camera was modeled as a classic pinhole, the 3D positions of the masked obstacles $\mathbf{O}=[\mathbf{o}_{k}^\top]\in\mathbb{R}^{K \times 3}$ ($K$ is the number of masked pixels) could be calculated as:
\begin{equation}
\begin{split}
    o^{x}_{k} & = \frac{(u_{k} - c_{x})(b+o^{z}_{k})}{f_{x}},\,o^{y}_{k} = \frac{(v_{k} - c_{y})(b+o^{z}_{k})}{f_{y}}, \\
    o^{z}_{k} & =\Gamma_{k}, \quad \forall k \in \mathbb{K},
\end{split}
\end{equation}
where $\mathbb{K}=\{i\,|\, \Gamma_{i}\wedge\Xi_{i} = 1\}$ is indices of masked obstacles; $\mathbf{o}_{k} = [o^{x}_{k},\,\,o^{y}_{k},\,\,o^{z}_{k}]^\top$ is the 3D position of an obstacle point; $b$ denotes the position of PCS (ProTac coordinate system) origin in the camera frame; $(u_{k}, v_{k})$ is the geometrical projection of $\mathbf{o}_{k}$ on the image plane; $f_{x}$ and $f_{y}$ are the focal lengths along $x$- and $y$-axes, respectively; $(c_{x}, c_{y})$ is the pixel location of the image principal point on the pixel coordinate $\{u, v\}$. The identification of model parameters $\{f_{x}, c_{x}, c_{y}, b\}$ and fisheye-lens correction were conducted following the method proposed in \cite{Lac21}. For ease of calculating the normal distance to the skin surface based on the location of the obstacles $\mathbf{O}$, the Cartesian coordinates of obstacle points are converted to a radial coordinate as $r_{k} = \sqrt{o^{x2}_{k} + o^{y2}_{k}}$. Thus, the normal distance between the obstacle points and the skin surface can be estimated as
\begin{equation}\label{eq:estimated_proximity_distance}
    n_{k} = r_{k} - r^{s}, \quad \forall k \in \mathbb{K},
\end{equation}
where $r^{s}$ is the radial of the sensor skin. From this, we could finally perform a quick search for the closet distance:
\begin{equation} \label{eq:estimated_closest_distance}
    \hat{n} = \min_{k\in\mathbb{K}}n_{k}.
\end{equation}

This proposed procedure for distance detection is derived for a \emph{single} camera view, while a combination of the two opposite cameras just as the current ProTac setup could provide a larger sensing range from any direction, which mitigates possible occlusions. 
