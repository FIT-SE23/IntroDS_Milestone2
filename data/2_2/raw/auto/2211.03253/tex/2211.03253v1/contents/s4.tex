\section{Performance evaluation} \label{sec: 4}
\subsection{Experimental setup} \label{sec: exp_setup}
\begin{figure}[t]
      \centering
      \includegraphics[width=0.6\columnwidth]{contents/figs/Fig_exp_setup.pdf}
      \caption{Illustrations of (a) simulation environment (SOFA) and (b) actual experiment scheme for training data collection. Figure (c) pictures the experiment setup for distance estimation in proximity mode.}
      \label{fig:exp_setup}
\end{figure}
\begin{figure*}[t]
\centering 
\subfloat[Measured contact depth versus true value.]{
\includegraphics[width=0.6\columnwidth]{contents/figs/Fig_contact_depth_accuracy.pdf}
\label{fig:contact_depth}
}
\hfill
\subfloat[Absolute measurement error with increased contact depth.]{
\includegraphics[width=0.6\columnwidth]{contents/figs/Fig_contact_depth_error.pdf}
\label{fig:abs_error}
}
\hfill
\subfloat[Estimated contact depths (ground-truth values = $2.5,\,4,\,5$\,mm) with various input images.]{
\includegraphics[width=0.6\columnwidth]{contents/figs/Fig_contact_depth_input_comparision.pdf}
\label{fig:input_comparision}
}\\
\caption{Evaluation of contact depth accuracy estimated based on different input signals.}
\label{fig:reconstruction_accuracy}
\end{figure*}

\subsubsection{Tactile mode} 

The testbed shown in Fig. \ref{fig:exp_setup}b was used to collect the tactile images for training the DNN model, as well as to evaluate the performance of the tactile mode. It is comprised of two linear stages, a rotating stage (Suruga Seiki Co., Japan) and a stepping motor controller (DS102, Suruga Seiki Co., Ltd., Japan). The $X$-axis stage drives a spherical-head indentor ($12\,$mm diameter) to make contact with the desired depth (maximum depth is $5\,$mm) at the exact positions of free nodes. The contact locations were secured by the horizontal movement of the indentor ($Z$-axis linear carrier) and the rotation of the ProTac sensor (rotation stage). It should be noted that the nominal axis of the indentor was pre-adjusted in advance to intersect with the $Z$-axis.

\subsubsection{Proximity mode} 
The ability to estimate ProTac-obstacle distance ($\hat{n}$) was studied with the experiment arrangement shown in Fig. \ref{fig:exp_setup}c. Specifically, an artificial human arm was vertically fixed onto a linear translation guide mechanism so that the hand directly faces a ProTac link. Then, the following procedure was conducted: 1) Put the arm slightly in touch with the skin and set this position as the origin (ground-truth distance $n = 0\,$mm), 2) Move the arm far away from the skin with the distance up to $100\,$mm in moving step of $10\,$mm. For each step, 150 samples of estimated distance Eq. \eqref{eq:estimated_closest_distance} using the algorithm in Section \ref{sec:proximity_sensing_method} were recorded to judge the sensing performance. The results of proximity sensing are presented in Section \ref{sec: result_proximity}.

\subsection{Tactile sensing mode} \label{sec: result_tactile}
For tactile sensing, we verify the accuracy of contact depth $\hat{d}_c$ estimated by the trained DNN with different types of input images. For evaluation, Unet-based DNN with $2048$ neurons for each of the last two FC layers was employed, since through our experimental trials it showed to outperform other model backbones. The model was trained with $80\%$ of total $11025$ samples, in which $20\%$ of the dataset was withheld for validation.  

The experimental results showed that measurement errors increased with true contact depth ($d_{c}$) in both cases of non-normalized (pure) and normalized visual inputs that have two tactile images concatenated (see Figs. \ref{fig:reconstruction_accuracy}a-b). However, normalized inputs yielded higher estimation accuracy as larger contact intensities, compared with the pure ones. In fact, the averaged absolute errors at $d_{c}=5\ $mm were more or less $0.7\ $mm and $0.6\ $mm, which approximate full-scale errors $14\%$ and $12\%$ (with FS $5\,$mm) for pure and normalized inputs, respectively. We also evaluated the sensing performance based on either the single-view visual input or concatenated two opposite camera views, each with and without normalization at different contact depths ($d_{c}=2.5,\,4,\,5\,$mm). The result showed that the inputs with normalization yielded better performance in both cases of single- and double-view input (see Fig. \ref{fig:input_comparision}). In addition, by concatenating two normalized tactile images, the measurement accuracy was improved by around $1.45\%$ and $1.09\%$ in terms of full-scale error at $d_{c}=4$ and $5\,$mm, respectively, as compared to the single-view images.

Lastly, we showcase the visualization of the skin shape reconstruction in the critical scenario that contact happens near the middle of the link; where the visual clue is farthest from both cameras (see Fig. \ref{fig:tactile_visulization}). In this case, with the contact depth $d_{c}=5\,$mm, the concatenated inputs caused an estimation accuracy of $1.22\,$mm and $24.4\%$ with respect to the absolute and full-scale errors, respectively. 

\begin{figure}[ht]
\centering 
\includegraphics[width=0.75\columnwidth]{contents/figs/Fig_result_tactile_visulization.pdf}
\caption{The visualization of DNN-based 3D reconstruction and its estimated contact depth compared to ground-truth $d_{c}=5\,$mm. The model takes the two concatenated tactile images (in the dark mode) as tactile input.}
\label{fig:tactile_visulization}
\end{figure}

\textit{Discussion}: The obtained results demonstrate the normalization of tactile inputs is necessary for improved sensing performance. Moreover, since the inference accuracy based on the single-view input is rather comparable with the concatenated one, we would argue that this sensing method is still applicable for small-sized tactile sensors with a single camera while combining camera views could yield better performance for such a large-scale device like the one showcased in this paper. It is also worth noting that although it is reasonable to recognize multi-point contact depth/location from the nodal displacement vector $\hat{\mathbf{D}}$, we will elaborate it in our future work.  

\subsection{Proximity sensing mode} \label{sec: result_proximity}
This section summarizes initial findings of the proximity-sensing abilities as the ProTac skin is in the transparent state. Figure \ref{fig:prox_vis_results} highlights the recognition of plenty of different obstacles (\emph{e.g.,} wallet, tape, hand, and human) from the corresponding transparent views (see Fig. \ref{fig:rgb_view}), which is expressed via the obstacle masks $\Xi$ (Fig. \ref{fig:obstacle_mask}).

The accuracy of the calibrated closest distance estimated by the ProTac link is reported in Figure \ref{fig:distance_accuracy}, in which the estimation accuracy reached approximately $10.35\,$mm in terms of RMSE (root mean squared error) metric averaged over a reliable range $n\in[20,\,100]\,$mm. Despite the fact the upper sensing range could be further than $100\,$mm, the distance out of the reliable range caused a lot of uncertainties because the DNN model for depth estimation did not yet fine-tune for specific ProTac images. Lastly, Figure \ref{fig:measurment_samples} shows the log of measurement samples at the baseline distance $n=80\,$mm, which yielded the measured distance mean $\hat{n}=82.87\,$mm.
\begin{figure}[ht]
\centering 
\subfloat[RGB camera view]{
\includegraphics[width=0.9\columnwidth]{contents/figs/Fig_object_rgb.pdf}
\label{fig:rgb_view}
}\\

\subfloat[Nearby object mask]{
\includegraphics[width=0.9\columnwidth]{contents/figs/Fig_object_mask.pdf}
\label{fig:obstacle_mask}
}
\caption{Examples of object mask extraction from transparent camera views.}
\label{fig:prox_vis_results}
\end{figure}

\begin{figure}[ht]
\centering 
\subfloat[ProTac-obstacle distance measurement accuracy]{
\includegraphics[width=0.92\columnwidth]{contents/figs/Fig_distance_accuracy.pdf}
\label{fig:distance_accuracy}
}\\

\subfloat[Distance measurements at $n=80\,mm$]{
\includegraphics[width=0.9\columnwidth]{contents/figs/Fig_distance_measurment_sample.pdf}
\label{fig:measurment_samples}
}
\caption{The evaluation of ProTac-based distance sensing. The experimental setup can be found in Section \ref{sec: exp_setup}.}
\label{fig:prox_distance_measurment}
\end{figure}

\textit{Discussion}: These preliminary results with the provided proximity sensing method promise a wider sensing range beyond $100\,$mm once fine-tuning the depth-map model is conducted. Also, the proposed method leaves room for the combination of two camera views in order to enlarge the sensing area, as well as for determining the approaching direction of nearby obstacles, which will be thoroughly examined in our future work. 

% \subsection{Mode switching evaluation}