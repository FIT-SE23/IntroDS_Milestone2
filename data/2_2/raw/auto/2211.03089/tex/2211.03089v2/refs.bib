
@misc{schuhmann2022laion,
  title={LAION-5B: laion-5b: A new era of open large-scale multi-modal datasets},
  author={Schuhmann, Christoph and others},
  year={2022}
}

@article{dalle2,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and others},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@article{dhariwal2020jukebox,
  title={Jukebox: A generative model for music},
  author={Dhariwal, Prafulla and others},
  journal={arXiv preprint arXiv:2005.00341},
  year={2020}
}

@INPROCEEDINGS{Vggsound,
  author={Chen, Honglie and others},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Vggsound: A Large-Scale Audio-Visual Dataset}, 
  year={2020}}
  
@article{okamoto2022should,
  title={How Should We Evaluate Synthesized Environmental Sounds},
  author={Okamoto, Yuki and Imoto, Keisuke and Takamichi, Shinnosuke and Fukumori, Takahiro and Yamashita, Yoichi},
  journal={arXiv preprint arXiv:2208.07679},
  year={2022}
}

@article{passt,
  title={Efficient training of audio transformers with patchout},
  author={Koutini, Khaled and Schl{\"u}ter, Jan and Eghbal-zadeh, Hamid and Widmer, Gerhard},
  journal={arXiv preprint arXiv:2110.05069},
  year={2021}
}
@inproceedings{vqvae,
 author = {van den Oord, Aaron and Vinyals, Oriol and kavukcuoglu, koray},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Neural Discrete Representation Learning},
 url = {https://proceedings.neurips.cc/paper/2017/file/7a98af17e63a0ac09ce2e96d03992fbc-Paper.pdf},
 volume = {30},
 year = {2017}
}
article{saharia2022photorealistic,
  title={Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  author={Saharia, Chitwan and others},
  journal={arXiv preprint arXiv:2205.11487},
  year={2022}
}
@article{galatolo2021generating,
  title={Generating images from caption and vice versa via CLIP-Guided Generative Latent Space Search},
  author={Galatolo, Federico A and Cimino, Mario GCA and Vaglini, Gigliola},
  journal={arXiv preprint arXiv:2102.01645},
  year={2021}
}
@article{yang2022diffsound,
  title={Diffsound: Discrete diffusion model for text-to-sound generation},
  author={Yang, Dongchao and others},
  journal={arXiv preprint arXiv:2207.09983},
  year={2022}
}
@article{hayes2021neural,
  title={Neural waveshaping synthesis},
  author={Hayes, Ben and Saitis, Charalampos and Fazekas, Gy{\"o}rgy},
  journal={arXiv preprint arXiv:2107.05050},
  year={2021}
}
@article{hawthorne2022multi,
  title={Multi-instrument Music Synthesis with Spectrogram Diffusion},
  author={Hawthorne, Curtis and Simon, Ian and Roberts, Adam and Zeghidour, Neil and Gardner, Josh and Manilow, Ethan and Engel, Jesse},
  journal={arXiv preprint arXiv:2206.05408},
  year={2022}
}
@article{mokady2021clipcap,
  title={Clipcap: Clip prefix for image captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}
@article{lin2021soundify,
  title={Soundify: Matching Sound Effects to Video},
  author={Lin, David Chuan-En and Germanidis, Anastasis and Valenzuela, Crist{\'o}bal and Shi, Yining and Martelaro, Nikolas},
  journal={arXiv preprint arXiv:2112.09726},
  year={2021}
}
@article{fid,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and others},
  journal={Advances in neural information processing systems},
  year={2017}
}

@inproceedings{fad,
  title={Fr{\'e}chet Audio Distance: A Reference-Free Metric for Evaluating Music Enhancement Algorithms.},
  author={Kilgour, Kevin and Zuluaga, Mauricio and Roblek, Dominik and Sharifi, Matthew},
  booktitle={INTERSPEECH},
  pages={2350--2354},
  year={2019}
}
@inproceedings{wu2022wav2clip,
  title={Wav2clip: Learning robust audio representations from clip},
  author={Wu, Ho-Hsiang and others},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2022},
}
@inproceedings{CLIPradford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and others},
  booktitle={International Conference on Machine Learning},
  year={2021}
}

@article{chen2020regnet,
  title={Generating visually aligned sound from videos},
  author={Chen, Peihao and others},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={8292--8302},
  year={2020},
  publisher={IEEE}
}

@article{hessel2021clipscore,
  title={Clipscore: A reference-free evaluation metric for image captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2104.08718},
  year={2021}
}
@article{nichol2021glide,
  title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and others},
  journal={arXiv preprint arXiv:2112.10741},
  year={2021}
}

@inproceedings{ LoopTestallenloopgen, 
	title={A Benchmarking Initiative for Audio-domain Music Generation using the {FreeSound Loop Dataset}},
	author={Tun-Min Hung and Bo-Yu Chen and Yen-Tung Yeh, and Yi-Hsuan Yang},
	booktitle = {Proc. Int. Society for Music Information Retrieval Conf.},
	year={2021},
}

@InProceedings{SpecVQGAN_Iashin_2021,  title={Taming Visually Guided Sound Generation},  author={Iashin, Vladimir and Rahtu, Esa},  booktitle={British Machine Vision Conference (BMVC)},  year={2021}}

@article{gowda2021macro,
  title={Macro-average: rare types are important too},
  author={Gowda, Thamme and You, Weiqiu and Lignos, Constantine and May, Jonathan},
  journal={arXiv preprint arXiv:2104.05700},
  year={2021}
}

@article{bilingualism,
author = {Cenoz, Jasone},
year = {2013},
month = {01},
pages = {1 - 16},
title = {The influence of bilingualism on third language acquisition: Focus on multilingualism},
volume = {46},
journal = {Language Teaching},
doi = {10.1017/S0261444811000218}
}

@inproceedings{welleck-etal-2020-consistency,
    title = "Consistency of a Recurrent Language Model With Respect to Incomplete Decoding",
    author = "Welleck, Sean  and
      Kulikov, Ilia  and
      Kim, Jaedeok  and
      Pang, Richard Yuanzhe  and
      Cho, Kyunghyun",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.448",
    doi = "10.18653/v1/2020.emnlp-main.448",
    pages = "5553--5568",
    abstract = "Despite strong performance on a variety of tasks, neural sequence models trained with maximum likelihood have been shown to exhibit issues such as length bias and degenerate repetition. We study the related issue of receiving infinite-length sequences from a recurrent language model when using common decoding algorithms. To analyze this issue, we first define inconsistency of a decoding algorithm, meaning that the algorithm can yield an infinite-length sequence that has zero probability under the model. We prove that commonly used incomplete decoding algorithms {--} greedy search, beam search, top-k sampling, and nucleus sampling {--} are inconsistent, despite the fact that recurrent language models are trained to produce sequences of finite length. Based on these insights, we propose two remedies which address inconsistency: consistent variants of top-k and nucleus sampling, and a self-terminating recurrent language model. Empirical results show that inconsistency occurs in practice, and that the proposed methods prevent inconsistency.",
}

@inproceedings{fan-etal-2018-hierarchical,
    title = "Hierarchical Neural Story Generation",
    author = "Fan, Angela  and
      Lewis, Mike  and
      Dauphin, Yann",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1082",
    doi = "10.18653/v1/P18-1082",
    pages = "889--898",
    abstract = "We explore story generation: creative systems that can build coherent and fluent passages of text about a topic. We collect a large dataset of 300K human-written stories paired with writing prompts from an online forum. Our dataset enables hierarchical story generation, where the model first generates a premise, and then transforms it into a passage of text. We gain further improvements with a novel form of model fusion that improves the relevance of the story to the prompt, and adding a new gated multi-scale self-attention mechanism to model long-range context. Experiments show large improvements over strong baselines on both automated and human evaluations. Human judges prefer stories generated by our approach to those from a strong non-hierarchical model by a factor of two to one.",
}

@inproceedings{transformer-gan,
    title={Symbolic Music Generation with Transformer-GANs},
    author={Aashiq Muhamed and Liang Li and Xingjian Shi and Suri Yaddanapudi and Wayne Chi and Dylan Jackson and Rahul Suresh and Zachary C. Lipton and Alexander J. Smola},
    booktitle={35th AAAI Conference on Artificial Intelligence, {AAAI} 2021},
    year={2021},
}

@inproceedings{vggish,
  title={CNN architectures for large-scale audio classification},
  author={Hershey, Shawn and others},
  booktitle={2017 ieee international conference on acoustics, speech and signal processing (icassp)},
  pages={131--135},
  year={2017},
  organization={IEEE}
}

@inproceedings{VQ-VAE-2,
 author = {Razavi, Ali and van den Oord, Aaron and Vinyals, Oriol},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Generating Diverse High-Fidelity Images with VQ-VAE-2},
 volume = {32},
 year = {2019}
}

@article{sparse,
  title={Generating Long Sequences with Sparse Transformers},
  author={Rewon Child and Scott Gray and Alec Radford and Ilya Sutskever},
  journal={ArXiv},
  year={2019},
  volume={abs/1904.10509}
}

@inproceedings{allyouneed,
 author = {Vaswani, Ashish and others},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Attention is All you Need},
 year = {2017}
}


@article{sokolova2009systematic,
  title={A systematic analysis of performance measures for classification tasks},
  author={Sokolova, Marina and Lapalme, Guy},
  journal={Information processing \& management},
  volume={45},
  number={4},
  pages={427--437},
  year={2009},
  publisher={Elsevier}
}

@inproceedings{yamamoto2020parallel,
  title={Parallel WaveGAN: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram},
  author={Yamamoto, Ryuichi and Song, Eunwoo and Kim, Jae-Min},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6199--6203},
  year={2020},
  organization={IEEE}
}

@inproceedings{chen2018visually,
  title={Visually indicated sound generation by perceptually optimized classification},
  author={Chen, Kan and others},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV) Workshops},
  year={2018}
}
@article{mehri2016samplernn,
  title={SampleRNN: An unconditional end-to-end neural audio generation model},
  author={Mehri, Soroush and Kumar, Kundan and Gulrajani, Ishaan and Kumar, Rithesh and Jain, Shubham and Sotelo, Jose and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1612.07837},
  year={2016}
}
@inproceedings{zhou2018visual,
  title={Visual to sound: Generating natural sound for videos in the wild},
  author={Zhou, Yipin and others},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  year={2018}
}

@article{borsos2022audiolm,
  title={Audiolm: a language modeling approach to audio generation},
  author={Borsos, Zal{\'a}n and others},
  journal={arXiv preprint arXiv:2209.03143},
  year={2022}
}

@article{kreuk2022audiogen,
  title={AudioGen: Textually Guided Audio Generation},
  author={Kreuk, Felix and others},
  journal={arXiv preprint arXiv:2209.15352},
  year={2022}
}
@inproceedings{ho2021classifier,
  title={Classifier-Free Diffusion Guidance},
  author={Ho, Jonathan and Salimans, Tim},
  booktitle={NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications},
  year={2021}
}

@article{oord2016wavenet,
  title={Wavenet: A generative model for raw audio},
  author={Oord, Aaron van den and others},
  journal={arXiv preprint arXiv:1609.03499},
  year={2016}
}

@inproceedings{gemmeke2017audio,
  title={Audio set: An ontology and human-labeled dataset for audio events},
  author={Gemmeke, Jort F and others},
  booktitle={2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={776--780},
  year={2017},
  organization={IEEE}
}
@article{gafni2022make,
  title={Make-a-scene: Scene-based text-to-image generation with human priors},
  author={Gafni, Oran and others},
  journal={arXiv preprint arXiv:2203.13131},
  year={2022}
}
@inproceedings{karras2019style,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4401--4410},
  year={2019}
}

@article{kumar2019melgan,
  title={Melgan: Generative adversarial networks for conditional waveform synthesis},
  author={Kumar, Kundan and others},
  journal={Advances in neural information processing systems},
  year={2019}
}