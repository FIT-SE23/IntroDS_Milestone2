\subsection{Preliminaries}

  \begin{enumerate}
    \item In Section \ref{sec:termination} we prove that Algorithm \ref{alg:ptree} uses a \emph{finite number of constraint-solving rules} to compute each branch of the partition tree.
    This proves the all considered security relations (trace equivalence and inclusion, simulation, (bi)similarity) to be decidable.
    \item For complexity purposes we then refine this result in Section \ref{sec:exp-mgs}:
    we prove that Algorithm~\ref{alg:ptree} applies at most an \emph{exponential number of rules} and that the nodes of the resulting partition tree have \emph{most general solutions of exponential (DAG) size}.
    \item Relying on these bounds, we show that two processes are not equivalent \textit{iff} there exists a \emph{non-equivalence witness of exponential size} (as defined in Section~\ref{sec:ptree-eq}).
    This shows the security relations to be decidable in co\nexp time.
    \item Finally we show in Section~\ref{sec:deepsec-hardness} that the security relations are \emph{co\nexp hard}.
    We also provide a complexity analysis in the pure pi-calculus.
    All in all:
  \end{enumerate}

  \begin{theorem}[restate=thmDeepsecConexp,name={complexity of equivalences}] \label{thm:deepsec-conexp}
    For bounded processes, the problems \TraceEquiv, \TraceInclus, \Simulation, \Similarity, and \Bisimilarity are co\nexp complete for constructor-destructor subterm convergent theories.
    Besides, in the pure pi calculus, \TraceEquiv and \TraceInclus are \polyh{2} complete, and \Simulation, \Similarity and \Bisimilarity are \pspace complete.
  \end{theorem}

  \paragraph{Notations}
  We also introduce some notations that will be used in most incoming sections.
  We recall that we study complexity w.r.t. the DAG size of terms (which provides stronger results compared to complexity bounds w.r.t. the tree size of terms);
  in particular the DAG size of a substitution \(\sigma\) is \(\dagsize{\sigma} = |\subterms(\im(\sigma))|\), hence the many occurrences of subterm sets below.
  Given an extended constraint system \(\C^e = (\Phi,\Df,\Eqfst,\Eqsnd,\Solved,\USolved)\) we write
  \begin{align*}
    \tag{first-order mgu}
    \mu^1 & = \mgu(\Eqfst) \\
    \tag{second-order mgu}
    \mu^2 & = \mgu(\Eqsnd) \\
    \tag{first-order terms}
    \terms[1] & = \subterms[1](\im(\Phi\mu^1),\im(\mu^1),\Solved \mu^1, \Df\mu^1) \\
    \tag{second-order terms}
    \terms[2] & = \subterms[2](\im(\mu^2),\Solved, \Df) \\
    \tag{solution recipes}
    \recipes & = \stc(\im(\mu^2),\ \Solved \cup \Df) \cup \vars[2](\Df)
  \end{align*}
  When the extended constraint system is not clear from context we write explicitly \(\mu^1(\C^e)\), \(\mu^2(\C^e)\), \(\terms[1](\C^e)\),...
  Intuitively \(\mu^i\) are the mgu's of the equations of \(\Eq[i]\) and we recall in particular that \(\mgs(\C^e) = \{\mu^2\}\) when \(\C^e\) is solved (Section~\ref{sec:mgs-proc}, Proposition~\ref{prop:correct-mgs-solved}).
  The other notations assume \(\mu^1 \neq \bot\) (if \(\mu^1 = \bot\), \(\C^e\) will be discarded by the normalisation rule \eqref{rule:mgs-unsat} anyway).
  The sets \(\terms[1]\) and \(\terms[2]\) respectively represent the first-order and second-order terms appearing in the system, while \(\recipes \subseteq \terms[2]\) models the set of recipes used to build the solution of \(\C^e\) (i.e., \(\mu^2\)) from \(\Solved \cup \Df\).
  We recall that it is the same set as the one used when defining the constraint-solving rules for most general solutions (Section~\ref{sec:mgs-rules}).

  \begin{remark}[uniformity of second-order terms across components]
    Due to an invariant of the procedure (\(\PredStruct\) formalised in Appendix \ref{app:ptree}, Section \ref{app:invariants}), we know that all extended constraint systems in a component \(\Gamma\) have the same second-order structure.
    Here this means that \(\mu^2(\C^e_1) = \mu^2(\C^e_2)\) and \(\terms[2](\C^e_1) = \terms[2](\C^e_2)\) for any \((\P_1,\C_1,\C^e_1),(\P_2,\C_2,\C^e_2) \in \Gamma\).
    For this reason we may write \(\mu^2(\Gamma)\) or \(\terms[2](\Gamma)\) instead of \(\mu^2(\C^e)\) or \(\terms[2](\C^e)\) for some arbitrary \((\P,\C,\C^e) \in \Gamma\).
  \end{remark}

\subsection{Termination of the constraint solving}
\label{sec:termination}

\subsubsection{Termination of the computation of most general solutions} \label{sec:termination-mgs}

We first study the termination of the procedure for computing most general solutions provided in Section~\ref{sec:mgs-gen}.
The proof mostly relies on the following measure that characterises the set of first-order terms of an extended constraint system \(\C^e\) that are not used in \(\mgs(\C^e)\), that is, that are not deduced by any recipe \(\xi \in \recipes(\C^e)\):
\[\measureNC(\C^e) =
  \{ t \in \terms[1] \mid t \not\in \X[1] \wedge \forall \xi \in \recipes(\C^e) \smallsetminus \X[2],\, (\xi,t) \notin \conseq(\Solved\mu^1 \cup \Df\mu^1)\}
\]
The simplification rules for mgs' do not affect this value (except maybe if \(\C^e\) is replaced by \(\bot\) by \eqref{rule:mgs-unsat}).
% We recall that the mgs constraint-solving rule \eqref{rule:conseq} is applied in priority over \eqref{rule:res} and \eqref{rule:cons};
The application of \eqref{rule:conseq} will ensure that \(\measureNC\) is at least non-increasing, while \eqref{rule:res} and \eqref{rule:cons} make it strictly decreasing.
We summarise this as the following proposition, proved in Appendix~\ref{app:termination};
we recall that, similarly to the correctness arguments in Section~\ref{sec:ptree}, the statements makes reference to some procedure invariants formalised in Appendix~\ref{app:invariants}:

\begin{proposition}[restate=propMgsDecrease,name={decrease of unused first-order terms during constraint solving}] \label{prop:mgs-decrease}
  Let \(\C^e\) be an extended constraint system such that \(\C^e \simplnorm = \C^e\) and the invariants \(\PredWellFormed(\C^e)\) and \(\PredCorrectFormula(\C^e)\) hold.
  Then let \(\C^e \simpStep{\Sigma} \C^{e\prime} \neq \bot\).
  If this transition is derived with:
  \begin{enumerate}%[label=(\textit{\roman*})]
    \item Rule \eqref{rule:conseq}: \(|\measureNC(\C^{e\prime})| \leqslant |\measureNC(\C^e)|\)
    \item Rules \eqref{rule:res} or \eqref{rule:cons}: \(|\measureNC(\C^{e\prime})| < |\measureNC(\C^e)|\)
  \end{enumerate}
\end{proposition}

Using this proposition we can then easily prove the computation of the set of most general solutions to be terminating, and actually to give an upper bound on its cardinality:

\begin{theorem}[restate=propMgsSize,name={termination for most general solutions}]
  There exist no infinite sequences of transitions w.r.t. \(\simpStep{}\).
  Besides if \(\C^e\) is an extended constraint system such that the invariants \(\PredWellFormed(\C^e)\) and \(\PredCorrectFormula(\C^e)\) hold, we have
  \[|\mgs(\C^e)| \leqslant (|\Solved(\C^e)| + 1)^{|\measureNC(\C^e)|}\]
\end{theorem}

\begin{proof}
  First of all we observe that consecutive applications of Rule \eqref{rule:conseq} are terminating, since applying this rule strictly decrease the cardinality of the set \(m(\C^e)\) of parameters \((\xi,\zeta)\) the rule can be applied with.
  Combining this with Proposition \ref{prop:mgs-decrease} we obtain that if \(\C^e \simpStep{\Sigma} \C^{e\prime} \neq \bot\) then \(\C^e < \C^{e\prime}\) w.r.t. the lexicographic composition of \(\measureNC\) and \(m\).

  Besides consecutive applications of Rule \eqref{rule:conseq} are also confluent by unicity of mgu's.
  For the same reason the applications of Rules \eqref{rule:res} or \eqref{rule:cons} can be performed on one deterministically-chosen deduction fact \((X \dedfact u) \in \Df\).
  We therefore obtain \(\mgs(\C^e) = \{\Sigma_{|\vars[2](\C^e)} \mid \C^e \SimpStep{\Sigma} \C^{e\prime} \text{ normalised}, \C^{e\prime} \text{ solved}\}\)
  where a reduction \(\C^e \SimpStep{\Sigma} \C^{e\prime}\) is said to be \emph{normalised} when all applications of Rule \eqref{rule:conseq} and the choice of deduction facts in Rules \eqref{rule:res} or \eqref{rule:cons} are done in a fixed, deterministic way.
  Since for any \(\C^e\), there are at most \(|\Solved(\C^e)|\) normalised applications of Rule \eqref{rule:res} and 1 normalised application of Rule \eqref{rule:cons}, we deduce by Proposition \ref{prop:mgs-decrease} that \(|\mgs(\C^e)| \leqslant (|\Solved(\C^e)|+1)^{|\measureNC(\C^e)|}\).
\end{proof}

\subsubsection{Termination of the computation of partition trees}
To bound the number of rule applications in Algorithm \ref{alg:ptree} we define a well-founded measure that decreases after each case-distinction, simplification, normalisation and vector-simplification rules.
More precisely the rule applications are always of the form
\begin{align*}
  \S \cup \{\Gamma\} & \rightarrow \S \cup \{\Gamma_1, \ldots, \Gamma_p\} &
  p \in \{1,2\}
\end{align*}
% \[\S \cup \{\Gamma\} \rightarrow \S \cup \{\Gamma_1, \ldots, \Gamma_p\}\]
and we show that for all \(i \in \eint{1}{p}\), \(\Gamma > \Gamma_i\) w.r.t. to a well-founded measure on components (under the invariants of the procedure defined in Appendix \ref{app:ptree}).
This therefore bounds the number of rule applications to compute a given branch of the partition tree.
The measure in question is a tuple of 9 integer components that is ordered w.r.t. the lexicographic ordering.

\paragraph{Measure 1:  sizes of the processes}

  As first element of the measure, we compute a maximum on the sizes of the processes in the multisets \(\P\), that is,
  \defcomp{1}{
    \max_{(\P,\C,\C^e) \in \Gamma} \sum_{R \in \P} \dagsize{R}
  }
  Notice that this stays unchanged for any simplification or case distinction rules but strictly decreases when applying the extended symbolic transitions.
  % Moreover, since the size of a process consider the explicit tree structure, we have that this first element of the tuple is bounded by the size of the initial processes \(P\) and \(Q\).

% \paragraph{Measure 2:  Number of non-deducibility facts}

%   The second element of the measure is the number of non-deducibility facts \(\forall X. X \ndedfact u\) appearing in \(\Df\).
%   This types of formulas can only be added by symbolic rules (that already decrease the first component of the measure) and strictly decrease when Rule \eqref{rule:channel} is applied.
%   \defcomp{2}{
%     \sum_{S \in \Gamma} |\{(\forall X.\, X \ndedfact u) \in \Df(S)\}|
%   }

\paragraph{Measure 2:  Number of constraint systems}

  The third element of the measure considers the number of extended symbolic processes in the set, i.e., \(|\Gamma|\), that may increase only when applying a symbolic transition;
  however it strictly decreases when applying the simplification rules \eqref{rule:vector-split solved} and \eqref{rule:vectorbot}.
  Moreover it also strictly decreases for the positive branch of Rule \eqref{rule:satisfiable} when applied with the case \ref{it:rule-sat-diseq} of its application conditions.
  In such a case, we consider a disequation \(\psi\) and a mgs \(\Sigma\) of \(\C^e_j\) that does not satisfy \(\psi\), which will lead to at least one \(S \in \Gamma\) being discarded by the simplification rule \eqref{rule:vectorbot}.
  \defcomp{2}{|\Gamma|}

  % Intuitively, \(n\) corresponds to the number of symbolic transitions possible from \(P\) and \(Q\) for a given symbolic trace.
  % Hence, we can bound \(n\) by \((|P|_{dag}|E|_{dag}|)^{|P|_{dag}} + (|Q|_{dag}|E|_{dag}|)^{|Q|_{dag}}\).
  % Notice that the part \(|E|_{dag}^{|P|_{dag}}\) is due to the computation of the most general unifiers modulo \(E\) in the symbolic transitions.
  % Moreover, notice that this bound is exponential in the size of the inputs \(P,Q\) and \(E\).

\paragraph{Measure 3:  Number of terms not consequence}

  Given \(\C^e\) an extended symbolic constraint system, let us consider the following set representing the set of terms that are not consequence of \(\Solved(\C^e)\) and \(\Df(\C^e)\):
  \[
    \setSDF(\C^e) = \{ t \in \terms[1] \mid \forall \xi, (\xi,t) \notin \conseq(\Solved(\C^e) \cup \Df(\C^e))\}
  \]
  Typically it corresponds to the terms that are not deducible by the attacker but could potentially be (because the knowledge base is not saturated yet).
  In fact, when the simplification Rule \eqref{rule:vector-solve} is applied, i.e., when a deduction fact \(\xi \dedfact u\) is added to \(\Solved(\C^e)\), the term \(u\) is necessarily a subterm of the frame by the invariant \(\PredWellFormed(\C^e)\).
  Moreover by definition of Rule \eqref{rule:vector-solve} we know that \(u\) is not already consequence, meaning that the size of \(\setSDF(\C^e)\) will strictly decrease.
  Finally the case distinction rules never increase the number of elements of \(\setSDF(\C^e)\):
  indeed they all consist of applying substitutions \(\Sigma\) that are most general solutions of some systems having \(\Solved(\C^e)\) as their knowledge base, hence their first-order terms are consequence by \(\Solved\)-basis.
  All in all we choose the following component:
  \defcomp{3}{\min_{(\P,\C,\C^e) \in \Gamma} |\setSDF(\C^e)|}

  % Finally, with the same arguments for showing \(\measureNC(\C^e_i) \leq \measureNC(\C_i)\), we can show that \(|\setSDF(\C^e_i)|\) is bounded by \(\measureNC(\C_i)\) and so \(|\setSDF(\C^e_i)| \leq 2(\dagsize{P} + \dagsize{Q})\times(\dagsize{E} + 1)\). Therefore, as third element, we consider \(\min(|\setSDF(\C^e_i)| \mid i = 1 \ldots n)\) which is bounded by \(2(\dagsize{P} + \dagsize{Q})\times(\dagsize{E} + 1)\).

\paragraph{Measure 4:  Number of unsolved extended constraint systems}

  We recall that the aim of Rule \eqref{rule:satisfiable}, case \ref{it:rule-sat-mgs} of its application conditions, is to put extended constraint systems in solved form (that is, in a form where they trivially have \(\mu^2\) as a unique mgs).
  If
  \defcomp{4}{|\{(\P,\C,\C^e) \in \Gamma \mid \C^e \text{ unsolved}\}|}
  then this measure is strictly decreasing when applying the rule in question.
  Once a system has a unique mgs, instantiating its second variables does not change this fact and the other case distinction rules are therefore non-increasing w.r.t. this measure.

  % Note that we trivially deduce that the number of unsolved systems is bounded by \(n\) and so the fourth element is bounded by \((|P|_{dag}|E|_{dag}|)^{|P|_{dag}} + (|Q|_{dag}|E|_{dag}|)^{|Q|_{dag}}\).

\paragraph{Measure 5:  Applicability of Rule REW}

  The next element represents the number of applications of Rule \eqref{rule:rewrite} that are still possible.
  Typically, we consider all the parameters of the rule \eqref{rule:rewrite} (the deduction facts from \(\Solved\), the rewrite rule, etc...) on which the rule would be applied with a most general solutions that does not already corresponds to a deduction fact in \(\USolved\).
  If \(\C^e\) is an extended constraint system we therefore consider \(\setRew(\C^e)\) the set of tuples \((\psi,\ell \rightarrow r, p, \psi_0, \Sigma)\) that satisfy all the application conditions of Rule \eqref{rule:rewrite}, and
  \defcomp{5}
    {\sum_{(\P,\C,\C^e) \in \Gamma} |\setRew(\C^e)|}
  By definition \(|\setRew(\C^e)|\) strictly decreases for at least one \((\P,\C,\C^e) \in \Gamma\) (and non-increasing for the others) when applying Rule \eqref{rule:rewrite}.
  Then let \((\P,\C,\C^e) \in \Gamma\):
  the other case distinction rules \eqref{rule:satisfiable} and \eqref{rule:equality} do not increase \(|\setRew(\C^e)|\).
  Indeed if we consider one of their applications \(\C^e \simpStep{\Sigma'} \CApply{\Sigma'}{\C^e}\),
  we have
  \[\setRew(\CApply{\Sigma'}{\C^e}) = \{(\psi\Sigma',\ell \rightarrow r, p, \psi_0, \Sigma\Sigma') \mid (\psi,\ell \rightarrow r, p, \psi_0, \Sigma) \in \setRew(\C^e)\}\,.\]

  Note however that \(|\setRew(\C^e)|\) may increase by application of Rule \eqref{rule:vector-solve} since \(|\Solved(\C^e)|\) will increase;
  yet the measure is already decreasing by the component \(\compon[3]\).


\paragraph{Measure 6:  Number of unsolved deduction formulas}

  We recall that Rule \eqref{rule:satisfiable}, case \ref{it:rule-sat-hyp} of its application conditions, applies a most general solution to remove the hypotheses of one formula \(\psi \in \USolved(\C^e)\) for some \((\P,\C,\C^e) \in \Gamma\)
  (the formula becomes solved in the positive branch, and is removed by \eqref{rule:Disequation removal 2} in the negative branch).
  This rule application is therefore strictly decreasing w.r.t. the measure
  \defcomp{6}
    {|\{\psi \in \USolved(\C^e) \mid (\P,\C,\C^e) \in \Gamma, \psi \text{ unsolved deduction formula}\}|}
  We only consider deduction formulas \(\psi\) for this component.
  In particular the only rule that may increase this measure (i.e., generate unsolved deduction formulas) is \eqref{rule:rewrite} which is already decreasing w.r.t. the previous component of the measure.

\paragraph{Measure 7:  Applicability of Rule EQ}

  Similarly to the analogue component for Rule \eqref{rule:rewrite}, we now define the next component that bounds the maximal number of possible applications of Rule \eqref{rule:equality}.
  %
  The application conditions stipulate that it can be applied either
  \begin{enumerate}%[label=(\textit{\roman*})]
    \item \label{it:measure-eq-1}
    on two deduction facts of \(\Solved(\C^e_i)\), or
    \item \label{it:measure-eq-2}
    on one deduction fact of \(\Solved(\C^e_i)\) in combination with a construction function symbol.
  \end{enumerate}
  Even if the application conditions also consider a mgs \(\Sigma\), the number of applications of Rule \eqref{rule:equality} will not depend on their number;
  this is intuitively because after applying the rule with one arbitrary mgs \(\Sigma\), the conditions forbid any later applications with identical parameters except \(\Sigma\).
  Formally consider for example the case \ref{it:measure-eq-1} (case \eqref{it:measure-eq-2} follows the same reasoning).
  The rule is applied on two deduction facts \((\xi_1 \dedfact u_1),(\xi_2 \dedfact u_2) \in \Solved(\C^e)\).
  Thus, an equality formula with \(\xi_1\Sigma \eqf \xi_2\Sigma\) as head will be added in \(\USolved(\CApply{\Sigma}{\C^e})\).
  However, in further applications of the rule, the condition that
  ``for all \((\clause{H}{\varphi}) \in \USolved(\CApply{\Sigma}{\C^e})\), \(H \neq (\xi_1 \eqf \xi_2)\)''
  will prevent a new application with the same (up to instantiation of \(\Sigma\)) deductions facts from \(\Solved(\CApply{\Sigma}{\C^e})\).

  % The same situation occurs in case (b) with the condition \emph{for all \((\clause{S}{\zeta_1 \eqf \zeta_2}{\varphi}) \in \USolved(\C^e_i)\), \(\zeta_1 = \xi_1\) implies \(\rootf{\zeta_2} \neq \ffun\)}.

  We therefore conclude that the rule \eqref{rule:equality} can be applied only once per pair of deduction facts in \(\Solved\) and once per deduction fact in \(\Solved\) and function symbol in \(\sigc\).
  If \(\C^e\) is an extended constraint system we therefore consider \(\setEq(\C^e)\) the set of pairs \((\psi,\psi') \in \Solved(\C^e)^2\) or \((\psi,\ffun) \in \Solved \times \sigc\) that satisfy all the application conditions of the rule \eqref{rule:equality}, and
  \defcomp{7}
    {\sum_{(\P,\C,\C^e) \in \Gamma} |\setEq(\C^e)|}

\paragraph{Measure 8:  Number of unsolved equality formulas}

  We now introduce the analogue of Component 7 for equality formulas, that is,
  \defcomp{8}
    {|\{\psi \in \USolved(\C^e) \mid (\P,\C,\C^e) \in \Gamma, \psi \text{ unsolved equality formula}\}|}
  As before Rule \eqref{rule:satisfiable} makes this measure decrease in the case \ref{it:rule-sat-hyp} of its application conditions.
  On the contrary unsolved equality formulas can be generated by two rules:
  the case distinction rule \eqref{rule:equality} or the vector-simplification rule \eqref{rule:vector-consequence}.
  % However, once again because of the priority order \eqref{rule:satisfiable} < \eqref{rule:equality} < \eqref{rule:rewrite}, the two rules cannot be triggered simultaneously and the rule \eqref{rule:equality} is only triggered when there is no unsolved equality formulas.
  % Note that due to the condition \emph{\(\forall i. \forall (\clause{S}{\zeta_1 \eqf \zeta_2}{\varphi}) \in \USolved_i\), \(\zeta_1 \neq \xi\) or \(\zeta_2 \neq \xi\)} in Rule \eqref{rule:vector-consequence},
  % two instances of the Rule \eqref{rule:vector-consequence} with different recipes \(\zeta\) (e.g. if \(u_1\) can be deducible with two different recipes) cannot be applied sequentially.
  % Thus, at any given moment, there is at most one unsolved equality formula per extended constraint system \(\C^e_i\), for all \(i \in \{1,\ldots, n\}\).
  %
  % We therefore consider \(| \{ \psi \in \USolved(\C^e_i) \mid i \in \{1,\ldots, n\} \wedge \psi\text{ is an unsolved equality formula}\}|\) as eighth element of the measure which is bounded by \(n\) and so by \((|P|_{dag}|E|_{dag}|)^{|P|_{dag}} + (|Q|_{dag}|E|_{dag}|)^{|Q|_{dag}}\).

\paragraph{Measure 9: Remaining most general solutions}

  So far, every time we showed that one of the previous element of the measure (strictly) decrease by application of a case distinction rule, we always focused on the positive branches of case-distinction rules.
  The negative branches on the contrary only add recipe disequations to the system, which does not increase any the previous components of the measure \emph{but} strictly decreases the number of most general solutions we can compute for the same instance of the rule.
  For example, if \(\Sigma \in \mgs(\C^e)\) then \(|\mgs(\C^e)| > |\mgs(\C^e[\Eqsnd \wedge \neg\Sigma])|\).
  Hence it suffices to consider the last component:
  \defcomp{9}
    {\left|\left\{\Sigma \mid
      \begin{array}{@{\ }l}
        \text{there exists a case distinction rule applicable} \\
        \text{from \(\C^e\) with parameter \(\Sigma\), \((\P,\C,\C^e) \in \Gamma\)}
      \end{array}\right\}\right|}
  % the measure strictly decrease in the negative branch of any of the case distinction rules.

  % Note however that it is unnecessary to bound this tenth element. We only require it to be finite for termination purposes, which is the case. Indeed, recall that we aim to bound the number of time a most general solution is applied in order to bound \(|R(\C^e_i)|\). Since this tenth element of the measure focus on the parts of the rules that do not apply most general solution, it does not impact the bound of \(|R(\C^e_i)|\).

\paragraph{Conclusion}
  This gives the termination of the algorithm for computing \(T \in \ptree(P,Q)\).
  We study more precisely the Components 1 to 9 of the measure in Appendix \ref{app:termination} and prove that they can all be bound by an exponential in \(\dagsize{P,Q,\R}\) (with \(\R\) the rewriting system, implicitly including the signature).
  Hence:

  \begin{theorem}[termination for partition trees] \label{thm:termination-ptree}
    For all \(P,Q\) plain processes, Algorithm \ref{alg:ptree} terminates with arguments \(P,Q\).
    Moreover each branch of the resulting tree is generated by applying at most an exponential number (in \(\dagsize{P,Q,\R}\)) of rules, not counting the negative branches of case distinction rules.
  \end{theorem}

\subsection{Bounding the size of most general solutions}
\label{sec:exp-mgs}

\subsubsection{Overall approach}
\paragraph{Objective}
  We now focus on the theoretical complexity of the decision problems \TraceEquiv, \Bisimilarity, \Simulation,\ldots
  Our goal for now is to prove that they are all decidable in co\nexp and the core argument to achieve this is to prove the theorem:

  \begin{theorem}[size of most general solutions] \label{thm:mgs-size}
    If \(T\) is a partition tree of \(P,Q\) (w.r.t. a rewriting system \(\R\)) generated by Algorithm \ref{alg:ptree}, then for all nodes \(n\) of \(T\), \(\dagsize{\mgs(n)}\) is exponential in \(\dagsize{P,Q,\R}\).
  \end{theorem}

  We will detail in Section \ref{sec:witness-complexity} how to derive a co\nexp decision procedure for equivalence properties by using this result.
  To bound the size of most general solutions we rely on the results previously established in Section \ref{sec:termination-mgs}:
  in the final partition tree \(\mgs(n) = \mu^2(\Gamma(n))\) and it therefore suffices to prove that for all nodes, \(\dagsize{\mu^2(\Gamma(n))}\) is exponential in \(\dagsize{P,Q,\R}\).
  However we will instead study the easier-to-track bound:
  \[|\terms[2](\Gamma(n))| \geqslant |\subterms(\im(\mu^2(\Gamma(n))))| = \dagsize{\mu^2(\Gamma(n))}\]
  % and we will therefore bound \(\terms[2]\) as it is easier to describe its evolution through the procedure.

\paragraph{Evolution of second-order terms}
  Let us now consider each constraint-solving rule and determine how \(\terms[2]\) evolves along the components along a branch of the partition tree.
  \begin{enumerate}
    \item \emph{Symbolic rules}:
    only Rules \eqref{rule:e-in} and \eqref{rule:e-out} increase the size of \(\terms[2]\) by adding at most two new second order variables.
    \item \emph{Simplification, normalisation, vector-simplification rules}:
    only Rule~\eqref{rule:vector-solve} may increase the size of \(\terms[2](\Gamma)\).
    Indeed, it transfers a deduction fact from \(\USolved\) in \(\Solved\) for each extended constraint systems in the current component \(\Gamma\).
    \item \emph{Case distinction rules}:
    the positive branches of these rules increase the size of \(\terms[2]\) whereas the negative branches leave it unchanged.
  \end{enumerate}
  It therefore suffices to prove the following result to obtain Theorem \ref{thm:mgs-size}:

  \begin{proposition}[evolution of second-order terms in partition trees] \label{prop:mgs-size-step}
    If \(\S \cup \{\Gamma\} \rightarrow \S \cup \S'\) where \(\S' = \{\Gamma'\}\) is obtained by Rule \eqref{rule:vector-solve} or \(\Gamma' \in \S'\) is the positive branch of a case distinction rule,
    then \(\dagsize{\terms[2](\Gamma')} - \dagsize{\terms[2](\Gamma)}\) is bounded by a polynomial in \(\dagsize{P,Q,\R}\).
  \end{proposition}

  Indeed we recall that by Theorem \ref{thm:termination-ptree}, we already know that each branch of the partition tree is obtained after applying at most an exponential number of rules (negative branches of case distinction rules excluded).
  Hence we obtain the expected exponential bound on \(\terms[2]\) when combined with the above proposition.
  The remaining of Section \ref{sec:exp-mgs} is dedicated to its proof.

\subsubsection{Bounding the increase of the second-order terms}
\paragraph{When applying a mgs}
  We first study the growth of \(\terms[2](\C^e)\) when applying a mgs to \(\C^e\), which means proving Theorem \ref{thm:mgs-size} in the case of Rule \eqref{rule:satisfiable}.
  Similarly to our previous results on most general solutions (Section \ref{sec:termination-mgs}), our bounds depend on \(\measureNC(\C^e)\) the number of first-order terms of \(\C^e\) that are not already used in the solution, i.e., in \(\mu^2\).
  %
  We also recall that by Proposition \ref{prop:mgs-decrease}, this measure is non-increasing when applying any of the mgs simplification and constraint-solving rules, and is even strictly decreasing in the case of Rule \eqref{rule:res} and \eqref{rule:cons}.
  Let us now show that its growth is actually inverted compared to \(\terms[2]\), that is, how much \(\terms[2]\) increases can be bounded by how much \(\measureNC\) decreases:

  \begin{proposition}[evolution of second-order terms when applying mgs]
    \label{prop:evol-mgs}
    For all extended processes \(\C^e\) that verify the invariants \(\PredWellFormed(\C^e)\) and \(\PredCorrectFormula(\C^e)\), we have
    \[\forall \Sigma \in \mgs(\C^e),\
      |\terms[2](\CApply{\Sigma}{\C^e})| \leq |\terms[2](\C^e)| + |\sig| \times (|\measureNC(\C^e)| - |\measureNC(\CApply{\Sigma}{\C^e})|)\]
  \end{proposition}

  \begin{proof}
    We assume \(|\sig| > 0\) by convention.
    It suffices to prove this property when replacing \(\CApply{\Sigma}{\C^e}\) by \(\C^{e\prime}\) for \(\C^e \rightarrow \C^{e\prime} \neq \bot\) obtained by a mgs simplification or constraint-solving rules.
    We perform a case analysis on the rule in question.

    \caseitem{\emph{case 1: simplification rule on formulas}}

      The simplification rules on formulas only affect first-order terms and second-order disequations and we therefore have \(\terms[2](\C^{e\prime}) = \terms[2](\C^e)\).

    \caseitem{\emph{case 2: mgs simplification rule}}

      We only need to consider Rule \eqref{rule:unifEqfst_simpl}.
      Since it only affects first-order terms, the reasoning is identical to the previous case.

    \caseitem{\emph{case 3: mgs constraint-solving rule}}

      Rules \eqref{rule:conseq} and \eqref{rule:res} apply a second-order substitution \(\Sigma = \mgu(\xi \eqs \zeta)\) to \(\C^e\) for some \(\xi,\zeta \in \terms[2](\C^e)\).
      In particular we deduce that \(|\terms[2](\C^{e\prime})| \leqslant |\terms[2](\C^e)|\) and the conclusion thus follows from the fact that \(\measureNC(\C^e) - \measureNC(\C^{e\prime}) \geqslant 0\) by Proposition \ref{prop:mgs-decrease}.
      Finally the only rule that increases \(\terms[2](\C^e)\) is the last one, \eqref{rule:cons}, that generates \(n\) fresh second-order variables for some constructor symbol \(\ffun/n\).
      In particular \(|\terms[2](\C^{e\prime})| \leqslant |\terms[2](\C^e)| + n\), hence the result since \(\measureNC(\C^e) - \measureNC(\C^{e\prime}) > 0\) by Proposition \ref{prop:mgs-decrease}.
  \end{proof}

  In particular we obtain Proposition \ref{prop:mgs-size-step} for Rule \eqref{rule:satisfiable} case \ref{it:rule-sat-mgs}, provided we manage to prove that \(\measureNC(\C^e)\) is bounded by a polynomial.
  We explain in Appendix \ref{app:termination} how to extend the argument to Rules \eqref{rule:equality}, \eqref{rule:rewrite} and \eqref{rule:vector-solve}.

\paragraph{Bound of unused terms}
  To conclude let us establish the polynomial bound on \(|\measureNC(\C^e)|\).
  In order to do so we explore the relation between \(\C\) and \(\C^e\) in \((\P,\C,\C^e) \in \Gamma\).
  Intuitively \(\measureNC(\C^e)\) always has less elements then \(\measureNC(\C)\) because
  \begin{enumerate}
    \item the symbolic rules always add the same constraints to \(\C\) and \(\C^e\), ensuring that \(\measureNC(\C^e)\) increases at most as much as \(\measureNC(\C)\) by these rules
    \item the other rules leave \(\C\) untouched and do not make \(\measureNC(\C^e)\) increase.
  \end{enumerate}

  \begin{proposition}[approximation of unused terms] \label{prop:approx-unused}
    For all \((\P,\C,\C^e) \in \Gamma\), 
    \[|\measureNC(\C^e)| \leqslant \dagsize{\Phi(\C)\mu^1(\C), \mu^1(\C)}\]
  \end{proposition}

  \begin{proof}
    Considering \(\C\) instead of \(\C^e\), we have the trivial approximation
    \[|\measureNC(\C)| \leqslant |\terms[1](\C)| = \subterms(\Phi(\C)\mu^1(\C), \mu^1(\C)) = \dagsize{\Phi(\C)\mu^1(\C), \mu^1(\C)}\,.\]
    It therefore suffices to prove that \(|\measureNC(\C^e)| \leqslant |\measureNC(\C)|\).
    For that we show that the inequality \(|\measureNC(\C^e)| \leqslant |\measureNC(\C)|\) is preserved when applying any of the constraint-solving rules.

    \caseitem{\emph{case 1: symbolic rules}}

      These rules add the same constraints to \(\C^e\) and \(\C\) (up to an additional deduction fact added to \(\USolved(\C^e)\) in the case of Rule \eqref{rule:e-out}, but this does not affect \(\measureNC(\C^e)\)).
      In particular since \(\Eqsnd(\C) = \Solved(\C) = \emptyset\), if we consider an instance \((\P,\C,\C^e) \sstep{\alpha} (\P',\C',\C^{e\prime})\) of a symbolic rule we therefore have
      \[|\measureNC(\C^{e\prime})| - |\measureNC(\C^e)| \leqslant |\measureNC(\C')| - |\measureNC(\C)|\]
      which gives the expected result.

    \caseitem{\emph{case 2: simplification, normalisation, vector-simplification rules}}

      By definition these rules only affect \(\C^e\) and leave \(\C\) untouched, hence the conclusion since these rules do not increase \(\measureNC(\C^e)\).

    \caseitem{\emph{case 3: case distinction rules}}

      Let us consider \(\CompatibleSubs(\C^e)\) the set of substitutions \(\Sigma\) such that the notation \(\CApply{\Sigma}{\C^e}\) is well defined, that is, such that
      \begin{enumerate}
        \item if \(\dom(\Sigma) \subseteq \vars[2](\Df(\C^e))\)
        \item for all \(X \in \dom(\Sigma)\), there exists \(t\) such that \((X\Sigma,t) \in \conseq(\Solved(\C^e) \cup \Df')\) where
        \(\Df' = \{Y \dedfact u \in \Df(\C^e) \mid Y \notin \dom(\Sigma)\} \cup D_\freshlab\) with
        \[D_\freshlab = \{Y \dedfact y \mid Y \in \vars[2](\im(\Sigma_{|\vars[2](\C^e)})) \smallsetminus \vars[2](\C^e), y \text{ fresh}\}\]
      \end{enumerate}
      This is intuitively the set of substitutions \(\Sigma\) whose image is constructed from \(\Solved(\C^e)\), up to the new variables of \(D_\freshlab\) introduced by \(\Sigma\).
      In particular we have for all \(\Sigma \in \CompatibleSubs(\C^e)\), \(|\measureNC(\CApply{\Sigma}{\C^e})| \leqslant |\measureNC(\C^e)|\) (which follows in more details from Proposition \ref{prop:trans-conseq} in Appendix \ref{app:ptree}), hence the conclusion.
  \end{proof}

  This relation allows to eventually reduce the problem to give a polynomial bound on \(\Phi(\C)\) and \(\mu^1(\C)\) which are only affected by symbolic rules (we recall that the other constraint-solving rules do not modify \(\C\)).
  All in all this concludes the proof of the expected polynomial bound:

  \begin{corollary}[polynomial evolution of second-order terms]
    For all extended processes \(\C^e\) that verify the invariants \(\PredWellFormed(\C^e)\) and \(\PredCorrectFormula(\C^e)\), we have
    \[\forall \Sigma \in \mgs(\C^e),\
      |\terms[2](\CApply{\Sigma}{\C^e})| \leq |\terms[2](\C^e)| + 9\dagsize{P,Q,\R}^3\]
  \end{corollary}

  \begin{proof}
    We agree on the convention that \(\dagsize{P}\), \(\dagsize{Q}\) and \(\dagsize{\R}\) are strictly positive.
    By Propositions \ref{prop:evol-mgs} and \ref{prop:approx-unused}, it suffices to prove that for all symbolic traces \(P \Sstep{\tr} (\P,\C)\),
    \(\dagsize{\Phi(\C)\mu^1(\C), \mu^1(\C)} \leqslant 9\dagsize{P,\R}^2\) (which, as we will see, is a very rough approximation).
    For that a quick induction on the length of \(\tr\) allows to construct a set of \(|\tr|\) variables \(Y = \{y_i\}_{i=1}^{|\tr|}\) and finite set of equations \(S\) such that
    \begin{enumerate}%[label=(\textit{\roman*})]
      \item \label{it:poly-step-1}
      \(\mu^1(\C) \in \mguR(S)\)
      \item \label{it:poly-step-2}
      for all \((u \eqs v) \in S\), \(u\) (resp. \(v\)) is either a subterm of a term appearing in \(P\) or a variable of \(Y\)
      \item \label{it:poly-step-3}
      for all terms \(u \in \im(\Phi(\C)\mu^1(\C))\), there exists \(u_0\) subterm of a term appearing in \(P\) such that \(u_0 \mu^1(\C) = u\)
    \end{enumerate}
    The variables of \(Y\) model the fresh channel variables introduced when executing \eqref{rule:s-in} or \eqref{rule:s-out} transitions, and the set of equations \(S\) collects the equality tests performed during the trace and how each variable of \(P\) is instantiated by \(\Eqfst\) (including by private communications).
    %
    Independently from this, by induction on a straightforward algorithm to compute mgu modulo theory, we have if \(\R\) is constructor-destructor subterm convergent
    \begin{align}
      |\subterms(\sigma)|
        \nonumber
        & \leqslant |\subterms(S)| + \dagsize{\R} \times |\{ t \in \subterms(S) \mid \rootf(t) \in \sigd \}| \\
        \label{eqn:mgu-modulo-bound} \tag{\mbox{\(\mathcal{E}\)}}
        & \leqslant 2|\subterms(S)| \times \dagsize{\R}
    \end{align}
    %
    Altogether we therefore obtain
    \begin{align*}
      \dagsize{\Phi(\C)\mu^1(\C), \mu^1(\C)}
        & \leqslant |\subterms(P)| + 2 \dagsize{\mu^1(\C)}
          & & \text{(by \ref{it:poly-step-3})} \\
        & \leqslant \dagsize{P} + 4|\subterms(S)| \times \dagsize{\R}
          & & \text{(by \ref{it:poly-step-1} and \eqref{eqn:mgu-modulo-bound})} \\
        & \leqslant \dagsize{P} + 4(\dagsize{P} + |\tr|)\dagsize{\R}
          & & \text{(by \ref{it:poly-step-2})} \\
        & \leqslant 9 \dagsize{P,\R}^2 & & \qedhere
    \end{align*}
  \end{proof}

\subsection{Complexity upper bounds for equivalence properties} \label{sec:witness-complexity}

\subsubsection{Complexity of trace equivalence}

The goal of this section is to prove the following theorem:

\begin{theorem}[complexity of trace equivalence] \label{thm:trace-equiv-complexity}
  \TraceEquiv are co\nexp for bounded processes and constructor-destructor subterm convergent theories.
\end{theorem}

The proof relies on the following arguments that were developed in previous sections:
\begin{enumerate}
  \item \emph{charactering trace inclusion with partition trees:}
  Theorem~\ref{thm:trace-equiv-ptree}
  \item \emph{existence of a mgs of exponential size:}
  Theorem \ref{thm:mgs-size}
  \item \emph{soundness and completeness of the symbolic semantics:}
  see Proposition~\ref{prop:symbolic-sound-complete}
\end{enumerate}
Using these ingredients we prove the core property:

\begin{proposition}[witness of non-trace equivalence of exponential size] \label{prop:trace-witness-exp}
  Let \(P_1,P_2\) be two plain processes w.r.t. a constructor-destructor subterm convergent rewriting system \(\R\).
  The following points are equivalent:
  \begin{enumerate}
    \item \label{it:trace-witness-1}
    \(P_1 \not\TraceIncl P_2\)
    \item \label{it:trace-witness-2}
    there exists a trace \(t : P_1 \Cstep{\tr} A_1\) such that \(\dagsize{t}\) is exponential in \(\dagsize{P,Q,\R}\) and for all \(P_2 \Cstep{\tr} A_2\), \(A_1 \not\StatEq A_2\).
  \end{enumerate}
\end{proposition}

\begin{proof}
  The proof of \ref{it:trace-witness-2}\(\Rightarrow\)\ref{it:trace-witness-1} is trivial and we therefore focus on \ref{it:trace-witness-1}\(\Rightarrow\)\ref{it:trace-witness-2}.
  Let us assume that \(P_1 \not\TraceIncl P_2\), and let \(T \in \ptree(P_1,P_2)\) the partition tree computed by Algorithm \ref{alg:ptree}.
  By Theorem \ref{thm:trace-equiv-ptree} we obtain a partition-tree trace \(P_1 \Tstep{\tr} (\P,\C),n\) such that there exist no traces of the form \(P_2 \Tstep{\tr} (\P',\C'),n\).
  But by Theorem \ref{thm:mgs-size} we know that the (DAG) size of \(\mgs(n)\) is of exponential in \(\dagsize{P,Q,\R}\), which gives a solution \((\Sigma,\sigma) \in \Sol[\pi(n)](\C)\) of exponential size as well by definition of a mgs.

  Let us then consider the trace \(t : P_1 \Cstep{\tr\Sigma} (\P\sigma, \Phi(\C)\sigma \norm)\) (that exists by soundness of the symbolic semantics) and show that it satisfies the conditions of \ref{it:trace-witness-2}.
  It is indeed of exponential DAG size.
  Besides assume by contradiction that there exists a trace \(P_2 \Cstep{\tr\Sigma} (\Q,\Psi)\) such that \(\Phi(\C)\sigma \StatEq \Psi\).
  By using the completeness of the symbolic semantics and the properties of the partition tree (Lemma~\ref{lem:PT-parent-concrete-derivation}), we would obtain a symbolic process \((\P',\C')\) such that \(P_2 \Tstep{\tr} (\P',\C'),n\), yielding a contradiction.
\end{proof}

To obtain a decidability result we also use the following result on static equivalence rephrased from \cite{AC06}:

\begin{proposition}[witness of non-static equivalence of polynomial size]
  If two frames \(\Phi\) and \(\Psi\) are not statically equivalent w.r.t. a subterm convergent rewriting system \(\R\), there exist two recipes \(\xi\) and \(\zeta\) such that \(\dagsize{\xi,\zeta}\) is polynomial in \(\dagsize{\Phi,\Psi,\R}\), \(\xi \Phi \norm = \zeta \Phi\norm\) and \(\xi \Psi\norm \neq \zeta \Psi\norm\).
\end{proposition}

Wrapping everything together we obtain the following \nexp decision procedure for non-trace equivalence:

\begin{enumerate}
  \item Given two processes \(P_1,P_2\), guess an integer \(i \in \eint{1}{2}\) and a trace \(P_1 \Cstep{\tr} (\P,\Phi)\) of exponential size.
  In particular, although \(|\dom(\Phi)| \leqslant |\tr|\), the sizes of the terms in \(\im(\Phi)\) may be exponential as well.
  \item For each of the exponentially-many traces of the form \(t : P_2 \Cstep{\tr} (\Q,\Psi)\), guess two recipes \(\xi_t,\zeta_t\) of exponential size.
  \item if for one such trace \(t\) we do not have \(\xi_t \Phi\norm = \zeta_t \Phi\norm \Leftrightarrow \xi_t \Psi\norm = \zeta_t \Psi\norm\), conclude that \(P_1 \not\TraceEq P_2\).
\end{enumerate}

\subsubsection{Complexity of labelled bisimilarity}

The goal of this section is to prove the following theorem:

\begin{theorem}[complexity of labelled bisimilarity]
  \Bisimilarity is co\nexp for bounded processes and constructor-destructor subterm convergent theories.
\end{theorem}

Similarly to trace equivalence we build on the results of the previous sections, this time using the characterisation of labelled bisimilarity based on symbolic witnesses (Theorem~\ref{thm:ptree-lab-bis}).
Given a partition tree with most general solutions of exponential size, our goal is therefore to derive from it a symbolic witness of non-equivalence and a solution of this witness (Definition~\ref{def:solution-witness}), both of exponential size as well.

\begin{proposition}[witness of non-labelled bisimilarity of exponential size]
  Let \(P_1,P_2\) be two plain processes w.r.t. a constructor-destructor subterm convergent rewriting system \(\R\).
  The following points are equivalent:
  \begin{enumerate}
    \item \label{it:bis-witness-1}
    \(P_1 \not\LabBis P_2\)
    \item \label{it:bis-witness-2}
    there exists a witness \(\witness\) for \((P_1,P_2)\) such that \(\dagsize{\witness}\) is exponential in \(\dagsize{P,Q,\R}\).
  \end{enumerate}
\end{proposition}

\begin{proof}
  The proof of \ref{it:trace-witness-2}\(\Rightarrow\)\ref{it:trace-witness-1} is trivial and we therefore focus on \ref{it:trace-witness-1}\(\Rightarrow\)\ref{it:trace-witness-2}.
  Let us assume that \(P_1 \not\LabBis P_2\), and let \(T \in \ptree(P_1,P_2)\) the partition tree computed by Algorithm \ref{alg:ptree}.
  By Theorem \ref{thm:ptree-lab-bis} we obtain a symbolic witness \(\witness_s\) for \((P_0,P_1,\rootf(T))\) such that \(\Sol(\witness_s) \neq \emptyset\), and it suffices to prove that there exists a solution of \(\witness_s\) of exponential size (where the size of a solution \(\fsol\) is \(\sum_{N \in \dom(\fsol)} \dagsize{\fsol(N)}\)).
  More precisely we construct by induction on \(\witness_s\) a function \(f\) mapping the nodes of \(\witness_s\) to second-order substitutions (not necessarily ground) such that:
  \begin{enumerate}
    \item \((f_{\mgs} f) \in \Sol(\witness_s)\), where \(f_{\mgs}(S,n) = \mgs(n)\) and the notation \(f = gh\) is defined by \(f(N) = g(N) h(N)\) for all nodes \(N\) of \(\witness_s\)
    \item for all \(\fsol \in \Sol(\witness_s)\), there exists \(f'\) such that \(\fsol = f_{\mgs} f f'\)
  \end{enumerate}
  In particular since \(f_{\mgs}\) is of exponential size by Theorem \ref{thm:mgs-size}, it suffices to ensure that \(f\) is of exponential size as well.

  \caseitem{\emph{case 1: \(\witness_s\) is reduced to a leaf \(N\)}.}

    Then it suffices to choose \(f(N) = \id\).

  \caseitem{\emph{case 2: \(\witness_s\) has a root labelled \((S,n)\) and children \(N_1, \ldots, N_p\) labelled \((S_1,n'), \ldots, (S_p,n')\)}}

    Let us write \(S = \{A_0,A_1\}\) with, by definition, a symbolic trace \(A_0 \sstep{\alpha} A_0'\) such that each trace \(A_1 \Sstep{\bar{\alpha}} A_1^i\) corresponds to a child \(S_i = \{A_0',A_1^i\}\).
    We apply the induction hypothesis to the children to obtain their respective functions \(f_1, \ldots, f_p\).
    %
    We recall that \(\Sol(\witness_s) \neq \emptyset\) by hypothesis and that all solutions \(\fsol\) verify \(\fsol(N_1) = \cdots = \fsol(N_p)\);
    thus, since by induction hypothesis all solutions of \(\witness_s\)  are instances of \(f_{\mgs} f_i\), we obtain:
    \[\mgu(\mgs(n') f_1(N_1)\rho_1 \wedge \ldots \wedge \mgs(n') f_p(N_p)\rho_p) \neq \bot\]
    for \(\rho_1, \ldots, \rho_p\) fresh variables renamings of \(\im(f_1(N_1)), \ldots, \im(f_p(N_p))\), respectively.
    In particular, assuming without loss of generality that all the \(f_i(N_i)\) have the same domain \((\vars[2](n') \smallsetminus \dom(\mgs(n'))) \cup \im(\mgs(n'))\), we can write
    \[\Sigma = \mgu(f_1(N_1)\rho_1 \wedge \ldots \wedge f_p(N_p)\rho_p) \neq \bot\]
    Note that this \(\mgu\) is only polynomially bigger than each \(f_i(N_i)\).
    Since \(\mgs(n')\) is an instance of \(\mgs(n)\), we also let \(\Sigma_0\) such that \(\mgs(n') = \mgs(n) \Sigma_0\).
    We then conclude the proof by defining \(f\) as follows:
    \begin{enumerate}
      \item \(f(\rootf(\witness_s)) = (\Sigma_0 \Sigma)_{|\vars[2](n)}\)
      \item for all \(i \in \eint{1}{p}\), for all nodes \(N\) in the subtree of \(\witness_s\) rooted in \(N_i\), \(f(N) = f_i \Sigma\). \qedhere
    \end{enumerate}
\end{proof}

\subsection{Complexity lower bounds} \label{sec:deepsec-hardness}

We prove in this section the complexity lower bounds stated in Theorem~\ref{thm:deepsec-conexp}.

\subsubsection{Extensions of the calculus} \label{sec:tools encoding}
We first introduce useful syntax extensions that can be encoded in the original calculus.
We point out that that using these encodings does not affect the complexity of deciding the related decision problems, since they rely on polynomial-size encodings.

\paragraph{Internal non-deterministic choice}

  A first classical operator is the \emph{non-deterministic choice}:
  \(P + Q\) is a process that can be executed either as \(P\) or as \(Q\).
  Its operational semantics can therefore be described by adding the following rule to those of Figure \ref{fig:semantics}:
  \begin{align}
    \tag{\mbox{\textsc{Choice}}}
    \label{rule:choice}
    (\multi {P+Q} \cup \P, \Phi) & \cstep {\silent} (\multi {R} \cup \P, \Phi) & \text{\small if \(R \in \{P,Q\}\)}
  \end{align}
  This reduction can easily be encoded as an internal communication on a fresh private channel.
  We formalise it by a process transformation \(\sem{\cdot}\):
  \begin{align}
    \label{translation choice}
    \sem {P+Q} &\eqdef \OutP{s}{s} \mid \InP{s}{x}.\sem{P} \mid \InP{s}{y}. \sem{Q} & \mbox{where \(s\in\Nall\) and \(x,y\in\X[1]\) are fresh}
  \end{align}
  and all other cases of the syntax are handled as homomorphic extensions of \(\sem{\cdot}\). % Saying it concisely, \(\sem\cdot\) translates processes with non-deterministic choices to usual processes by replacing the \(+\) by the expression above.
  As for the parallel operator we will sometimes use the big operator \(\sum\) assuming right-associativity. The correctness of this translation with respect to \(\TraceEq\) and \(\LabBis\) will be stated later on in this section.

  We also introduce the \(\guessBinary{x}\) construct which non-deterministically assigns either \(0\) or \(1\) to \(x\). \(\guessBinary{x}.P\) silently reduces to either \(P\{ x \mapsto \0\}\) or \(P\{ x \mapsto \1\}\) and \(\guessBinary{\vec{x}}.P\) is defined as \(\guessBinary{x_1}.\guessBinary{x_2}\ldots\guessBinary{x_n}.P\) where \(\vec x = x_1,\cdots,x_n\).
  Formally, we extend the operational semantics with the rule
  \begin{align*}
    %
    %% Choose 0
    \tag{\sc Choose-0}\label{rule:choose-0}
    (\P\cup\multi{\guessBinary{x}.P}, \Phi) &\cstep{\epsilon} (\P\cup\multi{P\{ x \mapsto \0\}}, \Phi)\\
    %
    %% Choose 1
    \tag{\sc Choose-1}\label{rule:choose-1}
    (\P\cup\multi{\guessBinary{x}.P}, \Phi) &\cstep{\epsilon} (\P\cup\multi{P\{ x \mapsto \1\}}, \Phi)\\
    %
  \end{align*}
  and define
  \[
    \sem{\guessBinary{y}.P} \eqdef (\OutP{d}{0} + \OutP{d}{1}) \mid \InP{d}{y}.\sem{P} \quad\mbox{with \(d \in \Nall\) is fresh}
  \]

\paragraph{Boolean circuits and formulae}
\label{sec:simplify section circuit}

  Complete problems in complexity theory often involve boolean formulae (e.g., \sat or \qbf). The ability to evaluate boolean formulae, or boolean circuits in general, within the applied \(\pi\)-calculus is therefore crucial. We can implement such a feature by the means of private channels and internal communication: each edge of a boolean circuit \(\Gamma\) indeed mimics a channel transmitting a boolean over a network (Figure \ref{fig:circuit conversion}).

  \begin{figure}[ht]
    \centering

    \begin{tikzpicture}
      [
        auto,
        or/.style={or gate US,draw}
      ]

      \newcommand\size{0.8}

      \node[or,fill=cyan!50] (OR) at (0,0) {\(\vee\)};
      \node (Arrow) at (2,0) {\scalebox{2}{\(\rightsquigarrow\)}};

      \node[draw,fill=cyan!50] (Inp) at (3.5,0) {};
      \node (Par1) at (5.5,0) {\scalebox{2}{\(|\)}};
      \node[draw,fill=cyan!50] (Comp) at (7.5,0) {};
      \node (Par2) at (9.5,0) {\scalebox{2}{\(|\)}};
      \node[draw,fill=cyan!50] (P) at (11.5,0) {\(P(x,y)\)};

      \draw[-] (OR) edge[sloped] node[above] {\scalebox{\size}{\(c_1\)}} (-1,0.3);
      \draw[-] (OR) edge[sloped] node[below] {\scalebox{\size}{\(c_2\)}} (-1,-0.3);
      \draw[-] (OR) edge[sloped] node[above] {\scalebox{\size}{\(c_3\)}} (1,0.3);
      \draw[-] (OR) edge[sloped] node[below] {\scalebox{\size}{\(c_4\)}} (1,-0.3);

      \draw[->] (Inp) edge[sloped] node[above] {\scalebox{\size}{\(\OutP{c_1}a\)}} (5,0.3);
      \draw[->] (Inp) edge[sloped] node[below] {\scalebox{\size}{\(\OutP{c_2}b\)}} (5,-0.3);

      \draw[<-] (Comp) edge[sloped] node[above] {\scalebox{\size}{\(\InP {c_1} x\)}} (6,0.3);
      \draw[<-] (Comp) edge[sloped] node[below] {\scalebox{\size}{\(\InP{c_2} y\)}} (6,-0.3);
      \draw[->] (Comp) edge[sloped] node[above] {\scalebox{\size}{\(\OutP{c_3}{x\vee y}\)}} (9,0.3);
      \draw[->] (Comp) edge[sloped] node[below] {\scalebox{\size}{\(\OutP{c_4}{x\vee y}\)}} (9,-0.3);

      \draw[<-] (P) edge[sloped] node[above] {\scalebox{\size}{\(\InP{c_3}x\)}} (10,0.3);
      \draw[<-] (P) edge[sloped] node[below] {\scalebox{\size}{\(\InP{c_4}y\)}} (10,-0.3);
    \end{tikzpicture}

    \caption{Simulation of an OR-gate within the applied \(\pi\)-calculus}
    \label{fig:circuit conversion}
  \end{figure}

  Formally, the essence of circuits lies in so-called {\it logical gates} which are boolean functions with at most two inputs. We assume without loss of generality that the gate has at most two (identical) outputs, to be given as input to other gates. Logical gates usually range over the constants \(\0\) and \(\1\) and the predicates \(\wedge\), \(\vee\) and \(\neg\) with the usual truth tables but we may use other common operators such as \(=\). From that a {\it boolean circuit} is an acyclic graph of logical gates: each input (resp. output) of a gate is either isolated or connected to a unique output (resp. input) of an other gate, which defines the edges of this graph.

  Such a circuit \(\Gamma\) with \(m\) isolated inputs and \(p\) isolated outputs thus models a boolean function \(\Gamma:\B^m\rightarrow\B^n\) (where \(\B=\{\0,\1\}\)).  We write \((c_1,c_2,g,c_3,c_4)\in\Gamma\) to state that \(g:\B^2\rightarrow\B\) is a gate of \(\Gamma\) whose inputs are passed through edges \(c_1\) and \(c_2\) and whose output is sent to edges \(c_3\) and \(c_4\). This notation is naturally lifted to other in-outdegrees.

\paragraph{Embedding into the calculus}
  The syntax of plain processes is now extended with the construction \(x_1,\cdots,x_n\leftarrow\Gamma(b_1,\cdots,b_m).P\) where \(\Gamma:\B^m\rightarrow\B^n\) is a circuit, \(x_1,\ldots,x_n\) variables and \(b_1,\cdots,b_m\) terms. We fix two distinct terms \(\0,\1 \in \sig_0\) to model \(\B\) within the calculus, and the labelled operational semantics is extended with the rule:
  \begin{align*}
    \tag{\textsc{Valuate}}\label{rule:valuate}
    (\P\cup\multi{\vec x \leftarrow \Gamma(\vec b).P}, \Phi) &\cstep{\epsilon}
    (\P\cup\multi{P\{ \vec{x} \mapsto \Gamma(\vec{b}\norm)\}}, \Phi) & \mbox{if \(\msg(\vec b)\) and \(\vec{b}\norm \subseteq \B\)}
  \end{align*}

  Now we have to extend the definition of \(\sem\cdot\) (previous subsection) to handle the new operator. For simplicity we only consider the case where gates have two inputs and two outputs: handling lower arities is straightforward. If \((c_1,c_2,g,c_3,c_4)\in\Gamma\), we first define:

  \[\sem{c_1,c_2,g,c_3,c_4}\eqdef\InP{c_1}x.\InP{c_2}y.\prod_{b,b'\in\B}\IfP~x=b~\ThenP~\IfP~y=b'~\ThenP~(\OutP{c_3}{g(b,b')}\mid\OutP{c_4}{g(b,b')})\]

  where \(c_1,c_2,c_3,c_4\in\Nall\) (assuming that different circuits in a process do not share edges). To sum it up, we simply see circuit edges as private channels and simulate the logical flow of the gate. It is then easily extended:
  \begin{align*}
    % \label{translation circuit}
    \sem{\evalFormula{\vec x}{\Gamma(\vec b)}.P} & \eqdef
    \left(\prod_{k=1}^m \OutP {c_{i_k}} {b_k}\right) \mid
    \left(\prod_{(c_1,c_2,g,c_3,c_4)\in\Gamma} \sem {c_1,c_2,g,c_3,c_4}\right) \mid
    \InP{c_{o_1}}{x_1} \ldots \InP {c_{o_n}} {x_n}. \sem {P}
  \end{align*}

  where \((c_{i_k})_{k=1}^m\) (resp. \((c_{o_k})_{k=1}^n\)) are the isolated input (resp. output) edges of \(\Gamma\).
  Note that when \(b\) and \(b'\) are fixed booleans, \(g(b,b')\) denotes the boolean obtained from the truth table of \(g\): we emphasise that \(g\) is {\it not} a function symbol of the signature \(\sig\).

  \begin{remark}[simplifying assumption]
    \label{rem:at least one gate}
    We assume that every input of a circuit goes through at least one gate and has at least one output. This is to avoid irrelevant side cases in proofs.
  \end{remark}

\paragraph{Correctness of the translation}

  Now we dispose of an extended syntax and semantics as well as a mapping \(\sem\cdot\) removing the new constructors from a process.
  The correctness of this translation is proven in Appendix \ref{app:termination}:

  \begin{proposition}[correctness of the encodings]
    \label{prop:encodings correct}
    Let \(\TraceEq^+\) and \(\LabBis^+\) be the notions of trace equivalence and labelled bisimilarity over the extended calculus (the flag \(^+\) being omitted outside of this lemma). For all extended processes \(A = (\P,\Phi)\), the translation \(\sem A = (\sem \P, \Phi) = (\multi {\sem P ~|~ P \in \P}, \Phi)\) can be computed in polynomial time, \(A\TraceEq^+\sem A\) and \(A\LabBis^+\sem A\).
  \end{proposition}

  \begin{remark}[stability of common fragments]
    As the finite and pure fragments of the applied \(\pi\)-calculus are closed under \(\sem\cdot\), sums and circuits can be safely used within any intersection of such fragments.
    The encoding does not use else branches either.
  \end{remark}

\subsubsection{Lower bounds in the pure fragment} \label{sec:lower-pure}

  We now use the above tool to state our reductions, first, in the pure pi calculus.
  
  \paragraph{Trace equivalence}

  To show that trace equivalence is \polyh{2}-hard we proceed by a reduction from \qbf[2], that is, the problem of deciding, given \(\varphi\) a boolean formula whose variables are partitioned into \(\{\vec x\}\cup\{\vec y\}\), whether \(\forall \vec{x}.\exists \vec{y}. \varphi(\vec x,\vec y) = \1\).
  Our goal is to thus to construct two processes \(A\) and \(B\) such that:
  \begin{align}
    A \TraceEq B 
    & & \textit{iff}
    & & \forall \vec{x}.\exists \vec{y}. \varphi(\vec x,\vec y) = \0 \label{tr pure hard}
  \end{align}

  \begin{figure}[!ht]
    \centering
    \scalebox{0.9}
    {
      \begin{tikzpicture}
        %% Node styles
        [
          op/.style={draw,circle,fill=cyan!50,minimum size=1.6em},
          test/.style={draw,rectangle},
          proc/.style={},
          title/.style={draw,rectangle,fill=cyan!50}
        ]
        %% Size reduction for tests
        \newcommand\size{0.9}

        %% Nodes
        \node(TitleP) [title] at (8,0) {\(P(t)\)};
        \node(Input) [proc] at (8,-1) {\(\InP c {\vec x}\)};
        \node(Guess) [proc] at (8,-2) {\(\guessBinary{\vec y}\)};
        \node(Comp) [proc] at (8,-3) {\(\evalFormula v {\varphi(\vec x,\vec y)}\)};
        \node(Send) [proc] at (8,-4) {\(\OutP c t\)};

        \node(TitleA) [title] at (0,0) {\(A\)};
        \node(SumCircleA) [op] at (0,-1) {};
        \node(SumA) [proc] at (0,-1) {\(+\)};
        \node(LeftA) [proc] at (-1,-2) {\(P(v)\)};
        \node(RightA) [proc] at (1,-2) {\(P(\1)\)};

        \node(TitleB) [title] at (4,0) {\(B\)};
        \node(SumCircleB) [op] at (4,-1) {};
        \node(SumB) [proc] at (4,-1) {\(+\)};
        \node(LeftB) [proc] at (3,-2) {\(P(\0)\)};
        \node(RightB) [proc] at (5,-2) {\(P(\1)\)};

        %% Edges
        \draw[->>] (Input) -- node[auto] {} (Guess);
        \draw[->>] (Guess) -- node[auto] {} (Comp);
        \draw[->>] (Comp) -- node[auto] {} (Send);

        \draw[->>] (SumCircleA) -- node[auto] {} (LeftA);
        \draw[->>] (SumCircleA) -- node[auto] {} (RightA);
        \draw[->>] (SumCircleB) -- node[auto] {} (LeftB);
        \draw[->>] (SumCircleB) -- node[auto] {} (RightB);
      \end{tikzpicture}
    }
    \caption{Schematic definition of \(A\) and \(B\)}
    \label{fig:eqtr pure hardness}
  \end{figure}

  Consider three distinct names \(c,\0,\1\in\sig_0\) (the last two modelling booleans for the syntax extension of circuit evaluation, see Section~\ref{sec:tools encoding}). 
  Processes \(A\) and \(B\) are depicted in Figure~\ref{fig:eqtr pure hardness}. 
  Intuitively, the process \(P(t)\) (where \(t\) is a term which may depend on the variables bound by \(P\)) gets a valuation of \(\vec x\) from the attacker, internally chooses a valuation of \(\vec y\), computes the value of \(\varphi(\vec x,\vec y)\) using rule \ref{rule:valuate}, and outputs \(t\). 
  From that it is quite easy to see that \(A\) and \(B\) have the same set of traces \textit{iff} for all valuation of \(\vec x\), there exists a valuation of \(\vec y\) such that \(\varphi(\vec x,\vec y)=\0\).
  This reduction is formalised and proved in Appendix~\ref{app:lower-pure}.

  \begin{theorem}
    In the pure pi-calculus, \TraceEquiv and \TraceInclus are \polyh{2}-hard for bounded positive processes.
  \end{theorem}

  Note that the hardness for \TraceInclus is directly implied by the hardness of \TraceEquiv.
  This is evidenced by the reduction that, for all processes \(P,Q\), \(P \TraceIncl Q\) \textit{iff} \(P + Q \TraceEq Q\).

  %%
  %%% Subsection
  %%

  \paragraph{Simulations}

  We now prove that labelled bisimilarity is \pspace-hard for the positive pure pi calculus by reduction from \qbf.
  This is more involved as \qbf allows arbitrary quantifier alternation.  Let \(\varphi\) be a boolean formula whose variables are partitioned into \(\{x_1,\ldots, x_n\}\cup\{y_1,\ldots, y_n\}\) for some \(n\in\mathbb N\). We construct (in polynomial time in the size of \(\varphi\) and \(n\)) two processes \(A\) and \(B\) such that:
  \begin{align}
    \label{eqn:reduction pspace hard}
    A \LabBis B
    & & \textit{iff}
    & & A \Simi B
    & & \forall x_1 \exists y_1 \ldots \forall x_n \exists y_n.~\varphi(x_1,\ldots, x_n,y_1,\ldots, y_n) = \0
  \end{align}

  Both \qbf and labelled bisimilarity may be seen as bisimulation games: an attacker plays the \(\exists\)-quantifiers (selects a transition in a process) whereas a defender responds with the \(\forall\)-quantifiers (tries to find a similarly-labelled sequence of transitions in the other process). The role of \(A\) and \(B\)  is to implement this intuitive connection: the attacker moves will be simulated by public inputs \(\InP c {x_i}\) and the defender responses by instructions \(\guessBinary{z_i}.\InP c {y_i}\). The structure of \(A\) and \(B\) is then designed to constrain the moves of the two players so that the winning condition of the attacker is exactly \(\exists x_1\forall y_1\ldots\exists x_n \forall y_n.~\varphi(\vec x,\vec y)=1\).% The definition is schematized in \cref{fig:eqobs pure hardness}.

  % \begin{remark}
  % 	\(A\) and \(B\) are defined by auxiliary processes \(A_i\) and \(B_i\), \(i\in\eint 1 {n+1}\), mutually calling each others. In order to avoid an exponential blow-up which would invalidate our reduction, we simulate a routine-call feature (\(\call P\)) by the mean of internal communication. Details in the formal construction, next paragraph.
  % \end{remark}

  \begin{figure}[!ht]
    \centering
    \scalebox{0.9}
    {
      \begin{tikzpicture}
        %% Node styles
        [
          op/.style={draw,circle,fill=cyan!50,minimum size=1.6em},
          test/.style={draw,rectangle},
          proc/.style={},
          title/.style={draw,rectangle,fill=cyan!50}
        ]
        %% Size reduction for tests
        \newcommand\size{0.9}

        %% Nodes
        \node(TitleAi) [title] at (0.5,0) {\(A_{i,~i\leqslant n}\)};
        \node(InputA) [proc] at (0.5,-1) {\(\InP c {x_i}\)};
        \node(TestBoolA) [test] at (0.5,-2) {\scalebox{\size}{\(x_i\in\B\)}};
        \node(ProcDiA) [proc] at (0.5,-3) {\(D_i\)};

        \node(TitleBi) [title] at (4,0) {\(B_{i,~i\leqslant n}\)};
        \node(InputB) [proc] at (4,-1) {\(\InP c {x_i}\)};
        \node(TestBoolB) [test] at (4,-2) {\scalebox{\size}{\(x_i\in\B\)}};
        \node(SumBCircle) [op] at (4,-3) {};
        \node(SumB) [proc] at (4,-3) {\(+\)};
        \node(ProcDiB) [proc] at (3,-4) {\(D_i\)};
        \node(InputB2) [proc] at (5,-4) {\(\InP c {y_i}\)};
        \node(TestBoolB2) [test] at (5,-5) {\scalebox{\size}{\(y_i\in\B\)}};
        \node(ProcBi) [proc] at (5,-6) {\(\call{B_{i+1}}\)};

        \node(TitleDi) [title] at (10,0) {\(D_{i,~i\leqslant n}\)};
        \node(GuessD) [proc] at (10,-1) {\(\guessBinary{z_i}\)};
        \node(InputD) [proc] at (10,-2) {\(\InP c {y_i}\)};
        \node(CompDiff) [proc] at (10,-3) {\(\evalFormula{r_i}{(y_i=z_i)}\)};
        \node(ParaCircle) [op] at (10,-4) {};
        \node(Para) [proc] at (10,-4) {\(|\)};
        \node(TestD1) [test] at (8,-4) {\scalebox{\size}{\(r_i=1\)}};
        \node(TestD0) [test] at (12,-4) {\scalebox{\size}{\(r_i=0\)}};
        \node(CallA) [proc] at (8,-5) {\(\call{A_{i+1}}\)};
        \node(CallB) [proc] at (12,-5) {\(\call{B_{i+1}}\)};

        \node(TitleAend) [title] at (14.5,0) {\(A_{n+1}\)};
        \node(CompAend) [proc] at (14.5,-1) {\(\evalFormula v {\varphi(\vec x,\vec y)}\)};
        \node(SendAend) [proc] at (14.5,-2) {\(\OutP c v\)};

        \node(TitleBend) [title] at (14.5,-4) {\(B_{n+1}\)};
        % \node(SumBendCircle) [op] at (15,-5) {~};
        % \node(SumBend) [proc] at (15,-5) {\(+\)};
        % \node(SendAend2) [proc] at (14,-6) {\(\call{A_{n+1}}\)};
        \node(SendBend) [proc] at (14.5,-5) {\(\OutP c \0\)};

        %% Edges
        \draw[-] (InputA) -- node[auto] {} (TestBoolA);
        \draw[->>] (TestBoolA) -- node[auto] {} (ProcDiA);

        \draw[-] (InputB) -- node[auto] {} (TestBoolB);
        \draw[->>] (TestBoolB) -- node[auto] {} (SumBCircle);
        \draw[->>] (SumBCircle) -- node[auto] {} (ProcDiB);
        \draw[->>] (SumBCircle) -- node[auto] {} (InputB2);
        \draw[-] (InputB2) -- node[auto] {} (TestBoolB2);
        \draw[->>] (TestBoolB2) -- node[auto] {} (ProcBi);

        \draw[->>] (GuessD) -- node[auto] {} (InputD);
        \draw[->>] (InputD) -- node[auto] {} (CompDiff);
        \draw[->>] (CompDiff) -- node[auto] {} (ParaCircle);
        \draw[-] (ParaCircle) -- node[auto] {} (TestD1);
        \draw[-] (ParaCircle) -- node[auto] {} (TestD0);
        \draw[->>] (TestD1) -- node[auto] {} (CallA);
        \draw[->>] (TestD0) -- node[auto] {} (CallB);

        \draw[->>] (CompAend) -- node[auto] {} (SendAend);
        % \draw[->>] (SumBendCircle) -- node[auto] {} (SendAend2);
        % \draw[->>] (SumBendCircle) -- node[auto] {} (SendBend);
      \end{tikzpicture}
    }
    \caption{Schematic definition of \(A_i\) and \(B_i\)}
    \label{fig:eqobs pure hardness}
  \end{figure}

  \(A\) and \(B\) are defined inductively by processes \(A_i\), \(B_i\) and \(D_i\), depicted in Figure~\ref{fig:eqobs pure hardness},  structured in a way that, in a bisimulation game:
  \begin{enumerate}
  \item the attacker chooses the instance of \(x_i\);
  \item the defender chooses the instance of \(z_i\) and can force the attacker to instanciate \(y_i\) with the same value (the attacker not doing so allows for a trivial victory of the defender).
  \end{enumerate}
  The intermediary processes \(\call{A_i}\) and \(\call{B_i}\) intuitively formalise value passing from one index to another, in order to avoid an exponential blowup when encoding \(n\) nested tests.
  Their precise definition and the correctness of the reduction is formalised in Appendix~\ref{app:lower-pure}.
  As before, the hardness of the pre-order follows from the hardness of its symmetric closure.

  \begin{theorem}
    In the pure pi-calculus, \Simulation, \Similarity and \Bisimilarity are \pspace-hard for bounded positive processes.
  \end{theorem}

\subsubsection{Reduction of SuccinctSAT to process equivalence}

Consider an instance of \sucsat, \(\Gamma\), with \(m+2\) inputs and \(n+1\) outputs and we design \(\sig\), \(\R\) subterm destructor and \(A\) and \(B\) positive processes such that, for any equivalence relation \({\approx} \in \{\Simi,\TraceEq,\LabBis\}\), \(A\not\approx B\) \textit{iff} \(\sem\Gamma_\varphi\) is satisfiable.

\paragraph{Term algebra}
  Terms are built over the following signature:
  \begin{align*}
    \sig \eqdef~~& \0,~\1, & & \mbox{(booleans \(\B\))}\\
               & \Node/2,~\pi/2, & & \mbox{(binary trees)}\\
               & \hfun/2, & & \mbox{(one-way binary hash)}\\
               & \hNode/2,~\hBool/2,~\invN/1,~\invB/1 & & \mbox{(testable binary hashes)}
  \end{align*}

  We equip this term algebra with the rewriting system \(E\) containing the following rules modelling subtree extraction (for binary trees) and argument testing (for hashes):
  \begin{align*}
    \pi(\Node(x,y),\0)\rightarrow~&x
    & \pi(\Node(x,y),\1)\rightarrow~&y\\
    \invN(\hNode(\Node(x,y),z))\rightarrow~&\1
    & \invB(\hBool(\0,z))\rightarrow~&\1 & \invB(\hBool(\1,z))\rightarrow~&\1
  \end{align*}

  In particular \(\R\) is subterm and destructor, the destructor symbols being \(\pi\), \(\invN\) and \(\invB\).
  We will also use a shortcut for recursive subtree extraction:
  if \(\ell\) is a finite sequence of first-order terms, the notation \(\recpos t \ell\) is inductively defined by:
  \begin{align*}
    \recpos t \epsilon &\eqdef t & \recpos t {b \cdot \ell} &\eqdef\recpos{\pi(t,b)}\ell
  \end{align*}

\paragraph{Core of the reduction}
  Let us give the intuition behind the construction before diving into the formalism.
  Recall that we are studying a formula in CNF \(\sem\Gamma_\varphi\) with \(2^n\) variables and \(2^m\) clauses. In particular, given a valuation of its \( 2^n\) variables, we can verify in non-deterministic polynomial time in \(n,m\) that it falsifies \(\sem\Gamma_\varphi\):
  \begin{enumerate}
    \item guess an integer \(i\in\eint 0 {2^m-1}\) as a sequence of \(m\) bits;
    \item obtain the three literals of the \(i\)\textsuperscript{th} clause of \(\sem\Gamma_\varphi\) (requiring three runs of the circuit \(\Gamma\)) and verify that the valuation falsifies the disjunction of the three literals.
  \end{enumerate}

  \noindent This non-deterministic verification is the essence our reduction. In the actual processes:
  \begin{enumerate}
    \item a process \(\CheckTree x\) checks that \(x\) is a correct encoding of a valuation, that is, that \(x\) is a complete binary tree of height \(n\) whose leaves are booleans;
    \item a process \(\CheckSat x\) implements the points {\it 1.} and {\it 2.} above.
  \end{enumerate}

  All of this is then formulated as equivalence properties within \(A\) and \(B\) (see the intermediary lemmas in the next paragraph for details). Intuitively, we want to express the following statement by equivalence properties: ``{\it for all term \(x\), either \(x\) is not an encoding of a valuation or falsifies a clause of \(\sem\Gamma_\varphi\)}''.
  A schematised definition is proposed in Figure \ref{fig:nexp reduction}.


  \begin{figure}[!ht]
    \centering
    \scalebox{0.80}
    {
      \begin{tikzpicture}
        %% Node styles
        [
          op/.style={draw,circle,fill=cyan!50,minimum size=1.6em},
          test/.style={draw,rectangle},
          proc/.style={},
          title/.style={draw,rectangle,fill=cyan!50}
        ]
        %% Size reduction for tests
        \newcommand\size{0.9}

        %% Nodes
        \node(TitleA) [title] at (-1.5,0) {\(A\)};
        \node(InputA) [proc] at (-1.5,-1) {\(\InP c x\)};
        \node(SumCircleA) [op] at (-1.5,-2) {};
        \node(SumA) [proc] at (-1.5,-2) {\(+\)};
        \node(CallA) [proc] at (-3,-3) {\(\CheckSat x\)};
        \node(VerifA) [proc] at (0,-3) {\(\CheckTree x\)};

        \node(TitleB) [title] at (-1.5,-4.1) {\(B\)};
        \node(InputB) [proc] at (-1.5,-5.1) {\(\InP c x\)};
        \node(SumCircleB) [op] at (-1.5,-6.1) {};
        \node(SumB) [proc] at (-1.5,-6.1) {\(+\)};
        \node(CallB) [proc] at (-3,-7.1) {\(\CheckSat x\)};
        \node(VerifB) [proc] at (0,-7.1) {\(\CheckTree x\)};
        \node(OutputB1) [proc] at (-1.5,-8.1) {\(\OutP c {\hfun(\0,s)}\)};
        \node(OutputB2) [proc] at (-1.5,-9.1) {\(\OutP c {\hfun(\1,s)}\)};

        \node(TitleP) [title] at (4,0) {\(\CheckSat x\)};
        \node(ChooseP) [proc] at (4,-1) {\(\guessBinary{p_1,\ldots,p_m}\)};
        \node(Lit1) [proc] at (4,-2) {\(\evalFormula{b_1,\ell_1}{\Gamma(\vec p,\0,\1)}\)};
        \node(Lit2) [proc] at (4,-3) {\(\evalFormula{b_2,\ell_2}{\Gamma(\vec p,\1,\0)}\)};
        \node(Lit3) [proc] at (4,-4) {\(\evalFormula{b_3,\ell_3}{\Gamma(\vec p,\1,\1)}\)};
        \node(Eval) [proc] at (4,-5.8) {\(\evalFormula v {\left(\begin{array}{l}b_1=\recpos x {\ell_1}\\~\vee~ b_2=\recpos x{\ell_2}\\~\vee~b_3=\recpos x {\ell_3}\end{array}\right)}\)};
        \node(OutputP1) [proc] at (4,-7.6) {\(\OutP c {\hfun(v,s)}\)};
        \node(OutputP2) [proc] at (4,-8.6) {\(\OutP c {\hfun(\1,s)}\)};

        \node(TitleQ) [title] at (10,0) {\(\CheckTree x\)};
        \node(SumCircleQ) [op] at (10,-1) {};
        \node(SumQ) [proc] at (10,-1) {\(+\)};
        \node(VerifNode) [proc] at (8.2,-2) {\(\sum_{i=0}^{n-1}\)};
        \node(ChooseVN1) [proc] at (8.2,-3) {\(\guessBinary{p_1,\ldots,p_i}\)};
        \node(OutputVN1) [proc] at (8.2,-4) {\(\OutP c {\hNode(\recpos x {\vec p},s)}\)};
        \node(OutputVN2) [proc] at (8.2,-5) {\(\OutP c {\hfun(\1,s)}\)};
        \node(Invi)[fill,circle,scale=0.3] at (11.8,-2) {};
        \node(VerifBool) [proc] at (11.8,-3) {\(\guessBinary{p_1,\ldots,p_n}\)};
        \node(OutputVB1) [proc] at (11.8,-4) {\(\OutP c {\hBool(\recpos x {\vec p},s)}\)};
        \node(OutputVB2) [proc] at (11.8,-5) {\(\OutP c {\hfun(\1,s)}\)};

        %% Edges
        \draw[->>] (InputA) -- node[auto] {} (SumCircleA);
        \draw[->>] (SumCircleA) -- node[auto] {} (CallA);
        \draw[->>] (SumCircleA) -- node[auto] {} (VerifA);

        \draw[->>] (InputB) -- node[auto] {} (SumCircleB);
        \draw[->>] (SumCircleB) -- node[auto] {} (CallB);
        \draw[->>] (SumCircleB) -- node[auto] {} (VerifB);
        \draw[->>] (SumCircleB) -- node[auto] {} (OutputB1);
        \draw[->>] (OutputB1) -- node[auto] {} (OutputB2);

        \draw[->>] (ChooseP) -- node[auto] {} (Lit1);
        \draw[->>] (Lit1) -- node[auto] {} (Lit2);
        \draw[->>] (Lit2) -- node[auto] {} (Lit3);
        \draw[->>] (Lit3) -- node[auto] {} (Eval);
        \draw[->>] (Eval) -- node[auto] {} (OutputP1);
        \draw[->>] (OutputP1) -- node[auto] {} (OutputP2);

        \draw[->>] (SumCircleQ) -- node[auto] {} (VerifNode);
        \draw[-] (SumCircleQ) -- node[auto] {} (Invi);
        \draw[->>] (Invi) -- node[auto] {} (VerifBool);
        \draw[-,dotted] (VerifNode) -- node[auto] {} (ChooseVN1);
        \draw[->>] (ChooseVN1) -- node[auto] {} (OutputVN1);
        \draw[->>] (OutputVN1) -- node[auto] {} (OutputVN2);
        \draw[->>] (VerifBool) -- node[auto] {} (OutputVB1);
        \draw[->>] (OutputVB1) -- node[auto] {} (OutputVB2);
      \end{tikzpicture}
    }
    \caption{Informal definition of \(A\) and \(B\)}
    \label{fig:nexp reduction}
  \end{figure}

\paragraph{Formal construction}
  Let us now define the processes depicted in Figure \ref{fig:nexp reduction} properly; note that all the proofs about the correctness of this construction are relegated to Appendix \ref{app:termination} but we still state several intermediary lemmas in order to highlight the proof structure.
  But first of all, let us give a name to a frame which is at the core of our reduction:
  \[\Phi_\0=\{\ax_1\mapsto\hfun(\0,s),~\ax_2\mapsto\hfun(\1,s)\}\]

  \(\Phi_\0\) is reached after executing the central branch of \(B\) and everything is about knowing under which conditions a frame statically equivalent to \(\Phi_\0\) can be reached in \(A\). Let us define the processes themselves now. We fix \(s\in\Nall\) and define, if \(x\) is a protocol term:
  \begin{align*}
    \CheckTree x \eqdef~& \displaystyle\sum_{i=0}^{n-1}\left(~\guessBinary{p_1,\ldots,p_i}.~\OutP c {\hNode(\recpos x{p_1\cdots p_i},s)}.~\OutP c {\hfun(\1,s)}~\right)\\
    & + \guessBinary{p_1,\ldots,p_n}.~\OutP c {\hBool(\recpos x{p_1\cdots p_n},s)}.~\OutP c {\hfun(\1,s)}
  \end{align*}


  \begin{proposition}[restate=propCorrectnessChecktree,name={correctness of the tree checker}]
    \label{prop:correctness checktree}
    Let \(x\) be a message which is not a complete binary tree of height \(n\) with boolean leaves.
    Then there exists a reduction \(\CheckTree x\Cstep {\epsilon} (\multi P,\emptyset)\) such that \(P \LabBis \OutP c {\hfun(\0,s)}.\, \OutP c {\hfun(\1,s)}\).
  \end{proposition}

  \noindent
  Now let us move on to \(\CheckSat x\). This process binds a lot of variables:
  \begin{enumerate}
    \item \(\vec p=p_1,\ldots,p_m\) models the non-deterministic choice of a clause number in \(\eint 0 {2^m-1}\);
    \item \(b_i,\ell_i\), \(i\in\eint 1 3\), where \(\ell_i\) is a sequence of \(n\) variables, model the literals of the clause chosen above (\(b_i\) is the negation bit and \(\ell_i\) the identifier of the variable);
    \item \(v\) stores whether the chosen clause is satisfied by the valuation modelled by \(x\).
  \end{enumerate}
  \[\begin{array}{rl}
    \CheckSat x\eqdef~&\guessBinary{\vec p}.\\
    &\evalFormula{b_1,\ell_1}{\Gamma(\vec p,\0,\1)}.\\
    &\evalFormula{b_2,\ell_2}{\Gamma(\vec p,\1,\0)}.\\
    &\evalFormula{b_3,\ell_3}{\Gamma(\vec p,\1,\1)}.\\
    &\evalFormula v {(b_1=\recpos x{\ell_1} \vee~ b_2=\recpos x{\ell_2} \vee~ b_3=\recpos x{\ell_3})}.\\
    &\OutP c{\hfun(v,s)}.\OutP c{\hfun(\1,s)}
  \end{array}\]

  \begin{proposition}[restate=propCorrectnessChacksat,name={correctness of the sat checker}]
    \label{prop:correctness checksat}
    Let \(x\) be a complete binary tree of height \(n\) whose leaves are booleans, and \(\val_x\) be the valuation mapping the variable number \(i\) of \(\sem\Gamma_\varphi\) to \(\recpos x {p_1 \cdots p_n} \in \B\) where \(p_1 \cdots p_n\) is the binary representation of \(i\) (i.e., \(i = \sum_{k=1}^np_k2^{k-1}\)).
    If \(\val_x\) does not satisfy \(\sem\Gamma_\varphi\) then there exists \(\CheckSat x \Cstep \epsilon P\) such that \(P \LabBis \OutP c {\hfun(\0,s)}.\, \OutP c {\hfun(\1,s)}\).
  \end{proposition}

  We can finally wrap up everything by defining \(A\) and \(B\) and stating the last part of the correctness theorem.
  We recall that all the proofs can be found in Appendix \ref{app:termination}.
  \begin{align*}
    A\eqdef~&\InP c x.(\CheckSat x ~+~ \CheckTree x)\\
    B\eqdef~&\InP c x.(\CheckSat x ~+~ \CheckTree x ~+~ \OutP c {\hfun(\0,s)}.\OutP c {\hfun(\1,s)})
  \end{align*}

  \begin{proposition}[restate=propCorrectnessCheckall,name={correctness of the reduction}]
    \label{prop:correctness checkall}
    For any equivalence relation \({\approx} \in \{\Simi,\TraceEq,\LabBis\}\), \(\sem\Gamma_\varphi\) is satisfiable \textit{iff} \(A\not\approx B\).
  \end{proposition}

  As a conclusion we obtain the co\nexp hardness of equivalence properties (and their respective pre-orders as a consequence) for constructor-destructor subterm convergent theories.
  This is stated by the theorem below, which additionally puts an emphasis on the fact that the rewriting system used in our reduction is constant, that is, it does not depend on \(\Gamma\).

  \begin{theorem}[restate=thmDeepsecHardness,name={hardness of equivalences}] \label{thm:conexp-finite}
    There exists a fixed constructor-destructor subterm convergent rewriting system \(\R\) such that the decision problems \(\R\)--\TraceEquiv, \(\R\)--\TraceInclus, \(\R\)--\Simulation, \(\R\)--\Similarity and \(\R\)--\Bisimilarity are co\nexp hard for bounded positive processes.
  \end{theorem}

