\section{Crowdsourcing study}

Then, we conducted our formal study. We chose crowdsourcing to collect user data concerning the affective arousal elicited by data visualization design and explore design-arousal relationships.

\subsubsection{Methodology}

We recruited 184 participants from Prolific who speak English as their first language and have correct vision. We rejected the data from ten participants, as they misunderstood the study task (\eg failed to understand why the texts were blurred and kept complaining about the legibility) or provided data with poor quality (\eg giving all the images the same ratings without explaining why). The remaining 174 participants included 98 females, 75 males, and one identified as non-binary. Their ages ranged from 18 to 78 (\textit{M} = 38.47, \textit{SD} = 13.79), and their educational levels varied (Less than a high school diploma: 0.57\%, High school or equivalent: 31.03\%, Bachelor or equivalent: 48.28\%, Master or equivalent: 16.09\%, Doctoral or equivalent: 4.02\%).
The participants were paid \$9 per hour. 
% and up to \$1 bonus if they answered the questions very carefully

The study procedure of the crowdsourcing study was identical to the pilot study. The participants first read an introduction page, then viewed 20 data visualizations (one at a time), rated arousal and valence, wrote down reasons for their ratings, and rated how they liked the designs. After viewing and rating all 20 images, the participants filled out a form to provide their demographic information and wrote down what design features they thought contributed to arousal and valence, respectively. 
The participants spent 22.34 minutes on average completing this study.


\subsection{\x{Analyses and Results}}

We got 3480 valid ratings for the 265 images, \x{including 1101 for the Infographic category, 1052 for the News Media category, and 1327 for the Government category}. Each image received 13.13 ratings on average.
% data rescale

\subsubsection{\x{Descriptive Analysis}}

\begin{figure}[b]
 \centering % avoid the use of \begin{center}...\end{center} and use \centering instead (more compact)
 \includegraphics[width=\columnwidth]{Figures/compare.jpg}
 \caption{How the ratings of affective arousal distributed in different groups, including image categories, gender, age, and education level. Dashed lines represent means.}
 \label{fig:mean_comparison}
\end{figure}

\begin{figure*}[!t]
  \centering
  \includegraphics[width=\linewidth]{Figures/teaser.jpg}
  \caption{Five designs that received the highest scores in affective arousal (H1 to H5) and five designs that received the lowest scores (L1 to L5) in our study. The scores range from 0 to 1, where 0 means not aroused and 1 means strongly aroused. All texts were blurred.}
	\label{fig:teaser}
\end{figure*}

\paragraph{Consistency of Ratings}

\x{We examined whether people formed consistent judgments on the arousing level of the images.
% The standard deviation of ratings for a single infographic ranges from 0.95 to 3.27 (\textit{M} = 2.15). 
% Since the least-viewed infographic has been rated 8 times, we extracted 8 ratings for every image and calculated the ICC.
We used intraclass correlation coefficients (ICC) to calculate the agreement in user ratings, and the result showed that the agreement was moderate (ICC1k = .589, 95\% CI = [.512, .658], \textit{p} < .001), suggesting that users held moderately similar judgments on affective arousal.}
% Then, we examined the ratings between different demographic groups (\ie gender, age, and education level). 
% % We used Kruskal Wallis H tests to compare ratings from different demographic groups.
% %Results showed that females had a slightly higher agreement on affective arousal (ICC2k = 0.5901) than males (ICC2k = 0.5568), but 
% Kruskal Wallis H tests showed that there was no significant difference between the ratings set by females, males, and non-binary people (\textit{p} = .87).
% Also, there was no significant difference between the ratings set by different age groups (split into <=25, 25-34, 34-45, 45-55, 55-65, and >65, \textit{p} = .33).
% However, we observed that the ratings from the participants without a high school diploma were significantly higher than that of people with a bachelor's degree (\textit{p} = .016) or with other degrees (\textit{p} = .006). But since the sample size of this group is small (7 participants), the finding should be taken cautiously.
% The above results indicate that in general, people can form a consistent perception of affective arousal when viewing infographic design. 
% In other words, despite the noise introduced by participant variability, affective arousal is somehow intrinsic to infographic design.

% % suggesting that the perception of colorfulness and visual complexity is more or less universal. People as a whole seem to make very similar judgments on these website characteristics, independent of their demographic background.
% % However, the Mann-Whitney’s U test result does not show any significant effect of user gender (Z = -1.157, p = 0.118, r = 0.51), while males tend to rate the perceived personality slightly higher (Mean = 2.52, SD = 1.00) than females (Mean = 2.47, SD = 1.09). In contrast to the past finding which stresses the gender effect on user assessment of UIs, e.g., females like colorful websites more than male [46], our study indicates that men and women may have similar perception towards the brand personality traits of mobile UIs. One possible interpretation is that the apps we pick are not gender-specific to have male and female users form different impressions.


\paragraph{Means \& Distributions Comparison}

Overall, the average arousal score of all the images was 0.53 (\textit{SD} = 0.23, 95\% CI = [0.52, 0.54]). \x{The distribution of the arousing levels of the images was close to a normal distribution}.
However, as shown in Fig.~\ref{fig:mean_comparison}, the means and distributions of affective arousal varied in different groups.
For example, the mean arousal of the \textit{Infographic} category was 0.61, higher than that of the \textit{News Media} category (\textit{M} = 0.53) and the \textit{Government} category (\textit{M} = 0.48). A Kruskal-Wallis H Test further showed that the difference was significant (\textit{H}(2) = 211.866, \textit{p} < .001). Dunn’s post-hoc test with a Bonferroni correction showed that the mean arousal of \textit{Infographic} was significantly higher than that of \textit{News Media} and \textit{Government} (\textit{p} < .001), and the mean arousal of \textit{News Media} was significantly higher than that of \textit{Government} (\textit{p} < .001).

We also examined the arousal scores set by different age, gender, and education groups. First, a Mann-Whitney U Test (\textit{z} = -.886, \textit{p} = .376) showed that there was no significant difference between the scores set by females and by males ("Non-binary" was not included because its sample size was too small). Then, we assigned the participants into 5 age groups (<=25, 26-35, 36-45, 46-55, >56) and compared the mean scores of arousal set by these groups. As shown in Fig.~\ref{fig:mean_comparison}, the mean arousal scores set by different age groups interestingly decreased with the increasing age. A Kruskal-Wallis H Test combined with a post-hoc test further showed that the difference was significant (\textit{H}(4) = 32.072, \textit{p} < .001) and mainly caused by the lower mean (\textit{M} = 0.48) of group 5 (age > 56). In other words, in our study, the younger participants were more aroused by the stimuli while the elder participants were generally calmer. A significant difference (\textit{H}(3) = 22.838, \textit{p} < .001) also existed in the scores given by participants with different education levels ("Less than a high school diploma" not included because its sample size was too small), mainly caused by the higher scores set by participants with a "Doctoral or equivalent" degree (\textit{M} = 0.60).
% gave significantly highest scores than participants with a "Master or equivalent" degree (\textit{p} < .001), "Bachelor or equivalent" degree (\textit{p} = .010), and "High school or equivalent" degree (\textit{p} = .002).
However, this finding should be taken cautiously since the sample size of "Doctoral or equivalent" was not big (7 participants).




We also calculated the mean arousal score for each image. Fig.~\ref{fig:teaser} shows the five images that received the highest scores in affective arousal and the five images that received the lowest scores. In line with the above findings, the top ranked images all belong to the \textit{Infographic} category (Fig.~\ref{fig:teaser} H1-H5) while the low-ranking images mostly belong to the \textit{Government} and \textit{News Media} categories (Fig.~\ref{fig:teaser} L2-L5).

\begin{figure}[t]
 \centering 
 \includegraphics[width=\columnwidth]{Figures/association.jpg}
 \caption{The relationships between (a) arousal and valence (\textit{$\tau$} = .592), (b) arousal and likability (\textit{$\tau$} = .539), and (c) valence and likability (\textit{$\tau$} = .736).}
 \label{fig:association}
\end{figure}

\paragraph{Correlation Analysis}

Then, we examined the correlations between affective arousal, valence, and likability \x{to see whether an arousing design will be pleasing or favorable}. Fig.~\ref{fig:association} plots the mutual relationships between these three variables. It can be seen from the figure that they generally showed a positive correlation with each other.
Given that likability is an ordinal variable and all the three variables are non-normal, we used Kendall's Tau (\textit{$\tau$}) to compute their correlation coefficients and significance levels. The results confirmed that arousal was positively correlated with likability (\textit{$\tau$} = .539, \textit{p} < .001), so as valence and likability \textit{($\tau$} = .736, \textit{p} < .001), whose positive correlation was even stronger. Besides, arousal and valence also showed a moderately positive correlation with each other (\textit{$\tau$} = .592, \textit{p} < .001). Note that these correlations still held when we conducted the correlational tests within different image categories.
% (\ie Infographic, News Media, Government).

To sum up, in general, high arousal was likely to co-occur with pleasure and high likability. However, there were also cases when arousal did not lead to pleasure or when arousal hindered likability. For example, as shown in Fig.~\ref{fig:association}, some participants set scores to  "high arousal + displeasure" or "high arousal + low likability". We will discuss such situations in detail in Section 5.2.


\begin{figure}[!b]
 \centering % avoid the use of \begin{center}...\end{center} and use \centering instead (more compact)
 \includegraphics[width=\columnwidth]{Figures/codes.jpg}
 \caption{\x{Arousal-related features reported by the participants in our crowdsourcing study. The codes about color, graphics, and information are mapped to computable variables in Section 4.1.3.1. The high-level strategies are discussed in Section 5.1.}}
 \label{fig:themes}
\end{figure}

\subsubsection{Qualitative Analysis}

As stated above, at the end of the user study, we asked the participants to write down what design features had helped augment their affective arousal. This resulted in 174 comments that suggest arousal-related design features from the perspective of users.


Then, we conducted an in-depth qualitative analysis on these 174 comments following the bottom-up procedure of thematic analysis~\cite{braun2006using}. Two of the authors first went through all the user comments and took notes on the messages deemed useful. 
Then, they coded the comments independently and generated possible themes by grouping the codes.
After that, they met to compare codes and discuss mismatches.
Through iterative discussions, they generated three themes most commonly mentioned by the participants, including \textit{color}, \textit{graphics}, and \textit{information}.
Then, they assigned the low-level codes into these three themes and discussed whether to retain, modify, or merge the codes. 
For example, when describing colors that had strong visual impact, the participants used different expressions such as \textit{strong color}, \textit{vibrant color}, and \textit{bold color}. Therefore, these similar expressions were merged into one code, namely \textit{strong color}. 
It was also noticed that some codes described high-level design strategies rather than specific design features. For example, \textit{simplicity} can mean simple colors, simple visualization design, or a small amount of data. \textit{Unusualness} can refer to unusual color, unusual shape, or unusual visual encodings.
Therefore, such codes were categorized into another theme called \textit{high-level strategies}.
After iterative discussions, the coders achieved a 100\% agreement. At last, they generated 412 codes from the 174 comments in total. 
The frequencies of all the codes were analyzed and the result visualized, as in Fig.~\ref{fig:themes}. Note that for the clarity of presentation, codes that occurred only once were excluded. Collectively, the codes visualized in Fig.~\ref{fig:themes} constitute 92.72\% of all the codes. Thus, they are highly representative of all the arousal-related design features written down by the participants.
% We revisit these codes in Section 5.2 when we discuss high-level design strategies for eliciting affective arousal.



As shown in Fig.~\ref{fig:themes}, \textit{color} and \textit{graphics} were the most mentioned themes. Within the theme of color, 49 codes only broadly referred to \textit{color} as a contributor to affective arousal. Apart from this, \textit{bright color} (28), \textit{colorfulness} (25), \textit{strong color} (14), and \textit{contrast} (13) were the most frequently-mentioned specific color features.
Within the theme of graphics, \textit{visualization type} (54), \textit{layout} (17), \textit{shape} (16), and \textit{density} (11) were the most frequently-mentioned features.
Within the theme of information, 11 codes talked about \textit{information amount} in a broad sense, while six codes specifically referred to \textit{text amount} and five codes specifically referred to \textit{data amount}. 
% Besides, \textit{information complexity} was also mentioned six times.
Last, with the theme of high-level strategies, \textit{unusualness} (37), \textit{simplicity} (17), and \textit{easy reading} (15) were most mentioned. Besides, \textit{clarity} (9), \textit{aesthetics}(9), \textit{complexity} (5), and \textit{boldness}(4) were also repeatedly mentioned.

% The above codes served as the basis for selecting computational metrics for the model presented in the next section.



\subsubsection{\x{Inferential Analysis}}

\x{Then, we sought to predict the user ratings for affective arousal using these codes and identify the most significant design features.
% However, since these high-level strategies are more or less ambiguous in meaning and can refer to multiple objects, we did
For each of the codes about color, graphics, and information in Fig.~\ref{fig:themes}, we reviewed previous literature in relevant fields (\eg computer vision, multimedia) to find the mature and commonly-used methods to map these codes to computable variables.
Below we first introduce these features briefly, then report the modeling process.}


\paragraph{\x{Design Features}}
The mappings are summarized in Table.~\ref{tab:features}.
% In line with Fig.~\ref{fig:themes}, we extracted three types of design feature from the images: color-based features, graphics-based features, and information-based features.

% To put all infographics into the same scale, we resized the infographics to make them all have a width of 500 pixels.

\begin{table*}[!t]
 \centering 
 \includegraphics[width=\textwidth]{Figures/features.pdf}
 \caption{\x{The mappings from qualitative codes to variables. For variable types, N denotes nominal, C denotes continuous, and O denotes ordinal.}}
 \label{tab:features}
\vspace{-2em}
\end{table*}




\textbf{Color-based Features.}
\x{To translate the code \textit{chromatic color}, we used a nominal variable whose value is yes or no to depict whether a visualization design is achromatic. To translate the code \textit{background color} in Fig.~\ref{fig:themes}, we coded the images' background colors manually and found that white and black were the dominant choices. Therefore, this code was translated into a nominal variable whose value can be white, black, or others. For codes that can be measured as continuous variables, such as \textit{bright color}, \textit{strong color}, \textit{colorfulness}, and \textit{contrast}, we referred to prior literature~\cite{machajdik2010affective,reinecke2013predicting} and extracted corresponding design features, such as calculating the mean and standard deviation of the S (\ie saturation) and V (\ie brightness) channels in the HSV color space using OpenCV, computing colorfulness using the algorithm proposed by Hasler~\etal~\cite{hasler2003measuring}, and calculating contrast using the RMS contrast algorithm~\cite{peli1990contrast}.
% by first transforming the images to grayscale and then calculating the standard deviation of each grayscale image.
Note that according to some comments, the participants' perception of brightness and saturation was also influenced by the dominant color, we also extracted the primary chromatic color of each image using Colorthief~\cite{colorthief} and calculated the mean and standard deviation of its saturation and brightness.}
% Last, we extracted features of color contrast. In the field of computer vision, contrast usually means the difference in luminance, deciding whether an image looks distinguishable or overcast. To compute this, we used the classic RMS contrast~\cite{peli1990contrast} by first transforming the images to grayscale and then calculating the standard deviation of the grayscale image.
% Among these features, the color hue is more special, because it is a circular variable ranging from 0 degrees to 360 degrees. Such non-linearity makes it difficult to be computed nor interpreted (\eg both 0 degrees and 360 degrees denote red). To deal with this issue, on the one hand, we used circular statistics in SciPy to calculate the mean of hue; on the other hand, we transformed the mean of hue into a nominal variable according to where the hue is located in the hue ring composed by the three primary colors of light: red, green, and blue (\eg 120 degrees fall into the area of green).
% To obtain these features, we transformed the images into CIE L\text{*}C\text{*}h color space, which defines color in a way that most resembles human perception. Then, we calculated the mean and standard deviation of the L (\ie brightness), C (\ie saturation), and H (\ie hue) channel, respectively. 
% We also computed a compound feature co-shaped by saturation and brightness (-.31 $\times$ brightness + .60 $\times$ saturation), which was proved to be associated with affective arousal according to ~\cite{valdez1994effects}.
Last, we translated the code \textit{color hue} using the algorithm proposed by van de Weijer~\etal~\cite{van2007learning}. This algorithm can identify and calculate the percentages of 11 nameable color hues (\ie black, blue, brown, green, gray, orange, pink, purple, red, white, yellow) in images. 
% This helped us look deeper into which specific hues have been used.
% We also grouped blue, green, and purple as cold colors, brown, orange, pink, red, and yellow as warm colors, and calculated the percentages of warm colors and cold colors.
% However, we also noticed that in our study, by saying color contrast, some participants wanted to emphasize the perceived contrast between hues, namely how complementary the colors are.
% % This is in accordance with prior research that contrasting colors are usually felt more energetic than homogeneous colors~\cite{}.
% Thus, for each image, we first changed the color space to RYB (in fine arts, designers usually select complementary color in the RYB color space, which is constructed by three primary pigments: red, yellow, blue), then calculated the maximum and mean value of how far each primary achromatic color in the palette is from the complementary colors of the other primary achromatic colors in the RYB color space.
% % In total, we obtained xx color-based features for analysis.


\textbf{Graphics-based Features.}
\x{
% As many of the codes in this theme have already been coded as tags in the \textit{targets410} dataset (detailed tags were enclosed in ~\cite{borkin2013makes}), when mapping these codes to variables, we 
As two codes in this theme (\textit{visualization type}, \textit{shape}) were closely related to how data was visualized into graphical elements, we used five features to depict the visual encodings of the visualizations. 
First, following the typology in ~\cite{borkin2013makes}, data visualizations were categorized into 12 types (\eg \textit{bar}, \textit{area}, \textit{map}, \textit{circle}) and a set of subtypes (\eg \textit{grouped bar chart} and \textit{stacked bar chart} in the category of \textit{bar}; \textit{pie chart} and \textit{donut chart} in the category of \textit{circle}).
% However, a shortcoming of these taxonomies is that they cannot characterize the specific data encodings of a visualization, which are fundamental to visualization design. 
In addition, we used variables to characterize which data marks (\eg \textit{bar}, \textit{line}, \textit{geoshape}), visual channels (\eg \textit{position}, \textit{size}, \textit{shape}), and layout (\eg \textit{X and Y coordinates}, \textit{grid}, \textit{polar coordinate}) had been used according to existing taxonomies~\cite{satyanarayan2016vega,munzner2014visualization}.
For example, H4 in Fig.~\ref{fig:teaser} was characterized as a visualization type called \textit{area} and a subtype called \textit{proportional area chart}. The shape of its data marks is \textit{circle}, and the overall shape of this visualization is also circular because it organizes the marks using a \textit{polar coordinate}. Two visual channels (\textit{color} and \textit{position}) have been used to encode data. 
% With these variables, we can characterize the graphical features of a data visualization at different granularities.
% complemented coding the images with a set of additional features, including
For the remaining qualitative codes in this theme, we mapped \textit{multiplicity}, which defines whether the visualization is stand-alone or somehow grouped with other visualizations, to categories such as \textit{single}, \textit{grouped}, and \textit{multi-panel}~\cite{borkin2013makes}.
% Since most images in our corpus came from the \textit{targets410} dataset, in which the images have already been labeled with the above features, we kept these labeled data and performed complement labeling of all the other images following the coding guidelines provided by Borkin~\etal~\cite{borkin2013makes}.
We mapped \textit{annotation} and \textit{3D} to nominal variables ([\textit{yes}, \textit{no}]) and computed \textit{density} by calculating the white space (the percentage of the background color) of each image.}
% according to Fig.~\ref{fig:themes}, 
% the overall shape
% sizing: text size
% To quantify the appearance of the texts, we identified the biggest and the smallest characters used in each infographic and calculated their sizes. We also calculated the text size contrast for each infographic by dividing the size of the biggest character by the size of the smallest character.


\textbf{Information-based Features.}
Information-based features concern the cognitive load of viewing a data visualization and can be further split into two main types: texts and data.
% concern the amount and the complexity of the information a viewer needs to process. 
First, although all the texts had been blurred, \x{several participants stated that they could still “feel” that there were a lot of texts to be read and this had also impacted their arousal.}
Therefore, we used Tesseract-OCR~\cite{smith2007overview} to identify the texts on the images, manually revised inaccurate identifications, and then counted how many words each image contained and the word density on each image by dividing the word amount by the size of the image. 
Next, to quantify the amount of data, we counted how many visual channels were used in each image in total, as well as how many distinct visual channels were used. We also counted the number of data marks in each image and how many distinct data marks were used. For example, Fig.~\ref{fig:teaser} H2 only has eight data marks while H4 contains more than 100 data marks, but both of them only used one type of data mark, namely \textit{circle}. 
In some images, the data marks were too many to be counted precisely (\eg thousands of overlapping dots), therefore, we transformed this feature into a nominal variable with three categories (\textit{<10}, \textit{10-100}, \textit{>=100}).
\x{Last, we used an ordinal variable, data-ink ratio ([\textit{good}, \textit{medium}, \textit{bad}])~\cite{borkin2013makes}, to characterize the cognitive load brought by information that was neither texts nor data (\eg axis ticks, gridlines).}
% By collecting these features, we were able to assess the cognitive load of decoding a data visualization.

% By coding the above features, we were able to comprehensively depict how a data visualization is designed through computational features.

\begin{figure*}[!t]
 \centering
 \includegraphics[width=\textwidth]{Figures/features_compare.jpg}
 \caption{\x{Comparing the important features suggested by different models. Note that the Multiple Linear Regression Model indicates importance through statistical significance (p-values) and standardized coefficients, while Random Forest and Decision Tree suggest key features through Gini importance. ${R}^2$ and MSE show the model performance, where ${R}^2$ (the coefficient of determination) represents the proportion of the variance explained, and MSE (mean squared error) measures the difference between the original and predicted values.}}
 \label{fig:features_compare}
 \vspace{-1em}
\end{figure*}

\paragraph{Modeling affective arousal}
\x{Based on the extracted features, we tried five widely used predictive models to explore important moderators of affective arousal. Three are linear models (Multiple Linear Regression, Ridge Regression, Lasso Regression) and two are ensemble models (Random Forest, Decision Tree). These models can help us estimate the relationship between affective arousal and design features while interpreting which features are contributing to the relationship.}
% random forest regression.
% According to the cross-validation result, we set the depth of RF as 5
The dependent variable is the mean arousal scores of the 265 images, and the design features of the 265 images we extracted in Table.~\ref{tab:features} are independent variables.
%数据预处理
During the data pre-processing stage, first, we checked and revised empty and mistaken values.
% Then, we examined the distributions of all the variables. For variables whose distributions were highly skewed, we used Box-Cox power transformation to make them more evenly distributed.
Then, for all nominal variables, we used the one-hot encoder in SciPy to transform them into a set of binary variables that use 1 and 0 to indicate the presence or absence of a category~\cite{garcia2015data}.
% word amount, trim outliers / log transformation
Next, we tried re-scaling the raw arousal scores set by each participant before calculating the mean arousal score received by each image. This step was done because we noticed from both the pilot study and the crowdsourcing study that the participants showed varied rating habits. For example, even with a very similar judgment of a design, some participants tended to set higher scores to arousal (\eg 0.95) while some thought 0.70 or 0.80 were already high scores. In other words, the participants' criteria of rating affective arousal were differently-ranged. Therefore, re-scaling the ratings helped mitigate the influence of rating habits and revealed the real judgments of all the participants. Specifically, we tried two common means of re-scaling, including the z-score normalization and the Min-Max normalization~\cite{garcia2015data}. 
%  In other words, for each participant, the highest score he/she set for arousal was scaled to 1, and the lowest score was scaled to 0.
When constructing the models, we tested the performance of the two re-scaled dependent variables as well the un-scaled version. Results showed that the z-score normalization method performed the best. Therefore, we adopted this version of dependent variable when constructing the final models.

%加一段pearson correlation analyses?
After data pre-processing, we used Pearson correlation coefficients to get an initial understanding of the correlations between the independent variables and the dependent variable.
Results showed that features such as the \textit{number of different visual channels} (\textit{r} = 0.52, \textit{p} < .001), \textit{colorfulness} (\textit{r} = 0.48, \textit{p} < .001), and \textit{standard deviation of saturation} (\textit{r} = 0.46, \textit{p} < .001) had a significantly positive relationship with affective arousal, while features such as \textit{X-Y coordinates layout} (\textit{r} = -0.61, \textit{p} < .001), \textit{table visualization} (\textit{r} = -0.52, \textit{p} < .001), and \textit{percentage of white} (\textit{r} = -0.49, \textit{p} < .001) had a significantly negative relationship with affective arousal. High correlations also exist between some design features. For example, the \textit{percentage of white} was highly correlated with \textit{mean brightness} (\textit{r} = 0.82, \textit{p} < .001). \x{These correlations were referred to when performing feature selection to prevent the overfitting problem.}

\x{Next, we fed the variables into the five models one by one. To enhance the validity of results, we adopted the idea of machine learning and split the dataset into a training set (70\%) and a test set (30\%) using Sklearn. When splitting the dataset, we also guaranteed that the distribution of the values of arousal in the test set was similar to that of the training test, which was close to a normal distribution. Then, we fed the training set to the models and evaluated the goodness of fit using the test set. }

\x{\textbf{Linear Models.}
For the Multiple Linear Regression, we fine-tuned the models by (1) fitting the models using a stepwise approach to drop redundant features;} (2) conducting multicollinearity diagnostics using the Variance Inflation Factor (VIF). A VIF above 10 implies serious multicollinearity and a VIF above 5 is usually deemed problematic~\cite{james2013introduction};
% a VIF below 10 is acceptable
(3) Ensuring that there was no autocorrelation problem using the Durbin-Watson test (0 < DW < 2); (4) Ensuring that the residuals were normally distributed by conducting the Anderson-Darling test and plotting a histogram for residuals. 
\x{For the Lasso Regression and Ridge Regression, we used five-fold cross-validation to identify the optimal values of their key parameter, alpha (\ie the strength of regularization). As a result, we found that in our case, the optimal alpha values for these two models were 0, which made their results identical to that of the Multiple Linear Regression.} 

\x{As shown in Fig.~\ref{fig:features_compare}, the Multiple Linear Regression yielded 11 statistically significant features. Seven features showed a significantly positive correlation with affective arousal, including \textit{colorfulness} ($\beta$ = .329, \textit{t} = 7.536, \textit{p} < .001), \textit{the number of different visual channels} ($\beta$ = .299, \textit{t} = 5.828, \textit{p} < .001), \textit{visualization subtype = heatmap} ($\beta$ = .141, \textit{t} = 3.013, \textit{p} = .003), \textit{layout = geo} ($\beta$ = .138, \textit{t} = 2.588, \textit{p} = .010), \textit{percentage of black} ($\beta$ = .131, \textit{t} = 2.957, \textit{p} = .004), \textit{visualization type = circle} ($\beta$ = .131, \textit{t} = 2.886, \textit{p} = .004), and \textit{number of data marks >= 100} ($\beta$ = .113, \textit{t} = 2.531, \textit{p} = .012).
On the other hand, four features showed a significantly negative correlation with affective arousal, including \textit{layout = grid} ($\beta$ = -.435, \textit{t} = -7.279, \textit{p} < .001), \textit{layout = X and Y coordinates} ($\beta$ = -.153, \textit{t} = -2.360, \textit{p} = .019), \textit{channel = texture} ($\beta$ = -.136, \textit{t} = -3.034, \textit{p} = .003), and \textit{visualization subtype = stacked bar} ($\beta$ = -.085, \textit{t} = -2.020, \textit{p} = .045). The training set explained 72.6\% of the variance in the dependent variable (${R}^2$ = .726, MSE = .071), and the test set explained 67.0\% (${R}^2$ = .670, MSE = .099).}

\x{\textbf{Ensemble Models.}
For ensemble models, we first identified the optimal hyperparameters (\eg max depth) for the models by performing five-fold cross-validation within a grid of hyperparameter ranges. We also fine-tuned the hyperparameters by observing the performance of the training set and the test set to avoid overfitting. % For example, if the ${R}^2$ of the test set was significantly lower than that of the training set, the overfitting problem may be present. 
At last, the Random Forest model had a max depth of 2. After iterating 1000 times, the average ${R}^2$ of the training set was .644 (MSE = .092), and the average ${R}^2$ of the test set was .595 (MSE = .122). 
The Decision Tree model had a max depth of 3. The average ${R}^2$ of the training set was .668 (MSE = .085), and the ${R}^2$ of the test set was .616 (MSE = .115). We also computed the Gini importance of the features in these two models and visualized high-ranking features in Fig.~\ref{fig:features_compare}. The most important features in the Random Forest model included the \textit{number of different visual channels} (Gini importance = .220), \textit{percentage of green} (.189), \textit{layout = X and Y coordinates} (.166), \textit{mean of saturation} (.103), \textit{layout = grid} (.065), \textit{colorfulness} (.048), \textit{percentage of white} (.042), \textit{visualization type = table} (.041), \textit{mark shape = text} (.017), and \textit{mark shape = circle} (.015). These 10 features collectively explained 90\% of the total importance. The most important features in the Decision Tree model included the \textit{number of different visual channels} (.424), \textit{layout = X and Y coordinates} (.241), \textit{colorfulness} (.130), \textit{percentage of white} (.075), \textit{mark shape = text} (.064), and \textit{layout = grid} (.062). These six features collectively explained 99\% of the total importance. 
}

\x{\textbf{Summary.}
By comparing the results in Fig.~\ref{fig:features_compare}, we found that four design features were collectively supported by all the models as the key moderators of affective arousal, including the \textit{number of different visual channels}, \textit{colorfulness}, \textit{layout = X and Y coordinates}, and \textit{layout = grid}. The first two features showed positive effects on affective arousal in all models, while the latter two features consistently showed a negative relationship with affective arousal. In other words, in our exploratory study, we found that the participants were more aroused by colorful visualizations with a certain amount of visual complexity. However, conventional layouts that put data in an upright and square space were less arousing.
We also noticed that there were features whose importance was not cross-validated by different models. For example, the \textit{percentage of green} showed high importance in the Random Forest model, but it was not important in other models. Such features are worthy of more investigation in the future.}


% Finally, apart from the Bayesian ARD Regression (adj. ${R}^2$ = .598, \textit{p} < .001), the other regression models yielded similar results. The Multiple Linear Model explained 69.8\% of the variance in the dependent variable (adj. ${R}^2$ = .698, \textit{p} < .001), while the Ridge Regression explained 69.8\% (adj. ${R}^2$ = .698, \textit{p} < .001), Lasso Regression explained 69.6\% (adj. ${R}^2$ = .696, \textit{p} < .001), and Bayesian Ridge Regression explained 69.8\% (adj. ${R}^2$ = .698, \textit{p} < .001).
% Since the main goal of this work was to infer what triggers affective arousal in data visualization design, we decided to use the Multiple Linear Regression model, which is easier to interpret, as our final model.

% The final regression model contains 13 independent variables and one constant.
% Fig.~\ref{fig:fit} visualizes the model's prediction in comparison with the affective arousal scores set by the participants in our crowdsourcing study.


% Among these 13 design features, four are color-based, seven are graphics-based, and two are information-based. We fed these features into the model separately and found that graphics-based features (adj. ${R}^2$ = .529, F(7, 257) = 43.28, \textit{p} < .001) explained most variance in user ratings for affective arousal, followed by color-based features (adj. ${R}^2$ = .382, F(4, 260) = 41.81, \textit{p} < .001) and information-based features (adj. ${R}^2$ = .321, F(2, 262) = 63.30, \textit{p} < .001).



% \begin{figure}[!t]
%  \centering
%  \includegraphics[width=\columnwidth]{Figures/fit.png}
%  \caption{The affective arousal scores predicted by the final model (y-axis) versus the scores set by the participants in the crowdsourcing study (x-axis). Adj. ${R}^2$ = .698.}
%  \label{fig:fit}
% \end{figure}






