% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage[]{emnlp2021}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath} % for \boldsymbol macro
\usepackage{color}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{latexsym}
\newcommand{\eg}{\textit{e.g.}}
\newcommand{\ie}{\textit{i.e.}}
\usepackage{times}
\usepackage{latexsym}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{tablefootnote}
\usepackage{color}
\usepackage{bbm}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage[normalem]{ulem}
\usepackage{url}
\usepackage{subcaption}
\usepackage{fdsymbol}
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.
\newcommand{\PET}{PET}
\newcommand{\La}{\mathcal{L}}
\newcommand{\ADAPET}{ADAPET}
\title{Prompt-based Text Entailment for Low-Resource Named Entity Recognition}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

% \author{

%     Dongfang Li \\
%     Harbin Institute of Technology (Shenzhen), Shenzhen, China \\\And
%     Baotian Hu \\\And
%     Qingcai Chen \\
%     % Hans Guesgen,
%     % Francisco Cruz,
%     % Marc Pujol-Gonzalez
%     % \\
% }
% \footnotemark[1]\thanks{\hspace{2mm}Co-corresponding authors}
\author{Dongfang Li$^1$, Baotian Hu$^1$\footnotemark[1]\thanks{\hspace{2mm}Corresponding authors}\hspace{2mm},  Qingcai Chen$^{1,2}$\footnotemark[1]\hspace{1mm}\\
$^1$Harbin Institute of Technology (Shenzhen), Shenzhen, China \\
$^2$Peng Cheng Laboratory, Shenzhen, China\\
\texttt{crazyofapple@gmail.com, \{hubaotian, qingcai.chen\}@hit.edu.cn}}

% \author{Dongfang Li$^1$, Qingcai Chen$^{1,2}$, Baotian Hu$^1$\\
% $^1$Harbin Institute of Technology (Shenzhen), Shenzhen, China \\
% $^2$Peng Cheng Laboratory, Shenzhen, China\\

% \texttt{crazyofapple@gmail.com, \{hubaotian, qingcai.chen\}@hit.edu.cn}}
% \affiliations{
%     %Afiliations

%     % \textsuperscript{\rm 1}Association for the Advancement of Artificial Intelligence\\
%     %If you have multiple authors and multiple affiliations
%     % use superscripts in text and roman font to identify them.
%     %For example,

%     \textsuperscript{\rm 1} Harbin Institute of Technology (Shenzhen), Shenzhen, China \\
%     \textsuperscript{\rm 2} Peng Cheng Laboratory, Shenzhen, China \\
%     crazyofapple@gmail.com, hubaotian@hit.edu.cn, qingcai.chen@hit.edu.cn
% }
\begin{document}
\maketitle
\begin{abstract}
%  To address learning challenges in these low-resource paradigms, researchers recently have interests in applying prompt-based learning into text classification and text generation. However, the application of prompt-based learning in the Named Entity Recognition (NER) task has not been fully explored. 
Pre-trained Language Models (PLMs) have been applied in NLP tasks and achieve promising results. Nevertheless, the fine-tuning procedure needs labeled data of the target domain, making it difficult to learn in low-resource and non-trivial labeled scenarios. To address these challenges, we propose Prompt-based Text Entailment (\texttt{PTE}) for low-resource named entity recognition, which better leverages knowledge in the PLMs. We first reformulate named entity recognition as the text entailment task. The original sentence with entity type-specific prompts is fed into PLMs to get entailment scores for each candidate. The entity type with the top score is then selected as final label. Then, we inject tagging labels into prompts and treat words as basic units instead of n-gram spans to reduce time complexity in generating candidates by n-grams enumeration.  Experimental results demonstrate that the proposed method \texttt{PTE} achieves competitive performance on the CoNLL03 dataset, and better than fine-tuned counterparts on the MIT Movie and Few-NERD dataset in low-resource settings.

\end{abstract}

\input{Introduction}
\input{Method}
\input{Exp}
\input{Conclusion}

\section*{Acknowledgements}
We thank the anonymous reviewers for their insightful comments and suggestions. This work is jointly supported by grants: Natural Science Foundation of China (No. 62006061,61872113,U1813215), Stable Support Program for Higher Education Institutions of Shenzhen (No. GXWD20201230155427003-20200824155011001) and Strategic Emerging Industry Development Special Funds of Shenzhen(No. JCYJ20200109113441941 and No. XMHT20190108009).
% Entries for the entire Anthology, followed by custom entries
\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}
\clearpage

% \appendix
\input{Appendix}

\end{document}
