@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{sallab2017deep,
  title={Deep reinforcement learning framework for autonomous driving},
  author={Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@InProceedings{pmlr-v97-fujimoto19a,
  title = 	 {Off-Policy Deep Reinforcement Learning without Exploration},
  author =       {Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2052--2062},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/fujimoto19a/fujimoto19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/fujimoto19a.html},
  abstract = 	 {Many practical applications of reinforcement learning constrain agents to learn from a fixed batch of data which has already been gathered, without offering further possibility for data collection. In this paper, we demonstrate that due to errors introduced by extrapolation, standard off-policy deep reinforcement learning algorithms, such as DQN and DDPG, are incapable of learning with data uncorrelated to the distribution under the current policy, making them ineffective for this fixed batch setting. We introduce a novel class of off-policy algorithms, batch-constrained reinforcement learning, which restricts the action space in order to force the agent towards behaving close to on-policy with respect to a subset of the given data. We present the first continuous control deep reinforcement learning algorithm which can learn effectively from arbitrary, fixed batch data, and empirically demonstrate the quality of its behavior in several tasks.}
}

@article{tejedor2020reinforcement,
  title={Reinforcement learning application in diabetes blood glucose control: A systematic review},
  author={Tejedor, Miguel and Woldaregay, Ashenafi Zebene and Godtliebsen, Fred},
  journal={Artificial intelligence in medicine},
  volume={104},
  pages={101836},
  year={2020},
  publisher={Elsevier}
}

@article{yu2021reinforcement,
  title={Reinforcement learning in healthcare: A survey},
  author={Yu, Chao and Liu, Jiming and Nemati, Shamim and Yin, Guosheng},
  journal={ACM Computing Surveys (CSUR)},
  volume={55},
  number={1},
  pages={1--36},
  year={2021},
  publisher={ACM New York, NY}
}

@article{kiran2021deep,
  title={Deep reinforcement learning for autonomous driving: A survey},
  author={Kiran, B Ravi and Sobh, Ibrahim and Talpaert, Victor and Mannion, Patrick and Al Sallab, Ahmad A and Yogamani, Senthil and P{\'e}rez, Patrick},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  year={2021},
  publisher={IEEE}
}

@article{fujimoto2021minimalist,
  title={A minimalist approach to offline reinforcement learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={20132--20145},
  year={2021}
}

@inproceedings{kostrikov2021offlinefisher,
  title={Offline reinforcement learning with  divergence critic regularization},
  author={Kostrikov, Ilya and Fergus, Rob and Tompson, Jonathan and Nachum, Ofir},
  booktitle={International Conference on Machine Learning},
  pages={5774--5783},
  year={2021},
  organization={PMLR}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International conference on machine learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}

@article{jaques2019way,
  title={Way off-policy batch deep reinforcement learning of implicit human preferences in dialog},
  author={Jaques, Natasha and Ghandeharioun, Asma and Shen, Judy Hanwen and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang and Picard, Rosalind},
  journal={arXiv preprint arXiv:1907.00456},
  year={2019}
}
@article{peng2019advantage,
  title={Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}
@article{siegel2020keep,
  title={Keep doing what worked: Behavioral modelling priors for offline reinforcement learning},
  author={Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:2002.08396},
  year={2020}
}

@article{nair2020accelerating,
  title={Accelerating online reinforcement learning with offline datasets},
  author={Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}
@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and Zolna, Konrad and Merel, Josh S and Springenberg, Jost Tobias and Reed, Scott E and Shahriari, Bobak and Siegel, Noah and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7768--7778},
  year={2020}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@inproceedings{bai2021principled,
  title={Principled exploration via optimistic bootstrapping and backward induction},
  author={Bai, Chenjia and Wang, Lingxiao and Han, Lei and Hao, Jianye and Garg, Animesh and Liu, Peng and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={577--587},
  year={2021},
  organization={PMLR}
}

@article{bai2022pessimistic,
  title={Pessimistic bootstrapping for uncertainty-driven offline reinforcement learning},
  author={Bai, Chenjia and Wang, Lingxiao and Yang, Zhuoran and Deng, Zhihong and Garg, Animesh and Liu, Peng and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2202.11566},
  year={2022}
}

@article{wu2021uncertainty,
  title={Uncertainty weighted actor-critic for offline reinforcement learning},
  author={Wu, Yue and Zhai, Shuangfei and Srivastava, Nitish and Susskind, Joshua and Zhang, Jian and Salakhutdinov, Ruslan and Goh, Hanlin},
  journal={arXiv preprint arXiv:2105.08140},
  year={2021}
}

@article{an2021uncertainty,
  title={Uncertainty-based offline reinforcement learning with diversified q-ensemble},
  author={An, Gaon and Moon, Seungyong and Kim, Jang-Hyun and Song, Hyun Oh},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={7436--7447},
  year={2021}
}

@article{auer2008near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Auer, Peter and Jaksch, Thomas and Ortner, Ronald},
  journal={Advances in neural information processing systems},
  volume={21},
  year={2008}
}

@article{osband2016deep,
  title={Deep exploration via bootstrapped DQN},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@inproceedings{o2018uncertainty,
  title={The uncertainty bellman equation and exploration},
  author={O’Donoghue, Brendan and Osband, Ian and Munos, Remi and Mnih, Volodymyr},
  booktitle={International Conference on Machine Learning},
  pages={3836--3845},
  year={2018}
}

@inproceedings{mavrin2019distributional,
  title={Distributional reinforcement learning for efficient exploration},
  author={Mavrin, Borislav and Yao, Hengshuai and Kong, Linglong and Wu, Kaiwen and Yu, Yaoliang},
  booktitle={International conference on machine learning},
  pages={4424--4434},
  year={2019},
  organization={PMLR}
}

@article{arulkumaran2017deep,
  title={Deep reinforcement learning: A brief survey},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={6},
  pages={26--38},
  year={2017},
  publisher={IEEE}
}
@article{arulkumaran2017deep,
  title={Deep reinforcement learning: A brief survey},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={6},
  pages={26--38},
  year={2017},
  publisher={IEEE}
}

@article{kostrikov2021offline,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@article{zhang2018advances,
  title={Advances in variational inference},
  author={Zhang, Cheng and B{\"u}tepage, Judith and Kjellstr{\"o}m, Hedvig and Mandt, Stephan},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={8},
  pages={2008--2026},
  year={2018},
  publisher={IEEE}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@article{rizzo2016energy,
  title={Energy distance},
  author={Rizzo, Maria L and Sz{\'e}kely, G{\'a}bor J},
  journal={wiley interdisciplinary reviews: Computational statistics},
  volume={8},
  number={1},
  pages={27--38},
  year={2016},
  publisher={Wiley Online Library}
}

@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International conference on machine learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}

@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{o2010play,
  title={Play it again: reactivation of waking experience and memory},
  author={O’Neill, Joseph and Pleydell-Bouverie, Barty and Dupret, David and Csicsvari, Jozsef},
  journal={Trends in neurosciences},
  volume={33},
  number={5},
  pages={220--229},
  year={2010},
  publisher={Elsevier}
}

@book{lin1992reinforcement,
  title={Reinforcement learning for robots using neural networks},
  author={Lin, Long-Ji},
  year={1992},
  publisher={Carnegie Mellon University}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@article{ko2006mathematical,
  title={Mathematical analysis},
  author={Ko, Stanley},
  year={2006}
}

@inproceedings{kalashnikov2018scalable,
  title={Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  pages={651--673},
  year={2018},
  organization={PMLR}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}