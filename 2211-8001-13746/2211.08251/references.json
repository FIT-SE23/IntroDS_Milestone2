{
    "2202.11566": {
        "title": "Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning",
        "authors": [
            "Chenjia Bai",
            "Lingxiao Wang",
            "Zhuoran Yang",
            "Zhihong Deng",
            "Animesh Garg",
            "Peng Liu",
            "Zhaoran Wang"
        ],
        "submission_date": "2022",
        "SemanticScholarId": "23abe79046d7f7b430d5d21b6a93598d0aa1b9c2"
    },
    "2110.06169": {
        "title": "Offline Reinforcement Learning with Implicit Q-Learning",
        "authors": [
            "Ilya Kostrikov",
            "Ashvin Nair",
            "S. Levine"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "348a855fe01f3f4273bf0ecf851ca688686dbfcc"
    },
    "2110.01548": {
        "title": "Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble",
        "authors": [
            "Gaon An",
            "Seungyong Moon",
            "Jang-Hyun Kim",
            "Hyun Oh Song"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "9560080a2c32682bd1c1a9850a54ca6163f1956e"
    },
    "2106.06860": {
        "title": "A Minimalist Approach to Offline Reinforcement Learning",
        "authors": [
            "Scott Fujimoto",
            "S. Gu"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "c879b25308026d6538e52b27bcf4fd3cb60855f3"
    },
    "2105.08140": {
        "title": "Uncertainty Weighted Actor-Critic for Offline Reinforcement Learning",
        "authors": [
            "Yue Wu",
            "Shuangfei Zhai",
            "Nitish Srivastava",
            "J. Susskind",
            "Jian Zhang",
            "R. Salakhutdinov",
            "Hanlin Goh"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "2c23085488337c4c1b5673b8d0f4ac95bda73529"
    },
    "2105.06022": {
        "title": "Principled Exploration via Optimistic Bootstrapping and Backward Induction",
        "authors": [
            "Chenjia Bai",
            "Lingxiao Wang",
            "Zhaoran Wang",
            "Lei Han",
            "Jianye Hao",
            "Animesh Garg",
            "Peng Liu"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "6d2f554fbd24715c2268d64f90b53a5f19044774"
    },
    "2006.15134": {
        "title": "Critic Regularized Regression",
        "authors": [
            "Ziyun Wang",
            "Alexander Novikov",
            "Konrad Zolna",
            "Jost Tobias Springenberg",
            "Scott E. Reed",
            "Bobak Shahriari",
            "Noah Siegel",
            "J. Merel",
            "Caglar Gulcehre",
            "N. Heess",
            "Nando de Freitas"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "7acbdb961f67d50fef359066f2a1d7755cf16ee2"
    },
    "2006.09359": {
        "title": "Accelerating Online Reinforcement Learning with Offline Datasets",
        "authors": [
            "Ashvin Nair",
            "Murtaza Dalal",
            "Abhishek Gupta",
            "S. Levine"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "0272b14dd471fe7b81df703af1b71d7600b77215"
    },
    "2006.04779": {
        "title": "Conservative Q-Learning for Offline Reinforcement Learning",
        "authors": [
            "Aviral Kumar",
            "Aurick Zhou",
            "G. Tucker",
            "S. Levine"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "28db20a81eec74a50204686c3cf796c42a020d2e"
    },
    "2005.01643": {
        "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems",
        "authors": [
            "S. Levine",
            "Aviral Kumar",
            "G. Tucker",
            "Justin Fu"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "5e7bc93622416f14e6948a500278bfbe58cd3890"
    },
    "2004.07219": {
        "title": "D4RL: Datasets for Deep Data-Driven Reinforcement Learning",
        "authors": [
            "Justin Fu",
            "Aviral Kumar",
            "Ofir Nachum",
            "G. Tucker",
            "S. Levine"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "a326d9f2d2d351001fece788165dbcbb524da2e4"
    },
    "2002.08396": {
        "title": "Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning",
        "authors": [
            "Noah Siegel",
            "Jost Tobias Springenberg",
            "Felix Berkenkamp",
            "A. Abdolmaleki",
            "M. Neunert",
            "Thomas Lampe",
            "Roland Hafner",
            "Martin A. Riedmiller"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "0881655dcdf891f529ebe7ac18301e138a5e265b"
    },
    "2002.00444": {
        "title": "Deep Reinforcement Learning for Autonomous Driving: A Survey",
        "authors": [
            "B. R. Kiran",
            "Ibrahim Sobh",
            "V. Talpaert",
            "P. Mannion",
            "A. A. Sallab",
            "S. Yogamani",
            "P. P'erez"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "129983331ca874142a3e8eb2d93d820bdf1f9aca"
    },
    "1910.00177": {
        "title": "Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning",
        "authors": [
            "Xue Bin Peng",
            "Aviral Kumar",
            "Grace Zhang",
            "S. Levine"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "ad14227e4f51276892ffc37aa43fd8750bb5eba8"
    },
    "1911.11361": {
        "title": "Behavior Regularized Offline Reinforcement Learning",
        "authors": [
            "Yifan Wu",
            "G. Tucker",
            "Ofir Nachum"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "9be492858863c8c7c24be1ecb75724de5086bd8e"
    },
    "1908.08796": {
        "title": "Reinforcement Learning in Healthcare: A Survey",
        "authors": [
            "Chao Yu",
            "Jiming Liu",
            "S. Nemati"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "222baa4e9e7ce691fdfddbc826a70e027daed70d"
    },
    "1907.00456": {
        "title": "Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human Preferences in Dialog",
        "authors": [
            "Natasha Jaques",
            "Asma Ghandeharioun",
            "Judy Hanwen Shen",
            "Craig Ferguson",
            "Àgata Lapedriza",
            "Noah J. Jones",
            "S. Gu",
            "Rosalind W. Picard"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "57daffd65a5d73a439903f3e50950c21c9eba687"
    },
    "1906.00949": {
        "title": "Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction",
        "authors": [
            "Aviral Kumar",
            "Justin Fu",
            "G. Tucker",
            "S. Levine"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "82b4b03a4659d6e04bd7cbf51d6e08fde1348dbd"
    },
    "1812.05905": {
        "title": "Soft Actor-Critic Algorithms and Applications",
        "authors": [
            "Tuomas Haarnoja",
            "Aurick Zhou",
            "Kristian Hartikainen",
            "G. Tucker",
            "Sehoon Ha",
            "Jie Tan",
            "Vikash Kumar",
            "Henry Zhu",
            "Abhishek Gupta",
            "P. Abbeel",
            "S. Levine"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "12c0751b4f51ed833172a713b7e32390032ead93"
    },
    "1812.02900": {
        "title": "Off-Policy Deep Reinforcement Learning without Exploration",
        "authors": [
            "Scott Fujimoto",
            "D. Meger",
            "Doina Precup"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "5285cb8faada5de8a92a47622950f6cfd476ac1d"
    },
    "1810.12894": {
        "title": "Exploration by Random Network Distillation",
        "authors": [
            "Yuri Burda",
            "Harrison Edwards",
            "A. Storkey",
            "Oleg Klimov"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "4cb3fd057949624aa4f0bbe7a6dcc8777ff04758"
    },
    "1806.10293": {
        "title": "QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation",
        "authors": [
            "Dmitry Kalashnikov",
            "A. Irpan",
            "P. Pastor",
            "Julian Ibarz",
            "Alexander Herzog",
            "Eric Jang",
            "Deirdre Quillen",
            "E. Holly",
            "Mrinal Kalakrishnan",
            "Vincent Vanhoucke",
            "S. Levine"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "eb37e7b76d26b75463df22b2a3aa32b6a765c672"
    },
    "1802.09477": {
        "title": "Addressing Function Approximation Error in Actor-Critic Methods",
        "authors": [
            "Scott Fujimoto",
            "H. V. Hoof",
            "D. Meger"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "4debb99c0c63bfaa97dd433bc2828e4dac81c48b"
    },
    "1711.05597": {
        "title": "Advances in Variational Inference",
        "authors": [
            "Cheng Zhang",
            "Judith Bütepage",
            "H. Kjellström",
            "S. Mandt"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "9884d18f265f9178ff9862d53cacbbc9957ddc4c"
    },
    "1709.10087": {
        "title": "Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations",
        "authors": [
            "A. Rajeswaran",
            "Vikash Kumar",
            "Abhishek Gupta",
            "John Schulman",
            "E. Todorov",
            "S. Levine"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "e010ba3ff5744604cdbfe44a733e2a98649ee907"
    },
    "1602.04621": {
        "title": "Deep Exploration via Bootstrapped DQN",
        "authors": [
            "Ian Osband",
            "C. Blundell",
            "A. Pritzel",
            "Benjamin Van Roy"
        ],
        "submission_date": "2016",
        "SemanticScholarId": "4b63e34276aa98d5345efa7fe09bb06d8a9d8f52"
    },
    "1312.5602": {
        "title": "Playing Atari with Deep Reinforcement Learning",
        "authors": [
            "Volodymyr Mnih",
            "K. Kavukcuoglu",
            "David Silver",
            "Alex Graves",
            "Ioannis Antonoglou",
            "D. Wierstra",
            "Martin A. Riedmiller"
        ],
        "submission_date": "2013",
        "SemanticScholarId": "2319a491378867c7049b3da055c5df60e1671158"
    }
}