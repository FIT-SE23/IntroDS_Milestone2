\documentclass[11pt]{article}

\usepackage[shortlabels]{enumitem}
\usepackage{amssymb}
\usepackage[mathscr]{euscript}
\usepackage{color}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{changepage}
\usepackage{color}
\usepackage{latexsym}
\usepackage{tablefootnote}
%\usepackage[notcite,notref]{showkeys}
\usepackage{epsfig}
\usepackage{multirow}
\usepackage{float}
\usepackage{array}
\usepackage{bbm}

\baselineskip=40pt \textheight 22.5truecm \topmargin -0.5125truein
\textwidth 15.74truecm \oddsidemargin -0.06truein \evensidemargin
-0.06truein

\def\bea{\begin{eqnarray}}
\def\beaa{\begin{eqnarray*}}
\def\beq{\begin{equation}}
\def\eea{\end{eqnarray}}
\def\eeaa{\end{eqnarray*}}
\def\eeq{\end{equation}}
\newcommand{\nn}{\nonumber}
\newcommand{\mb}[1]{\mbox{\boldmath $#1$}}

\allowdisplaybreaks

\def\proof{\noindent{\bf Proof}: \ignorespaces}
\def\endproof{{\ \hfill\hbox{%
      \vrule width1.0ex height1.0ex
    }\parfillskip 0pt}\par}

%\linespread{2.8}

\begin{document}


\newtheorem{definition}{Definition}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{assumption}{Assumption}[section]
\newtheorem{example}{Example}[section]
\newtheorem{algorithm}{Algorithm}[section]

\title{Superlinear Convergence of an Infeasible Interior Point Algorithm on the Homogeneous Feasibility Model of a Semi-definite Program}

\author{{\bf{Chee-Khian Sim}}\footnote{Email address: chee-khian.sim@port.ac.uk} \\ School of Mathematics and Physics\\ University of Portsmouth \\ Lion Gate Building, Lion Terrace \\ Portsmouth, PO1 3HF \\ United Kingdom}

\date{October 01, 2022}

\maketitle
\begin{abstract}
In the literature, superlinear convergence of implementable polynomial-time interior point algorithms to solve semi-definite programs (SDPs) can only be shown by (i) assuming that the given SDP is nondegenerate and modifying these algorithms, or (ii) considering special classes of SDPs, such as the class of linear semi-definite feasibility problems, when a suitable initial iterate is required as well. Otherwise, these algorithms are not easy to implement even though they can be shown to have polynomial iteration complexities and superlinear convergence.  These are besides the assumption of strict complementarity imposed on the given SDP.  In this paper, we show superlinear convergence of an implementable interior point algorithm that has polynomial iteration complexity when it is used to solve the homogeneous feasibility model of a primal-dual SDP pair that has no special structure imposed.  This is achieved by only assuming strict complementarity and the availability of an interior feasible point to the primal SDP.  Furthermore, we do not need to modify the algorithm to show this.

\vspace{10pt}

\noindent {\bf{Keywords.}} Semi-definite program; semi-definite linear complementarity problem; homogeneous feasibility model; interior point method; superlinear convergence.
\end{abstract}

%\begin{center}
%\LARGE{\bf{Superlinear Convergence of a Homogeneous Interior Point
%Algorithm on Linear Semi-definite Feasibility Problems}}
%\end{center}


\section{Introduction}\label{sec:introduction}

Many problems in diverse areas, such as optimal control, estimation and signal processing, communications and networks, statistics, and finance, can be modelled well as semi-definite programs (SDPs) \cite{Boyd}.  Finding effective and efficient ways to solve this class of problems is hence practically important.  Interior point methods (IPMs) have been proven to be successful in solving SDPs - see for example \cite{Alizadeh,Kojima1,Monteiro3,Zhang}.  Research on interior point methods is still ongoing with recent papers, such as \cite{Alzalg,Faybusovich,Rigo}, proposing contemporary interior point algorithms to solve symmetric cone problems, which include semi-definite programs.

Among different IPMs, primal-dual path following interior point algorithms are the most successful and most widely studied.  In this paper, we focus on an infeasible predictor-corrector primal-dual path following interior point algorithm to solve the homogeneous feasibility model \cite{Potra} of a primal-dual SDP pair. Global convergence, in particular, polynomial iteration complexity of the algorithm has been shown in \cite{Potra}.  In this paper, we consider the local convergence behavior of the algorithm.  

It proves not an easy task to show superlinear convergence of an implementable interior point algorithm that has polynomial iteration complexity on an SDP with minimal assumptions on the problem and no modifications to the algorithm.  In the literature, such as \cite{Kojima}, in addition to strict complementarity assumption, nondegeneracy assumption at an optimal solution and modifications to the algorithm, such as solving the corrector-step linear system in an iteration repeatedly instead of only once (``narrowing" the central path neighborhood\footnote{We note that this idea is used in \cite{Nesterov2} to show superlinear convergence of an interior point algorithm on a wide class of conic optimization problems.  Also, this is related to the sufficient conditions on behavior of iterates generated by the algorithm  as studied in \cite{Potra2,Potra1} for superlinear convergence.}), need to be imposed for superlinear convergence of the interior point algorithm.  In \cite{Luo}, without assuming  nondegeneracy, the feasible interior point algorithm considered in the paper is shown to have polynomial iteration complexity and superlinear convergence.  However, the algorithm is not easy to implement. The idea behind the algorithm considered in \cite{Luo} to have superlinear convergence when solving an SDP is to force the centrality measure of the $k^{th}$ iterate to converge to zero as $k$ tends to infinity.  This can be enforced in practice by for example, repeatedly solving the corrector-step linear system in an iteration, as in \cite{Kojima}, so as to ``narrow" the neighborhood of the central path in which iterates lie.  Therefore, we require existing algorithms to be modified for superlinear convergence.  If these algorithms are not modified, then special structure needs to be imposed on the SDP, such as, considering linear semi-definite feasibility problems (LSDFPs), for superlinear convergence \cite{Sim1,Sim6}.  The latter also additionally requires one to choose a suitable initial iterate.  In this paper, for the first time, we show superlinear convergence of an implementable interior point algorithm having polynomial iteration complexity on a primal-dual SDP pair by assuming strict complementarity and without special structure imposed on the problem.  Furthermore, no modifications to the algorithm, such as repeatedly solving the corrector-step linear system, instead of once, in an iteration, is needed to achieve this, although a suitable initial iterate is required. To show superlinear convergence, we consider the algorithm applied to the homogeneous feasibility model of the primal-dual SDP pair.  
%In this case, given an interior feasible point to the primal SDP pair as part of the initial iterate of the algorithm on the homogeneous feasibility model, we are able to show superlinear convergence of the algorithm to find optimal solutions to the primal-dual SDP pair.  To the best of our knowledge, this result is the first in the literature on superlinear convergence of the algorithm under consideration, without any modifications to the algorithm, and under only strict complementarity assumption on the primal-dual SDP pair.  

In Section \ref{sec:SDPhomogeneousmodel}, we describe the homogeneous feasibility model of a primal-dual SDP pair.  Then in Section \ref{sec:SDLCP}, we express the homogeneous feasibility model as a semi-definite linear complementarity problem. This allows us to apply results in the literature in Section \ref{sec:interiorpointalgorithm} to show superlinear convergence of an implementable interior point algorithm on the homogeneous feasibility model. We conclude the paper with Section \ref{sec:conclusion}.


% Finally, in Section \ref{sec:numerical}, we perform numerical experiments on random primal-dual SDP pairs to practically view the superlinear convergence behavior of the interior point algorithm on their homogeneous feasibility models.

\subsection{Notations}\label{subsec:notations}

The space of symmetric $n \times n$ matrices is denoted by $S^n$.  The cone of positive semi-definite (resp., positive definite) symmetric matrices is denoted by $S^n_+$ (resp. $S^n_{++}$).  The identity matrix is denoted by $I_{n \times n}$, where $n$ stands for the size of the matrix.  We omit the subscript when the size of the identity matrix is clear from the contex.  The matrix $E^{ij} \in \Re^{n_1 \times n_2}$ is defined to have $1$ in its $(i,j)$ entry, and zero everywhere else.

Given a matrix $G \in \Re^{n_1 \times n_2}$, $\| G \|_F: = \sqrt{{\rm{Tr}}(GG^T)}$ is the Frobenius norm of $G$, where ${\rm{Tr}}(\cdot)$ is the trace of a square matrix.  $G_{ij}$ is the entry of $G$ in the $i$th row and the $j$th column of $G$.  

Given a vector $x \in \Re^n$, $\| x \|$ refers to its Euclidean norm.  Also, ${\rm{Diag}}(x) \in \Re^{n \times n}$ is a square matrix with the entries of $x \in \Re^n$ making up the main diagonal elements of the matrix, with all its other elements equal to zero.

Given $X \in S^n$, ${\rm{svec}}(X)$ is defined to be
\begin{eqnarray*}
{\rm{svec}}(X) := (X_{11}, \sqrt{2}X_{21}, \ldots, \sqrt{2}X_{n1}, X_{22}, \sqrt{2}X_{32}, \ldots, X_{n-1,n-1}, \sqrt{2} X_{n,n-1}, X_{nn})^T \in \Re^{\tilde{n}},
\end{eqnarray*}
where $\tilde{n} = n(n+1)/2$.  ${\rm{svec}}(\cdot)$ sets up a one-to-one correspondence between $S^n$ and $\Re^{\tilde{n}}$.

Given functions $f : \Omega \rightarrow E$ and $g : \Omega \rightarrow \Re_{++}$, where $\Omega$ is an arbitrary set and $E$ is a normed vector space with norm $\| \cdot \|$.  For a subset $\hat{\Omega} \subseteq \Omega$, we write $f(w) = \mathcal{O}(g(w))$ for all $w \in \hat{\Omega}$ to mean that $\| f(w) \| \leq M g(w)$ for all $w \in \hat{\Omega}$, where $M > 0$ is a positive constant.  Suppose $E = S^n$.  Then we write $f(w) = \Theta (g(w))$ if for all $w \in \hat{\Omega}$, $f(w) \in S^n_{++}$, and $f(w) = \mathcal{O}(g(w))$, $f(w)^{-1} = \mathcal{O}(1/g(w))$.

\section{A Semi-definite Program and its Homogeneous Feasibility Model}\label{sec:SDPhomogeneousmodel}

%\noindent Consider the following linear semi-definite feasibility
%problem:

%\vspace{10pt}

%\noindent {\it{Given $m$ symmetric matrices $A_i \in S^n$ and $m$
%real numbers $b_i, i = 1, \ldots, m$, find an $X \in S^n_+$ that
%satisfies
%\begin{eqnarray*}
%{\mbox{Tr}}(A_i X) = b_i,\ i = 1, \ldots, m,
%\end{eqnarray*}
%\noindent where ${\mbox{Tr}}(\cdot)$ denotes the trace of a
%matrix.}}

%\vspace{10pt}

%Let us assume that $\{ A_1, \ldots, A_m\}$ are linearly independent.

\noindent Given $C, A_i \in S^n$, $i = 1, \ldots, m$, and $b = (b_1, \ldots, b_m)^T \in \Re^m$.  A (primal) semi-definite program (SDP) is given by
\begin{eqnarray}\label{primalSDP}
\begin{array}{ll}
\min & {\mbox{Tr}}(CX) \\
{\mbox{subject\ to}} & {\mbox{Tr}}(A_i X) = b_i,\ i = 1, \ldots, m,
\\
& X \in S^n_+.
\end{array}
\end{eqnarray}

%A linear semi-definite feasibility problem is a semi-definite
%program in which $C = 0$.

The dual of (\ref{primalSDP}) is given by
\begin{eqnarray}\label{dualSDP}
\begin{array}{ll}
\max & b^Ty \\
{\mbox{subject\ to}} & \sum_{i=1}^{m} y_iA_i + Y = C, \\
& Y \in S^n_+.
\end{array}
\end{eqnarray}
Here, $y = (y_1, \ldots, y_m)^T \in \Re^m$.

We impose the following assumptions on primal-dual SDP pair (\ref{primalSDP})-(\ref{dualSDP}) throughout this paper:
\begin{assumption}\label{ass:SDP}
\begin{enumerate}[(a)]
\item There exist $X \in S^n_{++}$ and  $(y, Y) \in \Re^m \times S^n_{++}$ that is feasible to (\ref{primalSDP}) and (\ref{dualSDP}) respectively.
\item $A_1, \ldots, A_m$ are linearly independent.
\end{enumerate}
\end{assumption}

The above assumptions, in particular, Assumption \ref{ass:SDP}(a), ensure that there exists an optimal solution $X^\ast$ to (\ref{primalSDP}) and an optimal solution $(y^\ast, Y^\ast)$ to
(\ref{dualSDP}) such that ${\rm{Tr}}(X^\ast Y^\ast) = 0$ - see for example, \cite{Boyd}.

We now introduce the homogeneous feasibility model, that appears in \cite{Potra}, that gives optimal
solutions to (\ref{primalSDP}) and (\ref{dualSDP}).  It is given by the
following homogeneous system:
\begin{eqnarray}
& & {\mbox{Tr}}(A_i X) =  b_i \tau,\ i = 1, \ldots, m,
\label{homogeneous1} \\
& & \sum_{i=1}^{m} y_i A_i + Y = \tau C,  \label{homogeneous2} \\
& & \kappa = b^T y - {\mbox{Tr}}(CX),  \label{homogeneous3} \\
& & X \in S^n_{+}, Y \in S^n_{+}, \tau \geq 0, \kappa \geq 0.
\label{homogeneous4}
\end{eqnarray}


Observe that (\ref{homogeneous1})-(\ref{homogeneous3}) implies that
\begin{eqnarray}\label{dualitygap}
{\mbox{Tr}}(XY) + \tau \kappa = 0,
\end{eqnarray}
\noindent from which we obtain, using (\ref{homogeneous4}),
\begin{eqnarray*}
XY & = & 0, \\
\tau \kappa & = & 0.
\end{eqnarray*}

Furthermore, observe that a solution to the homogeneous system is readily available and is given by
$(X,y,Y,\tau,\kappa) = (0,0,0,0,0)$.  However, we cannot derive optimal solutions to (\ref{primalSDP}) and (\ref{dualSDP}) from this.  If there exists a
solution $(X^\ast, y^\ast, Y^\ast, \tau^\ast, \kappa^\ast)$ to
(\ref{homogeneous1})-(\ref{homogeneous4}) such that $\kappa^\ast =
0$ and $\tau^\ast > 0$, then $(X^\ast/\tau^\ast, y^\ast/\tau^\ast,
Y^\ast/\tau^\ast)$ is an optimal solution to primal-dual SDP
pair (\ref{primalSDP})-(\ref{dualSDP}) with zero duality gap.  Conversely, if $(X^\ast, y^\ast, Y^\ast)$ is an optimal solution to primal-dual SDP pair (\ref{primalSDP})-(\ref{dualSDP}) with zero duality gap, then $(X^\ast, y^\ast, Y^\ast, 1, 0)$ solves the system (\ref{homogeneous1})-(\ref{homogeneous4}).  By Assumption \ref{ass:SDP}(a), which ensures an optimal solution to primal-dual SDP pair (\ref{primalSDP})-(\ref{dualSDP}) with zero duality gap, we see that this optimal solution can be obtained by solving (\ref{homogeneous1})-(\ref{homogeneous4}).  Interior point algorithms when applied to the homogeneous feasibility model can be used to find optimal solutions to  primal-dual SDP pair (\ref{primalSDP})-(\ref{dualSDP}) by finding a solution $(X^\ast, y^\ast, Y^\ast, \tau^\ast, \kappa^\ast)$ to
(\ref{homogeneous1})-(\ref{homogeneous4}) such that $\kappa^\ast =
0$ and $\tau^\ast > 0$.  Such an interior point algorithm is discussed in \cite{Potra}, which is also given in Section \ref{sec:interiorpointalgorithm} below.  These interior point algorithms necessarily have to be of the infeasible type in that the initial iterate and subsequent iterates generated by the algorithm cannot satisfy (\ref{homogeneous1})-(\ref{homogeneous3}).  This is so because if an iterate $(X_k, y_k, Y_k, \tau_k, \kappa_k) \in S^n_{++} \times \Re^m \times S^n_{++} \times \Re_{++} \times \Re_{++}$ for some $k \geq 0$ satisfies (\ref{homogeneous1})-(\ref{homogeneous3}), then (\ref{dualitygap}) holds, which is impossible since $X_k, Y_k \in S^n_{++}$ and $\tau_k, \kappa_k > 0$.

% We say that $(X,y,Y, \tau, \kappa) \in S^n_{++} \times \Re^m \times S^n_{++} \times \Re_{++} \times \Re_{++}$ is an infeasible interior point to homogeneous feasibility model (\ref{homogeneous1})-(\ref{homogeneous4}) if it does not satisfy (\ref{homogeneous1})-(\ref{homogeneous3}).
%Let us now write
%(\ref{homogeneous1})-(\ref{homogeneous3}) in another way as described below.
%
%From (\ref{homogeneous1}), we have
%\begin{eqnarray}\label{homogeneous1prime}
%\left[ \begin{array}{cc}
%        {\mbox{svec}}(A_1)^T & -b_1 \\
%        \vdots               & \vdots \\
%        {\mbox{svec}}(A_m)^T & -b_m
%        \end{array} \right]
%\left[ \begin{array}{c}
%        {\mbox{svec}}(X) \\
%        \tau
%        \end{array} \right] = 0.
%\end{eqnarray}
%
%On the other hand, combining (\ref{homogeneous2}) and (\ref{homogeneous3}) into one equation, we obtain
%\begin{eqnarray}\label{homogeneous23prime}
%\left[ \begin{array}{ccc}
%        {\mbox{svec}}(A_1) & \ldots & {\mbox{svec}}(A_m) \\
%        -b_1               & \ldots & -b_m
%        \end{array} \right]y +
%\left[ \begin{array}{cc}
%            0 & -{\mbox{svec}}(C) \\
%            {\mbox{svec}}(C)^T & 0
%        \end{array} \right] \left[ \begin{array}{c}
%                                        {\mbox{svec}}(X) \\
%                                        \tau
%                                    \end{array} \right] +
%\left[ \begin{array}{c}
%            {\mbox{svec}}(Y) \\
%            \kappa
%        \end{array} \right] = 0.
%\end{eqnarray}
%
%Let the following set of linearly independent vectors in $\Re^{\tilde{n} + 1}$
%\begin{eqnarray*}
%\left\{ \left[ \begin{array}{c}
%            {\mbox{svec}}(B_1) \\
%            d_1
%        \end{array} \right], \ldots,
%\left[ \begin{array}{c}
%            {\mbox{svec}}(B_{\tilde{n}+1 - m}) \\
%            d_{\tilde{n}+1-m}
%        \end{array} \right] \right\}
%\end{eqnarray*}
%spans the orthogonal subspace to the space spanned by
%\begin{eqnarray*}
%\left[ \begin{array}{c}
%            {\mbox{svec}}(A_1) \\
%            -b_1
%        \end{array} \right], \ldots,
%\left[ \begin{array}{c}
%            {\mbox{svec}}(A_m) \\
%            -b_m
%        \end{array} \right],
%\end{eqnarray*}
%\noindent where $\tilde{n} = n(n+1)/2$.
%
%Let
%\begin{eqnarray*}
%\mathcal{A} := \left[ \begin{array}{c}
%                        {\mbox{svec}}(A_1)^T \\
%                        \vdots \\
%                        {\mbox{svec}}(A_m)^T
%                    \end{array} \right], \ \
%b := \left[ \begin{array}{c}
%                b_1 \\
%                \vdots \\
%                b_m
%            \end{array} \right]
%\end{eqnarray*}
%and
%\begin{eqnarray*}
%\mathcal{B} := \left[ \begin{array}{c}
%                        {\mbox{svec}}(B_1)^T \\
%                        \vdots \\
%                        {\mbox{svec}}(B_{\tilde{n}+1 - m})^T
%                        \end{array} \right],\ \
%d := \left[ \begin{array}{c}
%                d_1 \\
%                \vdots \\
%                d_{\tilde{n} + 1 - m}
%            \end{array} \right].
%\end{eqnarray*}
%
%Therefore, (\ref{homogeneous1prime}) and (\ref{homogeneous23prime}) can be written as
%\begin{eqnarray}\label{eq:homogeneous1prime}
%[\mathcal{A}\ - b] 
%\left[ \begin{array}{c}
%{\rm{svec}}(X) \\
%\tau
%\end{array} \right] = 0
%\end{eqnarray}
%and
%\begin{eqnarray}\label{eq:homogeneous23prime}
%\left[ \begin{array}{cc}
%		\mathcal{A}^T \\
%		b^T 
%		\end{array} \right] y + 
%\left[ \begin{array}{cc}
%            0 & -{\mbox{svec}}(C) \\
%            {\mbox{svec}}(C)^T & 0
%        \end{array} \right] \left[ \begin{array}{c}
%                                        {\mbox{svec}}(X) \\
%                                        \tau
%                                    \end{array} \right] +
%\left[ \begin{array}{c}
%            {\mbox{svec}}(Y) \\
%            \kappa
%        \end{array} \right] = 0
%\end{eqnarray}
%respectively.  Furthermore, (\ref{eq:homogeneous23prime}) holds if and only if
%\begin{eqnarray*}
%[d {\rm{svec}}(C)^T\ - \mathcal{B} {\rm{svec}}(C) \ \mathcal{B} \ d ] \left[ \begin{array}{c}
%{\rm{svec}}{X} \\
%\tau \\
%{\rm{svec}}(Y) \\
%\kappa
%\end{array} \right] = 0.
%\end{eqnarray*}
%
%The above development implies that (\ref{homogeneous1})-(\ref{homogeneous3}) can be rewritten
%as
%\begin{eqnarray}\label{homogeneous1to3combined}
%\left[ \begin{array}{cccc}
%        \mathcal{A} & -b & 0 & 0 \\
%        d{\mbox{svec}}(C)^T & -\mathcal{B}{\mbox{svec}}(C) &
%        \mathcal{B} & d
%        \end{array} \right]
%\left[ \begin{array}{c}
%        {\mbox{svec}}(X) \\
%        \tau \\
%        {\mbox{svec}}(Y) \\
%        \kappa
%        \end{array} \right] = 0.
%\end{eqnarray}
%
%We have that (\ref{homogeneous1to3combined}) together with
%\begin{eqnarray}\label{homogeneous4prime}
%X \in S^n_+, Y \in S^n_+, \tau \geq 0, \kappa \geq 0,
%\end{eqnarray}
%forms the homogeneous feasibility model of the SDP pair (\ref{primalSDP})-(\ref{dualSDP}).
%
%We remind the reader that (\ref{dualitygap}) holds, which follows from (\ref{homogeneous1to3combined}) or (\ref{homogeneous1})-(\ref{homogeneous3}).  Also, it is easy to see that the matrix on the left-hand side of (\ref{homogeneous1to3combined}) has full row rank.
%
%


\section{Homogeneous Feasibility Model as a Semi-definite Linear Complementarity Problem}\label{sec:SDLCP}

Recall that a semi-definite linear complementarity problem (SDLCP), introduced in  \cite{Kojima1}, is given by:
\begin{eqnarray}
\mathcal{A}_1(X^1) + \mathcal{B}_1(Y^1) & = & q, \label{SDLCP1} \\
X^1Y^1 & = & 0, \label{SDLCP2} \\
X^1, Y^1 & \in & S^{n_1}_+, \label{SDLCP3}
\end{eqnarray}
where $\mathcal{A}_1, \mathcal{B}_1 : S^{n_1} \rightarrow \Re^{\tilde{n}_1}$ are linear operators, $q \in \Re^{\tilde{n}_1}$, and $\tilde{n}_1 = n_1(n_1+1)/2$.  The following assumptions are imposed on the SDLCP, which we show in Proposition \ref{prop:SDLCPAssumption} to hold for the SDLCP representation of the homogeneous feasibility model of primal-dual SDP (\ref{primalSDP})-(\ref{dualSDP}).  We are going to derive this representation in this section.
\begin{assumption}\label{ass:SDLCPassumptions}
\begin{enumerate}[(a)]
\item System (\ref{SDLCP1})-(\ref{SDLCP3}) is monotone.  That is, $\mathcal{A}_1(X^1) + \mathcal{B}_1(Y^1) = 0$ for $X^1, Y^1 \in S^{n_1} \Rightarrow {\rm{Tr}}(X^1Y^1) \geq 0$.
\item There exists at least one solution to SDLCP (\ref{SDLCP1})-(\ref{SDLCP3}).
\item $\{ \mathcal{A}_1(X^1) + \mathcal{B}_1(Y^1)\ ; \ X^1, Y^1 \in S^{n_1} \} = \Re^{\tilde{n}_1}$.
\end{enumerate}
\end{assumption}

When SDLCP (\ref{SDLCP1})-(\ref{SDLCP3}) is studied in some papers in the literature, instead of Assumption \ref{ass:SDLCPassumptions}(b), the following assumption is imposed:
\begin{assumption}\label{ass:strictfeasibility}
There exist $X^1, Y^1 \in S^{n_1}_{++}$ such that $\mathcal{A}_1(X^1) + \mathcal{B}_1(Y^1) = q$.
\end{assumption}
Assumptions \ref{ass:SDLCPassumptions}(a), (c) and \ref{ass:strictfeasibility} are imposed in \cite{Kojima1} where the paper studies feasible interior point algorithms on SDLCP (\ref{SDLCP1})-(\ref{SDLCP3}), while \cite{Kojima,Sim1} assume Assumption \ref{ass:SDLCPassumptions} in the study of infeasible interior point algorithms on SDLCP (\ref{SDLCP1})-(\ref{SDLCP3}).  In the study of infeasible interior point algorithms on SDLCP (\ref{SDLCP1})-(\ref{SDLCP3}), it is not necessary to impose Assumption \ref{ass:strictfeasibility}.  A reason being that we do not need a strictly feasible initial iterate in the algorithm.  In this paper, we solve primal-dual SDP pair (\ref{primalSDP})-(\ref{dualSDP}) by applying an interior point algorithm on homogeneous feasibility model (\ref{homogeneous1})-(\ref{homogeneous4}), the interior point algorithm is necessarily infeasible as discussed at the end of the previous section.  When we express the homogeneous feasibility model as an SDLCP (to be discussed next), the interior point algorithm that is applied to the homogeneous feasibility model can be equivalently applied to the corresponding SDLCP, and by necessity, the algorithm on the SDLCP is infeasible just like that for the homogeneous feasibility model.  Therefore, having Assumption \ref{ass:strictfeasibility} imposed on the SDLCP is not suitable and in fact can never hold in our case as there cannot exist an $(X, Y) \in S^n_{++} \times S^n_{++}$ such that (\ref{SDLCP1}) holds in the SDLCP obtained from the homogeneous feasibility model.  We therefore have Assumption \ref{ass:SDLCPassumptions}(b) in its place.  In fact, we will see later that when primal-dual SDP pair (\ref{primalSDP})-(\ref{dualSDP}) satisfies Assumption \ref{ass:SDP}, Assumption \ref{ass:SDLCPassumptions} holds for the SDLCP that results from homogeneous feasibility model (\ref{homogeneous1})-(\ref{homogeneous4}).


We now proceed to express homogeneous feasibility model (\ref{homogeneous1})-(\ref{homogeneous4}) as an SDLCP.  

%First, we form the following system:
%\begin{eqnarray*}
%& & {\rm{Tr}}\left( \left( \begin{array}{cc}
%						A_i & 0 \\
%						0   & -b_i
%						\end{array} \right) X_1 \right)  =  0,\ i = 1, \ldots, m, \\
%& & {\rm{Tr}}(E_{n+1, i-m} X_1)  =  0,\ i = m+1, \ldots, m+n, \\
%& & \left( \begin{array}{cc}
%	\sum_{i=1}^m y_i A_i - (X_1)_{n+1,n+1} C & 0 \\
%	0 & -b^Ty + {\rm{Tr}}(C (X_1)_{1\leq n, 1 \leq n}) 
%		\end{array} \right) + Y_1  =  0, \\
%& & X_1 \in S^{n+1}_+, Y_1 \in S^{n+1}_+.
%\end{eqnarray*}
%
%Let us now write
%(\ref{homogeneous1})-(\ref{homogeneous3}) in another way as described below.

We can write (\ref{homogeneous1}) as
\begin{eqnarray}\label{homogeneous1prime}
\left[ \begin{array}{cc}
        {\mbox{svec}}(A_1)^T & -b_1 \\
        \vdots               & \vdots \\
        {\mbox{svec}}(A_m)^T & -b_m
        \end{array} \right]
\left[ \begin{array}{c}
        {\mbox{svec}}(X) \\
        \tau
        \end{array} \right] = 0.
\end{eqnarray}

On the other hand, combining (\ref{homogeneous2}) and (\ref{homogeneous3}) into one equation, we obtain
\begin{eqnarray}\label{homogeneous23prime}
\left[ \begin{array}{ccc}
        {\mbox{svec}}(A_1) & \ldots & {\mbox{svec}}(A_m) \\
        -b_1               & \ldots & -b_m
        \end{array} \right]y +
\left[ \begin{array}{cc}
            0 & -{\mbox{svec}}(C) \\
            {\mbox{svec}}(C)^T & 0
        \end{array} \right] \left[ \begin{array}{c}
                                        {\mbox{svec}}(X) \\
                                        \tau
                                    \end{array} \right] +
\left[ \begin{array}{c}
            {\mbox{svec}}(Y) \\
            \kappa
        \end{array} \right] = 0.
\end{eqnarray}

Let us now rewrite (\ref{homogeneous1prime}) and (\ref{homogeneous23prime}) in a more compact form.  Let 
\begin{eqnarray*}
\mathcal{A} := \left[ \begin{array}{c}
                        {\mbox{svec}}(A_1)^T \\
                        \vdots \\
                        {\mbox{svec}}(A_m)^T
                    \end{array} \right],
\end{eqnarray*}
and recall that $b = (b_1, \ldots, b_m)^T$.  Then, (\ref{homogeneous1prime}) and (\ref{homogeneous23prime}) can be written as
\begin{eqnarray}\label{eq:homogeneous1prime}
[\mathcal{A}\ - b] 
\left[ \begin{array}{c}
{\rm{svec}}(X) \\
\tau
\end{array} \right] = 0
\end{eqnarray}
and
\begin{eqnarray}\label{eq:homogeneous23prime}
\left[ \begin{array}{cc}
		\mathcal{A}^T \\
		- b^T 
		\end{array} \right] y + 
\left[ \begin{array}{cc}
            0 & -{\mbox{svec}}(C) \\
            {\mbox{svec}}(C)^T & 0
        \end{array} \right] \left[ \begin{array}{c}
                                        {\mbox{svec}}(X) \\
                                        \tau
                                    \end{array} \right] +
\left[ \begin{array}{c}
            {\mbox{svec}}(Y) \\
            \kappa
        \end{array} \right] = 0
\end{eqnarray}
respectively.

Now, let the following set of linearly independent vectors in $\Re^{\tilde{n} + 1}$, which are orthogonal, 
\begin{eqnarray*}
\left\{ \left[ \begin{array}{c}
            {\mbox{svec}}(B_1) \\
            d_1
        \end{array} \right], \ldots,
\left[ \begin{array}{c}
            {\mbox{svec}}(B_{\tilde{n}+1 - m}) \\
            d_{\tilde{n}+1-m}
        \end{array} \right] \right\}
\end{eqnarray*}
spans the orthogonal subspace to the space spanned by
\begin{eqnarray*}
\left\{ \left[ \begin{array}{c}
            {\mbox{svec}}(A_1) \\
            -b_1
        \end{array} \right], \ldots,
\left[ \begin{array}{c}
            {\mbox{svec}}(A_m) \\
            -b_m
        \end{array} \right] \right\},
\end{eqnarray*}
\noindent where $\tilde{n} = n(n+1)/2$.

Let
\begin{eqnarray*}
\mathcal{B} := \left[ \begin{array}{c}
                        {\mbox{svec}}(B_1)^T \\
                        \vdots \\
                        {\mbox{svec}}(B_{\tilde{n}+1 - m})^T
                        \end{array} \right],\ \
d := \left[ \begin{array}{c}
                d_1 \\
                \vdots \\
                d_{\tilde{n} + 1 - m}
            \end{array} \right].
\end{eqnarray*}

Then, (\ref{eq:homogeneous23prime}) holds if and only if
\begin{eqnarray*}
[d {\rm{svec}}(C)^T\ - \mathcal{B} {\rm{svec}}(C) \ \mathcal{B} \ d ] \left[ \begin{array}{c}
{\rm{svec}}{X} \\
\tau \\
{\rm{svec}}(Y) \\
\kappa
\end{array} \right] = 0.
\end{eqnarray*}

The above development implies that (\ref{homogeneous1})-(\ref{homogeneous3}) can be rewritten
as
\begin{eqnarray}\label{homogeneous1to3combined}
\left[ \begin{array}{cccc}
        \mathcal{A} & -b & 0 & 0 \\
        d{\mbox{svec}}(C)^T & -\mathcal{B}{\mbox{svec}}(C) &
        \mathcal{B} & d
        \end{array} \right]
\left[ \begin{array}{c}
        {\mbox{svec}}(X) \\
        \tau \\
        {\mbox{svec}}(Y) \\
        \kappa
        \end{array} \right] = 0.
\end{eqnarray}

We have (\ref{homogeneous1to3combined}) together with
\begin{eqnarray}\label{homogeneous4prime}
X \in S^n_+, Y \in S^n_+, \tau \geq 0, \kappa \geq 0,
\end{eqnarray}
is also the homogeneous feasibility model of the SDP pair (\ref{primalSDP})-(\ref{dualSDP}).



%We remind the reader that (\ref{dualitygap}) holds, which follows from (\ref{homogeneous1to3combined}) or (\ref{homogeneous1})-(\ref{homogeneous3}).  Also, it is easy to see that the matrix on the left-hand side of (\ref{homogeneous1to3combined}) has full row rank.

We now express the homogeneous feasibility model as an SDLCP, by first making the following observation:
\begin{proposition}\label{prop:lineardependence}
For $i = 1, \ldots, \tilde{n} + 1 - m$,
\begin{eqnarray*}
\left[ \begin{array}{c}
		d_i {\rm{svec}}(C) \\
		- {\rm{svec}}(B_i)^T{\rm{svec}}(C) 
		\end{array} \right] \in \Re^{\tilde{n} + 1}
\end{eqnarray*}
is a linear combination of 
\begin{eqnarray*}
\left[ \begin{array}{c}
		{\rm{svec}}(A_1) \\
			-b_1
			\end{array}\right], \ldots, 
\left[ \begin{array}{c}
		{\rm{svec}}(A_m) \\
			-b_m
		\end{array} \right].
\end{eqnarray*}
\end{proposition}
\begin{proof}
First, note that
\begin{eqnarray*}
\left\{ \left[ \begin{array}{c}
		{\rm{svec}}(A_1) \\
			-b_1
			\end{array}\right], \ldots, 
\left[ \begin{array}{c}
		{\rm{svec}}(A_m) \\
			-b_m
		\end{array} \right], 
\left[ \begin{array}{c}
		{\rm{svec}}(B_1) \\
			d_1
		\end{array} \right], \ldots,
\left[ \begin{array}{c}
		{\rm{svec}}(B_{\tilde{n} + 1 -m}) \\
			d_{\tilde{n} + 1 - m}
		\end{array} \right] \right\}
\end{eqnarray*}
spans $\Re^{\tilde{n} + 1}$.  Therefore, given 
\begin{eqnarray*}
\left[ \begin{array}{c}
		d_i {\rm{svec}}(C) \\
		- {\rm{svec}}(B_i)^T{\rm{svec}}(C) 
		\end{array} \right],
\end{eqnarray*}
there exists $u^i_j, j = 1, \ldots, m$, $v_i$, $v^i_k$, for $k = 1, \ldots, \tilde{n} + 1 - m$, $k \not= i$, such that
\begin{eqnarray*}
\left[ \begin{array}{c}
		d_i {\rm{svec}}(C) \\
		- {\rm{svec}}(B_i)^T{\rm{svec}}(C) 
		\end{array} \right]
= \sum_{j=1}^m u_j^i \left[ \begin{array}{c}
		{\rm{svec}}(A_j) \\
			-b_j
			\end{array}\right]
+ v_i \left[ \begin{array}{c}
		{\rm{svec}}(B_i) \\
			d_i
		\end{array} \right]
+ \sum_{k = 1, k \not= i}^{\tilde{n} + 1 -m} v_k^i
		\left[ \begin{array}{c}
		{\rm{svec}}(B_k) \\
			d_k
		\end{array} \right].
\end{eqnarray*}
Multiplying both sides of the above equality by $({\rm{svec}}(B_l)^T\ d_l)$ and noting that \begin{eqnarray*}
\left\{ \left[ \begin{array}{c}
            {\mbox{svec}}(B_1) \\
            d_1
        \end{array} \right], \ldots,
\left[ \begin{array}{c}
            {\mbox{svec}}(B_{\tilde{n}+1 - m}) \\
            d_{\tilde{n}+1-m}
        \end{array} \right] \right\}
\end{eqnarray*}
is an orthogonal set which is orthogonal to $\left[ \begin{array}{c}
            {\mbox{svec}}(A_j) \\
            -b_j
        \end{array} \right], j = 1, \ldots, m$, 
we first observe that if $l = i$, then $v_i = 0$.  If $l \not= i$, then
\begin{eqnarray}\label{eqn:1}
d_i {\rm{svec}}(B_l)^T {\rm{svec}}(C) - d_l {\rm{svec}}(B_i)^T {\rm{svec}}(C) = v_l^i \left\| \left[ \begin{array}{c}
		{\rm{svec}}(B_l) \\
			d_l
		\end{array} \right] \right\|^2.
\end{eqnarray}
On the other hand, we have
\begin{eqnarray}\label{eqn:2}
d_l {\rm{svec}}(B_i)^T {\rm{svec}}(C) - d_i {\rm{svec}}(B_l)^T {\rm{svec}}(C) = v_i^l \left\| \left[ \begin{array}{c}
		{\rm{svec}}(B_i) \\
			d_i
		\end{array} \right] \right\|^2.
\end{eqnarray}
Adding (\ref{eqn:1}) and (\ref{eqn:2}), we get $v_l^i = v_i^l = 0$, and the proposition is proved.
\end{proof}

Using Proposition \ref{prop:lineardependence}, by performing row operations on (\ref{homogeneous1to3combined}), we can write (\ref{homogeneous1to3combined}) as
\begin{eqnarray}\label{homogeneous1to3combinedprime}
\left[ \begin{array}{cccc}
        \mathcal{A} & -b & 0 & 0 \\
        0 & 0 &
        \mathcal{B} & d
        \end{array} \right]
\left[ \begin{array}{c}
        {\mbox{svec}}(X) \\
        \tau \\
        {\mbox{svec}}(Y) \\
        \kappa
        \end{array} \right] = 0.
\end{eqnarray}

It is easy to convince ourselves that (\ref{homogeneous1to3combinedprime}), (\ref{homogeneous4prime}) is also the homogeneous feasibility model of primal-dual SDP pair (\ref{primalSDP})-(\ref{dualSDP}), just like (\ref{homogeneous1})-(\ref{homogeneous4}), and (\ref{homogeneous1to3combined}), (\ref{homogeneous4prime}).  

We are now ready to express the homogeneous feasibility model of primal-dual SDP pair (\ref{primalSDP})-(\ref{dualSDP}) as SDLCP (\ref{SDLCP1})-(\ref{SDLCP3}) by letting $n_1 = n+1, q = 0$, and $\mathcal{A}_1, \mathcal{B}_1$ such that
\begin{eqnarray}\label{def:A1}
\begin{array}{lll}
(\mathcal{A}_1(X^1))_i & := & {\rm{Tr}}\left( \left[ \begin{array}{cc}
														A_i & 0 \\
														0 & -b_i 
													\end{array} \right] X^1 \right),\ \ i = 1, \ldots, m, \\
(\mathcal{A}_1(X^1))_i & := & {\rm{Tr}}(E^{i-m,n+1} X^1), \ \ i = m+1, \ldots, m+n, \\
(\mathcal{A}_1(X^1))_i & := & 0, \ \ i = m + n + 1, \ldots, \tilde{n}_1,
\end{array}
\end{eqnarray}
and
\begin{eqnarray}\label{def:B1}
\begin{array}{lll}
(\mathcal{B}_1(Y^1))_j & := & 0, \ \ j = 1, \ldots, m + n, \\
%(\mathcal{B}_1(Y^1))_j & = & {\rm{Tr}}(E^{j-(m+n),n+1} Y^1), \ \ j = m + n + 1, \ldots, m + 2n, \\
(\mathcal{B}_1(Y^1))_j & := & {\rm{Tr}}\left(\left[ \begin{array}{cc}
										B_{j-(m+n)} & 0 \\
										0 & d_{j-(m+n)}
										\end{array} \right]Y^1 \right), \ \ j = m + n + 1, \ldots, \tilde{n}_1,
\end{array}
\end{eqnarray}
for $X^1, Y^1 \in S^{n_1}$.

\begin{remark}\label{rem:LSDFP}
Recall that a linear semi-definite feasibility problem (LSDFP) written as SDLCP (\ref{SDLCP1})-(\ref{SDLCP3}) is such that in (\ref{SDLCP1}), $(\mathcal{A}_1(X^1))_i = 0$ for $i = m_1 + 1, \ldots, \tilde{n}_1$, $(\mathcal{B}_1(Y^1))_j = 0$ for $j = 1, \ldots, m_1$, and $q_i = 0$ for $i = m_1 + 1, \ldots, \tilde{n}_1$ or $q_i = 0$ for $i = 1, \ldots, m_1$.  Here, $q = (q_1, \ldots, q_{\tilde{n}_1})^T$.  From (\ref{def:A1}), (\ref{def:B1}), we therefore see that the SDLCP representation of the homogeneous feasibility model has the structure of an LSDFP with $m_1 = m + n$ and $q = 0$.  This observation is important in that we are then able to apply results in the literature, namely \cite{Sim1}, to show the main result in the paper in Theorem \ref{thm:superlinearconvergence}.
\end{remark}

The following proposition relates a solution of the homogeneous feasibility model of primal-dual SDP pair (\ref{primalSDP})-(\ref{dualSDP}) to that of its SDLCP representation:
\begin{proposition}\label{prop:equivalence}
We have if $(X,Y,\tau,\kappa)$ satisfies (\ref{homogeneous1to3combinedprime}), (\ref{homogeneous4prime}), then
\begin{eqnarray}\label{eq:X1Y1}
X^1  =  \left[ \begin{array}{cc}
					X & 0 \\
					0 & \tau
				\end{array} \right], \quad
Y^1 = \left[ \begin{array}{cc}
					Y & \ast \\
					\ast & \kappa
			\end{array} \right],
\end{eqnarray}
where the ``$\ast$" entries in $Y^1$ are such that $Y^1 \in S^{n_1}_+$, satisfies (\ref{SDLCP1})-(\ref{SDLCP3}), where $n_1 = n + 1$, $q = 0$, $\mathcal{A}_1, \mathcal{B}_1$ are given  by (\ref{def:A1}), (\ref{def:B1}) respectively.  On the other hand, if $(X^1, Y^1)$ satisfies (\ref{SDLCP1})-(\ref{SDLCP3}), where $n_1 = n + 1$, $q = 0$, $\mathcal{A}_1, \mathcal{B}_1$ are given  by (\ref{def:A1}), (\ref{def:B1}) respectively, then $X^1, Y^1$ are given by (\ref{eq:X1Y1}), and $(X, Y, \tau, \kappa)$  satisfies (\ref{homogeneous1to3combinedprime}), (\ref{homogeneous4prime}).
\end{proposition}
\begin{proof}
The proposition is clear based on how $\mathcal{A}_1$ and $\mathcal{B}_1$ are defined in (\ref{def:A1}) and (\ref{def:B1}) respectively.
\end{proof}

We have another proposition below that shows that if primal-dual SDP pair (\ref{primalSDP})-(\ref{dualSDP}) satisfies Assumption \ref{ass:SDP}, then the SDLCP representation of its homogeneous feasibility model satisfies Assumption \ref{ass:SDLCPassumptions}:
\begin{proposition}\label{prop:SDLCPAssumption}
SDLCP (\ref{SDLCP1})-(\ref{SDLCP3}) with $n_1 = n+1$, $q = 0$ and $\mathcal{A}_1$, $\mathcal{B}_1$ given by (\ref{def:A1}), (\ref{def:B1}) respectively, satisfies Assumption \ref{ass:SDLCPassumptions} when primal-dual SDP pair (\ref{primalSDP})-
(\ref{dualSDP}) satisfies Assumption \ref{ass:SDP}.
\end{proposition}
\begin{proof}
We first make two observations.  Firstly, if $(X, Y, \tau, \kappa)$ satisfies  (\ref{homogeneous1to3combinedprime}), then ${\rm{Tr}}(XY) + \tau \kappa = 0$.  Secondly, the matrix on the left-hand side of (\ref{homogeneous1to3combinedprime}) has full row rank by Assumption \ref{ass:SDP}(b). 

\noindent Given SDLCP (\ref{SDLCP1})-(\ref{SDLCP3}) with $n_1 = n+1$, $q = 0$ and $\mathcal{A}_1$, $\mathcal{B}_1$ given by (\ref{def:A1}), (\ref{def:B1}) respectively.  Suppose
\begin{eqnarray*}
{\mathcal{A}}_1(X^1) + {\mathcal{B}}_1(Y^1) = 0
\end{eqnarray*}
for some $(X^1, Y^1) \in S^{n_1} \times S^{n_1}$.  Then $X^1$ and $Y^1$ are given  by
\begin{eqnarray*}
X^1  =  \left[ \begin{array}{cc}
					X & 0 \\
					0 & \tau
				\end{array} \right], \quad
Y^1 = \left[ \begin{array}{cc}
					Y & \ast \\
					\ast & \kappa
			\end{array} \right],
\end{eqnarray*} 
where $(X,Y, \tau, \kappa)$ satisfies (\ref{homogeneous1to3combinedprime}).  Hence, by the first observation above, we have ${\rm{Tr}}(X^1 Y^1) = {\rm{Tr}}(XY) + \tau \kappa = 0$.  Therefore, Assumption \ref{ass:SDLCPassumptions}(a) holds.  Furthermore, Assumption \ref{ass:SDLCPassumptions}(b) holds since a solution to the given SDLCP is $X^1 = 0, Y^1 = 0$.  Finally, the second observation above means that the matrix
\begin{eqnarray*}
\left[ \begin{array}{cccc}
        \mathcal{A} & -b & 0 & 0 \\
        0 & 0 &
        \mathcal{B} & d
        \end{array} \right]
\end{eqnarray*}
has full row rank.  This implies that the matrix $(\mathcal{A}_1 \ \mathcal{B}_1)$, where $\mathcal{A}_1$ and $\mathcal{B}_1$ are defined by (\ref{def:A1}) and (\ref{def:B1}) respectively, has full row rank, and hence Assumption \ref{ass:SDLCPassumptions}(c) holds as well. 
\end{proof}


%
%
%
%
%
%				
%By Proposition \ref{prop:equivalence}, we see that we can express the homogeneous feasibility model of primal-dual SDP pair (\ref{primalSDP})-(\ref{dualSDP}) as SDLCP (\ref{SDLCP1})-(\ref{SDLCP3}), with $n_1 = n+1$, $q = 0$, and $\mathcal{A}_1, \mathcal{B}_1$ given by (\ref{def:A1}), (\ref{def:B1}) respectively.  We have Assumption \ref{ass:SDLCPassumptions} holds for the resulting SDLCP.  If $(X^1, Y^1)$ satisfies ${\mathcal{A}}_1(X^1) + {\mathcal{B}}_1(Y^1) = 0$, then 
%\begin{eqnarray*}
%X^1  =  \left[ \begin{array}{cc}
%					X & 0 \\
%					0 & \tau
%				\end{array} \right], \quad
%Y^1 = \left[ \begin{array}{cc}
%					Y & \ast \\
%					\ast & \kappa
%			\end{array} \right],
%\end{eqnarray*} 
%where ${\rm{Tr}}(XY) + \tau \kappa = 0$, since $(X,Y,\tau,\kappa)$ satisfies (\ref{homogeneous1to3combinedprime}).  Hence, ${\rm{Tr}}(X^1Y^1) = 0$, and Assumption \ref{ass:SDLCPassumptions}(a) then holds.  Assumption \ref{ass:SDLCPassumptions}(b) holds since it is easy to see that $(X^1,Y^1) = (0,0)$ is a solution to the SDLCP, while Assumption \ref{ass:SDLCPassumptions}(c) is true by definition of $\mathcal{A}_1$ and $\mathcal{B}_1$ in (\ref{def:A1}), (\ref{def:B1}) respectively, and that the matrix on the left-hand side of (\ref{homogeneous1to3combinedprime}) has full row rank.


\section{An Infeasible Interior Point
Algorithm on the Homogeneous Feasibility Model}\label{sec:interiorpointalgorithm}

We describe in this section an infeasible path-following interior point algorithm on homogeneous
feasibility model (\ref{homogeneous1})-(\ref{homogeneous4}) (or (\ref{homogeneous1to3combined}), (\ref{homogeneous4prime}) or (\ref{homogeneous1to3combinedprime}), (\ref{homogeneous4prime})).  It generates iterates following an infeasible
central path in a (narrow) neighborhood.  This algorithm is a predictor-corrector type algorithm applied to the homogeneous feasibility model, and is first considered in \cite{Potra}.

An infeasible central path to homogeneous feasibility model (\ref{homogeneous1})-(\ref{homogeneous4}), 
$(X^c(\mu), y^c(\mu), Y^c(\mu),$ $\tau^c(\mu),$ $\kappa^c(\mu)) \in S^n_{++} \times \Re^m \times 
S^n_{++} \times \Re_{++} \times \Re_{++}$, satisfies
\begin{eqnarray*}
X^c(\mu)Y^c(\mu) & = & \mu I, \\
\tau^c(\mu) \kappa^c(\mu) & = & \mu,
\end{eqnarray*}
\noindent besides satisfying
\begin{eqnarray*}
{\mbox{Tr}}(A_i X^c(\mu)) - b_i\tau^c(\mu) & = & \frac{\mu}{\mu_0} ({\mbox{Tr}}(A_i X_0) - b_i\tau_0) ,\ i = 1, \ldots, m, \\
\sum_{i=1}^{m} (y^c(\mu))_i A_i + Y(\mu) - \tau(\mu) C & = & \frac{\mu}{\mu_0} \left( \sum_{i=1}^{m} (y_0)_i A_i + Y_0 - \tau_0 C \right) ,  \\
\kappa(\mu) - b^T y(\mu) + {\mbox{Tr}}(CX(\mu)) & = & \frac{\mu}{\mu_0} (\kappa_0 - b^T y_0 + {\mbox{Tr}}(CX_0)) \\
\end{eqnarray*}
for a given $(X_0,y_0, Y_0,\tau_0,\kappa_0) \in S^n_{++} \times \Re^m \times
S^n_{++} \times \Re_{++} \times \Re_{++}$, which is the value taken
by $(X^c(\mu),y^c(\mu),Y^c(\mu),$ $\tau^c(\mu),\kappa^c(\mu))$ when $\mu =
\mu_0$.

\begin{remark}\label{rem:centralpath}
In \cite{Sim1}, under Assumption \ref{ass:SDLCPassumptions}, the author discusses the existence and uniqueness of infeasible off-central paths, as defined in the paper, to SDLCP (\ref{SDLCP1})-(\ref{SDLCP3}).  Infeasible central path is an important and special infeasible off-central path.  Since the SDLCP representation of the homogeneous feasibility model as detailed in the previous section satisfies Assumption \ref{ass:SDLCPassumptions} (Proposition \ref{prop:SDLCPAssumption}), it means that infeasible central path to the SDLCP exists and is unique.  This ensures that given an infeasible interior point to the homogeneous feasibility model, the infeasible central path to the model, as defined above, passing through the point, exists and is unique.  Furthermore, any of its accumulation points is a solution to the model as is any of the accumulation points of an infeasible off-central path to SDLCP (\ref{SDLCP1})-(\ref{SDLCP3}). 
\end{remark}


From now onwards, whenever we mention central path, we are referring
to the infeasible central path.  


Consider the following (narrow) neighborhood of the central path:
\begin{eqnarray*}
\mathcal{N}(\beta,\mu) & := & \{(X, y, Y,\tau,\kappa) \in S^n_{++}
\times \Re^m \times S^n_{++} \times \Re_{++} \times \Re_{++}\ ;\\
& & \ \ \ \ (\|Y^{1/2}XY^{1/2} - \mu I \|_F^2 + (\tau \kappa - \mu)^2)^{1/2}
\leq \beta \mu,\ \mu = ({\rm{Tr}}(XY) + \tau \kappa)/(n+1) \}.
\end{eqnarray*}

In the algorithm described below, iterates generated by the algorithm always stay
within a neighborhood of the central path.  We consider the dual Helmberg-Kojima-Monteiro (HKM) search direction in the algorithm - see Remark \ref{rem:NT}.  Among different search directions used in interior point algorithms on SDLCPs/SDPs, the Alizadeh-Haeberly-Overton (AHO) \cite{Alizadeh}, Helmberg-Kojima-Monteiro (HKM) \cite{Helmberg,Kojima1,Monteiro3} and Nesterov-Todd (NT) \cite{Nesterov,Nesterov1} search directions are better known, with the latter two being implemented in SDP solvers, such as SeDuMi \cite{Sturm1} and SDPT3 \cite{Toh1}.  
  
Solving the following system of equations
for $(\Delta X, \Delta y, \Delta Y,\Delta \tau, \Delta \kappa) \in S^n \times \Re^m \times S^n \times \Re \times \Re$ plays
an important role in the algorithm:
\begin{eqnarray}
Y^{1/2}(X \Delta Y +  \Delta X Y)Y^{-1/2} + Y^{-1/2}(\Delta Y X + Y \Delta X)Y^{1/2} & = & 2(\sigma
\mu I
- Y^{1/2}XY^{1/2}), \label{sys1}\\
\kappa \Delta \tau + \tau \Delta \kappa & = & \sigma \mu - \tau
\kappa, \label{sys2}\\
{\rm{Tr}}(A_i \Delta X) - b_i \Delta \tau & = & -\overline{r}_i, \quad i = 1, \ldots, m,\label{sys3} \\
\sum_{i=1}^m \Delta y_i A_i + \Delta Y - \Delta \tau C & = & -
\overline{s}, \label{sys4} \\
\Delta \kappa - b^T \Delta y + {\rm{Tr}}(C \Delta X) & = & - \overline{\gamma}, \label{sys5}
\end{eqnarray}
where $\mu = ({\rm{Tr}}(XY) + \tau \kappa)/(n+1)$.  Note that it can be shown that $(\Delta X, \Delta y, \Delta Y, \Delta \tau, \Delta \kappa)$ in (\ref{sys1})-(\ref{sys5}) is uniquely determined \cite{Potra}.

%Written in matrix-vector form, (\ref{sys1})-(\ref{sys4}) can be
%written as
%
%\begin{eqnarray}\label{matrixvectorsystem}
%\left[ \begin{array}{cccc}
%        \mathcal{A} & -b & 0 & 0 \\
%        d{\mbox{svec}}(C)^T & -\mathcal{B}{\mbox{svec}}(C) &
%        \mathcal{B} & d \\
%        I & 0 & X \otimes_s Y^{-1} & 0 \\
%        0 & 1 & 0 & \frac{\tau}{\kappa}
%        \end{array} \right]
%\left[ \begin{array}{c}
%        {\mbox{svec}}(\Delta X) \\
%        \Delta \tau \\
%        {\mbox{svec}}(\Delta Y) \\
%        \Delta \kappa
%        \end{array} \right] =
%\left[ \begin{array}{c}
%        -\overline{r} \\
%        -\overline{s} \\
%        {\mbox{svec}}(\sigma \mu Y^{-1} - X) \\
%        \frac{\sigma \mu}{\kappa} - \tau
%        \end{array} \right].
%\end{eqnarray}
%Note that the matrix on the left-hand side of (\ref{matrixvectorsystem}) is invertible, and hence $(\Delta X, \Delta Y, \Delta \tau, \Delta \kappa)$ in (\ref{matrixvectorsystem}) can be uniquely determined.

The infeasible predictor-corrector path-following interior point algorithm
 on homogeneous feasibility model (\ref{homogeneous1}) - (\ref{homogeneous4})  is described as follows:
\begin{algorithm}\label{mainalgorithm} (See Algorithm 5.1 of \cite{Potra})
Given $\beta_1 < \beta_2$ with $\beta_2^2/(2(1-\beta_2)^2) \leq
\beta_1 < \beta_2 < \beta_2/(1-\beta_2) < 1$.  Choose $(X_0,y_0,Y_0,
\tau_0,\kappa_0) \in \mathcal{N}(\beta_1, \mu_0)$ with $(n+1) \mu_0
= {\rm{Tr}}(X_0 Y_0) + \tau_0 \kappa_0$. For $k = 0, 1, \ldots$,
do ($a1$) through ($a5$):
\begin{description}
\item[\hspace{5pt} ($a1$)] Set $X = X_k$, $y = y_k$, $Y = Y_k$, $\tau =
\tau_k$, $\kappa = \kappa_k$, and define
\begin{eqnarray*}
r_i & := & {\rm{Tr}}(A_i X) - b_i \tau, \quad i = 1, \ldots, m, \\
s & := & \sum_{i=1}^m y_i A_i + Y - \tau C, \\
\gamma & := & \kappa - b^T y + {\rm{Tr}}(CX).
\end{eqnarray*}
\item[\hspace{5pt} ($a2$)] If $\max \{({\rm{Tr}}(XY) + \tau
\kappa)/\tau^2 , | r_1/\tau |, \ldots, | r_m /\tau |, \| s/\tau \|  \} \leq \epsilon$, then
report $X/\tau$, $y/\tau$ and $Y/\tau$ as an approximate solution to
(\ref{primalSDP}) and (\ref{dualSDP}), respectively, and terminate.
If $\tau$ is sufficiently small, terminate with no optimal solutions
to (\ref{primalSDP}) and (\ref{dualSDP}) with zero duality gap.
\item[\hspace{5pt} ($a3$)] {\bf{[Predictor Step]}} Find the solution $(\Delta X_p,\Delta y_p, \Delta Y_p,\Delta \tau_p,
\Delta \kappa_p)$ of the linear system (\ref{sys1})-(\ref{sys5}), with
$\sigma = 0$, $\overline{r}_i = r_i, i = 1, \ldots, m$, $\overline{s} = s$ and $\overline{\gamma} = \gamma$. \newline
Define
\begin{eqnarray*}
\overline{X} = X + \overline{\alpha} \Delta X_p,\ \ \overline{y} = y + \overline{\alpha} \Delta y_p, \ \ \overline{Y} = Y +
\overline{\alpha} \Delta Y_p,\ \  \overline{\tau} = \tau +
\overline{\alpha}\Delta \tau_p,\ \ \overline{\kappa} = \kappa +
\overline{\alpha}\Delta \kappa_p,
\end{eqnarray*}
\noindent where the steplength $\overline{\alpha}$ satisfies
\begin{eqnarray}\label{steplengthinequality}
\alpha_1 \leq \overline{\alpha} \leq \alpha_2.
\end{eqnarray}
Here,
\begin{eqnarray}
\alpha_1 & = & \frac{2}{\sqrt{1 + 4 \delta/(\beta_2 - \beta_1)} +1},
\label{steplengthinequality1}\\
\delta & = & \frac{1}{\mu} \left\| \left[ \begin{array}{cc}
                                                Y & 0 \\
                                                0 & \kappa
                                            \end{array}\right]^{1/2}
\left[ \begin{array}{cc}
            \Delta X_p & 0  \\
            0 & \Delta \tau_p
        \end{array} \right]
\left[ \begin{array}{cc}
            \Delta Y_p & 0 \\
            0 & \Delta \kappa_p
        \end{array} \right]
\left[ \begin{array}{cc}
            Y & 0 \\
            0 & \kappa
        \end{array} \right]^{-1/2} \right\|_F,
        \label{steplengthinequality2}
\end{eqnarray}
where 
\begin{eqnarray*}
\mu = \frac{{\rm{Tr}}(XY) + \tau \kappa}{n + 1},
\end{eqnarray*}
and
\begin{eqnarray*}
& & \alpha_2 = \max \{ \tilde{\alpha} \in [0,1] \ ; \ (X+ \alpha \Delta X_p, y + \alpha \Delta y_p,  Y +
\alpha \Delta Y_p, \tau + \alpha \Delta \tau_p, \kappa + \alpha \Delta \kappa_p)
\\ 
& & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \in \mathcal{N}(\beta_2,(1-\alpha)\mu)\ \forall\ \alpha \in
[0,\tilde{\alpha}]\}.
\end{eqnarray*}
%If $\overline{\alpha} = 1$, then $\overline{X}$ and $\overline{Y}$
%solve (\ref{primalSDP}) and (\ref{dualSDP}) respectively, and
%terminate.
\item[\hspace{5pt} ($a4$)] {\bf{[Corrector Step]}} Find the solution $(\Delta X_c, \Delta y_c, \Delta Y_c, \Delta \tau_c, \Delta \kappa_c)$ of the
linear system (\ref{sys1})-(\ref{sys4}), with $\sigma = 1 -
\overline{\alpha}$, $\overline{r}_i = 0, i = 1, \ldots, m$, $\overline{s} = 0$ and $\overline{\gamma} = 0$.  Set
\begin{eqnarray*}
\begin{array}{c}
X_+ = \overline{X} + \Delta X_c,\ \ y_+ = \overline{y} + \Delta y_c,\ \ Y_+ = \overline{Y} + \Delta Y_c, \ \ \tau_+ =
\overline{\tau} + \Delta \tau_c,\ \ \kappa_+ = \overline{\kappa} +
\Delta \kappa_c, \\
\mu_+ = (1 - \overline{\alpha})\mu.
\end{array}
\end{eqnarray*}
\item[\hspace{5pt} ($a5$)] Set
\begin{eqnarray*}
\begin{array}{c}
X_{k+1} = X_+,\ \ y_{k+1} = y_+, \ \ Y_{k+1} = Y_+, \ \ \tau_{k+1} = \tau_+, \ \
\kappa_{k+1} = \kappa_+,\\
\mu_{k+1} = \mu_+.
\end{array}
\end{eqnarray*}
\end{description}
\end{algorithm}

The above algorithm can be easily adapted to solve primal-dual SDP pair (\ref{primalSDP})-(\ref{dualSDP}) instead of its homogeneous feasibility model.  An advantage of applying the algorithm on its homogeneous feasibility model is that we have superlinear convergence of iterates generated by the algorithm, as shown in Theorem \ref{thm:superlinearconvergence}.

For $k = 0, 1, \ldots$, define
\begin{eqnarray*}
(r_k)_i & := & {\rm{Tr}}(A_i X_k) - b_i \tau_k, \quad i = 1, \ldots, m, \\
s_k & := & \sum_{i=1}^m (y_k)_i A_i + Y_k - \tau_k C, \\
\gamma_k & := & \kappa_k - b^T y_k + {\rm{Tr}}(CX_k).
\end{eqnarray*}


\begin{remark}\label{rem:Remark1}
For all $k \geq 0$, we have
\begin{eqnarray*}
(X_k, y_k, Y_k, \tau_k, \kappa_k) \in \mathcal{N}(\beta_1, \mu_k).
\end{eqnarray*}
\end{remark}
Remark \ref{rem:Remark1} holds by \cite{Potra} - see also \cite{Potra1}.

\begin{remark}\label{rem:initialiterate}
Throughout this paper, we consider Algorithm \ref{mainalgorithm} with initial iterate $(X_0, y_0, Y_0,$ $\tau_0, \kappa_0) \in \mathcal{N}(\beta_1, \mu_0)$ such that $X_0 \in S^n_{++}$ is feasible to the primal SDP (\ref{primalSDP}), $(y_0, Y_0) = (0, I)$, $\tau_0 = 1$, and $\kappa_0 = 1$.  Therefore, we have $(r_0)_i =0, i = 1, \ldots, m$, while $s_0$ and $\gamma_0$ are generally nonzero in the algorithm.
\end{remark}

The following theorem provides global convergence and polynomial iteration complexity of Algorithm \ref{mainalgorithm}.  It is taken from \cite{Potra} and is stated here for the sake of completeness, even though the focus of this paper is to study the local convergence behavior of iterates generated by the algorithm.
\begin{theorem}\label{complexitytheorem} (See Theorem 5.2 of
\cite{Potra})  Assume that in Algorithm \ref{mainalgorithm}, we
choose a starting point of the form $(X_0,y_0,Y_0,\tau_0,\kappa_0) = (I,0,
I, 1, 1)$. Let
\begin{eqnarray*}
\epsilon_0 = \max \{ {\rm{Tr}}(X_0 Y_0) + \tau_0 \kappa_0,
|(r_0)_1 |, \ldots, | (r_0)_m |, \|s_0\| \},
\end{eqnarray*}
\noindent and let $\epsilon > 0$ be arbitrary.  Then the following
statements hold:
\begin{description}
\item[\hspace{5pt} (i)] If there exists an optimal solution to
(\ref{primalSDP}) and (\ref{dualSDP}) with zero duality gap, then
Algorithm \ref{mainalgorithm} terminates with an
$\epsilon$-approximate solution $(X_k/\tau_k,y_k/\tau_k,Y_k/\tau_k) \in S^n_+
\times S^n_+$ with
\begin{eqnarray*}
0 \leq {\rm{Tr}}(X_k Y_k/\tau_k^2) \leq \epsilon,\ \
|(r_k)_i/\tau_k| \leq \epsilon, i = 1, \ldots, m,\ \ \|s_k/\tau_k\| \leq \epsilon
\end{eqnarray*}
in a finite number of steps $k = K_\epsilon < \infty$.
\item[\hspace{5pt} (ii)] If $\rho^\ast = {\rm{Tr}}(X^\ast +
Y^\ast)$, where $X^\ast$ solves (\ref{primalSDP}) and $(y^\ast, Y^\ast)$ solves (\ref{dualSDP}) with zero duality gap, then $K_\epsilon
= \mathcal{O}(\sqrt{n} \ln (\rho^\ast \epsilon_0/\epsilon))$.
\item[\hspace{5pt} (iii)] For any choice of $\rho > 0$, there is an
index $k = \hat{K}_\epsilon = \mathcal{O}(\sqrt{n}\ln (\rho
\epsilon_0/\epsilon))$ such that either
    \begin{description}
    \item[(iiia)] $(X_k/\tau_k, y_k/\tau_k, Y_k/\tau_k)$ satisfies $0 \leq
    {\rm{Tr}}(X_kY_k/\tau_k^2) \leq \epsilon, |(r_k)_i/\tau_k | \leq
    \epsilon, i = 1, \ldots, m,$ $\|s_k / \tau_k \| \leq \epsilon$, or
    \item[(iiib)] $\tau_k < ( 1- \beta_1)/(\rho + 1)$, and in this case there is no solution $X^\ast, (y^\ast, Y^\ast)$ that solves
    (\ref{primalSDP}) and (\ref{dualSDP}) respectively, with ${\rm{Tr}}(X^\ast + Y^\ast) \leq \rho$
    \end{description}
\end{description}
\end{theorem}

It is easy to convince ourselves that Theorem \ref{complexitytheorem} still holds if $X_0, Y_0 \in S^n_{++}, y_0 \in \Re^m, \tau_0 > 0$ and $\kappa_0 > 0$, with $(X_0, y_0, Y_0, \tau_0, \kappa_0) \in \mathcal{N}(\beta_1, \mu_0)$.


Algorithm \ref{mainalgorithm} can be expressed as an equivalent algorithm, which we describe below, that is used to solve the SDLCP representation of the homogeneous feasibility model, (\ref{SDLCP1})-(\ref{SDLCP3}), where $n_1 = n + 1$, $q = 0$, $\mathcal{A}_1, \mathcal{B}_1$ are given  by (\ref{def:A1}), (\ref{def:B1}) respectively.  Before describing the algorithm,  we first define  an analogous (narrow) neighborhood of the central path of the SDLCP representation:
\begin{eqnarray*}
\mathcal{N}_1(\beta, \mu^1) & := & \{ (X^1, Y^1) \in S^{n_1}_{++} \times S^{n_1}_{++}\ ; \ \| (Y^1)^{1/2} X^1 (Y^1)^{1/2} - \mu^1 I \|_F \leq \beta \mu^1, \\
&  &  \ \ \ \ \mu^1 = {\rm{Tr}}(X^1 Y^1)/n_1 \}.
\end{eqnarray*}

Similar as before, we have a system of equations for $(\Delta X^1, \Delta Y^1) \in S^{n_1} \times S^{n_1}$ that plays an important role in the algorithm to solve the SDLCP representation, just like the system of equations for Algorithm \ref{mainalgorithm}:
\begin{eqnarray}
& & (Y^1)^{1/2}(X^1 \Delta Y^1 + \Delta X^1 Y^1)(Y^1)^{-1/2} + (Y^1)^{-1/2}(\Delta Y^1 X^1 + Y^1 \Delta X^1)(Y^1)^{1/2} \nonumber \\ 
&  & = 2(\sigma \mu^1 I - (Y^1)^{1/2} X^1 (Y^1)^{1/2}), \label{eq:sys1prime} \\
& & \mathcal{A}_1(\Delta X^1) + \mathcal{B}_1(\Delta Y^1) = - \overline{r}. \label{eq:sys2prime}
\end{eqnarray}
Note that it can be shown that $(\Delta X^1, \Delta Y^1)$ obtained from (\ref{eq:sys1prime}), (\ref{eq:sys2prime}) exists and is unique \cite{Sim1, Potra1}.

The corresponding algorithm to Algorithm \ref{mainalgorithm} for the SDLCP representation is given by:
\begin{algorithm}\label{mainalgorithm2} (See Algorithm 4.1 of \cite{Sim1}; Algorithm 2.1 of \cite{Potra1})
Given $\beta_1 < \beta_2$ with $\beta_2^2/(2(1-\beta_2)^2) \leq
\beta_1 < \beta_2 < \beta_2/(1-\beta_2) < 1$.  Choose $(X_0^1,Y_0^1) \in S^{n_1}_{++} \times S^{n_1}_{++}$ such that 
\begin{eqnarray}\label{def:initialiterateSDLCP}
X^1_0 = \left[ \begin{array}{cc}
					X_0 & 0 \\
					0   & \tau_0
				\end{array} \right], \quad
Y^1_0 = \left[ \begin{array}{cc}
					Y_0 & 0 \\
					0 & \kappa_0
				\end{array} \right],
\end{eqnarray}
where $X_0,Y_0,\tau_0,\kappa_0$ are from the initial iterate in Algorithm \ref{mainalgorithm}. For $k = 0, 1, \ldots$,
do ($a1$) through ($a5$):
\begin{description}
\item[\hspace{5pt} ($a1$)] Set $X^1 = X^1_k$, $Y^1 = Y^1_k$, and define
\begin{eqnarray*}
r := \mathcal{A}_1(X^1) + \mathcal{B}_1(Y^1).
\end{eqnarray*}
\item[\hspace{5pt} ($a2$)] If $\max \{{\rm{Tr}}(X^1Y^1)/(X^1)^2_{n_1,n_1} ,  \| r /X^1_{n_1,n_1} \|  \} \leq \epsilon$, then terminate with the solution $(X^1,Y^1)$.
If $X^1_{n_1,n_1}$ is sufficiently small, terminate with no optimal solutions
to (\ref{primalSDP}) and (\ref{dualSDP}) with zero duality gap.
\item[\hspace{5pt} ($a3$)] {\bf{[Predictor Step]}} Find the solution $(\Delta X^1_p, \Delta Y^1_p)$ of the linear system (\ref{eq:sys1prime}), (\ref{eq:sys2prime}), with
$\sigma = 0$, $\overline{r} = r$. \newline
Define
\begin{eqnarray*}
\overline{X}^1 = X^1 + \overline{\alpha} \Delta X^1_p,\ \ \overline{Y}^1 = Y^1 +
\overline{\alpha} \Delta Y^1_p,
\end{eqnarray*}
\noindent where the steplength $\overline{\alpha}$ satisfies
\begin{eqnarray}\label{steplengthinequalityprime}
\alpha_1 \leq \overline{\alpha} \leq \alpha_2.
\end{eqnarray}
Here,
\begin{eqnarray}
\alpha_1 & = & \frac{2}{\sqrt{1 + 4 \delta/(\beta_2 - \beta_1)} +1},
\label{steplengthinequality1prime}\\
\delta & = & \frac{1}{\mu^1} \| (Y^1)^{1/2} \Delta X_p^1 \Delta Y_p^1 (Y^1)^{-1/2} \|_F,
        \label{steplengthinequality2prime}
\end{eqnarray}
where 
\begin{eqnarray*}
\mu^1 = \frac{{\rm{Tr}}(X^1Y^1)}{n_1},
\end{eqnarray*}
and
\begin{eqnarray*}
\alpha_2 = \max \{ \tilde{\alpha} \in [0,1] \ ; \ (X^1+ \alpha \Delta X^1_p, Y^1 +
\alpha \Delta Y^1_p) \in \mathcal{N}_1(\beta_2,(1-\alpha)\mu^1)\ \forall\ \alpha \in
[0,\tilde{\alpha}]\}.
\end{eqnarray*}
%If $\overline{\alpha} = 1$, then $\overline{X}$ and $\overline{Y}$
%solve (\ref{primalSDP}) and (\ref{dualSDP}) respectively, and
%terminate.
\item[\hspace{5pt} ($a4$)] {\bf{[Corrector Step]}} Find the solution $(\Delta X^1_c, \Delta Y^1_c)$ of the
linear system (\ref{eq:sys1prime}), (\ref{eq:sys2prime}), with $\sigma = 1 -
\overline{\alpha}$ and $\overline{r} = 0$.  Set
\begin{eqnarray*}
\begin{array}{c}
X^1_+ = \overline{X}^1 + \Delta X^1_c,\ \ Y^1_+ = \overline{Y}^1 + \Delta Y^1_c, \\
\mu_+^1 = (1 - \overline{\alpha})\mu^1.
\end{array}
\end{eqnarray*}
\item[\hspace{5pt} ($a5$)] Set
\begin{eqnarray*}
\begin{array}{c}
X^1_{k+1} = X^1_+,\ \ Y^1_{k+1} = Y^1_+, \\
\mu_{k+1}^1 = \mu_+^1.
\end{array}
\end{eqnarray*}
\end{description}
\end{algorithm}

The following proposition relates the iterates in the two algorithms:
\begin{proposition}\label{prop:iteratesbothalgorithms}
For all $k \geq 0$,
\begin{eqnarray}\label{eq:kiterateSDLCP}
X^1_k = \left[ \begin{array}{cc}
					X_k & 0 \\
					0   & \tau_k
				\end{array} \right], \quad
Y^1_k = \left[ \begin{array}{cc}
					Y_k & 0 \\
					0 & \kappa_k
				\end{array} \right].
\end{eqnarray}
Consequently, $\mu_k^1 = \mu_k$ and $(X^1_k, Y^1_k) \in \mathcal{N}_1(\beta_1, \mu^1_k)$.
\end{proposition}
\begin{proof}
We show (\ref{eq:kiterateSDLCP}) holds by induction on $k \geq 0$.  It is clear that (\ref{eq:kiterateSDLCP}) holds when $k = 0$, by the choice of $X^1_0, Y^1_0$.  Suppose (\ref{eq:kiterateSDLCP}) holds for $k = k_0 \geq 0$.  Then, by comparing the system of equations (\ref{sys1})-(\ref{sys5}) and (\ref{eq:sys1prime}), (\ref{eq:sys2prime}), it can be seen easily that
\begin{eqnarray*}
\Delta X^1_p = \left[ \begin{array}{cc}
					\Delta X_p & 0 \\
					0   & \Delta \tau_p
				\end{array} \right], \quad
\Delta Y^1_p = \left[ \begin{array}{cc}
					\Delta Y_p & 0 \\
					0 & \Delta \kappa_p
				\end{array} \right]
\end{eqnarray*}
satisfy (\ref{eq:sys1prime}), (\ref{eq:sys2prime}) when $\sigma = 0, \overline{r} = r = \mathcal{A}_1(X^1) + \mathcal{B}_1(Y^1)$.  Furthermore, the steplength $\overline{\alpha}$ in the $(k_0 + 1)^{\rm{th}}$ iteration of both algorithms are the same.  These lead to
\begin{eqnarray}\label{eq:overlineX1Y1withoverlineXY}
\overline{X}^1 = \left[ \begin{array}{cc}
					\overline{X} & 0 \\
					0   & \overline{\tau}
				\end{array} \right], \quad
\overline{Y}^1 = \left[ \begin{array}{cc}
					\overline{Y} & 0 \\
					0 & \overline{\kappa}
				\end{array} \right].
\end{eqnarray}
With (\ref{eq:overlineX1Y1withoverlineXY}), again comparing the system of equations (\ref{sys1})-(\ref{sys5}) and (\ref{eq:sys1prime}), (\ref{eq:sys2prime}), it is also easy to see that
\begin{eqnarray*}
\Delta X^1_c = \left[ \begin{array}{cc}
					\Delta X_c & 0 \\
					0   & \Delta \tau_c
				\end{array} \right], \quad
\Delta Y^1_c = \left[ \begin{array}{cc}
					\Delta Y_c & 0 \\
					0 & \Delta \kappa_c
				\end{array} \right]
\end{eqnarray*}
satisfy (\ref{eq:sys1prime}), (\ref{eq:sys2prime}) when $\sigma = 1 - \overline{\alpha}$ and $\overline{r} = 0$.  Hence, we conclude that (\ref{eq:kiterateSDLCP}) holds for $k = k_0 + 1$.  Therefore, by induction, (\ref{eq:kiterateSDLCP}) holds for all $k \geq 0$.  Furthermore, we have
\begin{eqnarray*}
\mu_k^1 = \frac{{\rm{Tr}}(X^1_k Y^1_k)}{n_1} = \frac{{\rm{Tr}}(X_kY_k) + \tau_k \kappa_k}{n + 1} = \mu_k.
\end{eqnarray*}
Finally, comparing the definition of the neighborhood $\mathcal{N}(\beta, \mu)$ and the neighborhood $\mathcal{N}_1(\beta, \mu^1)$, and that $\mu_k = \mu_k^1$, we see that since $(X_k, y_k, Y_k, \tau_k, \kappa_k) \in \mathcal{N}(\beta_1, \mu_k)$ (Remark \ref{rem:Remark1}), we have $(X_k^1,Y_k^1) \in \mathcal{N}_1(\beta_1,\mu_k^1)$. 
\end{proof}

%We remark that $(X_0, Y_0, \tau_0, \kappa_0)$ that forms the initial iterate to Algorithm \ref{mainalgorithm} satisfies (\ref{homogeneous1to3combined}) in its first $m$ equations, and (\ref{homogeneous4prime}).  In Algorithm \ref{mainalgorithm2}, the corresponding initial iterate is given by
%
%and it satisfies the first $m+n$ equations in (\ref{SDLCP1}), and (\ref{SDLCP3}).  The relationship between the search directions in Algorithm \ref{mainalgorithm} and that in Algorithm \ref{mainalgorithm2} is clear.



\subsection{Superlinear Convergence}\label{subsec:superlinearconvergence}

We show in this subsection that Algorithm \ref{mainalgorithm} applied to the homogeneous feasibility model when the initial iterate $(X_0,y_0,Y_0,\tau_0,\kappa_0)$ is such that $X_0 \in S^n_{++}$ is feasible to primal SDP (\ref{primalSDP}), $(y_0,Y_0) = (0,I)$, $\tau_0 = 1$ and $\kappa_0 = 1$, leads to superlinear convergence of iterates generated by the algorithm, besides global convergence and polynomial iteration complexity (Theorem \ref{complexitytheorem}).  First, we state an additional assumption, strict complementarity, on primal-dual SDP pair (\ref{primalSDP})-(\ref{dualSDP}) that is needed for this result to hold.  Note that strict complementarity assumption is generally considered the minimal requirement for superlinear convergence of interior point algorithms, as investigated for example in \cite{Monteiro8}.

%We do this by first observing that the homogeneous feasibility model is equivalent to a semi-definite linear complementarity problem , which we describe below.  We can then apply results, as found in the literature, on superlinear convergence using interior point algorithms on a semi-definite linear complementarity problem to show that Algorithm \ref{mainalgorithm} is indeed superlinearly convergent.

\begin{assumption}\label{ass:strictcomplementarity}
There exists an optimal solution $X^\ast$ to primal SDP (\ref{primalSDP}) and an optimal solution $(y^\ast, Y^\ast)$ to dual SDP (\ref{dualSDP}) such that $X^\ast + Y^\ast \in S^n_{++}$.
\end{assumption}
A consequence of the above assumption on homogeneous feasibility model (\ref{homogeneous1})-(\ref{homogeneous4}) is that it has a solution $(X^\ast, y^\ast, Y^\ast, \tau^\ast, \kappa^\ast)$ with $X^\ast + Y^\ast \in S^n_{++}$ and $\tau^\ast + \kappa^\ast > 0$.  This then implies that its SDLCP representation has a solution $(X^{1,\ast},Y^{1,\ast})$ such that $X^{1,\ast} + Y^{1,\ast} \in S^{n_1}_{++}$, that is, the SDLCP representation has a strictly complementary solution.  

We consider local superlinear convergence using Algorithm \ref{mainalgorithm} in the sense of
\begin{eqnarray}\label{def:superlinearconvergence}
\frac{\mu_{k+1}}{\mu_k} \rightarrow 0, \ \ {\rm{as}}\ k \rightarrow \infty.
\end{eqnarray}
Consideration of superlinear convergence in the form (\ref{def:superlinearconvergence}) is typical in the interior point literature, such as \cite{Kojima,Luo,Potra1}.  It is closely related to local convergence behavior of iterates, as studied for example in \cite{Potrasingle}.

%Observe that since $X^{1,\ast}, Y^{1,\ast}$ commute, they are jointly diagonalizable by some orthogonal matrix $Q$.  So using this orthogonal similarity transformation on the matrices in the SDLCP representation, we may assume without loss of generality that
%\begin{eqnarray*}
%X^{1,\ast} = \left[ \begin{array}{cc}
%					\Gamma^{X} & 0 \\
%					0  &  0
%					\end{array} \right], \quad
%Y^{1,\ast} = \left[ \begin{array}{cc}
%					0  &  0 \\
%					0  &  \Gamma^Y
%					\end{array} \right],
%\end{eqnarray*}
%where $\Gamma^X = {\rm{Diag}}(\lambda_1^X, \ldots, \lambda_{k_0}^X) \in S^{k_0}_{++}$ and $\Gamma^Y = {\rm{Diag}}(\lambda_1^Y, \ldots, \lambda_{n_1 - k_0}^Y) \in S^{n_1 - k_0}_{++}$, by Assumption \ref{ass:strictcomplementarity}.
%
%Henceforth, whenever we partition a matrix $U \in S^{n_1}$, it is always understood that it is partitioned as $\left[ \begin{array}{cc}
%												U_{11}  &   U_{12}  \\
%												U_{12}^T & U_{22}
%											\end{array} \right]$, where $U_{11} \in S^{k_0}$, $U_{22} \in S^{n_1 - k_0}$ and $U_{12} \in \Re^{k_0 \times (n_1 - k_0)}$.
%
%Since the SDLCP representation satisfies Assumption \ref{ass:strictcomplementarity} in addition to Assumption \ref{ass:SDLCPassumptions} (Proposition \ref{prop:SDLCPAssumption}), we have
%\begin{eqnarray}\label{eq:X_kY_k_Order}
%X^1_k = \left[ \begin{array}{cc}
%				\Theta(1) & O(\sqrt{\mu_k}) \\
%				O(\sqrt{\mu_k}) & \Theta(\mu_k)
%				\end{array} \right], \quad 
%Y^1_k = \left[ \begin{array}{cc}
%				\Theta(\mu_k) & O(\sqrt{\mu_k}) \\
%				O(\sqrt{\mu_k}) & \Theta(1)
%				\end{array} \right].
%\end{eqnarray}
%The proof for (\ref{eq:X_kY_k_Order}) can be found for example in \cite{Preib,Sim2}.

The following result, which is the main result in this paper, ends this subsection:
\begin{theorem}\label{thm:superlinearconvergence}
Given an initial iterate $(X_0,y_0,Y_0,\tau_0,\kappa_0)$ to Algorithm \ref{mainalgorithm}, with $X_0 \in S^n_{++}$ feasible to primal SDP (\ref{primalSDP}), $(y_0,Y_0) = (0,I)$, $\tau_0 = 1$, and $\kappa_0 = 1$.  Iterates generated by Algorithm \ref{mainalgorithm} converge superlinearly in the sense of (\ref{def:superlinearconvergence}).
\end{theorem}
\begin{proof}
Let us show the result in the theorem by considering iterates generated by Algorithm \ref{mainalgorithm2} instead.  These iterates are related to those generated by Algorithm \ref{mainalgorithm} in a close way as shown in Proposition \ref{prop:iteratesbothalgorithms}.  We note that Algorithm \ref{mainalgorithm2} is Algorithm 4.1 in \cite{Sim1}, and Assumptions 2.1 and 3.1 in \cite{Sim1} are satisfied for the SDLCP representation of the homogeneous feasibility model (\ref{homogeneous1})-(\ref{homogeneous4}) defined in the previous section (Proposition \ref{prop:SDLCPAssumption} and Assumption \ref{ass:strictcomplementarity}).  Hence, results in \cite{Sim1} are applicable to our SDLCP representation.  The SDLCP representation that Algorithm \ref{mainalgorithm2} is solving has the structure of an LSDFP (Remark \ref{rem:LSDFP}), and therefore Theorem 5.1 in \cite{Sim1} can be applied on our SDLCP representation provided that Condition (51) in the theorem is satisfied.  

\noindent  Our choice of initial iterate to Algorithm \ref{mainalgorithm} leads to an initial iterate, $(X^1_0, Y^1_0)$, to Algorithm \ref{mainalgorithm2} that satisfies $\mathcal{A}_1(X^1_0) = 0$.  Therefore, Condition (51) of Theorem 5.1 in \cite{Sim1} is satisfied, and by the theorem, we have superlinear convergence in the sense that
\begin{eqnarray*}\label{larrow:convergence}
\frac{\mu^1_{k+1}}{\mu^1_k} \rightarrow 0, \ \ {\rm{as}}\ k \rightarrow \infty.
\end{eqnarray*}
This implies by Proposition \ref{prop:iteratesbothalgorithms}, where we have $\mu_k^1 = \mu_k$, superlinear convergence in the sense of (\ref{def:superlinearconvergence}) using Algorithm \ref{mainalgorithm} to solve the homogeneous feasibility model (\ref{homogeneous1})-(\ref{homogeneous4}) for the given initial iterate.
\end{proof}

We remark that the conclusion in Theorem \ref{thm:superlinearconvergence} still holds if $X_0$ is a strictly feasible solution to primal SDP (\ref{primalSDP}) and $\tau_0 = 1$ without the need for $y_0$ to be zero, $Y_0$ to be the identity matrix and $\kappa_0 = 1$.  However, we require $Y_0 \in S^n_{++}$ and $\kappa_0 > 0$.

\begin{remark}\label{rem:NT}
Similar result as Theorem \ref{thm:superlinearconvergence} also holds when the NT search direction is used in Algorithm \ref{mainalgorithm} instead of the dual HKM search direction.  The equivalent algorithm on the SDLCP representation in this case is Algorithm 1 in \cite{Sim6}.  We can then apply Theorem 4 or Corollary 1 in \cite{Sim6} to conclude superlinear convergence of iterates when the initial iterate to Algorithm \ref{mainalgorithm} with the NT search direction comes from a strictly feasible solution to primal SDP (\ref{primalSDP}).  The process to show this is analogous to what we have discussed and we will not repeat it again.
\end{remark}

\section{Conclusion}\label{sec:conclusion}

In this paper, we show superlinear convergence of an implementable polynomial-time infeasible predictor-corrector primal-dual path following interior point algorithm on the homogeneous feasibility model of a primal-dual SDP pair under the assumption of strict complementarity and a suitable choice of initial iterate to the algorithm. We do not need to modify the algorithm to show this.  This result improves on what is known in the IPM literature.    


\bibliographystyle{plain}
\bibliography{Reference_Sim}




%\begin{thebibliography}{9}
%\bibitem{Boyd1}
%S. Boyd and L. Vandenberghe, \emph{Convex Optimization}, Cambridge University Press, 2004.
%\bibitem{deKlerk}
%E. de Klerk, C. Roos and T. Terlay, \emph{Initialization in
%semidefinite programming via a self-dual skew-symmetric embedding,}
%Operations Research Letters, Vol. 20(1997), pp. 213-221.
%\bibitem{Kojima}
%M. Kojima, M. Shida and S. Shindoh, \emph{Local convergence of
%predictor-corrector infeasible-interior-point algorithms for SDPs
%and SDLCPs,}  Mathematical Programming, Series A, Vol. 80(1998), pp.
%129-160.
%\bibitem{Kojima1}
%M. Kojima, S. Shindoh and S. Hara, \emph{Interior-point methods for
%the monotone semidefinite linear complementarity problem in
%symmetric matrices,} SIAM Journal on Optimization, Vol. 7(1997), pp.
%86-125.
%\bibitem{Luo}
%Z.-Q. Luo, J.F. Sturm and S. Zhang, \emph{Superlinear convergence of a symmetric primal-dual path following algorithm for semidefinite programming}, SIAM Journal on Optimization, Vol. 8(1998), pp. 59-81.
%\bibitem{Potrasingle}
%F.A. Potra, \emph{Q-superlinear convergence of the iterates in primal-dual interior-point methods,} Mathematical Programming, Series A, Vol. 91(2001), pp. 99-115.
%\bibitem{Potra}
%F.A. Potra and R. Sheng, \emph{On homogeneous interior-point
%algorithms for semidefinite programming,} Optimization Methods and
%Software, Vol. 9(1998), pp. 161-184.
%\bibitem{Potra1}
%F.A. Potra and R. Sheng, \emph{A superlinearly convergent
%primal-dual infeasible-interior-point algorithm for semidefinite
%programming,} SIAM Journal on Optimization, Vol. 8(1998), pp.
%1007-1028.
%\bibitem{Preib}
%M. Prei$\ss$ and J. Stoer, \emph{Analysis of
%infeasible-interior-point paths arising with semidefinite linear
%complementarity problems,}  Mathematical Programming, Series A, Vol.
%99(2004), pp. 499-520.
%\bibitem{Sim1}
%C.-K. Sim, \emph{Superlinear convergence of an infeasible
%predictor-corrector path-following interior point algorithm for a
%semidefinite linear complementarity problem using the
%Helmberg-Kojima-Monteiro direction,} SIAM Journal on Optimization,
%Vol. 21(2011), pp. 102-126.
%\bibitem{Sim}
%C.-K. Sim and G. Zhao, \emph{Underlying paths in interior point
%methods for the monotone semidefinite linear complementarity
%problem,}  Mathematical Programming, Series A, Vol. 110(2007), pp.
%475-499.
%\bibitem{Sim2}
%C.-K. Sim and G. Zhao, \emph{Asymptotic behavior of
%Helmberg-Kojima-Monteiro (HKM) paths in interior point methods for
%monotone semidefinite linear complementarity problems: general
%theory,} Journal of Optimization Theory and Applications, Vol.
%137(2008), pp. 11-25.
%\end{thebibliography}



\end{document}




















Assume that there exist an optimal solution to (\ref{primalSDP}) and
an optimal solution to (\ref{dualSDP}) with zero duality gap. The
existence of such optimal solutions implies that every accumulation
point $(X^\ast,Y^\ast,\tau^\ast,\kappa^\ast)$ of an off-central path
$(X(\mu),Y(\mu),\tau(\mu),\kappa(\mu))$ has $\tau^\ast
> 0$ and $\kappa^\ast = 0$.

We have $X^\ast/\tau^\ast$ is an optimal solution to
(\ref{primalSDP}) and $Y^\ast/\tau^\ast$ is an optimal solution to
(\ref{dualSDP}).  Furthermore, assume that $X^\ast$ and $Y^\ast$ are
strictly complementary, that is, $X^\ast + Y^\ast \in S^n_{++}$.
Since they commute, they can be jointly diagonalized by some
orthogonal matrix $Q$.  So, using this orthogonal similarity
transformation of the matrices with $X^\ast$ and $Y^\ast$ multiplied
by $Q^T$ on the left and $Q$ on the right, we may assume without
loss of generality that
\begin{eqnarray}\label{XastYast}
X^\ast = \left[ \begin{array}{cc}
                    \Lambda_{11}^\ast & 0  \\
                    0                 & 0
                    \end{array} \right],\ \
Y^\ast = \left[ \begin{array}{cc}
                    0  &  0 \\
                    0  &  \Lambda_{22}^\ast
                \end{array} \right],
\end{eqnarray}
where $\Lambda_{11}^\ast = {\mbox{Diag}}(\lambda_1^\ast, \ldots,
\lambda_{k_0}^\ast) \in S^{k_0}_{++}$ and $\Lambda_{22}^\ast =
{\mbox{Diag}}(\lambda_{k_0+1}^\ast, \ldots, \lambda_n^\ast) \in
S^{n-k_0}_{++}$.  Here, $\lambda_1^\ast, \ldots, \lambda_n^\ast$ are
real numbers greater than zero.  Let us then consider a transformed
(\ref{primalSDP}) and (\ref{dualSDP}) with $C$ replaced by $Q^T C
Q$, and $A_i$ replaced by $Q^T A_i Q$, $i = 1, \ldots, m$, from now
onwards.

Hereafter, whenever we partition a matrix $S \in S^n$, we do it in a
similar way; that is, $S$ is always partitioned as $\left(
\begin{array}{cc}
    S_{11} & S_{12} \\
    S_{12}^T & S_{22}
\end{array} \right)$, where $S_{11} \in S^{k_0}$, $S_{22} \in
S^{n-k_0}$, and $S_{12} \in \Re^{k_0 \times (n - k_0)}$.

We have the following propositions:
\begin{proposition}\label{boundednessoffcentralpaths}
The set $\mathcal{U}$ defined by
\begin{eqnarray*}
&&\{ (X(\mu),Y(\mu),\tau(\mu),\kappa(\mu)) \in S^n_{++} \times
S^n_{++} \times \Re_{++} \times \Re_{++}\ ;\ 0 < \mu \leq \mu_0,
\lambda_{\min}(XY)(\mu_0) \geq D,\\
&& \| X(\mu_0) \| \leq C, \| Y(\mu_0) \| \leq C, C_1 \leq
\tau(\mu_0) \leq C, C_1 \leq \kappa(\mu_0) \leq C \}
\end{eqnarray*}
is bounded for fixed $\mu_0, C, C_1, D > 0$.  Here,
$\lambda_{\min}(XY)(\mu_0)$ is the minimum eigenvalue of
$X(\mu_0)Y(\mu_0)$.
\end{proposition}
\noindent {\it{Proof:}} Consider
$(X(\mu),Y(\mu),\tau(\mu),\kappa(\mu)) \in \mathcal{U}$, with
$(X(\mu_0),Y(\mu_0),\tau(\mu_0),\kappa(\mu_0)) =
(X_0,Y_0,\tau_0,\kappa_0)$.

\noindent We have from (\ref{dualitygap2}),
\begin{eqnarray*}
{\mbox{tr}}\left( \left( X(\mu) - \frac{\mu}{\mu_0}X_0 \right)
\left( Y(\mu) - \frac{\mu}{\mu_0}Y_0 \right)\right) + \left(
\tau(\mu) - \frac{\mu}{\mu_0}\tau_0 \right) \left( \kappa(\mu) -
\frac{\mu}{\mu_0}\kappa_0 \right) = 0.
\end{eqnarray*}
\noindent Hence, using (\ref{parameter}), (\ref{parameter1}), we
have
\begin{eqnarray}\label{inequality1}
{\mbox{tr}}(X(\mu)Y_0) + {\mbox{tr}}(X_0Y(\mu)) + \tau(\mu) \kappa_0
+ \tau_0 \kappa(\mu) = \left(1 + \frac{\mu}{\mu_0} \right)
({\mbox{tr}}(X_0Y_0) + \tau_0\kappa_0 ) \leq M,
\end{eqnarray}
\noindent for $0 < \mu \leq \mu_0$, where $M > 0$ depends only on
$\mu_0$ and $C$.

\noindent Since $\|X_0 \| \leq C$ and $\| Y_0 \| \leq C$, together
with $\lambda_{\min}(X_0Y_0) \geq D$, we must have that
$\lambda_{\min}(X_0)$ and $\lambda_{\min}(Y_0)$ are uniformly
bounded from below by a positive constant independent of
$(X(\mu),Y(\mu))$ chosen from $\mathcal{U}$.  Hence, by
(\ref{inequality1}), $X(\mu)$ and $Y(\mu)$ are bounded for all
$(X(\mu),Y(\mu),\tau(\mu),\kappa(\mu)) \in \mathcal{U}$. Similarly,
with $\tau_0 \geq D_1$ and $\kappa_0 \geq D_1$, we have from
(\ref{inequality1}) that $\tau(\mu)$ and $\kappa(\mu)$ are bounded
for all $(X(\mu),Y(\mu),\tau(\mu),\kappa(\mu)) \in \mathcal{U}$.
{\bf{QED}}


\begin{proposition}\label{boundednessoffcentralpaths1}
$Y_{11}(\mu)$ and $X_{22}(\mu)$ are equal to $\mathcal{O}(\mu)$,
$\|X_{12}(\mu)\|$ and $\|Y_{12}(\mu)\|$ are equal to
$\mathcal{O}(\sqrt{\mu})$, and $\kappa(\mu)$ is equal to
$\mathcal{O}(\mu)$, where the bounds are not dependent on any
off-central path $(X(\mu),Y(\mu),\tau(\mu),\kappa(\mu))$ as long as
$\lambda_{\min}(XY)(\mu_0) \geq D, \|X(\mu_0)\| \leq C, \|Y(\mu_0)\|
\leq C, C_1 \leq \tau(\mu_0) \leq C, C_1 \leq \kappa(\mu_0) \leq C$
for fixed $\mu_0, C, C_1, D > 0$.
\end{proposition}


\begin{proposition}\label{boundednessoffcentralpaths2}
$X_{11}(\mu)$ and $Y_{22}(\mu)$ are equal to $\Theta(1)$,
$X_{22}(\mu)$ and $Y_{11}(\mu)$ are equal to $\Theta(\mu)$,
$\tau(\mu)$ is equal to $\Theta(1)$, while $\kappa(\mu)$ is equal to
$\Theta(\mu)$, where the bounds are not dependent on any off-central
path $(X(\mu),Y(\mu),\tau(\mu),\kappa(\mu))$ as long as
$\lambda_{\min}(XY)(\mu_0) \geq D, \|X(\mu_0)\| \leq C, \|Y(\mu_0)\|
\leq C, C_1 \leq \tau(\mu_0) \leq C, C_1 \leq \kappa(\mu_0) \leq C$
for fixed $\mu_0, C, C_1, D > 0$.
\end{proposition}

%Let us consider the linear semi-definite feasibility problem in
%which $C = 0$ from now onwards.  Therefore, (\ref{ODEcombined}) is
%given by
%\begin{eqnarray}\label{ODEcombined1}
%\left[ \begin{array}{cccc}
%        \mathcal{A} & b & 0 & 0  \\
%        0 & 0 & \mathcal{B} & d \\
%        I & 0 & X \otimes_s Y^{-1} & 0 \\
%        0 & 1 & 0 & \frac{\tau}{\kappa}
%        \end{array} \right]
%\left[ \begin{array}{c}
%            {\mbox{svec}}(X^\prime) \\
%            \tau^\prime \\
%            {\mbox{svec}}(Y^\prime) \\
%            \kappa^\prime
%        \end{array} \right] = \frac{1}{\mu}
%\left[ \begin{array}{c}
%        \mu r_0/\mu_0 \\
%        \mu s_0/\mu_0 \\
%        {\mbox{svec}}(X) \\
%        \tau
%        \end{array} \right].
%\end{eqnarray}

From the above propositions, we have that
\begin{eqnarray*}
X(\mu) = \left[ \begin{array}{cc}
                    \Theta(1) & \mathcal{O}(\sqrt{\mu}) \\
                    \mathcal{O}(\sqrt{\mu}) & \Theta(\mu)
                    \end{array} \right],\ \
Y(\mu) = \left[ \begin{array}{cc}
                    \Theta(\mu) & \mathcal{O}(\sqrt{\mu}) \\
                    \mathcal{O}(\sqrt{\mu}) & \Theta(1)
                    \end{array} \right].
\end{eqnarray*}

Hence, we can write
\begin{eqnarray*}
X(\mu) & = & \left[ \begin{array}{cc}
                        I & 0  \\
                        0 & \sqrt{\mu}I
                    \end{array} \right] \tilde{X}(\mu)
            \left[ \begin{array}{cc}
                        I & 0 \\
                        0 & \sqrt{\mu}I
                    \end{array} \right], \\
Y(\mu) & = & \left[ \begin{array}{cc}
                        \sqrt{\mu}I & 0 \\
                        0           & I
                    \end{array} \right] \tilde{Y}(\mu)
            \left[ \begin{array}{cc}
                        \sqrt{\mu}I & 0 \\
                        0           & I
                    \end{array} \right],
\end{eqnarray*}
\noindent where
\begin{eqnarray*}
\tilde{X}(\mu) = \left[ \begin{array}{cc}
                            \Theta(1) & \mathcal{O}(1) \\
                            \mathcal{O}(1) & \Theta(1)
                        \end{array} \right],\ \
\tilde{Y}(\mu) = \left[ \begin{array}{cc}
                            \Theta(1) & \mathcal{O}(1) \\
                            \mathcal{O}(1) & \Theta(1)
                        \end{array} \right].
\end{eqnarray*}
Also, $\tau(\mu) = \tilde{\tau}(\mu)$ with $\tilde{\tau}(\mu) =
\Theta(1)$, and $\kappa(\mu) = \mu \tilde{\kappa}(\mu)$ with
$\tilde{\kappa}(\mu) = \Theta(1)$.

Before we go on, let us define new matrices $\bar{\mathcal{A}}(t)$
and $\bar{\mathcal{B}}(t)$ as follows:
\begin{eqnarray*}
\begin{array}{l}
(\bar{\mathcal{A}}(t))_{i\cdot} := \left\{
\begin{array}{ll}
{\rm{svec}}\left(\begin{array}{cc}
                            (A_{i})_{11}  &  t(A_{i})_{12} \\
                            t(A_{i})_{12}^T & t^2(A_{i})_{22}
                \end{array} \right)^T & , 1 \leq i \leq j_1, \\
{\rm{svec}}\left( \begin{array}{cc}
                            0     &    (A_{i})_{12} \\
                            (A_{i})_{12}^T &
                            t(A_{i})_{22}
                        \end{array} \right)^T & , j_1 + 1 \leq i \leq j_1 + j_2. \\
{\rm{svec}}\left( \begin{array}{cc}
                            0     &    0   \\
                            0     &    (A_{i})_{22}
                        \end{array} \right)^T & , j_1 + j_2 + 1 \leq
                        i \leq m,
\end{array} \right. \\
(\bar{\mathcal{B}}(t))_{j\cdot} := \left\{
\begin{array}{ll}
{\rm{svec}}\left( \begin{array}{cc}
                            t^2(B_{j})_{11}  &  t(B_{j})_{12} \\
                            t(B_{j})_{12}^T & (B_{j})_{22}
                        \end{array} \right)^T & , 1 \leq j \leq k_1, \\
{\rm{svec}}\left( \begin{array}{cc}
                            t(B_{j})_{11} & (B_{j})_{12} \\
                            (B_{j})_{12}^T &
                            0
                        \end{array} \right)^T & , k_1 + 1 \leq j \leq k_1 + k_2, \\
{\rm{svec}}\left( \begin{array}{cc}
                            (B_{j})_{11}     &    0   \\
                            0     &    0
                        \end{array} \right)^T  & , k_1 + k_2 + 1 \leq
                        j \leq \tilde{n}+1 - m,
\end{array} \right.
\end{array}
\end{eqnarray*}
\noindent where $t^2 = \mu$.


Also define $\bar{b}(t) = b$ and $\bar{d}(t) = t^2 d$.
%\vspace{10pt}


 The following proposition relates the above defined
new matrices with $\mathcal{A}$ and $\mathcal{B}$:
\begin{proposition}\label{relationmatrices}
\begin{eqnarray*}
\mathcal{A} \left( \left( \begin{array}{cc}
                            I & 0 \\
                            0 & tI
                        \end{array} \right) \otimes_s
                    \left( \begin{array}{cc}
                            I & 0 \\
                            0 & tI
                            \end{array} \right) \right) & = &
                            {\rm{Diag}}(I_{j_1},tI_{j_2},t^2I_{m-j_1-j_2})\bar{\mathcal{A}}(t),
                            \\
\mathcal{B} \left( \left( \begin{array}{cc}
                            tI & 0 \\
                            0  & I
                        \end{array} \right) \otimes_s
                    \left( \begin{array}{cc}
                            tI & 0 \\
                            0  & I
                            \end{array} \right) \right) & = &
                            {\rm{Diag}}(I_{k_1},tI_{k_2},t^2I_{\tilde{n}+1-m-k_1-k_2})\bar{\mathcal{B}}(t).
\end{eqnarray*}
\end{proposition}
\noindent {\it{Proof:}} The proposition is clear from the
definitions of the new matrices, and (\ref{SDPA1B1}). {\bf{QED}}

\begin{remark}\label{remarkrelationmatrices}
%Let
%\begin{eqnarray*}
%\bar{\mathcal{A}}(t) := \left( \begin{array}{c}
%                            \bar{\mathcal{A}}_1(t) \\
%                            0
%                        \end{array} \right),\ \
%\bar{\mathcal{B}}(t) := \left( \begin{array}{c}
%                            0 \\
%                            \bar{\mathcal{B}}_1(t)
%                        \end{array} \right),
%\end{eqnarray*}
\noindent We have
\begin{eqnarray*}
&&\left[ \begin{array}{cc}
        \mathcal{A} & b \\
        0           & 0
        \end{array} \right] \left( \left( \begin{array}{ccc}
                            I & 0 & 0 \\
                            0 & tI & 0 \\
                            0 & 0  & t
                        \end{array} \right) \otimes_s
                    \left( \begin{array}{ccc}
                            I & 0 & 0\\
                            0 & tI & 0 \\
                            0 & 0 & t
                            \end{array} \right) \right) \\
& = &
{\rm{Diag}}(I_{j_1},tI_{j_2},t^2I_{m-j_1-j_2},I_{k_1},tI_{k_2},t^2I_{\tilde{n}+1-m-k_1-k_2})\left[
\begin{array}{cc}
    \bar{\mathcal{A}}(t) & b(t) \\
    0                    & 0
\end{array} \right]  \\
& & \left[ \begin{array}{cc}
            0 & 0 \\
            \mathcal{B} & d
            \end{array} \right] \left( \left(
                        \begin{array}{ccc}
                            tI & 0 & 0 \\
                            0  & I & 0 \\
                            0  & 0 & 1
                        \end{array} \right) \otimes_s
                    \left( \begin{array}{ccc}
                            tI & 0 & 0 \\
                            0  & I & 0 \\
                            0  & 0 & 1
                            \end{array} \right) \right) \\
& = &
{\rm{Diag}}(I_{j_1},tI_{j_2},t^2I_{m-j_1-j_2},I_{k_1},tI_{k_2},t^2I_{\tilde{n}+1-m-k_1-k_2})
\left[ \begin{array}{cc}
            0    &    0 \\
            \bar{\mathcal{B}}(t) & d(t)
        \end{array} \right].
\end{eqnarray*}
\end{remark}


Note that $\mathcal{G}(\mu) = \left[ \begin{array}{cc}
                                        0  & 0 \\
                                        \mathcal{B} & d
                                    \end{array} \right] -
\left[ \begin{array}{cc}
            \mathcal{A} & b \\
            0           & 0
        \end{array} \right]
\left[ \begin{array}{cc}
            X \otimes_s Y^{-1} & 0 \\
            0             & \tau/\kappa
        \end{array} \right]$ is invertible for $\mu > 0$.  This
implies that the matrix on the left hand side of
(\ref{ODEcombined1}) is invertible with its inverse given by
\begin{eqnarray*}
\left[ \begin{array}{c|c}
       - \left[ \begin{array}{cc}
                    X \otimes_s Y^{-1} & 0 \\
                    0   & \tau/\kappa
                \end{array}\right] \mathcal{G}^{-1} &
\left[ \begin{array}{cc}
            I & 0 \\
            0 & 1
        \end{array}\right] + \left[ \begin{array}{cc}
            X \otimes_s Y^{-1} & 0 \\
            0             & \tau/\kappa
        \end{array} \right]\mathcal{G}^{-1} \left[ \begin{array}{cc}
            \mathcal{A} & b \\
            0           & 0
        \end{array} \right] \\ \\
        \hline \\
\mathcal{G}^{-1} & -\mathcal{G}^{-1}\left[ \begin{array}{cc}
            \mathcal{A} & b \\
            0           & 0
        \end{array} \right]
        \end{array} \right]
\end{eqnarray*}

Therefore, (\ref{ODEcombined1}) can be written as
\begin{eqnarray}
& & \left[ \begin{array}{c}
            {\mbox{svec}}(X^\prime) \\
            \tau^\prime \\
            {\mbox{svec}}(Y^\prime) \\
            \kappa^\prime
            \end{array} \right] \nonumber \\
& & = \frac{1}{\mu} \left[ \begin{array}{c} -\mu \left[
\begin{array}{cc}
X \otimes_s Y^{-1} & 0 \\
0     & \tau/\kappa
\end{array} \right] \mathcal{G}^{-1} \left[\begin{array}{c}
                                                r_0/\mu_0 \\
                                                s_0/\mu_0
                                            \end{array} \right] +
\left[ \begin{array}{c}
        {\mbox{svec}}(X) \\
        \tau
        \end{array} \right] \\
  + \left[
\begin{array}{cc}
X \otimes_s Y^{-1} & 0 \\
0     & \tau/\kappa
\end{array} \right] \mathcal{G}^{-1}
\left[ \begin{array}{cc}
            \mathcal{A} & b \\
            0           & 0
        \end{array} \right]
\left[ \begin{array}{c}
        {\mbox{svec}}(X) \\
        \tau
        \end{array} \right] \\ \\
        \hline \\
  \mu \mathcal{G}^{-1} \left[ \begin{array}{c}
                                r_0/\mu_0 \\
                                s_0/\mu_0
                            \end{array} \right] -
\mathcal{G}^{-1} \left[ \begin{array}{cc}
            \mathcal{A} & b \\
            0           & 0
        \end{array} \right]
\left[ \begin{array}{c}
        {\mbox{svec}}(X) \\
        \tau
        \end{array} \right]
        \end{array} \right]  \label{ODEcombined2}
\end{eqnarray}
\noindent where $\mu > 0$.


We have the following proposition

\begin{proposition}\label{equivalencerelation}
\begin{eqnarray*}
&&-\frac{\mu}{\mu_0} \left[
\begin{array}{cc}
X \otimes_s Y^{-1} & 0 \\
0     & \tau/\kappa
\end{array} \right] \mathcal{G}^{-1} \left[\begin{array}{c}
                                                r_0 \\
                                                s_0
                                            \end{array} \right] +
\left[ \begin{array}{c}
        {\mbox{svec}}(X) \\
        \tau
        \end{array} \right]  + \left[
\begin{array}{cc}
X \otimes_s Y^{-1} & 0 \\
0     & \tau/\kappa
\end{array} \right] \mathcal{G}^{-1}
\left[ \begin{array}{cc}
            \mathcal{A} & b \\
            0           & 0
        \end{array} \right]
\left[ \begin{array}{c}
        {\mbox{svec}}(X) \\
        \tau
        \end{array} \right] \\
&& = \frac{1}{2}\left[ -\frac{\mu}{\mu_0} \left[
\begin{array}{cc}
X \otimes_s Y^{-1} & 0 \\
0     & \tau/\kappa
\end{array} \right] \mathcal{G}^{-1} \left[\begin{array}{c}
                                                r_0 \\
                                                s_0
                                            \end{array} \right]
+ \left[ \begin{array}{c}
        {\mbox{svec}}(X) \\
        \tau
        \end{array} \right] \right], \\
&& \frac{\mu}{\mu_0} \mathcal{G}^{-1} \left[ \begin{array}{c}
                                r_0 \\
                                s_0
                            \end{array} \right] -
\mathcal{G}^{-1} \left[ \begin{array}{cc}
            \mathcal{A} & b \\
            0           & 0
        \end{array} \right]
\left[ \begin{array}{c}
        {\mbox{svec}}(X) \\
        \tau
        \end{array} \right] = \frac{1}{2}\left[ \frac{\mu}{\mu_0} \mathcal{G}^{-1}\left[ \begin{array}{c}
                                                r_0 \\
                                                s_0
                                            \end{array} \right] +
                                            \left[\begin{array}{c}
                                                    {\mbox{svec}}(Y)
                                                    \\
                                                    \kappa
                                                    \end{array}
                                                    \right] \right],
\end{eqnarray*}
\noindent where $(X,Y,\tau,\kappa)$ satisfies
\begin{eqnarray*}
\left[ \begin{array}{cc}
            \mathcal{A} & b \\
            0           & 0
        \end{array} \right]
\left[ \begin{array}{c}
        {\mbox{svec}}(X) \\
        \tau
        \end{array} \right] +
\left[ \begin{array}{cc}
            0      &  0 \\
            \mathcal{B} & d
        \end{array} \right]
\left[ \begin{array}{c}
        {\mbox{svec}}(Y) \\
        \kappa
        \end{array} \right] = \frac{\mu}{\mu_0}
        \left[\begin{array}{c}
                r_0 \\
                s_0
                \end{array} \right].
\end{eqnarray*}
\end{proposition}

Using (\ref{ODEcombined2}) and Proposition
\ref{equivalencerelation}, (\ref{ODEcombined1}) can be written as
\begin{eqnarray*}
&& \left[ \begin{array}{c}
            {\mbox{svec}}(X^\prime) \\
            \tau^\prime \\
            {\mbox{svec}}(Y^\prime) \\
            \kappa^\prime
            \end{array} \right] \\
& & = \frac{1}{2\mu} \left[ \begin{array}{c}
 -\frac{\mu}{\mu_0}
\left[
\begin{array}{cc}
X \otimes_s Y^{-1} & 0 \\
0     & \tau/\kappa
\end{array} \right] \mathcal{G}^{-1} \left[\begin{array}{c}
                                                r_0 \\
                                                s_0
                                            \end{array} \right]
+ \left[ \begin{array}{c}
        {\mbox{svec}}(X) \\
        \tau
        \end{array} \right] \\
 \frac{\mu}{\mu_0} \mathcal{G}^{-1}\left[ \begin{array}{c}
                                                r_0 \\
                                                s_0
                                            \end{array} \right] +
                                            \left[\begin{array}{c}
                                                    {\mbox{svec}}(Y)
                                                    \\
                                                    \kappa
                                                    \end{array}
                                                    \right]
\end{array} \right]
\end{eqnarray*}











\bibitem{Ait}
M. Ait Ramit, U. Helmke and J.B. Moore, \emph{A finite steps
algorithm for solving convex feasibility problems,} Journal of
Global Optimization, Vol. 38(2007), pp. 143-160.
\bibitem{Alizadeh}
F. Alizadeh, J.A. Haeberly and M. Overton, \emph{Primal-dual
interior-point methods for semidefinite programming: convergence
rates, stability and numerical results,} SIAM Journal on
Optimization, Vol. 8(1998), pp. 746-768.
\bibitem{BL}
D.A. Bayer and J.C. Lagarias, \emph{The nonlinear geometry of linear
programming, I, II, III,} transactions of the American Mathematical
Society, Vol. 314(1989), pp. 499-526, pp. 527-581, and Vol.
320(1990), pp. 193-225.
\bibitem{Boyd}
S. Boyd, L. El Ghaoui, E. Feron and V. Balakrishnan, \emph{Linear
Matrix Inequalities in System and Control Theory,} SIAM Studies in
Applied Mathematics, Philadelphia, 1994.
\bibitem{Boyd1}
S. Boyd and L. Vandenberghe, \emph{Convex Optimization}, Cambridge University Press, 2004.
\bibitem{Chua}
C.B. Chua, \emph{Analyticity of weighted central paths and error
bounds for semidefinite programming,} Mathematical Programming,
Series A, Vol. 115(2008), pp. 239-271.
\bibitem{Chua1}
S.K. Chua, K.-C. Toh \& G. Zhao, \emph{An analytic center cutting
plane method with deep cuts for semidefinite feasibility problems,}
Journal of Optimization Theory and Applications, Vol. 123(2004), pp.
291-318.
%\bibitem{Coddington}
%E.A. Coddington and N. Levinson, \emph{Theory of Ordinary
%Differential Equations,} International Series in Pure and Applied
%Mathematics, 1955.
\bibitem{Gahinet}
P. Gahinet \& A. Nemirovski, \emph{The projective method for solving
linear matrix inequalities,} Mathematical Programming, Series B,
Vol. 77(1997), pp. 163-190.
\bibitem{Goffin}
J.-L. Goffin, Z. Luo \& Y. Ye, \emph{Complexity analysis of an
interior cutting plane method for convex feasibility problems,} SIAM
Journal on Optimization, Vol. 6(1996), pp. 638-652.
\bibitem{Henrion}
D. Henrion \& J. Malick, \emph{Projection methods for conic
feasibility problems, applications to polynomial sum-of-squares
decompositions,} preprint, 2009.
\bibitem{Neto}
J.X. da Cruz Neto, O.P. Ferreira and R.D.C. Monteiro,
\emph{Asymptotic behavior of the central path for a special class of
degenerate SDP problems,} Mathematical Programming, Series A, Vol.
103(2005), pp. 487-514.
\bibitem{Helmberg}
C. Helmberg, F. Rendl, R.J. Vanderbei and H. Wolkowicz, \emph{An
interior-point method for semidefinite programming,} SIAM Journal on
Optimization, Vol. 6(1996), pp. 342-361.
%\bibitem{Horn}
%R.A. Horn and C.R. Johnson, \emph{Topics in Matrix Analysis,}
%Cambridge University Press, New York, 1991.
\bibitem{Kojima3}
M. Kojima, M. Shida and S. Shindoh, \emph{Reduction of monotone
linear complementarity problems over cones to linear programs over
cones,} Acta Mathematica Vietnamica, Vol. 22(1997), pp. 147-157.
\bibitem{Kojima}
M. Kojima, M. Shida and S. Shindoh, \emph{Local convergence of
predictor-corrector infeasible-interior-point algorithms for SDPs
and SDLCPs,}  Mathematical Programming, Series A, Vol. 80(1998), pp.
129-160.
\bibitem{Kojima2}
M. Kojima, M. Shida and S. Shindoh, \emph{A predictor-corrector
interior-point algorithm for the semidefinite linear complementarity
problem using the Alizadeh-Haeberly-Overton search direction,} SIAM
Journal on Optimization, Vol. 9(1999), pp. 444-465.
\bibitem{Kojima1}
M. Kojima, S. Shindoh and S. Hara, \emph{Interior-point methods for
the monotone semidefinite linear complementarity problem in
symmetric matrices,} SIAM Journal on Optimization, Vol. 7(1997), pp.
86-125.
\bibitem{Lu1}
Z. Lu and R.D.C. Monteiro, \emph{Error bounds and limiting behavior
of weighted paths associated with the SDP map $X^{1/2}SX^{1/2}$,}
SIAM Journal on Optimization, Vol. 15(2004), pp. 348-374.
\bibitem{Lu3}
Z. Lu and R.D.C. Monteiro, \emph{A note on the local convergence of
a predictor-corrector interior-point algorithm for the semidefinite
linear complementarity problem based on the
Alizadeh-Haeberly-Overton search direction,} SIAM Journal on
Optimization, Vol. 15(2005), pp. 1147-1154.
\bibitem{Lu2}
Z. Lu and R.D.C. Monteiro, \emph{Limiting behavior of the
Alizadeh-Haeberly-Overton weighted paths in semidefinite
programming,} Optimization Methods and Software, Vol. 22(2007), pp.
849-870.
\bibitem{Potrasingle}
F.A. Potra, \emph{Q-superlinear convergence of the iterates in primal-dual interior-point methods,} Mathematical Programming, Series A, Vol. 91(2001), pp. 99-115.
\bibitem{Potra}
F.A. Potra and R. Sheng, \emph{Superlinear convergence of
interior-point algorithms for semidefinite programming,} Journal of
Optimization Theory and Applications, Vol. 99(1998), pp. 103-119.
\bibitem{Potra1}
F.A. Potra and R. Sheng, \emph{A superlinearly convergent
primal-dual infeasible-interior-point algorithm for semidefinite
programming,} SIAM Journal on Optimization, Vol. 8(1998), pp.
1007-1028.
\bibitem{Preib1}
M. Prei$\ss$ and J. Stoer, \emph{Analysis of
infeasible-interior-point paths and high-order methods for solving
SDLCPs,} Parametric Optimization and Related Topics, VII.
Aportaciones Matem\'{a}ticas: Investigaci\'{o}n, 18(2004), pp.
235-251.
\bibitem{Preib}
M. Prei$\ss$ and J. Stoer, \emph{Analysis of
infeasible-interior-point paths arising with semidefinite linear
complementarity problems,}  Mathematical Programming, Series A, Vol.
99(2004), pp. 499-520.
\bibitem{Mehrotra}
S. Mehrotra, \emph{Quadratic convergence in a primal-dual method,}
Mathematics of Operations Research, Vol. 18(1993), pp. 741-751.
\bibitem{Monteiro}
R.D.C. Monteiro, \emph{Primal-dual path following algorithms for
semidefinite programming,} SIAM Journal on Optimization, Vol.
7(1997), pp. 663-678.
\bibitem{Monteiro2}
R.D.C. Monteiro and J.-S. Pang, \emph{On two interior-point mappings
for nonlinear semidefinite complementarity problem,} Mathematics of
Operations Research, Vol. 23(1998), pp. 39-60.
\bibitem{Monteiro1}
R.D.C. Monteiro and T. Tsuchiya, \emph{Polynomial convergence of a
new family of primal-dual algorithms for semidefinite programming,}
SIAM Journal on Optimization, Vol. 9(1999), pp. 551-577.
\bibitem{Monteiro3}
R.D.C. Monteiro and P.R. Zanj\'{a}como, \emph{General interior-point
maps and existence of weighted paths for nonlinear semidefinite
complementarity problem,} Mathematics of Operations Research, Vol.
25(2000), pp. 381-399.
\bibitem{Nesterov}
Y. Nesterov and M. Todd, \emph{Self-scaled barriers and
interior-point methods for convex programming,} Mathematics of
Operations Research, Vol. 22(1997), pp. 1-42.
\bibitem{Nesterov1}
Y. Nesterov and M. Todd, \emph{Primal-dual interior-point methods
for self-scaled cones,} SIAM Journal on Optimization, Vol. 8(1998),
pp. 324-364.
\bibitem{Sim}
C.-K. Sim and G. Zhao, \emph{Underlying paths in interior point
methods for the monotone semidefinite linear complementarity
problem,}  Mathematical Programming, Series A, Vol. 110(2007), pp.
475-499.
\bibitem{Sim1}
C.-K. Sim and G. Zhao, \emph{Asymptotic behavior of
Helmberg-Kojima-Monteiro (HKM) paths in interior point methods for
monotone semidefinite linear complementarity problems: general
theory,} Journal of Optimization Theory and Applications, Vol.
137(2008), pp. 11-25.
\bibitem{Sim2}
C.-K. Sim, \emph{On the analyticity of underlying HKM path at a
solution of monotone semidefinite linear complementarity problem,}
Journal of Optimization Theory and Applications, Vol. 141(2009), pp.
193-215.
\bibitem{Sonn}
G. Sonnevend, \emph{An analytic center for polyhedrons and new
classes for linear programming}. In: System Modelling and
Optimization (A. Prekopa, Ed.), Lecture Notes in Control and
Information Sciences, Vol. 84, Springer-Verlag, Berlin, 1985, pp.
866-876.
\bibitem{Stoer}
J. Stoer and M. Wechs, \emph{On the analyticity properties of
infeasible-interior-point paths for monotone linear complementarity
problems,} Numerische Mathematik, Vol. 81(1999), pp. 631-645.
\bibitem{Stoer2}
J. Stoer, M. Wechs and S. Mizuno, \emph{High order
infeasible-interior-point methods for solving sufficient linear
complementarity problems,} Mathematics of Operations Research, Vol.
23(1998), pp. 832-862.
\bibitem{Sturm}
J.F. Sturm, \emph{Superlinear convergence of an algorithm for
monotone linear complementarity problems, when no strictly
complementary solution exists,} Mathematics of Operations Research,
Vol. 24(1999), pp. 72-94.
\bibitem{Sun}
J. Sun, K.-C. Toh \& G. Zhao, \emph{An analytic center cutting plane
method for semidefinite feasibility problems,} Mathematics of
Operations Research, Vol. 27(2002), pp. 332-346.
\bibitem{Todd}
M.J. Todd, K.C. Toh and R.H. T\"{u}t\"{u}nc\"{u}, \emph{On the
Nesterov-Todd direction in semidefinite programming,} SIAM Journal
on Optimization, Vol. 8(1998), pp. 769-796.
\bibitem{Toh}
K.-C. Toh, G. Zhao \& J. Sun, \emph{A multiple-cut analytic center
cutting plane method for semidefinite feasibility problems,} SIAM
Journal on Optimization, Vol. 12(2002), pp. 1126-1146.
\bibitem{trnovska}
M. trnovsk\'a and M. Halick\'a, \emph{Limiting behavior and
analyticity of weighted central paths in semidefinite programming,}
preprint.
\bibitem{Tseng}
P. Tseng, \emph{Search directions and convergence analysis of some
infeasible path-following methods for the monotone semi-definite
LCP,} Optimization Methods and Software, Vol. 9(1998), pp. 245-268.
\bibitem{Ye1}
Y. Ye and K. Anstreicher, \emph{On quadratic and $O(\sqrt{n}L)$
convergence of a predictor-corrector algorithm for LCP,}
Mathematical Programming, Series A, Vol. 62(1993), pp. 537-551.
\bibitem{Ye2}
Y. Ye, O. G\"{u}ler, R.A. Tapia and Y. Zhang, \emph{A quadratically
convergent $O(\sqrt{n}L)$-iteration algorithm for linear
programming,} Mathematical Programming, Series A, Vol. 59(1993), pp.
151-162.
\bibitem{Zhang}
Y. Zhang, \emph{On extending some primal-dual interior-point
algorithms from linear programming to semidefinite programming,}
SIAM Journal on Optimization, Vol. 8(1998), pp. 365-386.
