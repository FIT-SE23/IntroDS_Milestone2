% Use only LaTeX2e, calling the article.cls class and 12-point type.

\documentclass[12pt]{article}
%TC:incbib

% Users of the {thebibliography} environment or BibTeX should use the
% scicite.sty package, downloadable from *Science* at
% http://www.sciencemag.org/authors/preparing-manuscripts-using-latex 
% This package should properly format in-text
% reference calls and reference-list numbers.

\usepackage{scicite}
\usepackage{graphicx}
\usepackage{times}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{verbatim}

\newcommand{\quickwordcount}[1]{%
  \immediate\write18{texcount -1 -sum -merge -q #1.tex output.bbl > #1-words.sum }%
  \input{#1-words.sum} words%
}

\newcommand{\detailtexcount}[1]{%
  \immediate\write18{texcount -merge -sum -q #1.tex output.bbl > #1.wcdetail }%
  \verbatiminput{#1.wcdetail}%
}

% The preamble here sets up a lot of new/revised commands and
% environments.  It's annoying, but please do *not* try to strip these
% out into a separate .sty file (which could lead to the loss of some
% information when we convert the file to other formats).  Instead, keep
% them in the preamble of your main LaTeX source file.

% The following parameters seem to provide a reasonable page setup.

\topmargin 0.0cm
\oddsidemargin 0.2cm
\textwidth 16cm 
\textheight 21cm
\footskip 1.0cm

%The next command sets up an environment for the abstract to your paper.

\newenvironment{sciabstract}{%
\begin{quote} \bf}
{\end{quote}}

% Include your paper's title here
%TC:ignore
%\title{Experimental Evidence of In-Memory Computing in a Ferrofluid. \\ AA: What it is about more provocative title -- "Colloid in-memory computer"?  {\scriptsize MC Ciao Andy! If I were a reviewer I would expect with such a title the detailed architecture of a computer. Here we are demonstrating that the material can run in-memory computing... I would keep this title for the next work!!! :-D We must do it!}} 

\title{Evidence of In-Memory Computing in a Ferrofluid}

% Place the author information here.  Please hand-code the contact
% information and notecalls; do *not* use \footnote commands.  Let the
% author contact information appear immediately below the author names
% as shown.  We would also prefer that you don't change the type-size
% settings shown here.

\author{Marco Crepaldi$^{1}$, Charanraj Mohan$^{1}$, Erik Garofalo$^{2}$,
\\
Andrew Adamatzky$^{3}$, Konrad Szaciłowski$^{4}$, Alessandro Chiolerio$^{2\ast}$\\
\\
\normalsize{$^{1}$Electronic Design Laboratory,}\\
\normalsize{Istituto Italiano di Tecnologia,16163, Genova, Italy}\\
\normalsize{$^{2}$Bioinspired Soft Robotics,}\\ 
\normalsize{Istituto Italiano di Tecnologia,16163, Genova, Italy}\\
\normalsize{$^{3}$Unconventional Computing Laboratory,}\\
\normalsize{University of West England, BS16 1QY, Bristol, United Kingdom}\\
\normalsize{$^{4}$Academic Centre for Materials and Nanotechnology,}\\ 
\normalsize{AGH University of Science and Technology, 30-059, Kraków, Poland}\\
\\
\normalsize{$^\ast$To whom correspondence should be addressed; E-mail:  alessandro.chiolerio@iit.it}
}
%TC:endignore
% Include the date command, but leave its argument blank.

\date{}

%%%%%%%%%%%%%%%%% END OF PREAMBLE %%%%%%%%%%%%%%%%

\begin{document} 

% Double-space the manuscript.

\baselineskip24pt

% Make the title.

\maketitle 

% Place your abstract within the special {sciabstract} environment.

\begin{sciabstract}

  %Currently, electrical computing systems are almost uniquely made of shapes of solid-state matter.
  %However, investigations on colloids featuring functional nanoparticles open a new field of science towards colloidal computers where memory and computing roles can coexist in a liquid aggregation state, regardless of their shape. 
  %Magnetic fluids are applicable in important research fields including energy harvesting, biomedical applications, soft robotics and exploration.
  %Ferrofluids (FFs) are shape reconfigurable and exhibit reversible paramagnetic-to-ferromagnetic transformation.
  Magnetic fluids are excellent candidates for important research fields including energy harvesting, biomedical applications, soft robotics and exploration. However, notwithstanding relevant advancements such as shape reconfigurability, that have been demonstrated, there is no evidence for their computation capability, including the emulation of synaptic functions.
  %, which requires complex non-linear dynamics.
  Here, we experimentally demonstrate that a $\mathrm{Fe}_3 \mathrm{O}_4$ water-based Ferrofluid (FF) can perform electrical analog computing and be programmed using quasi DC signals and read at Radio Frequency (RF) mode. We have observed features in all respects attributable to a memristive behavior, featuring both short and long-term information storage capacity and plasticity. The colloid was capable of classifying digits of a 8\,$\times$\,8 pixel dataset using a custom in-memory signal processing scheme, and through Physical Reservoir Computing (PRC) by training a readout layer. 
  %These findings demonstrate the feasibility of electrical analog computing using a colloid in a liquid aggregation state. 
\end{sciabstract}

% In setting up this template for *Science* papers, we've used both
% the \section* command and the \paragraph* command for topical
% divisions.  Which you use will of course depend on the type of paper
% you're writing.  Review Articles tend to have displayed headings, for
% which \section* is more appropriate; Research Articles, when they have
% formal topical divisions at all, tend to signal them with bold text
% that runs into the paragraph, for which \paragraph* is the right
% choice.  Either way, use the asterisk (*) modifier, as shown, to
% suppress numbering.
\paragraph*{One-Sentence Summary}
A Ferrofluid can store analog information and run electrical in-memory computing using quasi-DC write and RF read modes.

%\section*{Introduction}
\section*{Main Text}
As a part of the largest international effort underway to explore alternative computing methods called \emph{unconventional computing}\cite{bib8,adamatzky2021handbook},
there is a consolidated trend in the research on devices, materials and in natural processes, to find an implicit exhibition of computing features, even beyond solid aggregation state.
The idea of computing with liquids attracted engineers and mathematicians since the early 1900s~\cite{emch1901two}, but later prototypes of liquid computers were mostly based on hydraulic, reaction-diffusion, and fluidic principles \cite{adamatzky2019brief}.
%included hydraulic integrators, a monetary national income analog computer, fluid mappers, fluid logic, reaction-diffusion computers and fluid maze solvers .
Only recently, liquid and colloidal systems have been subject to attention for mimicking the ions moving in the human brain through embedding aqueous solutions in gel or solid-state scaffolds \cite{noushin}.
Being applicable to soft robotics \cite{bib76}, energy harvesting \cite{bib77}, and computation in general \cite{bib78}, 
magnetic fluids are always of great research interest (Sec.~S1). Particularly, ferrofluids (FFs) are mixtures in which nanometric-size dispersed insoluble particles are suspended throughout a solvent, the particles being typically superparamagnetic, giving rise to interesting collective behaviour. 
A potential of FF in computing, massive-parallel information processing, sensing, and energy harvesting regardless of their shape has not been addressed before, notwithstanding first reports on their shape reconfiguration are already available \cite{shape1}. Here, we demonstrate that a volume of a superparamagnetic FF can be interchangeably assigned to memory and computing roles. This property is consistent with the rising paradigm of in-memory computing, which aims at mitigating processor-memory data transfer bottleneck by embedding computation in memory \cite{ielmini2018memory,verma2019memory,le2018mixed,sebastian2020memory}. Furthermore, we demonstrate FF computation using the concept of Reservoir Computing (RC), a paradigm that takes advantage from system dynamics (spontaneous or excited from external sources) for advanced information processing. Reversibility, fading memory, nonlinearity of electrical response and structural stochasticity are usually considered as prerequisites for any physical implementation of RC concepts \cite{reservoir}, and most solid-state memristors fulfil these requirements \cite{reservoir2}.  
%Here, for the very first time we have observed and experimentally demonstrated electrical computing capabilities in a superparamagnetic water-based FF.
%, and features attributable to short and long term plasticity. 

%Conventional computer architectures have separate locations for data storage and computing, thus resources are wasted on information transfers between a memory and a processor. 

%\section*{Experimental Set-Up and First Proof}

\begin{figure}[h]%
\centering
\includegraphics[width=0.85\textwidth]{./figures/fig1-rasterized.eps}
\caption{\textbf{A} Experimental set-up. \textbf{B} Measurement concept and relevant parameters. The colloid is programmed using a quasi-DC voltage and its internal status is read through its distributed impedance values $Z_{11}^C$, $Z_{12}^C$, $Z_{21}^C$ and $Z_{22}^C$, that correspond to the sum of the samples obtained throughout the measurement bandwidth of the VNA (10\,MHz--6\,GHz). \textbf{C} Hysteresis loops as a function of experiment elapsed time obtained from an initial impedance multi-point (comprising $Z_{11}$, $Z_{12}$, $Z_{21}$ and $Z_{22}$) obtained by applying a -3.8\,V--3.8\,V voltage sweep.}\label{fig1}
\end{figure}


Our experimental setup shown in Fig.~\ref{fig1}A comprises a FF sample (the reservoir) connected to a two-port Vector Network Analyzer (VNA), a DC bias generator (where the negative terminal is internally connected to ground) and two bias tee circuits to decouple RF and DC signals (details in Materials and Methods). 
Both the DC bias generator and the VNA are connected to a Personal Computer to implement measurement scripts (Sec.~S2), that is, applying a DC voltage across the reservoir and reading the impedance through its S-parameters, that can be always converted to impedances as a function of frequency.
As shown in Fig.~\ref{fig1}B, the FF is stimulated as follows: a quasi-DC voltage $V_P$ (both positive and negative) is applied to the system to program/write it, and its internal status (read) is acquired in RF mode using the magnitude impedance parameters. Since the observed S-parameters and consequently impedance magnitude variations are small (Sec.~S3), the sum of the numerical impedance values over all scanned frequencies $Z_{xy}^C$ can be used profitably as an indicator (see the formulas in the figure). This way the S-parameters are collapsed to a single number for each measurement point, reducing data volume. Consequently, each reading measurement is an ensemble of four real numbers $Z_{11}^C$, $Z_{12}^C$, $Z_{21}^C$ and $Z_{22}^C$, all a function of time $t$, e.g., for port one, $Z_{11}^C\equiv Z_{11}^C(t)$. 

Hysteresis, a fingerprint of memristance \cite{chua1}, is a necessary condition for neuromorphic computation \cite{bib72}.
Fig.~\ref{fig1}C shows hysteresis loops obtained with a voltage sweep from -3.8\,V to 3.8\,V with steps of 0.1\,V each lasting 1\,s, repeated for 50 times. At the beginning of the test ($t$\,=\,0\,s) we started with $V_P$\,=\,-0.85\,V and impedance values were $Z_{11}^C(0)$\,=\,14312\,$\Omega$, $Z_{12}^C(0)$\,=\,2320\,$\Omega$, $Z_{21}^C(0)$\,=\,2060\,$\Omega$ and $Z_{22}^C(0)$\,=\,11795\,$\Omega$. 
The pinched hysteresis of $Z_{11}^C$ shrinks for positive $V_P$ as the number of iterations increases, even with such zero average excitation. The hysteresis of $Z_{22}^C$ shrinks throughout the whole $V_P$ range while for $Z_{12}^C$ and $Z_{21}^C$ we observe the opposite phenomenon. On the one hand, the results indicate that assuming a given DC stimulus, its effect on the impedance variation is not constant and varies over time. On the other hand, this feature indicates a long-term adjustment of the material towards an \emph{equilibrium} condition, that can be interpreted as the feature of memorizing the previous DC bias history. Furthermore, due to fluidity of the material, this memory will be naturally fading, which is another important prerequisite for an efficient and universal RC system \cite{memory1}.

%\section{Analog Memory}

\begin{figure}[h]%
\centering
\includegraphics[width=0.9\textwidth]{./figures/fig2-rasterized.eps}
\caption{\textbf{A} Long-term memory stimulus scheme and \textbf{B} results obtained by applying a positive pulse to the material of value 3.3\,V with different duration $T_P(i)$, and by restoring the initial impedance value $\mathrm{Z}_{11}^{C*}$\,=\,14338\,$\Omega$ for each test using a closed control loop. \textbf{C} Variation of $\mathrm{Z}_{22}^{C}$ and corresponding mean and variance during the {\tt Hold} phase for all information values. }\label{fig3}
\end{figure}

The liquid can be used to store information in the form of a particular impedance evolution at a given port. To pose a parallelism with biological neurons we can refer to a \emph{long-term plasticity} feature.
Fig.~\ref{fig3}A shows the stimulus scheme used to demonstrate storage capacity for $N$ information values -- in this specific test $N$\,=\,16. The test comprises repeated {\tt Reset}, {\tt Write} and {\tt Hold} phases, where {\tt Reset} implements a control loop on $\mathrm{Z}_{11}^C$ to reset its value to $\mathrm{Z}_{11}^{C*}$. 
The results in Fig.~\ref{fig3}B show that $\mathrm{Z}_{11}^{C*}$ is correctly reached for each iteration, and notwithstanding impedance control is implemented at port one, $\mathrm{Z}_{22}^C$ evolves towards well defined impedance values, that are a function of the applied pulse duration $T_P(i)$. Interestingly, the $\mathrm{Z}_{22}^C$ values do not reset at the beginning of each {\tt Write} phase. The small variation of the $\Delta Z_{22}^C$ values and the associated uniform distribution parameters during {\tt Hold} of Fig.~\ref{fig3}C, suggests that the colloid can be used as a high resolution short-term memory. In general, as $T_P(i)$ can be controlled with the power of continuum, analog information storage can be implemented and information can be stored even for a longer duration (Sec.~S4). 

%\section{Computing}

%\subsection{Pattern Classification}
%\label{secClassification}
\begin{figure}[h]%
\centering
\includegraphics[width=0.9\textwidth]{./figures/fig3-rasterized.eps}
\caption{\textbf{A} Weighting used for in-memory digit filtering, based on a simple elongation of the expected black pixels pulses. Each digit is serialized from bottom-left to top-right, sequentially line by line.
\textbf{B} Stimulus scheme for classification, with reset control on $Z_{22}^C$ after each serialized digit (exemplified here for {\tt 1} weighting). \textbf{C, D, E} Measured impedance variation for all digits for three examples weighted sequences, {\tt 1}, {\tt 4} and {\tt 7}. Weighting a particular digit leads to a lowering of its impedance $Z_{22}^C$ compared to the others (orange paths).
\textbf{F} Final $Z_{22}^C$ for all weighting sequences. Classification for digit {\tt 3} fails due to overlapping with {\tt 8}.}\label{fig5}
\end{figure}

By extending the memory stimulus scheme of Fig.~\ref{fig3}A, we could demonstrate in-memory digit classification. To this end, 
we prepared a dataset consisting of the ten digits {\tt 0}--{\tt 9}, in 8\,$\times$\,8 matrices of pixels (Sec.~S5) that we have serialized as shown in the scheme of Fig.~\ref{fig5}A. Data serialization has been demonstrated to be an efficient approach towards neuromorphic data processing with very minimal computational resources [e.g. single artificial neurons \cite{molecules, serial2}].
Each pixel, besides its value 0--1 that can be mapped to a voltage level $V_{P}$, can be attributed a weight in terms of pulse duration $w_i$ and, in general, an offset (in terms of additive voltage). It is therefore possible to build up sequences with higher or lower sensitivity to a particular digit or selectively filter particular pixel values. 
Here, we do not bias the colloid in the condition of having a pinched hysteresis, so to obtain a monotonic decrease of impedance during the tests, and therefore enable a direct comparison of the final value for all digits after the application of the sequences. 
By assuming instead that the system is in the conditions of a pinched hysteresis, the FF can progressively adapt to implement a learning mechanism by providing a particular non-zero offset weighting (Sec.~S6).
% weight and bias sequence for a digit that runs across the pinched hysteresis by a larger magnitude compared to others 

Fig.~\ref{fig5}B shows the stimulus scheme of the pattern classification test, which exploits in-memory computing features. Similarly to the memorization experiments here we apply a reset control on $Z_{22}^C$, towards the impedance set-point $Z_{22}^C$\,=\,14338 \,$\Omega$, using an initial {\tt Charge} phase at 10\,V. Each pixel is associated to a -3.3\,V or 0\,V voltage (black or white) for a given weight duration, with zero offset. After verifying differentiation (Sec.~S5), we provide the weighted sequences so that the pulse durations of the expected black pixels are longer compared to the others. We apply sequentially all serialized pixel matrices from {\tt 0} to {\tt 9}, using all the weighted sequences for each digit. Fig.~\ref{fig5}C--E show the measurement results assuming 4.5 and 0.25\,s weights (black and white, respectively), for three sample digits, {\tt 1}, {\tt 4} and {\tt 7}. Results show that with this in-memory computing scheme $Z_{22}^C$ decreases more considerably in case the weighted sequence matches the digit.
The final decision can then be achieved by using a simple threshold on the $Z_{22}^C$ value, which depends on the digit to be detected, or alternatively, by indexing the digit that leads to the lowest impedance after all of them are serialized.
This particular scheme works except for {\tt 3} which is a subset of {\tt 8} (Fig.~\ref{fig5}F), thus leading to 90\% accuracy. 
As an effect of long-term plasticity, we have observed also that if the above test is repeated for days without interruption, the impedance dynamics shrinks, irrespective of the digit (see Sec.~S7). The behaviour of the liquid, however, is reversible and impedance dynamics can be restored. 
%by applying a fixed 'reset' stimulation of -10\,V or waiting for a sufficiently long time.

%\subsection{Physical Reservoir Computing}

\begin{figure}[h]%
\centering
\includegraphics[width=0.9\textwidth]{./figures/fig4-rasterized.eps}
\caption{\textbf{A} Stimulus scheme used for both training and inference during PRC tests with parallelized outputs for the readout NN layer (each one identifying the effect of a pixel value), detail on the NN layer and conceptual liquid reservoir. \textbf{B} Confusion map of a real-time classification test of the digits {\tt 0} to {\tt 3} using the trained NN.}\label{fig6}
\end{figure}

Similarly to memristors (differences outlined in Sec.~S8), to further demonstrate the computation capability of the FF we have implemented PRC using an ad-hoc readout layer. 
The FF exhibits chaotic nature (resulting, \emph{inter alia} from Brownian motions as well as from the surfactant molecules featuring electrical polarizability), and within its deterministic features, it presents a strong sensitivity to initial electrical conditions (Sec.~S9), while it can provide both fading memory and long-term plasticity (for instance see the plots in Fig.~S3). 
RC is typically implemented taking advantage of a physical reservoir short-term memory \cite{bib67}. However, within the time frame of a digit classification, our findings show that the dynamics of the FF tend in the long-term to reduce if a trivial reset condition is used (Sec.~S7). Moreover, besides sensitivity to initial conditions, the FF exhibits chaotic non-equilibrium at repeated impedance sets (Sec.~S10).
Such features can make PRC unfeasible and it is thus necessary to 
%exploit only its fading memory effect,
avoid changes in dynamical regime during both training and inference. To mitigate these variations, we have designed a particular 'reset' sequence that maintains the dynamical features of the material consistent. It consists of the application of a high voltage towards two impedance points, that are higher and lower compared to the initial impedance $Z_{22}^{C*}$ used to run active computation, respectively. 
Fig.~\ref{fig6}A shows the measurement scheme and the reset sequence. In our tests $Z_{22}^C\rvert_\mathrm{LOW}$\,=\,16350\,$\Omega$, $Z_{22}^C\rvert_\mathrm{HIGH}$\,=\,16450\,$\Omega$ and $Z_{22}^{C*}$\,=\,16400\,$\Omega$.

We used constant weighting to serialize the 64 pixels of the digit matrices (each pixel lasts 2\,s, with -3.3\,V for {\tt 1} and 0\,V for {\tt 0}) and we have trained a Neural Network (NN) layer to classify four digits {\tt 0}--{\tt 3} (rationale and dataset in Sec.~S11). The NN comprises a first block which normalizes in parallel the 64 impedance values in the range 0--1 to get rid of residual dynamical variations due to the FF chaotic nature. The input layer is made of a 64 {\tt Dense} model, followed by a {\tt Batch Normalization} block (that helps back-propagation convergence), another 14 elements {\tt Dense} model, and finally a single {\tt Dense} neuron. Inference is achieved in real-time using the trained NN on new measurement data from the FF consisting on 64 impedance values $Z_{22}^C$. Fig.~\ref{fig6}B shows the confusion map, after detecting the four digits with the pre-trained NN, achieving an accuracy of 90.6\%.

%\section{Conclusion}\label{sec13}

In conclusion, we have demonstrated the first ever evidence of a FF in-memory computing device. A FF can implement complex calculations both with custom in-memory computing schemes, and PRC, thus widening its spectrum of features. Besides extending the possibilities of already existing applications, these findings make solutions featuring unprecedented plasticity, fault-tolerance and resilience towards extreme environments a plausible reality, thanks to FFs amorphous nature.


% Your references go at the end of the main text, and before the
% figures.  For this document we've used BibTeX, the .bib file
% scibib.bib, and the .bst file Science.bst.  The package scicite.sty
% was included to format the reference numbers according to *Science*
% style.

%BibTeX users: After compilation, comment out the following two lines and paste in
% the generated .bbl file. 

%\bibliography{scibib,liquidcomp}

%\bibliographystyle{Science}

\begin{thebibliography}{10}

\bibitem{bib8}
A.~Adamatzky, {\it Unconventional {C}omputing -- {A} {V}olume in the
  {E}ncyclopedia of {C}omplexity and {S}ystems {S}cience\/} (Springer, New
  York, 2018).

\bibitem{adamatzky2021handbook}
A.~Adamatzky, ed., {\it {Handbook Of Unconventional Computing (In 2
  Volumes)}\/} ({World Scientific}, 2021).

\bibitem{emch1901two}
A.~Emch, {\it The American Mathematical Monthly\/} {\bf 8}, 10 (1901).

\bibitem{adamatzky2019brief}
A.~Adamatzky, {\it {Philosophical Transactions of the Royal Society B}\/} {\bf
  374}, 20180372 (2019).

\bibitem{noushin}
N.~R. Kheirabadi, A.~Chiolerio, K.~Szaciłowski, A.~Adamatzky, {\it
  ChemPhysChem\/} {\bf N/A}, e202200390 (2022).

\bibitem{bib76}
A.~Chiolerio, M.~Quadrelli, {\it {A}dvanced {S}cience\/} {\bf 4}, 1700036
  (2017).

\bibitem{bib77}
A.~Chiolerio, M.~Quadrelli, {\it {E}nergy {T}echnology\/} {\bf 7}, 1800580
  (2019).

\bibitem{bib78}
A.~Chiolerio, {\it {A}dvanced {I}ntelligent {S}ystems\/} {\bf 2}, 2000120
  (2020).

\bibitem{shape1}
S.~Zhao, {\it et~al.\/}, {\it Nano {L}etters\/} {\bf 22}, 5538 (2022).

\bibitem{ielmini2018memory}
D.~Ielmini, H.-S.~P. Wong, {\it {Nature Electronics}\/} {\bf 1}, 333 (2018).

\bibitem{verma2019memory}
N.~Verma, {\it et~al.\/}, {\it {IEEE Solid-State Circuits Magazine}\/} {\bf
  11}, 43 (2019).

\bibitem{le2018mixed}
M.~Le~Gallo, {\it et~al.\/}, {\it {Nature Electronics}\/} {\bf 1}, 246 (2018).

\bibitem{sebastian2020memory}
A.~Sebastian, M.~Le~Gallo, R.~Khaddam-Aljameh, E.~Eleftheriou, {\it {Nature
  Nanotechnology}\/} {\bf 15}, 529 (2020).

\bibitem{reservoir}
K.~Nakajima, I.~Fisher, {\it Reservoir {C}omputing. {T}heory, {P}hysical
  {I}mplementations, and {A}pplications\/} ({S}pringer {N}ature, Singapore,
  2021).

\bibitem{reservoir2}
E.~Wlaźlak, D.~Przyczyna, R.~Gutierrez, G.~Cuniberti, K.~Szaciłowski, {\it
  {J}apanese {J}ournal of {A}pplied {P}hysics\/} {\bf 59}, SI0801 (2020).

\bibitem{chua1}
S.~P. Adhikari, M.~P. Sah, H.~Kim, L.~O. Chua, {\it IEEE Transactions on
  Circuits and Systems I: Regular Papers\/} {\bf 60}, 3008 (2013).

\bibitem{bib72}
J.~Shank, {\it et~al.\/}, {\it {S}cientific {R}eports\/} {\bf 8} (2018).

\bibitem{memory1}
L.~Gonon, J.-P. Ortega, {\it Neural networks\/} {\bf 138}, 10 (2021).

\bibitem{molecules}
D.~Przyczyna, M.~Lis, K.~Pilarczyk, K.~Szaciłowski, {\it Molecules\/} {\bf
  24}, 2738 (2019).

\bibitem{serial2}
Y.~Zhong, {\it et~al.\/}, {\it Nature Communications\/} {\bf 12}, 408 (2021).

\bibitem{bib67}
X.~Zhu, Q.~Wang, W.~D. Lu., {\it Nature {C}ommunications\/} {\bf 11} (2020).

\end{thebibliography}


%TC:ignore
\paragraph*{Funding}
This project has received funding from the European Union’s Horizon 2020 research and innovation programme FET OPEN ``Challenging current thinking” under grant agreement No 964388.

\paragraph*{Author Contributions}
M.C. devised and prepared the set-up, wrote the software, devised stimuli and ran measurements, analyzed the results, devised and trained the learning network, prepared the manuscript. A.C., conceptualized and devised the set-up, analyzed the results, prepared the manuscript and correspondence. C.M., E.G., A.A. and K.S. prepared the manuscript, analyzed the results and contributed.

\paragraph*{Competing Interests}

The authors declare they have no conflict of interest or competing interests.

\paragraph*{Data and Materials Availability}
Data is available upon reasonable request to the corresponding author.
\section*{Acknowledgments}
We thank Davide Dellepiane, Electronic Design Laboratory, for the assembly of the vial, and Alessandro Barcellona for the support in the design of the bias tee electronics. We thank Diego Torazza, Robotics Brain and Cognitive Sciences dept., for the 3D rendering of the vial.

%Here you should list the contents of your Supplementary Materials -- below is an example. 
%You should include a list of Supplementary figures, Tables, and any references that appear only in the SM. 
%Note that the reference numbering continues from the main text to the SM.
% In the example below, Refs. 4-10 were cited only in the SM.     
\section*{Supplementary Materials}
Materials and Methods\\
Supplementary Text (Sec.~S1 to S11)\\
Supplementary Fig.~S1 to S8\\
%TC:endignore

%\paragraph*{Word Count}
%\quickwordcount{ferrofluid-electrical-computing} including abstract, main text, references and figure captions.
%\detailtexcount{ferrofluid-electrical-computing}
% For your review copy (i.e., the file you initially send in for
% evaluation), you can use the {figure} environment and the
% \includegraphics command to stream your figures into the text, placing
% all figures at the end.  For the final, revised manuscript for
% acceptance and production, however, PostScript or other graphics
% should not be streamed into your compliled file.  Instead, set
% captions as simple paragraphs (with a \noindent tag), setting them
% off from the rest of the text with a \clearpage as shown  below, and
% submit figures as separate files according to the Art Department's
% instructions.


\end{document}




















