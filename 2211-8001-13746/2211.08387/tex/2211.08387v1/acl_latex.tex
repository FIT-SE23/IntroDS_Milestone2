\pdfoutput=1

\documentclass[11pt]{article}

\usepackage{acl}


\usepackage{times}
\usepackage{latexsym}

\usepackage[T1]{fontenc}

\usepackage[utf8]{inputenc}

\usepackage{microtype}
\usepackage{bbold}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{hhline}
\usepackage{pifont}
\usepackage{arydshln}
\usepackage{amsmath}

\definecolor{darkgreen}{HTML}{228B22}
\definecolor{nblue}{HTML}{377eb8}

\definecolor{ggreen}{HTML}{1b9e77}
\definecolor{oorange}{HTML}{d95f02}
\definecolor{bblue}{HTML}{7570b3}
\definecolor{ppurple}{HTML}{e37fbb}

\definecolor{lgreen}{HTML}{9CD24A}
\definecolor{yyellow}{HTML}{FFD52D}
\definecolor{ggold}{HTML}{E1BC89}
\definecolor{ggray}{HTML}{AAAAAA}

\newcommand{\xmark}{\textcolor{red}{\ding{55}}}
\newcommand{\cmark}{\textcolor{darkgreen}{\ding{51}}}
\newcommand{\keyword}[1]{{\textcolor{nblue}{\textbf{#1}}}}
\newcommand{\ent}[1]{{\textcolor{ppurple}{\textbf{#1}}}}
\newcommand{\hl}[2]{\colorbox{#1!20}{{#2}}}


\title{AutoTemplate: A Simple Recipe for Lexically Constrained Text Generation}

\author{Hayate Iso \\
  Megagon Labs\\
  \texttt{hayate@megagon.ai}}

\begin{document}
\maketitle
\begin{abstract}
Lexically constrained text generation is one of the constrained text generation tasks, which aims to generate text that covers all the given constraint lexicons. While the existing approaches tackle this problem using a lexically constrained beam search algorithm or dedicated model using non-autoregressive decoding, there is a trade-off between the generated text quality and the hard constraint satisfaction.
We introduce AutoTemplate, a simple yet effective lexically constrained text generation framework divided into template generation and lexicalization tasks.
The template generation is to generate the text with the placeholders, and lexicalization replaces them into the constraint lexicons to perform lexically constrained text generation.
We conducted the experiments on two tasks: keywords-to-sentence generations and entity-guided summarization.
Experimental results show that the AutoTemplate outperforms the competitive baselines on both tasks while satisfying the hard lexical constraints.
\end{abstract}

\section{Introduction}
Text generation often requires lexical constraints, i.e., generating a text containing pre-specified lexicons.
For example, the summarization task may require the generation of summaries that include specific people and places~\cite{fan-etal-2018-controllable,he2020ctrlsum}, and advertising text generation requires the generation of text that includes pre-specified keywords~\cite{miao2019cgmh,zhang-etal-2020-pointer}.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{fig/autotemplate.pdf}
    \caption{Illustration of AutoTemplate. We build the model input $\tilde{x}$ by concatenating the constraint lexicons $\mathcal{Z}$ with mask tokens. For the conditional text generation task, we further concatenate input document $x$. We also build the model output $\tilde{y}$ by masking the constraint lexicons in summary $y$. Then, we can train a standard sequence-to-sequence model, $p(\tilde{y} \mid \tilde{x})$, generate masked template $\tilde{y}$ given input $\tilde{x}$, and post-process to achieve lexically constrained text generation.}
    \label{fig:overview}
\end{figure}

However, the black-box nature of recent text generation models with pre-trained language models~\cite{devlin-etal-2019-bert,lewis-etal-2020-bart,brown2020gpt3} makes it challenging to impose such constraints to manipulate the output text explicitly.
\citet{hokamp-liu-2017-lexically} and others tweaked the beam search algorithm to meet lexical constraints by increasing the weights for the constraint lexicons during the beam search. However, it often misses to include the constrained lexicons.
\citet{miao2019cgmh} and others introduced specialized non-autoregressive models~\cite{gu2018nonautoregressive,lee-etal-2018-deterministic} that insert words between the constraint lexicons to meet lexical constraints.
However, these models are known to generate lower-quality of text than standard autoregressive models.

Meanwhile, classical text generation systems mainly relied on template-based methods~\cite{kukich-1983-design,tanaka-ishii-etal-1998-reactive-content}.
The template-based method selects the template based on the source information and replaces the placeholder tokens with the corresponding words.
The template-based method's advantage is to satisfy the constraints provided by the proper template easily.
While it is realistically possible to prepare a sufficient number of templates for specific tasks, such as data-to-text generation~\cite{angeli-etal-2010-simple,wiseman-etal-2017-challenges}, where the output text patterns are limited, it is impractical to prepare corresponding templates for all possible combinations of constrained lexicons.
Nevertheless, if we could \textit{automatically generate} such templates, we could easily perform lexically constrained text generation.

We propose AutoTemplate, a simple framework for lexically constrained text generations by automatically generating templates given constrained lexicons and replacing placeholders in the templates with constrained lexicons.
AutoTemplate, for example, can be used for summarization tasks, as shown in Figure~\ref{fig:overview}, by replacing the constraint lexicons (i.e., $\{\text{Japan, Akihito}\}$) in the output text with placeholder tokens during training and using these constraints as a prefix of the input, creating input-output pairs, and then using a standard auto-regressive encoder-decoder model~\cite{ilya2014seq,Bahdanau2015NeuralMT} to train the AutoTemplate model.
For the inference, the constraint lexicons are prefixed in the same way, the model generates the template for the constraints, and the placeholder tokens are replaced with the constraint lexicons to achieve lexically constrained text generation.

We evaluate AutoTemplate across two tasks: keywords-to-sentence generation on One-Billion-Words and Yelp datasets (\S\ref{sub:k2sg}), and entity-guided summarization on CNNDM~\cite{hermann2015teaching} and XSum datasets~\cite{narayan-etal-2018-dont}
(\S\ref{sec:method}). We observe that AutoTemplate shows better keywords-to-sentence generation and entity-guided summarization performance than competitive baselines, including autoregressive and non-autoregressive models, while satisfying the lexical constraints. 

\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{l|cccccc}
        \toprule
        & multiple keywords & autoregressive decoding& keyword conditioning & constraint satisfaction \\\midrule
        SeqBF~\scriptsize{\cite{mou-etal-2016-sequence}} & \xmark & \xmark & \cmark & \cmark\\
        CGMH~\scriptsize{\cite{miao2019cgmh}} & \cmark & \xmark & \cmark & \cmark\\
        GBS~\scriptsize{\cite{hokamp-liu-2017-lexically}} & \cmark & \cmark & \xmark & \xmark \\
        CTRLsum~\scriptsize{\cite{he2020ctrlsum}} & \cmark & \cmark & \cmark & \xmark\\\midrule
        AutoTemplate (ours) & \cmark & \cmark & \cmark & \cmark\\
        \bottomrule
    \end{tabular}
    \caption{Summary of existing work for lexically constrained text generation. SeqBF~\cite{mou-etal-2016-sequence} and CGMH~\cite{miao2019cgmh} use non-autoregressive decoding methods to insert words between given keywords. While these methods easily satisfy the lexical constraints, in general, non-autoregressive methods tend to produce lower-quality text generation than autoregressive methods. GBS~\cite{hokamp-liu-2017-lexically} and CTRLSum~\cite{he2020ctrlsum} use autoregressive methods to perform text generation, but there is no guarantee to satisfy all lexical constraints. AutoTemplate empirically demonstrates the capability to generate text that satisfies the constraints.}
    \label{tab:related}
\end{table*}

\section{AutoTemplate}
\label{sec:method}
AutoTemplate is a simple framework for lexically constrained text generation (\S\ref{sub:def}), divided into two steps: template generation (\S\ref{sub:template}) and lexicalization (\S\ref{sub:inference}).
The template generation task aims to generate the template $\tilde{y}$ with placeholders for the constraint lexicons  $\mathcal{Z}$, and the lexicalization is to replace these placeholders with the constraints to perform lexically constrained text generation.

\subsection{Problem Definition}
\label{sub:def}
Let $x$ be an input text, and $\mathcal{Z}$ be a set of constraint lexicons; the goal of the lexically constrained text generation is to generate a text $y$ that includes all the constraint lexicons $\mathcal{Z}$ based on the input text $x$. Note that unconditional text generation tasks, such as keywords-to-sentence generation (\S\ref{sub:k2sg}), are only conditioned by a set of lexicons $\mathcal{Z}$, and in this case, we treat the input data $x$ as empty to provide a unified description without loss of generality.

\subsection{Template Generation}
\label{sub:template}
Given training input-output pairs $(x, y)$ and constraint lexicons $\mathcal{Z}$, we aim to build a model that generates a template $\tilde{y}$, which is defined as a text with the same number of placeholder tokens as the constraint lexicons $\mathcal{Z}$.
We assume that the output text $y$ in the training set includes all the constraint lexicons $\mathcal{Z}$.

The template $\tilde{y}$ is created by replacing the constraint lexicon $\mathcal{Z}$ in the output text $y$ with unique placeholder tokens according to the order of appearances (i.e., \texttt{<X>}, \texttt{<Y>}, and \texttt{<Z>} in Figure~\ref{fig:overview})\footnote{We also prefix and postfix the placeholder tokens to use them as BOS and EOS tokens.}, and then the model input $\tilde{x}$ is created by prefixing the constraint lexicons $\mathcal{Z}$ with the input text $x$\footnote{We use $|$ as separator token for constraints $\mathcal{Z}$ and input text $x$ and also prefixed \texttt{TL;DR:}.} These lexicons $\mathcal{Z}$ are concatenated with the unique placeholder tokens to let the model know the alignment between input and outputs.

Using the AutoTemplate input-output pairs $(\tilde{x}, \tilde{y})$, we can build the template generation model $p(\tilde{y} | \tilde{x})$ with any sequence-to-sequence models.
This study builds the template generation model $p$ using an autoregressive Transformer model with a regular beam search~\cite{vaswani2017transformer} instead of using constrained beam searches~\cite{hokamp-liu-2017-lexically,post-vilar-2018-fast} and dedicated non-autoregressive models~\cite{miao2019cgmh,zhang-etal-2020-pointer,he-2021-parallel}.

\subsection{Lexicalization}
\label{sub:inference}
After generating the template $\tilde{y}$, we replace the placeholder tokens with constraint lexicons $\mathcal{Z}$ as post-processing to achieve lexically constrained text generation.
Specifically, during inference, constraint lexicons are prefixed to the input text $x$ in the same way to build the model input $\tilde{x}$.
Then, we can obtain the template $\tilde{y}$ from the model $p$ and replace the placeholder tokens with the constraint lexicons $\mathcal{Z}$.

\subsection{Comparison with existing approaches}
We summarize the properties of existing lexically constrained text generation methods and AutoTemplate in Table~\ref{tab:related}.
SeqBF~\cite{mou-etal-2016-sequence} is the first neural text generation model for lexically constrained text generation based on non-autoregressive decoding. The SeqBF performs lexically constrained text generation by generating forward and backward text for a given constraint lexicon.
The most significant limitation is that only a single keyword can be used for the constraint.

CGMH~\cite{miao2019cgmh} and similar models~\cite{zhang-etal-2020-pointer,he-2021-parallel} are yet another non-autoregressive models that can incorporate multiple keywords in their outputs. 
However, the quality of the output text of non-autoregressive models is not as good as that of autoregressive models~\cite{gu2018nonautoregressive}. Our experiments confirmed that AutoTemplate, which can take advantage of autoregressive models, produces higher quality text than non-autoregressive methods, with or without leveraging pre-training (\S\ref{sub:k2sg}).

Another direction is to incorporate \textit{soft} constraints into the autoregressive models such as constrained beam search~\cite{hokamp-liu-2017-lexically,post-vilar-2018-fast} and keywords conditioning~\cite{fan-etal-2018-controllable,he2020ctrlsum}.
GBS~\cite{hokamp-liu-2017-lexically} is a constrained bean search technique that incorporates multiple keywords as constraints and promotes the inclusion of those keywords in the output during beam search. However, GBS often misses keywords in the output text.

CTRLSum~\cite{he2020ctrlsum} imposes keyword conditioning into encoder-decoder models by prefixing the keywords with the input.
This method can be easily conditioned with multiple keywords as a prefix and can be implemented on an autoregressive model, resulting in high-quality text generation.
However, the CTRLSum model cannot guarantee to satisfy lexical constraints.
Our experiments show that as the number of constraints increases, it is more likely to miss constraint lexicons in the output text (\S\ref{sub:entity_guilded}).

\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{l|cccccc|cccccc}
        \toprule
        \multirow{2}{*}{\textbf{Model}} & \multicolumn{6}{c}{\textbf{One-Billion-Word}} & \multicolumn{6}{c}{\textbf{Yelp}}\\
        & \textbf{B2} & \textbf{B4} & \textbf{N2} & \textbf{N4} & \textbf{M} & \textbf{SR} & \textbf{B2} & \textbf{B4} & \textbf{N2} & \textbf{N4} &\textbf{M} & \textbf{SR} \\\midrule
        SeqBF~\scriptsize{\cite{mou-etal-2016-sequence}} &  4.4 & 0.7 & 0.62 & 0.62 & 7.0 & <100. & 6.9 & 2.1 & 0.52 & 0.53 & 8.7 & <100.\\
        GBS~\scriptsize{\cite{hokamp-liu-2017-lexically}} & 10.1 & 2.8 & 1.49 & 1.50 & 13.5 & $\leq$100. & 13.6 & 4.5 & 1.68 & 1.71 & 15.3 & $\leq$100.\\
        CGMH~\scriptsize{\cite{miao2019cgmh}} & 9.9 & 3.5 & 1.15 & 1.17 & 13.1 & 100. & 12.3 & 4.6 & 1.41 & 1.45 & 14.6 & 100. \\
        POINTER~\scriptsize{\cite{zhang-etal-2020-pointer}} & 8.7 & 1.6 & 2.11 & 2.12 & 14.3 & 100. & 10.6 & 2.4 & 2.14 & 2.16 & 16.8 & 100.\\
        CBART~\scriptsize{\cite{he-2021-parallel}} & 15.6 & 6.6 & 2.16 & 2.19 & 15.2 & 100. & 19.4 & 9.0 & 2.54 & 2.64 & 17.4 & 100. \\\midrule
        AutoTemplate & & & & & & & &\\
        \quad w/ T5-base & \underline{18.3} & \underline{7.6} & \underline{3.39} & \underline{3.45} & \underline{16.0} & 100. & \underline{23.7} & \underline{10.8} & \underline{3.62} & \underline{3.76} & \underline{17.8} & 100.\\
        \quad w/ T5-large & \textbf{18.9} & \textbf{8.1} & \textbf{3.49} & \textbf{3.54} & \textbf{16.2} & 100. & \textbf{24.1} & \textbf{11.1} & \textbf{3.68} & \textbf{3.83} & \textbf{17.9} & 100.\\
        \bottomrule
    \end{tabular}
    \caption{Results of keywords-to-sentence generation on the One-Billion-Word and Yelp datasets. \textbf{Bold-faced} and \underline{underlined} denote the best and second-best scores
respectively. Baseline results are copied from \citet{he-2021-parallel}. B2/4 denotes BLEU-2/4, N2/4 denotes NIST-2/4, M denotes METEOR-v1.5, and SR denotes the success rate of lexical constraint satisfaction.}
    \label{tab:key2text}
\end{table*}

\section{Experiments}
We present experiments across two tasks: keywords-to-sentence generation (\S\ref{sub:k2sg}), and entity-centric summarization (\S\ref{sub:entity_guilded}).

\subsection{Keywords-to-Sentence Generation}
\label{sub:k2sg}
Keywords-to-sentence generation is a task to generate a sentence that includes pre-specified keywords as lexical constraints.
We will show that AutoTemplate is a simple yet effective method to perform this problem without using a complex decoding scheme.

\paragraph{Dataset}
We use One-Billion-Word and the Yelp dataset following the previous studies~\cite{miao2019cgmh,zhang-etal-2020-pointer,he-2021-parallel}. 
One-Billion-Word is a dataset for language modeling based on the WMT 2011 news crawl data~\cite{Chelba2014OneBW}. The Yelp dataset is based on the Yelp open dataset\footnote{\url{https://www.yelp.com/dataset}}. We utilized the publicly available pre-processed dataset\footnote{\url{https://github.com/NLPCode/CBART}}, which consists of 1M, 0.1M sentences for training and development sets, respectively, and 6k sentences with 1-6 pre-specified keywords for test sets, which we summarized in Table~\ref{tab:data-stats}.


\begin{table}[t]
    \centering
    \footnotesize
    \begin{tabular}{c|ccc}
        \toprule
        \textbf{Data}\ & \# example & output len. & \# constraints\\\midrule
        1B-Words & 12M & 27.08 & 1 -- 6\\
        Yelp & 13M & 34.26 & 1 -- 6 \\\midrule
        CNNDM &  312k & 70.58 & 4.53\\
        XSum & 226k & 29.39 & 2.11\\
        \bottomrule
    \end{tabular}
    \caption{Dataset Statistics: The output length is the number of BPE tokens per example using the T5 tokenizer. For the summarization datasets, the average number of constraints per example is shown.}
    \label{tab:data-stats}
\end{table}

\paragraph{Baselines}
For the baselines, we used strong competitive models for lexically constrained text generation, including SeqBF~\cite{mou-etal-2016-sequence}, GBS~\cite{hokamp-liu-2017-lexically}, CGMH~\cite{miao2019cgmh}, POINTER~\cite{zhang-etal-2020-pointer}, and CBART~\cite{he-2021-parallel}.
SeqBF, GBS, and CGMH are implemented on top of GPT2-small~\cite{radford2019language} (117M parameters). POINTER is implemented on BERT-large~\cite{devlin-etal-2019-bert} (340M parameters), and CBART is on BART-large~\cite{lewis-etal-2020-bart} (406M parameters).

\paragraph{Model}
We instantiate the template generation model based on the Transformer~\cite{vaswani2017transformer} initialized with T5 checkpoints~\cite{raffel2020t5} implemented on \texttt{transformers} library~\cite{wolf-etal-2020-transformers}. We specifically utilized the T5-v1.1-base (220M parameters)\footnote{\url{https://huggingface.co/google/t5-v1_1-base}} and
T5-v1.1-Large (770M parameters)\footnote{\url{https://huggingface.co/google/t5-v1_1-large}}~\cite{shazeer2020t5v11}.
To train the model, we used AdamW optimizer~\cite{loshchilov2018decoupled} with a linear scheduler and warmup, whose initial learning rate is set to 1e-5, and label smoothing~\cite{szegedy2016rethinking} with a label smoothing factor of 0.1.

Since the dataset used in this experiment is a set of raw texts, we randomly select 1 to 6 words from the text and decompose them into constraint lexicons $\mathcal{Z}$ and a template $\tilde{y}$ to create the AutoTemplate training data.
Note that the constraint lexicons $\mathcal{Z}$ were selected from the words excluding punctuations and stopwords~\cite{loper-bird-2002-nltk}.

\paragraph{Metrics}
All performance is measured with the BLEU-2/4~\cite{papineni-etal-2002-bleu}, NIST-2/4 scores~\cite{Doddington2002AutomaticEO}, and METEOR v1.5~\cite{denkowski-lavie-2014-meteor}.
Following the previous study, we show the averaged performance across the number of keywords~\cite{he-2021-parallel}.


\paragraph{Results}
Table~\ref{tab:key2text} shows the results of keywords-to-sentence generation.
First, the performance of GBS is not as high as non-autoregressive methods. In general, autoregressive decoding produces better text quality than non-autoregressive decoding. However, since GBS is not conditioned on the keywords, it sometimes produces more general text that does not satisfy the keyword constraint.

Second, among the non-autoregressive baseline models, CBART outperforms CGMH and POINTER, suggesting that encoder-decoder models such as CBART can produce higher-quality text than decoder-only models such as CGMH and POINTER.

Finally, AutoTemplate consistently outperforms all the baselines on both datasets by a large margin while keeping the success rate at 100\% regardless of the model size.
This indicates that AutoTemplate could take advantage of both autoregressive decoding and encoder-decoder models as described above.
We also confirm that using larger T5 models consistently improves text generation quality across all metrics.

Table~\ref{tab:onebillion-1} and \ref{tab:yelp_1} show qualitative examples of generated texts of CBART and AutoTemplate and human written reference. More examples can be found in Appendix.
The examples show that the AutoTemplate generates long and fluent sentences while the CBART tends to generate short text in Table~\ref{tab:onebillion-1} or non-fluent text in Table~\ref{tab:yelp_1}.


\begin{table}[t]
    \centering
    \footnotesize
    \begin{tabular}{p{7cm}}
        \toprule
        \textbf{Keywords}:\quad\hl{ggreen}{leading},\hl{oorange}{currency},\hl{bblue}{software},\hl{ppurple}{industry}\\\midrule
        \textbf{Reference}:\quad Transoft International , Inc. is a \hl{ggreen}{leading} provider of \hl{oorange}{currency} supply chain management \hl{bblue}{software} solutions for the banking \hl{ppurple}{industry} .\\\midrule
        \textbf{CBART}:\quad The \hl{ggreen}{leading} edge \hl{oorange}{currency} trading \hl{bblue}{software} \hl{ppurple}{industry} .\\\midrule
        \textbf{AutoTemplate}: The company is a \hl{ggreen}{leading} provider of \hl{oorange}{currency} management \hl{bblue}{software} to the financial services \hl{ppurple}{industry}.\\
        \bottomrule
    \end{tabular}
    \caption{Example generations for the keywords-to-sentence generation on One-billion-word.}
    \label{tab:onebillion-1}
\end{table}

\begin{table}[t]
    \centering
    \footnotesize
    \begin{tabular}{p{7cm}}
        \toprule
        \textbf{Keywords}:\quad\hl{ggreen}{nail},\hl{oorange}{salon},\hl{bblue}{always},\hl{ppurple}{world} \\\midrule
        \textbf{Reference}:\quad this is the very best \hl{ggreen}{nail} \hl{oorange}{salon} ! i \hl{bblue}{always} see amanda , her workmanship is out of this \hl{ppurple}{world} !\\\midrule
        \textbf{CBART}:\quad this is my favorite \hl{ggreen}{nail} \hl{oorange}{salon} in town ! \hl{bblue}{always} clean , friendly and the \hl{ppurple}{world} amazing .\\\midrule
        \textbf{AutoTemplate}: I have been going to this \hl{ggreen}{nail} \hl{oorange}{salon} for over a year now. they \hl{bblue}{always} do a great job, and the prices are out of this \hl{ppurple}{world}.\\
        \bottomrule
    \end{tabular}
    \caption{Example generations for the keywords-to-sentence generation on Yelp.}
    \label{tab:yelp_1}
\end{table}

\subsection{Entity-guided Summarization}
\label{sub:entity_guilded}
Automatic text summarization distills essential information in a document into short paragraphs, but different readers might want to know different things about specific entities, such as people or places. Thus, one summary might not meet all readers' needs. Entity-guided summarization aims to generate a summary focused on the entities of interest.
This experiment demonstrates that AutoTemplate can produce summaries that satisfy lexical constraints, even under complex entity conditioning.

\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{l|ccccc|ccccc}
    \toprule
    \multirow{2}{*}{\textbf{Model}} & \multicolumn{5}{c|}{\textbf{CNNDM}} & \multicolumn{5}{c}{\textbf{XSum}}\\
        & R1 & R2 & RL & BS & SR & R1 & R2 & RL & BS & SR \\\midrule
        \textit{reported results} & & & & & & & &\\
        \quad BART~\scriptsize{\cite{lewis-etal-2020-bart}} & 44.24 & 21.25 & 41.06 & 0.336 & - & 45.14 & 22.27 & 37.25 & - & - \\
        \quad CTRLSum~\scriptsize{\cite{he2020ctrlsum}} & 48.75 & 25.98 & 45.42 & 0.422 & - & - & - & - & - & -\\
        \textit{our implementation} & & & & & & & & \\
        \quad BART~\scriptsize{\cite{lewis-etal-2020-bart}} & 44.20 & 21.28 & 41.02 & 0.358 & 26.12 & 44.21 & 20.93 & 35.18 & 0.510 & 46.69 \\
        \quad CTRLSum~\scriptsize{\cite{he2020ctrlsum}} & 47.57 & 25.56 & 44.30 & 0.437 & 75.46 & 50.07 & 26.73 & 40.90 & 0.581 & 86.32\\\midrule
        AutoTemplate &. & & & & & &\\
        \quad w/ T5-base & \underline{51.02} & \underline{27.59} & \underline{47.85} & \underline{0.441} & 100. & \underline{50.49} & \underline{28.19} & \underline{43.89} & \underline{0.591} & 100. \\
        \quad w/ T5-large & \textbf{52.56} & \textbf{29.33} & \textbf{49.38} & \textbf{0.465} & 100. & \textbf{52.65} & \textbf{30.52} & \textbf{46.19} & \textbf{0.614} & 100.\\
    \bottomrule
    \end{tabular}
    \caption{Results of entity-guided summarization with oracle entities on CNNDM and XSum datasets. R1/2/L denotes ROUGE-1/2/L, BS denotes BERTScore, and SR denotes the success rate of lexical constraint satisfaction. \textbf{Bold-faced} and \underline{underlined} denote the best and second-best scores respectively.}
    \label{tab:entity-sum}
\end{table*}

\paragraph{Dataset}
We use CNNDM dataset~\cite{hermann2015teaching} and XSum dataset~\cite{narayan-etal-2018-dont} for the experiment.
We simulate the entity-guided summarization setting by providing the oracle entity sequence from the gold summary as lexical constraints.
Specifically, we use stanza, an off-the-shelf NER parser~\cite{qi-etal-2020-stanza}, to parse the oracle entity sequence from the gold summary to create entity-guided summarization data.
As summarized in the statistics in Table~\ref{tab:data-stats} and more detailed entity distributions in Figure~\ref{fig:entity-dist}, the CNNDM dataset tends to have more entities than XSum, which makes the 
Since the number of oracle entities can exceed 10, especially in the CNNDM dataset, as shown in Figure~\ref{fig:entity-dist}, this setup is much more complex than in the previous setting that evaluates whether a single pre-specified entity is included~\cite{fan-etal-2018-controllable,he2020ctrlsum}.
Note that one instance in the test set of the CNNDM dataset has a 676-word reference summary with 84 oracle entities, which is difficult to deal with large pre-trained language models, so we excluded it from the success rate evaluation.

\paragraph{Baselines}
We used competitive models as baselines, including fine-tuned BART~\cite{lewis-etal-2020-bart} and CTRLSum~\cite{he2020ctrlsum}. Similar to AutoTemplate, CTRLSum further conditions the input with lexical constraints and generates the output. The difference is that CTRLSum directly generates the output text, while AutoTemplate generates the corresponding template.

\paragraph{Model}
We use the same training configurations to instantiate the model used in the keywords-to-sentence generation task.

To build the training dataset, we use the masked gold summary by the oracle entity sequence as the output template $\tilde{y}$ as described in \S\ref{sec:method}, 
At inference time, we use the oracle entity sequence and the source document as input to generate the template and post-process to produce the output text.


\paragraph{Metrics}
We evaluate the entity-guided summarization performance using F1 scores of ROUGE-1/2/L~\cite{lin-2004-rouge}\footnote{\url{https://github.com/pltrdy/files2rouge}}, BERTScore~\cite{Zhang*2020BERTScore:}~\footnote{\url{https://github.com/Tiiiger/bert_score}}, and the success rate of entity constraint satisfaction following previous study~\cite{he2020ctrlsum}.



\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{fig/entity_dist.pdf}
    \caption{Distribution of the number of oracle entities. The CNNDM dataset (left) tends to have longer summaries and contains more entities than the XSUM dataset. As the number of entities increases, it becomes more and more difficult to include all the entities in the generated summary.}
    \label{fig:entity-dist}
\end{figure}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{fig/success_rate.pdf}
    \caption{Success rate of entities included in the generated summary at a different number of entities. The \textbf{\textcolor{ggreen}{green line}} denotes the BART model~\cite{lewis-etal-2020-bart}, the \textbf{\textcolor{oorange}{orange line}} denotes the CTRLSum model~\cite{he2020ctrlsum}, and \textbf{\textcolor{bblue}{blue line}} denotes AutoTemplate model. These graphs show that CTRLSum can include a limited number of entities in summary with a high chance. However, it becomes more and more difficult as the number of entities increases, while AutoTemplate always satisfies the constraint.}
    \label{fig:success-rate}
\end{figure}
\paragraph{Results}
Table~\ref{tab:entity-sum} shows the results of entity-guided summarization.
CTRLSum and AutoTemplate show improvements in summarization performance compared to the standard BART model, indicating that entity guidance contributes to the improvement in summarization performance.

On the other hand, while AutoTemplate always satisfies entity constraints, CTRLSum shows a constraint satisfaction success rate of 75.46\% for CNNDM and 86.32\% for XSum, characterizing the difference between AutoTemplate and CTRLSum.
As shown in Figure ~\ref{fig:success-rate}, while CTRLSum shows a high success rate when the number of entity constraints is limited, the success rate decreases monotonically as the number of constraints increases.

Finally, the AutoTemplate had a 100\% success rate regardless of the number of entity constraints and showed the highest summarization quality.

Table~\ref{tab:entsum-cnndm} shows the qualitative examples of the generated summaries by CTRLSum and AutoTemplate.
While CTRLSum could only include 10 of the 18 constraint entities in the generated summary, AutoTemplate covered all entities and generated a fluent summary.

We also show the generated summaries with different entity conditioning by AutoTemplate in Table~\ref{tab:controllable}. We confirmed that AutoTemplate can produce summaries with a different focus using different entity conditioning and can also include constraint entities in the generated summary.

\begin{table*}[t]
    \centering
    \footnotesize
    \begin{tabular}{p{\linewidth}}
        \toprule
        \textbf{Constrained Entities: }$\{$\hl{ggreen}{Amir Khan},\hl{oorange}{Manny Pacquiao},\hl{bblue}{Abu Dhabi},\hl{ppurple}{UAE}, \hl{lgreen}{Khan},\hl{yyellow}{Floyd Mayweather Jr},\hl{ggold}{Las Vegas},\\
        \hl{ggray}{PacMan},\hl{ggreen}{Bob Arum},\hl{oorange}{UAE},\hl{bblue}{\underline{Khan}},\hl{ppurple}{\underline{Muslim}},\hl{lgreen}{\underline{Brit}},\hl{yyellow}{\underline{the Money Man}},\hl{ggold}{\underline{PacMan}}, \hl{ggray}{\underline{Khan}},\hl{ggreen}{\underline{Chris Algieri}},\hl{oorange}{\underline{New York}} $\}$\\\midrule
        \textbf{CTRLSum}~\cite{he2020ctrlsum}: \hl{ggreen}{Amir Khan} could face \hl{oorange}{Manny Pacquiao} in \hl{bblue}{Abu Dhabi}, \hl{ppurple}{UAE}. \hl{lgreen}{Khan} has been linked with a fight with \hl{yyellow}{Floyd Mayweather Jr} in \hl{ggold}{Las Vegas}. The \hl{ggray}{PacMan}'s promoter \hl{ggreen}{Bob Arum} is keen for a fight in the \hl{oorange}{UAE}.\\\midrule
        \textbf{AutoTemplate:}  \hl{ggreen}{Amir Khan} could face \hl{oorange}{Manny Pacquiao} in \hl{bblue}{Abu Dhabi}, \hl{ppurple}{UAE}. \hl{lgreen}{Khan} is preparing to face \hl{yyellow}{Floyd Mayweather Jr} in \hl{ggold}{Las Vegas} on May 2. \hl{ggray}{PacMan}'s vintage promoter \hl{ggreen}{Bob Arum} has to hand a treasure trove of an offer for a fight in the \hl{oorange}{UAE} this November or December. \hl{bblue}{\underline{Khan}} is a hero of the \hl{ppurple}{\underline{Muslim}} world, the \hl{lgreen}{\underline{Brit}} would be a huge attraction there. Assuming that \hl{yyellow}{\underline{the Money Man}} wins his interim bout with \hl{ggold}{\underline{PacMan}} next month, all that would appear to stand between him and his long-awaited mega-fight is the outside chance of a re-match. \hl{ggray}{\underline{Khan}} is set to fight \hl{ggreen}{\underline{Chris Algieri}} in \hl{oorange}{\underline{New York}} next month.\\
        \midrule
        \textbf{Reference}: \hl{ggreen}{Amir Khan} could be set to face \hl{oorange}{Manny Pacquiao} in \hl{bblue}{Abu Dhabi}, \hl{ppurple}{UAE}. \hl{lgreen}{Khan}'s hopes of taking on \hl{yyellow}{Floyd Mayweather Jr} in \hl{ggold}{Las Vegas} have faded. \hl{ggray}{PacMan}'s promoter \hl{ggreen}{Bob Arum} has a mega offer for a \hl{oorange}{UAE} fight late in 2015. \hl{bblue}{\underline{Khan}} is a hero of the \hl{ppurple}{\underline{Muslim}} world and his lure in the Middle East is clear. The \hl{lgreen}{\underline{Brit}} will be ringside when \hl{yyellow}{\underline{the Money Man}} fights the \hl{ggold}{\underline{PacMan}} on May 2. \hl{ggray}{\underline{Khan}} must first win interim bout with \hl{ggreen}{\underline{Chris Algieri}} in \hl{oorange}{\underline{New York}} on May 29.\\
    \bottomrule
    \end{tabular}
    \caption{Qualitative comparisons between CTRLSum and AutoTemplate. Constraint entities are extracted from the reference summary (oracle entities). \underline{Underlined entities} are missed by the CTRLSum~\cite{he2020ctrlsum} while AutoTemplate can incorporate them into the generated summary.}
    \label{tab:entsum-cnndm}
\end{table*}

\begin{table*}[ht]
    \centering
    \footnotesize
    \begin{tabular}{p{\linewidth}}
    \toprule
        \textbf{Constraint Entities: }  $\{$\hl{ggreen}{Game Boy},\hl{oorange}{Apple},\hl{bblue}{Chris Gallizzi}, \hl{ppurple}{Nintendo}$\}$ \\\midrule
        \textbf{AutoTemplate}: Case adds iconic \hl{ggreen}{Game Boy} buttons to \hl{oorange}{Apple} handset. It also lets gamers play their existing cartridges on their handset. Developer \hl{bblue}{Chris Gallizzi} said: 'We wanted to create a retro device that can be easily adapted into any modern gamer's arsenal of devices' \hl{ppurple}{Nintendo} advised keeping cartridges away from dust, where possible, to avoid gameplay glitches.\\\midrule
        \textbf{Constraint Entities: } $\{$\hl{lgreen}{Hyperkin},\hl{ppurple}{Nintendo},\hl{yyellow}{Game Boy Color},\hl{ggold}{Start and Select}$\}$\\\midrule
        \textbf{AutoTemplate}: \hl{lgreen}{Hyperkin} has designed a case that adds the iconic directional arrows from the \hl{ppurple}{Nintendo} \hl{yyellow}{Game Boy Color}. It was originally devised as part of an April Fool's joke, but the popularity and demand for a real product was so high the firm has announced plans to sell it. It will feature an eight-way D-pad, two action buttons, a \hl{ggold}{Start and Select} button, and a battery that can be charged through the phone.\\
        \bottomrule
    \end{tabular}
    \caption{Examples of controlled summary generation by changing constraint entities. By conditioning with different entities, the model can generate summaries with different points of interest for the same source article.}
    \label{tab:controllable}
\end{table*}

\begin{table*}[ht]
    \centering
    \scriptsize
    \setlength{\tabcolsep}{3pt}
    \begin{tabular}{l|ccccc|ccccc|cccc|cccc}
        \toprule
        & \multicolumn{10}{c|}{\textbf{Keywords-to-Sentence Generation}} & \multicolumn{8}{c}{\textbf{Entity-guided Summarization}}\\
        & \multicolumn{5}{c|}{\textbf{One-Billion-Word}} & \multicolumn{5}{c|}{\textbf{Yelp}} & \multicolumn{4}{c|}{\textbf{CNNDM}} & \multicolumn{4}{c}{\textbf{XSum}}\\
        & B2 & B4 & N2 & N4 & M & B2 & B4 & N2 & N4 & M & R1 & R2 & RL & BS &  R1 & R2 & RL & BS \\\midrule
        AutoTemplate & 18.3 & 7.6 & 3.39 & 3.45 & 16.0 & 23.7 & 10.8 & 3.62 & 3.76 & 17.8 & 51.02 & 27.59 & 47.85 & 0.441 & 50.49 & 28.19 & 43.89 & 0.591\\
        \quad w/ random init & 17.0 & 6.5 & 3.23 & 3.27 & 15.6 & 22.4 & 9.8 & 3.42 & 3.54 & 17.6 & 38.38 & 11.91 & 35.06 & 0.210 & 39.51 & 15.84 & 32.07 & 0.412 \\
        \quad w/ single mask & 16.6 & 5.9 & 3.15 & 3.19 & 15.0 & 15.9 & 5.2 & 2.86 & 2.92 & 13.8 & 48.05 & 24.53 & 44.69 & 0.387 & 45.67 & 23.07 & 39.31 & 0.493 \\
        \bottomrule
    \end{tabular}
    \caption{Ablation studies for keywords-to-sentence generation and entity-guided summarization tasks using T5-base checkpoints.}
    \label{tab:ablation}
\end{table*}
\begin{table}[ht]
    \centering
    \scriptsize
    \begin{tabular}{l|cc}
        \toprule
        \multirow{2}{*}{Fluency (\%)} & \multicolumn{2}{c}{Keywords-to-Sentence} \\
        & One-billion-words & Yelp \\\midrule
        CBART~\tiny{\cite{he-2021-parallel}} & 94.42 & 93.95\\
        AutoTemplate & 97.05 & 98.15\\
        Reference & 97.25 & 90.77 \\\midrule
        \multirow{2}{*}{Fluency (\%)} & \multicolumn{2}{c}{Entity-guided summarization}\\
        & CNNDM & XSum \\\midrule
        BART~\tiny{\cite{lewis-etal-2020-bart}} & 96.77 & 98.88\\
        CTRLSum~\tiny{\cite{he2020ctrlsum}} & 96.68 & 99.01 \\
        AutoTemplate & 96.38 & 98.91\\
        Reference & 91.55 & 98.73\\
        \bottomrule
    \end{tabular}
    \caption{Results of fluency evaluations by the acceptability classifier.}. %
    \label{tab:fluency}
\end{table}
\section{Analysis}

\paragraph{Does AutoTemplate generate fluent text?}
AutoTemplate decomposes the lexically constrained text generation task into template generation and lexicalization tasks.
The template generation task aims to produce unnatural output, including placeholder tokens, leading to concerns that the final output text will be less fluent than the directly generated text.

To this end, we evaluate the fluency of the output text by AutoTemplate and baselines.
We specifically used the grammatical acceptability classifier based on \texttt{roberta-large} fine-tuned on CoLA dataset~\cite{warstadt-etal-2019-neural} following \citet{krishna-etal-2020-reformulating}\footnote{\url{https://huggingface.co/cointegrated/roberta-large-cola-krishna2020}} and show the micro averaged accuracy of sentence-level grammaticality.\footnote{Although we can also measure fluency using the perplexity of an external language model, it can assign low perplexity to unnatural texts containing common words~\cite{mir-etal-2019-evaluating}. Therefore, we decided to evaluate fluency using the classifier.}.

We show the results in Table~\ref{tab:fluency}. For the keywords-to-sentence generation task, AutoTemplate shows better fluency scores than the CBART model, characterizing the differences between CBART and AutoTemplate. While CBART relies on the non-autoregressive models, which leads to non-fluent text generation, AutoTemplate can be implemented on top of autoregressive models. Thus, AutoTemplate can generate more fluent output text.

For the entity-guided summarization task, AutoTemplate shows similar fluency with the state-of-the-art autoregressive text generation models, including BART and CTRLSum, indicating that the AutoTemplate can generate as fluent text as the state-of-the-art direct generation models.

\paragraph{Importance of Pre-training}
To evaluate the importance of pre-training for AutoTemplate, we performed ablation studies using a \textit{randomly} initialized model.
As shown in \ref{tab:ablation}, we confirmed that the model with pre-training significantly improves the quality of generated text in both keywords-to-sentence generation and entity-guided summarization cases.
Note that the keyword-to-sentence generation model with random initialization generally produced better text quality than the baseline CBART model, confirming the importance of using autoregressive models.

\paragraph{Are unique placeholders needed?}
Throughout this study, we assumed the unique placeholder tokens according to the order of appearance, i.e., \texttt{<X>}, \texttt{<Y>} and \texttt{<Z>}, so we investigate the importance of this design choice.
We show the performance of AutoTemplate with a single type of placeholder token (i.e., \texttt{<X>} for all placeholders in the template $\tilde{y}$) in Table~\ref{tab:ablation}.
We observed a significant drop in the quality of the generated text for both keyword-to-sentence generation and entity-guided summarization tasks, suggesting the importance of using unique placeholder tokens.


\section{Further Related Work}
\paragraph{Template-based Text Generation}
Before the era of neural encoder-decoder models, most NLG systems rely on templates to perform text generation~\cite{kukich-1983-design,tanaka-ishii-etal-1998-reactive-content}.
The classical approaches aim to build a template manually~\cite{kukich-1983-design,reiter_dale_2000} or automatically~\cite{angeli-etal-2010-simple,kondadadi-etal-2013-statistical}, but more recent studies aim to derive templates as latent variables~\cite{wiseman-etal-2018-learning,li-rush-2020-posterior,fu2020latent} or to use retrieved examples as soft templates~\cite{cao-etal-2018-retrieve,peng-etal-2019-text}.
While these studies use the template mainly to control the "how to say" aspect in text generation, this study uses it to ensure that lexical constraints are satisfied.

\paragraph{Copy mechanism}
The copy mechanism was originally introduced to deal with the out-of-vocabulary problem in machine translation by selecting the words from the source in addition to the vocabulary, such as the unknown word replacement with post-processing~\cite{jean-etal-2015-using,luong-etal-2015-addressing}, and the joint modeling of unknown word probabilities into encoder-decoder models~\cite{gu-etal-2016-incorporating,gulcehre-etal-2016-pointing}, but with the advent of subword units~\cite{sennrich-etal-2016-neural,kudo-2018-subword}, the unknown word problem has been diminished. Thus, the copy mechanism is not widely used now, especially in machine translation.

However, the copy mechanism still plays a vital role in more complex text generation tasks involving numerical computation~\cite{murakami-etal-2017-learning,suadaa-etal-2021-towards} and logical reasoning~\cite{chen-etal-2020-logical}.
Specifically, they produce special tokens that serve as placeholders and replace them with the desired words in post-processing.
AutoTemplate adapts a similar copy mechanism to perform lexically constrained text generation, showing that it can cover all the constrained entities in its outputs, even for more complex conditioning (more than ten entities).




\section{Conclusions}
This study proposes AutoTemplate, a simple yet effective framework for lexically constrained text generation. 
The core idea is to decompose lexically constrained text generation into two steps, template generation, and lexicalization, by converting the input and output formats. The template generation can be done with standard encoder-decoder models with beam search so that AutoTemplate can perform lexically constrained text generation without using complex decoding algorithms such as non-autoregressive decoding and constrained beam search.
Experimental results show that the AutoTemplate significantly outperforms the competitive baselines across keywords-to-sentence generation and entity-guided summarization tasks while satisfying the lexical constraints.

\section*{Acknowledgements}
We thank Tom M. Mitchell for the helpful feedback on this work.

\bibliography{custom}
\bibliographystyle{acl_natbib}

\appendix

\section{More qualitative examples}
\label{sec:k2s-more}
Table~\ref{tab:onebillion_2}-\ref{tab:yelp_3} show more qualitative examples of keywords-to-sentence generation task.
\begin{table}[t]
    \centering
    \footnotesize
    \begin{tabular}{p{7cm}}
        \toprule
        \textbf{Keywords}: \hl{ggreen}{government},\hl{oorange}{ability},\hl{bblue}{companies},\hl{ppurple}{legal} \\\midrule
        \textbf{Reference}: Generally , the \hl{ggreen}{government} has the \hl{oorange}{ability} to compel the cooperation of private \hl{bblue}{companies} and assure them \hl{ppurple}{legal} immunity with a valid court order .\\\midrule
        \textbf{CBART}: The \hl{ggreen}{government} has restricted the \hl{oorange}{ability} of insurance \hl{bblue}{companies} to take \hl{ppurple}{legal} action .\\\midrule
        \textbf{AutoTemplate:} The \hl{ggreen}{government} has the \hl{oorange}{ability} to force \hl{bblue}{companies} to comply with \hl{ppurple}{legal} requirements, he said.\\
        \bottomrule
    \end{tabular}
    \caption{Example generations for the keywords-to-sentence generation on One-billion-word.}
    \label{tab:onebillion_2}
\end{table}

\begin{table}[t]
    \centering
    \footnotesize
    \begin{tabular}{p{7cm}}
        \toprule
        \textbf{Keywords}:  \hl{ggreen}{time},\hl{oorange}{voters},\hl{bblue}{primary},\hl{ppurple}{days} \\\midrule
        \textbf{Reference}: At the same \hl{ggreen}{time} , he said the more he appears before \hl{oorange}{voters} , the better he does on \hl{bblue}{primary} \hl{ppurple}{days} .\\\midrule
        \textbf{CBART}: The last \hl{ggreen}{time} , the \hl{oorange}{voters} were in the \hl{bblue}{primary} , two \hl{ppurple}{days} before Nov .\\\midrule
        \textbf{AutoTemplate}: At the same \hl{ggreen}{time}, \hl{oorange}{voters} will be able to cast their ballots during the \hl{bblue}{primary} \hl{ppurple}{days}, he said.\\
        \bottomrule
    \end{tabular}
    \caption{Example generations for the keywords-to-sentence generation on One-billion-word.}
    \label{tab:onebillion_3}
\end{table}


\begin{table}[t]
    \centering
    \footnotesize
    \begin{tabular}{p{7cm}}
        \toprule
        \textbf{Keywords}:  \hl{ggreen}{experience}, \hl{oorange}{top}, \hl{bblue}{easily}, \hl{ppurple}{driver} \\\midrule
        \textbf{Reference}: my \hl{ggreen}{experience} with lv cans was \hl{oorange}{top} notch . cab was \hl{bblue}{easily} flagged just off the strip , the route was direct and the \hl{ppurple}{driver} was very nice .\\\midrule
        \textbf{CBART}: the whole \hl{ggreen}{experience} was \hl{oorange}{top} notch , \hl{bblue}{easily} by the \hl{ppurple}{driver} .\\\midrule
        \textbf{AutoTemplate:} i had a great \hl{ggreen}{experience} with this company. they were on \hl{oorange}{top} of everything. i was \hl{bblue}{easily} able to get a \hl{ppurple}{driver} to pick me up at my hotel.\\
        \bottomrule
    \end{tabular}
    \caption{Example generations for the keywords-to-sentence generation on Yelp.}
    \label{tab:yelp_2}
\end{table}


\begin{table}[t]
    \centering
    \footnotesize
    \begin{tabular}{p{7cm}}
        \toprule
        \textbf{Keywords}:  \hl{ggreen}{southern}, \hl{oorange}{fresh}, \hl{bblue}{made}, \hl{ppurple}{friendly} \\\midrule
        \textbf{Reference}: absolutely , the best pizza in \hl{ggreen}{southern} nevada ! the pizza is always \hl{oorange}{fresh} , \hl{bblue}{made} fresh as ordered . the wait staff is very \hl{ppurple}{friendly} and effecient !\\\midrule
        \textbf{CBART}: great \hl{ggreen}{southern} food , \hl{oorange}{fresh} and \hl{bblue}{made} with \hl{ppurple}{friendly} staff .\\\midrule
        \textbf{AutoTemplate}: this is the best \hl{ggreen}{southern} food i have ever had. everything is \hl{oorange}{fresh} and \hl{bblue}{made} to order. the staff is very \hl{ppurple}{friendly} and helpful. i will definitely be back.\\
        \bottomrule
    \end{tabular}
    \caption{Example generations for the keywords-to-sentence generation on Yelp.}
    \label{tab:yelp_3}
\end{table}



\end{document}
