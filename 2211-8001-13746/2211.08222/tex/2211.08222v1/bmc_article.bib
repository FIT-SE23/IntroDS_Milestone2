% bmc_article.bib
% 
%  An example of bibtex entries.
%  Entries taken from BMC instructions for authors page.

% uncomment next line to make author-year bibliography
% @settings{label, options="nameyear"}

@article{blank,
	author  = {}, 
	title   = {},
	journal = {}, 
	year  = {},
	  month = {}, 
	  volume= {}, 
	  number= {}, 
	  pages = {},
	  note  = {} 
}	

% Article within a journal
@ARTICLE{koon,
	author  = {Koonin, E V and Altschul, S F and P Bork}, 
	title   = {BRCA1 protein products: functional motifs}, 
	journal = {Nat Genet}, 
	year    = {1996},
	volume  = {13}, 
	pages   = {266-267}
}	

% Article within a journal supplement
@ARTICLE{oreg,
	author  = {Orengo, C A and Bray, J E and Hubbard, 
		   T and LoConte, L and Sillitoe, I}, 
	title   = {Analysis and assessment of ab initio 
		   three-dimensional prediction, secondary 
		   structure, and contacts prediction},
	journal = {Proteins}, 
	year    = {1999},
	volume  = {Suppl 3}, 
	pages   = {149-170}
}	

% In press article
@inpress{khar,
	author  = {Kharitonov, S A and Barnes, P J}, 
	title   = {Clinical aspects of exhaled nitric oxide},
	journal = {Eur Respir J}, 
	note    = {in press} 
}	

%
% Published abstract
%
@ARTICLE{zvai,
	author  = {Zvaifler, N J and Burger, J A and Marinova-Mutafchieva, 
		   L and Taylor, P and Maini, R N},
	title   = {Mesenchymal cells, stromal derived factor-1 and 
		   rheumatoid arthritis [abstract]},
	journal = {Arthritis Rheum}, 
	year    = {1999},
	volume  = {42}, 
	pages   = {s250},
}	


%
% Article within conference proceedings
%
@Inproceedings{xjon,
	author    = {X Jones}, 
	title     = {Zeolites and synthetic mechanisms},
	booktitle = {Proceedings of the First National Conference on 
		     Porous Sieves: 27-30 June 1996; Baltimore},
	year      = {1996},
	  editor  = {Y Smith}, 
	  pages   = {16-27},
	  organization  = {Stoneham: Butterworth-Heinemann}
}	

%%%%%%%%
%  Book chapter, or article within a book
%
@incollection{schn,
	author    = {E Schnepf}, 
	title     = {From prey via endosymbiont to plastids: 
		     comparative studies in dinoflagellates},
	booktitle = {Origins of Plastids}, 
	editor    = {R A Lewin}, 
	publisher = {Chapman and Hall},
	pages     = {53-76}, 
	year      = {1993},
	  address = {New York}, 
	  volume  = {2}, 
	  edition = {2nd} 
}	

%%%%%%%%
% Whole issue of journal
%
@wholejournal{pond,
	editor  = {B Ponder and S Johnston and L Chodosh}, 
	title   = {Innovative oncology},
	journal = {Breast Cancer Res}, 
	year  = {1998},
	  volume= {10}, 
	  pages = {1-72}
}	


%%%%%%%%
% Whole conference proceedings
%
@proceedings{smith,
	editor  = {Y Smith}, 
	title   = {Proceedings of the First National Conference
		   on Porous Sieves: 27-30 June 1996; Baltimore},
	year = 1996,
	  address= {Stoneham}, 
	  publisher = {Butterworth-Heinemann},
}	


%%%%%%%%
% Complete book
%
@book{marg,
	author    = {L Margulis}, 
	title     = {Origin of Eukaryotic Cells},
	publisher = {Yale University Press}, 
	year      = {1970},
	address   = {New Haven} 
}



%%%%%%%%
% Monograph or book in series 
%
@incollection{hunn,
	author    = {G W Hunninghake and J E Gadek}, 
	title     = {The alveloar macrophage},
	booktitle = {Cultured Human Cells and Tissues},
	publisher = {Academic Press}, 
	year      = {1995},
  pages      = {54-56},
	  editor   = {T J R Harris}, 
	  address  = {New York}, 
	  note     = {Stoner G (Series Editor): Methods and Perspectives in Cell Biology, vol 1} 
}


%%%%%%%%
% Book with institutional author
@manual{advi,
	  title   = {Annual Report}, 
	    organization  = {Advisory Committee on Genetic Modification}, 
	    address = {London},
	    year    = {1999}
}


%%%%%%%%
% PHD Thesis
%
@phdthesis{koha,
	author = {R Kohavi}, 
	title  = {Wrappers for performance enhancement and
		  obvious decision graphs},
	school = {Stanford University, Computer Science Department},
	year   = {1995}
}

%%%%%%%%
% Webpage Link / URL
%
@webpage{mouse,
	title  = {The Mouse Tumor Biology Database},
	url = {http://tumor.informatics.jax.org/cancer\_links.html}
}



%Refs started here

@article{sitzmann_meta-analysis_2011,
	title = {A meta-analysis of self-regulated learning in work-related training and educational attainment: what we know and where we need to go},
	volume = {137},
% 	issn = {1939-1455},
	shorttitle = {A meta-analysis of self-regulated learning in work-related training and educational attainment},
	doi = {10.1037/a0022777},
	abstract = {Researchers have been applying their knowledge of goal-oriented behavior to the self-regulated learning domain for more than 30 years. This review examines the current state of research on self-regulated learning and gaps in the field's understanding of how adults regulate their learning of work-related knowledge and skills. Self-regulation theory was used as a conceptual lens for deriving a heuristic framework of 16 fundamental constructs that constitute self-regulated learning. Meta-analytic findings (k=430, N=90,380) support theoretical propositions that self-regulation constructs are interrelated-30\% of the corrected correlations among constructs were .50 or greater. Goal level, persistence, effort, and self-efficacy were the self-regulation constructs with the strongest effects on learning. Together these constructs accounted for 17\% of the variance in learning, after controlling for cognitive ability and pretraining knowledge. However, 4 self-regulatory processes-planning, monitoring, help seeking, and emotion control-did not exhibit significant relationships with learning. Thus, a parsimonious framework of the self-regulated learning domain is presented that focuses on a subset of self-regulatory processes that have both limited overlap with other core processes and meaningful effects on learning. Research is needed to advance the field's understanding of how adults regulate their learning in an increasingly complex and knowledge-centric work environment. Such investigations should capture the dynamic nature of self-regulated learning, address the role of self-regulation in informal learning, and investigate how trainees regulate their transfer of training.},
	number = {3},
	journal = {Psychological Bulletin},
	author = {Sitzmann, Traci and Ely, Katherine},
	month = may,
	year = {2011},
	pmid = {21401218},
	keywords = {Achievement, Adult, Educational Status, Goals, Humans, Inservice Training, Internal-External Control, Learning, Self Efficacy},
	pages = {421--442},
}

@incollection{suraworachet_examining_2021,
	address = {Cham},
	title = {Examining the {relationship} {between} {reflective} {writing} {behaviour} and {self}-regulated {Learning} {competence}: {a} {time}-{series} {analysis}},
	volume = {12884},
% 	isbn = {978-3-030-86435-4 978-3-030-86436-1},
	shorttitle = {Examining the {Relationship} {Between} {Reflective} {Writing} {Behaviour} and {Self}-regulated {Learning} {Competence}},
% 	url = {https://link.springer.com/10.1007/978-3-030-86436-1_13},
	abstract = {Self-Regulated Learning (SRL) competence is imperative to academic achievement. For reflective academic writing tasks, which are common for university assessments, this is especially the case since students are often required to plan the task independently to be successful. The purpose of the current study was to examine different reflection behaviours of postgraduate students that were required to reflect on individual tasks over a fifteen-week-long higher education course. Forty students participated in a standardised questionnaire at the beginning of the course to assess their SRL competence and then participated in weekly individual reflection tasks on Google Docs. We examined students’ reflective writing behaviours based on time-series and correlation analysis of fine-grained data retrieved from Google Docs. More specifically, reflection behaviours between students with high SRL and low SRL competence were investigated. The results show that students with high SRL competence tend to reflect more frequently and more systematically than students with low SRL competence. Even though no statistically significant difference in academic performance between the two groups was found, there were statistical correlations between academic performance and individual reflective writing behaviours. We conclude the paper with a discussion on the insights into the temporal reflection patterns of different SRL competence student clusters, the impact of these behaviours on students’ academic performance, and potential suggestions for appropriate support for students with different levels of SRL.},
	booktitle = {Technology-{Enhanced} {Learning} for a {Free}, {Safe}, and {Sustainable} {World}},
	publisher = {Springer International Publishing},
	author = {Suraworachet, Wannapon and Villa-Torrano, Cristina and Zhou, Qi and Asensio-Pérez, Juan I. and Dimitriadis, Yannis and Cukurova, Mutlu},
	editor = {De Laet, Tinne and Klemke, Roland and Alario-Hoyos, Carlos and Hilliger, Isabel and Ortega-Arranz, Alejandro},
	year = {2021},
	doi = {10.1007/978-3-030-86436-1_13},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {163--177},
}

@article{liu_combining_2021,
	title = {Combining factor analysis with writing analytics for the formative assessment of written reflection},
	volume = {120},
% 	issn = {07475632},
% 	url = {https://linkinghub.elsevier.com/retrieve/pii/S0747563221000558},
	doi = {10.1016/j.chb.2021.106733},
	abstract = {The formative assessment of written reflection provides opportunities for students to improve their practice in an iterative manner using reflective writing. However, manual formative assessment of written reflection is time consuming and subjective. While progress has been made in deploying writing analytics tools to provide auto­ mated, formative feedback, few approaches to automated assessment are grounded in a validated, theory-based, formative assessment model. To address this, we propose a five-factor model of the Capability for Written Reflection (CWRef), grounded in the scholarship of reflective writing pedagogy. This paper uses Confirmatory Factor Analysis to validate the CWRef model by examining the relative contributions of textual features, derived from writing analytics, to each factor in the model, and their contributions to CWRef. The model was evaluated with two reflective writing corpora, showing which textual features, derived using Academic Writing Analytics and Linguistic Inquiry \& Word Count, were significant indicators of factors in both corpora. In addition, it was found that the reflective writing context was an important factor influencing the validity of the CWRef model. Finally, we consider how this new analytical assessment model could enable improved tracking of progression in reflective writing, providing the basis for improved formative feedback.},
% 	urldate = {2022-03-29},
	journal = {Computers in Human Behavior},
	author = {Liu, Ming and Kitto, Kirsty and Buckingham Shum, Simon},
	month = jul,
	year = {2021},
	pages = {106733},
}

@article{thorpe_reflective_2004,
	title = {Reflective learning journals: {from} concept to practice},
	volume = {5},
% 	url = {https://doi.org/10.1080/1462394042000270655},
	doi = {10.1080/1462394042000270655},
	number = {3},
	journal = {Reflective Practice},
	author = {Thorpe, Karran},
	year = {2004},
	note = {Publisher: Routledge},
	pages = {327--343},
}

@article{ryan_pedagogical_2013,
	title = {The pedagogical balancing act: teaching reflection in higher education},
	volume = {18},
% 	url = {https://doi.org/10.1080/13562517.2012.694104},
	doi = {10.1080/13562517.2012.694104},
	number = {2},
	journal = {Teaching in Higher Education},
	author = {Ryan, Mary},
	year = {2013},
	note = {Publisher: Routledge},
	pages = {144--155},
}

@article{lew_writing_2011,
	title = {Writing to learn: can reflection journals be used to promote self-reflection and learning?},
	volume = {30},
% 	url = {https://doi.org/10.1080/07294360.2010.512627},
	doi = {10.1080/07294360.2010.512627},
	number = {4},
	journal = {Higher Education Research \& Development},
	author = {Lew, Duan Ning Magdeleine and Schmidt, Henk G.},
	year = {2011},
	note = {Publisher: Routledge},
% \_eprint: https://doi.org/10.1080/07294360.2010.512627},
	pages = {519--532},
}

@article{jenson_promoting_2011,
	title = {Promoting {self}-regulation and {critical} {reflection} {through} {writing} {students}’ {use} of {electronic} {portfolio}},
	volume = {1},
% 	issn = {2157-622X},
	number = {1},
	journal = {International Journal of ePortfolio},
	author = {Jenson, Jill D},
	year = {2011},
	pages = {49--60},
}

@article{strong_making_2001,
	title = {Making {students} as {important} as {standards}.},
	volume = {59},
% 	issn = {ISSN-0013-1784},
	number = {3},
	journal = {ASCD Educational Leadership},
	author = {Strong, Richard W. and Silver, Harvey F. and Perini, Matthew J.},
	year = {2001},
	pages = {56--61},
}

@article{connor-greene_making_2000,
	title = {Making {connections}: {evaluating} the {effectiveness} of {journal} {writing} in {enhancing} {student} {learning}},
	volume = {27},
% 	url = {https://doi.org/10.1207/S15328023TOP2701_10},
	doi = {10.1207/S15328023TOP2701_10},
	abstract = {Although journal writing has been extensively described and advocated in the teaching literature, little attention has been given to empirical assessment of its effectiveness in increasing student learning. Previous evaluations typically relied on student and faculty perceptions rather than performance measures. In this article, I describe journal writing as a way to actively engage students in learning about personality theories and include new criteria for instructor evaluation of journal entries. Analysis of student test grades indicated that a journal writing assignment increased student learning, and student evaluations supported the perceived usefulness of this exercise in fostering understanding. Examples from journals illustrate the ways in which students connected the course material to their own observations.},
	number = {1},
	journal = {Teaching of Psychology},
	author = {Connor-Greene, Patricia A.},
	year = {2000},
% 	note = {\_eprint: https://doi.org/10.1207/S15328023TOP2701\_10},
	pages = {44--46},
}

@article{boutet_evaluating_2017,
	title = {Evaluating the {implementation} and {effectiveness} of {reflection} {writing}},
	volume = {8},
% 	issn = {1918-2902},
% 	url = {https://ojs.lib.uwo.ca/index.php/cjsotl_rcacea/article/view/7001},
	doi = {10.5206/cjsotl-rcacea.2017.1.8},
	abstract = {There is ample theoretical justification for incorporating reflection exercises as a tool for preparing students for life beyond university, yet the utility of such exercises needs to be documented if resources are to be devoted to their implementation. This study describes the implementation and evaluates the effectiveness of a reflection exercise that was introduced in an entry-level undergraduate psychology course. Students completed four periodic reflection journals and submitted an essay summarizing their progress as learner at the end of the semester using examples from the journals to support their reflection. Multiple qualitative analysis methods were used to measure the reflective content of the summary essays. The analyses support the effectiveness of the exercise in promoting reflection on the process of learning including strengths, weaknesses, learning strategies, competence, efforts, and emotions. In addition, reviewing the reflective essays provided the instructor with invaluable insight into the students’ experience. We conclude that reflection writing can be incorporated in undergraduate studies to encourage the development of life-long learning skills with reasonable time requirements. Suggestions for modes of implementation as well as future avenues of research are discussed.},
	number = {1},
% 	urldate = {2022-05-26},
	journal = {The Canadian Journal for the Scholarship of Teaching and Learning},
	author = {Boutet, Isabelle and Vandette, Marie-Pier and Valiquette-Tessier, Sophie-Claire},
	month = mar,
	year = {2017},
}


@article{cooner_assessing_2006,
	title = {Assessing {principal} {internships} and {habits} of {mind}: {the} {use} of {journey} {mapping} to {enhance} {reflection}},
	volume = {2},
% 	url = {https://nsuworks.nova.edu/innovate/vol2/iss4/4},
	number = {4},
	journal = {Innovate: Journal of Online Education},
	author = {Cooner, Donna and Dickmann, Ellyn},
	year = {2006},
	pages = {7},
}

@article{zimmerman_becoming_1997,
	title = {Becoming a {self}-{regulated} {writer}: {a} {social} {cognitive} {perspective}},
	volume = {22},
% 	issn = {0361-476X},
% 	url = {https://www.sciencedirect.com/science/article/pii/S0361476X9790919X},
	doi = {https://doi.org/10.1006/ceps.1997.0919},
	abstract = {Becoming an adept writer involves more than knowledge of vocabulary and grammar, it depends on high levels of personal regulation because writing activities are usually self-planned, self-initiated, and self-sustained. We present a social cognitive model of writing composed of three fundamental forms of self-regulation: environmental, behavioral, and covert or personal. Each of these triadic forms of self-regulation interact reciprocally via a cyclic feedback loop through which writers self-monitor and self-react to feedback about the effectiveness of specific self-regulatory techniques or processes. Well known writers’ personal descriptions of ten major self-regulatory techniques are recounted, and empirical studies demonstrating the effectiveness of these self-regulatory techniques are discussed. We conclude that writing self-regulation is a complex system of interdependent processes that are closely linked to an underlying sense of self-efficacy, and we discuss implications of the proposed model of self-regulatory processes and self-beliefs for guiding future research and developing innovative writing instruction.},
	number = {1},
	journal = {Contemporary Educational Psychology},
	author = {Zimmerman, Barry J. and Risemberg, Rafael},
	year = {1997},
	pages = {73--101},
}

@article{zimmerman_social_1989,
	title = {A {social} {cognitive} {view} of {self}-{regulated} {academic} {learning}},
	volume = {81},
	doi = {10.1037/0022-0663.81.3.329},
	journal = {Journal of Educational Psychology},
	author = {Zimmerman, Barry J.},
	month = sep,
	year = {1989},
	pages = {329--339},
}

@article{cukurova_students_2018,
	title = {Students’ knowledge acquisition and ability to apply knowledge into different science contexts in two different independent learning settings},
	volume = {36},
% 	issn = {0263-5143},
% 	url = {https://doi.org/10.1080/02635143.2017.1336709},
	doi = {10.1080/02635143.2017.1336709},
	number = {1},
	journal = {Research in Science \& Technological Education},
	author = {Cukurova, Mutlu and Bennett, Judith and Abrahams, Ian},
	month = jan,
	year = {2018},
	note = {Publisher: Routledge},
	pages = {17--34},
}

@book{mcintosh_action_2010,
	address = {London},
	title = {Action research and reflective practice : creative and visual methods to facilitate reflection and learning},
% 	isbn = {0-203-86011-X},
	publisher = {Routledge},
	author = {McIntosh, Paul},
	year = {2010},
	keywords = {Action research, Reflection (Philosophy)},
}

@inproceedings{shum_critical_2016,
	address = {Edinburgh, United Kingdom},
	title = {Critical perspectives on writing analytics},
% 	isbn = {978-1-4503-4190-5},
	doi = {10.1145/2883851.2883854},
% 	urldate = {2022-05-26},
% 	booktitle = {Proceedings of the {Sixth} {International} {Conference} on {Learning} {Analytics} \& {Knowledge} - {LAK} '16},
	booktitle = {{LAK16}: 6th {International} {Learning} {Analytics} and {Knowledge} {Conference}},
	publisher = {ACM Press},
	author = {Shum, Simon Buckingham and Knight, Simon and McNamara, Danielle and Allen, Laura and Bektik, Duygu and Crossley, Scott},
	year = {2016},
	pages = {481--483},

}


@inproceedings{oncel_automatic_2021,
	address = {Irvine CA USA},
	title = {Automatic {student} {writing} {evaluation}: {investigating} the {impact} of {individual} {differences} on {source}-{based} {writing}},
% 	isbn = {978-1-4503-8935-8},
	shorttitle = {Automatic {Student} {Writing} {Evaluation}},
% 	url = {https://dl.acm.org/doi/10.1145/3448139.3448207},
	doi = {10.1145/3448139.3448207},
	abstract = {Automated Writing Evaluation systems have been developed to help students improve their writing skills through the automated delivery of both summative and formative feedback. These systems have demonstrated strong potential in a variety of educational contexts; however, they remain limited in their personalization and scope. The purpose of the current study was to begin to address this gap by examining whether individual differences could be modeled in a source-based writing context. Undergraduate students (n=106) wrote essays in response to multiple sources and then completed an assessment of their vocabulary knowledge. Natural language processing tools were used to characterize the linguistic properties of the source-based essays at four levels: descriptive, lexical, syntax, and cohesion. Finally, machine learning models were used to predict students’ vocabulary scores from these linguistic features. The models accounted for approximately 29\% of the variance in vocabulary scores, suggesting that the linguistic features of source-based essays are reflective of individual differences in vocabulary knowledge. Overall, this work suggests that automated text analyses can help to understand the role of individual differences in the writing process, which may ultimately help to improve personalization in computer-based learning environments.},
% 	urldate = {2022-05-26},
	booktitle = {{LAK21}: 11th {International} {Learning} {Analytics} and {Knowledge} {Conference}},
	publisher = {ACM},
	author = {Öncel, Püren and Flynn, Lauren E. and Sonia, Allison N. and Barker, Kennis E. and Lindsay, Grace C. and McClure, Caleb M. and McNamara, Danielle S. and Allen, Laura K.},
	month = apr,
	year = {2021},
	pages = {620--625},
}

@article{bridgeman_design_2017,
	title = {Design and evaluation of automated writing evaluation models: {relationships} with writing in naturalistic settings},
	volume = {34},
% 	issn = {10752935},
	shorttitle = {Design and evaluation of automated writing evaluation models},
% 	url = {https://linkinghub.elsevier.com/retrieve/pii/S1075293517300399},
	doi = {10.1016/j.asw.2017.10.001},
	abstract = {Automated Writing Evaluation (AWE)systems are built by extracting features from a 30 min essay and using a statistical model that weights those features to optimally predict human scores on the 30 min essays. But the goal of AWE should be to predict performance in real world naturalistic tasks, not just to predict human scores on 30 min essays. Therefore, a more meaningful way of creating the feature weights in the AWE model is to select weights that are optimized to predict the real world criterion. This unique new approach was used in a sample of 194 graduate students who supplied two examples of their writing from required graduate school coursework. Contrary to results from a prior study predicting portfolio scores, the experimental model was no more eﬀective than the traditional model in predicting scores on actual writing done in graduate school. Importantly, when the new weights were evaluated in large samples of international students, the population subgroups that were advantaged or disadvantaged by the new weights were diﬀerent from the groups advantaged/disadvantaged by the traditional weights. It is critically important for any developer of AWE models to recognize that models that are equally eﬀective in predicting an external criterion may advantage/disadvantage diﬀerent groups.},
% 	urldate = {2022-05-26},
	journal = {Assessing Writing},
	author = {Bridgeman, Brent and Ramineni, Chaitanya},
	month = oct,
	year = {2017},
	pages = {62--71},
}

@inproceedings{kovanovic_understand_2018,
	address = {Sydney New South Wales Australia},
	title = {Understand students' self-reflections through learning analytics},
% 	isbn = {978-1-4503-6400-3},
% 	url = {https://dl.acm.org/doi/10.1145/3170358.3170374},
	doi = {10.1145/3170358.3170374},
	abstract = {Reflective writing has been widely recognized as one of the most effective activities for fostering students’ reflective and critical thinking. The analysis of students’ reflective writings has been the focus of many research studies. However, to date this has been typically a very labor-intensive manual process involving content analysis of student writings. With recent advancements in the field of learning analytics, there have been several attempts to use text analytics to examine student reflective writings. This paper presents the results of a study examining the use of theoretically-sound linguistic indicators of different psychological processes for the development of an analytics system for assessment of reflective writing. More precisely, we developed a random-forest classification system using linguistic indicators provided by the LIWC and Coh-Metrix tools. We also examined what particular indicators are representative of the different types of student reflective writings.},
% 	urldate = {2022-05-26},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Learning} {Analytics} and {Knowledge}},
	publisher = {ACM},
	author = {Kovanović, Vitomir and Joksimović, Srećko and Mirriahi, Negin and Blaine, Ellen and Gašević, Dragan and Siemens, George and Dawson, Shane},
	month = mar,
	year = {2018},
	pages = {389--398},
}

@inproceedings{winograd_detecting_2021,
	address = {Irvine CA USA},
	title = {Detecting {high} {orders} of {cognitive} {complexity} in {students}’ {reasoning} in {argumentative} {writing} {about} {ocean} {acidification}},
% 	isbn = {978-1-4503-8935-8},
% 	url = {https://dl.acm.org/doi/10.1145/3448139.3448202},
	doi = {10.1145/3448139.3448202},
	abstract = {Providing students in STEM courses the opportunity to write about scientific content can be beneficial to the learning process. However, it is a logistical challenge to provide feedback to students’ written work in large-enrollment courses. Motivated by these reasons, the study presented herein considers a method to identify the depth of students’ scientific reasoning in their written work. A writingto-learn (WTL) activity was implemented in a large undergraduate general chemistry class. An analytical framework of cognitive operations that characterizes students’ scientific reasoning evidenced in their writing was applied. Engagement in some of the more complex cognitive operations, such as causal reasoning and argumentation, was a sign that students were properly engaging in meaning making activities. This work considers a method to automate coaching of students in using more complex reasoning in their writing with the desired outcome that it may help students better engage with the science content. We consider a series of new natural language processing models to discern types of reasoning in student essays from the WTL activity.},
% 	urldate = {2022-05-26},
	booktitle = {{LAK21}: 11th {International} {Learning} {Analytics} and {Knowledge} {Conference}},
	publisher = {ACM},
	author = {Winograd, Blair A. and Dood, Amber J and Moeller, Robert and Moon, Alena and Gere, Anne and Shultz, Ginger},
	month = apr,
	year = {2021},
	pages = {586--591},
}

@inproceedings{shibani_constructing_2020,
	address = {Cham},
	title = {Constructing {automated} {revision} {graphs}: {a} {novel} {visualization} {technique} to {study} {student} {writing}},
% 	isbn = {978-3-030-52240-7},
	abstract = {This paper introduces a novel technique of constructing Automated Revision Graphs (ARG) to facilitate the study of revisions in writing. ARG plots sentences of a written text as nodes, and their similarities to sentences from its previous draft as edges to visualize text as graph. Implemented in two forms: simple and multi-stage, the graphs demonstrate how sentence-level differences can be visualized in short texts to study revision products, processes, and student interaction with feedback in student writing.},
	booktitle = {Artificial {Intelligence} in {Education}},
	publisher = {Springer International Publishing},
	author = {Shibani, Antonette},
	editor = {Bittencourt, Ig Ibert and Cukurova, Mutlu and Muldner, Kasia and Luckin, Rose and Millán, Eva},
	year = {2020},
	pages = {285--290},
}

@inproceedings{turkay_itero_2018,
	address = {Montreal QC Canada},
	title = {Itero: {a} {revision} {history} {analytics} {tool} for {exploring} {writing} {behavior} and {reflection}},
% 	isbn = {978-1-4503-5621-3},
	shorttitle = {Itero},
% 	url = {https://dl.acm.org/doi/10.1145/3170427.3188474},
	doi = {10.1145/3170427.3188474},
	abstract = {The overarching goals of this study are to better understand how monitoring the writing processes can be deeply integrated into writing practices using writing revision analytics and visualizations that may ultimately impact writing self-efficacy; and to examine the effects of a writing revision tool on users’ writing awareness during individual and collaborative writing. We developed Itero, a writing revision history analytics application that allows users to observe their writing behavior via visualizations and descriptive statistics. In this paper, we report findings from two pilot studies: one focused on user experiences during an individual writing task and the other during a collaborative writing task. Findings show evidence that Itero may increase users’ writing self-awareness and understanding of their collaboration structure, and warrants further investigation.},
% 	urldate = {2022-05-26},
	booktitle = {Extended {Abstracts} of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Türkay, Selen and Seaton, Daniel and Ang, Andrew M.},
	month = apr,
	year = {2018},
	pages = {1--6},
}

@inproceedings{gibson_reflective_2017,
	address = {Vancouver British Columbia Canada},
	title = {Reflective writing analytics for actionable feedback},
% 	isbn = {978-1-4503-4870-6},
% 	url = {https://dl.acm.org/doi/10.1145/3027385.3027436},
	doi = {10.1145/3027385.3027436},
	abstract = {Re ective writing can provide a powerful way for students to integrate professional experience and academic learning. However, writing re ectively requires high quality actionable feedback, which is time-consuming to provide at scale. is paper reports progress on the design, implementation, and validation of a Re ective Writing Analytics platform to provide actionable feedback within a tertiary authentic assessment context. e contributions are: (1) a new conceptual framework for re ective writing; (2) a computational approach to modelling re ective writing, deriving analytics, and providing feedback; (3) the pedagogical and user experience rationale for platform design decisions; and (4) a pilot in a student learning context, with preliminary data on educator and student acceptance, and the extent to which we can evidence that the so ware provided actionable feedback for re ective writing.},
% 	urldate = {2022-05-26},
	booktitle = {Proceedings of the {Seventh} {International} {Learning} {Analytics} \& {Knowledge} {Conference}},
	publisher = {ACM},
	author = {Gibson, Andrew and Aitken, Adam and Sándor, Ágnes and Buckingham Shum, Simon and Tsingos-Lucas, Cherie and Knight, Simon},
	month = mar,
	year = {2017},
	pages = {153--162},
}

@article{cotos_understanding_2020,
	title = {Understanding graduate writers’ interaction with and impact of the {research} {writing} {tutor} during revision},
	volume = {12},
% 	url = {https://www.jowr.org/index.php/jowr/article/view/577},
	doi = {10.17239/jowr-2020.12.01.07},
	abstract = {Teaching the craft of written science communication is an arduous task that requires familiarity with disciplinary writing conventions. With the burgeoning of technological advancements, practitioners preparing novice research writers can begin to augment teaching and learning with activities in digital writing environments attuned to the conventions of scientific writing in the disciplines. The Research Writing Tutor (RWT) is one such technology. Grounded in an integrative theoretical framework, it was designed to help students acquire knowledge about the research article genre and develop research writing competence. One of its modules was designed to facilitate revision by providing different forms of automated feedback and scaffolding that are genre-based and discipline-specific. This study explores whether and how the features of the RWT may impact revision while using this module of the tool. Drawing from cognitive writing modeling, this study investigates the behaviors of a multidisciplinary group of 11 graduate-student writers by exploring how they interacted with the RWT's features and how this interaction may create conditions for enhanced revision processes and text modifications. Findings demonstrate promising potential for the use of this automated feedback tool in fostering writers' metacognitive processing during revision. This research adds to theory on cognitive writing models by acknowledging the evolving role of digital environments in writing practices and offering insights into future development of automated tools for genre-based writing instruction.},
	number = {1},
% 	urldate = {2022-05-26},
	journal = {Journal of Writing Research},
	author = {Cotos, Elena and Huffman, Sarah and Link, Stephanie},
	month = jun,
	year = {2020},
% 	note = {Section: Articles},
	pages = {187--232},
}

@inproceedings{shibani_contextualizable_2019,
	address = {Tempe AZ USA},
	title = {Contextualizable {learning} {analytics} {design}: {a} {generic} {model} and {writing} {analytics} {evaluations}},
% 	isbn = {978-1-4503-6256-6},
	shorttitle = {Contextualizable {Learning} {Analytics} {Design}},
% 	url = {https://dl.acm.org/doi/10.1145/3303772.3303785},
	doi = {10.1145/3303772.3303785},
	abstract = {A major promise of learning analytics is that through the collection of large amounts of data we can derive insights from authentic learning environments, and impact many learners at scale. However, the context in which the learning occurs is important for educational innovations to impact student learning. In particular, for student-facing learning analytics systems like feedback tools to work effectively, they have to be integrated with pedagogical approaches and the learning design. This paper proposes a conceptual model to strike a balance between the concepts of generalizable scalable support and contextualized specific support by clarifying key elements that help to contextualize student-facing learning analytics tools. We demonstrate an implementation of the model using a writing analytics example, where the features, feedback and learning activities around the automated writing feedback tool are tuned for the pedagogical context and the assessment regime in hand, by co-designing them with the subject experts. The model can be employed for learning analytics to move from generalized support to meaningful contextualized support for enhancing learning.},
% 	urldate = {2022-05-26},
	booktitle = {Proceedings of the 9th {International} {Conference} on {Learning} {Analytics} \& {Knowledge}},
	publisher = {ACM},
	author = {Shibani, Antonette and Knight, Simon and Shum, Simon Buckingham},
	month = mar,
	year = {2019},
	pages = {210--219},
}

@article{wingate_impact_2010,
	title = {The impact of formative feedback on the development of academic writing},
	volume = {35},
% 	issn = {0260-2938},
% 	url = {https://doi.org/10.1080/02602930903512909},
	doi = {10.1080/02602930903512909},
	number = {5},
	journal = {Assessment \& Evaluation in Higher Education},
	author = {Wingate, Ursula},
	month = aug,
	year = {2010},
	publisher = {Routledge},
	note = {Publisher: Routledge},
	pages = {519--533},
}

@incollection{vytasek_analytics_2020,
	address = {Cham},
	title = {Analytics for {student} {engagement}},
% 	isbn = {978-3-030-13743-4},
% 	url = {https://doi.org/10.1007/978-3-030-13743-4_3},
	abstract = {Volumes of detailed information are now unobtrusively collected as students use learning management systems and digital learning environments in their studies. This significantly elevates opportunities to better understand how students learn. The learning analytics community is exploring these data to describe learning processes [117] and ground recommendations for improved learning environments [8, 102, 139]. One challenge in this work is need for more and more detailed information about each student’s learning processes to mine for developing useful and timely feedback for students and teachers [150]. Student engagement is a strong focus in this work. Research consistently shows positive relationships between engagement and academic success (e.g., [68, 111]). However, to construct learning analytics describing student engagement and recommending more productive forms of engagement, the field needs to better understand what student engagement means, how it can be observed online and quantified, and how it relates to learning processes and achievement. We review literatures describing student engagement and its relations to learning focusing on engagement in online and distance learning in postsecondary education. We catalog conceptualizations, measurement approaches and benefits of student engagement for learning and academic achievement. Through lenses of learning analytics and learning science, we map the evolution of analytics about student engagement and propose future research to bridge the learning analytics—learning science gap. We note challenges of tracking and supporting student engagement and recommend strategies that are predicted to facilitate positive long-term change.},
	booktitle = {Machine {Learning} {Paradigms}: {Advances} in {Learning} {Analytics}},
	publisher = {Springer International Publishing},
	author = {Vytasek, J. M. and Patzak, A. and Winne, P. H.},
	editor = {Virvou, Maria and Alepis, Efthimios and Tsihrintzis, George A. and Jain, Lakhmi C.},
	year = {2020},
	doi = {10.1007/978-3-030-13743-4_3},
	pages = {23--48},
}

@article{plak_raising_2022,
	title = {Raising {student} {engagement} using {digital} {nudges} {tailored} to {students}’ {motivation} and {perceived} {ability} {levels}},
	journal = {British Journal of Educational Technology},
	author = {Plak, Simone and Klaveran, Chris van and Cornelisz, Illja},
	year = {2022},
	note    = {in press},
}


@Inproceedings{iraj_understanding_2020,
	address = {Frankfurt Germany},
	title = {Understanding students' engagement with personalised feedback messages},
% 	isbn = {978-1-4503-7712-6},
% 	url = {https://dl.acm.org/doi/10.1145/3375462.3375527},
	doi = {10.1145/3375462.3375527},
	abstract = {Feedback is a major factor of student success within higher education learning. However, recent changes – such as increased class sizes and socio-economic diversity of the student population – challenged the provision of effective student feedback. Although the use of educational technology for personalised feedback to diverse students has gained traction, the feedback gap still exists: educators wonder which students respond to feedback and which do not. In this study, a set of trackable Call to Action (CTA) links was embedded in two sets of feedback messages focusing on students’ time management, with the goal of (1) examining the association between feedback engagement and course success and (2), to predict students’ reaction to provided feedback. We also conducted two focus groups to further examine students’ perception of provided feedback messages. Our results revealed that early engagement with the feedback was associated with higher chances of succeeding in the course. Likewise, previous engagement with feedback was highly predictive of students’ engagement in the future, and also that certain student sub-populations, (e.g., female students), were more likely to engage than others. Such insight enables instructors to ask “why” questions, improve feedback processes and narrow the feedback gap. Practical implications of our findings are further discussed.},
% 	urldate = {2022-05-26},
	booktitle = {Proceedings of the {Tenth} {International} {Conference} on {Learning} {Analytics} \& {Knowledge}},
	publisher = {ACM},
	author = {Iraj, Hamideh and Fudge, Anthea and Faulkner, Margaret and Pardo, Abelardo and Kovanović, Vitomir},
	month = mar,
	year = {2020},
	pages = {438--447},
}

@article{nelson_good_2012,
	title = {Good practice for enhancing the engagement and success of commencing students},
	volume = {63},
% 	issn = {0018-1560, 1573-174X},
% 	url = {http://link.springer.com/10.1007/s10734-011-9426-y},
	doi = {10.1007/s10734-011-9426-y},
	abstract = {There is widespread recognition that higher education institutions (HEIs) must actively support commencing students to ensure equity in access to the opportunities afforded by higher education. This role is particularly critical for students who because of educational, cultural or ﬁnancial disadvantage or because they are members of social groups currently under-represented in higher education, may require additional transitional support to ‘‘level the playing ﬁeld.’’ The challenge faced by HEIs is to provide this ‘‘support’’ in a way that is integrated into regular teaching and learning practices and reaches all commencing students. The Student Success Program (SSP) is an intervention in operation at the Queensland University of Technology (QUT) designed to identify and support those students deemed to be at risk of disengaging from their learning and their institution. Two sets of evidence of the impact of the SSP are presented: First, its expansion (a) from a one-faculty pilot project (Nelson et al. in Stud Learn Eval Innov Dev 6:1–15, 2009) to all faculties and (b) into a variety of applications mirroring the student life cycle; and second, an evaluation of the impact of the SSP on students exposed to it. The outcomes suggest that: the SSP is an example of good practice that can be successfully applied to a variety of learning contexts and student enrolment situations; and the impact of the intervention on student persistence is sustained for at least 12 months and positively inﬂuences student retention. It is claimed that the good practice evidenced by the SSP is dependent on its integration into the broader First Year Experience Program at QUT as an example of transition pedagogy in action.},
	number = {1},
% 	urldate = {2022-05-26},
	journal = {Higher Education},
	author = {Nelson, Karen J. and Quinn, Carole and Marrington, Andrew and Clarke, John A.},
	month = jan,
	year = {2012},
	pages = {83--96},
}

@article{hattie_power_2007,
	title = {The {power} of {feedback}},
	volume = {77},
% 	issn = {0034-6543, 1935-1046},
% 	url = {http://journals.sagepub.com/doi/10.3102/003465430298487},
	doi = {10.3102/003465430298487},
	abstract = {Feedback is one of the most powerful influences on learning and achievement, but this impact can be either positive or negative. Its power is frequently mentioned in articles about learning and teaching, but surprisingly few recent studies have systematically investigated its meaning. This article provides a conceptual analysis of feedback and reviews the evidence related to its impact on learning and achievement. This evidence shows that although feedback is among the major influences, the type of feedback and the way it is given can be differentially effective. A model of feedback is then proposed that identifies the particular properties and circumstances that make it effective, and some typically thorny issues are discussed, including the timing of feedback and the effects of positive and negative feedback. Finally, this analysis is used to suggest ways in which feedback can be used to enhance its effectiveness in classrooms.},
	number = {1},
% 	urldate = {2022-05-26},
	journal = {Review of Educational Research},
	author = {Hattie, John and Timperley, Helen},
	month = mar,
	year = {2007},
	pages = {81--112},
}

@inproceedings{macqueen_methods_1967,
	title = {Some methods for classification and analysis of multivariate observations},
	volume = {1},
	booktitle = {Proceedings of the fifth {Berkeley} symposium on mathematical statistics and probability},
	author = {MacQueen, J.},
	year = {1967},
	pages = {281--197},
}

@book{shin_time_2017,
	address = {Berkeley, CA},
	title = {Time series analysis in the social sciences : the fundamentals},
% 	isbn = {0-520-96638-4},
	abstract = {Times Series Analysis in the Social Sciences is a practical and highly readable introduction written exclusively for students and researchers whose mathematical background is limited to basic algebra. The book focuses on fundamental elements of time series analysis that social scientists need to understand so they can employ time series analysis for their research and practice. Through step-by-step explanations and using monthly violent crime rates as case studies, this book explains univariate time series from the preliminary visual analysis through the modeling of seasonality, trends, and residuals, to the evaluation and prediction of estimated models. The book also explains smoothing, multiple time series analysis, and interrupted time series analysis. With a wealth of practical advice and supplemental data sets wherein students can apply their knowledge, this flexible and friendly primer is suitable for all students in the social sciences.},
	publisher = {University of California Press},
	author = {Shin, Youseop},
	year = {2017},
	doi = {10.1525/9780520966383},
	keywords = {Electronic books, Social sciences -- Statistical methods, Time-series analysis},
}

@book{hyndman_forecasting_2018,
	address = {Melbourne, Australia},
	edition = {2nd},
	title = {Forecasting: principles and practice},
	url = {OTexts.com/fpp2},
	publisher = {OTexts},
	author = {Hyndman, Rob J. and Athanasopoulos, George},
	year = {2018},
}

@article{fredricks_school_2004,
	title = {School {engagement}: {potential} of the {concept}, {state} of the {evidence}},
	volume = {74},
% 	issn = {0034-6543},
% 	url = {https://doi.org/10.3102/00346543074001059},
	doi = {10.3102/00346543074001059},
	abstract = {The concept of school engagement has attracted increasing attention as representing a possible antidote to declining academic motivation and achievement. Engagement is presumed to be malleable, responsive to contextual features, and amenable to environmental change. Researchers describe behavioral, emotional, and cognitive engagement and recommend studying engagement as a multifaceted construct. This article reviews definitions, measures, precursors, and outcomes of engagement; discusses limitations in the existing research; and suggests improvements. The authors conclude that, although much has been learned, the potential contribution of the concept of school engagement to research on student experience has yet to be realized. They call for richer characterizations of how students behave, feel, and think?research that could aid in the development of finely tuned interventions},
	number = {1},
% 	urldate = {2022-05-26},
	journal = {Review of Educational Research},
	author = {Fredricks, Jennifer A and Blumenfeld, Phyllis C and Paris, Alison H},
	month = mar,
	year = {2004},
	note = {Publisher: American Educational Research Association},
	pages = {59--109},
}

@article{yip_learning_2012,
	title = {Learning strategies and self-efficacy as predictors of academic performance: a preliminary study},
	volume = {18},
% 	issn = {1353-8322},
% 	url = {https://doi.org/10.1080/13538322.2012.667263},
	doi = {10.1080/13538322.2012.667263},
	number = {1},
	journal = {Quality in Higher Education},
	author = {Yip, Michael C.W.},
	month = apr,
	year = {2012},
	note = {Publisher: Routledge},
	pages = {23--34},
}

@article{mitchell_exploration_2019,
	title = {An {exploration} of {writing} {self}-{efficacy} and {writing} {self}-{regulatory} {behaviours} in {undergraduate} {writing}},
	volume = {10},
% 	url = {https://ojs.lib.uwo.ca/index.php/cjsotl_rcacea/article/view/8175},
	doi = {10.5206/cjsotl-rcacea.2019.2.8175},
	abstract = {\&lt;p\&gt;Students will take independent action to improve their writing when they believe those actions will have a positive effect. The data presented focuses on the self-regulatory writing behaviours of nursing students in their third year. The purpose was to explore patterns of writing self-efficacy, anxiety levels, and student grade point average (GPA) in relation to student choices with help seeking, advanced planning of writing, revision habits, and response to feedback. Low writing self-efficacy, high anxiety students sought help from more sources, reported their feedback made them feel negative about their capabilities as writers, and were less likely to report reading and applying feedback to future writing efforts. No patterns of writing self-efficacy or anxiety levels emerged with respect to student revision habits or their choice to begin their assignments in advance of the due date. GPA was also not associated with the writing self-regulatory choices assessed. As the primary writing support for students in the later years of a nursing program, educators should consider interventions that encourage help seeking, facilitate students’ understanding and integration of the feedback they receive into their assignment revisions, and normalize the negative emotions that interfere with the self-efficacy levels required to write well.\&lt;/p\&gt;},
	number = {2},
% 	urldate = {2022-05-26},
	journal = {The Canadian Journal for the Scholarship of Teaching and Learning},
	author = {Mitchell, Kim M. and McMillan, Diana E. and Rabbani, Rasheda},
	month = aug,
	year = {2019},
% 	note = {Section: Research Papers},
}

@article{sobel_spacing_2011,
	title = {Spacing effects in real-world classroom vocabulary learning},
	volume = {25},
% 	issn = {08884080},
% 	url = {https://onlinelibrary.wiley.com/doi/10.1002/acp.1747},
	doi = {10.1002/acp.1747},
	abstract = {As a primary goal, educators often strive to maximize the amount of information pupils remember. In the lab, psychologists have found efﬁcient memory strategies for retaining school-related materials. One such strategy is the spacing effect, a memory advantage that occurs when learning is distributed across time instead of crammed into a single study session. Spaced learning is not often explicitly utilized in actual classrooms, perhaps due to a paucity of research in applied settings and with school-aged children. The current study examined the spacing effect in real-world ﬁfth-grade classrooms. We taught 39 children unfamiliar English words using both massed and spaced learning. Five weeks later, we tested vocabulary recall. One-week spacing produced superior long-term retention compared to massed learning. This ﬁnding demonstrates that the spacing effect can be generalized to vocabulary learning in applied settings and middle-school-aged children. Copyright \# 2010 John Wiley \& Sons, Ltd.},
	number = {5},
% 	urldate = {2022-05-26},
	journal = {Applied Cognitive Psychology},
	author = {Sobel, Hailey S. and Cepeda, Nicholas J. and Kapler, Irina V.},
	month = sep,
	year = {2011},
	pages = {763--767},
}

@article{rohrer_effects_2006,
	title = {The effects of overlearning and distributed practise on the retention of mathematics knowledge},
	volume = {20},
% 	issn = {08884080, 10990720},
% 	url = {https://onlinelibrary.wiley.com/doi/10.1002/acp.1266},
	doi = {10.1002/acp.1266},
	abstract = {In two experiments, 216 college students learned to solve one kind of mathematics problem before completing one of various practise schedules. In Experiment 1, students either massed 10 problems in a single session or distributed these 10 problems across two sessions separated by 1 week. The beneﬁt of distributed practise was nil among students who were tested 1 week later but extremely large among students tested 4 weeks later. In Experiment 2, students completed three or nine practise problems in one session. The additional six problems constituted a strategy known as overlearning, but this extra effort had no effect on test scores 1 or 4 weeks later. Thus, long-term retention was boosted by distributed practise and unaffected by overlearning. Unfortunately, most mathematics textbooks rely on a format that emphasises overlearning and minimises distributed practise. An easily adopted alternative format is advocated. Copyright \# 2006 John Wiley \& Sons, Ltd.},
	number = {9},
% 	urldate = {2022-05-26},
	journal = {Applied Cognitive Psychology},
	author = {Rohrer, Doug and Taylor, Kelli},
	month = dec,
	year = {2006},
	pages = {1209--1224},
}

@article{rohrer_interleaving_2012,
	title = {Interleaving {helps} {students} {distinguish} among {similar} {concepts}},
	volume = {24},
% 	issn = {1040726X, 1573336X},
% 	url = {http://www.jstor.org/stable/43546796},
	abstract = {[When students encounter a set of concepts (or terms or principles) that are similar in some way, they often confuse one with another. For instance, they might mistake one word for another word with a similar spelling (e.g., allusion instead of illusion) or choose the wrong strategy for a mathematics problem because it resembles a different kind of problem. By one proposition explored in this review, these kinds of errors occur more frequently when all exposures to one of the concepts are grouped together. For instance, in most middle school science texts, the questions in each assignment are devoted to the same concept, and this blocking of exposures ensures that students need not learn to distinguish between two similar concepts. In an alternative approach described in this review, exposures to each concept are interleaved with exposures to other concepts, so that a question on one concept is followed by a question on a different concept. In a number of experiments that have compared interleaving and blocking, interleaving produced better scores on final tests of learning. The evidence is limited, though, and ecologically valid studies are needed. Still, a prudent reading of the data suggests that at least a portion of the exposures should be interleaved.]},
	number = {3},
% 	urldate = {2022-05-26},
	journal = {Educational Psychology Review},
	author = {Rohrer, Doug},
	year = {2012},
	note = {Publisher: Springer},
	pages = {355--367},
}

@incollection{carpenter_spacing_2014,
	address = {Washington,  DC,  US},
	title = {Spacing and interleaving of study and practice.},
% 	isbn = {978-1-941804-29-2 (PDF)},
	abstract = {Learning requires repetition. Whether conjugating verbs in a foreign language, applying a mathematical formula, or learning to pitch a softball, a particular concept or skill must be practiced multiple times before it is fully mastered. It seems rather intuitive that learning benefits from repetition, however, what is less intuitive is how these repetitions should be scheduled. When learning a new concept, should students study that concept again immediately? Or should they wait a while and study it again later? A related question concerns how to schedule repetitions of similar concepts within a subject. When students learn about fractions, for example, should they practice one type of fractions problem over and over (e.g., how to add fractions) before moving on to a different type of problem (e.g., how to multiply fractions)? Or, would they learn the information better by practicing both types of problems together? Students and instructors are faced with these decisions on a daily basis. Research on human cognition has shown that learning can be significantly affected by the way in which repetitions are scheduled. This research can help inform the decisions that students must make concerning when to study information in order to maximize learning. This chapter describes relevant research and offers pedagogical recommendations regarding two specific learning principles—the spacing effect and the interleaving effect. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	booktitle = {Applying science of learning in education: {Infusing} psychological science into the curriculum.},
	publisher = {Society for the Teaching of Psychology},
	author = {Carpenter, Shana K.},
	year = {2014},
	keywords = {*Cognitive Processes, *Learning, *Learning Schedules, *Practice, Study Habits},
	pages = {131--141},
}

@incollection{graham_role_1994,
	title = {The role and development of self-regulation in the writing process},
	booktitle = {Self-regulation of learning and performance: {Issues} and educational applications},
	publisher = {Lawrence Erlbaum Associates, Inc.},
	author = {Graham, Steve and Harris, Karen R.},
	editor = {Schunk, Dale H and Zimmerman, Barry J},
	year = {1994},
	volume  = {1}, 
	pages = {203--228},
	address = {Hillsdale NJ}

}


@article{neto_automatic_2021,
	title = {Automatic {content} {analysis} of {online} {discussions} for {cognitive} {presence}: {a} {study} of the {generalizability} {across} {educational} {contexts}},
	volume = {14},
	doi = {10.1109/TLT.2021.3083178},
	number = {3},
	journal = {IEEE Transactions on Learning Technologies},
	author = {Neto, Valter and Rolim, Vitor and Pinheiro, Anderson and Lins, Rafael Dueire and Gašević, Dragan and Mello, Rafael Ferreira},
	year = {2021},
	pages = {299--312},
}


@inproceedings{crossley_automated_2019,
	address = {Cham},
	title = {Automated {summarization} {evaluation} ({ASE}) {using} {natural} {language} {processing} {tools}},
% 	isbn = {978-3-030-23204-7},
	abstract = {Summarization is an effective strategy to promote and enhance learning and deep comprehension of texts. However, summarization is seldom implemented by teachers in classrooms because the manual evaluation of students’ summaries requires time and effort. This problem has led to the development of automated models of summarization quality. However, these models often rely on features derived from expert ratings of student summarizations of specific source texts and are therefore not generalizable to summarizations of new texts. Further, many of the models rely of proprietary tools that are not freely or publicly available, rendering replications difficult. In this study, we introduce an automated summarization evaluation (ASE) model that depends strictly on features of the source text or the summary, allowing for a purely text-based model of quality. This model effectively classifies summaries as either low or high quality with an accuracy above 80\%. Importantly, the model was developed on a large number of source texts allowing for generalizability across texts. Further, the features used in this study are freely and publicly available affording replication.},
	booktitle = {Artificial {Intelligence} in {Education}},
	publisher = {Springer International Publishing},
	author = {Crossley, Scott A. and Kim, Minkyung and Allen, Laura and McNamara, Danielle},
	editor = {Isotani, Seiji and Millán, Eva and Ogan, Amy and Hastings, Peter and McLaren, Bruce and Luckin, Rose},
	year = {2019},
	pages = {84--95},
}
@article{cukurova2019artificial,
  title={Artificial intelligence and multimodal data in the service of human decision-making: A case study in debate tutoring},
  author={Cukurova, Mutlu and Kent, Carmel and Luckin, Rosemary},
  journal={British Journal of Educational Technology},
  volume={50},
  number={6},
  pages={3032--3046},
  year={2019},
  publisher={Wiley Online Library}
}


@inproceedings{bodily_trends_2017,
	address = {Vancouver British Columbia Canada},
	title = {Trends and issues in student-facing learning analytics reporting systems research},
	% isbn = {978-1-4503-4870-6},
	% url = {https://dl.acm.org/doi/10.1145/3027385.3027403},
	doi = {10.1145/3027385.3027403},
	abstract = {We conducted a literature review on systems that track learning analytics data (e.g., resource use, time spent, assessment data, etc.) and provide a report back to students in the form of visualizations, feedback, or recommendations. This review included a rigorous article search process; 945 articles were identified in the initial search. After filtering out articles that did not meet the inclusion criteria, 94 articles were included in the final analysis. Articles were coded on five categories chosen based on previous work done in this area: functionality, data sources, design analysis, perceived effects, and actual effects. The purpose of this review is to identify trends in the current studentfacing learning analytics reporting system literature and provide recommendations for learning analytics researchers and practitioners for future work.},
	% urldate = {2022-07-08},
	booktitle = {Proceedings of the {Seventh} {International} {Learning} {Analytics} \& {Knowledge} {Conference}},
	publisher = {ACM},
	author = {Bodily, Robert and Verbert, Katrien},
	month = mar,
	year = {2017},
	pages = {309--318},
}

@article{sadler_beyond_2010,
	title = {Beyond feedback: developing student capability in complex appraisal},
	volume = {35},
	% issn = {0260-2938},
	% url = {https://doi.org/10.1080/02602930903541015},
	doi = {10.1080/02602930903541015},
	number = {5},
	journal = {Assessment \& Evaluation in Higher Education},
	author = {Sadler, D. Royce},
	month = aug,
	year = {2010},
	note = {Publisher: Routledge},
	pages = {535--550},
}

@article{torres_reflection_2020,
	title = {Reflection through assessment: {A} systematic narrative review of teacher feedback and student self-perception},
	volume = {64},
	% issn = {0191491X},
	shorttitle = {Reflection through assessment},
	% url = {https://linkinghub.elsevier.com/retrieve/pii/S0191491X19300306},
	doi = {10.1016/j.stueduc.2019.100814},
	abstract = {Beginning with two important meta-analyses by Hattie and Timperley (2007) and Shute (2008), the relationship between teacher feedback and student self-perception has received more attention. One way students enact a self-perception is by reﬂectively writing about their participation within a particular ﬁeld of study. The current review analyzes how teacher feedback facilitates and supports the formation of self-perception made visible in students’ reﬂective writing. The following electronic databases were searched up to February 2018: CINAHL, Academic Search Complete, PsycINFO, ERIC, ProQuest Dissertations and Theses, and Google Scholar. Five themes in total were constructed. These themes indicate contexts when feedback might lead to students reﬂecting through writing on a self-perception. Features of feedback that most likely promote this kind of reﬂection can be described as: content situated, dialogic, and empathic. As a secondary category of themes, feedback should position students as: ﬂuid and/or vulnerable.},
	urldate = {2022-07-24},
	journal = {Studies in Educational Evaluation},
	author = {Torres, J.T. and Higheagle Strong, Zoe and Adesope, Olusola O.},
	month = mar,
	year = {2020},
	pages = {100814},
}

@article{rozental_medical_2021,
	title = {Medical students' experiences and needs from written reflective journal feedback},
	volume = {55},
	% issn = {0308-0110, 1365-2923},
	% url = {https://onlinelibrary.wiley.com/doi/10.1111/medu.14406},
	doi = {10.1111/medu.14406},
	abstract = {Introduction: Reflective ability is an important skill for enhancing professionalism and developing communication skills. To improve reflective ability, medical educators encourage use of written reflective journals, for which feedback is important. It is difficult for educators to anticipate how their feedback will be perceived. Therefore, this study examined students' experiences with educators' written feedback on reflective journals.
Methods: A qualitative, immersion/crystallization analysis of 60 written feedback texts to 15 medical students (30 identified by students as meaningful and 30 as less meaningful) and in-depth semi-structured interviews with these students. We did not define ‘meaningful’, to leave room for students' own interpretations. We analysed the feedback to identify what it includes (its components) and analysed the interviews to learn about students' experiences of receiving the feedback and the specific components.
Results: Students experienced five components as meaningful: supportive and encouraging statements; legitimisation of their emotions; educators sharing personalprofessional experiences; asking questions to enhance reflection; and focusing on the students' main concern. These components enhanced students' willingness to read and learn from the feedback. Three components were experienced as less meaningful: detached, impersonal feedback; negative tone (criticism); and technical issues, for example brevity. These disappointing and hurtful components led students to pay less attention to the feedback or to invest less effort in future written assignments.
Conclusions: The present study identified components in written reflective journal feedback texts and the experience and needs of students who received them. It showed the complexity of writing reflective feedback because of the need to support students through it, help them deal with emotions, identify and focus on personal content that matters to them, and provide opportunities to develop and enhance their reflective ability, while being mindful of their emotional state. To help educators in this challenging task, a self-assessment mnemonic (‘FEEDBACK’) for use before sending the initial feedback was developed.},
	number = {4},
	% urldate = {2022-07-24},
	journal = {Medical Education},
	author = {Rozental, Lior and Meitar, Dafna and Karnieli‐Miller, Orit},
	month = apr,
	year = {2021},
	pages = {505--517},
}

@article{dekker_which_2013,
	title = {Which characteristics of written feedback are perceived as stimulating students’ reflective competence: an exploratory study},
	volume = {13},
	% issn = {1472-6920},
	shorttitle = {Which characteristics of written feedback are perceived as stimulating students’ reflective competence},
	% url = {https://bmcmededuc.biomedcentral.com/articles/10.1186/1472-6920-13-94},
	doi = {10.1186/1472-6920-13-94},
	abstract = {Background: Teacher feedback on student reflective writing is recommended to improve learners’ reflective competence. To be able to improve teacher feedback on reflective writing, it is essential to gain insight into which characteristics of written feedback stimulate students’ reflection processes. Therefore, we investigated (1) which characteristics can be distinguished in written feedback comments on reflective writing and (2) which of these characteristics are perceived to stimulate students’ reflection processes.
Methods: We investigated written feedback comments from forty-three teachers on their students’ reflective essays. In Study 1, twenty-three medical educators grouped the comments into distinct categories. We used Multiple Correspondence Analysis to determine dimensions in the set of comments. In Study 2, another group of twenty-one medical educators individually judged whether the comments stimulated reflection by rating them on a five-point scale. We used t-tests to investigate whether comments classified as stimulating and not stimulating reflection differed in their scores on the dimensions.
Results: Our results showed that characteristics of written feedback comments can be described in three dimensions: format of the feedback (phrased as statement versus question), focus of the feedback (related to the levels of students’ reflections) and tone of the feedback (positive versus negative). Furthermore, comments phrased as a question and in a positive tone were judged as stimulating reflection more than comments at the opposite side of those dimensions (t = (14.5) = 6.48; p = {\textless} .001 and t = (15) = −1.80; p {\textless} .10 respectively). The effect sizes were large for format of the feedback comment (r = .86) and medium for tone of the feedback comment (r = .42).
Conclusions: This study suggests that written feedback comments on students’ reflective essays should be formulated as a question, positive in tone and tailored to the individual student’s reflective level in order to stimulate students to reflect on a slightly higher level. Further research is needed to examine whether incorporating these characteristics into teacher training helps to improve the quality of written feedback comments on reflective writing.},
	number = {1},
	% urldate = {2022-07-24},
	journal = {BMC Medical Education},
	author = {Dekker, Hanke and Schönrock-Adema, Johanna and Snoek, Jos W and van der Molen, Thys and Cohen-Schotanus, Janke},
	month = dec,
	year = {2013},
	pages = {94},
}


@article{stern_effective_2006,
	title = {Effective faculty feedback: {The} road less traveled},
	volume = {11},
	% issn = {10752935},
	shorttitle = {Effective faculty feedback},
	% url = {https://linkinghub.elsevier.com/retrieve/pii/S1075293505000656},
	doi = {10.1016/j.asw.2005.12.001},
	abstract = {Grading papers may be one of the most stressful, most time consuming, and least rewarding activities in which professors engage. Although effective grading techniques for papers have been widely researched, especially within the “Writing” or “English” scholarly arenas, has this information been put into practice? The goals of this paper are two-fold: (1) to replicate and extend Connor and Lunsford’s [Connors, R. J., \& Lunsford, A. A. (1993). Teachers’ rhetorical comments on student papers. College Composition and Communication, 44, 200–223] analysis of faculty comments, and (2) to review some of the tips for effective grading practices and see if the comments reﬂected these effective practice advice. A content analysis was conducted on faculty comments from 598 graded papers written for hundreds of courses from 30 different departments in the university. Results indicate that most comments were technical corrections that addressed spelling, grammar, word choice, and missing words. Macro- and mid-level comments that addressed paper organization and quality of the ideas contained in it were surprisingly absent. The lack of these larger idea and argument centered comments may prevent students from improving the quality of the larger issues in writing and refocus them on the smaller, albeit important, technical issues of writing.},
	number = {1},
	urldate = {2022-07-24},
	journal = {Assessing Writing},
	author = {Stern, Lesa A. and Solomon, Amanda},
	month = jan,
	year = {2006},
	pages = {22--41},
}

@article{bain_developing_2002,
	title = {Developing {Reflection} on {Practice} {Through} {Journal} {Writing}: {Impacts} of variations in the focus and level of feedback},
	volume = {8},
	% issn = {1354-0602, 1470-1278},
	shorttitle = {Developing {Reflection} on {Practice} {Through} {Journal} {Writing}},
	% url = {https://www.tandfonline.com/doi/full/10.1080/13540600220127368},
	doi = {10.1080/13540600220127368},
	abstract = {Journal writing is a popular technique for encouraging student-teachers to re¯ ect on their professional practice during ® eld experience placements. This paper explores the role and importance of journal feedback in developing students’ re¯ ective skills. Weekly journal entries were submitted by 35 student-teachers during a 6-week ® eld placement. Students received individual feedback on each journal entry that focused on either the level of re¯ ection attained in their writing or the particular issues that their entries addressed. Within these groups, the type of feedback provided was further varied according to the level of questioning and challenge with which students were confronted (high versus low). The relative effectiveness of the four different types of feedback in improving student journal writing and facilitating re¯ ection on practice is examined. Although students in all conditions reported positive aspects of the feedback they received, feedback that focused on the level of re¯ ection attained was more effective in bringing about improvement in journal writing than feedback that focused on teaching issues. Such feedback, combined with issue-related questions and comments designed to challenge the student and encourage consideration of alternative perspectives, would appear to offer the most effective strategy for enhancing the effectiveness of journal writing as a learning tool.},
	language = {en},
	number = {2},
	% urldate = {2022-07-24},
	journal = {Teachers and Teaching},
	author = {Bain, John D. and Mills, Colleen and Ballantyne, Roy and Packer, Jan},
	month = may,
	year = {2002},
	pages = {171--196},
}

@article{page_teacher_1958,
	title = {Teacher comments and student performance: {A} seventy-four classroom experiment in school motivation.},
	volume = {49},
	% issn = {1939-2176(Electronic),0022-0663(Print)},
	doi = {10.1037/h0041940},
	abstract = {2139 high school students took an objective exam as it occurred in the usual course of instruction. The papers were divided into 3 groups: the No Comment group receiving only a letter grade; the Specified Comment group—general encouraging comments predesignated for each letter grade; and the Free Comment group—whatever the teacher felt appropriate. On the next objective test given: (a) both comment groups scored significantly higher than the students receiving no comments, (b) there were no significant differences in comment effect between 12 schools, (c) there were no conclusive differences between grade levels, and (d) there were no significant differences between the better and the poorer students in their response to comments. From Psyc Abstracts 36:02:2KB73P. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {4},
	journal = {Journal of Educational Psychology},
	author = {Page, Ellis Batten},
	year = {1958},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {*Academic Achievement, *Motivation, *Teaching, Classrooms, High School Students, Teachers},
	pages = {173--181},
}

@article{aronson_comparison_2012,
	title = {A comparison of two methods of teaching reflective ability in {Year} 3 medical students: {Comparison} of teaching methods for reflection},
	volume = {46},
	% issn = {03080110},
	shorttitle = {A comparison of two methods of teaching reflective ability in {Year} 3 medical students},
	% url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1365-2923.2012.04299.x},
	doi = {10.1111/j.1365-2923.2012.04299.x},
	language = {en},
	number = {8},
	% urldate = {2022-07-24},
	journal = {Medical Education},
	author = {Aronson, Louise and Niehaus, Brian and Hill-Sakurai, Laura and Lai, Cindy and O’Sullivan, Patricia S.},
	month = aug,
	year = {2012},
	pages = {807--814},
}

@article{stewart_teacher_1976,
	title = {Teacher comments, letter grades, and student performance: {What} do we really know?},
	volume = {68},
	% issn = {1939-2176(Electronic),0022-0663(Print)},
	doi = {10.1037/0022-0663.68.4.488},
	abstract = {Attempted to replicate E. B. Page's (1958) major finding of written comment effectiveness. 415 5th and 7th graders in 17 mathematics and spelling classes were evaluated by their teachers for 6 wks with experimentally determined combinations of letter grades and comments. Immediate and long-term treatment effects were judged by objective test performance following a mean of 1.6 and 4.1 evaluations, respectively. Results from a Friedman analysis of variance indicated no significant main effects. Data from 12 other replication studies were examined. Results of the L test of ordered hypotheses indicates no significant amount of agreement between Page's major finding and the general order of experimental results of the replication studies. Implications for classroom teachers are discussed. (31 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {4},
	journal = {Journal of Educational Psychology},
	author = {Stewart, Linda G. and White, Mary A.},
	year = {1976},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {*Academic Achievement, *Elementary School Students, *Experimental Replication, *Grading (Educational), Junior High School Students},
	pages = {488--500},
}

@article{wald_reflecting_2009,
	title = {Reflecting on {Reflections}: {Enhancement} of {Medical} {Education} {Curriculum} {With} {Structured} {Field} {Notes} and {Guided} {Feedback}},
	volume = {84},
	% issn = {1040-2446},
	% url = {https://journals.lww.com/academicmedicine/Fulltext/2009/07000/Reflecting_on_Reflections__Enhancement_of_Medical.9.aspx},
	abstract = {The promotion of reflective capacity within the teaching of clinical skills and professionalism is posited as fostering the development of competent health practitioners. An innovative approach combines structured reflective writing by medical students and individualized faculty feedback to those students to augment instruction on reflective practice. A course for preclinical students at the Warren Alpert Medical School of Brown University, entitled “Doctoring,” combined reflective writing assignments (field notes) with instruction in clinical skills and professionalism and early clinical exposure in a small-group format. Students generated multiple e-mail field notes in response to structured questions on course topics. Individualized feedback from a physician–behavioral scientist dyad supported the students’ reflective process by fostering critical-thinking skills, highlighting appreciation of the affective domain, and providing concrete recommendations. The development and implementation of this innovation are presented, as is an analysis of the written evaluative comments of students taking the Doctoring course. Theoretical and clinical rationales for features of the innovation and supporting evidence of their effectiveness are presented. Qualitative analyses of students’ evaluations yielded four themes of beneficial contributions to their learning experience: promoting deeper and more purposeful reflection, the value of (interdisciplinary) feedback, the enhancement of group process, and personal and professional development. Evaluation of the innovation was the fifth theme; some limitations are described, and suggestions for improvement are provided. Issues of the quality of the educational paradigm, generalizability, and sustainability are addressed.},
	number = {7},
	journal = {Academic Medicine},
	author = {Wald, Hedy S. and Davis, Stephen W. and Reis, Shmuel P. and Monroe, Alicia D. and Borkan, Jeffrey M.},
	year = {2009},
}

@inproceedings{jivet2021quantum,
  title={Quantum of Choice: How learners’ feedback monitoring decisions, goals and self-regulated learning skills are related},
  author={Jivet, Ioana and Wong, Jacqueline and Scheffel, Maren and Valle Torre, Manuel and Specht, Marcus and Drachsler, Hendrik},
  booktitle={LAK21: 11th international learning analytics and knowledge conference},
  pages={416--427},
  year={2021}
}

@book{luckin2018machine,
  title={Machine Learning and Human Intelligence: The future of education for the 21st century.},
  author={Luckin, Rosemary},
  year={2018},
  publisher={ERIC}
}

@inproceedings{cukurova2019learning,
  title={Learning analytics as AI extenders in education: Multimodal machine learning versus multimodal learning analytics},
  author={Cukurova, Mutlu},
  booktitle={Artificial intelligence and adaptive education},
  volume={2019},
  year={2019},
  organization={AIAED}
}