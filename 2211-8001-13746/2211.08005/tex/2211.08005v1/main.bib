
@inproceedings{jeon_dr_2012,
  title = {Dr. {{Android}} and {{Mr}}. {{Hide}}: Fine-Grained Permissions in Android Applications},
  shorttitle = {Dr. {{Android}} and {{Mr}}. {{Hide}}},
  booktitle = {Proceedings of the Second {{ACM}} Workshop on {{Security}} and Privacy in Smartphones and Mobile Devices - {{SPSM}} '12},
  author = {Jeon, Jinseong and Micinski, Kristopher K. and Vaughan, Jeffrey A. and Fogel, Ari and Reddy, Nikhilesh and Foster, Jeffrey S. and Millstein, Todd},
  year = {2012},
  pages = {3},
  publisher = {{ACM Press}},
  address = {{Raleigh, North Carolina, USA}},
  doi = {10.1145/2381934.2381938},
  url = {http://dl.acm.org/citation.cfm?doid=2381934.2381938},
  urldate = {2020-12-19},
  eventtitle = {The Second {{ACM}} Workshop},
  isbn = {978-1-4503-1666-8}
}


@inproceedings{rasthofer_droidforce_2014,
  title = {{{DroidForce}}: {{Enforcing Complex}}, {{Data}}-Centric, {{System}}-Wide {{Policies}} in {{Android}}},
  shorttitle = {{{DroidForce}}},
  booktitle = {2014 {{Ninth International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Rasthofer, Siegfried and Arzt, Steven and Lovat, Enrico and Bodden, Eric},
  year = {2014},
  pages = {40--49},
  publisher = {{IEEE}},
  address = {{Fribourg, Switzerland}},
  doi = {10.1109/ARES.2014.13},
  url = {http://ieeexplore.ieee.org/document/6980262/},
  urldate = {2020-12-19},
  eventtitle = {2014 {{Ninth International Conference}} on {{Availability}}, {{Reliability}} and {{Security}} ({{ARES}})}
}

@inproceedings{10.1145/3025453.3025683,
author = {Gugenheimer, Jan and Stemasov, Evgeny and Frommel, Julian and Rukzio, Enrico},
title = {ShareVR: Enabling Co-Located Experiences for Virtual Reality between HMD and Non-HMD Users},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025683},
doi = {10.1145/3025453.3025683},
abstract = {Virtual reality (VR) head-mounted displays (HMD) allow for a highly immersive experience and are currently becoming part of the living room entertainment. Current VR systems focus mainly on increasing the immersion and enjoyment for the user wearing the HMD (HMD user), resulting in all the bystanders (Non-HMD users) being excluded from the experience. We propose ShareVR, a proof-of-concept prototype using floor projection and mobile displays in combination with positional tracking to visualize the virtual world for the Non-HMD user, enabling them to interact with the HMD user and become part of the VR experience. We designed and implemented ShareVR based on the insights of an initial online survey (n=48) with early adopters of VR HMDs. We ran a user study (n=16) comparing ShareVRto a baseline condition showing how the interaction using ShareVR led to an increase of enjoyment, presence and social interaction. In a last step we implemented several experiences for ShareVR, exploring its design space and giving insights for designers of co-located asymmetric VR experiences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4021–4033},
numpages = {13},
keywords = {sharevr, co-located virtual reality, multi-user virtual reality, asymmetric virtual reality, consumer virtual reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@INPROCEEDINGS{8798074,  author={Cheng, Lung-Pan and Ofek, Eyal and Holz, Christian and Wilson, Andrew D.},  booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},   title={VRoamer: Generating On-The-Fly VR Experiences While Walking inside Large, Unknown Real-World Building Environments},   year={2019},  volume={},  number={},  pages={359-366},  doi={10.1109/VR.2019.8798074}}

@article{He2015,
	author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	title = {Deep Residual Learning for Image Recognition},
	journal = {arXiv preprint arXiv:1512.03385},
	year = {2015}
}

@inproceedings{davis_retroskeleton_2013,
  title = {{{RetroSkeleton}}: Retrofitting Android Apps},
  shorttitle = {{{RetroSkeleton}}},
  booktitle = {Proceeding of the 11th Annual International Conference on {{Mobile}} Systems, Applications, and Services - {{MobiSys}} '13},
  author = {Davis, Benjamin and Chen, Hao},
  year = {2013},
  pages = {181},
  publisher = {{ACM Press}},
  address = {{Taipei, Taiwan}},
  doi = {10.1145/2462456.2464462},
  url = {http://dl.acm.org/citation.cfm?doid=2462456.2464462},
  urldate = {2020-12-19},
  eventtitle = {Proceeding of the 11th Annual International Conference},
  isbn = {978-1-4503-1672-9}
}


@incollection{garcia-alfaro_appguard_2014,
  title = {{{AppGuard}} – {{Fine}}-{{Grained Policy Enforcement}} for {{Untrusted Android Applications}}},
  booktitle = {Data {{Privacy Management}} and {{Autonomous Spontaneous Security}}},
  author = {Backes, Michael and Gerling, Sebastian and Hammer, Christian and Maffei, Matteo and von Styp-Rekowsky, Philipp},
  editor = {Garcia-Alfaro, Joaquin and Lioudakis, Georgios and Cuppens-Boulahia, Nora and Foley, Simon and Fitzgerald, William M.},
  year = {2014},
  volume = {8247},
  pages = {213--231},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-54568-9_14},
  url = {http://link.springer.com/10.1007/978-3-642-54568-9_14},
  urldate = {2020-12-19},
  isbn = {978-3-642-54567-2 978-3-642-54568-9},
  options = {useprefix=true},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}


@INPROCEEDINGS{Davis12i-arm-droid:a,
    author = {Benjamin Davis and Ben S and Armen Khodaverdian and Hao Chen},
    title = {I-ARM-Droid: A rewriting framework for in-app reference monitors for android applications},
    booktitle = {In Proceedings of the Mobile Security Technologies 2012, MOST ’12.},
    publisher={IEEE},
    year = {2012},
    address={New York, NY, United States},
    pages={1-9},
}


@inproceedings{enck_taintdroid_2010,
  title = {{{TaintDroid}}: {{An Information}}-Flow {{Tracking System}} for {{Realtime Privacy Monitoring}} on {{Smartphones}}},
  booktitle = {Proceedings of the 9th {{USENIX Conference}} on {{Operating Systems Design}} and {{Implementation}}},
  publisher = {USENIX Association},
  author = {Enck, William and Gilbert, Peter and Chun, Byung-Gon and Cox, Landon P. and Jung, Jaeyeon and McDaniel, Patrick and Sheth, Anmol N.},
  year = {2010},
  pages = {393--407},
  series = {{{OSDI}}'10},
  address = {Berkeley, CA, United States}
}

@inproceedings {Aurasium,
author = {Rubin Xu and Hassen Sa{\"\i}di and Ross Anderson},
title = {Aurasium: Practical Policy Enforcement for Android Applications},
booktitle = {21st {USENIX} Security Symposium ({USENIX} Security 12)},
year = {2012},
isbn = {978-931971-95-9},
address = {Bellevue, WA},
pages = {539--552},
url = {https://www.usenix.org/conference/usenixsecurity12/technical-sessions/presentation/xu_rubin},
publisher = {{USENIX} Association},
month = aug,
}


@inproceedings{agarwal_protectmyprivacy_2013,
  title = {{{ProtectMyPrivacy}}: Detecting and Mitigating Privacy Leaks on {{iOS}} Devices Using Crowdsourcing},
  shorttitle = {{{ProtectMyPrivacy}}},
  booktitle = {Proceeding of the 11th Annual International Conference on {{Mobile}} Systems, Applications, and Services - {{MobiSys}} '13},
  author = {Agarwal, Yuvraj and Hall, Malcolm},
  year = {2013},
  pages = {97},
  publisher = {{ACM Press}},
  address = {{Taipei, Taiwan}},
  doi = {10.1145/2462456.2464460},
  url = {http://dl.acm.org/citation.cfm?doid=2462456.2464460},
  urldate = {2020-02-14},
  eventtitle = {Proceeding of the 11th Annual International Conference},
  isbn = {978-1-4503-1672-9}
}



@book{benjamin_race_2019,
  title = {Race after Technology: Abolitionist Tools for the New {{Jim}} Code},
  shorttitle = {Race after Technology},
  author = {Benjamin, Ruha},
  address = {Cambridge, United Kingdom},
  year = {2019},
  publisher = {{Polity}},
  location = {{Medford, MA}},
  isbn = {978-1-5095-2643-7},
  keywords = {21st century,African Americans,Digital divide,Information technology,Race relations,Social aspects,Social conditions,SOCIAL SCIENCE / Demography,United States,Whites},
  pagetotal = {1}
}



@inproceedings{binns_third_2018,
  title = {Third {{Party Tracking}} in the {{Mobile Ecosystem}}},
  booktitle = {Proceedings of the 10th {{ACM Conference}} on {{Web Science}} - {{WebSci}} '18},
  author = {Binns, Reuben and Lyngs, Ulrik and Van Kleek, Max and Zhao, Jun and Libert, Timothy and Shadbolt, Nigel},
  year = {2018},
  pages = {23--31},
  publisher = {{ACM Press}},
  location = {{Amsterdam, Netherlands}},
  doi = {10.1145/3201064.3201089},
  url = {http://dl.acm.org/citation.cfm?doid=3201064.3201089},
  urldate = {2020-02-14},
  eventtitle = {The 10th {{ACM Conference}}},
  isbn = {978-1-4503-5563-6},
  address = {New York, NY, United States}
}



@article{zimmeck_maps_2019,
  title = {{{MAPS}}: {{Scaling Privacy Compliance Analysis}} to a {{Million Apps}}},
  shorttitle = {{{MAPS}}},
  author = {Zimmeck, Sebastian and Story, Peter and Smullen, Daniel and Ravichander, Abhilasha and Wang, Ziqi and Reidenberg, Joel and Cameron Russell, N. and Sadeh, Norman},
  year = {2019},
  journaltitle = {Proceedings on Privacy Enhancing Technologies},
  volume = {2019},
  pages = {66--86},
  issn = {2299-0984},
  doi = {10.2478/popets-2019-0037},
  url = {https://content.sciendo.com/view/journals/popets/2019/3/article-p66.xml},
  urldate = {2020-02-14},
  number = {3}
}



@inproceedings{lyngs_self-control_2019,
  title = {Self-{{Control}} in {{Cyberspace}}: {{Applying Dual Systems Theory}} to a {{Review}} of {{Digital Self}}-{{Control Tools}}},
  shorttitle = {Self-{{Control}} in {{Cyberspace}}},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Lyngs, Ulrik and Lukoff, Kai and Slovak, Petr and Binns, Reuben and Slack, Adam and Inzlicht, Michael and Van Kleek, Max and Shadbolt, Nigel},
  address = {New York, NY, United States},
  year = {2019},
  pages = {1--18},
  publisher = {{Association for Computing Machinery}},
  location = {{Glasgow, Scotland Uk}},
  doi = {10.1145/3290605.3300361},
  url = {https://doi.org/10.1145/3290605.3300361},
  urldate = {2020-12-09},
  isbn = {978-1-4503-5970-2},
  keywords = {addiction,attention,distraction,focus,ict non-use,interruptions,self-control,self-regulation},
  series = {{{CHI}} '19}
}



@inproceedings{wu_design_2019,
  title = {Design and {{Evaluation}} of a {{Social Media Writing Support Tool}} for {{People}} with {{Dyslexia}}},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Wu, Shaomei and Reynolds, Lindsay and Li, Xian and Guzmán, Francisco},
  year = {2019},
  pages = {1--14},
  publisher = {{ACM}},
  address = {{Glasgow Scotland Uk}},
  doi = {10.1145/3290605.3300746},
  url = {https://dl.acm.org/doi/10.1145/3290605.3300746},
  urldate = {2020-12-20},
  eventtitle = {{{CHI}} '19: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-5970-2}
}


@inproceedings{kannengiesser2016insight,
	author = {Kannengiesser, Nils and  Neutze, Johannes and  Baumgarten, Uwe and  Song, Sejun and },
	title = {An Insight to Cracking Solutions and Circumvention of Major Protection Methods for Android},
	booktitle = {International Symposium on Ambient Intelligence and Embedded Systems},
	year = {2016},
	address = {Heraklion, Crete, Greece },
	url = {http://amies-2016.international-symposium.org/proceedings_2016/Kannengiesser_Neutze_Baumgarten_Song_AmiEs_2016_Paper.pdf},
	keywords = {Android, Google, Amazon, LVL, DRM, Copy Protection, Attacks},
	publisher={Springer},
	pages={1-6},
}

@inproceedings{10.1145/3173574.3174108,
author = {Gray, Colin M. and Kou, Yubo and Battles, Bryan and Hoggatt, Joseph and Toombs, Austin L.},
title = {The Dark (Patterns) Side of UX Design},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174108},
doi = {10.1145/3173574.3174108},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {design character, ux practice, dark patterns, practice-led research, ethics, design responsibility},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/2590296.2590311,
author = {Van Acker, Steven and Nikiforakis, Nick and Desmet, Lieven and Piessens, Frank and Joosen, Wouter},
title = {Monkey-in-the-Browser: Malware and Vulnerabilities in Augmented Browsing Script Markets},
year = {2014},
isbn = {9781450328005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2590296.2590311},
doi = {10.1145/2590296.2590311},
booktitle = {Proceedings of the 9th ACM Symposium on Information, Computer and Communications Security},
pages = {525–530},
numpages = {6},
keywords = {greasemonkey, userscripts.org, large-scale analysis, script market, browser extension, vulnerabilities, dom-based XSS, malware, augmented browsing},
location = {Kyoto, Japan},
series = {ASIA CCS '14}
}

@article{10.1145/3359183,
author = {Mathur, Arunesh and Acar, Gunes and Friedman, Michael J. and Lucherini, Elena and Mayer, Jonathan and Chetty, Marshini and Narayanan, Arvind},
title = {Dark Patterns at Scale: Findings from a Crawl of 11K Shopping Websites},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CSCW},
url = {https://doi.org/10.1145/3359183},
doi = {10.1145/3359183},
journal = {Proceedings of the ACM on Human-Computer Interaction},
month = nov,
articleno = {81},
numpages = {32},
keywords = {nudging, dark patterns, manipulation, consumer protection, deceptive content}
}

@ARTICLE{Cybenko_2002,
  author={G. {Cybenko} and A. {Giani} and P. {Thompson}},
  journal={Computer}, 
  title={Cognitive hacking: a battle for the mind}, 
  year={2002},
  volume={35},
  number={8},
  pages={50-56},
  doi={10.1109/MC.2002.1023788}
}


@inproceedings{10.1145/3313831.3376600,
author = {Di Geronimo, Linda and Braz, Larissa and Fregnan, Enrico and Palomba, Fabio and Bacchelli, Alberto},
title = {UI Dark Patterns and Where to Find Them: A Study on Mobile Applications and User Perception},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376600},
doi = {10.1145/3313831.3376600},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {user experiments, dark patterns, ethical design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3290605.3300472,
author = {Moser, Carol and Schoenebeck, Sarita Y. and Resnick, Paul},
title = {Impulse Buying: Design Practices and Consumer Needs},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300472},
doi = {10.1145/3290605.3300472},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {self-control, e-commerce, dark patterns, behavior change},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3319535.3354212,
author = {Utz, Christine and Degeling, Martin and Fahl, Sascha and Schaub, Florian and Holz, Thorsten},
title = {(Un)Informed Consent: Studying GDPR Consent Notices in the Field},
year = {2019},
isbn = {9781450367479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319535.3354212},
doi = {10.1145/3319535.3354212},
booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
pages = {973–990},
numpages = {18},
keywords = {consent, gdpr, notifications, usable privacy},
location = {London, United Kingdom},
series = {CCS '19}
}

@misc{soe2020circumvention,
      title={Circumvention by design -- dark patterns in cookie consents for online news outlets}, 
      author={Than Htut Soe and Oda Elise Nordberg and Frode Guribye and Marija Slavkovik},
      year={2020},
      eprint={2006.13985},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}

@article {MultiplePurposesMultipleProblemsAUserStudyofConsentDialogsafterGDPR,
      author = "Dominique Machuletz and Rainer Böhme",
      title = "Multiple Purposes, Multiple Problems: A User Study of Consent Dialogs after GDPR",
      journal = "Proceedings on Privacy Enhancing Technologies",
      year = "01 Apr. 2020",
      publisher = "Sciendo",
      address = "Berlin",
      volume = "2020",
      number = "2",
      doi = "https://doi.org/10.2478/popets-2020-0037",
      pages=      "481 - 498",
      url = "https://content.sciendo.com/view/journals/popets/2020/2/article-p481.xml"
}

@inproceedings{10.1145/3313831.3376321,
author = {Nouwens, Midas and Liccardi, Ilaria and Veale, Michael and Karger, David and Kagal, Lalana},
title = {Dark Patterns after the GDPR: Scraping Consent Pop-Ups and Demonstrating Their Influence},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376321},
doi = {10.1145/3313831.3376321},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {consent management platforms, gdpr, notice and consent, controlled experiment, web scraper, dark patterns},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@article{martinez2016,
 title = {{Automatic Repair of Real Bugs in Java: A Large-Scale Experiment on the Defects4J Dataset}},
 author = {Matias Martinez and Thomas Durieux and Romain Sommerard and Jifeng Xuan and Martin Monperrus},
 journal = {Springer Empirical Software Engineering},
 year = {2016},
 volume={22},
 number={4},
 pages={1936-1964},
 url = {https://hal.archives-ouvertes.fr/hal-01387556/document},
 doi = {10.1007/s10664-016-9470-4},
}

@misc{ye2019automated,
      title={Automated Patch Assessment for Program Repair at Scale}, 
      author={He Ye and Matias Martinez and Martin Monperrus},
      year={2019},
      eprint={1909.13694},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@inproceedings{10.1145/2786805.2786825,
author = {Smith, Edward K. and Barr, Earl T. and Le Goues, Claire and Brun, Yuriy},
title = {Is the Cure Worse than the Disease? Overfitting in Automated Program Repair},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2786825},
doi = {10.1145/2786805.2786825},
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {532–543},
numpages = {12},
keywords = {GenProg, empirical evaluation, IntroClass, independent evaluation, automated program repair, TrpAutoRepair},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}


@inproceedings{monge_roffarello_race_2019,
  title = {The {{Race Towards Digital Wellbeing}}: {{Issues}} and {{Opportunities}}},
  shorttitle = {The {{Race Towards Digital Wellbeing}}},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Monge Roffarello, Alberto and De Russis, Luigi},
  year = {2019},
  pages = {1--14},
  publisher = {{ACM}},
  location = {{Glasgow Scotland Uk}},
  doi = {10.1145/3290605.3300616},
  url = {https://dl.acm.org/doi/10.1145/3290605.3300616},
  urldate = {2020-12-21},
  eventtitle = {{{CHI}} '19: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-5970-2}
}



@inproceedings{lyngs_i_2020,
  title = {'{{I Just Want}} to {{Hack Myself}} to {{Not Get Distracted}}': {{Evaluating Design Interventions}} for {{Self}}-{{Control}} on {{Facebook}}},
  shorttitle = {'{{I Just Want}} to {{Hack Myself}} to {{Not Get Distracted}}'},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Lyngs, Ulrik and Lukoff, Kai and Slovak, Petr and Seymour, William and Webb, Helena and Jirotka, Marina and Zhao, Jun and Van Kleek, Max and Shadbolt, Nigel},
  year = {2020},
  pages = {1--15},
  publisher = {{ACM}},
  address = {{Honolulu HI USA}},
  doi = {10.1145/3313831.3376672},
  url = {https://dl.acm.org/doi/10.1145/3313831.3376672},
  urldate = {2020-06-17},
  eventtitle = {{{CHI}} '20: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-6708-0},
}

@inproceedings{10.1145/3170427.3188553,
author = {Fansher, Madison and Chivukula, Shruthi Sai and Gray, Colin M.},
title = {\#darkpatterns: UX Practitioner Conversations About Ethical Design},
year = {2018},
isbn = {9781450356213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170427.3188553},
doi = {10.1145/3170427.3188553},
booktitle = {Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {ethics, practice-led research, twitter, dark patterns},
location = {Montreal QC, Canada},
series = {CHI EA '18}
}

@inproceedings{1e882f77dcb649b4aa4146efd6a07693,
title = "Adversarial examples for malware detection",
author = "Kathrin Grosse and Nicolas Papernot and Praveen Manoharan and Michael Backes and Patrick McDaniel",
year = "2017",
doi = "10.1007/978-3-319-66399-9_4",
language = "English (US)",
isbn = "9783319663982",
series = "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
publisher = "Springer Verlag",
pages = "62--79",
editor = "Foley, {Simon N.} and Dieter Gollmann and Einar Snekkenes",
booktitle = "Computer Security – ESORICS 2017 - 22nd European Symposium on Research in Computer Security, Proceedings",
address = "Germany",
}

@inproceedings{10.1145/3134600.3134636,
author = {Chen, Lingwei and Hou, Shifu and Ye, Yanfang},
title = {SecureDroid: Enhancing Security of Machine Learning-Based Detection against Adversarial Android Malware Attacks},
year = {2017},
isbn = {9781450353458},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3134600.3134636},
doi = {10.1145/3134600.3134636},
booktitle = {Proceedings of the 33rd Annual Computer Security Applications Conference},
pages = {362–372},
numpages = {11},
keywords = {Machine Learning, Android Malware Detection, Adversarial Attack},
location = {Orlando, FL, USA},
series = {ACSAC 2017}
}

@article{CHEN2018326,
title = "Automated poisoning attacks and defenses in malware detection systems: An adversarial machine learning approach",
journal = "Computers \& Security",
volume = "73",
pages = "326 - 344",
year = "2018",
issn = "0167-4048",
doi = "https://doi.org/10.1016/j.cose.2017.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S0167404817302444",
author = "Sen Chen and Minhui Xue and Lingling Fan and Shuang Hao and Lihua Xu and Haojin Zhu and Bo Li",
}

@inproceedings{10.1145/3134600.3134642,
author = {Yang, Wei and Kong, Deguang and Xie, Tao and Gunter, Carl A.},
title = {Malware Detection in Adversarial Settings: Exploiting Feature Evolutions and Confusions in Android Apps},
year = {2017},
isbn = {9781450353458},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3134600.3134642},
doi = {10.1145/3134600.3134642},
booktitle = {Proceedings of the 33rd Annual Computer Security Applications Conference},
pages = {288–302},
numpages = {15},
keywords = {Malware detection, Adversarial classification},
location = {Orlando, FL, USA},
series = {ACSAC 2017}
}

@article{7917369,
author = {Demontis, Ambra and Melis, Marco and Biggio, Battista and Maiorca, Davide and Arp, Daniel and Rieck, Konrad and Corona, Igino and Giacinto, Giorgio and Roli, Fabio},
title = {Yes, Machine Learning Can Be More Secure! A Case Study on Android Malware Detection},
year = {2019},
issue_date = {July 2019},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {16},
number = {4},
issn = {1545-5971},
url = {https://doi.org/10.1109/TDSC.2017.2700270},
doi = {10.1109/TDSC.2017.2700270},
journal = {IEEE Trans. Dependable Secur. Comput.},
month = jul,
pages = {711–724},
numpages = {14}
}

@ARTICLE{8782574,  author = {Chen, Xiao and Li, Chaoran and Wang, Derui and Wen, Sheng and Zhang, Jun and Nepal, Surya and Xiang, Yang and Ren, Kui}, journal={IEEE Transactions on Information Forensics and Security},   title={Android HIV: A Study of Repackaging Malware for Evading Machine-Learning Detection},   year={2020},  volume={15},  number={},  pages={987-1001},  doi={10.1109/TIFS.2019.2932228}}

@article{KARBAB2018S48,
title = "MalDozer: Automatic framework for android malware detection using deep learning",
journal = "Digital Investigation",
volume = "24",
pages = "S48 - S59",
year = "2018",
issn = "1742-2876",
doi = "https://doi.org/10.1016/j.diin.2018.01.007",
url = "http://www.sciencedirect.com/science/article/pii/S1742287618300392",
author = "ElMouatez Billah Karbab and Mourad Debbabi and Abdelouahid Derhab and Djedjiga Mouheb",
keywords = "Mobile, Android, Malware, IoT, Deep learning",
}
 
 @article{8406618,
  title={DeepRefiner: Multi-layer Android Malware Detection System Applying Deep Neural Networks},
  author={K. Xu and Yingjiu Li and R. Deng and K. Chen},
  journal={2018 IEEE European Symposium on Security and Privacy (EuroS\&P)},
  year={2018},
  pages={473-487},
  number={1}, volume={1},
  doi={10.1109/EuroSP.2018.00040}
}

@inproceedings{7846953,
author = {Su, Xin and Zhang, Dafang and Li, Wenjia and Zhao, Kai},
year = {2016},
month = {08},
pages = {244-251},
title = {A Deep Learning Approach to Android Malware Feature Learning and Detection},
doi = {10.1109/TrustCom.2016.0070},
booktitle={2016 IEEE Trustcom/BigDataSE/ISPA},
publisher={IEEE},
address={Tianjin, China},
}

@INPROCEEDINGS{8004891,  author = {Liang, Hongliang and Song, Yan and Xiao, Da},  booktitle={2017 IEEE International Conference on Intelligence and Security Informatics (ISI)},   title={An end-to-end model for Android malware detection},   year={2017},  pages={140-142}, address={Beijing}, publisher={IEEE}, doi={10.1109/ISI.2017.8004891}}

@INPROCEEDINGS{7814490,  author = {Hou, Shifu and Saas, Aaron and Chen, Lifei and Ye, Yanfang}, booktitle={2016 IEEE/WIC/ACM International Conference on Web Intelligence Workshops (WIW)},   title={Deep4MalDroid: A Deep Learning Framework for Android Malware Detection Based on Linux Kernel System Call Graphs},   year={2016},  volume={}, address={Omaha, NE, USA}, publisher={IEEE}, number={},  pages={104-111},  doi={10.1109/WIW.2016.040}}

@misc{rieger_sinders_2020, title={Dark Patterns: Regulating Digital Design}, url={https://www.stiftung-nv.de/sites/default/files/dark.patterns.english.pdf}, journal={Stiftung Neue Verantwortung}, author={Rieger, Sebastian and Sinders, Caroline}, year={2020}, month={May}} 
 
 


@inproceedings{shklovski_leakiness_2014,
  title = {Leakiness and Creepiness in App Space: Perceptions of Privacy and Mobile App Use},
  address = {New York, NY, United States},
  shorttitle = {Leakiness and Creepiness in App Space},
  booktitle = {Proceedings of the 32nd Annual {{ACM}} Conference on {{Human}} Factors in Computing Systems - {{CHI}} '14},
  author = {Shklovski, Irina and Mainwaring, Scott D. and Skúladóttir, Halla Hrund and Borgthorsson, Höskuldur},
  year = {2014},
  pages = {2347--2356},
  publisher = {ACM Press},
  location = {Toronto, Ontario, Canada},
  doi = {10.1145/2556288.2557421},
  url = {http://dl.acm.org/citation.cfm?doid=2556288.2557421},
  urldate = {2020-02-14},
  eventtitle = {The 32nd Annual {{ACM}} Conference},
  isbn = {978-1-4503-2473-1}
}

 

@misc{bundeskartellamt,
  title = {B6-22/16 ({Facebook} v {Bundeskartellamt})},
  author = {Bundeskartellamt},
  year = {2019}
}


@misc{tcontrol,
  title = {TrackerControl},
  author = {Kollnig, Konrad},
  year = {2020},
  url = {https://trackercontrol.org/},
}
@misc{cydia,
  author = {Jay Freeman},
  title = {Cydia Substrate},
  year = {2020},
  url = {http://www.cydiasubstrate.com/},
}
@misc{xp,
  author = {rovo89},
  title = {Xposed Framework},
  year = {2020},
  url = {https://xposed.info/},
}

@misc{lp,
  author = {LuckyPatcher},
  title = {Lucky Patcher},
  year = {2020},
  url = {https://www.luckypatchers.com/},
}
@misc{apkm,
  author = {Niklas Higi},
  title = {apk-mitm},
  year = {2020},
  url = {https://github.com/shroudedcode/apk-mitm/},
}
@misc{ag,
  author = {AdGuard},
  title = {AdGuard},
  year = {2020},
  url = {https://adguard.com/},
}

@misc{stat,
  author = {Statista},
  title = {Ad blocking user penetration rate in the United States from 2014 to 2021},
  year = {2021},
  url = {https://www.statista.com/statistics/804008/ad-blocking-reach-usage-us/},
}
@misc{playstore,
  author = {Statista},
  title = {Number of available applications in the Google Play Store from December 2009 to December 2020},
  year = {2021},
  url = {https://www.statista.com/statistics/266210/number-of-available-applications-in-the-google-play-store/},
}

@book{lessig_code_2006,
    title        = {Code 2.0},
    author       = {Lessig, Lawence},
    publisher    = {Basic Books},
    isbn         = {978-0-465-03914-2},
    edition      = 1,
    date         = 2006
}

@misc{xda,
  author = {evilwombat},
  title = {A de-bullshified version of Facebook (less ads, less clutter, less crap)},
  year = {2020},
  url = {https://forum.xda-developers.com/t/a-de-bullshified-version-of-facebook-less-ads-less-clutter-less-crap.3586318/},
}

@misc{vanced,
  author = {Vanced},
  title = {Vanced},
  year = {2020},
  url = {https://vancedapp.com/},
}

@article{LEE2014373,
title = "The dark side of smartphone usage: Psychological traits, compulsive behavior and technostress",
journal = "Computers in Human Behavior",
volume = "31",
pages = "373 - 383",
year = "2014",
issn = "0747-5632",
doi = "https://doi.org/10.1016/j.chb.2013.10.047",
url = "http://www.sciencedirect.com/science/article/pii/S074756321300397X",
author = "Yu-Kang Lee and Chun-Tuan Chang and You Lin and Zhao-Hong Cheng",
keywords = "Compulsive usage of smartphones, Technostress, Locus of control, Social interaction anxiety, Need for touch, Materialism",
}

@article{phoneabuse,
title = "Smartphones and Cognition: A Review of Research Exploring the Links between Mobile Technology Habits and Cognitive Functioning",
journal = "Frontiers in Psychology",
volume = "8",
pages = "605",
year = "2017",
doi = "https://doi.org/10.3389/fpsyg.2017.00605",
url = "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5403814/",
author = "Wilmer, Henry H. and Sherman, Lauren E. and Chein, Jason M.",
}

@book{10.5555/2821581,
author = {Fogg, B.J.},
title = {Persuasive Technology: Using Computers to Change What We Think and Do},
year = {2003},
isbn = {9780080479941},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
}

@inproceedings{10.1145/3334480.3381070,
author = {Rogers, Yvonne and Dourish, Paul and Olivier, Patrick and Brereton, Margot and Forlizzi, Jodi},
title = {The Dark Side of Interaction Design},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3381070},
doi = {10.1145/3334480.3381070},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–4},
numpages = {4},
keywords = {nudging, dark patterns, digital addiction, dark side, interaction design, data exploitation},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}





%%%%%%%%%%%%%%%%%%%%%%%%%% BEFORE THIS LINE IS GREASEDROID BIB

@misc{stat_0,
  author = {Statista},
  title = {Daily time spent with the internet per capita worldwide from 2011 to 2021, by device},
  year = {2019},
  url = {https://www.statista.com/statistics/319732/daily-time-spent-online-device/},
}

@inproceedings{gd,
  title = {I Want My App That Way: Reclaiming Sovereignty Over Personal Devices},
  booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems Late-Breaking Works},
  author = {Kollnig, Konrad and Datta, Siddhartha and Van Kleek, Max},
  year = {2021},
  pages = {},
  publisher = {{ACM Press}},
  location = {{Yokohama, Japan}},
  doi = {},
  url = {https://arxiv.org/abs/2102.11819},
  address = {Yokohama, Japan}
}

@article{hmgov,
 title = {{Online Harms
White Paper}},
 author = {Government HM},
 journal = {Government Report on Transparency Reporting},
 year = {2019},
 url = {https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/793360/Online_Harms_White_Paper.pdf},
}

@article{kovacs_thesis,
 title = {{HabitLab: In-The-Wild Behavior Change Experiments at Scale}},
 author = {Kovacs Geza},
 journal = {Stanford Department of Computer Science},
 year = {2019},
 url = {https://stacks.stanford.edu/file/druid:qq438qv1791/Thesis-augmented.pdf},
}

@misc{stat_ios,
  author = {Statista},
  title = {Mobile operating systems' market share worldwide from January 2012 to January 2021},
  year = {2021},
  url = {https://www.statista.com/statistics/272698/global-market-share-held-by-mobile-operating-systems-since-2009/},
}

@inproceedings{10.5555/1924943.1924971,
author = {Enck, William and Gilbert, Peter and Chun, Byung-Gon and Cox, Landon P. and Jung, Jaeyeon and McDaniel, Patrick and Sheth, Anmol N.},
title = {TaintDroid: An Information-Flow Tracking System for Realtime Privacy Monitoring on Smartphones},
year = {2010},
publisher = {USENIX Association},
address = {USA},
abstract = {Today's smartphone operating systems frequently fail to provide users with adequate control over and visibility into how third-party applications use their private data. We address these shortcomings with TaintDroid, an efficient, system-wide dynamic taint tracking and analysis system capable of simultaneously tracking multiple sources of sensitive data. TaintDroid provides realtime analysis by leveraging Android's virtualized execution environment. TaintDroid incurs only 14% performance overhead on a CPU-bound micro-benchmark and imposes negligible overhead on interactive third-party applications. Using TaintDroid to monitor the behavior of 30 popular third-party Android applications, we found 68 instances of potential misuse of users' private information across 20 applications. Monitoring sensitive data with TaintDroid provides informed use of third-party applications for phone users and valuable input for smartphone security service firms seeking to identify misbehaving applications.},
booktitle = {Proceedings of the 9th USENIX Conference on Operating Systems Design and Implementation},
pages = {393–407},
numpages = {15},
location = {Vancouver, BC, Canada},
series = {OSDI'10}
}

@misc{oilcan,
  title = {OilCan},
  author = {Sharkey, Jeffrey},
  year = {2008},
  url = {http://oilcan.jsharkey.org/},
}

@misc{apktool,
  title = {apktool},
  author = {Tumbleson, Connor},
  year = {2010},
  url = {https://github.com/iBotPeaches/Apktool},
}

@article{10.1145/3274364,
author = {Kovacs, Geza and Wu, Zhengxuan and Bernstein, Michael S.},
title = {Rotating Online Behavior Change Interventions Increases Effectiveness But Also Increases Attrition},
year = {2018},
issue_date = {November 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CSCW},
url = {https://doi.org/10.1145/3274364},
doi = {10.1145/3274364},
abstract = {Behavior change systems help people manage their time online and achieve many other goals. These systems typically consist of a single static intervention, such as a timer or site blocker, to persuade users to behave in ways consistent with their stated goals. However, static interventions decline in effectiveness over time as users begin to ignore them. In this paper, we compare the effectiveness of static interventions to a rotation strategy, where users experience different interventions over time. We built and deployed a browser extension called HabitLab, which features many interventions that the user can enable across social media and other web sites to control their time spent browsing. We ran three in-the-wild field experiments on HabitLab to compare static interventions to rotated interventions. We found that rotating between interventions increased effectiveness as measured by time on site, but also increased attrition: more users uninstalled HabitLab. To minimize attrition, we introduced a just-in-time information design about rotation. This design reduced attrition rates by half. With this research, we suggest that interaction design, paired with rotation of behavior change interventions, can help users gain control of their online habits.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {95},
numpages = {25},
keywords = {social computing, behavior change}
}

@misc{kovacs2021now,
      title={Not Now, Ask Later: Users Weaken Their Behavior Change Regimen Over Time, But Expect To Re-Strengthen It Imminently}, 
      author={Geza Kovacs and Zhengxuan Wu and Michael S. Bernstein},
      year={2021},
      eprint={2101.11743},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}

@misc{erad,
  title = {News Feed Eradicator for Facebook},
  author = {West, Jordan},
  year = {2012},
  url = {https://chrome.google.com/webstore/detail/news-feed-eradicator-for/fjcldmjmjhkklehbacihaiopjklihlgg?hl=en},
}

@misc{unhook,
  title = {Unhook - Remove YouTube Recommended Videos},
  author = {unhook.app},
  year = {2022},
  url = {https://chrome.google.com/webstore/detail/unhook-remove-youtube-rec/khncfooichmfjbepaaaebmommgaepoid?hl=en},
}

@misc{tesseract,
  author = {Google},
  title = {Tesseract},
  year = {2007},
  url = {https://github.com/tesseract-ocr/tesseract},
}

@misc{zhou2017east,
      title={EAST: An Efficient and Accurate Scene Text Detector}, 
      author={Xinyu Zhou and Cong Yao and He Wen and Yuzhi Wang and Shuchang Zhou and Weiran He and Jiajun Liang},
      year={2017},
      eprint={1704.03155},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{InstaPrefs,
  author = {MaaarZ},
  title = {InstaPrefs},
  year = {2019},
  url = {https://forum.xda-developers.com/t/app-xposed-instaprefs-the-ultimate-instagram-utility.4005051/},
}

@misc{grayswitch,
  author = {Vegard IT GmbH},
  title = {Gray-Switch},
  year = {2021},
  url = {https://play.google.com/store/apps/details?id=com.vegardit.grayswitch},
}

@misc{accessibility,
  author = {Google},
  title = {Android Accessibility Suite},
  year = {2021},
  url = {https://play.google.com/store/apps/details?id=com.google.android.marvin.talkback},
}

@misc{detoxdroid,
  author = {flxapps},
  title = {DetoxDroid},
  year = {2021},
  url = {https://github.com/flxapps/DetoxDroid},
}

@misc{swipe,
  author = {Happening Studios},
  title = {Swipe for Facebook},
  year = {2021},
  url = {https://play.google.com/store/apps/details?id=com.happening.studios.swipeforfacebookfree&hl=en_GB\&gl=US},
}

@misc{friendly,
  author = {Friendly App Studio},
  title = {Friendly Social Browser},
  year = {2022},
  url = {https://apps.apple.com/us/app/friendly-for-facebook/id400169658},
}

@misc{hidelikes,
  author = {hidelikes.com},
  title = {Hide Likes},
  year = {2022},
  url = {https://chrome.google.com/webstore/detail/hide-likes/ebamaffgiechnomghfojkmlkaipoadni},
}

@article{10.1007/s10916-013-0001-1,
author = {Lee, Heyoung and Ahn, Heejune and Choi, Samwook and Choi, Wanbok},
title = {The SAMS: Smartphone Addiction Management System and Verification},
year = {2014},
issue_date = {January   2014},
publisher = {Plenum Press},
address = {USA},
volume = {38},
number = {1},
issn = {0148-5598},
url = {https://doi.org/10.1007/s10916-013-0001-1},
doi = {10.1007/s10916-013-0001-1},
abstract = {While the popularity of smartphones has given enormous convenience to our lives, their pathological use has created a new mental health concern among the community. Hence, intensive research is being conducted on the etiology and treatment of the condition. However, the traditional clinical approach based surveys and interviews has serious limitations: health professionals cannot perform continual assessment and intervention for the affected group and the subjectivity of assessment is questionable. To cope with these limitations, a comprehensive ICT (Information and Communications Technology) system called SAMS (Smartphone Addiction Management System) is developed for objective assessment and intervention. The SAMS system consists of an Android smartphone application and a web application server. The SAMS client monitors the user's application usage together with GPS location and Internet access location, and transmits the data to the SAMS server. The SAMS server stores the usage data and performs key statistical data analysis and usage intervention according to the clinicians' decision. To verify the reliability and efficacy of the developed system, a comparison study with survey-based screening with the K-SAS (Korean Smartphone Addiction Scale) as well as self-field trials is performed. The comparison study is done using usage data from 14 users who are 19 to 50 year old adults that left at least 1 week usage logs and completed the survey questionnaires. The field trial fully verified the accuracy of the time, location, and Internet access information in the usage measurement and the reliability of the system operation over more than 2 weeks. The comparison study showed that daily use count has a strong correlation with K-SAS scores, whereas daily use times do not strongly correlate for potentially addicted users. The correlation coefficients of count and times with total K-SAS score are CC = 0.62 and CC =0.07, respectively, and the  t -test analysis for the contrast group of potential addicts and the values for the non-addicts were  p  = 0.047 and  p  = 0.507, respectively.},
journal = {J. Med. Syst.},
month = jan,
pages = {1–10},
numpages = {10},
keywords = {Statistical analysis, Smartphone addiction, Objective assessment, ICT system}
}

@inproceedings{10.1145/2675133.2675244,
author = {Ko, Minsam and Yang, Subin and Lee, Joonwon and Heizmann, Christian and Jeong, Jinyoung and Lee, Uichin and Shin, Daehee and Yatani, Koji and Song, Junehwa and Chung, Kyong-Mee},
title = {NUGU: A Group-Based Intervention App for Improving Self-Regulation of Limiting Smartphone Use},
year = {2015},
isbn = {9781450329224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2675133.2675244},
doi = {10.1145/2675133.2675244},
abstract = {Our preliminary study reveals that individuals use various management strategies for limiting smartphone use, ranging from keeping smartphones out of reach to removing apps. However, we also found that users often had difficulties in maintaining their chosen management strategies due to lack of self-regulation. In this paper, we present NUGU, a group-based intervention app for improving self-regulation of limiting smartphone use through leveraging social support: groups of people limit their use together by sharing their limiting information. NUGU is designed based on social cognitive theory, and it has been developed iteratively through two pilot tests. Our three-week user study (n = 62) demonstrated that compared with its non-social counterpart, the NUGU users' usage amount significantly decreased and their perceived level of managing disturbances improved. Furthermore, our exit interview confirmed that NUGU's design elements are effective for achieving limiting goals.},
booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work \& Social Computing},
pages = {1235–1245},
numpages = {11},
keywords = {social support, smartphone use, group-based intervention},
location = {Vancouver, BC, Canada},
series = {CSCW '15}
}

@inproceedings{10.1145/2968219.2971591,
author = {Andone, Ionut and B\l{}aszkiewicz, Konrad and Eibes, Mark and Trendafilov, Boris and Montag, Christian and Markowetz, Alexander},
title = {Menthal: A Framework for Mobile Data Collection and Analysis},
year = {2016},
isbn = {9781450344623},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2968219.2971591},
doi = {10.1145/2968219.2971591},
abstract = {We present a framework for collecting and analyzing mobile users' data. We have built our own framework in order to fulfill specific tracking requirements such as app usage and affect/mood recording. We incentivize the users to share their data through giving feedback. The UX and the interface are primary concerns in our Android app. To be able to process large amounts of data we developed our analysis platform using a modern big data stack. The framework has been deployed in a large scale longitudinal experiment since January 2014. It has attracted more than 400, 000 app installs and more than 350, 000 registered participants.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct},
pages = {624–629},
numpages = {6},
keywords = {mobile computing, data mining, mobile user acquisition, mobile devices, infrastructure, user behavior observation, mobile sensing},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/2858036.2858403,
author = {Hiniker, Alexis and Hong, Sungsoo (Ray) and Kohno, Tadayoshi and Kientz, Julie A.},
title = {MyTime: Designing and Evaluating an Intervention for Smartphone Non-Use},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858403},
doi = {10.1145/2858036.2858403},
abstract = {Though many people report an interest in self-limiting certain aspects of their phone use, challenges adhering to self-defined limits are common. We conducted a design exercise and online survey to map the design space of interventions for smartphone non-use and distilled these into a small taxonomy of intervention categories. Using these findings, we implemented "MyTime," an intervention to support people in achieving goals related to smartphone non-use. We conducted a deployment study with 23 participants over two weeks and found that participants reduced their time with the apps they feel are a poor use of time by 21% while their use of the apps they feel are a good use of time remained unchanged. We found that a small taxonomy describes users' diverse set of desired behavior changes relating to smartphone non-use, and that these desired changes predict: 1) the hypothetical features they are interested in trying, 2) the extent to which they engage with these features in practice, and 3) their changes in behavior in response to the intervention. We link users' desired behaviors to the categories of our design taxonomy, providing a foundation for a theoretical model of designing for smartphone non-use.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {4746–4757},
numpages = {12},
keywords = {technology non-use, productivity, mindfulness, mobile phones, smartphones},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/3229434.3229463,
author = {Okeke, Fabian and Sobolev, Michael and Dell, Nicola and Estrin, Deborah},
title = {Good Vibrations: Can a Digital Nudge Reduce Digital Overload?},
year = {2018},
isbn = {9781450358989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229434.3229463},
doi = {10.1145/3229434.3229463},
abstract = {Digital overuse on mobile devices is a growing problem in everyday life. This paper describes a generalizable mobile intervention that combines nudge theory and negative reinforcement to create a subtle, repeating phone vibration that nudges a user to reduce their digital consumption. For example, if a user has a daily Facebook limit of 30 minutes but opens Facebook past this limit, the user's phone will issue gentle vibrations every five seconds, but the vibration stops once the user navigates away from Facebook. We evaluated the intervention through a three-week controlled experiment with 50 participants on Amazon's Mechanical Turk platform with findings that show daily digital consumption was successfully reduced by over 20%. Although the reduction did not persist after the intervention was removed, insights from qualitative feedback suggest that the intervention made participants more aware of their app usage habits; and we discuss design implications of episodically applying our intervention in specific everyday contexts such as education, sleep, and work. Taken together, our findings advance the HCI community's understanding of how to curb digital overload.},
booktitle = {Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services},
articleno = {4},
numpages = {12},
keywords = {digital overload, intervention, digital nudge, social media, smartphones, vibration, negative reinforcement},
location = {Barcelona, Spain},
series = {MobileHCI '18}
}

@inproceedings{10.1145/2541831.2541870,
author = {L\"{o}chtefeld, Markus and B\"{o}hmer, Matthias and Ganev, Lyubomir},
title = {AppDetox: Helping Users with Mobile App Addiction},
year = {2013},
isbn = {9781450326483},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2541831.2541870},
doi = {10.1145/2541831.2541870},
abstract = {With the increasing adoption of smartphones also a problematic phenomena become apparent: People are changing their habits and become addicted to different services that these devices provide. In this paper we present AppDetox: an app that allows users to purposely create rules that keep them from using certain apps. We describe our deployment of the app on a mobile application store, and present initial findings gained through observation of about 11,700 users of the application. We find that people are rather rigorous when restricting their app use, and that mostly they suppress use of social networking and messaging apps.},
booktitle = {Proceedings of the 12th International Conference on Mobile and Ubiquitous Multimedia},
articleno = {43},
numpages = {2},
keywords = {technology addiction, smartphone use, digital detox, apps},
location = {Lule\r{a}, Sweden},
series = {MUM '13}
}

@misc{al,
  author = {AV Tech Labs},
  title = {Auto Logout},
  year = {2019},
  url = {https://chrome.google.com/webstore/detail/auto-logout/affkccgnaoeohjnojjnpdalhpjhdiebh?hl=en},
}

@misc{anchor,
  author = {Twomuch Studio},
  title = {Anchor},
  year = {2020},
  url = {https://experiments.withgoogle.com/anchor},
}

@misc{twt,
  author = {PrettyMind},
  title = {TimeWaste Timer},
  year = {2015},
  url = {https://timewaste.prettymind.co/},
}

@inproceedings{10.1145/3290605.3300560,
author = {Kovacs, Geza and Gregory, Drew Mylander and Ma, Zilin and Wu, Zhengxuan and Emami, Golrokh and Ray, Jacob and Bernstein, Michael S.},
title = {Conservation of Procrastination: Do Productivity Interventions Save Time Or Just Redistribute It?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300560},
doi = {10.1145/3290605.3300560},
abstract = {Productivity behavior change systems help us reduce our time on unproductive activities. However, is that time actually saved, or is it just redirected to other unproductive activities? We report an experiment using HabitLab, a behavior change browser extension and phone application, that manipulated the frequency of interventions on a focal goal and measured the effects on time spent on other applications and platforms. We find that, when intervention frequency increases on the focal goal, time spent on other applications is held constant or even reduced. Likewise, we find that time is not redistributed across platforms from browser to mobile phone or vice versa. These results suggest that any conservation of procrastination effect is minimal, and that behavior change designers may target individual productivity goals without causing substantial negative second-order effects.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {distractions and interruptions, behavior change},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@article{journals/jgtools/Telea04,
  added-at = {2013-05-14T00:00:00.000+0200},
  author = {Telea, Alexandru},
  biburl = {https://www.bibsonomy.org/bibtex/2b0bf54e265d011a8e1fe256e6fcf556b/dblp},
  ee = {http://dx.doi.org/10.1080/10867651.2004.10487596},
  interhash = {abdaa4cbd096648856a6e420b10f0898},
  intrahash = {b0bf54e265d011a8e1fe256e6fcf556b},
  journal = {J. Graphics, GPU, \& Game Tools},
  keywords = {dblp},
  number = 1,
  pages = {23-34},
  timestamp = {2013-08-13T14:04:51.000+0200},
  title = {An Image Inpainting Technique Based on the Fast Marching Method.},
  url = {http://dblp.uni-trier.de/db/journals/jgtools/jgtools9.html#Telea04},
  volume = 9,
  year = 2004
}

@inproceedings{Koch2015SiameseNN,
  added-at = {2017-03-27T16:51:39.000+0200},
  author = {Koch, Gregory and Zemel, Richard and Salakhutdinov, Ruslan},
  biburl = {https://www.bibsonomy.org/bibtex/26f83b8c4cf316e77e6f6ce1e97411b30/bsc},
  interhash = {a2596c72ef39240b7c4f86e6038d9344},
  intrahash = {6f83b8c4cf316e77e6f6ce1e97411b30},
  keywords = {neural-networks one-shot-learning},
  timestamp = {2017-03-27T16:51:39.000+0200},
  title = {Siamese Neural Networks for One-shot Image Recognition},
  year = 2015
}

@misc{fbdemet,
      title={What Do Metrics Want? How Quantification Prescribes Social Interaction on Facebook}, 
      author={Benjamin Grosser},
      year={2014},
      url = {http://computationalculture.net/what-do-metrics-want/},
}

@misc{fbd,
      title={Facebook Demetricator}, 
      author={Benjamin Grosser},
      year={2012},
      url = {https://bengrosser.com/projects/facebook-demetricator/},
}

@misc{twd,
      title={Twitter Demetricator}, 
      author={Benjamin Grosser},
      year={2018},
      url = {https://bengrosser.com/projects/twitter-demetricator/},
}

@misc{igd,
      title={Instagram Demetricator},
      author={Benjamin Grosser},
      year={2019},
      url = {https://bengrosser.com/projects/instagram-demetricator/},
}

@inproceedings{hateoffensive,
  title = {Automated Hate Speech Detection and the Problem of Offensive Language},
  author = {Davidson, Thomas and Warmsley, Dana and Macy, Michael and Weber, Ingmar}, 
  booktitle = {Proceedings of the 11th International AAAI Conference on Web and Social Media},
  series = {ICWSM '17},
  year = {2017},
  location = {Montreal, Canada},
  pages = {512-515}
  }
  
@misc{bodyguard,
      title={Bodyguard},
      author={Bodyguard, Inc},
      year={2019},
      url = {https://www.bodyguard.ai/},
}
  
@misc{googledev,
      title={Developer Program Policy},
      author={Google},
      year={2021},
      url = {https://support.google.com/googleplay/android-developer/answer/10355942},
}

@misc{fbtrans,
      title={Content Restrictions Based on Local Law},
      author={Meta},
      year={2022},
      url = {https://transparency.fb.com/data/content-restrictions/},
}

@misc{stest,
      title={The History of Software Testing},
      author={Meerts, Joris and Dorothy Graham},
      year={2010},
      url = {http://www.testingreferences.com/testinghistory.php},
}

@article{labelme,
  abstract = {              We seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.
              },
  added-at = {2013-10-24T16:11:28.000+0200},
  author = {Russell, BryanC. and Torralba, Antonio and Murphy, KevinP. and Freeman, WilliamT.},
  biburl = {https://www.bibsonomy.org/bibtex/22d79977030d6fcc55896d5ed6515cdae/alex_ruff},
  description = {LabelMe: A Database and Web-Based Tool for Image Annotation - Springer},
  doi = {10.1007/s11263-007-0090-8},
  interhash = {3c35da3a09183fa5296187ab0981aa50},
  intrahash = {2d79977030d6fcc55896d5ed6515cdae},
  issn = {0920-5691},
  journal = {International Journal of Computer Vision},
  keywords = {database evaluation optical_flow performance segmentation},
  language = {English},
  number = {1-3},
  pages = {157-173},
  publisher = {Springer US},
  timestamp = {2013-10-24T16:11:28.000+0200},
  title = {LabelMe: A Database and Web-Based Tool for Image Annotation},
  url = {http://dx.doi.org/10.1007/s11263-007-0090-8},
  volume = 77,
  year = 2008
}




@ARTICLE{844354,  author={Parasuraman, R. and Sheridan, T.B. and Wickens, C.D.},  journal={IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},   title={A model for types and levels of human interaction with automation},   year={2000},  volume={30},  number={3},  pages={286-297},  doi={10.1109/3468.844354}}

@misc{recaptcha,
      title={reCAPTCHA FAQ},
      author={Google},
      year={2010},
      url = {https://web.archive.org/web/20100705103425/http://www.google.com/recaptcha/faq},
}

@misc{fbdev,
      title={Community Standards},
      author={Facebook},
      year={2021},
      url = {https://www.facebook.com/communitystandards/},
}

@misc{twdev,
      title={Rules and Policies},
      author={Twitter},
      year={2021},
      url = {https://help.twitter.com/en/rules-and-policies},
}
  
@inproceedings{10.1145/3292522.3326034,
author = {Mathew, Binny and Dutt, Ritam and Goyal, Pawan and Mukherjee, Animesh},
title = {Spread of Hate Speech in Online Social Media},
year = {2019},
isbn = {9781450362023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292522.3326034},
doi = {10.1145/3292522.3326034},
abstract = {Hate speech is considered to be one of the major issues currently plaguing the online social media. With online hate speech culminating in gruesome scenarios like the Rohingya genocide in Myanmar, anti-Muslim mob violence in Sri Lanka, and the Pittsburgh synagogue shooting, there is a dire need to understand the dynamics of user interaction that facilitate the spread of such hateful content. In this paper, we perform the first study that looks into the diffusion dynamics of the posts made by hateful and non-hateful users on Gab (Gab.com). We collect a massive dataset of 341K users with 21M posts and investigate the diffusion of the posts generated by hateful and non-hateful users. We observe that the content generated by the hateful users tend to spread faster, farther and reach a much wider audience as compared to the content generated by normal users. We further analyze the hateful and non-hateful users on the basis of their account and network characteristics. An important finding is that the hateful users are far more densely connected among themselves. Overall, our study provides the first cross-sectional view of how hateful users diffuse hate content in online social media.},
booktitle = {Proceedings of the 10th ACM Conference on Web Science},
pages = {173–182},
numpages = {10},
keywords = {online social media, gab, hate speech, degroot model, information diffusion},
location = {Boston, Massachusetts, USA},
series = {WebSci '19}
}

@article{10.1145/3415163,
author = {Mathew, Binny and Illendula, Anurag and Saha, Punyajoy and Sarkar, Soumya and Goyal, Pawan and Mukherjee, Animesh},
title = {Hate Begets Hate: A Temporal Study of Hate Speech},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {CSCW2},
url = {https://doi.org/10.1145/3415163},
doi = {10.1145/3415163},
abstract = {With the ongoing debate on 'freedom of speech' vs. 'hate speech,' there is an urgent need to carefully understand the consequences of the inevitable culmination of the two, i.e., 'freedom of hate speech' over time. An ideal scenario to understand this would be to observe the effects of hate speech in an (almost) unrestricted environment. Hence, we perform the first temporal analysis of hate speech on Gab.com, a social media site with very loose moderation policy. We first generate temporal snapshots of Gab from millions of posts and users. Using these temporal snapshots, we compute an activity vector based on DeGroot model to identify hateful users. The amount of hate speech in Gab is steadily increasing and the new users are becoming hateful at an increased and faster rate. Further, our analysis analysis reveals that the hate users are occupying the prominent positions in the Gab network. Also, the language used by the community as a whole seem to correlate more with that of the hateful users as compared to the non-hateful ones. We discuss how, many crucial design questions in CSCW open up from our work.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {92},
numpages = {24},
keywords = {degroot, moderation, language analysis, gab, hate speech, freedom of speech, temporal analysis}
}

@inproceedings{elsherief2018hate,
 abstract = {While social media empowers freedom of expression and individual voices, it also enables anti-social behavior, online harassment, cyberbullying, and hate speech. In this paper, we deepen our understanding of online hate speech by focusing on a largely neglected but crucial aspect of hate speech--its target: either directed towards a specific person or entity, or generalized towards a group of people sharing a common protected characteristic. We perform the first linguistic and psycholinguistic analysis of these two forms of hate speech},
 author = {ElSherief, Mai and Kulkarni, Vivek and Nguyen, Dana and Wang, William Yang and Belding, Elizabeth},
 booktitle = {Twelfth International AAAI Conference on Web and Social Media},
 cites = {66},
 eprint = {https://www.aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/viewPDFInterstitial/17910/16995},
 gsrank = {1},
 title = {Hate lingo: A target-based linguistic analysis of hate speech in social media},
 url = {https://www.aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/viewPaper/17910},
 venue = {… AAAI Conference on …},
 year = {2018}
}

@ARTICLE{5557884,  author={P. {Arbeláez} and M. {Maire} and C. {Fowlkes} and J. {Malik}},  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},   title={Contour Detection and Hierarchical Image Segmentation},   year={2011},  volume={33},  number={5},  pages={898-916},  doi={10.1109/TPAMI.2010.161}}

@misc{radford2021learning,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{nn,
      title={NudeNet},
      author={Bedapudi, Praneeth},
      year={2018},
      url = {https://github.com/notAI-tech/NudeNet},
}

@misc{fbt,
      title={Community Standards Enforcement},
      author={Facebook},
      year={2019},
      url = {https://transparency.facebook.com/community-standards-enforcement},
}

@misc{tm,
      title={TamperMonkey},
      author={Biniok, Jan},
      year={2018},
      url = {https://www.tampermonkey.net/},
}

@inproceedings{10.1145/3368089.3417940,
author = {Xie, Mulong and Feng, Sidong and Xing, Zhenchang and Chen, Jieshan and Chen, Chunyang},
title = {UIED: A Hybrid Tool for GUI Element Detection},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3417940},
doi = {10.1145/3368089.3417940},
abstract = {Graphical User Interface (GUI) elements detection is critical for many GUI automation and GUI testing tasks. Acquiring the accurate positions and classes of GUI elements is also the very first step to conduct GUI reverse engineering or perform GUI testing. In this paper, we implement a User Iterface Element Detection (UIED), a toolkit designed to provide user with a simple and easy-to-use platform to achieve accurate GUI element detection. UIED integrates multiple detection methods including old-fashioned computer vision (CV) approaches and deep learning models to handle diverse and complicated GUI images. Besides, it equips with a novel customized GUI element detection methods to produce state-of-the-art detection results. Our tool enables the user to change and edit the detection result in an interactive dashboard. Finally, it exports the detected UI elements in the GUI image to design files that can be further edited in popular UI design tools such as Sketch and Photoshop. UIED is evaluated to be capable of accurate detection and useful for downstream works. Tool URL: <a>http://uied.online</a> Github Link: <a>https://github.com/MulongXie/UIED</a>},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1655–1659},
numpages = {5},
keywords = {Deep Learning, Object Detection, User Interface, Computer Vision},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@misc{vx,
      title={Virtual Xposed},
      author={VrtualApp},
      year={2016},
      url = {https://virtualxposed.org/},
}

@inproceedings{10.1145/3338906.3338976,
author = {Zhang, He and Huang, Xin and Zhou, Xin and Huang, Huang and Babar, Muhammad Ali},
title = {Ethnographic Research in Software Engineering: A Critical Review and Checklist},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338976},
doi = {10.1145/3338906.3338976},
abstract = {Software Engineering (SE) community has recently been investing significant amount of effort in qualitative research to study the human and social aspects of SE processes, practices, and technologies. Ethnography is one of the major qualitative research methods, which is based on constructivist paradigm that is different from the hypothetic-deductive research model usually used in SE. Hence, the adoption of ethnographic research method in SE can present significant challenges in terms of sufficient understanding of the methodological requirements and the logistics of its applications. It is important to systematically identify and understand various aspects of adopting ethnography in SE and provide effective guidance. We carried out an empirical inquiry by integrating a systematic literature review and a confirmatory survey. By reviewing the ethnographic studies reported in 111 identified papers and 26 doctoral theses and analyzing the authors' responses of 29 of those papers, we revealed several unique insights. These identified insights were then transformed into a preliminary checklist that helps improve the state-of-the-practice of using ethnography in SE. This study also identifies the areas where methodological improvements of ethnography are needed in SE.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {659–670},
numpages = {12},
keywords = {Ethnography, systematic (literature) review, empirical software engineering, qualitative research},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{44873,
title	= {Distilling the Knowledge in a Neural Network},
author	= {Geoffrey Hinton and Oriol Vinyals and Jeffrey Dean},
year	= {2015},
URL	= {http://arxiv.org/abs/1503.02531},
booktitle	= {NIPS Deep Learning and Representation Learning Workshop}
}

@inproceedings{10.1145/223904.223962,
author = {John, Bonnie E. and Packer, Hilary},
title = {Learning and Using the Cognitive Walkthrough Method: A Case Study Approach},
year = {1995},
isbn = {0201847051},
publisher = {ACM Press/Addison-Wesley Publishing Co.},
address = {USA},
url = {https://doi.org/10.1145/223904.223962},
doi = {10.1145/223904.223962},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {429–436},
numpages = {8},
location = {Denver, Colorado, USA},
series = {CHI '95}
}

@inproceedings{10.1145/223355.223735,
author = {Rieman, John and Franzke, Marita and Redmiles, David},
title = {Usability Evaluation with the Cognitive Walkthrough},
year = {1995},
isbn = {0897917553},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/223355.223735},
doi = {10.1145/223355.223735},
booktitle = {Conference Companion on Human Factors in Computing Systems},
pages = {387–388},
numpages = {2},
location = {Denver, Colorado, USA},
series = {CHI '95}
}

@article{https://doi.org/10.1111/cdev.13422,
author = {Lee, Hae Yeon and Jamieson, Jeremy P. and Reis, Harry T. and Beevers, Christopher G. and Josephs, Robert A. and Mullarkey, Michael C. and O’Brien, Joseph M. and Yeager, David S.},
title = {Getting Fewer “Likes” Than Others on Social Media Elicits Emotional Distress Among Victimized Adolescents},
journal = {Child Development},
volume = {91},
number = {6},
pages = {2141-2159},
doi = {https://doi.org/10.1111/cdev.13422},
url = {https://srcd.onlinelibrary.wiley.com/doi/abs/10.1111/cdev.13422},
eprint = {https://srcd.onlinelibrary.wiley.com/doi/pdf/10.1111/cdev.13422},
abstract = {Three studies examined the effects of receiving fewer signs of positive feedback than others on social media. In Study 1, adolescents (N = 613, Mage = 14.3 years) who were randomly assigned to receive few (vs. many) likes during a standardized social media interaction felt more strongly rejected, and reported more negative affect and more negative thoughts about themselves. In Study 2 (N = 145), negative responses to receiving fewer likes were associated with greater depressive symptoms reported day-to-day and at the end of the school year. Study 3 (N = 579) replicated Study 1’s main effect of receiving fewer likes and showed that adolescents who already experienced peer victimization at school were the most vulnerable. The findings raise the possibility that technology which makes it easier for adolescents to compare their social status online—even when there is no chance to share explicitly negative comments—could be a risk factor that accelerates the onset of internalizing symptoms among vulnerable youth.},
year = {2020}
}

@article{doi:10.1521/jscp.2018.37.10.751,
author = {Hunt, Melissa G. and Marx, Rachel and Lipson, Courtney and Young, Jordyn},
title = {No More FOMO: Limiting Social Media Decreases Loneliness and Depression},
journal = {Journal of Social and Clinical Psychology},
volume = {37},
number = {10},
pages = {751-768},
year = {2018},
doi = {10.1521/jscp.2018.37.10.751},

URL = { 
        https://doi.org/10.1521/jscp.2018.37.10.751
    
},
eprint = { 
        https://doi.org/10.1521/jscp.2018.37.10.751
    
}
,
    abstract = { Introduction: Given the breadth of correlational research linking social media use to worse well-being, we undertook an experimental study to investigate the potential causal role that social media plays in this relationship. Method: After a week of baseline monitoring, 143 undergraduates at the University of Pennsylvania were randomly assigned to either limit Facebook, Instagram and Snapchat use to 10 minutes, per platform, per day, or to use social media as usual for three weeks. Results: The limited use group showed significant reductions in loneliness and depression over three weeks compared to the control group. Both groups showed significant decreases in anxiety and fear of missing out over baseline, suggesting a benefit of increased self-monitoring. Discussion: Our findings strongly suggest that limiting social media use to approximately 30 minutes per day may lead to significant improvement in well-being. }
}

@inproceedings{10.1145/3201064.3201089,
author = {Binns, Reuben and Lyngs, Ulrik and Van Kleek, Max and Zhao, Jun and Libert, Timothy and Shadbolt, Nigel},
title = {Third Party Tracking in the Mobile Ecosystem},
year = {2018},
isbn = {9781450355636},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3201064.3201089},
doi = {10.1145/3201064.3201089},
abstract = {Third party tracking allows companies to identify users and track their behaviour across multiple digital services. This paper presents an empirical study of the prevalence of third-party trackers on 959,000 apps from the US and UK Google Play stores. We find that most apps contain third party tracking, and the distribution of trackers is long-tailed with several highly dominant trackers accounting for a large portion of the coverage. The extent of tracking also differs between categories of apps; in particular, news apps and apps targeted at children appear to be amongst the worst in terms of the number of third party trackers associated with them. Third party tracking is also revealed to be a highly trans-national phenomenon, with many trackers operating in jurisdictions outside the EU. Based on these findings, we draw out some significant legal compliance challenges facing the tracking industry.},
booktitle = {Proceedings of the 10th ACM Conference on Web Science},
pages = {23–31},
numpages = {9},
keywords = {mobile, static analysis, data protection, privacy, android, behavioural advertising, tracking},
location = {Amsterdam, Netherlands},
series = {WebSci '18}
}

@inproceedings{43405,
title	= {Explaining and Harnessing Adversarial Examples},
author	= {Ian Goodfellow and Jonathon Shlens and Christian Szegedy},
year	= {2015},
URL	= {http://arxiv.org/abs/1412.6572},
booktitle	= {International Conference on Learning Representations}
}

@inproceedings{feiman2017detecting,
title={Detecting Adversarial Samples from Artifacts},
author={Reuben Feinman and Ryan R. Curtin and Saurabh Shintre and Andrew B. Gardner},
booktitle={International Conference on Machine Learning},
year={2017}
}

@inproceedings{10.1145/2998181.2998224,
author = {Pater, Jessica and Mynatt, Elizabeth},
title = {Defining Digital Self-Harm},
year = {2017},
isbn = {9781450343350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2998181.2998224},
doi = {10.1145/2998181.2998224},
abstract = {Self-harm is the infliction of pain or injury onto oneself. Though historically these behaviors were relegated to the fringes of communities, information technology now enables new ways to foster and encourage these dangerous activities. This paper defines the concept of digital self-harm as&nbsp;the online communication and activity that leads to, supports, or exacerbates, non-suicidal yet intentional harm or impairment of an individual's physical wellbeing. We outline a research agenda for the CSCW community to understand the correlation and possible causation of offline self-harm behaviors due to online activities, and to design and assess technologies focused on prevention, mitigation and treatment. CAUTION: This paper includes media that could potentially be triggering to those dealing with an eating disorder or with other self-harm related illnesses. Please use caution when reading or disseminating this paper.},
booktitle = {Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
pages = {1501–1513},
numpages = {13},
keywords = {social media, pro-mia, thinspiration, self-harm, social computing, self-injury, digital self-harm, behavioral health, health, computer-mediated communication, cutting, mental health, pro-ana},
location = {Portland, Oregon, USA},
series = {CSCW '17}
}

@inproceedings{10.1145/3038912.3052555,
author = {Wang, Yilin and Tang, Jiliang and Li, Jundong and Li, Baoxin and Wan, Yali and Mellina, Clayton and O'Hare, Neil and Chang, Yi},
title = {Understanding and Discovering Deliberate Self-Harm Content in Social Media},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052555},
doi = {10.1145/3038912.3052555},
abstract = {Studies suggest that self-harm users found it easier to discuss self-harm-related thoughts and behaviors using social media than in the physical world. Given the enormous and increasing volume of social media data, on-line self-harm content is likely to be buried rapidly by other normal content. To enable voices of self-harm users to be heard, it is important to distinguish self-harm content from other types of content. In this paper, we aim to understand self-harm content and provide automatic approaches to its detection. We first perform a comprehensive analysis on self-harm social media using different input cues. Our analysis, the first of its kind in large scale, reveals a number of important findings. Then we propose frameworks that incorporate the findings to discover self-harm content under both supervised and unsupervised settings. Our experimental results on a large social media dataset from Flickr demonstrate the effectiveness of the proposed frameworks and the importance of our findings in discovering self-harm content.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {93–102},
numpages = {10},
keywords = {social media mining, mental health, user modeling, self-harm detection},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{10.1145/3313831.3376370,
author = {Honary, Mahsa and Bell, Beth and Clinch, Sarah and Vega, Julio and Kroll, Leo and Sefi, Aaron and McNaney, Roisin},
title = {Shaping the Design of Smartphone-Based Interventions for Self-Harm},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376370},
doi = {10.1145/3313831.3376370},
abstract = {Self-harm is a prevalent issue amongst young people, yet it is thought around 40% will never seek professional help due to stigma surrounding it. It is generally a way of coping with emotional distress and can have a range of triggers which are highly heterogeneous to the individual. In a move towards enhancing the accessibility of personalized interventions for self-harm, we undertook a three-stage study. We first conducted interviews with 4 counsellors in self-harm to understand how they clinically respond to self-harm triggers. We then ran a survey with 37 young people, to explore perceptions of mobile sensing, and current and future uses for smartphone-based interventions. Finally, we ran a workshop with 11 young people to further explore how a context-aware self-management application might be used to support them. We contribute an in-depth understanding of how triggers for self-harm might be identified and subsequently predicted and prevented using mobile-sensing technology.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mental health, co-design, trust, self-harm, situation-aware app, non-suicidal self-injury, mobile sensing, intervention},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@article{10.1145/3359186,
author = {Pater, Jessica A. and Farrington, Brooke and Brown, Alycia and Reining, Lauren E. and Toscos, Tammy and Mynatt, Elizabeth D.},
title = {Exploring Indicators of Digital Self-Harm with Eating Disorder Patients: A Case Study},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CSCW},
url = {https://doi.org/10.1145/3359186},
doi = {10.1145/3359186},
abstract = {Digital self-harm encompasses a variety of activities, including the use of social media to facilitate or amplify mental illness-related behaviors. To understand the extent of these behaviors and their impacts, we conducted an in-depth case study with three patients who are in recovery from an eating disorder. We collected survey data, conducted interviews reflecting back to their technology use during their active disease state, and reviewed up to 18 months of their social media data leading up to the start of their initial point of recovery. Through the triangulation of this data, we explore the role of social media and social technologies in relation to their eating disorder. By utilizing this methodology, we were able to provide a contextually rich and nuanced lens for exploring the impacts of digital self-harm on this group of patients. We found that patients acknowledged that the eating disordered content on social media had a negative impact on their health, often contributing to a worsening of the physical manifestations of their disorder. Conversely, while they actively consumed this content, our participants did not produce online content related to eating disordered activities or behaviors. Finally, we discuss the patterns within their social media data and how platform designers and operators could use these findings in the future through design considerations for future platform-based interventions.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {84},
numpages = {26},
keywords = {digital self-harm, eating disorder, case study, instagram, social media, tumblr, twitter}
}

@book{Vandeveer2014,
author = {Donald Vandeveer},
doi = {doi:10.1515/9781400854066},
url = {https://doi.org/10.1515/9781400854066},
title = {Paternalistic Intervention: The Moral Bounds on Benevolence},
year = {2014},
publisher = {Princeton University Press},
ISBN = {9781400854066}
}

@article{SUZUKI198532,
title = {Topological structural analysis of digitized binary images by border following},
journal = {Computer Vision, Graphics, and Image Processing},
volume = {30},
number = {1},
pages = {32-46},
year = {1985},
issn = {0734-189X},
doi = {https://doi.org/10.1016/0734-189X(85)90016-7},
url = {https://www.sciencedirect.com/science/article/pii/0734189X85900167},
author = {Satoshi Suzuki and KeiichiA be},
abstract = {Two border following algorithms are proposed for the topological analysis of digitized binary images. The first one determines the surroundness relations among the borders of a binary image. Since the outer borders and the hole borders have a one-to-one correspondence to the connected components of 1-pixels and to the holes, respectively, the proposed algorithm yields a representation of a binary image, from which one can extract some sort of features without reconstructing the image. The second algorithm, which is a modified version of the first, follows only the outermost borders (i.e., the outer borders which are not surrounded by holes). These algorithms can be effectively used in component counting, shrinking, and topological structural analysis of binary images, when a sequential digital computer is used.}
}

@article{greaseterminator,
  author    = {Siddhartha Datta and
               Konrad Kollnig and
               Nigel Shadbolt},
  title     = {Mind-proofing Your Phone: Navigating the Digital Minefield with GreaseTerminator},
  journal   = {CoRR},
  volume    = {abs/2112.10699},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.10699},
  eprinttype = {arXiv},
  eprint    = {2112.10699},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-10699.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  numpages = 22
}


@inproceedings{vidgen-etal-2021-learning,
    title = "Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection",
    author = "Vidgen, Bertie  and
      Thrush, Tristan  and
      Waseem, Zeerak  and
      Kiela, Douwe",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.132",
    doi = "10.18653/v1/2021.acl-long.132",
    pages = "1667--1682",
    abstract = "We present a human-and-model-in-the-loop process for dynamically generating datasets and training better performing and more robust hate detection models. We provide a new dataset of 40,000 entries, generated and labelled by trained annotators over four rounds of dynamic data creation. It includes 15,000 challenging perturbations and each hateful entry has fine-grained labels for the type and target of hate. Hateful entries make up 54{\%} of the dataset, which is substantially higher than comparable datasets. We show that model performance is substantially improved using this approach. Models trained on later rounds of data collection perform better on test sets and are harder for annotators to trick. They also have better performance on HateCheck, a suite of functional tests for online hate detection. We provide the code, dataset and annotation guidelines for other researchers to use.",
}

@article{DBLP:journals/corr/abs-1907-11692,
  author    = {Yinhan Liu and
               Myle Ott and
               Naman Goyal and
               Jingfei Du and
               Mandar Joshi and
               Danqi Chen and
               Omer Levy and
               Mike Lewis and
               Luke Zettlemoyer and
               Veselin Stoyanov},
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal   = {CoRR},
  volume    = {abs/1907.11692},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.11692},
  archivePrefix = {arXiv},
  eprint    = {1907.11692},
  timestamp = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{roberta,
  title = {roberta-base},
  author = {HuggingFace},
  year = {2022},
  url = {https://huggingface.co/roberta-base},
}

@ONLINE {wikidump,
    author = "Wikimedia Foundation",
    year = {2008},
    title  = "Wikimedia Downloads",
    url    = "https://dumps.wikimedia.org"
}

@InProceedings{Zhu_2015_ICCV,
    title = {Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books},
    author = {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
    booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
    month = {December},
    year = {2015}
}

@incollection{Steinhart1998-STEDM,
	booktitle = {The Digital Phoenix: How Computers Are Changing Philosophy},
	pages = {117--134},
	author = {Eric Steinhart},
	editor = {Terrell Ward Bynum and James Moor},
	publisher = {Blackwell},
	title = {Digital Metaphysics},
	year = {1998}
}

@book{10.5555/529708,
author = {Heim, Michael Henry},
title = {The  Metaphysics of Virtual Reality},
year = {1993},
isbn = {0195081781},
publisher = {Oxford University Press, Inc.},
address = {USA},
edition = {1st}
}

@book{Rescher1991-RESGLM,
	publisher = {Routledge},
	year = {1991},
	title = {G. W. Leibniz's Monadology},
	author = {Nicholas Rescher}
}

@article{KollnigShubaBinnsVan,
author = {Konrad Kollnig and Anastasia Shuba and Reuben Binns and Max Van Kleek and Nigel Shadbolt},
doi = {doi:10.2478/popets-2022-0033},
url = {https://doi.org/10.2478/popets-2022-0033},
title = {Are iPhones Really Better for Privacy? A Comparative Study of iOS and Android Apps},
journal = {Proceedings on Privacy Enhancing Technologies},
number = {2},
volume = {2022},
year = {2022},
pages = {6--24}
}

@misc{karlgren1990algebra,
  title={An algebra for recommendations: Using reader data as a basis for measuring document proximity},
  author={Karlgren, Jussi},
  year={1990},
  publisher={Department of Computer and Systems Sciences, Stockholm University}
}

@article{Woods00,
author = {Bob Woods and Laura O'Philbin and Emma M Farrell and Aimee E Spector and Martin Orrell},
title = {Reminiscence therapy for dementia},
journal = {Cochrane Database of Systematic Reviews},
number = {3},
year = {2018},
publisher = {John Wiley & Sons, Ltd},
ISSN = {1465-1858},
DOI = {10.1002/14651858.CD001120.pub3},
keywords = {*Mental Recall; Aged; Dementia [*therapy]; Humans; Middle Aged; Orientation; Psychotherapy, Group [*methods]; Randomized Controlled Trials as Topic; Reality Therapy},
URL = {https://doi.org//10.1002/14651858.CD001120.pub3}
}

@inproceedings{
galanti2022on,
title={On the Role of Neural Collapse in Transfer Learning},
author={Tomer Galanti and Andr{\'a}s Gy{\"o}rgy and Marcus Hutter},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=SwIp410B6aQ}
}

@inproceedings{
abnar2022exploring,
title={Exploring the Limits of Large Scale Pre-training},
author={Samira Abnar and Mostafa Dehghani and Behnam Neyshabur and Hanie Sedghi},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=V3C8p78sDa}
}

@inproceedings{NEURIPS2020_0607f4c7,
 author = {Neyshabur, Behnam and Sedghi, Hanie and Zhang, Chiyuan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {512--523},
 publisher = {Curran Associates, Inc.},
 title = {What is being transferred in transfer learning? },
 url = {https://proceedings.neurips.cc/paper/2020/file/0607f4c705595b911a4f3e7a127b44e0-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{
Raghu2020Rapid,
title={Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML},
author={Aniruddh Raghu and Maithra Raghu and Samy Bengio and Oriol Vinyals},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkgMkCEtPB}
}

@misc{datta2021widen,
      title={Widen The Backdoor To Let More Attackers In}, 
      author={Siddhartha Datta and Giulio Lovisotto and Ivan Martinovic and Nigel Shadbolt},
      year={2021},
      eprint={2110.04571},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{datta2022backdoors,
      title={Backdoors Stuck At The Frontdoor: Multi-Agent Backdoor Attacks That Backfire}, 
      author={Siddhartha Datta and Nigel Shadbolt},
      year={2022},
      eprint={2201.12211},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@inproceedings{datta2021learnweight,
    title = "{L}earn2{W}eight: Parameter Adaptation against Similar-domain Adversarial Attacks",
    author = "Datta, Siddhartha",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2022.coling-1.427",
    pages = "4832--4843",
    abstract = "Recent work in black-box adversarial attacks for NLP systems has attracted attention. Prior black-box attacks assume that attackers can observe output labels from target models based on selected inputs. In this work, inspired by adversarial transferability, we propose a new type of black-box NLP adversarial attack that an attacker can choose a similar domain and transfer the adversarial examples to the target domain and cause poor performance in target model. Based on domain adaptation theory, we then propose a defensive strategy, called Learn2Weight, which trains to predict the weight adjustments for target model in order to defense the attack of similar-domain adversarial examples. Using Amazon multi-domain sentiment classification dataset, we empirically show that Learn2Weight model is effective against the attack compared to standard black-box defense methods such as adversarial training and defense distillation. This work contributes to the growing literature on machine learning safety.",
}

@misc{finn2017modelagnostic,
      title={Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks}, 
      author={Chelsea Finn and Pieter Abbeel and Sergey Levine},
      year={2017},
      eprint={1703.03400},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{10.1145/3479600,
author = {Cho, Hyunsung and Choi, DaEun and Kim, Donghwi and Kang, Wan Ju and Choe, Eun Kyoung and Lee, Sung-Ju},
title = {Reflect, Not Regret: Understanding Regretful Smartphone Use with App Feature-Level Analysis},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW2},
url = {https://doi.org/10.1145/3479600},
doi = {10.1145/3479600},
abstract = {Digital intervention tools against problematic smartphone usage help users control their consumption on smartphones, for example, by setting a time limit on an app. However, today's social media apps offer a mix of quasiessential and addictive features in an app (e.g., Instagram has following feeds, recommended feeds, stories, and direct messaging features), which makes it hard to apply a uniform logic for all uses of an app without a nuanced understanding of feature-level usage behaviors. We study when and why people regret using different features of social media apps on smartphones. We examine regretful feature uses in four smartphone social media apps (Facebook, Instagram, YouTube, and KakaoTalk) by utilizing feature usage logs, ESM surveys on regretful use collected for a week, and retrospective interviews from 29 Android users. In determining whether a feature use is regretful, users considered different types of rewards they obtained from using a certain feature (i.e., social, informational, personal interests, and entertainment) as well as alternative rewards they could have gained had they not used the smartphone (e.g., productivity). Depending on the types of rewards and the way rewards are presented to users, probabilities to regret vary across features of the same app. We highlight three patterns of features with different characteristics that lead to regretful use. First, "following"-based features (e.g., Facebook's News Feed and Instagram's Following Posts and Stories) induce habitual checking and quickly deplete rewards from app use. Second, recommendation-based features situated close to actively used features (e.g., Instagram's Suggested Posts adjacent to Search) cause habitual feature tour and sidetracking from the original intention of app use. Third, recommendation-based features with bite-sized contents (e.g., Facebook's Watch Videos) induce using "just a bit more," making people fall into prolonged use. We discuss implications of our findings for how social media apps and intervention tools can be designed to reduce regretful use and how feature-level usage information can strengthen self-reflection and behavior changes.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {oct},
articleno = {456},
numpages = {36},
keywords = {digital wellbeing, social media, smartphone use, regret, app feature}
}

@inbook{10.1145/3313831.3376672,
author = {Lyngs, Ulrik and Lukoff, Kai and Slovak, Petr and Seymour, William and Webb, Helena and Jirotka, Marina and Zhao, Jun and Van Kleek, Max and Shadbolt, Nigel},
title = { 'I Just Want to Hack Myself to Not Get Distracted': Evaluating Design Interventions for Self-Control on Facebook},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376672},
abstract = {Beyond being the world's largest social network, Facebook is for many also one of its greatest sources of digital distraction. For students, problematic use has been associated with negative effects on academic achievement and general wellbeing. To understand what strategies could help users regain control, we investigated how simple interventions to the Facebook UI affect behaviour and perceived control. We assigned 58 university students to one of three interventions: goal reminders, removed newsfeed, or white background (control). We logged use for 6 weeks, applied interventions in the middle weeks, and administered fortnightly surveys. Both goal reminders and removed newsfeed helped participants stay on task and avoid distraction. However, goal reminders were often annoying, and removing the newsfeed made some fear missing out on information. Our findings point to future interventions such as controls for adjusting types and amount of available information, and flexible blocking which matches individual definitions of 'distraction'.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@misc{chromewebstore,
  title = {Chrome Web Store},
  author = {Google},
  year = {2010},
  url = {https://chrome.google.com/webstore/},
}

@article{e1b52b8c74c04b46932c8b36e8880c0e,
title = "Time for the Human Screenome Project",
abstract = "To understand how people use digital media, researchers need to move beyond screen time and capture everything we do and see on our screens. [Figure not available: see fulltext.].",
author = "Byron Reeves and Thomas Robinson and Nilam Ram",
note = "Funding Information: The US National Institutes of Health (NIH) is Publisher Copyright: {\textcopyright} 2020, Nature.",
year = "2020",
month = jan,
day = "16",
doi = "10.1038/d41586-020-00032-5",
language = "English (US)",
volume = "577",
pages = "314--317",
journal = "Nature",
issn = "0028-0836",
publisher = "Nature Publishing Group",
number = "7790",
}

@article{doi:10.1080/07370024.2019.1578652,
author = {Byron Reeves and Nilam Ram and Thomas N. Robinson and James J. Cummings and C. Lee Giles and Jennifer Pan and Agnese Chiatti and Mj Cho and Katie Roehrick and Xiao Yang and Anupriya Gagneja and Miriam Brinberg and Daniel Muise and Yingdan Lu and Mufan Luo and Andrew Fitzgerald and Leo Yeykelis},
title = {Screenomics: A Framework to Capture and Analyze Personal Life Experiences and the Ways that Technology Shapes Them},
journal = {Human–Computer Interaction},
volume = {36},
number = {2},
pages = {150-201},
year  = {2021},
publisher = {Taylor & Francis},
doi = {10.1080/07370024.2019.1578652},
    note ={PMID: 33867652},

URL = { 
        https://doi.org/10.1080/07370024.2019.1578652
    
},
eprint = { 
        https://doi.org/10.1080/07370024.2019.1578652
    
}

}

@inproceedings{aghajanyan-etal-2021-intrinsic,
    title = "Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning",
    author = "Aghajanyan, Armen  and
      Gupta, Sonal  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.568",
    doi = "10.18653/v1/2021.acl-long.568",
    pages = "7319--7328",
    abstract = "Although pretrained language models can be fine-tuned to produce state-of-the-art results for a very wide range of language understanding tasks, the dynamics of this process are not well understood, especially in the low data regime. Why can we use relatively vanilla gradient descent algorithms (e.g., without strong regularization) to tune a model with hundreds of millions of parameters on datasets with only hundreds or thousands of labeled examples? In this paper, we argue that analyzing fine-tuning through the lens of intrinsic dimension provides us with empirical and theoretical intuitions to explain this remarkable phenomenon. We empirically show that common pre-trained models have a very low intrinsic dimension; in other words, there exists a low dimension reparameterization that is as effective for fine-tuning as the full parameter space. For example, by optimizing only 200 trainable parameters randomly projected back into the full space, we can tune a RoBERTa model to achieve 90{\%} of the full parameter performance levels on MRPC. Furthermore, we empirically show that pre-training implicitly minimizes intrinsic dimension and, perhaps surprisingly, larger models tend to have lower intrinsic dimension after a fixed number of pre-training updates, at least in part explaining their extreme effectiveness. Lastly, we connect intrinsic dimensionality with low dimensional task representations and compression based generalization bounds to provide intrinsic-dimension-based generalization bounds that are independent of the full parameter count.",
}

@inproceedings{10.1145/3490099.3511117,
author = {Sanchez, T\'{e}o and Caramiaux, Baptiste and Thiel, Pierre and Mackay, Wendy E.},
title = {Deep Learning Uncertainty in Machine Teaching},
year = {2022},
isbn = {9781450391443},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490099.3511117},
doi = {10.1145/3490099.3511117},
abstract = {Machine Learning models can output confident but incorrect predictions. To address this problem, ML researchers use various techniques to reliably estimate ML uncertainty, usually performed on controlled benchmarks once the model has been trained. We explore how the two types of uncertainty—aleatoric and epistemic—can help non-expert users understand the strengths and weaknesses of a classifier in an interactive setting. We are interested in users’ perception of the difference between aleatoric and epistemic uncertainty and their use to teach and understand the classifier. We conducted an experiment where non-experts train a classifier to recognize card images, and are tested on their ability to predict classifier outcomes. Participants who used either larger or more varied training sets significantly improved their understanding of uncertainty, both epistemic or aleatoric. However, participants who relied on the uncertainty measure to guide their choice of training data did not significantly improve classifier training, nor were they better able to guess the classifier outcome. We identified three specific situations where participants successfully identified the difference between aleatoric and epistemic uncertainty: placing a card in the exact same position as a training card; placing different cards next to each other; and placing a non-card, such as their hand, next to or on top of a card. We discuss our methodology for estimating uncertainty for Interactive Machine Learning systems and question the need for two-level uncertainty in Machine Teaching. },
booktitle = {27th International Conference on Intelligent User Interfaces},
pages = {173–190},
numpages = {18},
keywords = {Interactive Machine Learning, ML uncertainty, Machine Teaching, Human-AI Interaction, Human-centered analysis},
location = {Helsinki, Finland},
series = {IUI '22}
}

@inproceedings{10.1145/3292500.3330773,
author = {Zhang, Shanshan and He, Lihong and Dragut, Eduard and Vucetic, Slobodan},
title = {How to Invest My Time: Lessons from Human-in-the-Loop Entity Extraction},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330773},
doi = {10.1145/3292500.3330773},
abstract = {Recognizing entities that follow or closely resemble a regular expression (regex) pattern is an important task in information extraction. Common approaches for extraction of such entities require humans to either write a regex recognizing an entity or manually label entity mentions in a document corpus. While human effort is critical to build an entity recognition model, surprisingly little is known about how to best invest that effort given a limited time budget. To get an answer, we consider an iterative human-in-the-loop (HIL) framework that allows users to write a regex or manually label entity mentions, followed by training and refining a classifier based on the provided information. We demonstrate on 5 entity recognition tasks that classification accuracy improves over time with either approach. When a user is allowed to choose between regex construction and manual labeling, we discover that (1) if the time budget is low, spending all time for regex construction is often advantageous, (2) if the time budget is high, spending all time for manual labeling seems to be superior, and (3) between those two extremes, writing regexes followed by manual labeling is typically the best approach. Our code and data is available at https://github.com/nymph332088/HILRecognizer.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {2305–2313},
numpages = {9},
keywords = {human-in-the-loop, regex, entity extraction, neural networks},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@article{wallace-etal-2019-trick,
    title = "Trick Me If You Can: Human-in-the-Loop Generation of Adversarial Examples for Question Answering",
    author = "Wallace, Eric  and
      Rodriguez, Pedro  and
      Feng, Shi  and
      Yamada, Ikuya  and
      Boyd-Graber, Jordan",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    year = "2019",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q19-1029",
    doi = "10.1162/tacl_a_00279",
    pages = "387--401",
    abstract = "Adversarial evaluation stress-tests a model{'}s understanding of natural language. Because past approaches expose superficial patterns, the resulting adversarial examples are limited in complexity and diversity. We propose human- in-the-loop adversarial generation, where human authors are guided to break models. We aid the authors with interpretations of model predictions through an interactive user interface. We apply this generation framework to a question answering task called Quizbowl, where trivia enthusiasts craft adversarial questions. The resulting questions are validated via live human{--}computer matches: Although the questions appear ordinary to humans, they systematically stump neural and information retrieval models. The adversarial questions cover diverse phenomena from multi-hop reasoning to entity type distractors, exposing open challenges in robust question answering.",
}

@misc{https://doi.org/10.48550/arxiv.2108.00941,
  doi = {10.48550/ARXIV.2108.00941},
  
  url = {https://arxiv.org/abs/2108.00941},
  
  author = {Wu, Xingjiao and Xiao, Luwei and Sun, Yixuan and Zhang, Junhang and Ma, Tianlong and He, Liang},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A Survey of Human-in-the-loop for Machine Learning},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{datta2022low,
  title={Low-Loss Subspace Compression for Clean Gains against Multi-Agent Backdoor Attacks},
  author={Datta, Siddhartha and Shadbolt, Nigel},
  journal={arXiv preprint arXiv:2203.03692},
  year={2022}
}

@INPROCEEDINGS{9157772,  author={Simon, Christian and Koniusz, Piotr and Nock, Richard and Harandi, Mehrtash},  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Adaptive Subspaces for Few-Shot Learning},   year={2020},  volume={},  number={},  pages={4135-4144},  doi={10.1109/CVPR42600.2020.00419}}

@inproceedings{10.1145/3126594.3126651,
author = {Deka, Biplab and Huang, Zifeng and Franzen, Chad and Hibschman, Joshua and Afergan, Daniel and Li, Yang and Nichols, Jeffrey and Kumar, Ranjitha},
title = {Rico: A Mobile App Dataset for Building Data-Driven Design Applications},
year = {2017},
isbn = {9781450349819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3126594.3126651},
doi = {10.1145/3126594.3126651},
abstract = {Data-driven models help mobile app designers understand best practices and trends, and can be used to make predictions about design performance and support the creation of adaptive UIs. This paper presents Rico, the largest repository of mobile app designs to date, created to support five classes of data-driven applications: design search, UI layout generation, UI code generation, user interaction modeling, and user perception prediction. To create Rico, we built a system that combines crowdsourcing and automation to scalably mine design and interaction data from Android apps at runtime. The Rico dataset contains design data from more than 9.7k Android apps spanning 27 categories. It exposes visual, textual, structural, and interactive design properties of more than 72k unique UI screens. To demonstrate the kinds of applications that Rico enables, we present results from training an autoencoder for UI layout similarity, which supports query- by-example search over UIs.},
booktitle = {Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology},
pages = {845–854},
numpages = {10},
keywords = {app datasets, design search, design mining, mobile app design},
location = {Qu\'{e}bec City, QC, Canada},
series = {UIST '17}
}

@article{Luo2021CharacteristicsAC,
  title={Characteristics and Challenges of Low-Code Development: The Practitioners' Perspective},
  author={Yajing Luo and Peng Liang and Chong Wang and Mojtaba Shahin and Jing Zhan},
  journal={Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
  year={2021}
}

@conference {actionbert , title = {Actionbert: leveraging user actions for semantic understanding of user interfaces}, year = {2021}, author = {Zecheng He and Srinivas Sunkara and Xiaoxue Zang and Ying Xu and Lijuan Liu and Nevan Wichers and Gabriel Schubiner and Ruby B. Lee and Jindong Chen} }

@inproceedings{74ffee915d6e4089bbe9f3ef3196ec8f,
title = "GUIGAN: learning to generate GUI designs using generative adversarial networks",
abstract = "Graphical User Interface (GUI) is ubiquitous in almost all modern desktop software, mobile applications and online websites. A good GUI design is crucial to the success of the software in the market, but designing a good GUI which requires much innovation and creativity is difficult even to well-trained designers. In addition, the requirement of rapid development of GUI design also aggravates designers' working load. So, the availability of various automated generated GUIs can help enhance the design personalization and specialization as they can cater to the taste of different designers. To assist designers, we develop a model tool to automatically generate GUI designs. Different from conventional image generation models based on image pixels, our tool is to reuse GUI components collected from existing mobile app GUIs for composing a new design which is similar to natural-language generation. Our tool is based on SeqGAN by modelling the GUI component style compatibility and GUI structure. The evaluation demonstrates that our model significantly outperforms the best of the baseline methods by 30.77% in Fr'echet Inception distance (FID) and 12.35% in 1-Nearest Neighbor Accuracy (1-NNA). Through a pilot user study, we provide initial evidence of the usefulness of our approach for generating acceptable brand new GUI designs. ",
keywords = "Deep learning, Generative Adversarial Network, Graphical User Interface, GUI design, Mobile application",
author = "Tianming Zhao and Chunyang Chen and Yuanning Liu and Xiaodong Zhu",
note = "Publisher Copyright: {\textcopyright} 2021 IEEE. Copyright: Copyright 2021 Elsevier B.V., All rights reserved.; International Conference on Software Engineering 2021, ICSE 2021 ; Conference date: 25-05-2021 Through 28-05-2021",
year = "2021",
doi = "10.1109/ICSE43902.2021.00074",
language = "English",
isbn = "9781665402965",
series = "Proceedings - International Conference on Software Engineering",
publisher = "IEEE, Institute of Electrical and Electronics Engineers",
pages = "748--760",
editor = "{van Deursen}, Arie and Tao Xie",
booktitle = "Proceedings - 2021 IEEE/ACM 43rd International Conference on Software Engineering, ICSE 2021",
address = "United States of America",
url = "https://conf.researchr.org/committee/icse-2021/icse-2021-organizing-committe, https://conf.researchr.org/home/icse-2021, https://ieeexplore-ieee-org.ezproxy.lib.monash.edu.au/xpl/conhome/9401806/proceeding",
}

@inproceedings{10.1145/3220134.3220135,
author = {Beltramelli, Tony},
title = {Pix2code: Generating Code from a Graphical User Interface Screenshot},
year = {2018},
isbn = {9781450358972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3220134.3220135},
doi = {10.1145/3220134.3220135},
abstract = {Transforming a graphical user interface screenshot created by a designer into computer code is a typical task conducted by a developer in order to build customized software, websites, and mobile applications. In this paper, we show that deep learning methods can be leveraged to train a model end-to-end to automatically reverse engineer user interfaces and generate code from a single input image with over 77% of accuracy for three different platforms (i.e. iOS, Android and web-based technologies).},
booktitle = {Proceedings of the ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
articleno = {3},
numpages = {6},
keywords = {Deep Neural Networks, Automated Software Engineering, User Interface Reverse Engineering},
location = {Paris, France},
series = {EICS '18}
}

@inproceedings{10.1145/2509136.2509552,
author = {Choi, Wontae and Necula, George and Sen, Koushik},
title = {Guided GUI Testing of Android Apps with Minimal Restart and Approximate Learning},
year = {2013},
isbn = {9781450323741},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2509136.2509552},
doi = {10.1145/2509136.2509552},
abstract = {Smartphones and tablets with rich graphical user interfaces (GUI) are becoming increasingly popular. Hundreds of thousands of specialized applications, called apps, are available for such mobile platforms. Manual testing is the most popular technique for testing graphical user interfaces of such apps. Manual testing is often tedious and error-prone. In this paper, we propose an automated technique, called Swift-Hand, for generating sequences of test inputs for Android apps. The technique uses machine learning to learn a model of the app during testing, uses the learned model to generate user inputs that visit unexplored states of the app, and uses the execution of the app on the generated inputs to refine the model. A key feature of the testing algorithm is that it avoids restarting the app, which is a significantly more expensive operation than executing the app on a sequence of inputs. An important insight behind our testing algorithm is that we do not need to learn a precise model of an app, which is often computationally intensive, if our goal is to simply guide test execution into unexplored parts of the state space. We have implemented our testing algorithm in a publicly available tool for Android apps written in Java. Our experimental results show that we can achieve significantly better coverage than traditional random testing and L*-based testing in a given time budget. Our algorithm also reaches peak coverage faster than both random and L*-based testing.},
booktitle = {Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages &amp; Applications},
pages = {623–640},
numpages = {18},
keywords = {automata, gui testing, learning, android},
location = {Indianapolis, Indiana, USA},
series = {OOPSLA '13}
}

@article{10.1145/2544173.2509552,
author = {Choi, Wontae and Necula, George and Sen, Koushik},
title = {Guided GUI Testing of Android Apps with Minimal Restart and Approximate Learning},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/2544173.2509552},
doi = {10.1145/2544173.2509552},
abstract = {Smartphones and tablets with rich graphical user interfaces (GUI) are becoming increasingly popular. Hundreds of thousands of specialized applications, called apps, are available for such mobile platforms. Manual testing is the most popular technique for testing graphical user interfaces of such apps. Manual testing is often tedious and error-prone. In this paper, we propose an automated technique, called Swift-Hand, for generating sequences of test inputs for Android apps. The technique uses machine learning to learn a model of the app during testing, uses the learned model to generate user inputs that visit unexplored states of the app, and uses the execution of the app on the generated inputs to refine the model. A key feature of the testing algorithm is that it avoids restarting the app, which is a significantly more expensive operation than executing the app on a sequence of inputs. An important insight behind our testing algorithm is that we do not need to learn a precise model of an app, which is often computationally intensive, if our goal is to simply guide test execution into unexplored parts of the state space. We have implemented our testing algorithm in a publicly available tool for Android apps written in Java. Our experimental results show that we can achieve significantly better coverage than traditional random testing and L*-based testing in a given time budget. Our algorithm also reaches peak coverage faster than both random and L*-based testing.},
journal = {SIGPLAN Not.},
month = {oct},
pages = {623–640},
numpages = {18},
keywords = {automata, android, gui testing, learning}
}

@inproceedings{10.1145/3411764.3445049,
author = {Li, Toby Jia-Jun and Popowski, Lindsay and Mitchell, Tom and Myers, Brad A},
title = {Screen2Vec: Semantic Embedding of GUI Screens and GUI Components},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445049},
doi = {10.1145/3411764.3445049},
abstract = { Representing the semantics of GUI screens and components is crucial to data-driven computational methods for modeling user-GUI interactions and mining GUI designs. Existing GUI semantic representations are limited to encoding either the textual content, the visual design and layout patterns, or the app contexts. Many representation techniques also require significant manual data annotation efforts. This paper presents Screen2Vec, a new self-supervised technique for generating representations in embedding vectors of GUI screens and components that encode all of the above GUI features without requiring manual annotation using the context of user interaction traces. Screen2Vec is inspired by the word embedding method Word2Vec, but uses a new two-layer pipeline informed by the structure of GUIs and interaction traces and incorporates screen- and app-specific metadata. Through several sample downstream tasks, we demonstrate Screen2Vec’s key useful properties: representing between-screen similarity through nearest neighbors, composability, and capability to represent user tasks. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {578},
numpages = {15},
keywords = {interaction mining, screen semantics, GUI embedding},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inbook{10.1145/3313831.3376589,
author = {Duan, Peitong and Wierzynski, Casimir and Nachman, Lama},
title = {Optimizing User Interface Layouts via Gradient Descent},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376589},
abstract = {Automating parts of the user interface (UI) design process has been a longstanding challenge. We present an automated technique for optimizing the layouts of mobile UIs. Our method uses gradient descent on a neural network model of task performance with respect to the model's inputs to make layout modifications that result in improved predicted error rates and task completion times. We start by extending prior work on neural network based performance prediction to 2-dimensional mobile UIs with an expanded interaction space. We then apply our method to two UIs, including one that the model had not been trained on, to discover layout alternatives with significantly improved predicted performance. Finally, we confirm these predictions experimentally, showing improvements up to 9.2 percent in the optimized layouts. This demonstrates the algorithm's efficacy in improving the task performance of a layout, and its ability to generalize and improve layouts of new interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3290607.3313089,
author = {Yang, Xiao and Ram, Nilam and Robinson, Thomas and Reeves, Byron},
title = {Using Screenshots to Predict Task Switching on Smartphones},
year = {2019},
isbn = {9781450359719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290607.3313089},
doi = {10.1145/3290607.3313089},
abstract = {Mobile phone use is pervasive, yet little is known about task switching on digital platforms and applications. We propose an unobtrusive experience sampling method to observe how individuals use their smartphones by taking screenshots every 5 seconds when the device is on. The purpose of this paper is to incorporate the psychological process into feature extraction, and use these features to effectively predict the task switching behavior on smartphones. Features are extracted from the sequence of screenshots, gauging visual stimulation, cognitive load, velocity and accumulation, sentiment, and time-related factors. Labels of task switching behavior were manually tagged for 87,182 screenshots from 60 subjects. Using random forest, we demonstrate that we can correctly infer a user's task switching behavior from unstructured data in screenshots with up to 77% accuracy, demonstrating it is a viable option to use features of the screenshots to predict task switching behavior.},
booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {screenshots, unobtrusive experience sampling, task switching},
location = {Glasgow, Scotland Uk},
series = {CHI EA '19}
}

@inproceedings{10.1145/3472749.3474763,
author = {Wu, Jason and Zhang, Xiaoyi and Nichols, Jeff and Bigham, Jeffrey P},
title = {Screen Parsing: Towards Reverse Engineering of UI Models from Screenshots},
year = {2021},
isbn = {9781450386357},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472749.3474763},
doi = {10.1145/3472749.3474763},
abstract = { Automated understanding of user interfaces (UIs) from their pixels can improve accessibility, enable task automation, and facilitate interface design without relying on developers to comprehensively provide metadata. A first step is to infer what UI elements exist on a screen, but current approaches are limited in how they infer how those elements are semantically grouped into structured interface definitions. In this paper, we motivate the problem of screen parsing, the task of predicting UI elements and their relationships from a screenshot. We describe our implementation of screen parsing and provide an effective training procedure that optimizes its performance. In an evaluation comparing the accuracy of the generated output, we find that our implementation significantly outperforms current systems (up to 23%). Finally, we show three example applications that are facilitated by screen parsing: (i) UI similarity search, (ii) accessibility enhancement, and (iii) code generation from UI screenshots.},
booktitle = {The 34th Annual ACM Symposium on User Interface Software and Technology},
pages = {470–483},
numpages = {14},
keywords = {ui semantics, hierarchy prediction, user interface modeling},
location = {Virtual Event, USA},
series = {UIST '21}
}

@misc{identiswap,
  author = {Konrad Kollnig},
  title = {IdentiSwap},
  year = {2021},
  url = {https://github.com/kasnder/identiswap},
}

@misc{horizon,
  author = {Meta},
  title = {Meta Horizon Workrooms},
  year = {2022},
  url = {https://www.meta.com/gb/work/workrooms/},
}

@misc{aib,
  author = {Andrey Ignatov},
  title = {AI-Benchmark},
  year = {2021},
  url = {https://ai-benchmark.com/ranking_deeplearning_detailed.html/},
}

@misc{cardboard,
  author = {Google},
  title = {Google Cardboard},
  year = {2022},
  url = {https://arvr.google.com/cardboard/},
}


@ARTICLE{9552430,
author={Strobelt, Hendrik and Kinley, Jambay and Krueger, Robert and Beyer, Johanna and Pfister, Hanspeter and Rush, Alexander M.},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={GenNI: Human-AI Collaboration for Data-Backed Text Generation},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Table2Text systems generate textual output based on structured data utilizing machine learning. These systems are essential for fluent natural language interfaces in tools such as virtual assistants; however, left to generate freely these ML systems often produce misleading or unexpected outputs. GenNI (Generation Negotiation Interface) is an interactive visual system for high-level human-AI collaboration in producing descriptive text. The tool utilizes a deep learning model designed with explicit control states. These controls allow users to globally constrain model generations, without sacrificing the representation power of the deep learning models. The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable. We report multiple use cases on two experiments that improve over uncontrolled generation approaches, while at the same time providing fine-grained control. A demo and source code are available at https://genni.vizhub.ai.},
keywords={},
doi={10.1109/TVCG.2021.3114845},
ISSN={1941-0506},
month={},}

@inproceedings{10.1145/1294211.1294256,
author = {Olsen, Dan R.},
title = {Evaluating User Interface Systems Research},
year = {2007},
isbn = {9781595936790},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1294211.1294256},
doi = {10.1145/1294211.1294256},
abstract = {The development of user interface systems has languished with the stability of desktop computing. Future systems, however, that are off-the-desktop, nomadic or physical in nature will involve new devices and new software systems for creating interactive applications. Simple usability testing is not adequate for evaluating complex systems. The problems with evaluating systems work are explored and a set of criteria for evaluating new UI systems work is presented.},
booktitle = {Proceedings of the 20th Annual ACM Symposium on User Interface Software and Technology},
pages = {251–258},
numpages = {8},
keywords = {user interface systems evaluation},
location = {Newport, Rhode Island, USA},
series = {UIST '07}
}

@inbook{10.1145/3173574.3173610,
author = {Ledo, David and Houben, Steven and Vermeulen, Jo and Marquardt, Nicolai and Oehlberg, Lora and Greenberg, Saul},
title = {Evaluation Strategies for HCI Toolkit Research},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173610},
abstract = {Toolkit research plays an important role in the field of HCI, as it can heavily influence both the design and implementation of interactive systems. For publication, the HCI community typically expects toolkit research to include an evaluation component. The problem is that toolkit evaluation is challenging, as it is often unclear what 'evaluating' a toolkit means and what methods are appropriate. To address this problem, we analyzed 68 published toolkit papers. From our analysis, we provide an overview of, reflection on, and discussion of evaluation methods for toolkit contributions. We identify and discuss the value of four toolkit evaluation strategies, including the associated techniques that each employs. We offer a categorization of evaluation strategies for toolkit researchers, along with a discussion of the value, potential limitations, and trade-offs associated with each strategy.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17}
}

@article{kishino,
author = {Milgram, Paul and Kishino, Fumio},
year = {1994},
month = {12},
pages = {1321-1329},
title = {A Taxonomy of Mixed Reality Visual Displays},
volume = {vol. E77-D, no. 12},
journal = {IEICE Trans. Information Systems}
}

@inproceedings{10.1145/3173574.3173703,
author = {Lindlbauer, David and Wilson, Andy D.},
title = {Remixed Reality: Manipulating Space and Time in Augmented Reality},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173703},
doi = {10.1145/3173574.3173703},
abstract = {We present Remixed Reality, a novel form of mixed reality. In contrast to classical mixed reality approaches where users see a direct view or video feed of their environment, with Remixed Reality they see a live 3D reconstruction, gathered from multiple external depth cameras. This approach enables changing the environment as easily as geometry can be changed in virtual reality, while allowing users to view and interact with the actual physical world as they would in augmented reality. We characterize a taxonomy of manipulations that are possible with Remixed Reality: spatial changes such as erasing objects; appearance changes such as changing textures; temporal changes such as pausing time; and viewpoint changes that allow users to see the world from different points without changing their physical location. We contribute a method that uses an underlying voxel grid holding information like visibility and transformations, which is applied to live geometry in real time.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, remixed reality, augmented reality},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3126594.3126601,
author = {Yue, Ya-Ting and Yang, Yong-Liang and Ren, Gang and Wang, Wenping},
title = {SceneCtrl: Mixed Reality Enhancement via Efficient Scene Editing},
year = {2017},
isbn = {9781450349819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3126594.3126601},
doi = {10.1145/3126594.3126601},
abstract = {Due to the development of 3D sensing and modeling techniques, the state-of-the-art mixed reality devices such as Microsoft Hololens have the ability of digitalizing the physical world. This unique feature bridges the gap between virtuality and reality and largely elevates the user experience. Unfortunately, the current solution only performs well if the virtual contents complement the real scene. It can easily cause visual artifacts when the reality needs to be modified due to the virtuality (e.g., remove real objects to offer more space for virtual objects), a common scenario in mixed reality applications such as room redecoration and environment design. We present a novel system, called emph{SceneCtrl}, that allows the user to interactively edit the real scene sensed by Hololens, such that the reality can be adapted to suit virtuality. Our proof-of-concept prototype employs scene reconstruction and understanding to enable efficient editing such as deleting, moving, and copying real objects in the scene. We also demonstrate emph{SceneCtrl} on a number of example scenarios in mixed reality, verifying the enhanced experience by resolving conflicts between virtuality and reality.},
booktitle = {Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology},
pages = {427–436},
numpages = {10},
keywords = {scene editing, mixed reality, enhanced experience},
location = {Qu\'{e}bec City, QC, Canada},
series = {UIST '17}
}

@inproceedings{10.1109/ISMAR.2012.6402551,
author = {Herling, Jan and Broll, Wolfgang},
title = {PixMix: A Real-Time Approach to High-Quality Diminished Reality},
year = {2012},
isbn = {9781467346603},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISMAR.2012.6402551},
doi = {10.1109/ISMAR.2012.6402551},
abstract = {Diminished Reality (DR) allows to remove objects from a video stream while preseving a frame to frame coherence. Some approaches apply a pseudo-DR, allowing for the removal of objects only, while their background can be observed by a second camera. Most real DR approaches are highly computational expensive, not even allowing for interactive rates and/or apply significant restrictions regarding the uniformity of the background, or allow linear camera movements or even a static camera only. In this paper we will present a real-time capable Diminished Reality approach for high-quality image manipulation. Our approach achieves a significantly better performance and image quality for almost planar but non-trivial image backgrounds. Our Diminished Reality pipeline provides coherent video streams even for nonlinear camera movements due to the integration of homography based object tracking.},
booktitle = {Proceedings of the 2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
pages = {141–150},
numpages = {10},
keywords = {Visualization, Artificial, Cost function, Cameras, Methodology and Techniques, Image segmentation, and virtual realities, Coherence, Real-time systems, Streaming media, Applications, augmented},
series = {ISMAR '12}
}

@inproceedings{10.1145/215585.215639,
author = {Rekimoto, Jun and Nagao, Katashi},
title = {The World through the Computer: Computer Augmented Interaction with Real World Environments},
year = {1995},
isbn = {089791709X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/215585.215639},
doi = {10.1145/215585.215639},
booktitle = {Proceedings of the 8th Annual ACM Symposium on User Interface and Software Technology},
pages = {29–36},
numpages = {8},
keywords = {user-Interface software and technology, computer augmented environments, augmented reality, palmtop computers, ubiquitous computing, barcode},
location = {Pittsburgh, Pennsylvania, USA},
series = {UIST '95}
}

@inproceedings{10.1145/3491102.3501821,
author = {Gruenefeld, Uwe and Auda, Jonas and Mathis, Florian and Schneegass, Stefan and Khamis, Mohamed and Gugenheimer, Jan and Mayer, Sven},
title = {VRception: Rapid Prototyping of Cross-Reality Systems in Virtual Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501821},
doi = {10.1145/3491102.3501821},
abstract = {Cross-reality systems empower users to transition along the reality-virtuality continuum or collaborate with others experiencing different manifestations of it. However, prototyping these systems is challenging, as it requires sophisticated technical skills, time, and often expensive hardware. We present VRception, a concept and toolkit for quick and easy prototyping of cross-reality systems. By simulating all levels of the reality-virtuality continuum entirely in Virtual Reality, our concept overcomes the asynchronicity of realities, eliminating technical obstacles. Our VRception Toolkit leverages this concept to allow rapid prototyping of cross-reality systems and easy remixing of elements from all continuum levels. We replicated six cross-reality papers using our toolkit and presented them to their authors. Interviews with them revealed that our toolkit sufficiently replicates their core functionalities and allows quick iterations. Additionally, remote participants used our toolkit in pairs to collaboratively implement prototypes in about eight minutes that they would have otherwise expected to take days.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {611},
numpages = {15},
keywords = {Augmented Reality, Transitional Interfaces, Prototyping, Virtual Reality, Cross-Reality Systems},
location = {New Orleans, LA, USA},
series = {CHI '22}
}


@inproceedings{10.1145/3491102.3517665,
author = {Qian, Xun and He, Fengming and Hu, Xiyun and Wang, Tianyi and Ipsita, Ananya and Ramani, Karthik},
title = {ScalAR: Authoring Semantically Adaptive Augmented Reality Experiences in Virtual Reality},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517665},
doi = {10.1145/3491102.3517665},
abstract = {Augmented Reality (AR) experiences tightly associate virtual contents with environmental entities. However, the dissimilarity of different environments limits the adaptive AR content behaviors under large-scale deployment. We propose ScalAR, an integrated workflow enabling designers to author semantically adaptive AR experiences in Virtual Reality (VR). First, potential AR consumers collect local scenes with a semantic understanding technique. ScalAR then synthesizes numerous similar scenes. In VR, a designer authors the AR contents’ semantic associations and validates the design while being immersed in the provided scenes. We adopt a decision-tree-based algorithm to fit the designer’s demonstrations as a semantic adaptation model to deploy the authored AR experience in a physical scene. We further showcase two application scenarios authored by ScalAR and conduct a two-session user study where the quantitative results prove the accuracy of the AR content rendering and the qualitative results show the usability of ScalAR.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {65},
numpages = {18},
keywords = {Augmented Reality, Semantic Understanding, Virtual Reality, Adaptation, Immersive Authoring},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@article{mann1994,
  title={Mediated reality},
  author={Mann, Steve},
  journal={Technical Report},
  year={1994},
  publisher={ITML Percom TR-260, University of Toronto}
}

@article{mann2001videoorbits,
  title={Videoorbits on eye tap devices for deliberately diminished reality or altering the visual perception of rigid planar patches of a real world scene},
  author={Mann, Steve and Fung, James},
  journal={EYE},
  volume={3},
  pages={P3},
  year={2001},
  publisher={Citeseer}
}

@article{10.1162/1054746021470603,
author = {Mann, Steve and Fung, James},
title = {EyeTap Devices for Augmented, Deliberately Diminished, or Otherwise Altered Visual Perception of Rigid Planar Patches of Real-World Scenes},
year = {2002},
issue_date = {April 2002},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {11},
number = {2},
issn = {1054-7460},
url = {https://doi.org/10.1162/1054746021470603},
doi = {10.1162/1054746021470603},
abstract = {Diminished reality is as important as augmented reality, and both are possible with a device called the Reality Mediator. Over the past two decades, we have designed, built, worn, and tested many different embodiments of this device in the context of wearable computing, Incorporated into the Reality Mediator is an "EyeTap" system, which is a device that quantifies and resynthesizes light that would otherwise pass through one or both lenses of the eye(s) of a wearer. The functional principles of EyeTap devices are discussed, in detail. The EyeTap diverts into a spatial measurement system at least a portion of light that would otherwise pass through the center of projection of at least one lens of an eye of a wearer. The Reality Mediator has at least one mode of operation in which it reconstructs these rays of light, under the control of a wearable computer system. The computer system then uses new results in algebraic projective geometry and comparametric equations to perform head tracking, as well as to track motion of rigid planar patches present in the scene. We describe how our tracking algorithm allows an EyeTap to alter the light from a particular portion of the scene to give rise to a computer-controlled, selectively mediated reality. An important difference between mediated reality and augmented reality includes the ability to not just augment but also deliberately diminish or otherwise alter the visual perception of reality. For example, diminished reality allows additional information to be inserted without causing the user to experience information overload. Our tracking algorithm also takes into account the effects of automatic gain control, by performing motion estimation in both spatial as well as tonal motion coordinates.},
journal = {Presence: Teleoper. Virtual Environ.},
month = {apr},
pages = {158–175},
numpages = {18}
}

@inproceedings{lester-etal-2021-power,
    title = "The Power of Scale for Parameter-Efficient Prompt Tuning",
    author = "Lester, Brian  and
      Al-Rfou, Rami  and
      Constant, Noah",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.243",
    doi = "10.18653/v1/2021.emnlp-main.243",
    pages = "3045--3059",
    abstract = "In this work, we explore {``}prompt tuning,{''} a simple yet effective mechanism for learning {``}soft prompts{''} to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signals from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3{'}s few-shot learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method {``}closes the gap{''} and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant because large models are costly to share and serve and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed {``}prefix tuning{''} of Li and Liang (2021) and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient {``}prompt ensembling.{''} We release code and model checkpoints to reproduce our experiments.",
}

@misc{bach2022promptsource,
      title={PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts},
      author={Stephen H. Bach and Victor Sanh and Zheng-Xin Yong and Albert Webson and Colin Raffel and Nihal V. Nayak and Abheesht Sharma and Taewoon Kim and M Saiful Bari and Thibault Fevry and Zaid Alyafeai and Manan Dey and Andrea Santilli and Zhiqing Sun and Srulik Ben-David and Canwen Xu and Gunjan Chhablani and Han Wang and Jason Alan Fries and Maged S. Al-shaibani and Shanya Sharma and Urmish Thakker and Khalid Almubarak and Xiangru Tang and Xiangru Tang and Mike Tian-Jian Jiang and Alexander M. Rush},
      year={2022},
      eprint={2202.01279},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{zhang-etal-2022-promptgen,
    title = "{P}rompt{G}en: Automatically Generate Prompts using Generative Models",
    author = "Zhang, Yue  and
      Fei, Hongliang  and
      Li, Dingcheng  and
      Li, Ping",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2022",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-naacl.3",
    doi = "10.18653/v1/2022.findings-naacl.3",
    pages = "30--37",
    abstract = "Recently, prompt learning has received significant attention, where the downstream tasks are reformulated to the mask-filling task with the help of a textual prompt. The key point of prompt learning is finding the most appropriate prompt. This paper proposes a novel model PromptGen, which can automatically generate prompts conditional on the input sentence. PromptGen is the first work considering dynamic prompt generation for knowledge probing, based on a pre-trained generative model. To mitigate any label information leaking from the pre-trained generative model, when given a generated prompt, we replace the query input with {``}None{''}. We pursue that this perturbed context-free prompt cannot trigger the correct label. We evaluate our model on the knowledge probing LAMA benchmark, and show that PromptGen significantly outperforms other baselines.",
}

@inproceedings{10.1145/2207676.2208573,
author = {Matthews, Tara and Judge, Tejinder and Whittaker, Steve},
title = {How Do Designers and User Experience Professionals Actually Perceive and Use Personas?},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208573},
doi = {10.1145/2207676.2208573},
abstract = {Personas are a critical method for orienting design and development teams to user experience. Prior work has noted challenges in justifying them to developers. In contrast, it has been assumed that designers and user experience professionals - whose goal is to focus designs on targeted users - will readily exploit personas. This paper examines that assumption. We present the first study of how experienced user-centered design (UCD) practitioners with prior experience deploying personas, use and perceive personas in industrial software design. We identify limits to the persona approach in the context studied. Practitioners used personas almost exclusively for communication, but not for design. Participants identified four problems with personas, finding them abstract, impersonal, misleading and distracting. Our findings argue for a new approach to persona deployment and construction. Personas cannot replace immersion in actual user data. And rather than focusing on creating engaging personas, it is critical to avoid persona attributes that mislead or distract.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1219–1228},
numpages = {10},
keywords = {user study, evaluation, design tools, methods, personas},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@misc{https://doi.org/10.48550/arxiv.1506.01497,
  doi = {10.48550/ARXIV.1506.01497},
  
  url = {https://arxiv.org/abs/1506.01497},
  
  author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1405.0312,
  doi = {10.48550/ARXIV.1405.0312},
  
  url = {https://arxiv.org/abs/1405.0312},
  
  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Microsoft COCO: Common Objects in Context},
  
  publisher = {arXiv},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.2210.05791,
  doi = {10.48550/ARXIV.2210.05791},
  
  url = {https://arxiv.org/abs/2210.05791},
  
  author = {Shelby, Renee and Rismani, Shalaleh and Henne, Kathryn and Moon, AJung and Rostamzadeh, Negar and Nicholas, Paul and Yilla, N'Mah and Gallegos, Jess and Smart, Andrew and Garcia, Emilio and Virk, Gurleen},
  
  keywords = {Human-Computer Interaction (cs.HC), General Literature (cs.GL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Sociotechnical Harms: Scoping a Taxonomy for Harm Reduction},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{MEAIDI2014586,
title = {The sensory construction of dreams and nightmare frequency in congenitally blind and late blind individuals},
journal = {Sleep Medicine},
volume = {15},
number = {5},
pages = {586-595},
year = {2014},
issn = {1389-9457},
doi = {https://doi.org/10.1016/j.sleep.2013.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S1389945714000379},
author = {Amani Meaidi and Poul Jennum and Maurice Ptito and Ron Kupers},
keywords = {Blindness, Dreaming, Quality of sleep, Visual consciousness, Imagery, Nightmares},
abstract = {Objectives
We aimed to assess dream content in groups of congenitally blind (CB), late blind (LB), and age- and sex-matched sighted control (SC) participants.
Methods
We conducted an observational study of 11 CB, 14 LB, and 25 SC participants and collected dream reports over a 4-week period. Every morning participants filled in a questionnaire related to the sensory construction of the dream, its emotional and thematic content, and the possible occurrence of nightmares. We also assessed participants’ ability of visual imagery during waking cognition, sleep quality, and depression and anxiety levels.
Results
All blind participants had fewer visual dream impressions compared to SC participants. In LB participants, duration of blindness was negatively correlated with duration, clarity, and color content of visual dream impressions. CB participants reported more auditory, tactile, gustatory, and olfactory dream components compared to SC participants. In contrast, LB participants only reported more tactile dream impressions. Blind and SC participants did not differ with respect to emotional and thematic dream content. However, CB participants reported more aggressive interactions and more nightmares compared to the other two groups.
Conclusions
Our data show that blindness considerably alters the sensory composition of dreams and that onset and duration of blindness plays an important role. The increased occurrence of nightmares in CB participants may be related to a higher number of threatening experiences in daily life in this group.}
}

@misc{https://doi.org/10.48550/arxiv.2110.07058,
  doi = {10.48550/ARXIV.2110.07058},
  
  url = {https://arxiv.org/abs/2110.07058},
  
  author = {Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and Martin, Miguel and Nagarajan, Tushar and Radosavovic, Ilija and Ramakrishnan, Santhosh Kumar and Ryan, Fiona and Sharma, Jayant and Wray, Michael and Xu, Mengmeng and Xu, Eric Zhongcong and Zhao, Chen and Bansal, Siddhant and Batra, Dhruv and Cartillier, Vincent and Crane, Sean and Do, Tien and Doulaty, Morrie and Erapalli, Akshay and Feichtenhofer, Christoph and Fragomeni, Adriano and Fu, Qichen and Gebreselasie, Abrham and Gonzalez, Cristina and Hillis, James and Huang, Xuhua and Huang, Yifei and Jia, Wenqi and Khoo, Weslie and Kolar, Jachym and Kottur, Satwik and Kumar, Anurag and Landini, Federico and Li, Chao and Li, Yanghao and Li, Zhenqiang and Mangalam, Karttikeya and Modhugu, Raghava and Munro, Jonathan and Murrell, Tullie and Nishiyasu, Takumi and Price, Will and Puentes, Paola Ruiz and Ramazanova, Merey and Sari, Leda and Somasundaram, Kiran and Southerland, Audrey and Sugano, Yusuke and Tao, Ruijie and Vo, Minh and Wang, Yuchen and Wu, Xindi and Yagi, Takuma and Zhao, Ziwei and Zhu, Yunyi and Arbelaez, Pablo and Crandall, David and Damen, Dima and Farinella, Giovanni Maria and Fuegen, Christian and Ghanem, Bernard and Ithapu, Vamsi Krishna and Jawahar, C. V. and Joo, Hanbyul and Kitani, Kris and Li, Haizhou and Newcombe, Richard and Oliva, Aude and Park, Hyun Soo and Rehg, James M. and Sato, Yoichi and Shi, Jianbo and Shou, Mike Zheng and Torralba, Antonio and Torresani, Lorenzo and Yan, Mingfei and Malik, Jitendra},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Ego4D: Around the World in 3,000 Hours of Egocentric Video},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{HAARHOROWITZ2020102938,
title = {Dormio: A targeted dream incubation device},
journal = {Consciousness and Cognition},
volume = {83},
pages = {102938},
year = {2020},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2020.102938},
url = {https://www.sciencedirect.com/science/article/pii/S1053810020300416},
author = {Adam {Haar Horowitz} and Tony J. Cunningham and Pattie Maes and Robert Stickgold},
keywords = {Dreams, Sleep onset, Memory, Wearables, Electronics, Devices, Creativity, Incubation},
abstract = {Information processing during sleep is active, ongoing and accessible to engineering. Protocols such as targeted memory reactivation use sensory stimuli during sleep to reactivate memories and demonstrate subsequent, specific enhancement of their consolidation. These protocols rely on physiological, as opposed to phenomenological, evidence of their reactivation. While dream content can predict post-sleep memory enhancement, dreaming itself remains a black box. Here, we present a novel protocol using a new wearable electronic device, Dormio, to automatically generate serial auditory dream incubations at sleep onset, wherein targeted information is repeatedly presented during the hypnagogic period, enabling direct incorporation of this information into dream content, a process we call targeted dream incubation (TDI). Along with validation data, we discuss how Dormio and TDI protocols can serve as tools for controlled experimentation on dream content, shedding light on the role of dreams in the overnight transformation of experiences into memories.}
}

@misc{https://doi.org/10.48550/arxiv.2204.06125,
  doi = {10.48550/ARXIV.2204.06125},
  
  url = {https://arxiv.org/abs/2204.06125},
  
  author = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Hierarchical Text-Conditional Image Generation with CLIP Latents},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{https://doi.org/10.48550/arxiv.2205.11487,
  doi = {10.48550/ARXIV.2205.11487},
  
  url = {https://arxiv.org/abs/2205.11487},
  
  author = {Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S. Sara and Lopes, Rapha Gontijo and Salimans, Tim and Ho, Jonathan and Fleet, David J and Norouzi, Mohammad},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.2206.10789,
  doi = {10.48550/ARXIV.2206.10789},
  
  url = {https://arxiv.org/abs/2206.10789},
  
  author = {Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and Hutchinson, Ben and Han, Wei and Parekh, Zarana and Li, Xin and Zhang, Han and Baldridge, Jason and Wu, Yonghui},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Scaling Autoregressive Models for Content-Rich Text-to-Image Generation},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{10.1093/nc/nix001,
    author = {Nielsen, Tore},
    title = "{Microdream neurophenomenology}",
    journal = {Neuroscience of Consciousness},
    volume = {2017},
    number = {1},
    year = {2017},
    month = {03},
    abstract = "{Nightly transitions into sleep are usually uneventful and transpire in the blink of an eye. But in the laboratory these transitions afford a unique view of how experience is transformed from the perceptually grounded consciousness of wakefulness to the hallucinatory simulations of dreaming. The present review considers imagery in the sleep-onset transition—“microdreams” in particular—as an alternative object of study to dreaming as traditionally studied in the sleep lab. A focus on microdream phenomenology has thus far proven fruitful in preliminary efforts to (i) develop a classification for dreaming’s core phenomenology (the “oneiragogic spectrum”), (ii) establish a structure for assessing dreaming’s multiple memory inputs (“multi-temporal memory sources”), (iii) further Silberer’s project for classifying sleep-onset images in relation to waking cognition by revealing two new imagery types (“autosensory imagery,” “exosensory imagery”), and (iv) embed a potential understanding of microdreaming processes in a larger explanatory framework (“multisensory integration approach”). Such efforts may help resolve outstanding questions about dream neurophysiology and dreaming’s role in memory consolidation during sleep but may also advance discovery in the neuroscience of consciousness more broadly.}",
    issn = {2057-2107},
    doi = {10.1093/nc/nix001},
    url = {https://doi.org/10.1093/nc/nix001},
    note = {nix001},
    eprint = {https://academic.oup.com/nc/article-pdf/2017/1/nix001/25023972/nix001.pdf},
}

@ARTICLE{10.3389/fpsyg.2014.01133,
  
AUTHOR={Hobson, J. Allan and Hong, Charles C.-H. and Friston, Karl J.},   
	 
TITLE={Virtual reality and consciousness inference in dreaming},      
	
JOURNAL={Frontiers in Psychology},      
	
VOLUME={5},           
	
YEAR={2014},      
	  
URL={https://www.frontiersin.org/articles/10.3389/fpsyg.2014.01133},       
	
DOI={10.3389/fpsyg.2014.01133},      
	
ISSN={1664-1078},   
   
ABSTRACT={This article explores the notion that the brain is genetically endowed with an innate virtual reality generator that – through experience-dependent plasticity – becomes a generative or predictive model of the world. This model, which is most clearly revealed in rapid eye movement (REM) sleep dreaming, may provide the theater for conscious experience. Functional neuroimaging evidence for brain activations that are time-locked to rapid eye movements (REMs) endorses the view that waking consciousness emerges from REM sleep – and dreaming lays the foundations for waking perception. In this view, the brain is equipped with a virtual model of the world that generates predictions of its sensations. This model is continually updated and entrained by sensory prediction errors in wakefulness to ensure veridical perception, but not in dreaming. In contrast, dreaming plays an essential role in maintaining and enhancing the capacity to model the world by minimizing model complexity and thereby maximizing both statistical and thermodynamic efficiency. This perspective suggests that consciousness corresponds to the embodied process of inference, realized through the generation of virtual realities (in both sleep and wakefulness). In short, our premise or hypothesis is that the waking brain engages with the world to predict the causes of sensations, while in sleep the brain’s generative model is actively refined so that it generates more efficient predictions during waking. We review the evidence in support of this hypothesis – evidence that grounds consciousness in biophysical computations whose neuronal and neurochemical infrastructure has been disclosed by sleep research.}
}

@article{krakow2010imagery,
  title={Imagery rehearsal therapy: principles and practice},
  author={Krakow, Barry and Zadra, Antonio},
  journal={Sleep Medicine Clinics},
  volume={5},
  number={2},
  pages={289--298},
  year={2010},
  publisher={Elsevier}
}

@article{mallett2020pilot,
  title={A pilot investigation into brain-computer interface use during a lucid dream},
  author={Mallett, Remington},
  journal={International Journal of Dream Research},
  pages={62--69},
  year={2020}
}

@article{skarbez2022revisiting,
  title={Revisiting milgram and kishino’s reality-virtuality continuum. Front},
  author={Skarbez, R and Smith, M and Whitton, MC},
  journal={Presence and Beyond: Evaluating User Experience in AR/MR/VR},
  pages={8},
  year={2022},
  publisher={Frontiers Media SA}
}

@inproceedings{datta-2022-learn2weight,
    title = "{L}earn2{W}eight: Parameter Adaptation against Similar-domain Adversarial Attacks",
    author = "Datta, Siddhartha",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2022.coling-1.427",
    pages = "4832--4843",
    abstract = "Recent work in black-box adversarial attacks for NLP systems has attracted attention. Prior black-box attacks assume that attackers can observe output labels from target models based on selected inputs. In this work, inspired by adversarial transferability, we propose a new type of black-box NLP adversarial attack that an attacker can choose a similar domain and transfer the adversarial examples to the target domain and cause poor performance in target model. Based on domain adaptation theory, we then propose a defensive strategy, called Learn2Weight, which trains to predict the weight adjustments for target model in order to defense the attack of similar-domain adversarial examples. Using Amazon multi-domain sentiment classification dataset, we empirically show that Learn2Weight model is effective against the attack compared to standard black-box defense methods such as adversarial training and defense distillation. This work contributes to the growing literature on machine learning safety.",
}

@misc{greasevision,
  doi = {10.48550/ARXIV.2204.03731},
  
  url = {https://arxiv.org/abs/2204.03731},
  
  author = {Datta, Siddhartha and Kollnig, Konrad and Shadbolt, Nigel},
  
  keywords = {Human-Computer Interaction (cs.HC), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {GreaseVision: Rewriting the Rules of the Interface},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}

@misc{https://doi.org/10.48550/arxiv.2205.09891,
  doi = {10.48550/ARXIV.2205.09891},
  
  url = {https://arxiv.org/abs/2205.09891},
  
  author = {Datta, Siddhartha and Shadbolt, Nigel},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Interpolating Compressed Parameter Subspaces},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}


@misc{mota,
  doi = {10.48550/ARXIV.2209.14996},
  
  url = {https://arxiv.org/abs/2209.14996},
  
  author = {Datta, Siddhartha and Shadbolt, Nigel},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Multiple Modes for Continual Learning},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}


@article{ewc,
	doi = {10.1073/pnas.1611835114},
  
	url = {https://doi.org/10.1073%2Fpnas.1611835114},
  
	year = 2017,
	month = {mar},
  
	publisher = {Proceedings of the National Academy of Sciences},
  
	volume = {114},
  
	number = {13},
  
	pages = {3521--3526},
  
	author = {James Kirkpatrick and Razvan Pascanu and Neil Rabinowitz and Joel Veness and Guillaume Desjardins and Andrei A. Rusu and Kieran Milan and John Quan and Tiago Ramalho and Agnieszka Grabska-Barwinska and Demis Hassabis and Claudia Clopath and Dharshan Kumaran and Raia Hadsell},
  
	title = {Overcoming catastrophic forgetting in neural networks},
  
	journal = {Proceedings of the National Academy of Sciences}
}

