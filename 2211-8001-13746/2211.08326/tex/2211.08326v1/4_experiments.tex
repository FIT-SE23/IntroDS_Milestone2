\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{img/ablation.pdf}
    \caption{Ablation study of the kernel functions. The Gaussian kernel (rbf) with $\sigma=2$ yields the best generalization results (Ext. MAE) and final score across all three loss functions. We also notice an overall slight improvement in the site balanced accuracy.}
    \label{fig:kernel-ablation}
\end{figure*}

\section{Experimental Data}
We conduct our experiments on the OpenBHB dataset, which contains 5330 3D brain MRI scans from 71 different acquisition sites. Every scan comes from a different subject. The subjects have European-American, European and Asian origins, to promote diversity. Three modalities are available, derived from the same T1-w MRI scan (VBM, SBM, and quasi-raw). We focus this study on gray matter volumes (VBM). The model evaluation on OpenBHB is done on two private test sets (internal and external). The internal test set contains the same sites as training, the external contains unseen ones. 

\section{Experiments and Results}
\label{sec:experiments}

As network architecture, we employ the 3D implementations of ResNet-18 (33.2M parameters), AlexNet (2.5M parameters), and DenseNet-121 (11.3M parameters).
For comparison with~\cite{dufumier2022openbhb}, we use the Adam optimizer, with an initial learning rate of $10^{-4}$ decayed by a factor of $0.9$ every 10 epochs, and a weight decay of $5*10^{-5}$. We use a batch size of 32, and train for a total of 300 epochs.
Our trainings are implemented in PyTorch, and run on an NVIDIA A40 GPU, with a single training taking \url{~}24h.
For every model, we evaluate the mean absolute error (MAE) on both the internal and external test sets. Furthermore, the OpenBHB challenge computes a balanced accuracy (BAcc) for site prediction, training a logistic regression on the model representations. %
The final challenge score is then computed as $\mathcal{L}_c = \text{BAcc}^{0.3} \cdot \text{MAE}_{\text{ext}}$.\\

\noindent\subsection{Kernel function ablation study}
\begin{table}
    \centering
    \begin{tabular}{l l | l l l}
        \toprule
        Kernel & $\sigma$ / $\gamma$ & $\mathcal{L}^{y-aware}$ & $\mathcal{L}^{threshold}$ & $\mathcal{L}^{exp}$ \\ 
        \midrule
        Cauchy & 1 & 2.15 & 2.28 & 1.82 \\
               & 2 & 2.48 & 3.03 & 1.83 \\
        RBF & 1 & 2.43 & 2.63 & 1.58 \\
            & \textbf{2} & \textbf{1.82} & \textbf{1.74} & \textbf{1.54} \\
        \bottomrule
    \end{tabular}
    \caption{Ablation study of kernel functions, in terms of challenge's score.}
    \label{tab:kernel-ablation}
\end{table}
We test two different kernels: a Gaussian kernel $K_g(u) = \exp\left({-{||u||^2}/{2\sigma^2}}\right)$
and Cauchy kernel $K_c(u) = 1/(\gamma||u||^2 + 1)$. We perform an ablation study for the two different kernels and hyperparameters, employing a ResNet-18 model. Fig.~\ref{fig:kernel-ablation} shows the result. For each kernel, we report the metrics on the test set along with the final challenge score, for the three loss functions. Focusing on the final score, it's easy to see that a Gaussian kernel with $\sigma=2$ produces the best results for all losses (for readability, the final score is also reported in Tab.~\ref{tab:kernel-ablation}). 
This can be attributed to the overall lower error on the external set (Ext. MAE), showing that, with this setting, the models can generalize better. Furthermore, we also notice an overall lower balanced accuracy for site prediction, showing that this configuration is somewhat more robust to site noise.\\

\noindent\subsection{Comparison of contrastive regression losses}
In Tab.~\ref{tab:losses-comparison} we compare the results obtained with the different losses. Focusing on the aggregate score, the best results are obtained with $\mathcal{L}^{exp}$ (1.54). Furthermore, $\mathcal{L}^{exp}$ also outperforms the other losses in every evaluated metric. Most significantly, it shows the best generalization capability in the external test set, which, undoubtedly, is the most relevant result from a practical clinical perspective. 
On the internal test, we score a MAE of 2.55, which is also slightly better than the related literature on a similarly sized dataset with UKB~\cite{peng2021}. 
Interestingly, $\mathcal{L}^{exp}$ also shows the best robustness to site-related noise (with a BAcc of 5.1), which indicates that the learned space preserves the neuroanatomical features very well while also removing site noise. \\

\begin{table}
    \centering
    \begin{tabular}{r l l l c}
        \toprule
        Method & Int. MAE & BAcc & Ext. MAE & $\mathcal{L}_c$\\
        \midrule
        $\mathcal{L}^{y-aware}$ & \underline{2.66}\std{0.00} & 6.60\std{0.17} & 4.10\std{0.01} & 1.82 \\
        $\mathcal{L}^{thr}$ & 2.95\std{0.01} & \underline{5.73}\std{0.15} & 4.10\std{0.01} & 1.74 \\
        $\mathcal{L}^{exp}$ & \textbf{2.55}\std{0.00} & \textbf{5.1}\std{0.1} & \textbf{3.76}\std{0.01} & \textbf{1.54} \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of contrastive losses.}
    \label{tab:losses-comparison}
\end{table}

\noindent\subsection{Final results on the OpenBHB challenge}
Finally, we report the ranking of $\mathcal{L}^{exp}$ of the OpenBHB leaderboard, testing also AlexNet and DenseNet-121. Tab.~\ref{tab:openbhb-results} shows the results. We compare with baseline models~\cite{dufumier2022openbhb} trained with the L1 loss, and with ComBat~\cite{fortin2018harmonization}, a site harmonization algorithm developed for MRIs. 
Our proposed $\mathcal{L}^{exp}$ achieves state-of-the-art performance on the final leaderboard, scoring the best final score and metrics on both the internal and external test set, with ResNet-18. The improvement observed in the external test is also reflected for both AlexNet and DenseNet compared to all baselines. For these models, the internal MAE reached by the L1 baseline is slighly lower than $\mathcal{L}^{exp}$. 
However, when looking at the other metrics, it is easy to see that this is due to more overfitting on the internal sites for the baseline. Lastly, regarding the balanced accuracy, we observe a significant improvement with respect to the L1 baseline, showing that $\mathcal{L}^{exp}$ possesses some debiasing capability towards site noise. Besides AlexNet, however, ComBat still achieves a lower accuracy, showing that there is room for improvement. 


\begin{table}
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{r l l l l c}
        \toprule
        Method & Model & Int. MAE & BAcc & Ext. MAE & $\mathcal{L}_c$\\
        \midrule
        \multirow{3}{*}{Baseline ($\ell_1$)}
            & DenseNet & 2.55\std{0.01} & 8.0\std{0.9} & 7.13\std{0.05} & 3.34 \\
            & ResNet-18  & 2.67\std{0.05} & 6.7\std{0.1} & 4.18\std{0.01} & 1.86 \\
            & AlexNet & 2.72\std{0.01} & 8.3\std{0.2} & 4.66\std{0.05} & 2.21 \\
        \midrule
        \multirow{3}{*}{ComBat}
            & DenseNet & 5.92\std{0.01} & 2.23\std{0.06} & 10.48\std{0.17} & 3.38 \\
            & ResNet-18 & 4.15\std{0.01} & \textbf{4.5}\std{0.0} & 4.76\std{0.03} & 1.88 \\
            & AlexNet & 3.37\std{0.01} & 6.8\std{0.3} & 5.23\std{0.12} & 2.33 \\
        \midrule
        \multirow{3}{*}{$\mathcal{L}^{exp}$}
            & DenseNet & 2.85\std{0.00} & 5.34\std{0.06} & 4.43\std{0.00} & 1.84 \\
            & ResNet-18 & \textbf{2.55}\std{0.00} & {5.1}\std{0.1} & \textbf{3.76}\std{0.01} & \textbf{1.54} \\
            & AlexNet & 2.77\std{0.01} & 5.8\std{0.1} & 4.01\std{0.01} & 1.71\\
        \bottomrule
    \end{tabular}%
    }
    \caption{Final scores on the OpenBHB leaderboard. Reference results from~\cite{dufumier2022openbhb}.}
    \label{tab:openbhb-results}
\end{table}

