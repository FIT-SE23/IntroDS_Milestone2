@inproceedings{9343062,
  title     = {A non-Discriminatory Approach to Ethical Deep Learning},
  author    = {Tartaglione, Enzo and Grangetto, Marco},
  booktitle = {2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {943-950},
  doi       = {10.1109/TrustCom50675.2020.00126}
}

@article{aitchison_infonce_2021,
  title    = {{InfoNCE} is a variational autoencoder},
  url      = {http://arxiv.org/abs/2107.02495},
  abstract = {We show that a popular self-supervised learning method, InfoNCE, is a special case of a new family of unsupervised learning methods, the self-supervised variational autoencoder (SSVAE). SSVAEs circumvent the usual VAE requirement to reconstruct the data by using a carefully chosen implicit decoder. The InfoNCE objective was motivated as a simplified parametric mutual information estimator. Under one choice of prior, the SSVAE objective (i.e. the ELBO) is exactly equal to the mutual information (up to constants). Under an alternative choice of prior, the SSVAE objective is exactly equal to the simplified parametric mutual information estimator used in InfoNCE (up to constants). Importantly, the use of simplified parametric mutual information estimators is believed to be critical to obtain good high-level representations, and the SSVAE framework naturally provides a principled justification for using prior information to choose these estimators.},
  urldate  = {2021-09-23},
  journal  = {arXiv:2107.02495 [cs, stat]},
  author   = {Aitchison, Laurence},
  month    = jul,
  year     = {2021},
  note     = {arXiv: 2107.02495
              version: 1},
  keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
  file     = {arXiv.org Snapshot:/home/pgori/Zotero/storage/I8RWMJBY/2107.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/G8TH9U4M/Aitchison - 2021 - InfoNCE is a variational autoencoder.pdf:application/pdf}
}

@inproceedings{alvi2018turning,
  title     = {Turning a blind eye: Explicit removal of biases and variation from deep neural network embeddings},
  author    = {Alvi, Mohsan and Zisserman, Andrew and Nell{\aa}ker, Christoffer},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  pages     = {0--0},
  year      = {2018}
}

@article{apostolopoulos2020covid,
  title     = {Covid-19: automatic detection from x-ray images utilizing transfer learning with convolutional neural networks},
  author    = {Apostolopoulos, Ioannis D and Mpesiana, Tzani A},
  journal   = {Physical and Engineering Sciences in Medicine},
  pages     = {1},
  year      = {2020},
  publisher = {Springer}
}

@article{arora_theoretical_2019,
  title    = {A {Theoretical} {Analysis} of {Contrastive} {Unsupervised} {Representation} {Learning}},
  url      = {http://arxiv.org/abs/1902.09229},
  abstract = {Recent empirical works have successfully used unlabeled data to learn feature representations that are broadly useful in downstream classification tasks. Several of these methods are reminiscent of the well-known word2vec embedding algorithm: leveraging availability of pairs of semantically "similar" data points and "negative samples," the learner forces the inner product of representations of similar pairs with each other to be higher on average than with negative samples. The current paper uses the term contrastive learning for such algorithms and presents a theoretical framework for analyzing them by introducing latent classes and hypothesizing that semantically similar points are sampled from the same latent class. This framework allows us to show provable guarantees on the performance of the learned representations on the average classification task that is comprised of a subset of the same set of latent classes. Our generalization bound also shows that learned representations can reduce (labeled) sample complexity on downstream tasks. We conduct controlled experiments in both the text and image domains to support the theory.},
  urldate  = {2021-09-23},
  journal  = {arXiv:1902.09229 [cs, stat]},
  author   = {Arora, Sanjeev and Khandeparkar, Hrishikesh and Khodak, Mikhail and Plevrakis, Orestis and Saunshi, Nikunj},
  month    = feb,
  year     = {2019},
  note     = {arXiv: 1902.09229},
  keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file     = {arXiv.org Snapshot:/home/pgori/Zotero/storage/7W25V5RM/1902.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/8S729KRT/Arora et al. - 2019 - A Theoretical Analysis of Contrastive Unsupervised.pdf:application/pdf}
}

@inproceedings{arpit2017memorization,
  author    = {Arpit, Devansh and Jastrzundefinedbski, Stanis\l{}aw and Ballas, Nicolas and Krueger, David and Bengio, Emmanuel and Kanwal, Maxinder S. and Maharaj, Tegan and Fischer, Asja and Courville, Aaron and Bengio, Yoshua and Lacoste-Julien, Simon},
  title     = {A Closer Look at Memorization in Deep Networks},
  year      = {2017},
  publisher = {JMLR.org},
  abstract  = {We examine the role of memorization in deep learning, drawing connections to capacity, generalization, and adversarial robustness. While deep networks are capable of memorizing noise data, our results suggest that they tend to prioritize learning simple patterns first. In our experiments, we expose qualitative differences in gradient-based optimization of deep neural networks (DNNs) on noise vs. real data. We also demonstrate that for appropriately tuned explicit regularization (e.g., dropout) we can degrade DNN training performance on noise datasets without compromising generalization on real data. Our analysis suggests that the notions of effective capacity which are dataset independent are unlikely to explain the generalization performance of deep networks when trained with gradient based methods because training data itself plays an important role in determining the degree of memorization.},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
  pages     = {233–242},
  numpages  = {10},
  location  = {Sydney, NSW, Australia},
  series    = {ICML'17}
}

@article{attenberg2015beat,
  title     = {Beat the machine: Challenging humans to find a predictive model's “unknown unknowns”},
  author    = {Attenberg, Joshua and Ipeirotis, Panos and Provost, Foster},
  journal   = {Journal of Data and Information Quality (JDIQ)},
  volume    = {6},
  number    = {1},
  pages     = {1--17},
  year      = {2015},
  publisher = {ACM New York, NY, USA}
}

@article{li2020prototypical,
  title={Prototypical contrastive learning of unsupervised representations},
  author={Li, Junnan and Zhou, Pan and Xiong, Caiming and Hoi, Steven CH},
  journal={arXiv preprint arXiv:2005.04966},
  year={2020}
}

@article{wachinger2021detect,
  title={Detect and correct bias in multi-site neuroimaging datasets},
  author={Wachinger, Christian and others},
  journal={MedIA},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{glocker2019machine,
  title={Machine learning with multi-site imaging data: An empirical study on the impact of scanner effects},
  author={Glocker, Ben and others},
  booktitle={MedNeurIPS Workshop},
  year={2019}
}

@inproceedings{zhang2022rethinking,
  title={Rethinking the Augmentation Module in Contrastive Learning: Learning Hierarchical Augmentation Invariance with Expanded Views},
  author={Zhang, Junbo and Ma, Kaisheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16650--16659},
  year={2022}
}


@inproceedings{bahng2019rebias,
  title     = {Learning De-biased Representations with Biased Representations},
  author    = {Bahng, Hyojin and Chun, Sanghyuk and Yun, Sangdoo and Choo, Jaegul and Oh, Seong Joon},
  year      = {2020},
  booktitle = {International Conference on Machine Learning (ICML)}
}

@inproceedings{bahri2022scarf,
  title     = {Scarf: Self-Supervised Contrastive Learning using Random Feature Corruption},
  author    = {Dara Bahri and Heinrich Jiang and Yi Tay and Donald Metzler},
  booktitle = {International Conference on Learning Representations},
  year      = {2022}
}

@inproceedings{barbano2021bridging,
  author    = {Barbano, Carlo Alberto and Tartaglione, Enzo and Grangetto, Marco},
  title     = {Bridging the Gap Between Debiasing and Privacy for Deep Learning},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops},
  month     = {October},
  year      = {2021},
  pages     = {3806-3815}
}

@article{barbano2023unbiased,
  title   = {Unbiased Supervised Contrastive Learning},
  author  = {Barbano, Carlo Alberto and others},
  year    = 2022,
  journal = {arXiv:2211.05568},
}

@inproceedings{beutel2019putting,
  title     = {Putting fairness principles into practice: Challenges, metrics, and improvements},
  author    = {Beutel, Alex and Chen, Jilin and Doshi, Tulsee and Qian, Hai and Woodruff, Allison and Luu, Christine and Kreitmann, Pierre and Bischof, Jonathan and Chi, Ed H},
  booktitle = {Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
  pages     = {453--459},
  year      = {2019}
}

@article{brendel2019bagnet,
  author    = {Wieland Brendel and Matthias Bethge},
  doi       = {10.48550/arxiv.1904.00760},
  journal   = {7th International Conference on Learning Representations, ICLR 2019},
  month     = {3},
  publisher = {International Conference on Learning Representations, ICLR},
  title     = {Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet},
  url       = {https://arxiv.org/abs/1904.00760v1},
  year      = {2019}
}

@inproceedings{buolamwini2018gender,
  title     = {Gender shades: Intersectional accuracy disparities in commercial gender classification},
  author    = {Buolamwini, Joy and Gebru, Timnit},
  booktitle = {Conference on fairness, accountability and transparency},
  pages     = {77--91},
  year      = {2018}
}

@inproceedings{cadene2019rubi,
  title     = {Rubi: Reducing unimodal biases for visual question answering},
  author    = {Cadene, Remi and Dancette, Corentin and Cord, Matthieu and Parikh, Devi and others},
  booktitle = {Advances in neural information processing systems},
  pages     = {841--852},
  year      = {2019}
}

@article{caron_unsupervised_2019,
  title    = {Unsupervised {Pre}-{Training} of {Image} {Features} on {Non}-{Curated} {Data}},
  url      = {http://arxiv.org/abs/1905.01278},
  abstract = {Pre-training general-purpose visual features with convolutional neural networks without relying on annotations is a challenging and important task. Most recent efforts in unsupervised feature learning have focused on either small or highly curated datasets like ImageNet, whereas using non-curated raw datasets was found to decrease the feature quality when evaluated on a transfer task. Our goal is to bridge the performance gap between unsupervised methods trained on curated data, which are costly to obtain, and massive raw datasets that are easily available. To that effect, we propose a new unsupervised approach which leverages self-supervision and clustering to capture complementary statistics from large-scale data. We validate our approach on 96 million images from YFCC100M [44], achieving state-of-the-art results among unsupervised methods on standard benchmarks, which conﬁrms the potential of unsupervised learning when only non-curated raw data are available. We also show that pre-training a supervised VGG-16 with our method achieves 74.9\% top-1 classiﬁcation accuracy on the validation set of ImageNet, which is an improvement of +0.8\% over the same network trained from scratch. Our code is available at https://github. com/facebookresearch/DeeperCluster.},
  language = {en},
  urldate  = {2021-04-26},
  journal  = {arXiv:1905.01278 [cs]},
  author   = {Caron, Mathilde and Bojanowski, Piotr and Mairal, Julien and Joulin, Armand},
  month    = aug,
  year     = {2019},
  note     = {arXiv: 1905.01278},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file     = {Caron et al. - 2019 - Unsupervised Pre-Training of Image Features on Non.pdf:/home/pgori/Zotero/storage/KIWZNVU8/Caron et al. - 2019 - Unsupervised Pre-Training of Image Features on Non.pdf:application/pdf}
}

@article{caron2020unsupervised,
  title   = {Unsupervised learning of visual features by contrasting cluster assignments},
  author  = {Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {33},
  pages   = {9912--9924},
  year    = {2020}
}

@article{chabanne2017privacy,
  title   = {Privacy-preserving classification on deep neural network.},
  author  = {Chabanne, Herv{\'e} and de Wargny, Amaury and Milgram, Jonathan and Morel, Constance and Prouff, Emmanuel},
  journal = {IACR Cryptology ePrint Archive},
  volume  = {2017},
  pages   = {35},
  year    = {2017}
}

@article{chakraborty_g-simclr_2020,
  title      = {G-{SimCLR} : {Self}-{Supervised} {Contrastive} {Learning} with {Guided} {Projection} via {Pseudo} {Labelling}},
  shorttitle = {G-{SimCLR}},
  url        = {http://arxiv.org/abs/2009.12007},
  abstract   = {In the realms of computer vision, it is evident that deep neural networks perform better in a supervised setting with a large amount of labeled data. The representations learned with supervision are not only of high quality but also helps the model in enhancing its accuracy. However, the collection and annotation of a large dataset are costly and time-consuming. To avoid the same, there has been a lot of research going on in the field of unsupervised visual representation learning especially in a self-supervised setting. Amongst the recent advancements in self-supervised methods for visual recognition, in SimCLR Chen et al. shows that good quality representations can indeed be learned without explicit supervision. In SimCLR, the authors maximize the similarity of augmentations of the same image and minimize the similarity of augmentations of different images. A linear classifier trained with the representations learned using this approach yields 76.5\% top-1 accuracy on the ImageNet ILSVRC-2012 dataset. In this work, we propose that, with the normalized temperature-scaled cross-entropy (NT-Xent) loss function (as used in SimCLR), it is beneficial to not have images of the same category in the same batch. In an unsupervised setting, the information of images pertaining to the same category is missing. We use the latent space representation of a denoising autoencoder trained on the unlabeled dataset and cluster them with k-means to obtain pseudo labels. With this apriori information we batch images, where no two images from the same category are to be found. We report comparable performance enhancements on the CIFAR10 dataset and a subset of the ImageNet dataset. We refer to our method as G-SimCLR.},
  urldate    = {2021-02-24},
  journal    = {arXiv:2009.12007 [cs, stat]},
  author     = {Chakraborty, Souradip and Gosthipaty, Aritra Roy and Paul, Sayak},
  month      = sep,
  year       = {2020},
  note       = {arXiv: 2009.12007},
  keywords   = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning, Computer Science - Machine Learning},
  file       = {arXiv.org Snapshot:/home/pgori/Zotero/storage/FZ4CY9SX/2009.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/FQ5CN7M5/Chakraborty et al. - 2020 - G-SimCLR  Self-Supervised Contrastive Learning wi.pdf:application/pdf}
}

@inproceedings{chang2017deep,
  title     = {Deep adaptive image clustering},
  author    = {Chang, Jianlong and Wang, Lingfeng and Meng, Gaofeng and Xiang, Shiming and Pan, Chunhong},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  pages     = {5879--5887},
  year      = {2017}
}

@inproceedings{chen_big_2020,
  address   = {Vancouver, Canada},
  title     = {Big {Self}-{Supervised} {Models} are {Strong} {Semi}-{Supervised} {Learners}},
  url       = {http://arxiv.org/abs/2006.10029},
  abstract  = {One paradigm for learning from few labeled examples while making best use of a large amount of unlabeled data is unsupervised pretraining followed by supervised fine-tuning. Although this paradigm uses unlabeled data in a task-agnostic way, in contrast to common approaches to semi-supervised learning for computer vision, we show that it is surprisingly effective for semi-supervised learning on ImageNet. A key ingredient of our approach is the use of big (deep and wide) networks during pretraining and fine-tuning. We find that, the fewer the labels, the more this approach (task-agnostic use of unlabeled data) benefits from a bigger network. After fine-tuning, the big network can be further improved and distilled into a much smaller one with little loss in classification accuracy by using the unlabeled examples for a second time, but in a task-specific way. The proposed semi-supervised learning algorithm can be summarized in three steps: unsupervised pretraining of a big ResNet model using SimCLRv2, supervised fine-tuning on a few labeled examples, and distillation with unlabeled examples for refining and transferring the task-specific knowledge. This procedure achieves 73.9\% ImageNet top-1 accuracy with just 1\% of the labels (\${\textbackslash}le\$13 labeled images per class) using ResNet-50, a \$10{\textbackslash}times\$ improvement in label efficiency over the previous state-of-the-art. With 10\% of labels, ResNet-50 trained with our method achieves 77.5\% top-1 accuracy, outperforming standard supervised training with all of the labels.},
  urldate   = {2021-09-22},
  booktitle = {{arXiv}:2006.10029 [cs, stat]},
  author    = {Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey},
  month     = oct,
  year      = {2020},
  note      = {arXiv: 2006.10029},
  keywords  = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
  file      = {arXiv.org Snapshot:/home/pgori/Zotero/storage/9S5XWV8T/2006.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/BUD4IQ9N/Chen et al. - 2020 - Big Self-Supervised Models are Strong Semi-Supervi.pdf:application/pdf}
}

@article{chen_improved_2020,
  title    = {Improved {Baselines} with {Momentum} {Contrastive} {Learning}},
  url      = {http://arxiv.org/abs/2003.04297},
  abstract = {Contrastive unsupervised learning has recently shown encouraging progress, e.g., in Momentum Contrast (MoCo) and SimCLR. In this note, we verify the effectiveness of two of SimCLR's design improvements by implementing them in the MoCo framework. With simple modifications to MoCo---namely, using an MLP projection head and more data augmentation---we establish stronger baselines that outperform SimCLR and do not require large training batches. We hope this will make state-of-the-art unsupervised learning research more accessible. Code will be made public.},
  urldate  = {2021-09-23},
  journal  = {arXiv:2003.04297 [cs]},
  author   = {Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  month    = mar,
  year     = {2020},
  note     = {arXiv: 2003.04297},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file     = {arXiv.org Snapshot:/home/pgori/Zotero/storage/NS9ZV6H6/2003.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/H3ACSATC/Chen et al. - 2020 - Improved Baselines with Momentum Contrastive Learn.pdf:application/pdf}
}

@article{chen_intriguing_2021,
  title    = {Intriguing {Properties} of {Contrastive} {Losses}},
  url      = {http://arxiv.org/abs/2011.02803},
  language = {en},
  urldate  = {2021-08-05},
  journal  = {arXiv:2011.02803 [cs, stat]},
  author   = {Chen, Ting and Luo, Calvin and Li, Lala},
  month    = jun,
  year     = {2021},
  note     = {arXiv: 2011.02803},
  keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file     = {Chen et al. - 2021 - Intriguing Properties of Contrastive Losses.pdf:/home/pgori/Zotero/storage/2BXGJQUG/Chen et al. - 2021 - Intriguing Properties of Contrastive Losses.pdf:application/pdf}
}

@article{chen_sampling_2017,
  title    = {On {Sampling} {Strategies} for {Neural} {Network}-based {Collaborative} {Filtering}},
  url      = {http://arxiv.org/abs/1706.07881},
  abstract = {Recent advances in neural networks have inspired people to design hybrid recommendation algorithms that can incorporate both (1) user-item interaction information and (2) content information including image, audio, and text. Despite their promising results, neural network-based recommendation algorithms pose extensive computational costs, making it challenging to scale and improve upon. In this paper, we propose a general neural network-based recommendation framework, which subsumes several existing state-of-the-art recommendation algorithms, and address the efficiency issue by investigating sampling strategies in the stochastic gradient descent training for the framework. We tackle this issue by first establishing a connection between the loss functions and the user-item interaction bipartite graph, where the loss function terms are defined on links while major computation burdens are located at nodes. We call this type of loss functions "graph-based" loss functions, for which varied mini-batch sampling strategies can have different computational costs. Based on the insight, three novel sampling strategies are proposed, which can significantly improve the training efficiency of the proposed framework (up to \${\textbackslash}times 30\$ times speedup in our experiments), as well as improving the recommendation performance. Theoretical analysis is also provided for both the computational cost and the convergence. We believe the study of sampling strategies have further implications on general graph-based loss functions, and would also enable more research under the neural network-based recommendation framework.},
  urldate  = {2021-09-23},
  journal  = {arXiv:1706.07881 [cs, stat]},
  author   = {Chen, Ting and Sun, Yizhou and Shi, Yue and Hong, Liangjie},
  month    = jun,
  year     = {2017},
  note     = {arXiv: 1706.07881},
  keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Computer Science - Information Retrieval, Computer Science - Social and Information Networks},
  file     = {arXiv.org Snapshot:/home/pgori/Zotero/storage/NDY6K8V9/1706.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/E868U8ZR/Chen et al. - 2017 - On Sampling Strategies for Neural Network-based Co.pdf:application/pdf}
}


@article{chen2020mocov2,
  author = {Xinlei Chen and Haoqi Fan and Ross Girshick and Kaiming He},
  doi    = {10.48550/arxiv.2003.04297},
  month  = {3},
  title  = {Improved Baselines with Momentum Contrastive Learning},
  url    = {https://arxiv.org/abs/2003.04297v1},
  year   = {2020}
}


@inproceedings{chen2020simCLR,
  title        = {A simple framework for contrastive learning of visual representations},
  author       = {Chen, Ting and others},
  booktitle    = {ICML},
  year         = {2020},
}


@inproceedings{chen2021simsiam,
  title     = {Exploring simple siamese representation learning},
  author    = {Chen, Xinlei and He, Kaiming},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {15750--15758},
  year      = {2021}
}

@inproceedings{chopra_learning_2005,
  title     = {Learning a {Similarity} {Metric} {Discriminatively}, with {Application} to {Face} {Verification}},
  volume    = {1},
  isbn      = {978-0-7695-2372-9},
  url       = {http://ieeexplore.ieee.org/document/1467314/},
  doi       = {10.1109/CVPR.2005.202},
  abstract  = {We present a method for training a similarity metric from data. The method can be used for recognition or veriﬁcation applications where the number of categories is very large and not known during training, and where the number of training samples for a single category is very small. The idea is to learn a function that maps input patterns into a target space such that the ¢¤£ norm in the target space approximates the “semantic” distance in the input space. The method is applied to a face veriﬁcation task. The learning process minimizes a discriminative loss function that drives the similarity metric to be small for pairs of faces from the same person, and large for pairs from different persons. The mapping from raw to the target space is a convolutional network whose architecture is designed for robustness to geometric distortions. The system is tested on the Purdue/AR face database which has a very high degree of variability in the pose, lighting, expression, position, and artiﬁcial occlusions such as dark glasses and obscuring scarves.},
  language  = {en},
  urldate   = {2021-09-23},
  booktitle = {{CVPR}},
  publisher = {IEEE},
  author    = {Chopra, S. and Hadsell, R. and LeCun, Y.},
  year      = {2005},
  pages     = {539--546},
  file      = {Chopra et al. - 2005 - Learning a Similarity Metric Discriminatively, wit.pdf:/home/pgori/Zotero/storage/LSXMC78M/Chopra et al. - 2005 - Learning a Similarity Metric Discriminatively, wit.pdf:application/pdf}
}


@article{chuang_debiased_2020,
  title    = {Debiased {Contrastive} {Learning}},
  url      = {http://arxiv.org/abs/2007.00224},
  abstract = {A prominent technique for self-supervised representation learning has been to contrast semantically similar and dissimilar pairs of samples. Without access to labels, dissimilar (negative) points are typically taken to be randomly sampled datapoints, implicitly accepting that these points may, in reality, actually have the same label. Perhaps unsurprisingly, we observe that sampling negative examples from truly different labels improves performance, in a synthetic setting where labels are available. Motivated by this observation, we develop a debiased contrastive objective that corrects for the sampling of same-label datapoints, even without knowledge of the true labels. Empirically, the proposed objective consistently outperforms the state-of-the-art for representation learning in vision, language, and reinforcement learning benchmarks. Theoretically, we establish generalization bounds for the downstream classification task.},
  urldate  = {2021-09-23},
  journal  = {arXiv:2007.00224 [cs, stat]},
  author   = {Chuang, Ching-Yao and Robinson, Joshua and Yen-Chen, Lin and Torralba, Antonio and Jegelka, Stefanie},
  month    = oct,
  year     = {2020},
  note     = {arXiv: 2007.00224},
  keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
  file     = {arXiv.org Snapshot:/home/pgori/Zotero/storage/UYDBNYJH/2007.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/ECRK5NK5/Chuang et al. - 2020 - Debiased Contrastive Learning.pdf:application/pdf}
}

@article{cifar10,
  title    = {CIFAR-10 (Canadian Institute for Advanced Research)},
  journal  = {},
  author   = {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
  year     = {},
  url      = {http://www.cs.toronto.edu/~kriz/cifar.html},
  keywords = {Dataset},
  terms    = {}
}

@article{cifar100,
  title    = {CIFAR-100 (Canadian Institute for Advanced Research)},
  journal  = {},
  author   = {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
  year     = {},
  url      = {http://www.cs.toronto.edu/~kriz/cifar.html},
  keywords = {Dataset},
  terms    = {}
}

@inproceedings{ClarkYZ19,
  author    = {Christopher Clark and
               Mark Yatskar and
               Luke Zettlemoyer},
  editor    = {Kentaro Inui and
               Jing Jiang and
               Vincent Ng and
               Xiaojun Wan},
  title     = {Don't Take the Easy Way Out: Ensemble Based Methods for Avoiding Known
               Dataset Biases},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural
               Language Processing and the 9th International Joint Conference on
               Natural Language Processing, {EMNLP-IJCNLP} 2019, Hong Kong, China,
               November 3-7, 2019},
  pages     = {4067--4080},
  publisher = {Association for Computational Linguistics},
  year      = {2019},
  url       = {https://doi.org/10.18653/v1/D19-1418},
  doi       = {10.18653/v1/D19-1418},
  timestamp = {Thu, 12 Dec 2019 13:23:43 +0100},
  biburl    = {https://dblp.org/rec/conf/emnlp/ClarkYZ19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{cole_franke2017,
  title     = {Predicting age using neuroimaging: innovative brain ageing biomarkers},
  author    = {Cole, James H and Franke, Katja},
  journal   = {Trends in neurosciences},
  volume    = {40},
  number    = {12},
  pages     = {681--690},
  year      = {2017},
  publisher = {Elsevier}
}

@article{cole2017predicting,
  title     = {Predicting brain age with deep learning from raw imaging data results in a reliable and heritable biomarker},
  author    = {Cole, James H and others},
  journal   = {NeuroImage},
  year      = {2017},
  publisher = {Elsevier}
}


@article{cole2018,
  title     = {Brain age predicts mortality},
  author    = {Cole, James H and Ritchie, Stuart J and Bastin, Mark E and Hern{\'a}ndez, MC Vald{\'e}s and Maniega, S Mu{\~n}oz and Royle, Natalie and Corley, Janie and Pattie, Alison and Harris, Sarah E and Zhang, Qian and others},
  journal   = {Molecular psychiatry},
  volume    = {23},
  number    = {5},
  pages     = {1385--1392},
  year      = {2018},
  publisher = {Nature Publishing Group}
}

@article{corbett2018measure,
  title   = {The measure and mismeasure of fairness: A critical review of fair machine learning},
  author  = {Corbett-Davies, Sam and Goel, Sharad},
  journal = {arXiv preprint arXiv:1808.00023},
  year    = {2018}
}


@inproceedings{cortes2013multi,
  title        = {Multi-class classification with maximum margin multiple kernel},
  author       = {Cortes, Corinna and Mohri, Mehryar and Rostamizadeh, Afshin},
  booktitle    = {International Conference on Machine Learning},
  pages        = {46--54},
  year         = {2013},
  organization = {PMLR}
}


@article{cremer_reinterpreting_2017,
  title    = {Reinterpreting {Importance}-{Weighted} {Autoencoders}},
  url      = {http://arxiv.org/abs/1704.02916},
  abstract = {The standard interpretation of importance-weighted autoencoders is that they maximize a tighter lower bound on the marginal likelihood than the standard evidence lower bound. We give an alternate interpretation of this procedure: that it optimizes the standard variational lower bound, but using a more complex distribution. We formally derive this result, present a tighter lower bound, and visualize the implicit importance-weighted distribution.},
  urldate  = {2021-09-23},
  journal  = {arXiv:1704.02916 [stat]},
  author   = {Cremer, Chris and Morris, Quaid and Duvenaud, David},
  month    = aug,
  year     = {2017},
  note     = {arXiv: 1704.02916},
  keywords = {Statistics - Machine Learning},
  file     = {arXiv.org Snapshot:/home/pgori/Zotero/storage/H4CNXUNU/1704.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/3JNRAAHR/Cremer et al. - 2017 - Reinterpreting Importance-Weighted Autoencoders.pdf:application/pdf}
}

@article{Cruz2020OnTC,
  title   = {On the Composition and Limitations of Publicly Available COVID-19 X-Ray Imaging Datasets},
  author  = {Beatriz Garcia Santa Cruz and J. S{\"o}lter and M. Bossa and A. Husch},
  journal = {ArXiv},
  year    = {2020},
  volume  = {abs/2008.11572}
}


@inproceedings{Cubuk_2019_CVPR,
  author    = {Cubuk, Ekin D. and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V.},
  title     = {AutoAugment: Learning Augmentation Strategies From Data},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2019}
}


@inproceedings{das2017assisting,
  title        = {Assisting users in a world full of cameras: A privacy-aware infrastructure for computer vision applications},
  author       = {Das, Anupam and Degeling, Martin and Wang, Xiaoyou and Wang, Junjue and Sadeh, Norman and Satyanarayanan, Mahadev},
  booktitle    = {2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  pages        = {1387--1396},
  year         = {2017},
  organization = {IEEE}
}

@inproceedings{deng2009imagenet,
  title        = {Imagenet: A large-scale hierarchical image database},
  author       = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle    = {2009 IEEE conference on computer vision and pattern recognition},
  pages        = {248--255},
  year         = {2009},
  organization = {Ieee}
}


@article{deng2012mnist,
  title     = {The mnist database of handwritten digit images for machine learning research},
  author    = {Deng, Li},
  journal   = {IEEE Signal Processing Magazine},
  volume    = {29},
  number    = {6},
  pages     = {141--142},
  year      = {2012},
  publisher = {IEEE}
}

@article{dosovitskiy2020vit,
  title   = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author  = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal = {ICLR},
  year    = {2021}
}

@article{dufumier2021brain,
  author   = {Benoit Dufumier and Pietro Gori and Ilaria Battaglia and Julie Victor and Antoine Grigis and Edouard Duchesnay},
  doi      = {10.48550/arxiv.2106.01132},
  journal  = {NeuroImage},
  keywords = {Brain MRI,CNN Bench-mark,Data Augmentation,Deep Ensemble Learning,Deep Learning},
  month    = {6},
  title    = {Benchmarking CNN on 3D Anatomical Brain MRI: Architectures, Data Augmentation and Deep Ensemble Learning},
  url      = {https://arxiv.org/abs/2106.01132v1},
  year     = {2021}
}

@inproceedings{dufumier2021contrastive,
  title        = {Contrastive learning with continuous proxy meta-data for 3d mri classification},
  author       = {Dufumier, Benoit and others},
  booktitle    = {MICCAI},
  year         = {2021},
  organization = {Springer}
}

@article{dufumier2022openbhb,
  title     = {OpenBHB: a Large-Scale Multi-Site Brain MRI Data-set for Age Prediction and Debiasing},
  author    = {Dufumier, Benoit and others},
  journal   = {NeuroImage},
  year      = {2022},
  publisher = {Elsevier}
}

@article{dufumier2022rethinking,
  title   = {Rethinking Positive Sampling for Contrastive Learning with Kernel},
  author  = {Dufumier, Benoit and others},
  journal = {arXiv:2206.01646},
  year    = {2022}
}

@article{dwibedi2021little,
  title   = {With a little help from my friends: Nearest-neighbor contrastive learning of visual representations},
  author  = {Dwibedi, Debidatta and Aytar, Yusuf and Tompson, Jonathan and Sermanet, Pierre and Zisserman, Andrew},
  journal = {arXiv preprint arXiv:2104.14548},
  year    = {2021}
}

@article{eidinger2014age,
  title     = {Age and gender estimation of unfiltered faces},
  author    = {Eidinger, Eran and Enbar, Roee and Hassner, Tal},
  journal   = {IEEE Transactions on Information Forensics and Security},
  volume    = {9},
  number    = {12},
  pages     = {2170--2179},
  year      = {2014},
  publisher = {IEEE}
}

@article{Elsayed2018,
  abstract  = {We present a formulation of deep learning that aims at producing a large
               margin classifier. The notion of margin, minimum distance to a decision
               boundary, has served as the foundation of several theoretically profound and
               empirically successful results for both classification and regression tasks.
               However, most large margin algorithms are applicable only to shallow models
               with a preset feature representation; and conventional margin methods for
               neural networks only enforce margin at the output layer. Such methods are
               therefore not well suited for deep networks. In this work, we propose a novel loss function to impose a margin on any
               chosen set of layers of a deep network (including input and hidden layers). Our
               formulation allows choosing any norm on the metric measuring the margin. We
               demonstrate that the decision boundary obtained by our loss has nice properties
               compared to standard classification loss functions. Specifically, we show
               improved empirical results on the MNIST, CIFAR-10 and ImageNet datasets on
               multiple tasks: generalization from small training sets, corrupted labels, and
               robustness against adversarial perturbations. The resulting loss is general and
               complementary to existing data augmentation (such as random/adversarial input
               transform) and regularization techniques (such as weight decay, dropout, and
               batch norm).},
  author    = {Gamaleldin F. Elsayed and Dilip Krishnan and Hossein Mobahi and Kevin Regan and Samy Bengio},
  doi       = {10.48550/arxiv.1803.05598},
  issn      = {10495258},
  journal   = {Advances in Neural Information Processing Systems},
  month     = {3},
  pages     = {842-852},
  publisher = {Neural information processing systems foundation},
  title     = {Large Margin Deep Networks for Classification},
  volume    = {2018-December},
  url       = {https://arxiv.org/abs/1803.05598v2},
  year      = {2018}
}

@article{fernando2017pathnet,
  title   = {Pathnet: Evolution channels gradient descent in super neural networks},
  author  = {Fernando, Chrisantha and Banarse, Dylan and Blundell, Charles and Zwols, Yori and Ha, David and Rusu, Andrei A and Pritzel, Alexander and Wierstra, Daan},
  journal = {arXiv preprint arXiv:1701.08734},
  year    = {2017}
}

@article{fortin2018harmonization,
  author    = {Jean Philippe Fortin and others},
  doi       = {10.1016/J.NEUROIMAGE.2017.11.024},
  issn      = {1095-9572},
  journal   = {NeuroImage},
  pmid      = {29155184},
  publisher = {Neuroimage},
  title     = {Harmonization of cortical thickness measurements across scanners and sites},
  url       = {https://pubmed.ncbi.nlm.nih.gov/29155184/},
  year      = {2018}
}

@inproceedings{french1991using,
  title        = {Using semi-distributed representations to overcome catastrophic forgetting in connectionist networks},
  author       = {French, Robert M},
  booktitle    = {Proceedings of the 13th annual cognitive science society conference},
  pages        = {173--178},
  year         = {1991},
  organization = {Erlbaum}
}


@article{french1997pseudo,
  title     = {Pseudo-recurrent connectionist networks: An approach to the'sensitivity-stability'dilemma},
  author    = {French, Robert M},
  journal   = {Connection Science},
  volume    = {9},
  number    = {4},
  pages     = {353--380},
  year      = {1997},
  publisher = {Taylor \& Francis}
}

@article{french1999catastrophic,
  title     = {Catastrophic forgetting in connectionist networks},
  author    = {French, Robert M},
  journal   = {Trends in cognitive sciences},
  volume    = {3},
  number    = {4},
  pages     = {128--135},
  year      = {1999},
  publisher = {Elsevier}
}

@article{frosst_analyzing_2019,
  title    = {Analyzing and {Improving} {Representations} with the {Soft} {Nearest} {Neighbor} {Loss}},
  url      = {http://arxiv.org/abs/1902.01889},
  abstract = {We explore and expand the \${\textbackslash}textit\{Soft Nearest Neighbor Loss\}\$ to measure the \${\textbackslash}textit\{entanglement\}\$ of class manifolds in representation space: i.e., how close pairs of points from the same class are relative to pairs of points from different classes. We demonstrate several use cases of the loss. As an analytical tool, it provides insights into the evolution of class similarity structures during learning. Surprisingly, we find that \${\textbackslash}textit\{maximizing\}\$ the entanglement of representations of different classes in the hidden layers is beneficial for discrimination in the final layer, possibly because it encourages representations to identify class-independent similarity structures. Maximizing the soft nearest neighbor loss in the hidden layers leads not only to improved generalization but also to better-calibrated estimates of uncertainty on outlier data. Data that is not from the training distribution can be recognized by observing that in the hidden layers, it has fewer than the normal number of neighbors from the predicted class.},
  urldate  = {2021-09-23},
  journal  = {arXiv:1902.01889 [cs, stat]},
  author   = {Frosst, Nicholas and Papernot, Nicolas and Hinton, Geoffrey},
  month    = feb,
  year     = {2019},
  note     = {arXiv: 1902.01889},
  keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
  file     = {arXiv.org Snapshot:/home/pgori/Zotero/storage/NXHS38ZA/1902.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/59M87LCD/Frosst et al. - 2019 - Analyzing and Improving Representations with the S.pdf:application/pdf}
}

@article{gaser2013brainage,
  title     = {BrainAGE in mild cognitive impaired patients: predicting the conversion to Alzheimer’s disease},
  author    = {Gaser, Christian and Franke, Katja and Kl{\"o}ppel, Stefan and Koutsouleris, Nikolaos and Sauer, Heinrich and Alzheimer's Disease Neuroimaging Initiative},
  journal   = {PloS one},
  volume    = {8},
  number    = {6},
  pages     = {e67346},
  year      = {2013},
  publisher = {Public Library of Science San Francisco, USA}
}

@inproceedings{geirhos2018imagenettrained,
  title     = {ImageNet-trained {CNN}s are biased towards texture; increasing shape bias improves accuracy and robustness.},
  author    = {Robert Geirhos and Patricia Rubisch and Claudio Michaelis and Matthias Bethge and Felix A. Wichmann and Wieland Brendel},
  booktitle = {International Conference on Learning Representations},
  year      = {2019},
  url       = {https://openreview.net/forum?id=Bygh9j09KX}
}

@inproceedings{gilad2016cryptonets,
  title     = {Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy},
  author    = {Gilad-Bachrach, Ran and Dowlin, Nathan and Laine, Kim and Lauter, Kristin and Naehrig, Michael and Wernsing, John},
  booktitle = {International Conference on Machine Learning},
  pages     = {201--210},
  year      = {2016}
}

@book{GoodBengCour16,
  title     = {Deep Learning},
  author    = {Ian J. Goodfellow and Yoshua Bengio and Aaron Courville},
  publisher = {MIT Press},
  year      = {2016},
  address   = {Cambridge, MA, USA},
  note      = {\url{http://www.deeplearningbook.org}}
}

@inproceedings{goodfellow2014generative,
  author    = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K. Q. Weinberger},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Generative Adversarial Nets},
  url       = {https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf},
  volume    = {27},
  year      = {2014}
}

@article{goyal_self-supervised_2021,
  title    = {Self-supervised {Pretraining} of {Visual} {Features} in the {Wild}},
  url      = {http://arxiv.org/abs/2103.01988},
  abstract = {Recently, self-supervised learning methods like MoCo [22], SimCLR [8], BYOL [20] and SwAV [7] have reduced the gap with supervised methods. These results have been achieved in a control environment, that is the highly curated ImageNet dataset. However, the premise of self-supervised learning is that it can learn from any random image and from any unbounded dataset. In this work, we explore if self-supervision lives to its expectation by training large models on random, uncurated images with no supervision. Our ﬁnal SElf-supERvised (SEER) model, a RegNetY with 1.3B parameters trained on 1B random images with 512 GPUs achieves 84.2\% top-1 accuracy, surpassing the best self-supervised pretrained model by 1\% and conﬁrming that self-supervised learning works in a real world setting. Interestingly, we also observe that selfsupervised models are good few-shot learners achieving 77.9\% top-1 with access to only 10\% of ImageNet.},
  language = {en},
  urldate  = {2021-04-26},
  journal  = {arXiv:2103.01988 [cs]},
  author   = {Goyal, Priya and Caron, Mathilde and Lefaudeux, Benjamin and Xu, Min and Wang, Pengchao and Pai, Vivek and Singh, Mannat and Liptchinsky, Vitaliy and Misra, Ishan and Joulin, Armand and Bojanowski, Piotr},
  month    = mar,
  year     = {2021},
  note     = {arXiv: 2103.01988},
  keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
  file     = {Goyal et al. - 2021 - Self-supervised Pretraining of Visual Features in .pdf:/home/pgori/Zotero/storage/XJBPI98F/Goyal et al. - 2021 - Self-supervised Pretraining of Visual Features in .pdf:application/pdf}
}


@InProceedings{Graf2021,
  title = 	 {Dissecting Supervised Contrastive Learning},
  author =       {Graf, Florian and others},
  booktitle = 	 {ICML},
  year = 	 {2021},
  pdf = 	 {http://proceedings.mlr.press/v139/graf21a/graf21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/graf21a.html},
}

@article{grill2020bootstrap,
  title   = {Bootstrap your own latent-a new approach to self-supervised learning},
  author  = {Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {33},
  pages   = {21271--21284},
  year    = {2020}
}

@inproceedings{gupta2018robot,
  title     = {Robot learning in homes: Improving generalization and reducing dataset bias},
  author    = {Gupta, Abhinav and Murali, Adithyavairavan and Gandhi, Dhiraj Prakashchand and Pinto, Lerrel},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {9094--9104},
  year      = {2018}
}

@inproceedings{gutstein2015reduction,
  title        = {Reduction of catastrophic forgetting with transfer learning and ternary output codes},
  author       = {Gutstein, Steven and Stump, Ethan},
  booktitle    = {2015 International Joint Conference on Neural Networks (IJCNN)},
  pages        = {1--8},
  year         = {2015},
  organization = {IEEE}
}

@inproceedings{hadsell_dimensionality_2006,
  title     = {Dimensionality {Reduction} by {Learning} an {Invariant} {Mapping}},
  volume    = {2},
  booktitle = {CVPR},
  publisher = {IEEE},
  author    = {Hadsell, R. and Chopra, S. and LeCun, Y.},
  year      = {2006},
  pages     = {1735--1742}
}

@article{hadsell_dimensionality_nodate,
  title    = {Dimensionality {Reduction} by {Learning} an {Invariant} {Mapping}},
  abstract = {Dimensionality reduction involves mapping a set of high dimensional input points onto a low dimensional manifold so that “similar” points in input space are mapped to nearby points on the manifold. Most existing techniques for solving the problem suffer from two drawbacks. First, most of them depend on a meaningful and computable distance metric in input space. Second, they do not compute a “function” that can accurately map new input samples whose relationship to the training data is unknown. We present a method - called Dimensionality Reduction by Learning an Invariant Mapping (DrLIM) - for learning a globally coherent non-linear function that maps the data evenly to the output manifold. The learning relies solely on neighborhood relationships and does not require any distance measure in the input space. The method can learn mappings that are invariant to certain transformations of the inputs, as is demonstrated with a number of experiments. Comparisons are made to other techniques, in particular LLE.},
  language = {en},
  author   = {Hadsell, Raia and Chopra, Sumit and LeCun, Yann},
  pages    = {8},
  file     = {Hadsell et al. - Dimensionality Reduction by Learning an Invariant .pdf:/home/pgori/Zotero/storage/CQE8J296/Hadsell et al. - Dimensionality Reduction by Learning an Invariant .pdf:application/pdf}
}

@article{haochen2021provable,
  title   = {Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss},
  author  = {HaoChen, Jeff Z and Wei, Colin and Gaidon, Adrien and Ma, Tengyu},
  journal = {arXiv preprint arXiv:2106.04156},
  year    = {2021}
}

@article{haralick1973textural,
  author  = {Haralick, Robert M. and Shanmugam, K. and Dinstein, Its'Hak},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  title   = {Textural Features for Image Classification},
  year    = {1973},
  volume  = {SMC-3},
  number  = {6},
  pages   = {610-621},
  doi     = {10.1109/TSMC.1973.4309314}
}

@inproceedings{hassan2019automatic,
  title        = {Automatic Anonymization of Textual Documents: Detecting Sensitive Information via Word Embeddings},
  author       = {Hassan, Fadi and S{\'a}nchez, David and Soria-Comas, Jordi and Domingo-Ferrer, Josep},
  booktitle    = {2019 18th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/13th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)},
  pages        = {358--365},
  year         = {2019},
  organization = {IEEE}
}

@inproceedings{he_momentum_2020,
  title   = {Momentum {Contrast} for {Unsupervised} {Visual} {Representation} {Learning}},
  url     = {https://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html},
  urldate = {2021-02-24},
  author  = {He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  year    = {2020},
  pages   = {9729--9738},
  file    = {Snapshot:/home/pgori/Zotero/storage/6CSWWPHF/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html:text/html;Full Text PDF:/home/pgori/Zotero/storage/JTUFS8TY/He et al. - 2020 - Momentum Contrast for Unsupervised Visual Represen.pdf:application/pdf}
}

@article{he2015deep,
  author    = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  doi       = {10.48550/arxiv.1512.03385},
  isbn      = {9781467388504},
  issn      = {10636919},
  journal   = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  month     = {12},
  pages     = {770-778},
  publisher = {IEEE Computer Society},
  title     = {Deep Residual Learning for Image Recognition},
  volume    = {2016-December},
  url       = {https://arxiv.org/abs/1512.03385v1},
  year      = {2015}
}

@inproceedings{he2016deep,
  title     = {Deep residual learning for image recognition},
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {770--778},
  year      = {2016}
}


@inproceedings{hendricks2018women,
  title        = {Women also snowboard: Overcoming bias in captioning models},
  author       = {Hendricks, Lisa Anne and Burns, Kaylee and Saenko, Kate and Darrell, Trevor and Rohrbach, Anna},
  booktitle    = {European Conference on Computer Vision},
  pages        = {793--811},
  year         = {2018},
  organization = {Springer}
}


@article{Hendrycks2019,
  abstract  = {In this paper we establish rigorous benchmarks for image classifier
               robustness. Our first benchmark, ImageNet-C, standardizes and expands the
               corruption robustness topic, while showing which classifiers are preferable in
               safety-critical applications. Then we propose a new dataset called ImageNet-P
               which enables researchers to benchmark a classifier's robustness to common
               perturbations. Unlike recent robustness research, this benchmark evaluates
               performance on common corruptions and perturbations not worst-case adversarial
               perturbations. We find that there are negligible changes in relative corruption
               robustness from AlexNet classifiers to ResNet classifiers. Afterward we
               discover ways to enhance corruption and perturbation robustness. We even find
               that a bypassed adversarial defense provides substantial common perturbation
               robustness. Together our benchmarks may aid future work toward networks that
               robustly generalize.},
  author    = {Dan Hendrycks and Thomas Dietterich},
  doi       = {10.48550/arxiv.1903.12261},
  journal   = {7th International Conference on Learning Representations, ICLR 2019},
  month     = {3},
  publisher = {International Conference on Learning Representations, ICLR},
  title     = {Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  url       = {https://arxiv.org/abs/1903.12261v1},
  year      = {2019}
}


@article{hendrycks2021nae,
  title   = {Natural Adversarial Examples},
  author  = {Dan Hendrycks and Kevin Zhao and Steven Basart and Jacob Steinhardt and Dawn Song},
  journal = {CVPR},
  year    = {2021}
}


@inproceedings{hetherington1993catastrophic,
  title     = {Catastrophic interference is eliminated in pretrained networks},
  author    = {Hetherington, McRae K},
  booktitle = {Proceedings of the 15th Annual Conference of the Cognitive Science Society},
  pages     = {723--728},
  year      = {1993}
}


@book{hleg2019ethics,
  title     = {Ethics guidelines for trustworthy AI},
  author    = {European Commission (AI HLEG)},
  year      = {2019},
  publisher = {High-Level Expert Group on Artificial Intelligence},
  url       = {https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai}
}


@inproceedings{hong2021unbiased,
  author    = {Youngkyu Hong and Eunho Yang},
  booktitle = {Thirty-Fifth Conference on Neural Information Processing Systems},
  title     = {Unbiased Classification through Bias-Contrastive and Bias-Balanced Learning},
  url       = {https://openreview.net/forum?id=2OqZZAqxnn},
  year      = {2021}
}

@inproceedings{hu2017learning,
  title        = {Learning discrete representations via information maximizing self-augmented training},
  author       = {Hu, Weihua and Miyato, Takeru and Tokui, Seiya and Matsumoto, Eiichi and Sugiyama, Masashi},
  booktitle    = {International conference on machine learning},
  pages        = {1558--1567},
  year         = {2017},
  organization = {PMLR}
}


@inproceedings{huang2017densely,
  title     = {Densely connected convolutional networks},
  author    = {Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {4700--4708},
  year      = {2017}
}


@inproceedings{huishu2015multi,
  author    = {Huishu, Shi and others},
  booktitle = {IMCCC},
  title     = {Multi-scale Cauchy Kernel Function and Its Application in Multi-class SVM},
  year      = {2015},
  volume    = {},
  number    = {},
  doi       = {10.1109/IMCCC.2015.248}
}
 
@misc{Idelbayev18a,
  author       = {Yerlan Idelbayev},
  title        = {Proper {ResNet} Implementation for {CIFAR10/CIFAR100} in {PyTorch}},
  howpublished = {\url{https://github.com/akamaster/pytorch_resnet_cifar10}},
  note         = {Accessed: 2020-05},
  year         = {2018}
}

@article{ilyas2019imagenet9,
  author    = {Andrew Ilyas and Shibani Santurkar and Dimitris Tsipras and Logan Engstrom and Brandon Tran and Aleksander Madry},
  doi       = {10.48550/arxiv.1905.02175},
  issn      = {10495258},
  journal   = {Advances in Neural Information Processing Systems},
  month     = {5},
  publisher = {Neural information processing systems foundation},
  title     = {Adversarial Examples Are Not Bugs, They Are Features},
  volume    = {32},
  url       = {https://arxiv.org/abs/1905.02175v4},
  year      = {2019}
}

  

@inproceedings{imagenetcvpr09,
  author    = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
  title     = {{ImageNet: A Large-Scale Hierarchical Image Database}},
  booktitle = {CVPR09},
  year      = {2009},
  bibsource = {http://www.image-net.org/papers/imagenet_cvpr09.bib}
}

@inproceedings{irvin2019chexpert,
  title     = {Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison},
  author    = {Irvin, Jeremy and Rajpurkar, Pranav and Ko, Michael and Yu, Yifan and Ciurea-Ilcus, Silviana and Chute, Chris and Marklund, Henrik and Haghgoo, Behzad and Ball, Robyn and Shpanskaya, Katie and others},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {33},
  pages     = {590--597},
  year      = {2019}
}

@inproceedings{ji2019invariant,
  title     = {Invariant information clustering for unsupervised image classification and segmentation},
  author    = {Ji, Xu and Henriques, Joao F and Vedaldi, Andrea},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages     = {9865--9874},
  year      = {2019}
}

@article{JMLR:v9:vandermaaten08a,
  author  = {Laurens van der Maaten and Geoffrey Hinton},
  title   = {Visualizing Data using t-SNE},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
  volume  = {9},
  number  = {86},
  pages   = {2579-2605},
  url     = {http://jmlr.org/papers/v9/vandermaaten08a.html}
}

@article{Jonsson2019,
  doi       = {10.1038/s41467-019-13163-9},
  url       = {https://doi.org/10.1038/s41467-019-13163-9},
  year      = {2019},
  month     = nov,
  publisher = {Springer Science and Business Media {LLC}},
  volume    = {10},
  number    = {1},
  author    = {B. A. Jonsson and others},
  title     = {Brain age prediction using deep learning uncovers associated sequence variants},
  journal   = {Nature Communications}
}

@inproceedings{Khosla2012UndoingTD,
  title     = {Undoing the Damage of Dataset Bias},
  author    = {A. Khosla and Tinghui Zhou and Tomasz Malisiewicz and Alexei A. Efros and A. Torralba},
  booktitle = {ECCV},
  year      = {2012}
}

@inproceedings{khosla2020supervised,
  author    = {Prannay Khosla and others},
  booktitle   = {NeurIPS},
  title     = {Supervised Contrastive Learning},
  year      = {2020}
}

@inproceedings{Kim_2019_CVPR,
  author    = {Kim, Byungju and Kim, Hyunwoo and Kim, Kyungsu and Kim, Sungjin and Kim, Junmo},
  title     = {Learning Not to Learn: Training Deep Neural Networks With Biased Data},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2019}
}

@inproceedings{Kim2016ExamplesAN,
  title     = {Examples are not enough, learn to criticize! Criticism for Interpretability},
  author    = {Been Kim and O. Koyejo and Rajiv Khanna},
  booktitle = {NIPS},
  year      = {2016}
}

@inproceedings{kim2019learning,
  author    = {Kim, Byungju and Kim, Hyunwoo and Kim, Kyungsu and Kim, Sungjin and Kim, Junmo},
  title     = {Learning Not to Learn: Training Deep Neural Networks With Biased Data},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2019}
}

@article{kirkpatrick2017overcoming,
  title     = {Overcoming catastrophic forgetting in neural networks},
  author    = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal   = {Proceedings of the national academy of sciences},
  volume    = {114},
  number    = {13},
  pages     = {3521--3526},
  year      = {2017},
  publisher = {National Acad Sciences}
}

@inproceedings{kortge1990episodic,
  title        = {Episodic memory in connectionist networks},
  author       = {Kortge, Chris A},
  booktitle    = {Proceedings of the 12th Annual Conference of the Cognitive Science Society},
  pages        = {764--771},
  year         = {1990},
  organization = {Erlbaum}
}

@article{koutsouleris2014,
  title     = {Accelerated brain aging in schizophrenia and beyond: a neuroanatomical marker of psychiatric disorders},
  author    = {Koutsouleris, Nikolaos and Davatzikos, Christos and Borgwardt, Stefan and Gaser, Christian and Bottlender, Ronald and Frodl, Thomas and Falkai, Peter and Riecher-R{\"o}ssler, Anita and M{\"o}ller, Hans-J{\"u}rgen and Reiser, Maximilian and others},
  journal   = {Schizophrenia bulletin},
  volume    = {40},
  number    = {5},
  pages     = {1140--1153},
  year      = {2014},
  publisher = {Oxford University Press US}
}

@inproceedings{lam1996glcm,
  author    = {Lam, S.W.-C.},
  booktitle = {1996 IEEE International Conference on Systems, Man and Cybernetics. Information Intelligence and Systems (Cat. No.96CH35929)},
  title     = {Texture feature extraction using gray level gradient based co-occurence matrices},
  year      = {1996},
  volume    = {1},
  number    = {},
  pages     = {267-271 vol.1},
  doi       = {10.1109/ICSMC.1996.569778}
}

@article{laumer2015impact,
  title     = {The impact of business process management and applicant tracking systems on recruiting process performance: an empirical study},
  author    = {Laumer, Sven and Maier, Christian and Eckhardt, Andreas},
  journal   = {Journal of Business Economics},
  volume    = {85},
  number    = {4},
  pages     = {421--453},
  year      = {2015},
  publisher = {Springer}
}

@article{lecun2010mnist,
  title   = {MNIST handwritten digit database},
  author  = {LeCun, Yann and Cortes, Corinna and Burges, CJ},
  journal = {ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  volume  = {2},
  year    = {2010}
}

@inproceedings{lee2017overcoming,
  title     = {Overcoming catastrophic forgetting by incremental moment matching},
  author    = {Lee, Sang-Woo and Kim, Jin-Hwa and Jun, Jaehyun and Ha, Jung-Woo and Zhang, Byoung-Tak},
  booktitle = {Advances in neural information processing systems},
  pages     = {4652--4662},
  year      = {2017}
}

@inproceedings{lee2021learning,
  author    = {Jungsoo Lee and Eungyeup Kim and Juyoung Lee and Jihyeon Lee and Jaegul Choo},
  booktitle = {Thirty-Fifth Conference on Neural Information Processing Systems},
  title     = {Learning Debiased Representation via Disentangled Feature Augmentation},
  url       = {https://openreview.net/forum?id=-oUhJJILWHb},
  year      = {2021}
} 

@article{lewandowsky1991gradual,
  title   = {Gradual unlearning and catastrophic interference: A comparison of distributed architectures},
  author  = {Lewandowsky, Stephan},
  journal = {Relating theory and data: Essays on human memory in honor of Bennet B. Murdock},
  pages   = {445--476},
  year    = {1991}
}

@incollection{lewandowsky1995catastrophic,
  title     = {Catastrophic interference in neural networks: causes, solutions, and data},
  author    = {Lewandowsky, Stephan and Li, Shu-Chen},
  booktitle = {Interference and inhibition in cognition},
  pages     = {329--361},
  year      = {1995},
  publisher = {Elsevier}
}

@inproceedings{li2021shapetexture,
  title     = {Shape-Texture Debiased Neural Network Training},
  author    = {Yingwei Li and Qihang Yu and Mingxing Tan and Jieru Mei and Peng Tang and Wei Shen and Alan Yuille and cihang xie},
  booktitle = {International Conference on Learning Representations},
  year      = {2021},
  url       = {https://openreview.net/forum?id=Db4yerZTYkz}
}

@inproceedings{liu2015faceattributes,
  title     = {Deep Learning Face Attributes in the Wild},
  author    = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
  month     = {December},
  year      = {2015}
}

@article{lloyd1982least,
  author  = {Lloyd, S.},
  journal = {IEEE Transactions on Information Theory},
  title   = {Least squares quantization in PCM},
  year    = {1982},
  volume  = {28},
  number  = {2},
  pages   = {129-137},
  doi     = {10.1109/TIT.1982.1056489}
}

@article{luo2022pseudo,
  author   = {Luyang Luo and Dunyuan Xu and Hao Chen and Tien-Tsin Wong and Pheng-Ann Heng},
  doi      = {10.48550/arxiv.2203.09860},
  keywords = {Chest X-ray,Debias,Shortcut Learning},
  month    = {3},
  title    = {Pseudo Bias-Balanced Learning for Debiased Chest X-ray Classification},
  url      = {https://arxiv.org/abs/2203.09860v1},
  year     = {2022}
}

@article{madras2018learning,
  title   = {Learning adversarially fair and transferable representations},
  author  = {Madras, David and Creager, Elliot and Pitassi, Toniann and Zemel, Richard},
  journal = {arXiv preprint arXiv:1802.06309},
  year    = {2018}
}

@article{maguolo2020critic,
  title   = {A critic evaluation of methods for covid-19 automatic detection from x-ray images},
  author  = {Maguolo, Gianluca and Nanni, Loris},
  journal = {arXiv preprint arXiv:2004.12823},
  year    = {2020}
}

@article{mcclelland1995there,
  title     = {Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory.},
  author    = {McClelland, James L and McNaughton, Bruce L and O'reilly, Randall C},
  journal   = {Psychological review},
  volume    = {102},
  number    = {3},
  pages     = {419},
  year      = {1995},
  publisher = {American Psychological Association}
}

@incollection{mccloskey1989catastrophic,
  title     = {Catastrophic interference in connectionist networks: The sequential learning problem},
  author    = {McCloskey, Michael and Cohen, Neal J},
  booktitle = {Psychology of learning and motivation},
  volume    = {24},
  pages     = {109--165},
  year      = {1989},
  publisher = {Elsevier}
}

@inproceedings{mo2019differential,
  title        = {A Differential Privacy-Based Protecting Data Preprocessing Method for Big Data Mining},
  author       = {Mo, Ran and Liu, Jianfeng and Yu, Wentao and Jiang, Fu and Gu, Xin and Zhao, Xiaoshuai and Liu, Weirong and Peng, Jun},
  booktitle    = {2019 18th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/13th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)},
  pages        = {693--699},
  year         = {2019},
  organization = {IEEE}
}

@article{molavipour_conditional_2020,
  title    = {Conditional {Mutual} {Information} {Neural} {Estimator}},
  url      = {http://arxiv.org/abs/1911.02277},
  doi      = {10.1109/ICASSP40776.2020.9053422},
  abstract = {Several recent works in communication systems have proposed to leverage the power of neural networks in the design of encoders and decoders. In this approach, these blocks can be tailored to maximize the transmission rate based on aggregated samples from the channel. Motivated by the fact that, in many communication schemes, the achievable transmission rate is determined by a conditional mutual information term, this paper focuses on neural-based estimators for this information-theoretic quantity. Our results are based on variational bounds for the KL-divergence and, in contrast to some previous works, we provide a mathematically rigorous lower bound. However, additional challenges with respect to the unconditional mutual information emerge due to the presence of a conditional density function which we address here.},
  urldate  = {2021-09-23},
  journal  = {ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  author   = {Molavipour, Sina and Bassi, Germán and Skoglund, Mikael},
  month    = may,
  year     = {2020},
  note     = {arXiv: 1911.02277},
  keywords = {Computer Science - Machine Learning, Computer Science - Information Theory},
  pages    = {5025--5029},
  file     = {arXiv.org Snapshot:/home/pgori/Zotero/storage/QRZ4GKAN/1911.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/ADR3KTA5/Molavipour et al. - 2020 - Conditional Mutual Information Neural Estimator.pdf:application/pdf}
}

@inproceedings{nam2020learning,
  title     = {Learning from Failure: Training Debiased Classifier from Biased Classifier},
  author    = {Junhyun Nam and Hyuntak Cha and Sungsoo Ahn and Jaeho Lee and Jinwoo Shin},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2020}
}

@inproceedings{NEURIPS2020_1457c0d6,
  author    = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
  pages     = {1877--1901},
  publisher = {Curran Associates, Inc.},
  title     = {Language Models are Few-Shot Learners},
  volume    = {33},
  year      = {2020}
}

@article{nozawa_pac-bayesian_2020,
  title    = {{PAC}-{Bayesian} {Contrastive} {Unsupervised} {Representation} {Learning}},
  url      = {http://arxiv.org/abs/1910.04464},
  urldate  = {2021-09-23},
  journal  = {arXiv:1910.04464 [cs, math, stat]},
  author   = {Nozawa, Kento and Germain, Pascal and Guedj, Benjamin},
  month    = jul,
  year     = {2020},
  note     = {arXiv: 1910.04464},
  keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Mathematics - Statistics Theory},
  file     = {arXiv.org Snapshot:/home/pgori/Zotero/storage/GU33LYCU/1910.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/8DWI5RHN/Nozawa et al. - 2020 - PAC-Bayesian Contrastive Unsupervised Representati.pdf:application/pdf}
}

@article{oord_representation_2019,
  title    = {Representation {Learning} with {Contrastive} {Predictive} {Coding}},
  url      = {http://arxiv.org/abs/1807.03748},
  abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
  urldate  = {2021-09-23},
  journal  = {arXiv:1807.03748 [cs, stat]},
  author   = {Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  month    = jan,
  year     = {2019},
  note     = {arXiv: 1807.03748},
  keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
  file     = {arXiv.org Snapshot:/home/pgori/Zotero/storage/2D5LVG2E/1807.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/Z92CBSXA/Oord et al. - 2019 - Representation Learning with Contrastive Predictiv.pdf:application/pdf}
}

@inproceedings{Orekondy_2018_CVPR,
  author    = {Orekondy, Tribhuvanesh and Fritz, Mario and Schiele, Bernt},
  title     = {Connecting Pixels to Privacy and Utility: Automatic Redaction of Private Information in Images},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2018}
}

@article{peng2021,
  title     = {Accurate brain age prediction with lightweight deep neural networks},
  author    = {Peng, Han and others},
  year      = {2021},
  journal = {MedIA},
  publisher = {Elsevier}
}

@inproceedings{poole_variational_2019,
  title     = {On {Variational} {Bounds} of {Mutual} {Information}},
  booktitle = {ICML},
  author    = {Poole, Ben and Ozair, Sherjil and Oord, Aaron van den and Alemi, Alexander A. and Tucker, George},
  year      = {2019}
}

@article{ratcliff1990connectionist,
  title     = {Connectionist models of recognition memory: constraints imposed by learning and forgetting functions.},
  author    = {Ratcliff, Roger},
  journal   = {Psychological review},
  volume    = {97},
  number    = {2},
  pages     = {285},
  year      = {1990},
  publisher = {American Psychological Association}
}

@article{revisetool,
  author  = {Angelina Wang and Arvind Narayanan and Olga Russakovsky},
  title   = {{REVISE}: A Tool for Measuring and Mitigating Bias in Visual Datasets},
  year    = {2020},
  journal = {European Conference on Computer Vision (ECCV)}
}

@article{robins1995catastrophic,
  title     = {Catastrophic forgetting, rehearsal and pseudorehearsal},
  author    = {Robins, Anthony},
  journal   = {Connection Science},
  volume    = {7},
  number    = {2},
  pages     = {123--146},
  year      = {1995},
  publisher = {Taylor \& Francis}
}

@article{robinson2020contrastive,
  title   = {Contrastive learning with hard negative samples},
  author  = {Robinson, Joshua and Chuang, Ching-Yao and Sra, Suvrit and Jegelka, Stefanie},
  journal = {arXiv preprint arXiv:2010.04592},
  year    = {2020}
}

@inproceedings{Ross2017RightFT,
  title     = {Right for the Right Reasons: Training Differentiable Models by Constraining their Explanations},
  author    = {A. Ross and M. Hughes and Finale Doshi-Velez},
  booktitle = {IJCAI},
  year      = {2017}
}

@article{Rothe-IJCV-2018,
  author    = {Rasmus Rothe and Radu Timofte and Luc Van Gool},
  title     = {Deep expectation of real and apparent age from a single image without facial landmarks},
  journal   = {International Journal of Computer Vision},
  volume    = {126},
  number    = {2-4},
  pages     = {144--157},
  year      = {2018},
  publisher = {Springer}
}

@article{rousseeuw87silhouetteCluster,
  added-at    = {2021-06-08T14:01:15.000+0200},
  address     = {Amsterdam, The Netherlands, The Netherlands},
  author      = {Rousseeuw, Peter},
  biburl      = {https://www.bibsonomy.org/bibtex/2ab24f772541918abed19c8c367d7b6b0/bsc},
  description = {Silhouettes: a graphical aid to the interpretation and validation of cluster analysis},
  doi         = {http://dx.doi.org/10.1016/0377-0427(87)90125-7},
  interhash   = {bc0f62c7895f91c787354d03f23da976},
  intrahash   = {ab24f772541918abed19c8c367d7b6b0},
  issn        = {0377-0427},
  journal     = {J. Comput. Appl. Math.},
  keywords    = {clustering silhouette},
  number      = 1,
  pages       = {53--65},
  publisher   = {Elsevier Science Publishers B. V.},
  timestamp   = {2021-06-08T14:01:15.000+0200},
  title       = {Silhouettes: a graphical aid to the interpretation and validation of cluster analysis},
  url         = {http://portal.acm.org/citation.cfm?id=38772},
  volume      = 20,
  year        = 1987
}

@inproceedings{Roy_2019_CVPR,
  author    = {Roy, Proteek Chandan and Boddeti, Vishnu Naresh},
  title     = {Mitigating Information Leakage in Image Representations: A Maximum Entropy Approach},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2019}
}

@inproceedings{sagawa2019distributionally,
  title     = {Distributionally Robust Neural Networks},
  author    = {Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  booktitle = {International Conference on Learning Representations},
  year      = {2019}
}

@inproceedings{salakhutdinov_learning_2007,
  title     = {Learning a {Nonlinear} {Embedding} by {Preserving} {Class} {Neighbourhood} {Structure}},
  url       = {https://proceedings.mlr.press/v2/salakhutdinov07a.html},
  abstract  = {We show how to pretrain and fine-tune a multilayer neural network to learn a nonlinear transformation from the input space to a lowdimensional feature space in which K-nearest neighbour classification performs well. We also show how the non-linear transformation can be improved using unlabeled data. Our method achieves a much lower error rate than Support Vector Machines or standard backpropagation on a widely used version of the MNIST handwritten digit recognition task. If some of the dimensions of the low-dimensional feature space are not used for nearest neighbor classification, our method uses these dimensions to explicitly represent transformations of the digits that do not affect their identity.},
  language  = {en},
  urldate   = {2021-09-23},
  booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
  publisher = {PMLR},
  author    = {Salakhutdinov, Ruslan and Hinton, Geoff},
  month     = mar,
  year      = {2007},
  note      = {ISSN: 1938-7228},
  pages     = {412--419},
  file      = {Full Text PDF:/home/pgori/Zotero/storage/M6R49KP5/Salakhutdinov and Hinton - 2007 - Learning a Nonlinear Embedding by Preserving Class.pdf:application/pdf}
}

@article{sattigeri2018fairness,
  title   = {Fairness gan},
  author  = {Sattigeri, Prasanna and Hoffman, Samuel C and Chenthamarakshan, Vijil and Varshney, Kush R},
  journal = {arXiv preprint arXiv:1805.09910},
  year    = {2018}
}

@article{schramowski2020making,
  title   = {Making deep neural networks right for the right scientific reasons by interacting with their explanations},
  author  = {Patrick {Schramowski} and Wolfgang {Stammer} and Stefano {Teso} and Anna {Brugger} and Franziska {Herbert} and Xiaoting {Shao} and Hans-Georg {Luigs} and Anne-Katrin {Mahlein} and Kristian {Kersting}},
  journal = {Nature Machine Intelligence},
  volume  = {2},
  number  = {8},
  pages   = {476--486},
  notes   = {Sourced from Microsoft Academic - https://academic.microsoft.com/paper/3048549109},
  year    = {2020}
}

@article{schroff_facenet_2015,
  title      = {{FaceNet}: {A} {Unified} {Embedding} for {Face} {Recognition} and {Clustering}},
  shorttitle = {{FaceNet}},
  url        = {http://arxiv.org/abs/1503.03832},
  doi        = {10.1109/CVPR.2015.7298682},
  abstract   = {Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63\%. On YouTube Faces DB it achieves 95.12\%. Our system cuts the error rate in comparison to the best published result by 30\% on both datasets. We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.},
  urldate    = {2021-09-23},
  journal    = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  author     = {Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  month      = jun,
  year       = {2015},
  note       = {arXiv: 1503.03832},
  keywords   = {Computer Science - Computer Vision and Pattern Recognition},
  pages      = {815--823},
  file       = {arXiv.org Snapshot:/home/pgori/Zotero/storage/MB4QJVCG/1503.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/QT6XZT9M/Schroff et al. - 2015 - FaceNet A Unified Embedding for Face Recognition .pdf:application/pdf}
}

@inproceedings{schroff2015facenet,
  title     = {Facenet: A unified embedding for face recognition and clustering},
  author    = {Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {815--823},
  year      = {2015}
}

@inproceedings{Selvaraju_2019_ICCV,
  author    = {Selvaraju, Ramprasaath R. and Lee, Stefan and Shen, Yilin and Jin, Hongxia and Ghosh, Shalini and Heck, Larry and Batra, Dhruv and Parikh, Devi},
  title     = {Taking a HINT: Leveraging Explanations to Make Vision and Language Models More Grounded},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  month     = {October},
  year      = {2019}
}

@inproceedings{selvaraju2017grad,
  title     = {Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author    = {Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  pages     = {618--626},
  year      = {2017}
}

@article{sethy2020detection,
  title   = {Detection of coronavirus disease (covid-19) based on deep features},
  author  = {Sethy, Prabira Kumar and Behera, Santi Kumari},
  journal = {Preprints},
  volume  = {2020030300},
  pages   = {2020},
  year    = {2020}
}

@misc{shmatikovmachine,
  title  = {What Are Machine Learning Models Hiding?},
  author = {Shmatikov, Vitaly and Song, Congzheng}
}

@inproceedings{snoek2012practical,
  title     = {Practical bayesian optimization of machine learning algorithms},
  author    = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
  booktitle = {Advances in neural information processing systems},
  pages     = {2951--2959},
  year      = {2012}
}

@inproceedings{sohn_improved_2016,
  title     = {Improved {Deep} {Metric} {Learning} with {Multi}-class {N}-pair {Loss} {Objective}},
  volume    = {29},
  url       = {https://papers.nips.cc/paper/2016/hash/6b180037abbebea991d8b1232f8a8ca9-Abstract.html},
  urldate   = {2021-09-23},
  booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
  publisher = {Curran Associates, Inc.},
  author    = {Sohn, Kihyuk},
  year      = {2016},
  file      = {Full Text PDF:/home/pgori/Zotero/storage/6ZWK6SEQ/Sohn - 2016 - Improved Deep Metric Learning with Multi-class N-p.pdf:application/pdf}
}

@article{sohn2020fixmatch,
  title   = {Fixmatch: Simplifying semi-supervised learning with consistency and confidence},
  author  = {Sohn, Kihyuk and Berthelot, David and Carlini, Nicholas and Zhang, Zizhao and Zhang, Han and Raffel, Colin A and Cubuk, Ekin Dogus and Kurakin, Alexey and Li, Chun-Liang},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {33},
  pages   = {596--608},
  year    = {2020}
}

@article{song2013kernel,
  title     = {Kernel embeddings of conditional distributions: A unified kernel framework for nonparametric inference in graphical models},
  author    = {Song, Le and Fukumizu, Kenji and Gretton, Arthur},
  journal   = {IEEE Signal Processing Magazine},
  volume    = {30},
  number    = {4},
  pages     = {98--111},
  year      = {2013},
  publisher = {IEEE}
}

@inproceedings{song2017machine,
  title        = {Machine learning models that remember too much},
  author       = {Song, Congzheng and Ristenpart, Thomas and Shmatikov, Vitaly},
  booktitle    = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  pages        = {587--601},
  year         = {2017},
  organization = {ACM}
}

@article{sordoni_decomposed_2021,
  title    = {Decomposed {Mutual} {Information} {Estimation} for {Contrastive} {Representation} {Learning}},
  url      = {http://arxiv.org/abs/2106.13401},
  abstract = {Recent contrastive representation learning methods rely on estimating mutual information (MI) between multiple views of an underlying context. E.g., we can derive multiple views of a given image by applying data augmentation, or we can split a sequence into views comprising the past and future of some step in the sequence. Contrastive lower bounds on MI are easy to optimize, but have a strong underestimation bias when estimating large amounts of MI. We propose decomposing the full MI estimation problem into a sum of smaller estimation problems by splitting one of the views into progressively more informed subviews and by applying the chain rule on MI between the decomposed views. This expression contains a sum of unconditional and conditional MI terms, each measuring modest chunks of the total MI, which facilitates approximation via contrastive bounds. To maximize the sum, we formulate a contrastive lower bound on the conditional MI which can be approximated efficiently. We refer to our general approach as Decomposed Estimation of Mutual Information (DEMI). We show that DEMI can capture a larger amount of MI than standard non-decomposed contrastive bounds in a synthetic setting, and learns better representations in a vision domain and for dialogue generation.},
  urldate  = {2021-09-22},
  journal  = {arXiv:2106.13401 [cs]},
  author   = {Sordoni, Alessandro and Dziri, Nouha and Schulz, Hannes and Gordon, Geoff and Bachman, Phil and Tachet, Remi},
  month    = jun,
  year     = {2021},
  note     = {arXiv: 2106.13401},
  keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file     = {arXiv.org Snapshot:/home/pgori/Zotero/storage/FZUM8AV4/2106.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/CWNWVELQ/Sordoni et al. - 2021 - Decomposed Mutual Information Estimation for Contr.pdf:application/pdf}
}

@inproceedings{stock2020eccv,
  author    = {Pierre Stock and
               Moustapha Ciss{\'{e}}},
  editor    = {Vittorio Ferrari and
               Martial Hebert and
               Cristian Sminchisescu and
               Yair Weiss},
  title     = {ConvNets and ImageNet Beyond Accuracy: Understanding Mistakes and
               Uncovering Biases},
  booktitle = {Computer Vision - {ECCV} 2018 - 15th European Conference, Munich,
               Germany, September 8-14, 2018, Proceedings, Part {VI}},
  series    = {Lecture Notes in Computer Science},
  volume    = {11210},
  pages     = {504--519},
  publisher = {Springer},
  year      = {2018},
  url       = {https://doi.org/10.1007/978-3-030-01231-1\_31},
  doi       = {10.1007/978-3-030-01231-1\_31},
  timestamp = {Fri, 25 Dec 2020 01:15:00 +0100},
  biburl    = {https://dblp.org/rec/conf/eccv/StockC18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{szegedy2016rethinking,
  title     = {Rethinking the inception architecture for computer vision},
  author    = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {2818--2826},
  year      = {2016}
}

@inproceedings{tartaglione2019post,
  title        = {Post-synaptic potential regularization has potential},
  author       = {Tartaglione, Enzo and Perlo, Daniele and Grangetto, Marco},
  booktitle    = {International Conference on Artificial Neural Networks},
  pages        = {187--200},
  year         = {2019},
  organization = {Springer}
}

@inproceedings{tartaglione2019take,
  title        = {Take a ramble into solution spaces for classification problems in neural networks},
  author       = {Tartaglione, Enzo and Grangetto, Marco},
  booktitle    = {International Conference on Image Analysis and Processing},
  pages        = {345--355},
  year         = {2019},
  organization = {Springer}
}

@article{tartaglione2020pruning,
  title   = {Pruning artificial neural networks: a way to find well-generalizing, high-entropy sharp minima},
  author  = {Tartaglione, Enzo and Bragagnolo, Andrea and Grangetto, Marco},
  journal = {arXiv preprint arXiv:2004.14765},
  year    = {2020}
}

@article{tartaglione2020unveiling,
  title   = {Unveiling COVID-19 from Chest X-ray with deep learning: a hurdles race with small data},
  author  = {Tartaglione, Enzo and Barbano, Carlo Alberto and Berzovini, Claudio and Calandri, Marco and Grangetto, Marco},
  journal = {Int. J. Environ. Res. Public Health},
  volume  = {17},
  number  = {18},
  pages   = {6933},
  year    = {2020}
}

@inproceedings{tartaglione2021end,
  author    = {Tartaglione, Enzo and Barbano, Carlo Alberto and Grangetto, Marco},
  title     = {EnD: Entangling and Disentangling Deep Representations for Bias Correction},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2021},
  pages     = {13508-13517}
}

@inproceedings{tejankar2021isd,
  title     = {ISD: Self-supervised learning by iterative similarity distillation},
  author    = {Tejankar, Ajinkya and Koohpayegani, Soroush Abbasi and Pillai, Vipin and Favaro, Paolo and Pirsiavash, Hamed},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages     = {9609--9618},
  year      = {2021}
}

@inproceedings{teso2019aies_XIML,
  year      = { 2019 },
  title     = { Explanatory Interactive Machine Learning },
  pages     = { },
  booktitle = { Proceedings of the 2nd AAAI/ACM Conference on AI, Ethics, and Society (AIES) },
  author    = { Stefano Teso and Kristian Kersting }
}

@inproceedings{tian_contrastive_2020,
  address   = {Cham},
  series    = {Lecture {Notes} in {Computer} {Science}},
  title     = {Contrastive {Multiview} {Coding}},
  isbn      = {978-3-030-58621-8},
  doi       = {10.1007/978-3-030-58621-8_45},
  abstract  = {Humans view the world through many sensory channels, e.g., the long-wavelength light channel, viewed by the left eye, or the high-frequency vibrations channel, heard by the right ear. Each view is noisy and incomplete, but important factors, such as physics, geometry, and semantics, tend to be shared between all views (e.g., a “dog” can be seen, heard, and felt). We investigate the classic hypothesis that a powerful representation is one that models view-invariant factors. We study this hypothesis under the framework of multiview contrastive learning, where we learn a representation that aims to maximize mutual information between different views of the same scene but is otherwise compact. Our approach scales to any number of views, and is view-agnostic. We analyze key properties of the approach that make it work, finding that the contrastive loss outperforms a popular alternative based on cross-view prediction, and that the more views we learn from, the better the resulting representation captures underlying scene semantics. Code is available at: http://github.com/HobbitLong/CMC/.},
  language  = {en},
  booktitle = {Computer {Vision} – {ECCV} 2020},
  publisher = {Springer International Publishing},
  author    = {Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},
  editor    = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
  year      = {2020},
  note      = {tex.ids= tian\_contrastive\_2020
               arXiv: 1906.05849},
  keywords  = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
  pages     = {776--794},
  file      = {Tian et al. - 2020 - Contrastive Multiview Coding.pdf:/home/pgori/Zotero/storage/NQQQHMQT/Tian et al. - 2020 - Contrastive Multiview Coding.pdf:application/pdf;arXiv.org Snapshot:/home/pgori/Zotero/storage/I8K3GRK7/1906.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/U36UBMTP/Tian et al. - 2020 - Contrastive Multiview Coding.pdf:application/pdf;Submitted Version:/home/pgori/Zotero/storage/96AAVLXG/Tian et al. - 2020 - Contrastive Multiview Coding.pdf:application/pdf}
}

@article{tian_what_2020,
  title    = {What {Makes} for {Good} {Views} for {Contrastive} {Learning}?},
  url      = {http://arxiv.org/abs/2005.10243},
  abstract = {Contrastive learning between multiple views of the data has recently achieved state of the art performance in the field of self-supervised representation learning. Despite its success, the influence of different view choices has been less studied. In this paper, we use theoretical and empirical analysis to better understand the importance of view selection, and argue that we should reduce the mutual information (MI) between views while keeping task-relevant information intact. To verify this hypothesis, we devise unsupervised and semi-supervised frameworks that learn effective views by aiming to reduce their MI. We also consider data augmentation as a way to reduce MI, and show that increasing data augmentation indeed leads to decreasing MI and improves downstream classification accuracy. As a by-product, we achieve a new state-of-the-art accuracy on unsupervised pre-training for ImageNet classification (\$73{\textbackslash}\%\$ top-1 linear readout with a ResNet-50). In addition, transferring our models to PASCAL VOC object detection and COCO instance segmentation consistently outperforms supervised pre-training. Code:http://github.com/HobbitLong/PyContrast},
  urldate  = {2021-09-23},
  journal  = {arXiv:2005.10243 [cs]},
  author   = {Tian, Yonglong and Sun, Chen and Poole, Ben and Krishnan, Dilip and Schmid, Cordelia and Isola, Phillip},
  month    = dec,
  year     = {2020},
  note     = {arXiv: 2005.10243},
  keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
  file     = {arXiv.org Snapshot:/home/pgori/Zotero/storage/6GZ6UBEC/2005.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/U8L4IFGM/Tian et al. - 2020 - What Makes for Good Views for Contrastive Learning.pdf:application/pdf}
}

@incollection{tommasi2017deeper,
  title     = {A deeper look at dataset bias},
  author    = {Tommasi, Tatiana and Patricia, Novi and Caputo, Barbara and Tuytelaars, Tinne},
  booktitle = {Domain adaptation in computer vision applications},
  pages     = {37--55},
  year      = {2017},
  publisher = {Springer}
}

@inproceedings{torralba2011unbiased,
  title        = {Unbiased look at dataset bias.},
  author       = {Torralba, Antonio and Efros, Alexei A and others},
  booktitle    = {CVPR},
  pages        = {7},
  year         = {2011},
  organization = {Citeseer}
}

@article{tsai2022conditional,
  title   = {Conditional contrastive learning with kernel},
  author  = {Tsai, Yao-Hung Hubert and others},
  journal = {arXiv:2202.05458},
  year    = {2022}
}


@article{tschannen_mutual_2020,
  title    = {On {Mutual} {Information} {Maximization} for {Representation} {Learning}},
  url      = {http://arxiv.org/abs/1907.13625},
  abstract = {Many recent methods for unsupervised or self-supervised representation learning train feature extractors by maximizing an estimate of the mutual information (MI) between different views of the data. This comes with several immediate problems: For example, MI is notoriously hard to estimate, and using it as an objective for representation learning may lead to highly entangled representations due to its invariance under arbitrary invertible transformations. Nevertheless, these methods have been repeatedly shown to excel in practice. In this paper we argue, and provide empirical evidence, that the success of these methods cannot be attributed to the properties of MI alone, and that they strongly depend on the inductive bias in both the choice of feature extractor architectures and the parametrization of the employed MI estimators. Finally, we establish a connection to deep metric learning and argue that this interpretation may be a plausible explanation for the success of the recently introduced methods.},
  urldate  = {2021-09-23},
  journal  = {arXiv:1907.13625 [cs, stat]},
  author   = {Tschannen, Michael and Djolonga, Josip and Rubenstein, Paul K. and Gelly, Sylvain and Lucic, Mario},
  month    = jan,
  year     = {2020},
  note     = {arXiv: 1907.13625},
  keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
  file     = {arXiv.org Snapshot:/home/pgori/Zotero/storage/UDEM6CI7/1907.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/75LPKHVT/Tschannen et al. - 2020 - On Mutual Information Maximization for Representat.pdf:application/pdf}
}


@inproceedings{van2020scan,
  title        = {Scan: Learning to classify images without labels},
  author       = {Van Gansbeke, Wouter and Vandenhende, Simon and Georgoulis, Stamatios and Proesmans, Marc and Van Gool, Luc},
  booktitle    = {European Conference on Computer Vision},
  pages        = {268--285},
  year         = {2020},
  organization = {Springer}
}

@inproceedings{verma_towards_2021,
  title     = {Towards {Domain}-{Agnostic} {Contrastive} {Learning}},
  url       = {https://proceedings.mlr.press/v139/verma21a.html},
  abstract  = {Despite recent successes, most contrastive self-supervised learning methods are domain-specific, relying heavily on data augmentation techniques that require knowledge about a particular domain, such as image cropping and rotation. To overcome such limitation, we propose a domain-agnostic approach to contrastive learning, named DACL, that is applicable to problems where domain-specific data augmentations are not readily available. Key to our approach is the use of Mixup noise to create similar and dissimilar examples by mixing data samples differently either at the input or hidden-state levels. We theoretically analyze our method and show advantages over the Gaussian-noise based contrastive learning approach. To demonstrate the effectiveness of DACL, we conduct experiments across various domains such as tabular data, images, and graphs. Our results show that DACL not only outperforms other domain-agnostic noising methods, such as Gaussian-noise, but also combines well with domain-specific methods, such as SimCLR, to improve self-supervised visual representation learning.},
  language  = {en},
  urldate   = {2021-09-23},
  booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
  publisher = {PMLR},
  author    = {Verma, Vikas and Luong, Thang and Kawaguchi, Kenji and Pham, Hieu and Le, Quoc},
  month     = jul,
  year      = {2021},
  note      = {ISSN: 2640-3498},
  pages     = {10530--10541},
  file      = {Supplementary PDF:/home/pgori/Zotero/storage/DPLKKV5R/Verma et al. - 2021 - Towards Domain-Agnostic Contrastive Learning.pdf:application/pdf;Full Text PDF:/home/pgori/Zotero/storage/4MHQMH72/Verma et al. - 2021 - Towards Domain-Agnostic Contrastive Learning.pdf:application/pdf}
}

@inproceedings{vinyals2015show,
  title     = {Show and tell: A neural image caption generator},
  author    = {Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {3156--3164},
  year      = {2015}
}

@article{voulodimos2018deep,
  title     = {Deep learning for computer vision: A brief review},
  author    = {Voulodimos, Athanasios and Doulamis, Nikolaos and Doulamis, Anastasios and Protopapadakis, Eftychios},
  journal   = {Computational intelligence and neuroscience},
  volume    = {2018},
  year      = {2018},
  publisher = {Hindawi}
}


@misc{wandb,
  title  = {Experiment Tracking with Weights and Biases},
  year   = {2020},
  note   = {Software available from wandb.com},
  url    = {https://www.wandb.com/},
  author = {Biewald, Lukas}
}

@inproceedings{wang_learning_2014,
  title     = {Learning {Fine}-grained {Image} {Similarity} with {Deep} {Ranking}},
  booktitle = {{CVPR}},
  author    = {Wang, Jiang and song, Yang and Leung, Thomas and Rosenberg, Chuck and Wang, Jinbin and Philbin, James and Chen, Bo and Wu, Ying},
  year      = {2014}
}

@inproceedings{wang_ranked_2021,
  title     = {Ranked {List} {Loss} for {Deep} {Metric} {Learning}},
  author    = {Wang, Xinshao and Hua, Yang and Kodirov, Elyor and Robertson, Neil M.},
  year      = {2019},
  booktitle = {{CVPR}}
}

@article{wang_understanding_2020,
  title    = {Understanding {Contrastive} {Representation} {Learning} through {Alignment} and {Uniformity} on the {Hypersphere}},
  url      = {http://arxiv.org/abs/2005.10242},
  urldate  = {2021-09-23},
  journal  = {ICML},
  author   = {Wang, Tongzhou and Isola, Phillip},
  year     = {2020},
  keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning, Computer Science - Machine Learning}
}

@article{wang_understanding_nodate,
  title    = {Understanding the {Behaviour} of {Contrastive} {Loss}},
  language = {en},
  author   = {Wang, Feng and Liu, Huaping},
  pages    = {10},
  file     = {Wang et Liu - Understanding the Behaviour of Contrastive Loss.pdf:/home/pgori/Zotero/storage/269VQ6F6/Wang et Liu - Understanding the Behaviour of Contrastive Loss.pdf:application/pdf}
}

@inproceedings{wang2018learning,
  title     = {Learning Robust Representations by Projecting Superficial Statistics Out},
  author    = {Haohan Wang and Zexue He and Zachary L. Lipton and Eric P. Xing},
  booktitle = {International Conference on Learning Representations},
  year      = {2019},
  url       = {https://openreview.net/forum?id=rJEjjoR9K7}
}
@inproceedings{wang2019iccv,
  author    = {Tianlu Wang and Jieyu Zhao and Mark Yatskar and Kai-Wei Chang and Vicente Ordonez},
  title     = {Balanced Datasets Are Not Enough: Estimating and Mitigating Gender Bias in Deep Image Representations},
  booktitle = {International Conference on Computer Vision (ICCV)},
  month     = {October},
  year      = {2019}
}

@inproceedings{wang2020fair,
  author    = {Zeyu Wang and Klint Qinami and Ioannis Karakozis and Kyle Genova and Prem Nair and Kenji Hata and Olga Russakovsky},
  title     = {Towards Fairness in Visual Recognition: Effective Strategies for Bias Mitigation},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2020}
}

@inproceedings{wei_co2_2020,
  title      = {{CO2}: {Consistent} {Contrast} for {Unsupervised} {Visual} {Representation} {Learning}},
  shorttitle = {{CO2}},
  url        = {https://openreview.net/forum?id=U4XLJhqwNF1},
  abstract   = {Contrastive learning has recently been a core for unsupervised visual representation learning. Without human annotation, the common practice is to perform an instance discrimination task: Given a...},
  language   = {en},
  urldate    = {2021-04-26},
  author     = {Wei, Chen and Wang, Huiyu and Shen, Wei and Yuille, Alan},
  month      = sep,
  year       = {2020},
  file       = {Full Text PDF:/home/pgori/Zotero/storage/PPD6JS62/Wei et al. - 2020 - CO2 Consistent Contrast for Unsupervised Visual R.pdf:application/pdf;Snapshot:/home/pgori/Zotero/storage/FY9AQE7S/forum.html:text/html}
}

@inproceedings{weinberger_distance_2006,
  title     = {Distance {Metric} {Learning} for {Large} {Margin} {Nearest} {Neighbor} {Classification}},
  volume    = {18},
  url       = {https://proceedings.neurips.cc/paper/2005/hash/a7f592cef8b130a6967a90617db5681b-Abstract.html},
  urldate   = {2021-09-24},
  booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
  publisher = {MIT Press},
  author    = {Weinberger, Kilian Q and Blitzer, John and Saul, Lawrence},
  year      = {2006},
  file      = {Full Text PDF:/Users/pgori/Zotero/storage/XFD2VHRE/Weinberger et al. - 2006 - Distance Metric Learning for Large Margin Nearest .pdf:application/pdf}
}

@article{weinberger_distance_nodate,
  title    = {Distance {Metric} {Learning} for {Large} {Margin} {Nearest} {Neighbor} {Classiﬁcation}},
  abstract = {The accuracy of k-nearest neighbor (kNN) classiﬁcation depends signiﬁcantly on the metric used to compute distances between different examples. In this paper, we show how to learn a Mahalanobis distance metric for kNN classiﬁcation from labeled examples. The Mahalanobis metric can equivalently be viewed as a global linear transformation of the input space that precedes kNN classiﬁcation using Euclidean distances. In our approach, the metric is trained with the goal that the k-nearest neighbors always belong to the same class while examples from different classes are separated by a large margin. As in support vector machines (SVMs), the margin criterion leads to a convex optimization based on the hinge loss. Unlike learning in SVMs, however, our approach requires no modiﬁcation or extension for problems in multiway (as opposed to binary) classiﬁcation. In our framework, the Mahalanobis distance metric is obtained as the solution to a semideﬁnite program. On several data sets of varying size and difﬁculty, we ﬁnd that metrics trained in this way lead to signiﬁcant improvements in kNN classiﬁcation. Sometimes these results can be further improved by clustering the training examples and learning an individual metric within each cluster. We show how to learn and combine these local metrics in a globally integrated manner.},
  language = {en},
  author   = {Weinberger, Kilian Q and Saul, Lawrence K},
  pages    = {38},
  file     = {Weinberger and Saul - Distance Metric Learning for Large Margin Nearest .pdf:/home/pgori/Zotero/storage/Z7244VD7/Weinberger and Saul - Distance Metric Learning for Large Margin Nearest .pdf:application/pdf}
}

@inproceedings{Wu_2019_CVPR,
  author    = {Wu, Bingzhe and Zhao, Shiwan and Sun, Guangyu and Zhang, Xiaolu and Su, Zhong and Zeng, Caihong and Liu, Zhihong},
  title     = {P3SGD: Patient Privacy Preserving SGD for Regularizing Deep CNNs in Pathological Image Classification},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2019}
}

@article{wu_mutual_2020,
  title    = {On {Mutual} {Information} in {Contrastive} {Learning} for {Visual} {Representations}},
  url      = {http://arxiv.org/abs/2005.13149},
  abstract = {In recent years, several unsupervised, "contrastive" learning algorithms in vision have been shown to learn representations that perform remarkably well on transfer tasks. We show that this family of algorithms maximizes a lower bound on the mutual information between two or more "views" of an image where typical views come from a composition of image augmentations. Our bound generalizes the InfoNCE objective to support negative sampling from a restricted region of "difficult" contrasts. We find that the choice of negative samples and views are critical to the success of these algorithms. Reformulating previous learning objectives in terms of mutual information also simplifies and stabilizes them. In practice, our new objectives yield representations that outperform those learned with previous approaches for transfer to classification, bounding box detection, instance segmentation, and keypoint detection. \% experiments show that choosing more difficult negative samples results in a stronger representation, outperforming those learned with IR, LA, and CMC in classification, bounding box detection, instance segmentation, and keypoint detection. The mutual information framework provides a unifying comparison of approaches to contrastive learning and uncovers the choices that impact representation learning.},
  urldate  = {2021-09-23},
  journal  = {arXiv:2005.13149 [cs, stat]},
  author   = {Wu, Mike and Zhuang, Chengxu and Mosse, Milan and Yamins, Daniel and Goodman, Noah},
  month    = jun,
  year     = {2020},
  note     = {arXiv: 2005.13149},
  keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning, Computer Science - Machine Learning},
  file     = {arXiv.org Snapshot:/home/pgori/Zotero/storage/WX7I6UVU/2005.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/R3QEZD8F/Wu et al. - 2020 - On Mutual Information in Contrastive Learning for .pdf:application/pdf}
}


@inproceedings{wu_unsupervised_2018,
  title     = {Unsupervised {Feature} {Learning} via {Non}-{Parametric} {Instance}-level {Discrimination}},
  url       = {http://arxiv.org/abs/1805.01978},
  abstract  = {Neural net classifiers trained on data with annotated class labels can also capture apparent visual similarity among categories without being directed to do so. We study whether this observation can be extended beyond the conventional domain of supervised learning: Can we learn a good feature representation that captures apparent similarity among instances, instead of classes, by merely asking the feature to be discriminative of individual instances? We formulate this intuition as a non-parametric classification problem at the instance-level, and use noise-contrastive estimation to tackle the computational challenges imposed by the large number of instance classes. Our experimental results demonstrate that, under unsupervised learning settings, our method surpasses the state-of-the-art on ImageNet classification by a large margin. Our method is also remarkable for consistently improving test performance with more training data and better network architectures. By fine-tuning the learned feature, we further obtain competitive results for semi-supervised learning and object detection tasks. Our non-parametric model is highly compact: With 128 features per image, our method requires only 600MB storage for a million images, enabling fast nearest neighbour retrieval at the run time.},
  urldate   = {2021-09-24},
  booktitle = {{CVPR}},
  author    = {Wu, Zhirong and Xiong, Yuanjun and Yu, Stella and Lin, Dahua},
  year      = {2018},
  note      = {arXiv: 1805.01978},
  keywords  = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
  file      = {arXiv Fulltext PDF:/Users/pgori/Zotero/storage/QV737CL2/Wu et al. - 2018 - Unsupervised Feature Learning via Non-Parametric I.pdf:application/pdf;arXiv.org Snapshot:/Users/pgori/Zotero/storage/64W3D5C3/1805.html:text/html}
}

@article{xiao_what_2021,
  title    = {What {Should} {Not} {Be} {Contrastive} in {Contrastive} {Learning}},
  url      = {http://arxiv.org/abs/2008.05659},
  abstract = {Recent self-supervised contrastive methods have been able to produce impressive transferable visual representations by learning to be invariant to different data augmentations. However, these methods implicitly assume a particular set of representational invariances (e.g., invariance to color), and can perform poorly when a downstream task violates this assumption (e.g., distinguishing red vs. yellow cars). We introduce a contrastive learning framework which does not require prior knowledge of speciﬁc, task-dependent invariances. Our model learns to capture varying and invariant factors for visual representations by constructing separate embedding spaces, each of which is invariant to all but one augmentation. We use a multi-head network with a shared backbone which captures information across each augmentation and alone outperforms all baselines on downstream tasks. We further ﬁnd that the concatenation of the invariant and varying spaces performs best across all tasks we investigate, including coarse-grained, ﬁne-grained, and few-shot downstream classiﬁcation tasks, and various data corruptions.},
  language = {en},
  urldate  = {2021-04-27},
  journal  = {arXiv:2008.05659 [cs]},
  author   = {Xiao, Tete and Wang, Xiaolong and Efros, Alexei A. and Darrell, Trevor},
  month    = mar,
  year     = {2021},
  note     = {arXiv: 2008.05659},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file     = {Xiao et al. - 2021 - What Should Not Be Contrastive in Contrastive Lear.pdf:/home/pgori/Zotero/storage/3T6K5YI2/Xiao et al. - 2021 - What Should Not Be Contrastive in Contrastive Lear.pdf:application/pdf}
}

@inproceedings{Xie2017ControllableIT,
  title     = {Controllable Invariance through Adversarial Feature Learning},
  author    = {Qizhe Xie and Zihang Dai and Yulun Du and E. Hovy and Graham Neubig},
  booktitle = {NIPS},
  year      = {2017}
}


@article{xu_understanding_2021,
  title    = {{UNDERSTANDING} {THE} {ROLE} {OF} {IMPORTANCE} {WEIGHT}- {ING} {FOR} {DEEP} {LEARNING}},
  abstract = {The recent paper by Byrd \& Lipton (2019), based on empirical observations, raises a major concern on the impact of importance weighting for the over-parameterized deep learning models. They observe that as long as the model can separate the training data, the impact of importance weighting diminishes as the training proceeds. Nevertheless, there lacks a rigorous characterization of this phenomenon. In this paper, we provide formal characterizations and theoretical justiﬁcations on the role of importance weighting with respect to the implicit bias of gradient descent and margin-based learning theory. We reveal both the optimization dynamics and generalization performance under deep learning models. Our work not only explains the various novel phenomenons observed for importance weighting in deep learning, but also extends to the studies where the weights are being optimized as part of the model, which applies to a number of topics under active research.},
  language = {en},
  author   = {Xu, Da},
  year     = {2021},
  pages    = {20},
  file     = {Xu - 2021 - UNDERSTANDING THE ROLE OF IMPORTANCE WEIGHT- ING F.pdf:/home/pgori/Zotero/storage/6RR5QUYU/Xu - 2021 - UNDERSTANDING THE ROLE OF IMPORTANCE WEIGHT- ING F.pdf:application/pdf}
}




@inproceedings{xu2018fairgan,
  title        = {Fairgan: Fairness-aware generative adversarial networks},
  author       = {Xu, Depeng and Yuan, Shuhan and Zhang, Lu and Wu, Xintao},
  booktitle    = {2018 IEEE International Conference on Big Data (Big Data)},
  pages        = {570--575},
  year         = {2018},
  organization = {IEEE}
}

@article{yamaguchi2004reassessment,
  title     = {Reassessment of catastrophic interference},
  author    = {Yamaguchi, Makoto},
  journal   = {Neuroreport},
  volume    = {15},
  number    = {15},
  pages     = {2423--2426},
  year      = {2004},
  publisher = {LWW}
}

@article{yeh2021decoupled,
  title   = {Decoupled Contrastive Learning},
  author  = {Yeh, Chun-Hsiao and Hong, Cheng-Yao and Hsu, Yen-Chi and Liu, Tyng-Luh and Chen, Yubei and LeCun, Yann},
  journal = {arXiv preprint arXiv:2110.06848},
  year    = {2021}
}

@inproceedings{yu_deep_2019,
  title     = {Deep {Metric} {Learning} {With} {Tuplet} {Margin} {Loss}},
  booktitle = {{IEEE} {ICCV}},
  author    = {Yu, Baosheng and Tao, Dacheng},
  year      = {2019},
  pages     = {6489--6498}
}

@article{zbontar_barlow_2021,
  title      = {Barlow {Twins}: {Self}-{Supervised} {Learning} via {Redundancy} {Reduction}},
  shorttitle = {Barlow {Twins}},
  url        = {http://arxiv.org/abs/2103.03230},
  abstract   = {Self-supervised learning (SSL) is rapidly closing the gap with supervised methods on large computer vision benchmarks. A successful approach to SSL is to learn representations which are invariant to distortions of the input sample. However, a recurring issue with this approach is the existence of trivial constant representations. Most current methods avoid such collapsed solutions by careful implementation details. We propose an objective function that naturally avoids such collapse by measuring the cross-correlation matrix between the outputs of two identical networks fed with distorted versions of a sample, and making it as close to the identity matrix as possible. This causes the representation vectors of distorted versions of a sample to be similar, while minimizing the redundancy between the components of these vectors. The method is called Barlow Twins, owing to neuroscientist H. Barlow's redundancy-reduction principle applied to a pair of identical networks. Barlow Twins does not require large batches nor asymmetry between the network twins such as a predictor network, gradient stopping, or a moving average on the weight updates. It allows the use of very high-dimensional output vectors. Barlow Twins outperforms previous methods on ImageNet for semi-supervised classification in the low-data regime, and is on par with current state of the art for ImageNet classification with a linear classifier head, and for transfer tasks of classification and object detection.},
  language   = {en},
  urldate    = {2021-04-27},
  journal    = {arXiv:2103.03230 [cs, q-bio]},
  author     = {Zbontar, Jure and Jing, Li and Misra, Ishan and LeCun, Yann and Deny, Stéphane},
  month      = mar,
  year       = {2021},
  note       = {tex.ids= zbontar\_barlow\_2021-1
                arXiv: 2103.03230},
  keywords   = {Computer Science - Computer Vision and Pattern Recognition, Quantitative Biology - Neurons and Cognition, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {Zbontar et al. - 2021 - Barlow Twins Self-Supervised Learning via Redunda.pdf:/home/pgori/Zotero/storage/HYNPU2Z7/Zbontar et al. - 2021 - Barlow Twins Self-Supervised Learning via Redunda.pdf:application/pdf;arXiv.org Snapshot:/home/pgori/Zotero/storage/I83VSHFG/2103.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/A9XNTDXG/Zbontar et al. - 2021 - Barlow Twins Self-Supervised Learning via Redunda.pdf:application/pdf}
}

@article{zhang2018gce,
  author    = {Zhilu Zhang and Mert R. Sabuncu},
  doi       = {10.48550/arxiv.1805.07836},
  isbn      = {1805.07836v4},
  issn      = {10495258},
  journal   = {Advances in Neural Information Processing Systems},
  month     = {5},
  pages     = {8778-8788},
  publisher = {Neural information processing systems foundation},
  title     = {Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels},
  volume    = {2018-December},
  url       = {https://arxiv.org/abs/1805.07836v4},
  year      = {2018}
}

@article{zhang2019artificial,
  title   = {Artificial intelligence: American attitudes and trends},
  author  = {Zhang, Baobao and Dafoe, Allan},
  journal = {Available at SSRN 3312874},
  year    = {2019}
}

@article{zhao2021learning,
  author = {Bowen Zhao and Chen Chen and Qi Ju and Shutao Xia},
  doi    = {10.48550/arxiv.2111.13108},
  month  = {11},
  title  = {Learning Debiased Models with Dynamic Gradient Alignment and Bias-conflicting Sample Mining},
  url    = {https://arxiv.org/abs/2111.13108v1},
  year   = {2021}
}

