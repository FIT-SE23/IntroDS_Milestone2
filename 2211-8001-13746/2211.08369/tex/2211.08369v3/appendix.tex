\clearpage
\appendix

\section{Reproducibility}
\label{sec:A}

\subsection{Experimental results}

\subsubsection{Setup}
For both \textsc{jwa} and \textsc{dbert}, we use the same preprocessing pipeline on all four datasets. First, we filter out instances with fewer than three tokens to achieve stable agreement evaluation.\footnote{If a sequence consists of only two tokens, rank-correlation with Kendall-$\tau$ will either result in a perfect match, or completely different observations as swapping the two ranks leads to an inverse ranking.}
Next, we lowercase the tokens, remove non-alphanumeric tokens, and truncate the sequence to $200$ tokens if the sequence length exceeds this threshold. We set the maximum vocabulary size to $20$k for models which do not leverage subword vocabularies.

\subsubsection{Validation set performance}
We report the validation set performance in \Cref{tab:f1_scores_val}.

\subsubsection{Computing infrastructure}
We conducted our experiments on $2 \times$ \textit{AMD Ryzen Threadripper 3970X 32-Core Processors} and $2 \times$ \textit{NVIDIA GeForce RTX 3090} GPUs with $24$GB of RAM. We used \textit{PyTorch} version $1.9.0$ and CUDA $11.4$.
 

\subsubsection{Average runtime}
\Cref{tab:runtime} shows the average experiment runtime for each model across the datasets we used.

\begin{table}[t!]
\small
\centering
\begin{tabular}{lrrrr}
\toprule
& & Base & Conicity & Tying \\
\midrule
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textsc{dbert}}}
& SUBJ & $.94$ & $.89$ & $.94$ \\
& SST & $.85$ & $.85$ & $.85$ \\
& TREC & $.94$ & $.89$ & $.91$ \\
& IMDB & $.90$ & $.89$ & $.89$ \\
\midrule
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textsc{jwa}}}
& SUBJ & $.93$ & $.90$ & $.91$ \\
& SST & $.82$ & $.79$ & $.81$ \\
& TREC & $.91$ & $.87$ & $.89$ \\
& IMDB & $.90$ & $.87$ & $.88$ \\
\bottomrule
\end{tabular}
\caption{$F_1$ scores on \textit{validation} sets across datasets for \textsc{dbert} and \textsc{jwa}. We average the results over $5$ runs with different seeds. The scores pertain to the same experiments as in \Cref{tab:f1_scores}, where we report test $F_1$ scores.}
\label{tab:f1_scores_val}
\end{table}


\begin{table}
\centering
\small
\begin{tabular}{lrr}
\toprule
& \textsc{jwa} & \textsc{dbert} \\
\midrule
SUBJ & $3.4$ & $11.2$ \\
SST & $2.7$ & $8.9$ \\
TREC & $1.2$ & $3.7$  \\
IMDB & $6.1$ & $107.5$ \\
\end{tabular}
\caption{Experiment duration in minutes for both models across datasets. We report the average runtime over $5$ different runs.}
\label{tab:runtime}
\end{table}

\subsubsection{Number of parameters}
The \textsc{jwa} and \textsc{dbert} models that we used contained $1,714,951$ and $66,954,241$ trainable parameters, respectively.

\subsection{Hyperparameter search}
\label{subsec:A_hs}
We used the following parameter grids for \textsc{jwa}: $[10^{-1}, 10^{-2}, 10^{-3}, 10^{-4}, 10^{-5}, 10^{-6}]$ for learning rate,  and $[50, 100, 150, 200]$ for the hidden state dimension. We yield best average results on validation sets across all datasets when the learning rate is set to $10^{-3}$ and the hidden size is set to $150$. For \textsc{dbert}, we find that the most robust initial learning rate on the four datasets is $2 \times 10^{-5}$, among the options we explored $[5 \times 10^{-4}, 10^{-4}, 10^{-5}, 2 \times 10^{-5}, 5 \times 10^{-5}, 10^{-6}]$. Additionally, we clip the gradients for both models such that the gradient norm $\le 1$. We use the Adam \cite{kingma-ba-2015-adam} optimizer for \textsc{jwa} and AdamW \cite{loshchilov-hutter-2017-fixing} for \textsc{dbert}. We run both models for $5$ epochs and repeat the experiments $5$ times with different seeds: $[1, 2, 3, 4, 5]$.

For regularization methods, we conducted a grid search with parameter grid $[0.1, 0.3, 0.5, 1, 5, 10]$ for \textsc{conicity} and $[0.1, 0.3, 0.5, 1, 5, 10, 20]$ for \textsc{tying}. We select the models with the strongest regularization scale, which is within $3$ $F_1$ points from the unregularized model. \Cref{tab:reg_params} shows the selected values for each model across all datasets.


\begin{table}
\small
\centering
\begin{tabular}{lrrrrrr}
\toprule
& \multicolumn{2}{c}{\textsc{jwa}} & \multicolumn{2}{c}{\textsc{dbert}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
& C & T & C & T \\
\midrule
SUBJ & $1.$ & $1.$ & $5.$ & $1.$ \\
SST & $1.$ & $0.5$ & $0.1$ & $0.5$ \\
TREC & $1.$ & $1.$ & $0.1$ & $0.3$  \\
IMDB & $0.3$ & $1.$ & $1.$ & $1.$ \\
\bottomrule
\end{tabular}
\caption{Selected hyperparameter values for \textsc{conicity} (C) and \textsc{tying} (T).}
\label{tab:reg_params}
\end{table}

\begin{table}
\centering
\small
\begin{tabular}{lrr}
\toprule
& \textsc{jwa} & \textsc{dbert} \\
\midrule
SUBJ & $3.4$ & $11.2$ \\
SST & $2.7$ & $8.9$ \\
TREC & $1.2$ & $3.7$  \\
IMDB & $6.1$ & $107.5$ \\
\end{tabular}
\caption{Experiment duration in minutes for both models across datasets. We report the average runtime over $5$ different runs.}
\label{tab:runtime}
\end{table}

\subsection{Dataset statistics}
We report the number of instances per split for each dataset in \Cref{tab:dataset_stats}. We note that all of the datasets we used contain predominantly texts in English.

\begin{table}[t!]
\small
\centering
\begin{tabular}{lrrrr}
\toprule
& Train & Validation & Test & Total \\
\midrule
SUBJ & $7,000$ & $1,000$ & $2,000$ & $10,000$\\
SST & $6,819$ & $868$ & $1,810$ & $9,497$ \\
TREC & $1,987$ & $159$ & $486$ & $2,632$ \\
IMDB & $17,212$ & $4,304$ & $4,363$ & $25,879$ \\
\end{tabular}
\caption{Number of instances in each split and the total number of instances in each dataset after we excluded too short examples (see \cref{subsec:datasets}).}
\label{tab:dataset_stats}
\end{table}


\section{Additional experiments}
\label{sec:B}

We show the full version of local curvature statistics in \Cref{tab:repr_dbert_full} (without averaging over datasets). In \Cref{fig:corr-jwa-subj,fig:corr-jwa-sst,fig:corr-jwa-trec,fig:corr-jwa-imdb,fig:corr-dbert-subj,fig:corr-dbert-sst,fig:corr-dbert-trec,fig:corr-dbert-imdb} we plot correlation scores ($k_\tau$ and $p_r$) with standard deviation on the test splits. We include the results for all datasets across training epochs for regularized models (\textsc{conicity}, \textsc{tying}) when compared to their unregularized, \textsc{base} variants. 

% \begin{figure}
%   \centering
%   \includegraphics[width=\linewidth]{img/kendall1.pdf}
%   \caption{$k_\tau = .49$, $p_r = .94$}
%   \label{fig:kendall1}
% \end{figure}

\begin{table*}
\centering
\small
\begin{tabular}{lrrrrrrr}
\toprule
& & \multicolumn{2}{c}{Confidence} & \multicolumn{2}{c}{Ambiguity} & \multicolumn{2}{c}{Variability} \\
\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8}
& & B & T & B & T & B & T \\
\midrule
\multirow{4}{*}{\rotatebox[origin=c]{90}{Grad norm}}
& SUBJ & $-.37_{.00}$ & $-.06_{.00}$ & $.48_{.00}$ & $.05_{.02}$ & $.45_{.00}$ & $.00_{.83}$ \\
& SST & $-.40_{.00}$ & $.02_{.34}$ & $.58_{.00}$ & $.08_{.00}$ & $.42_{.00}$ & $-.23_{.00}$ \\
& TREC & $-.32_{.00}$ & $.05_{.32}$ & $.39_{.00}$ & $-.12_{.01}$ & $.38_{.00}$ & $.18_{.00}$ \\
& IMDB & $-.46_{.00}$ & $-.11_{.00}$ & $.61_{.00}$ & $.17_{.00}$ & $.60_{.00}$ & $.30_{.00}$ \\
\midrule
\multirow{4}{*}{\rotatebox[origin=c]{90}{Min dist}}
& SUBJ & $-.59_{.00}$ & $.01_{.70}$ & $.79_{.00}$ & $-.10_{.00}$ & $.74_{.00}$ & $.06_{.00}$ \\
& SST & $-.45_{.00}$ & $.30_{.00}$ & $.70_{.00}$ & $-.44_{.00}$ & $.49_{.00}$ & $.30_{.00}$ \\
& TREC & $-.55_{.00}$ & $.17_{.00}$ & $.70_{.00}$ & $-.26_{.00}$ & $.68_{.00}$ & $.25_{.00}$ \\
& IMDB & $-.53_{.00}$ & $.50_{.00}$ & $.70_{.00}$ & $-.74_{.00}$ & $.64_{.00}$ & $.04_{.00}$ \\
\bottomrule
\end{tabular}
\caption{Correlations between local curvature statistics in the representation space and cartography attributes for each dataset. We use average gradient norms (\textit{grad norm}) of the hidden representation with respect to the input embeddings and average distance to the nearest instance (\textit{min dist}). The columns correspond to the cartography attributes. We report the results for the unregularized model (B) and the regularized one to which we applied tying (T). The values in the subscript denote the standard deviation.}
\label{tab:repr_dbert_full}
\end{table*}


\begin{figure}[h]

\centering
\includegraphics[width=\linewidth]{img/agr/JWA-SUBJ.pdf}
\caption{\textsc{jwa} -- SUBJ}
\label{fig:corr-jwa-subj}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{img/agr/JWA-SST.pdf}
\caption{\textsc{jwa} -- SST}
\label{fig:corr-jwa-sst}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{img/agr/JWA-TREC.pdf}
\caption{\textsc{jwa} -- TREC}
\label{fig:corr-jwa-trec}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{img/agr/JWA-IMDB.pdf}
\caption{\textsc{jwa} -- IMDB}
\label{fig:corr-jwa-imdb}
\end{figure}


\begin{figure}
\centering
\includegraphics[width=\linewidth]{img/agr/DBERT-SUBJ.pdf}
\caption{\textsc{dbert} -- SUBJ}
\label{fig:corr-dbert-sst}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{img/agr/JWA-SST.pdf}
\caption{\textsc{dbert} -- SST}
\label{fig:corr-dbert-subj}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{img/agr/DBERT-TREC.pdf}
\caption{\textsc{dbert} -- TREC}
\label{fig:corr-dbert-trec}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{img/agr/DBERT-IMDB.pdf}
\caption{\textsc{dbert} -- IMDB}
\label{fig:corr-dbert-imdb}
\end{figure}

