\section{The Cartography of Agreement}
\label{sec:agreement-cartography}

We have shown that by using a more appropriate correlation measure and applying regularization, agreement of saliency methods increases significantly.
In this section, we are interested in finding out the cause of increased agreement through applying regularization -- are there certain instance groups in the dataset that benefit the most, and if so, what changes in the representation space resulted in the increased agreement? 
We leverage methods from dataset cartography \cite{swayamdipta2020dataset} to distribute instances into \textit{easy-to-learn}, \textit{hard-to-learn}, and \textit{ambiguous} categories based on their prediction confidence and variability.
Concretely, if an instance exhibits \textbf{low} prediction variability and \textbf{high} prediction confidence between epochs, this implies that the model is able to quickly and accurately classify those instances, making them \textit{easy-to-learn}.
Instances that also exhibit \textbf{low} variability but \textbf{low} prediction confidence, align with the idea that the model is consistently unable to correctly classify them, making them \textit{hard-to-learn}.
Finally, instances that exhibit \textbf{high} variability and confidence close to the decision threshold indicate that the model is likely often changing its prediction between class labels for those instances, making them \textit{ambiguous}.
Since ambiguous instances are characterized by confidence near the prediction threshold, \citet{swayamdipta2020dataset} complement \textit{variability} and \textit{confidence} with another statistic introduced by \citet{chang2017active}, namely \textit{closeness}, defined as $c_i = p^{(i)} \cdot (1-p^{(i)})$, where $p^{(i)}$ is the average correct class probability of instance $x^{(i)}$ across all training epochs.
A \textbf{high} closeness value denotes that the instance is consistently near the decision boundary, and thus is a good indicator of ambiguity within the model. %

Intuitively, one would expect high agreement between saliency methods on instances that are easy-to-learn and low agreement otherwise.
However, when computing how agreement distributes across instance groups, we find that the converse is true.
In unregularized models (\Cref{fig:subj-cartography}) we observe that easy-to-learn instances exhibit low average agreement, while ambiguous instances have high average agreement.
In \Cref{tab:cart_dbert_full}, we report average agreement scores across all pairs of saliency methods on representative samples from each cartography group.\footnote{We select representative samples for each group through the relative frequency of their correct classification. If, out of $5$ epochs, an instance was correctly classified $5$ times, it is representative of the \textit{easy-to-learn} category. If it was correctly classified $0$ times, it is representative of the \textit{hard-to-learn} category, and if the number of correct classifications is $2$ or $3$, it is representative of the \textit{ambiguous} category.}
We observe a clear distinction in agreement for both the base and regularized models, which is higher for ambiguous instances when compared to easy- and hard-to-learn instance groups.
Furthermore, we can also observe a consistently high increase in agreement when the models are regularized across all instance groups for all datasets, indicating that regularization techniques reduce representation entanglement.

One might wonder how the increase in agreement distributes across instances and dataset cartography attributes.
In \Cref{fig:regularized-cartography} we visualize how the relationship between agreement and cartography attributes changes when the models are regularized.
We observe that for the \textsc{jwa} model, all datasets exhibit a consistent and significant increase in agreement.
Furthermore, we notice that for the \textsc{dbert} model, apart from increasing agreement, regularization reduces confidence of the model predictions and increases variability -- indicating that it reduces the known problem of overconfidence present in pretrained language models.

\begin{table}
\small
\centering
\begin{tabular}{lrrrrrr}
\toprule
& \multicolumn{2}{c}{Easy} & \multicolumn{2}{c}{Amb} & \multicolumn{2}{c}{Hard} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
& B & T & B & T & B & T \\
\midrule
SUBJ & $.28$ & $\mathbf{.52}$\nospacetext{$^\dagger$} & $.48$ & $\mathbf{.74}$\nospacetext{$^\dagger$} & $.40$ & $\mathbf{.57}$\nospacetext{$^\dagger$} \\
SST & $.24$ & $\mathbf{.57}$\nospacetext{$^\dagger$} & $.36$ & $\mathbf{.63}$\nospacetext{$^\dagger$} & $.30$ & $\mathbf{.55}$\nospacetext{$^\dagger$} \\
TREC & $.33$ & $\mathbf{.49}$\nospacetext{$^\dagger$} & $.50$ & $\mathbf{.62}$\nospacetext{$^\dagger$} & $.32$ & $\mathbf{.40}$\nospacetext{$^\dagger$} \\
IMDB & $.34$ & $\mathbf{.48}$\nospacetext{$^\dagger$} & $.42$ & $\mathbf{.59}$\nospacetext{$^\dagger$} & $.36$ & $\mathbf{.51}$\nospacetext{$^\dagger$} \\
\bottomrule
\end{tabular}
\caption{Average agreement (Pearson-$r$) across saliency methods pairs per cartography groups. We select representative samples for each group based on the number of times a certain instance was classified correctly during training.
We report average agreement for the unregularized model (B) and the one regularized by weight tying (T), with the numbers in \textbf{bold} indicating the higher agreement value among the two models. We averaged the results over $5$ runs. We ran one-sided Wilcoxon tests to check whether T is significantly better than B for a particular group. Significantly higher agreement values ($p < .05$) are marked with a $\dagger$.
}
\label{tab:cart_dbert_full}
\end{table}



\subsection{The Curvature of Agreement}
\label{sub:agr-curvature}

To better understand the cause of this distinction between various feature groups, we will now analyse local curvature and density in the representation space.
We are interested in: (1) how densely are the instances distributed in the representation space across cartography categories and (2) whether the local space around an instance is sharp or smooth. 
For both models and all instances, we obtain sequence representations $h$ used as inputs to the decoder.
We estimate instance density as the average distance to the nearest instance in the dataset.
We estimate local smoothness around an instance representation as the $L_2$ norm of the gradient of the hidden representation with respect to the input embeddings. %
If the gradient norm is high, the local space is sharp and minor perturbations can have a large effect on the prediction probability.

In \Cref{tab:repr_dbert}, we report correlations between each of these two statistics and dataset cartography attributes.
We observe that for the unregularized model, there is a significant negative correlation between confidence and both gradient norm and minimum distance to nearest example, indicating that the local space around easy instances is smooth and densely populated.
On the other hand, there is a high positive correlation between both closeness and variability and both gradient norm and minimum distance to nearest example -- indicating that the local space around ambiguous instances is sharp and sparsely populated.
When we turn our attention to the regularized model, we observe that the correlation between gradient norm and any of the cartography attributes vanishes, while the correlations between distance and the attributes are reduced in absolute value and their sign is flipped.

From these observations we hypothesize that the cause of low agreement on easy-to-learn instances is the multitude of possible explanations as to why such an instance should be correctly classified.
This hypothesis is in line with the Rashomon effect \cite{breiman2001statistical}, which is about there often existing a multitude of adequate descriptions that end up with the same error rate, or in our case, prediction probability.
Due to a plethora of corroborating evidence, the representation space
around easy instances is smooth to such an extent that perturbations do not significantly affect the prediction probability, which negatively affects computation of gradient-based explanations by saliency methods. 
The converse is true for ambiguous instances, where we hypothesize the model observes evidence for both classes and is unable to reach a confident decision.
However, this difficulty of reaching a decision also causes saliency methods to have a precise definition of what the evidence is -- as the local curvature is sharp, and any minor perturbation could significantly affect prediction probability.





\begin{table}
\small
\centering
\begin{tabular}{lrrrrrr}
\toprule
& \multicolumn{2}{c}{Conf} & \multicolumn{2}{c}{Close} & \multicolumn{2}{c}{Var} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
& B & T & B & T & B & T \\
\midrule
Grad norm & $-.39$ & $-.02$ & $.52$ & $.05$ & $.46$ & $.06$ \\
Min dist & $-.53$ & $.25$ & $.72$ & $-.39$ & $.64$ & $.16$ \\
\bottomrule
\end{tabular}
\caption{Correlations (Pearson-$r$) between local curvature statistics in the representation space and cartography attributes. We report average gradient norms (\textit{grad norm}) of the hidden representation with respect to the input embeddings and average distance to the nearest instance (\textit{min dist}). Columns correspond to the cartography attributes: \textit{conf} -- confidence, \textit{close} -- closeness, and \textit{var} -- confidence variance. We report the results for the \textsc{base} model (B) and the model regularized by \textsc{tying} (T). Results reported are averages over all datasets.}
\label{tab:repr_dbert}
\end{table}



\begin{figure*}
\centering
\begin{subfigure}{.45\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/cart/DBERT-SUBJ-crt-corr.pdf}
  \caption{Correctness}
  \label{fig:dbert-cart-subj}
\end{subfigure}
\begin{subfigure}{.45\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/cart/DBERT-SUBJ-crt-agr.pdf}
  \caption{Agreement}
  \label{fig:dbert-cart-subj-agreement}
\end{subfigure}
\caption{Dataset cartography for \textsc{dbert} on the SUBJ dataset. (\subref{fig:dbert-cart-subj}) shows instance \textit{correctness}, i.e., the number of times an instance has been classified correctly during training, plotted across the cartography attributes \textit{variability} (x-axis) and \textit{confidence} (y-axis). On the other hand, (\subref{fig:dbert-cart-subj-agreement}) shows the agreement on the same plot. We use a random subsample of instances in (\subref{fig:dbert-cart-subj-agreement}) to improve visibility.}
\label{fig:subj-cartography}
\end{figure*}


\begin{figure*}
\small
\centering
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/JWA-SUBJ-confidence.pdf}
  \caption{\textsc{jwa} -- SUBJ}
  \label{c}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/JWA-SST-confidence.pdf}
  \caption{\textsc{jwa} -- SST}
  \label{fig:jwa-corr-sst}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/JWA-TREC-confidence.pdf}
  \caption{\textsc{jwa} -- TREC}
  \label{fig:jwa-corr-trec}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/JWA-IMDB-confidence.pdf}
  \caption{\textsc{jwa} -- IMDB}
  \label{fig:jwa-corr-imdb}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/DBERT-SUBJ-confidence.pdf}
  \caption{\textsc{dbert} -- SUBJ}
  \label{fig:dbert-corr-subj}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/DBERT-SST-confidence.pdf}
  \caption{\textsc{dbert} -- SST}
  \label{fig:dbert-corr-sst}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/DBERT-TREC-confidence.pdf}
  \caption{\textsc{dbert} -- TREC}
  \label{fig:dbert-corr-trec}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/DBERT-IMDB-confidence.pdf}
  \caption{\textsc{dbert} -- IMDB}
  \label{fig:dbert-corr-imdb}
\end{subfigure}

\bigskip

\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/JWA-SUBJ-variability.pdf}
  \caption{\textsc{jwa} -- SUBJ}
  \label{fig:jwa-var-subj}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/JWA-SST-variability.pdf}
  \caption{\textsc{jwa} -- SST}
  \label{fig:jwa-var-sst}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/JWA-TREC-variability.pdf}
  \caption{\textsc{jwa} -- TREC}
  \label{fig:jwa-var-trec}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/JWA-IMDB-variability.pdf}
  \caption{\textsc{jwa} -- IMDB}
  \label{fig:jwa-var-imdb}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/DBERT-SUBJ-variability.pdf}
  \caption{\textsc{dbert} -- SUBJ}
  \label{fig:dbert-var-subj}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/DBERT-SST-variability.pdf}
  \caption{\textsc{dbert} -- SST}
  \label{fig:dbert-var-sst}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/DBERT-TREC-variability.pdf}
  \caption{\textsc{dbert} -- TREC}
  \label{fig:dbert-var-trec}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{img/attr/DBERT-IMDB-variability.pdf}
  \caption{\textsc{dbert} -- IMDB}
  \label{fig:dbert-var-imdb}
\end{subfigure}
\caption{Relationship between agreement and cartography. Subfigures (a)--(h) and subfigures (i)--(p) show Pearson-$r$ agreement for each instance in the dataset with respect to \textit{confidence} and \textit{variability}, respectively. The red dots pertain to the unregularized model (\textsc{base}) and the blue crosses to the regularized model (\textsc{tying}).}
\label{fig:regularized-cartography}
\end{figure*}


