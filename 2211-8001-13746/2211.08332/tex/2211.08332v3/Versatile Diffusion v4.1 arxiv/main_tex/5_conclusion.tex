In this article, we proposed Versatile Diffusion that handles text, image, and variations all in one, from which we generalized a multi-flow multimodal framework that can further extend to new tasks and domains. Through inclusive experiments, we demonstrate that such a multi-flow multimodal diffusion method can perform well on both primary tasks and applications. Moreover, VD can be a heuristic step toward universal AI research. 
