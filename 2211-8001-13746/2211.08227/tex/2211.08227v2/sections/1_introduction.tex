\section{Introduction}
\label{sec:introduction}
Reliable, fast, and efficient data processing is crucial given the growing volumes of data in both industry and research.
These needs are often addressed by using distributed dataflow frameworks like Spark~\cite{Zaharia2010}, and Flink~\cite{Carbone2015}.
As these frameworks' handle parallelism, distribution, and fault tolerance, they make it easier for users to create scalable data-parallel programs.
The resulting applications can use a variety of compute clusters for data processing.

However, it is still difficult to choose and configure resources in a way that closely meets user-specific goals and constraints~\cite{RajanKCK16,cloudcomputingchallenges2018}.
Numerous strategies have been put forth to assist users, and they can be grouped into two categories:
Model-based techniques~\cite{MaoAMK16,RajanKCK16,ShahAKW19,AlSayehS19,KirchoffXMR19,ChenLLWZ21silhouette,ScheinertTZWAWK21,WillTSBK21,AlSayehMJPS22} often rely on access to historical performance data, however, historical workload execution data is not always available.
Search-based techniques~\cite{AlipourfardLCVY17,HsuNFM18,bilal2020finding,klimovic2018selecta,fekry2020accelerating,MendesCRG20,LiuXL20,SongZLSFDS21} conduct costly profiling runs prior to executing the actual workload utilizing all, or a fraction, of the input data to iteratively create performance models.

Often enough though, the optimized resource configuration is only relevant for the workload at hand. 
Information about the underlying infrastructure are solely obtained implicitly, i.e., by measuring the performance of the target workload in one execution context.
As a consequence, a thorough understanding of utilized resources and their capabilities is lacking and insights gained cannot be easily transferred to other contexts, for instance, when profiling new workloads with different resource demands. 
This requires repeated profiling overhead for reoccurring or comparable workloads that could be avoided, rendering current approaches less resource-efficient than they could be.

Addressing these limitations, we present \emph{Perona}, a novel approach to explicit and robust infrastructure fingerprinting. 
It motivates the usage of common sets and configurations of benchmarking tools to assess the full capabilities of target infrastructures and to make the obtained benchmarking metrics directly comparable.
This explicit fingerprinting operation transparently reveals the characteristics of resources and allows ranking them.
Perona discards irrelevant benchmarking metrics in a data-driven manner by learning a dense, low-dimensional representation of input metric vectors. 
With these, more sophisticated resource decisions can be made for big data analytics, e.g., with regard to scheduling or resource allocations.
To be able to assess a recent benchmark execution, our approach incorporates results of prior benchmark executions, which is particularly useful for detecting resource degradation. 

\emph{Contributions}. The contributions of this paper are:

\begin{itemize}
    \item A novel approach for incorporating infrastructure fingerprinting into model-based methods for optimized resource configuration of workloads through ranking of resources and detection of degrading resource behavior.
    \item A method for context-aware representation learning of benchmark metrics, thereby not only discarding insignificant features but also taking prior benchmark runs and corresponding machine metrics into account. 
    \item An openly available implementation\footnote{\url{https://github.com/dos-group/perona-infrastructure-fingerprinting}} of Perona which we evaluated with regard to common metrics and in interplay with resource configuration methods for distributed dataflows and scientific workflows. 
\end{itemize}

\emph{Outline}. \autoref{sec:related_work} discusses the related work.
\autoref{sec:approach} describes the three main aspects of our approach in detail. 
\autoref{sec:evaluation} presents the results of our evaluation.
\autoref{sec:conclusion} concludes the paper and gives an outlook on future work.