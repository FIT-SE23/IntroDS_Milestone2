@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@inproceedings{ghiasi2021simple,
  title={Simple copy-paste is a strong data augmentation method for instance segmentation},
  author={Ghiasi, Golnaz and Cui, Yin and Srinivas, Aravind and Qian, Rui and Lin, Tsung-Yi and Cubuk, Ekin D and Le, Quoc V and Zoph, Barret},
  booktitle={CVPR},
  pages={2918--2928},
  year={2021}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={ECCV},
  pages={213--229},
  year={2020},
  organization={Springer}
}
@article{zhou2021probabilistic,
  title={Probabilistic two-stage detection},
  author={Zhou, Xingyi and Koltun, Vladlen and Kr{\"a}henb{\"u}hl, Philipp},
  journal={arXiv preprint arXiv:2103.07461},
  year={2021}
}

@inproceedings{zhu2020deformable,
  title={Deformable DETR: Deformable Transformers for End-to-End Object Detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{li2022dn,
  title={Dn-detr: Accelerate detr training by introducing query denoising},
  author={Li, Feng and Zhang, Hao and Liu, Shilong and Guo, Jian and Ni, Lionel M and Zhang, Lei},
  booktitle={CVPR},
  pages={13619--13627},
  year={2022}
}
@inproceedings{liu2021dab,
  title={DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR},
  author={Liu, Shilong and Li, Feng and Zhang, Hao and Yang, Xiao and Qi, Xianbiao and Su, Hang and Zhu, Jun and Zhang, Lei},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{zhang2022dino,
  title={DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection},
  author={Zhang, Hao and Li, Feng and Liu, Shilong and Zhang, Lei and Su, Hang and Zhu, Jun and Ni, Lionel and Shum, Heung-Yeung},
  booktitle={ICLR},
  year={2022}
}


@inproceedings{roh2021sparse,
  title={Sparse DETR: Efficient End-to-End Object Detection with Learnable Sparsity},
  author={Roh, Byungseok and Shin, JaeWoong and Shin, Wuhyun and Kim, Saehoon},
  booktitle={ICLR},
  year={2021}
}

@article{yao2021efficient,
  title={Efficient detr: improving end-to-end object detector with dense prior},
  author={Yao, Zhuyu and Ai, Jiangbo and Li, Boxun and Zhang, Chi},
  journal={arXiv preprint arXiv:2104.01318},
  year={2021}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and others},
  journal={arXiv preprint arXiv:1503.02531},
  volume={2},
  number={7},
  year={2015}
}

@inproceedings{beyer2022knowledge,
  title={Knowledge distillation: A good teacher is patient and consistent},
  author={Beyer, Lucas and Zhai, Xiaohua and Royer, Am{\'e}lie and Markeeva, Larisa and Anil, Rohan and Kolesnikov, Alexander},
  booktitle={CVPR},
  pages={10925--10934},
  year={2022}
}

@inproceedings{chang2023detrdistill,
  title={Detrdistill: A universal knowledge distillation framework for detr-families},
  author={Chang, Jiahao and Wang, Shuo and Xu, Hai-Ming and Chen, Zehui and Yang, Chenhongyi and Zhao, Feng},
  booktitle={ICCV},
  pages={6898--6908},
  year={2023}
}

% od
@inproceedings{tian2019fcos,
  title={Fcos: Fully convolutional one-stage object detection},
  author={Tian, Zhi and Shen, Chunhua and Chen, Hao and He, Tong},
  booktitle={ICCV},
  pages={9627--9636},
  year={2019}
}
@article{li2020generalized,
  title={Generalized focal loss: Learning qualified and distributed bounding boxes for dense object detection},
  author={Li, Xiang and Wang, Wenhai and Wu, Lijun and Chen, Shuo and Hu, Xiaolin and Li, Jun and Tang, Jinhui and Yang, Jian},
  journal={NIPS},
  volume={33},
  pages={21002--21012},
  year={2020}
}
@article{cai2019cascade,
  title={Cascade R-CNN: high quality object detection and instance segmentation},
  author={Cai, Zhaowei and Vasconcelos, Nuno},
  journal={PAMI},
  volume={43},
  number={5},
  pages={1483--1498},
  year={2019},
  publisher={IEEE}
}
@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={ICCV},
  pages={2980--2988},
  year={2017}
}
@inproceedings{redmon2016you,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={CVPR},
  pages={779--788},
  year={2016}
}
@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={NIPS},
  volume={28},
  year={2015}
}
@inproceedings{pang2019libra,
  title={Libra r-cnn: Towards balanced learning for object detection},
  author={Pang, Jiangmiao and Chen, Kai and Shi, Jianping and Feng, Huajun and Ouyang, Wanli and Lin, Dahua},
  booktitle={CVPR},
  pages={821--830},
  year={2019}
}

@inproceedings{yan2019meta,
  title={Meta r-cnn: Towards general solver for instance-level low-shot learning},
  author={Yan, Xiaopeng and Chen, Ziliang and Xu, Anni and Wang, Xiaoxi and Liang, Xiaodan and Lin, Liang},
  booktitle={CVPR},
  pages={9577--9586},
  year={2019}
}

@article{zhang2019cad,
  title={CAD-Net: A context-aware detection network for objects in remote sensing imagery},
  author={Zhang, Gongjie and Lu, Shijian and Zhang, Wei},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={57},
  number={12},
  pages={10015--10024},
  year={2019},
  publisher={IEEE}
}

@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={ICCV},
  pages={2961--2969},
  year={2017}
}
% detr
@inproceedings{dai2021dynamic,
  title={Dynamic detr: End-to-end object detection with dynamic attention},
  author={Dai, Xiyang and Chen, Yinpeng and Yang, Jianwei and Zhang, Pengchuan and Yuan, Lu and Zhang, Lei},
  booktitle={ICCV},
  pages={2988--2997},
  year={2021}
}
@inproceedings{sun2021rethinking,
  title={Rethinking transformer-based set prediction for object detection},
  author={Sun, Zhiqing and Cao, Shengcao and Yang, Yiming and Kitani, Kris M},
  booktitle={ICCV},
  pages={3611--3620},
  year={2021}
}

@inproceedings{gao2021fast,
  title={Fast convergence of detr with spatially modulated co-attention},
  author={Gao, Peng and Zheng, Minghang and Wang, Xiaogang and Dai, Jifeng and Li, Hongsheng},
  booktitle={ICCV},
  pages={3621--3630},
  year={2021}
}

@inproceedings{zhang2022accelerating,
  title={Accelerating DETR Convergence via Semantic-Aligned Matching},
  author={Zhang, Gongjie and Luo, Zhipeng and Yu, Yingchen and Cui, Kaiwen and Lu, Shijian},
  booktitle={CVPR},
  pages={949--958},
  year={2022}
}

@inproceedings{meng2021conditional,
  title={Conditional detr for fast training convergence},
  author={Meng, Depu and Chen, Xiaokang and Fan, Zejia and Zeng, Gang and Li, Houqiang and Yuan, Yuhui and Sun, Lei and Wang, Jingdong},
  booktitle={ICCV},
  pages={3651--3660},
  year={2021}
}

@inproceedings{wang2022anchor,
  title={Anchor detr: Query design for transformer-based detector},
  author={Wang, Yingming and Zhang, Xiangyu and Yang, Tong and Sun, Jian},
  booktitle={AAAI},
  volume={36},
  number={3},
  pages={2567--2575},
  year={2022}
}
@inproceedings{wang2021pnp,
  title={Pnp-detr: Towards efficient visual analysis with transformers},
  author={Wang, Tao and Yuan, Li and Chen, Yunpeng and Feng, Jiashi and Yan, Shuicheng},
  booktitle={ICCV},
  pages={4661--4670},
  year={2021}
}
% kd ref
@inproceedings{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={ICLR},
  year={2020}
}

@article{kang2021instance,
  title={Instance-conditional knowledge distillation for object detection},
  author={Kang, Zijian and Zhang, Peizhen and Zhang, Xiangyu and Sun, Jian and Zheng, Nanning},
  journal={NIPS},
  volume={34},
  pages={16468--16480},
  year={2021}
}

@inproceedings{zhang2022minivit,
  title={MiniViT: Compressing Vision Transformers with Weight Multiplexing},
  author={Zhang, Jinnian and Peng, Houwen and Wu, Kan and Liu, Mengchen and Xiao, Bin and Fu, Jianlong and Yuan, Lu},
  booktitle={CVPR},
  pages={12145--12154},
  year={2022}
}

@inproceedings{yang2022masked,
  title={Masked generative distillation},
  author={Yang, Zhendong and Li, Zhe and Shao, Mingqi and Shi, Dachuan and Yuan, Zehuan and Yuan, Chun},
  booktitle={ECCV},
  pages={53--69},
  year={2022},
  organization={Springer}
}

@inproceedings{guo2021distilling,
  title={Distilling object detectors via decoupled features},
  author={Guo, Jianyuan and Han, Kai and Wang, Yunhe and Wu, Han and Chen, Xinghao and Xu, Chunjing and Xu, Chang},
  booktitle={CVPR},
  pages={2154--2164},
  year={2021}
}

@article{chen2017learning,
  title={Learning efficient object detection models with knowledge distillation},
  author={Chen, Guobin and Choi, Wongun and Yu, Xiang and Han, Tony and Chandraker, Manmohan},
  journal={NIPS},
  volume={30},
  year={2017}
}

@inproceedings{heo2019comprehensive,
  title={A comprehensive overhaul of feature distillation},
  author={Heo, Byeongho and Kim, Jeesoo and Yun, Sangdoo and Park, Hyojin and Kwak, Nojun and Choi, Jin Young},
  booktitle={ICCV},
  pages={1921--1930},
  year={2019}
}

@inproceedings{zhao2022decoupled,
  title={Decoupled Knowledge Distillation},
  author={Zhao, Borui and Cui, Quan and Song, Renjie and Qiu, Yiyu and Liang, Jiajun},
  booktitle={CVPR},
  pages={11953--11962},
  year={2022}
}
@inproceedings{li2017mimicking,
  title={Mimicking very efficient network for object detection},
  author={Li, Quanquan and Jin, Shengying and Yan, Junjie},
  booktitle={CVPR},
  pages={6356--6364},
  year={2017}
}

@inproceedings{tian2019contrastive,
  title={Contrastive Representation Distillation},
  author={Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},
  booktitle={ICLR},
  year={2019}
}
@inproceedings{yang2022focal,
  title={Focal and global knowledge distillation for detectors},
  author={Yang, Zhendong and Li, Zhe and Jiang, Xiaohu and Gong, Yuan and Yuan, Zehuan and Zhao, Danpei and Yuan, Chun},
  booktitle={CVPR},
  pages={4643--4652},
  year={2022}
}
@inproceedings{zhang2020improve,
  title={Improve object detection with feature-based knowledge distillation: Towards accurate and efficient detectors},
  author={Zhang, Linfeng and Ma, Kaisheng},
  booktitle={ICLR},
  year={2020}
}
@inproceedings{yang2022cross,
  title={Cross-image relational knowledge distillation for semantic segmentation},
  author={Yang, Chuanguang and Zhou, Helong and An, Zhulin and Jiang, Xue and Xu, Yongjun and Zhang, Qian},
  booktitle={CVPR},
  pages={12319--12328},
  year={2022}
}
@inproceedings{yim2017gift,
  title={A gift from knowledge distillation: Fast optimization, network minimization and transfer learning},
  author={Yim, Junho and Joo, Donggyu and Bae, Jihoon and Kim, Junmo},
  booktitle={CVPR},
  pages={4133--4141},
  year={2017}
}
@inproceedings{zagoruyko2016paying,
  title={Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  booktitle={ICLR},
  year={2016}
}
@inproceedings{liu2019structured,
  title={Structured knowledge distillation for semantic segmentation},
  author={Liu, Yifan and Chen, Ke and Liu, Chris and Qin, Zengchang and Luo, Zhenbo and Wang, Jingdong},
  booktitle={CVPR},
  pages={2604--2613},
  year={2019}
}
@inproceedings{wang2019distilling,
  title={Distilling object detectors with fine-grained feature imitation},
  author={Wang, Tao and Yuan, Li and Zhang, Xiaopeng and Feng, Jiashi},
  booktitle={CVPR},
  pages={4933--4942},
  year={2019}
}

@inproceedings{dai2021general,
  title={General instance distillation for object detection},
  author={Dai, Xing and Jiang, Zeren and Wu, Zhao and Bao, Yiping and Wang, Zhicheng and Liu, Si and Zhou, Erjin},
  booktitle={CVPR},
  pages={7842--7851},
  year={2021}
}
@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={ICML},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}

% coco
@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={ECCV},
  pages={740--755},
  year={2014},
  organization={Springer}
}
%exp
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  pages={770--778},
  year={2016}
}
@article{krizhevsky2017imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={ACM},
  volume={60},
  number={6},
  pages={84--90},
  year={2017},
  publisher={AcM New York, NY, USA}
}
@article{romero2014fitnets,
  title={Fitnets: Hints for thin deep nets},
  author={Romero, Adriana and Ballas, Nicolas and Kahou, Samira Ebrahimi and Chassang, Antoine and Gatta, Carlo and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.6550},
  year={2014}
}