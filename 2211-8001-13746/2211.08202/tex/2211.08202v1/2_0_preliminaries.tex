We now define the required notation for multi-objective optimization as well as the considered objective functions and give an introduction to the \NSGA.
For $m\in \N$, an \emph{$m$-objective function} $f$ is a tuple $(f_1,\ldots, f_m)$, where $f_i\colon \Omega\rightarrow \R$ for some search space $\Omega$.
For all $x\in\Omega$, we define $f(x)=(f_1(x),\ldots, f_m(x))$.
Other than in single-objective optimization, there is usually no solution that maximizes all $m$ objective functions simultaneously.
For two solutions $x,y$, we say that $x$ \emph{dominates} $y$ and write $x\succeq y$ if and only if $f_j(x)\ge f_j(y)$ for all $1\le j\le m$.
If additionally there is a $j_0$ such that $f_{j_0}(x)>f_{j_0}(y)$, we say that $x$ \emph{strictly dominates} $y$, denoted by $x\succ y$.
A solution is \emph{Pareto-optimal} if it is not strictly dominated by any other solution.
We refer to the set of objective values of Pareto-optimal solutions as the \emph{Pareto front}.
In our analyses, we analyze the number of function evaluations until the population covers the Pareto front, i.e., until for each value $p$ on the Pareto front the population contains a solution $x$ with $f(x)=p$.

\subsection{\threeOMM}
We are interested in studying the \NSGA on a 3-objective function.
The \oneminmax function, first proposed by \cite{GielL10}, translates the well-established \onemax benchmark into a bi-objective setting. 
It is defined as $\oneminmax\colon \{0,1\}^n\rightarrow \N\times \N$ by 
\begin{equation*}
    \oneminmax(x) = (\zeromax(x),\onemax(x)) = \left(n-\sum_{i=1}^nx_i, \sum_{i=1}^nx_i\right)
\end{equation*}
for all $x=(x_1,\ldots,x_n)\in\{0,1\}^n$.

We call its translation into a 3-objective setting \threeOMM (for 3-\oneminmax).
For even $n$, we define $\threeOMM\colon \{0,1\}^n\rightarrow \N^3$ by
\begin{align*}
 \threeOMM(x)
 %  = (\zeromax(x), \onemax(x_{1\ldots n/2}),
  %                 \onemax(x_{n/2+1\ldots n}))
   = \left(n-\sum_{i=1}^n x_i,
          \sum_{i=1}^{n/2} x_i,
          \sum_{i=n/2+1}^{n} x_i\right)
\end{align*}
for all $x=(x_1,\ldots,x_n)\in\{0,1\}^n$.

\input{2_1_algorithm}