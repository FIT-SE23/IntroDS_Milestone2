Many practical applications require to optimize for multiple, conflicting objectives.
Such tasks can be tackled by population-based algorithms, whose population eventually represents the set of Pareto solutions, that are not strictly dominated by any other one.  
Thereby, they represent multiple useful trade-offs between the objectives and let the user choose among these.
Indeed, evolutionary algorithms (EAs), or, more precisely, multi-objective evolutionary algorithms (MOEAs), have been successfully applied to many real-world problems \cite{ZhouQLZSZ11}.
Among these, Zhou et al.~\cite{ZhouQLZSZ11} identify the non-dominated sorting genetic algorithm (\NSGAtwo) \cite{DebPAM02} as the most prominent one.

Both empirical evaluations \cite{KhareYD03, PurshouseF07} and recent mathematical runtime analyses \cite{ZhengLD22,DoerrQ22ppsn,BianQ22ppsn} confirm the strong results of the \NSGAtwo on bi-objective benchmarks.
The performance of the \NSGAtwo on problems with 3 or more objectives, however, is not as well understood.
Empirical studies, for example \cite{KhareYD03}, suggest that the \NSGAtwo struggles with such problems.
As a remedy, Deb and Jain~\cite{Deb_Jain_2014} proposed a modified version of the \NSGAtwo, called \NSGA.
It replaces the crowding distance, a measure which the \NSGAtwo uses in addition to the dominance relation to determine which individuals are taken in the next generation, by a procedure involving reference points in the solution space.
Their evaluations on benchmarks with 3 to 15 objectives show that the \NSGA is suitable for more than 2 objectives.

These empirical insights are, however, not yet backed with a theoretical understanding.
In order to fill this gap, we mathematically analyze the runtime of the \NSGA on \threeOMM, a 3-objective adaption of the traditional \onemax benchmark.
Let the Pareto front be the set of objective values of Pareto solutions.
We show that by employing sufficiently many reference points and a population at least the size of the Pareto front, $N \ge (\frac{n}{2}+1)^2$, once a solution for a point on the Pareto front is sampled, the population will always contain a solution for this point.
This enables us to bound the expected optimization time and give an upper bound of $O(n^3)$ on the expected number of iterations until the \NSGA creates a population that covers the Pareto front.

\paragraph*{Previous Work.}
For the sake of brevity, we do not further discuss empirical and practical works here.
Since the beginning of the century, mathematical runtime analyzes have been employed in order to gain insights and prove bounds on the running time of multi-objective randomized search heuristics \cite{LaumannsTZWD02,Giel03,Thierens03}.  
At first, research focused on analyzing simple, synthetic algorithms like the SEMO and the global SEMO (GSEMO).
Though in practical applications, usually more sophisticated algorithms are employed, these analyses still admitted useful insights.
Later, the runtimes of more realistic algorithms have been studied mathematically \cite{BrockhoffFN08,LiZZZ16}.
Only recently, first mathematical runtime analyses of the \NSGAtwo on bi-objective benchmarks appeared.
The first one of these proves a running time in $O(N n \log n)$ on the \oneminmax benchmark and in $O(Nn^2)$ on the \lotz (\textsc{LeadingOnesTrailingZeroes}) benchmark, when employing a population of $N\ge 4(n+1)$ individuals \cite{ZhengLD22}.
A central observation in their proof is that this population size suffices to ensure that, once a solution for a point on the Pareto front is sampled, the population will always contain a solution with this objective value.
Employing a population size that exactly matches the size of the Pareto front does not suffice, as then, for an exponential time, the \NSGAtwo will miss a constant fraction of the Pareto front.
Nevertheless, a smaller population is still able to find good approximations of the Pareto front \cite{ZhengD22gecco}. 
Further, by assuming the objectives to be sorted identically, the required size of the population was reduced to $2(n+1)$ \cite{BianQ22ppsn}. 
The same work studies the \NSGAtwo when employing crossover, but does not improve the running time bounds of \cite{ZhengLD22}.
Also, it introduces a novel selection mechanism, improving the running time on the \lotz benchmark to $O(n^2)$.
Recently, the \NSGAtwo was studied on a multimodal benchmark \cite{DoerrQ22ppsn}. 
We note that all these results only cover bi-objective benchmarks.

The SEMO has been studied on benchmarks with more than two objectives.
The first bounds on the expected number of function evaluations when optimizing the many-objective variants of \textsc{CountingOnesCountingZeroes} and \textsc{LeadingOnesTrailingZeroes}, \mcocz and \mlotz, are in $O(n^{m+1})$, for bitstrings of length $n$ and $m$ objectives \cite{LaumannsTZ04}.
For \mcocz, the bound was later improved to $O(n^m)$, if $m>4$, and $O(n^3 \log n)$, if $m=4$ \cite{BianQT18ijcaigeneral}.
Further, the MOEA/D, an algorithm that decomposes a multi-objective problem into multiple single-objective problems which are then solved in a co-evolutionary manner, has been studied on \mcocz and \mlotz \cite{HuangZLL21}. 
As this approach drastically differs from the one of the \NSGAtwo and \NSGA, we do not discuss these results in detail.