
@article{ge_note_2011,
	title = {A note on the complexity of {Lp} minimization},
	volume = {129},
	doi = {10.1007/s10107-011-0470-2},
	abstract = {We discuss the Lp (0 ≤ p {\textless} 1) minimization problem arising from sparse solution construction and compressed sensing. For any fixed 0 {\textless} p {\textless} 1, we prove that finding the global minimal value of the problem is strongly NP-Hard, but computing a local minimizer of the problem can be done in polynomial time. We also develop an interior-point potential reduction algorithm with a provable complexity bound and demonstrate preliminary computational results of effectiveness of the algorithm. © Springer and Mathematical Optimization Society 2011.},
	number = {2},
	journal = {Mathematical Programming},
	author = {Ge, Dongdong and Jiang, Xiaoye and Ye, Yinyu},
	year = {2011},
	keywords = {Global optimization, Interior-point method, Nonconvex programming, Sparse solution reconstruction},
	pages = {285--299},
	file = {Ge et al. - 2011 - A note on the complexity of L p minimization.pdf:/Users/brent/Zotero/storage/VSZW5A4K/Ge et al. - 2011 - A note on the complexity of L p minimization.pdf:application/pdf},
}

@article{toint_nonlinear_2013,
	title = {Nonlinear stepsize control, trust regions and regularizations for unconstrained optimization},
	volume = {28},
	issn = {1055-6788},
	url = {https://doi.org/10.1080/10556788.2011.610458},
	doi = {10.1080/10556788.2011.610458},
	abstract = {A class of algorithms for unconstrained optimization is introduced, which subsumes the classical trust-region algorithm and two of its newer variants, as well as the cubic and quadratic regularization methods. A unified theory of global convergence to first-order critical points is then described for this class.},
	number = {1},
	urldate = {2022-06-28},
	journal = {Optimization Methods and Software},
	author = {Toint, Philippe   L.},
	month = feb,
	year = {2013},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10556788.2011.610458},
	keywords = {global convergence, nonlinear optimization, unconstrained problems},
	pages = {82--95},
	file = {Snapshot:/Users/brent/Zotero/storage/Q9L9L2N6/10556788.2011.html:text/html;Toint - 2013 - Nonlinear stepsize control, trust regions and regu.pdf:/Users/brent/Zotero/storage/ZKFGMWDC/Toint - 2013 - Nonlinear stepsize control, trust regions and regu.pdf:application/pdf},
}

@article{grapiglia_convergence_2015,
	title = {On the convergence and worst-case complexity of trust-region and regularization methods for unconstrained optimization},
	volume = {152},
	issn = {0025-5610, 1436-4646},
	url = {http://link.springer.com/10.1007/s10107-014-0794-9},
	doi = {10.1007/s10107-014-0794-9},
	language = {en},
	number = {1-2},
	urldate = {2022-06-28},
	journal = {Mathematical Programming},
	author = {Grapiglia, Geovani N. and Yuan, Jinyun and Yuan, Ya-xiang},
	month = aug,
	year = {2015},
	keywords = {49M37, 90C30, 90C29, 65K05, 49M15, 68Q25, 90C60, Composite nonsmooth optimization, Global convergence, Multiobjective optimization, Regularization methods, Trust-region methods, Unconstrained Optimization, Worst-case complexity},
	pages = {491--520},
	file = {Grapiglia et al. - 2015 - On the convergence and worst-case complexity of tr.pdf:/Users/brent/Zotero/storage/TNGH8QAU/Grapiglia et al. - 2015 - On the convergence and worst-case complexity of tr.pdf:application/pdf},
}

@article{more_computing_1983,
	title = {Computing a {Trust} {Region} {Step}},
	volume = {4},
	url = {https://doi.org/10.1137/0904038},
	doi = {10.1137/0904038},
	abstract = {We propose an algorithm for the problem of minimizing a quadratic function subject to an ellipsoidal constraint and show that this algorithm is guaranteed to produce a nearly optimal solution in a finite number of iterations. We also consider the use of this algorithm in a trust region Newton’s method. In particular, we prove that under reasonable assumptions the sequence generated by Newton’s method has a limit point which satisfies the first and second order necessary conditions for a minimizer of the objective function. Numerical results for GQTPAR, which is a Fortran implementaton of our algorithm, show that GQTPAR is quite successful in a trust region method. In our tests a call to GQTPAR only required 1.6 iterations on the average.},
	number = {3},
	journal = {SIAM Journal on Scientific and Statistical Computing},
	author = {Moré, Jorge J. and Sorensen, D. C.},
	year = {1983},
	note = {\_eprint: https://doi.org/10.1137/0904038},
	pages = {553--572},
	file = {Mor and Sorensen - COMPUTING A TRUSTREGION STEP.pdf:/Users/brent/Zotero/storage/IWIVGGS2/Mor and Sorensen - COMPUTING A TRUSTREGION STEP.pdf:application/pdf},
}

@article{bian_worst-case_2013,
	title = {Worst-{Case} {Complexity} of {Smoothing} {Quadratic} {Regularization} {Methods} for {Non}-{Lipschitzian} {Optimization}},
	volume = {23},
	issn = {1052-6234, 1095-7189},
	url = {http://epubs.siam.org/doi/10.1137/120864908},
	doi = {10.1137/120864908},
	abstract = {In this paper, we propose a smoothing quadratic regularization (SQR) algorithm for solving a class of nonsmooth nonconvex, perhaps even non-Lipschitzian minimization problems, which has wide applications in statistics and sparse reconstruction. The proposed SQR algorithm is a ﬁrst order method. At each iteration, the SQR algorithm solves a strongly convex quadratic minimization problem with a diagonal Hessian matrix, which has a simple closed-form solution that is inexpensive to calculate. We show that the worst-case complexity of reaching an scaled stationary point is O( −2). Moreover, if the objective function is locally Lipschitz continuous, the SQR algorithm with a slightly modiﬁed updating scheme for the smoothing parameter and iterate can obtain an Clarke stationary point in at most O( −3) iterations.},
	language = {en},
	number = {3},
	urldate = {2022-06-21},
	journal = {SIAM Journal on Optimization},
	author = {Bian, Wei and Chen, Xiaojun},
	month = jan,
	year = {2013},
	pages = {1718--1741},
	file = {Bian and Chen - 2013 - Worst-Case Complexity of Smoothing Quadratic Regul.pdf:/Users/brent/Zotero/storage/8KJQGS95/Bian and Chen - 2013 - Worst-Case Complexity of Smoothing Quadratic Regul.pdf:application/pdf},
}

@article{li_improved_2016,
	title = {Improved dropout for shallow and deep learning},
	volume = {29},
	journal = {Advances in neural information processing systems},
	author = {Li, Zhe and Gong, Boqing and Yang, Tianbao},
	year = {2016},
	file = {Full Text:/Users/brent/Zotero/storage/ANX5PIR6/Li et al. - 2016 - Improved dropout for shallow and deep learning.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/GP327BYS/7bb060764a818184ebb1cc0d43d382aa-Abstract.html:text/html},
}

@article{chen_smoothing_2012,
	title = {Smoothing methods for nonsmooth, nonconvex minimization},
	volume = {134},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-012-0569-0},
	doi = {10.1007/s10107-012-0569-0},
	abstract = {We consider a class of smoothing methods for minimization problems where the feasible set is convex but the objective function is not convex, not differentiable and perhaps not even locally Lipschitz at the solutions. Such optimization problems arise from wide applications including image restoration, signal reconstruction, variable selection, optimal control, stochastic equilibrium and spherical approximations. In this paper, we focus on smoothing methods for solving such optimization problems, which use the structure of the minimization problems and composition of smoothing functions for the plus function (x)+. Many existing optimization algorithms and codes can be used in the inner iteration of the smoothing methods. We present properties of the smoothing functions and the gradient consistency of subdifferential associated with a smoothing function. Moreover, we describe how to update the smoothing parameter in the outer iteration of the smoothing methods to guarantee convergence of the smoothing methods to a stationary point of the original minimization problem.},
	language = {en},
	number = {1},
	urldate = {2022-06-20},
	journal = {Mathematical Programming},
	author = {Chen, Xiaojun},
	month = aug,
	year = {2012},
	keywords = {49M37, 65K10, 90C26, 90C30, Eigenvalue optimization, Nonconvex minimization, Nonsmooth, Regularized minimization problems, Smoothing methods, Stochastic variational inequality problems},
	pages = {71--99},
	file = {Full Text PDF:/Users/brent/Zotero/storage/6XU595K5/Chen - 2012 - Smoothing methods for nonsmooth, nonconvex minimiz.pdf:application/pdf},
}

@inproceedings{stella_simple_2017,
	title = {A simple and efficient algorithm for nonlinear model predictive control},
	booktitle = {2017 {IEEE} 56th {Annual} {Conference} on {Decision} and {Control} ({CDC})},
	publisher = {IEEE},
	author = {Stella, Lorenzo and Themelis, Andreas and Sopasakis, Pantelis and Patrinos, Panagiotis},
	year = {2017},
	pages = {1939--1944},
	file = {Full Text:/Users/brent/Zotero/storage/P493G8BQ/Stella et al. - 2017 - A simple and efficient algorithm for nonlinear mod.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/QGB5YYHM/8263933.html:text/html},
}

@article{frantar_m-fac_nodate,
	title = {M-{FAC}: {Efﬁcient} {Matrix}-{Free} {Approximations} of {Second}-{Order} {Information}},
	abstract = {Efﬁciently approximating local curvature information of the loss function is a key tool for optimization and compression of deep neural networks. Yet, most existing methods to approximate second-order information have high computational or storage costs, which limits their practicality. In this work, we investigate matrix-free, linear-time approaches for estimating Inverse-Hessian Vector Products (IHVPs) for the case when the Hessian can be approximated as a sum of rank-one matrices, as in the classic approximation of the Hessian by the empirical Fisher matrix. We propose two new algorithms: the ﬁrst is tailored towards network compression and can compute the IHVP for dimension d, if the Hessian is given as a sum of m rank-one matrices, using O(dm2) precomputation, O(dm) cost for computing the IHVP, and query cost O(m) for any single element of the inverse Hessian. The second algorithm targets an optimization setting, where we wish to compute the product between the inverse Hessian, estimated over a sliding window of optimization steps, and a given gradient direction, as required for preconditioned SGD. We give an algorithm with cost O(dm + m2) for computing the IHVP and O(dm + m3) for adding or removing any gradient from the sliding window. These two algorithms yield state-of-the-art results for network pruning and optimization with lower computational overhead relative to existing second-order methods. Implementations are available at [9] and [17].},
	language = {en},
	author = {Frantar, Elias and Kurtic, Eldar and Alistarh, Dan},
	pages = {14},
	file = {Frantar et al. - M-FAC Efﬁcient Matrix-Free Approximations of Seco.pdf:/Users/brent/Zotero/storage/4YKAX2GP/Frantar et al. - M-FAC Efﬁcient Matrix-Free Approximations of Seco.pdf:application/pdf},
}

@misc{haider_distributed_2021,
	title = {A {Distributed} {Optimisation} {Framework} {Combining} {Natural} {Gradient} with {Hessian}-{Free} for {Discriminative} {Sequence} {Training}},
	url = {http://arxiv.org/abs/2103.07554},
	abstract = {This paper presents a novel natural gradient and Hessian-free (NGHF) optimisation framework for neural network training that can operate eﬃcently in a distributed manner. It relies on the linear conjugate gradient (CG) algorithm to combine the natural gradient (NG) method with local curvature information from Hessian-free (HF) or other second-order methods. A solution to a numerical issue in CG allows eﬀective parameter updates to be generated with far fewer CG iterations than usually used (e.g. 5-8 instead of 200). This work also presents a novel preconditioning approach to improve the progress made by individual CG iterations for models with shared parameters. Although applicable to other training losses and model structures, NGHF is investigated in this paper for lattice-based discriminative sequence training for hybrid hidden Markov model acoustic models using a standard recurrent neural network, long short-term memory, and time delay neural network models for output probability calculation. Automatic speech recognition experiments are reported on the multi-genre broadcast data set for a range of diﬀerent acoustic model types. These experiements show that NGHF achieves larger word error rate reductions than standard stochastic gradient descent or Adam, while requiring orders of magnitude fewer parameter updates.},
	language = {en},
	urldate = {2022-05-27},
	publisher = {arXiv},
	author = {Haider, Adnan and Zhang, Chao and Kreyssig, Florian L. and Woodland, Philip C.},
	month = mar,
	year = {2021},
	note = {Number: arXiv:2103.07554
arXiv:2103.07554 [cs, eess]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
	file = {Haider et al. - 2021 - A Distributed Optimisation Framework Combining Nat.pdf:/Users/brent/Zotero/storage/IHULILEU/Haider et al. - 2021 - A Distributed Optimisation Framework Combining Nat.pdf:application/pdf},
}

@techreport{luo_adaptive_2019,
	title = {Adaptive {Gradient} {Methods} with {Dynamic} {Bound} of {Learning} {Rate}},
	url = {http://arxiv.org/abs/1902.09843},
	abstract = {Adaptive optimization methods such as AdaGrad, RMSprop and Adam have been proposed to achieve a rapid training process with an element-wise scaling term on learning rates. Though prevailing, they are observed to generalize poorly compared with SGD or even fail to converge due to unstable and extreme learning rates. Recent work has put forward some algorithms such as AMSGrad to tackle this issue but they failed to achieve considerable improvement over existing methods. In our paper, we demonstrate that extreme learning rates can lead to poor performance. We provide new variants of Adam and AMSGrad, called AdaBound and AMSBound respectively, which employ dynamic bounds on learning rates to achieve a gradual and smooth transition from adaptive methods to SGD and give a theoretical proof of convergence. We further conduct experiments on various popular tasks and models, which is often insufficient in previous work. Experimental results show that new variants can eliminate the generalization gap between adaptive methods and SGD and maintain higher learning speed early in training at the same time. Moreover, they can bring significant improvement over their prototypes, especially on complex deep networks. The implementation of the algorithm can be found at https://github.com/Luolc/AdaBound .},
	number = {arXiv:1902.09843},
	urldate = {2022-05-26},
	institution = {arXiv},
	author = {Luo, Liangchen and Xiong, Yuanhao and Liu, Yan and Sun, Xu},
	month = feb,
	year = {2019},
	doi = {10.48550/arXiv.1902.09843},
	note = {arXiv:1902.09843 [cs, stat]
type: article},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/VNTRAKCT/Luo et al. - 2019 - Adaptive Gradient Methods with Dynamic Bound of Le.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/9MANRKYE/1902.html:text/html},
}

@misc{zhao_towards_2021,
	title = {Towards {Better} {Accuracy}-efficiency {Trade}-offs: {Divide} and {Co}-training},
	shorttitle = {Towards {Better} {Accuracy}-efficiency {Trade}-offs},
	url = {http://arxiv.org/abs/2011.14660},
	abstract = {The width of a neural network matters since increasing the width will necessarily increase the model capacity. However, the performance of a network does not improve linearly with the width and soon gets saturated. In this case, we argue that increasing the number of networks (ensemble) can achieve better accuracy-efﬁciency trade-offs than purely increasing the width. To prove it, one large network is divided into several small ones regarding its parameters and regularization components. Each of these small networks has a fraction of the original one’s parameters. We then train these small networks together and make them see various views of the same data to increase their diversity. During this co-training process, networks can also learn from each other. As a result, small networks can achieve better ensemble performance than the large one with few or no extra parameters or FLOPs. Small networks can also achieve faster inference speed than the large one by concurrent running on different devices. We validate our argument with 8 different neural architectures on common benchmarks through extensive experiments. The code is available at https://github. com/mzhaoshuai/Divide-and-Co-training.},
	language = {en},
	urldate = {2022-05-26},
	publisher = {arXiv},
	author = {Zhao, Shuai and Zhou, Liguang and Wang, Wenxiao and Cai, Deng and Lam, Tin Lun and Xu, Yangsheng},
	month = mar,
	year = {2021},
	note = {Number: arXiv:2011.14660
arXiv:2011.14660 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Zhao et al. - 2021 - Towards Better Accuracy-efficiency Trade-offs Div.pdf:/Users/brent/Zotero/storage/8D36X5YW/Zhao et al. - 2021 - Towards Better Accuracy-efficiency Trade-offs Div.pdf:application/pdf},
}

@article{zagoruyko_wide_2016,
	title = {Wide residual networks},
	journal = {arXiv preprint arXiv:1605.07146},
	author = {Zagoruyko, Sergey and Komodakis, Nikos},
	year = {2016},
	file = {Full Text:/Users/brent/Zotero/storage/S7F6ZVUC/Zagoruyko and Komodakis - 2016 - Wide residual networks.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/XN8RS6RF/1605.html:text/html},
}

@inproceedings{savarese_domain-independent_2021,
	address = {Nashville, TN, USA},
	title = {Domain-{Independent} {Dominance} of {Adaptive} {Methods}},
	isbn = {978-1-66544-509-2},
	url = {https://ieeexplore.ieee.org/document/9578761/},
	doi = {10.1109/CVPR46437.2021.01602},
	abstract = {From a simpliﬁed analysis of adaptive methods, we derive AvaGrad, a new optimizer which outperforms SGD on vision tasks when its adaptability is properly tuned. We observe that the power of our method is partially explained by a decoupling of learning rate and adaptability, greatly simplifying hyperparameter search. In light of this observation, we demonstrate that, against conventional wisdom, Adam can also outperform SGD on vision tasks, as long as the coupling between its learning rate and adaptability is taken into account. In practice, AvaGrad matches the best results, as measured by generalization accuracy, delivered by any existing optimizer (SGD or adaptive) across image classiﬁcation (CIFAR, ImageNet) and character-level language modelling (Penn Treebank) tasks.},
	language = {en},
	urldate = {2022-05-26},
	booktitle = {2021 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Savarese, Pedro and McAllester, David and Babu, Sudarshan and Maire, Michael},
	month = jun,
	year = {2021},
	pages = {16281--16290},
	file = {Savarese et al. - 2021 - Domain-Independent Dominance of Adaptive Methods.pdf:/Users/brent/Zotero/storage/JJKQWA2F/Savarese et al. - 2021 - Domain-Independent Dominance of Adaptive Methods.pdf:application/pdf},
}

@inproceedings{tripuraneni_stochastic_2018,
	title = {Stochastic {Cubic} {Regularization} for {Fast} {Nonconvex} {Optimization}},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper/2018/hash/db1915052d15f7815c8b88e879465a1e-Abstract.html},
	urldate = {2022-05-25},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Tripuraneni, Nilesh and Stern, Mitchell and Jin, Chi and Regier, Jeffrey and Jordan, Michael I},
	year = {2018},
	file = {Full Text PDF:/Users/brent/Zotero/storage/2THY6LD3/Tripuraneni et al. - 2018 - Stochastic Cubic Regularization for Fast Nonconvex.pdf:application/pdf},
}

@article{cartis_adaptive_2011,
	title = {Adaptive cubic regularisation methods for unconstrained optimization. {Part} {I}: motivation, convergence and numerical results},
	volume = {127},
	issn = {0025-5610, 1436-4646},
	shorttitle = {Adaptive cubic regularisation methods for unconstrained optimization. {Part} {I}},
	url = {http://link.springer.com/10.1007/s10107-009-0286-5},
	doi = {10.1007/s10107-009-0286-5},
	language = {en},
	number = {2},
	urldate = {2022-05-25},
	journal = {Mathematical Programming},
	author = {Cartis, Coralia and Gould, Nicholas I. M. and Toint, Philippe L.},
	month = apr,
	year = {2011},
	pages = {245--295},
	file = {Cartis et al. - 2011 - Adaptive cubic regularisation methods for unconstr.pdf:/Users/brent/Zotero/storage/SGBEHBAY/Cartis et al. - 2011 - Adaptive cubic regularisation methods for unconstr.pdf:application/pdf},
}

@article{cartis_adaptive_2011-1,
	title = {Adaptive cubic regularisation methods for unconstrained optimization. {Part} {II}: worst-case function- and derivative-evaluation complexity},
	volume = {130},
	issn = {0025-5610, 1436-4646},
	shorttitle = {Adaptive cubic regularisation methods for unconstrained optimization. {Part} {II}},
	url = {http://link.springer.com/10.1007/s10107-009-0337-y},
	doi = {10.1007/s10107-009-0337-y},
	language = {en},
	number = {2},
	urldate = {2022-05-25},
	journal = {Mathematical Programming},
	author = {Cartis, Coralia and Gould, Nicholas I. M. and Toint, Philippe L.},
	month = dec,
	year = {2011},
	pages = {295--319},
	file = {Cartis et al. - 2011 - Adaptive cubic regularisation methods for unconstr.pdf:/Users/brent/Zotero/storage/CB64NLF3/Cartis et al. - 2011 - Adaptive cubic regularisation methods for unconstr.pdf:application/pdf},
}

@inproceedings{martens_deep_2010,
	title = {Deep learning via hessian-free optimization.},
	volume = {27},
	booktitle = {{ICML}},
	author = {Martens, James},
	year = {2010},
	pages = {735--742},
	file = {Full Text:/Users/brent/Zotero/storage/UNW2QUKF/Martens - 2010 - Deep learning via hessian-free optimization..pdf:application/pdf},
}

@incollection{martens_training_2012,
	title = {Training deep and recurrent networks with hessian-free optimization},
	booktitle = {Neural networks: {Tricks} of the trade},
	publisher = {Springer},
	author = {Martens, James and Sutskever, Ilya},
	year = {2012},
	pages = {479--535},
	file = {Full Text:/Users/brent/Zotero/storage/GUJ5ZUSC/Martens and Sutskever - 2012 - Training deep and recurrent networks with hessian-.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/DSVMHUFQ/978-3-642-35289-8_27.html:text/html},
}

@article{pearlmutter_fast_1994,
	title = {Fast exact multiplication by the {Hessian}},
	volume = {6},
	number = {1},
	journal = {Neural computation},
	author = {Pearlmutter, Barak A.},
	year = {1994},
	note = {Publisher: MIT Press},
	pages = {147--160},
	file = {Full Text:/Users/brent/Zotero/storage/4I4ZDG8U/Pearlmutter - 1994 - Fast exact multiplication by the Hessian.pdf:application/pdf},
}

@book{montavon_neural_2012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Neural {Networks}: {Tricks} of the {Trade}: {Second} {Edition}},
	volume = {7700},
	isbn = {978-3-642-35288-1 978-3-642-35289-8},
	shorttitle = {Neural {Networks}},
	url = {http://link.springer.com/10.1007/978-3-642-35289-8},
	language = {en},
	urldate = {2022-05-25},
	publisher = {Springer Berlin Heidelberg},
	editor = {Montavon, Grégoire and Orr, Geneviève B. and Müller, Klaus-Robert},
	year = {2012},
	doi = {10.1007/978-3-642-35289-8},
	file = {Montavon et al. - 2012 - Neural Networks Tricks of the Trade Second Editi.pdf:/Users/brent/Zotero/storage/RX8E59PD/Montavon et al. - 2012 - Neural Networks Tricks of the Trade Second Editi.pdf:application/pdf},
}

@techreport{hu_second-order_2019,
	title = {Second-order {Information} in {First}-order {Optimization} {Methods}},
	url = {http://arxiv.org/abs/1912.09926},
	abstract = {In this paper, we try to uncover the second-order essence of several first-order optimization methods. For Nesterov Accelerated Gradient, we rigorously prove that the algorithm makes use of the difference between past and current gradients, thus approximates the Hessian and accelerates the training. For adaptive methods, we related Adam and Adagrad to a powerful technique in computation statistics---Natural Gradient Descent. These adaptive methods can in fact be treated as relaxations of NGD with only a slight difference lying in the square root of the denominator in the update rules. Skeptical about the effect of such difference, we design a new algorithm---AdaSqrt, which removes the square root in the denominator and scales the learning rate by sqrt(T). Surprisingly, our new algorithm is comparable to various first-order methods(such as SGD and Adam) on MNIST and even beats Adam on CIFAR-10! This phenomenon casts doubt on the convention view that the square root is crucial and training without it will lead to terrible performance. As far as we have concerned, so long as the algorithm tries to explore second or even higher information of the loss surface, then proper scaling of the learning rate alone will guarantee fast training and good generalization performance. To the best of our knowledge, this is the first paper that seriously considers the necessity of square root among all adaptive methods. We believe that our work can shed light on the importance of higher-order information and inspire the design of more powerful algorithms in the future.},
	number = {arXiv:1912.09926},
	urldate = {2022-05-24},
	institution = {arXiv},
	author = {Hu, Yuzheng and Lin, Licong and Tang, Shange},
	month = dec,
	year = {2019},
	doi = {10.48550/arXiv.1912.09926},
	note = {arXiv:1912.09926 [cs, math, stat]
version: 1
type: article},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/W35M7TI9/Hu et al. - 2019 - Second-order Information in First-order Optimizati.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/WQUT52LX/1912.html:text/html},
}

@article{vaswani_painless_nodate,
	title = {Painless {Stochastic} {Gradient}: {Interpolation}, {Line}-{Search}, and {Convergence} {Rates}},
	abstract = {Recent works have shown that stochastic gradient descent (SGD) achieves the fast convergence rates of full-batch gradient descent for over-parameterized models satisfying certain interpolation conditions. However, the step-size used in these works depends on unknown quantities and SGD’s practical performance heavily relies on the choice of this step-size. We propose to use line-search techniques to automatically set the step-size when training models that can interpolate the data. In the interpolation setting, we prove that SGD with a stochastic variant of the classic Armijo line-search attains the deterministic convergence rates for both convex and strongly-convex functions. Under additional assumptions, SGD with Armijo line-search is shown to achieve fast convergence for non-convex functions. Furthermore, we show that stochastic extra-gradient with a Lipschitz line-search attains linear convergence for an important class of non-convex functions and saddle-point problems satisfying interpolation. To improve the proposed methods’ practical performance, we give heuristics to use larger step-sizes and acceleration. We compare the proposed algorithms against numerous optimization methods on standard classiﬁcation tasks using both kernel methods and deep networks. The proposed methods result in competitive performance across all models and datasets, while being robust to the precise choices of hyper-parameters. For multi-class classiﬁcation using deep networks, SGD with Armijo line-search results in both faster convergence and better generalization.},
	language = {en},
	author = {Vaswani, Sharan and Laradji, Issam and Gidel, Gauthier and Mishkin, Aaron and Schmidt, Mark and Lacoste-Julien, Simon},
	pages = {14},
	file = {Snapshot:/Users/brent/Zotero/storage/CXGXV9D5/2557911c1bf75c2b643afb4ecbfc8ec2-Abstract.html:text/html;Vaswani et al. - Painless Stochastic Gradient Interpolation, Line-.pdf:/Users/brent/Zotero/storage/VZMR72ED/Vaswani et al. - Painless Stochastic Gradient Interpolation, Line-.pdf:application/pdf},
}

@article{bollapragada_nonlinear_2022,
	title = {Nonlinear acceleration of momentum and primal-dual algorithms},
	issn = {0025-5610, 1436-4646},
	url = {https://link.springer.com/10.1007/s10107-022-01775-x},
	doi = {10.1007/s10107-022-01775-x},
	abstract = {We describe convergence acceleration schemes for multistep optimization algorithms where the underlying ﬁxed-point operator is not symmetric. In particular, our analysis handles algorithms with momentum terms such as Nesterov’s accelerated method or primal-dual methods. The acceleration technique combines previous iterates through a weighted sum, whose coefﬁcients are computed via a simple linear system. We analyze performance in both online and ofﬂine modes, and we study in particular a variant of Nesterov’s method that uses nonlinear acceleration at each iteration. We use Crouzeix’s conjecture to show that acceleration performance is controlled by the solution of a Chebyshev problem on the numerical range of a non-symmetric operator modeling the behavior of iterates near the optimum. Numerical experiments are detailed on logistic regression problems.},
	language = {en},
	urldate = {2022-05-24},
	journal = {Mathematical Programming},
	author = {Bollapragada, Raghu and Scieur, Damien and d’Aspremont, Alexandre},
	month = feb,
	year = {2022},
	file = {Bollapragada et al. - 2022 - Nonlinear acceleration of momentum and primal-dual.pdf:/Users/brent/Zotero/storage/FKCMLKPF/Bollapragada et al. - 2022 - Nonlinear acceleration of momentum and primal-dual.pdf:application/pdf;Full Text:/Users/brent/Zotero/storage/8XZJLYB3/Bollapragada et al. - 2022 - Nonlinear acceleration of momentum and primal-dual.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/VGETF63A/s10107-022-01775-x.html:text/html},
}

@article{bergou_subsampling_2018,
	title = {A subsampling line-search method with second-order results},
	journal = {arXiv preprint arXiv:1810.07211},
	author = {Bergou, El-houcine and Diouane, Youssef and Kunc, Vladimir and Kungurtsev, Vyacheslav and Royer, Clément W.},
	year = {2018},
	file = {Full Text:/Users/brent/Zotero/storage/M9K4YXSU/Bergou et al. - 2018 - A subsampling line-search method with second-order.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/NNQ8D94F/1810.html:text/html},
}

@article{scieur_nonlinear_2018,
	title = {Nonlinear acceleration of deep neural networks},
	author = {Scieur, Damien and Oyallon, Edouard and d'Aspremont, Alexandre and Bach, Francis},
	year = {2018},
	file = {Full Text:/Users/brent/Zotero/storage/JC9R7HRQ/Scieur et al. - 2018 - Nonlinear acceleration of deep neural networks.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/Y6F5VTNT/hal-01799269.html:text/html},
}

@inproceedings{yao_pyhessian_2020,
	title = {Pyhessian: {Neural} networks through the lens of the hessian},
	shorttitle = {Pyhessian},
	booktitle = {2020 {IEEE} international conference on big data ({Big} data)},
	publisher = {IEEE},
	author = {Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael W.},
	year = {2020},
	pages = {581--590},
	file = {Full Text:/Users/brent/Zotero/storage/NQAK5S9S/Yao et al. - 2020 - Pyhessian Neural networks through the lens of the.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/XV4C49PY/9378171.html:text/html},
}

@article{berahas_robust_2020,
	title = {A robust multi-batch {L}-{BFGS} method for machine learning},
	volume = {35},
	number = {1},
	journal = {Optimization Methods and Software},
	author = {Berahas, Albert S. and Takáč, Martin},
	year = {2020},
	note = {Publisher: Taylor \& Francis},
	pages = {191--219},
	file = {Full Text:/Users/brent/Zotero/storage/YXLNW6DR/Berahas and Takáč - 2020 - A robust multi-batch L-BFGS method for machine lea.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/AD3K3X6U/10556788.2019.html:text/html},
}

@article{yao_large_2018,
	title = {Large batch size training of neural networks with adversarial training and second-order information},
	journal = {arXiv preprint arXiv:1810.01021},
	author = {Yao, Zhewei and Gholami, Amir and Arfeen, Daiyaan and Liaw, Richard and Gonzalez, Joseph and Keutzer, Kurt and Mahoney, Michael},
	year = {2018},
	file = {Full Text:/Users/brent/Zotero/storage/R4CAGTQM/Yao et al. - 2018 - Large batch size training of neural networks with .pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/4VUKWJ4V/1810.html:text/html},
}

@article{anil_scalable_2020,
	title = {Scalable second order optimization for deep learning},
	journal = {arXiv preprint arXiv:2002.09018},
	author = {Anil, Rohan and Gupta, Vineet and Koren, Tomer and Regan, Kevin and Singer, Yoram},
	year = {2020},
	file = {Full Text:/Users/brent/Zotero/storage/S7A7NDDS/Anil et al. - 2020 - Scalable second order optimization for deep learni.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/D64YTADF/2002.html:text/html},
}

@misc{yao_large_2020,
	title = {Large batch size training of neural networks with adversarial training and second-order information},
	url = {http://arxiv.org/abs/1810.01021},
	abstract = {The most straightforward method to accelerate Stochastic Gradient Descent (SGD) computation is to distribute the randomly selected batch of inputs over multiple processors. To keep the distributed processors fully utilized requires commensurately growing the batch size. However, large batch training often leads to poorer generalization. A recently proposed solution for this problem is to use adaptive batch sizes in SGD. In this case, one starts with a small number of processes and scales the processes as training progresses. Two major challenges with this approach are (i) that dynamically resizing the cluster can add non-trivial overhead, in part since it is currently not supported, and (ii) that the overall speed up is limited by the initial phase with smaller batches. In this work, we address both challenges by developing a new adaptive batch size framework, with autoscaling based on the Ray framework. This allows very efficient elastic scaling with negligible resizing overhead (0.32{\textbackslash}\% of time for ResNet18 ImageNet training). Furthermore, we propose a new adaptive batch size training scheme using second order methods and adversarial training. These enable increasing batch sizes earlier during training, which leads to better training time. We extensively evaluate our method on Cifar-10/100, SVHN, TinyImageNet, and ImageNet datasets, using multiple neural networks, including ResNets and smaller networks such as SqueezeNext. Our method exceeds the performance of existing solutions in terms of both accuracy and the number of SGD iterations (up to 1{\textbackslash}\% and \$5{\textbackslash}times\$, respectively). Importantly, this is achieved without any additional hyper-parameter tuning to tailor our method in any of these experiments.},
	language = {en},
	urldate = {2022-05-24},
	publisher = {arXiv},
	author = {Yao, Zhewei and Gholami, Amir and Arfeen, Daiyaan and Liaw, Richard and Gonzalez, Joseph and Keutzer, Kurt and Mahoney, Michael},
	month = jan,
	year = {2020},
	note = {Number: arXiv:1810.01021
arXiv:1810.01021 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control, Computer Science - Artificial Intelligence},
	file = {Yao et al. - 2020 - Large batch size training of neural networks with .pdf:/Users/brent/Zotero/storage/KV45HVR7/Yao et al. - 2020 - Large batch size training of neural networks with .pdf:application/pdf},
}

@inproceedings{bollapragada_progressive_2018,
	title = {A progressive batching {L}-{BFGS} method for machine learning},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Bollapragada, Raghu and Nocedal, Jorge and Mudigere, Dheevatsa and Shi, Hao-Jun and Tang, Ping Tak Peter},
	year = {2018},
	pages = {620--629},
	file = {Full Text:/Users/brent/Zotero/storage/HLAKSJXU/Bollapragada et al. - 2018 - A progressive batching L-BFGS method for machine l.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/Z8TSXUSS/bollapragada18a.html:text/html},
}

@book{conn_trust_2000,
	title = {Trust region methods},
	publisher = {SIAM},
	author = {Conn, Andrew R. and Gould, Nicholas IM and Toint, Philippe L.},
	year = {2000},
	file = {Conn et al. - 2000 - Trust region methods.pdf:/Users/brent/Zotero/storage/CKR48S5V/Conn et al. - 2000 - Trust region methods.pdf:application/pdf},
}

@mastersthesis{ye_efficient_2011,
	title = {Efficient trust region subproblem algorithms},
	school = {University of Waterloo},
	author = {Ye, Heng},
	year = {2011},
	file = {Full Text:/Users/brent/Zotero/storage/2PMNCKG6/Ye - 2011 - Efficient trust region subproblem algorithms.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/P8WLPGST/6297.html:text/html},
}

@article{bottou_optimization_2018,
	title = {Optimization {Methods} for {Large}-{Scale} {Machine} {Learning}},
	volume = {60},
	issn = {0036-1445, 1095-7200},
	url = {https://epubs.siam.org/doi/10.1137/16M1080173},
	doi = {10.1137/16M1080173},
	abstract = {This paper provides a review and commentary on the past, present, and future of numerical optimization algorithms in the context of machine learning applications. Through case studies on text classiﬁcation and the training of deep neural networks, we discuss how optimization problems arise in machine learning and what makes them challenging. A major theme of our study is that large-scale machine learning represents a distinctive setting in which the stochastic gradient (SG) method has traditionally played a central role while conventional gradient-based nonlinear optimization techniques typically falter. Based on this viewpoint, we present a comprehensive theory of a straightforward, yet versatile SG algorithm, discuss its practical behavior, and highlight opportunities for designing algorithms with improved performance. This leads to a discussion about the next generation of optimization methods for large-scale machine learning, including an investigation of two main streams of research on techniques that diminish noise in the stochastic directions and methods that make use of second-order derivative approximations.},
	language = {en},
	number = {2},
	urldate = {2022-05-10},
	journal = {SIAM Review},
	author = {Bottou, Léon and Curtis, Frank E. and Nocedal, Jorge},
	month = jan,
	year = {2018},
	pages = {223--311},
	file = {1606.04838.zip:/Users/brent/Zotero/storage/A8F7BFBW/1606.04838.zip:application/zip;Bottou et al. - 2018 - Optimization Methods for Large-Scale Machine Learn.pdf:/Users/brent/Zotero/storage/5YX3UGP2/Bottou et al. - 2018 - Optimization Methods for Large-Scale Machine Learn.pdf:application/pdf},
}

@article{chen_optimality_2013,
	title = {Optimality {Conditions} and a {Smoothing} {Trust} {Region} {Newton} {Method} for {NonLipschitz} {Optimization}},
	volume = {23},
	issn = {1052-6234, 1095-7189},
	url = {http://epubs.siam.org/doi/10.1137/120871390},
	doi = {10.1137/120871390},
	abstract = {Regularized minimization problems with nonconvex, nonsmooth, perhaps nonLipschitz penalty functions have attracted considerable attention in recent years, owing to their wide applications in image restoration, signal reconstruction, and variable selection. In this paper, we derive aﬃne-scaled second order necessary and suﬃcient conditions for local minimizers of such minimization problems. Moreover, we propose a global convergent smoothing trust region Newton method which can ﬁnd a point satisfying the aﬃne-scaled second order necessary optimality condition from any starting point. Numerical examples are given to demonstrate the eﬀectiveness of the smoothing trust region Newton method.},
	language = {en},
	number = {3},
	urldate = {2022-04-10},
	journal = {SIAM Journal on Optimization},
	author = {Chen, Xiaojun and Niu, Lingfeng and Yuan, Yaxiang},
	month = jan,
	year = {2013},
	pages = {1528--1552},
	file = {Chen et al. - 2013 - Optimality Conditions and a Smoothing Trust Region.pdf:/Users/brent/Zotero/storage/NPKYJS3E/Chen et al. - 2013 - Optimality Conditions and a Smoothing Trust Region.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/AK7FYGLC/120871390.html:text/html},
}

@inproceedings{biswas_semidefinite_2004,
	title = {Semidefinite programming for ad hoc wireless sensor network localization},
	isbn = {1-58113-846-6},
	doi = {10.1145/984622.984630},
	abstract = {We describe an SDP relaxation based method for the position estimation problem in wireless sensor networks. The optimization problem is set up so as to minimize the error in sensor positions to fit distance measures. Observable gauges are developed to check the quality of the point estimation of sensors or to detect erroneous sensors. The performance of this technique is highly satisfactory compared to other techniques. Very few anchor nodes are required to accurately estimate the position of all the unknown nodes in a network. Also the estimation errors are minimal even when the anchor nodes are not suitably placed within the network or the distance measurements are noisy.},
	booktitle = {Third {International} {Symposium} on {Information} {Processing} in {Sensor} {Networks}, {IPSN} 2004},
	author = {Biswas, Pratik and Ye, Yinyu},
	year = {2004},
	keywords = {Semidefinite Programming, Sensor Network Localization},
	pages = {46--54},
	file = {Biswas and Ye - 2004 - Semidefinite programming for ad hoc wireless senso.pdf:/Users/brent/Zotero/storage/DMLKCX7T/Biswas and Ye - 2004 - Semidefinite programming for ad hoc wireless senso.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/ZPNWV8SR/984622.html:text/html},
}

@article{biswas_semidefinite_2006,
	title = {Semidefinite programming approaches for sensor network localization with noisy distance measurements},
	volume = {3},
	number = {4},
	journal = {IEEE transactions on automation science and engineering},
	author = {Biswas, Pratik and Liang, T.-C. and Toh, K.-C. and Ye, Yinyu and Wang, T.-C.},
	year = {2006},
	note = {Publisher: IEEE},
	pages = {360--371},
	file = {Biswas et al. - 2006 - Semidefinite programming approaches for sensor net.pdf:/Users/brent/Zotero/storage/QPMZBF98/Biswas et al. - 2006 - Semidefinite programming approaches for sensor net.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/VXP957VQ/1707954.html:text/html},
}

@article{biswas_semidefinite_2006-1,
	title = {Semidefinite programming based algorithms for sensor network localization},
	volume = {2},
	number = {2},
	journal = {ACM Transactions on Sensor Networks (TOSN)},
	author = {Biswas, Pratik and Lian, Tzu-Chen and Wang, Ta-Chung and Ye, Yinyu},
	year = {2006},
	note = {Publisher: ACM New York, NY, USA},
	pages = {188--220},
	file = {Full Text:/Users/brent/Zotero/storage/YQG9M643/Biswas et al. - 2006 - Semidefinite programming based algorithms for sens.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/Y9UH8QC7/1149283.html:text/html},
}

@article{wang_further_2008,
	title = {Further relaxations of the semidefinite programming approach to sensor network localization},
	volume = {19},
	number = {2},
	journal = {SIAM Journal on Optimization},
	author = {Wang, Zizhuo and Zheng, Song and Ye, Yinyu and Boyd, Stephen},
	year = {2008},
	note = {Publisher: SIAM},
	pages = {655--673},
	file = {Snapshot:/Users/brent/Zotero/storage/BP3LQAWB/060669395.html:text/html;Wang et al. - 2008 - Further relaxations of the semidefinite programmin.pdf:/Users/brent/Zotero/storage/R3XX9BGA/Wang et al. - 2008 - Further relaxations of the semidefinite programmin.pdf:application/pdf},
}

@misc{ye_zero-order_nodate,
	title = {Zero-{Order} and {First}-{Order} {Optimization} {Algorithms} {I}},
	language = {en},
	author = {Ye, Yinyu},
	file = {Ye - Zero-Order and First-Order Optimization Algorithms.pdf:/Users/brent/Zotero/storage/GF5UIY8N/Ye - Zero-Order and First-Order Optimization Algorithms.pdf:application/pdf},
}

@misc{ye_more_nodate,
	title = {More {First}-{Order} {Optimization} {Algorithms}},
	language = {en},
	author = {Ye, Yinyu},
	file = {Ye - More First-Order Optimization Algorithms.pdf:/Users/brent/Zotero/storage/6G4U7RPE/Ye - More First-Order Optimization Algorithms.pdf:application/pdf},
}

@misc{ye_duallagrangian_nodate,
	title = {Dual/{Lagrangian} {Methods} for {Constrained} {Optimization}},
	language = {en},
	author = {Ye, Yinyu},
	file = {Ye - DualLagrangian Methods for Constrained Optimizati.pdf:/Users/brent/Zotero/storage/PRAGD7KL/Ye - DualLagrangian Methods for Constrained Optimizati.pdf:application/pdf},
}

@article{baydin_automatic_2018,
	title = {Automatic differentiation in machine learning: a survey},
	shorttitle = {Automatic differentiation in machine learning},
	url = {http://arxiv.org/abs/1502.05767},
	abstract = {Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD), also called algorithmic differentiation or simply "autodiff", is a family of techniques similar to but more general than backpropagation for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established field with applications in areas including computational fluid dynamics, atmospheric sciences, and engineering design optimization. Until very recently, the fields of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other's results. Despite its relevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names "dynamic computational graphs" and "differentiable programming". We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main implementation techniques. By precisely defining the main differentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms "autodiff", "automatic differentiation", and "symbolic differentiation" as these are encountered more and more in machine learning settings.},
	urldate = {2022-04-17},
	journal = {arXiv:1502.05767 [cs, stat]},
	author = {Baydin, Atilim Gunes and Pearlmutter, Barak A. and Radul, Alexey Andreyevich and Siskind, Jeffrey Mark},
	month = feb,
	year = {2018},
	note = {arXiv: 1502.05767},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, 68W30, 65D25, 68T05, Computer Science - Symbolic Computation, G.1.4, I.2.6},
	file = {arXiv.org Snapshot:/Users/brent/Zotero/storage/RX2AJT92/1502.html:text/html;Baydin et al. - 2018 - Automatic differentiation in machine learning a s.pdf:/Users/brent/Zotero/storage/6S7A3EGW/Baydin et al. - 2018 - Automatic differentiation in machine learning a s.pdf:application/pdf},
}

@article{martens_learning_nodate,
	title = {Learning {Recurrent} {Neural} {Networks} with {Hessian}-{Free} {Optimization}},
	abstract = {In this work we resolve the long-outstanding problem of how to effectively train recurrent neural networks (RNNs) on complex and difﬁcult sequence modeling problems which may contain long-term data dependencies. Utilizing recent advances in the Hessian-free optimization approach (Martens, 2010), together with a novel damping scheme, we successfully train RNNs on two sets of challenging problems. First, a collection of pathological synthetic datasets which are known to be impossible for standard optimization approaches (due to their extremely long-term dependencies), and second, on three natural and highly complex real-world sequence datasets where we ﬁnd that our method signiﬁcantly outperforms the previous state-of-theart method for training neural sequence models: the Long Short-term Memory approach of Hochreiter and Schmidhuber (1997). Additionally, we offer a new interpretation of the generalized Gauss-Newton matrix of Schraudolph (2002) which is used within the HF approach of Martens.},
	language = {en},
	author = {Martens, James and Sutskever, Ilya},
	pages = {8},
	file = {Martens and Sutskever - Learning Recurrent Neural Networks with Hessian-Fr.pdf:/Users/brent/Zotero/storage/WLJLZAF9/Martens and Sutskever - Learning Recurrent Neural Networks with Hessian-Fr.pdf:application/pdf},
}

@article{yao_hessian-based_nodate,
	title = {Hessian-based {Analysis} of {Large} {Batch} {Training} and {Robustness} to {Adversaries}},
	abstract = {Large batch size training of Neural Networks has been shown to incur accuracy loss when trained with the current methods. The exact underlying reasons for this are still not completely understood. Here, we study large batch size training through the lens of the Hessian operator and robust optimization. In particular, we perform a Hessian based study to analyze exactly how the landscape of the loss function changes when training with large batch size. We compute the true Hessian spectrum, without approximation, by back-propagating the second derivative. Extensive experiments on multiple networks show that saddle-points are not the cause for generalization gap of large batch size training, and the results consistently show that large batch converges to points with noticeably higher Hessian spectrum. Furthermore, we show that robust training allows one to favors ﬂat areas, as points with large Hessian spectrum show poor robustness to adversarial perturbation. We further study this relationship, and provide empirical and theoretical proof that the inner loop for robust training is a saddle-free optimization problem. We present detailed experiments with ﬁve different network architectures, including a residual network, tested on MNIST, CIFAR-10, and CIFAR-100 datasets.},
	language = {en},
	author = {Yao, Zhewei and Gholami, Amir and Lei, Qi and Keutzer, Kurt and Mahoney, Michael W},
	pages = {11},
	file = {Yao et al. - Hessian-based Analysis of Large Batch Training and.pdf:/Users/brent/Zotero/storage/IZLZ7MYU/Yao et al. - Hessian-based Analysis of Large Batch Training and.pdf:application/pdf},
}

@inproceedings{martens_optimizing_2015,
	title = {Optimizing neural networks with kronecker-factored approximate curvature},
	booktitle = {International conference on machine learning},
	publisher = {PMLR},
	author = {Martens, James and Grosse, Roger},
	year = {2015},
	pages = {2408--2417},
	file = {Martens and Grosse - 2015 - Optimizing neural networks with kronecker-factored.pdf:/Users/brent/Zotero/storage/ESFZ673V/Martens and Grosse - 2015 - Optimizing neural networks with kronecker-factored.pdf:application/pdf;Martens and Grosse - 2015 - Optimizing neural networks with kronecker-factored.pdf:/Users/brent/Zotero/storage/UKGZ2KPW/Martens and Grosse - 2015 - Optimizing neural networks with kronecker-factored.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/ULMH8HHW/martens15.html:text/html},
}

@inproceedings{osawa_large-scale_2019,
	address = {Long Beach, CA, USA},
	title = {Large-{Scale} {Distributed} {Second}-{Order} {Optimization} {Using} {Kronecker}-{Factored} {Approximate} {Curvature} for {Deep} {Convolutional} {Neural} {Networks}},
	isbn = {978-1-72813-293-8},
	url = {https://ieeexplore.ieee.org/document/8953771/},
	doi = {10.1109/CVPR.2019.01264},
	abstract = {Large-scale distributed training of deep neural networks suffer from the generalization gap caused by the increase in the effective mini-batch size. Previous approaches try to solve this problem by varying the learning rate and batch size over epochs and layers, or some ad hoc modiﬁcation of the batch normalization. We propose an alternative approach using a second-order optimization method that shows similar generalization capability to ﬁrst-order methods, but converges faster and can handle larger minibatches. To test our method on a benchmark where highly optimized ﬁrst-order methods are available as references, we train ResNet-50 on ImageNet. We converged to 75\% Top-1 validation accuracy in 35 epochs for mini-batch sizes under 16,384, and achieved 75\% even with a mini-batch size of 131,072, which took only 978 iterations.},
	language = {en},
	urldate = {2022-04-12},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Osawa, Kazuki and Tsuji, Yohei and Ueno, Yuichiro and Naruse, Akira and Yokota, Rio and Matsuoka, Satoshi},
	month = jun,
	year = {2019},
	pages = {12351--12359},
	file = {Osawa et al. - 2019 - Large-Scale Distributed Second-Order Optimization .pdf:/Users/brent/Zotero/storage/X5WM9SUK/Osawa et al. - 2019 - Large-Scale Distributed Second-Order Optimization .pdf:application/pdf},
}

@article{bian_smoothing_2012,
	title = {Smoothing {SQP} algorithm for non-{Lipschitz} optimization with complexity analysis},
	journal = {Preprint, February},
	author = {Bian, W. and Chen, XIAOJUN},
	year = {2012},
	file = {Full Text:/Users/brent/Zotero/storage/MKSP3HLT/Bian and Chen - 2012 - Smoothing SQP algorithm for non-Lipschitz optimiza.pdf:application/pdf},
}

@article{lu_iterative_2014,
	title = {Iterative reweighted minimization methods for \$\$ l\_p \$\$ lp regularized unconstrained nonlinear programming},
	volume = {147},
	number = {1},
	journal = {Mathematical Programming},
	author = {Lu, Zhaosong},
	year = {2014},
	note = {Publisher: Springer},
	pages = {277--307},
	file = {Full Text:/Users/brent/Zotero/storage/5AWPXMMD/Lu - 2014 - Iterative reweighted minimization methods for \$\$ l.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/54GZWEIP/s10107-013-0722-4.html:text/html},
}

@article{lemarechal_new_1995,
	title = {New variants of bundle methods},
	volume = {69},
	issn = {0025-5610, 1436-4646},
	url = {http://link.springer.com/10.1007/BF01585555},
	doi = {10.1007/BF01585555},
	abstract = {In this paper we describe a number of new variants of bundle methods for nonsmooth unconstrained and constrained convex optimization, convex-concave games and variaüonal inequaliües. We outline the ideas underlying these methods and present rate-of-convergenceestimates.},
	language = {en},
	number = {1-3},
	urldate = {2021-11-22},
	journal = {Mathematical Programming},
	author = {Lemaréchal, Claude and Nemirovskii, Arkadii and Nesterov, Yurii},
	month = jul,
	year = {1995},
	pages = {111--147},
	file = {Lemaréchal et al. - 1995 - New variants of bundle methods.pdf:/Users/brent/Zotero/storage/TMINJKIH/Lemaréchal et al. - 1995 - New variants of bundle methods.pdf:application/pdf},
}

@book{nocedal_numerical_2006,
	title = {Numerical optimization},
	publisher = {Springer Science \& Business Media},
	author = {Nocedal, Jorge and Wright, Stephen},
	year = {2006},
	keywords = {Mathematical optimization, Nonlinear optimization},
	file = {Nocedal, Wright_2006_Numerical optimization:/Users/brent/Zotero/storage/N4YTXIVK/Nocedal, Wright_2006_Numerical optimization.pdf:application/pdf},
}

@article{themelis_douglas-rachford_2021,
	title = {Douglas-{Rachford} splitting and {ADMM} for nonconvex optimization: {Accelerated} and {Newton}-type linesearch algorithms},
	shorttitle = {Douglas-{Rachford} splitting and {ADMM} for nonconvex optimization},
	url = {http://arxiv.org/abs/2005.10230},
	abstract = {Although the performance of popular optimization algorithms such as Douglas-Rachford splitting (DRS) and the ADMM is satisfactory in small and well-scaled problems, ill conditioning and problem size pose a severe obstacle to their reliable employment. Expanding on recent convergence results for DRS and ADMM applied to nonconvex problems, we propose two linesearch algorithms to enhance and robustify these methods by means of quasi-Newton directions. The proposed algorithms are suited for nonconvex problems, require the same black-box oracle of DRS and ADMM, and maintain their (subsequential) convergence properties. Numerical evidence shows that the employment of L-BFGS in the proposed framework greatly improves convergence of DRS and ADMM, making them robust to ill conditioning. Under regularity and nondegeneracy assumptions at the limit point, superlinear convergence is shown when quasi-Newton Broyden directions are adopted.},
	urldate = {2022-03-25},
	journal = {arXiv:2005.10230 [math]},
	author = {Themelis, Andreas and Stella, Lorenzo and Patrinos, Panagiotis},
	month = nov,
	year = {2021},
	note = {arXiv: 2005.10230},
	keywords = {Mathematics - Optimization and Control, 90C06, 90C25, 90C26, 49J52, 49J53},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/LH6E9MJT/Themelis et al. - 2021 - Douglas-Rachford splitting and ADMM for nonconvex .pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/WTYSK53R/2005.html:text/html},
}

@misc{ye_second_2005,
	title = {Second {Order} {Optimization} {Algorithms} {II}: {Interior}-{Point} {Algorithms}},
	language = {en},
	author = {Ye, Yinyu},
	year = {2005},
	file = {Ye - Second Order Optimization Algorithms II Interior-.pdf:/Users/brent/Zotero/storage/9CNKGN3Q/Ye - Second Order Optimization Algorithms II Interior-.pdf:application/pdf},
}

@misc{tibshirani_proximal_nodate,
	title = {Proximal {Gradient} {Descent} and {Acceleration}},
	language = {en},
	author = {Tibshirani, Ryan},
	file = {Tibshirani - Proximal Gradient Descent and Acceleration.pdf:/Users/brent/Zotero/storage/4QEQAV9R/Tibshirani - Proximal Gradient Descent and Acceleration.pdf:application/pdf},
}

@article{kong_fista_2021,
	title = {{FISTA} and {Extensions}–{Review} and {New} {Insights}},
	journal = {arXiv preprint arXiv:2107.01267},
	author = {Kong, Weiwei and Melo, Jefferson G. and Monteiro, Renato DC},
	year = {2021},
	file = {Kong et al. - 2021 - FISTA and Extensions–Review and New Insights.pdf:/Users/brent/Zotero/storage/8RT5JIPY/Kong et al. - 2021 - FISTA and Extensions–Review and New Insights.pdf:application/pdf},
}

@article{beck_fast_2009,
	title = {A {Fast} {Iterative} {Shrinkage}-{Thresholding} {Algorithm} for {Linear} {Inverse} {Problems}},
	volume = {2},
	issn = {1936-4954},
	url = {http://epubs.siam.org/doi/10.1137/080716542},
	doi = {10.1137/080716542},
	abstract = {We consider the class of iterative shrinkage-thresholding algorithms (ISTA) for solving linear inverse problems arising in signal/image processing. This class of methods, which can be viewed as an extension of the classical gradient algorithm, is attractive due to its simplicity and thus is adequate for solving large-scale problems even with dense matrix data. However, such methods are also known to converge quite slowly. In this paper we present a new fast iterative shrinkage-thresholding algorithm (FISTA) which preserves the computational simplicity of ISTA but with a global rate of convergence which is proven to be signiﬁcantly better, both theoretically and practically. Initial promising numerical results for wavelet-based image deblurring demonstrate the capabilities of FISTA which is shown to be faster than ISTA by several orders of magnitude.},
	language = {en},
	number = {1},
	urldate = {2022-03-23},
	journal = {SIAM Journal on Imaging Sciences},
	author = {Beck, Amir and Teboulle, Marc},
	month = jan,
	year = {2009},
	pages = {183--202},
	file = {Beck and Teboulle - 2009 - A Fast Iterative Shrinkage-Thresholding Algorithm .pdf:/Users/brent/Zotero/storage/5N5JKRFF/Beck and Teboulle - 2009 - A Fast Iterative Shrinkage-Thresholding Algorithm .pdf:application/pdf},
}

@article{nesterov_gradient_2013,
	title = {Gradient methods for minimizing composite functions},
	volume = {140},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-012-0629-5},
	doi = {10.1007/s10107-012-0629-5},
	abstract = {In this paper we analyze several new methods for solving optimization problems with the objective function formed as a sum of two terms: one is smooth and given by a black-box oracle, and another is a simple general convex function with known structure. Despite the absence of good properties of the sum, such problems, both in convex and nonconvex cases, can be solved with efficiency typical for the first part of the objective. For convex problems of the above structure, we consider primal and dual variants of the gradient method (with convergence rate \$\$O{\textbackslash}left(\{1 {\textbackslash}over k\}{\textbackslash}right)\$\$), and an accelerated multistep version with convergence rate \$\$O{\textbackslash}left(\{1 {\textbackslash}over k{\textasciicircum}2\}{\textbackslash}right)\$\$, where \$\$k\$\$is the iteration counter. For nonconvex problems with this structure, we prove convergence to a point from which there is no descent direction. In contrast, we show that for general nonsmooth, nonconvex problems, even resolving the question of whether a descent direction exists from a point is NP-hard. For all methods, we suggest some efficient “line search” procedures and show that the additional computational work necessary for estimating the unknown problem class parameters can only multiply the complexity of each iteration by a small constant factor. We present also the results of preliminary computational experiments, which confirm the superiority of the accelerated scheme.},
	language = {en},
	number = {1},
	urldate = {2022-03-23},
	journal = {Mathematical Programming},
	author = {Nesterov, Yu.},
	month = aug,
	year = {2013},
	pages = {125--161},
	file = {Springer Full Text PDF:/Users/brent/Zotero/storage/H26D5LK5/Nesterov - 2013 - Gradient methods for minimizing composite function.pdf:application/pdf},
}

@article{yuan_recent_2015,
	title = {Recent advances in trust region algorithms},
	volume = {151},
	number = {1},
	journal = {Mathematical Programming},
	author = {Yuan, Ya-xiang},
	year = {2015},
	note = {Publisher: Springer},
	pages = {249--281},
	file = {Snapshot:/Users/brent/Zotero/storage/5WCDVAM3/s10107-015-0893-2.html:text/html;Springer Full Text PDF:/Users/brent/Zotero/storage/SASRIDJZ/Yuan - 2015 - Recent advances in trust region algorithms.pdf:application/pdf},
}

@article{ben-tal_hidden_1996,
	title = {Hidden convexity in some nonconvex quadratically constrained quadratic programming},
	volume = {72},
	issn = {0025-5610, 1436-4646},
	url = {http://link.springer.com/10.1007/BF02592331},
	doi = {10.1007/BF02592331},
	abstract = {We consider the problem of minimizing an indefinite quadratic objective function subject to twosided indelinite quadratic constraints. Under a suitable simultaneous diagonalization assumption \{\vphantom{\}}which trivially holds for trust region type problems), we prove that the original problem is equivalent to a convex minimization problem with simple linear constraints. We then consider a special problem of minimizing a concave quadratic function subject to finitely many convex quadratic constraints, which is also shown to be equivalent to a minimax convex problem. In both cases we derive the explicit nonlinear transformations which allow for recovering the optimal solution of the nonconvex problems via their equivalent convex counterparts. Special cases and applications are also discussed. We outline interior-point polynon{\textasciitilde}al-time algorithms for the solution of the equivalent convex programs.},
	language = {en},
	number = {1},
	urldate = {2022-02-27},
	journal = {Mathematical Programming},
	author = {Ben-Tal, Aharon and Teboulle, Marc},
	month = jan,
	year = {1996},
	pages = {51--63},
	file = {Ben-Tal and Teboulle - 1996 - Hidden convexity in some nonconvex quadratically c.pdf:/Users/brent/Zotero/storage/9IPMYAYA/Ben-Tal and Teboulle - 1996 - Hidden convexity in some nonconvex quadratically c.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/GIQIFQ3G/BF02592331.html:text/html},
}

@article{ye_affine_1992,
	title = {On affine scaling algorithms for nonconvex quadratic programming},
	volume = {56},
	number = {1},
	journal = {Mathematical Programming},
	author = {Ye, Yinyu},
	year = {1992},
	note = {Publisher: Springer},
	pages = {285--300},
	file = {Snapshot:/Users/brent/Zotero/storage/NWDF6YEV/BF01580903.html:text/html;Ye - 1992 - On affine scaling algorithms for nonconvex quadrat.pdf:/Users/brent/Zotero/storage/D8GFRYR6/Ye - 1992 - On affine scaling algorithms for nonconvex quadrat.pdf:application/pdf},
}

@book{luenberger_linear_2021,
	address = {Cham},
	series = {International {Series} in {Operations} {Research} \& {Management} {Science}},
	title = {Linear and {Nonlinear} {Programming}},
	volume = {228},
	isbn = {978-3-030-85449-2 978-3-030-85450-8},
	url = {https://link.springer.com/10.1007/978-3-030-85450-8},
	language = {en},
	urldate = {2022-02-15},
	publisher = {Springer International Publishing},
	author = {Luenberger, David G. and Ye, Yinyu},
	year = {2021},
	doi = {10.1007/978-3-030-85450-8},
	file = {Luenberger and Ye - 2021 - Linear and Nonlinear Programming.pdf:/Users/brent/Zotero/storage/N7WRN96G/Luenberger and Ye - 2021 - Linear and Nonlinear Programming.pdf:application/pdf},
}

@article{adachi_solving_2017,
	title = {Solving the {Trust}-{Region} {Subproblem} {By} a {Generalized} {Eigenvalue} {Problem}},
	volume = {27},
	issn = {1052-6234, 1095-7189},
	url = {http://epubs.siam.org/doi/10.1137/16M1058200},
	doi = {10.1137/16M1058200},
	abstract = {The state-of-the-art algorithms for solving the trust-region subproblem (TRS) are based on an iterative process, involving solutions of many linear systems, eigenvalue problems, subspace optimization, or line search steps. A relatively underappreciated fact, due to Gander, Golub, and von Matt [Linear Algebra Appl., 114 (1989), pp. 815–839], is that TRSs can be solved by one generalized eigenvalue problem, with no outer iterations. In this paper we rediscover this fact and discover its great practicality, which exhibits good performance both in accuracy and eﬃciency. Moreover, we generalize the approach in various directions, namely by allowing for an ellipsoidal constraint, dealing with the so-called hard case, and obtaining approximate solutions eﬃciently when high accuracy is unnecessary. We demonstrate that the resulting algorithm is a general-purpose TRS solver, eﬀective both for dense and large-sparse problems, including the so-called hard case. Our algorithm is easy to implement: its essence is a few lines of MATLAB code.},
	language = {en},
	number = {1},
	urldate = {2022-01-19},
	journal = {SIAM Journal on Optimization},
	author = {Adachi, Satoru and Iwata, Satoru and Nakatsukasa, Yuji and Takeda, Akiko},
	month = jan,
	year = {2017},
	pages = {269--291},
	file = {Adachi et al. - 2017 - Solving the Trust-Region Subproblem By a Generaliz.pdf:/Users/brent/Zotero/storage/8ZL9WHMN/Adachi et al. - 2017 - Solving the Trust-Region Subproblem By a Generaliz.pdf:application/pdf;Adachi et al. - 2017 - Solving the Trust-Region Subproblem By a Generaliz.pdf:/Users/brent/Zotero/storage/8P6V9YMY/Adachi et al. - 2017 - Solving the Trust-Region Subproblem By a Generaliz.pdf:application/pdf;Full Text:/Users/brent/Zotero/storage/6EJ8F6Y7/Adachi et al. - 2017 - Solving the trust-region subproblem by a generaliz.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/28VXRNCG/16m1058200.html:text/html},
}

@book{ye_interior_1997,
	title = {Interior point algorithms: theory and analysis},
	volume = {44},
	shorttitle = {Interior point algorithms},
	publisher = {John Wiley \& Sons},
	author = {Ye, Yinyu},
	year = {1997},
	file = {Snapshot:/Users/brent/Zotero/storage/2RIHH5P7/books.html:text/html;Ye - 1997 - Interior point algorithms theory and analysis.pdf:/Users/brent/Zotero/storage/EDXLQWNB/Ye - 1997 - Interior point algorithms theory and analysis.pdf:application/pdf},
}

@article{ye_new_2003,
	title = {New results on quadratic minimization},
	volume = {14},
	number = {1},
	journal = {SIAM Journal on Optimization},
	author = {Ye, Yinyu and Zhang, Shuzhong},
	year = {2003},
	note = {Publisher: SIAM},
	pages = {245--267},
	file = {Snapshot:/Users/brent/Zotero/storage/R6HXJEPB/S105262340139001X.html:text/html;Ye and Zhang - 2003 - New results on quadratic minimization.pdf:/Users/brent/Zotero/storage/A2DUF6AH/Ye and Zhang - 2003 - New results on quadratic minimization.pdf:application/pdf},
}

@book{nesterov_lectures_2018,
	title = {Lectures on convex optimization},
	volume = {137},
	publisher = {Springer},
	author = {Nesterov, Yurii},
	year = {2018},
	file = {Nesterov - 2018 - Lectures on convex optimization.pdf:/Users/brent/Zotero/storage/8HX869QC/Nesterov - 2018 - Lectures on convex optimization.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/M6WPS6GV/10.html:text/html},
}

@inproceedings{yuan_review_2000,
	title = {A review of trust region algorithms for optimization},
	volume = {99},
	booktitle = {Iciam},
	author = {Yuan, Ya-xiang},
	year = {2000},
	note = {Issue: 1},
	keywords = {Nonlinear optimization},
	pages = {271--282},
	file = {Yuan_2000_A review of trust region algorithms for optimization:/Users/brent/Zotero/storage/JNTXN6QM/Yuan_2000_A review of trust region algorithms for optimization.pdf:application/pdf},
}

@article{lemarechal_geometric_2001,
	title = {A geometric study of duality gaps, with applications},
	volume = {90},
	number = {3},
	journal = {Mathematical Programming},
	author = {Lemaréchal, Claude and Renaud, Arnaud},
	year = {2001},
	note = {Publisher: Springer},
	pages = {399--427},
	file = {Snapshot:/Users/brent/Zotero/storage/RAVKRC42/PL00011429.html:text/html;Springer Full Text PDF:/Users/brent/Zotero/storage/2BR3875R/Lemaréchal and Renaud - 2001 - A geometric study of duality gaps, with applicatio.pdf:application/pdf},
}

@article{ho-nguyen_second-order_2017,
	title = {A {Second}-{Order} {Cone} {Based} {Approach} for {Solving} the {Trust}-{Region} {Subproblem} and {Its} {Variants}},
	volume = {27},
	issn = {1052-6234},
	url = {https://epubs.siam.org/doi/abs/10.1137/16M1065197},
	doi = {10.1137/16M1065197},
	abstract = {We study the trust-region subproblem (TRS) of minimizing a nonconvex quadratic function over the unit ball with additional conic constraints. Despite having a nonconvex objective, it is known that the classical TRS and a number of its variants are polynomial-time solvable. In this paper, we follow a second-order cone (SOC) based approach to derive an exact convex reformulation of the TRS under a structural condition on the conic constraint. Our structural condition is immediately satisfied when there are no additional conic constraints, and it generalizes several such conditions studied in the literature. As a result, our study highlights an explicit connection between the classical nonconvex TRS and smooth convex quadratic minimization, which allows for the application of cheap iterative methods such as Nesterov's accelerated gradient descent, to the TRS. Furthermore, under slightly stronger conditions, we give a low-complexity characterization of the convex hull of the epigraph of the nonconvex quadratic function intersected with the constraints defining the domain without any additional variables. We also explore the inclusion of additional hollow constraints to the domain of the TRS, and convexification of the associated epigraph.},
	number = {3},
	urldate = {2021-11-16},
	journal = {SIAM Journal on Optimization},
	author = {Ho-Nguyen, Nam and Kilinç-Karzan, Fatma},
	month = jan,
	year = {2017},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {90C26, 90C30, 90C25, 90C20, convex hull, convex reformulation, iterative methods, second-order conic programming, trust-region subproblem},
	pages = {1485--1512},
	file = {Ho-Nguyen and Kilinç-Karzan - 2017 - A Second-Order Cone Based Approach for Solving the.pdf:/Users/brent/Zotero/storage/78J4TAW2/Ho-Nguyen and Kilinç-Karzan - 2017 - A Second-Order Cone Based Approach for Solving the.pdf:application/pdf;Ho-Nguyen and Kilinç-Karzan - 2017 - A Second-Order Cone Based Approach for Solving the.pdf:/Users/brent/Zotero/storage/76VFNTIR/Ho-Nguyen and Kilinç-Karzan - 2017 - A Second-Order Cone Based Approach for Solving the.pdf:application/pdf},
}

@article{sturm_cones_2003,
	title = {On cones of nonnegative quadratic functions},
	volume = {28},
	number = {2},
	journal = {Mathematics of Operations research},
	author = {Sturm, Jos F. and Zhang, Shuzhong},
	year = {2003},
	note = {Publisher: INFORMS},
	pages = {246--267},
	file = {Full Text:/Users/brent/Zotero/storage/ZY8FZJLP/Sturm and Zhang - 2003 - On cones of nonnegative quadratic functions.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/BDWWA49A/moor.28.2.246.html:text/html;Snapshot:/Users/brent/Zotero/storage/NBN5GR2U/moor.28.2.246.html:text/html;Sturm and Zhang - 2003 - On cones of nonnegative quadratic functions.pdf:/Users/brent/Zotero/storage/R8I38P7R/Sturm and Zhang - 2003 - On cones of nonnegative quadratic functions.pdf:application/pdf},
}

@article{liu_quadratic_2019,
	title = {Quadratic optimization with orthogonality constraint: explicit Łojasiewicz exponent and linear convergence of retraction-based line-search and stochastic variance-reduced gradient methods},
	volume = {178},
	issn = {1436-4646},
	shorttitle = {Quadratic optimization with orthogonality constraint},
	url = {https://doi.org/10.1007/s10107-018-1285-1},
	doi = {10.1007/s10107-018-1285-1},
	abstract = {The problem of optimizing a quadratic form over an orthogonality constraint (QP-OC for short) is one of the most fundamental matrix optimization problems and arises in many applications. In this paper, we characterize the growth behavior of the objective function around the critical points of the QP-OC problem and demonstrate how such characterization can be used to obtain strong convergence rate results for iterative methods that exploit the manifold structure of the orthogonality constraint (i.e., the Stiefel manifold) to find a critical point of the problem. Specifically, our primary contribution is to show that the Łojasiewicz exponent at any critical point of the QP-OC problem is 1 / 2. Such a result is significant, as it expands the currently very limited repertoire of optimization problems for which the Łojasiewicz exponent is explicitly known. Moreover, it allows us to show, in a unified manner and for the first time, that a large family of retraction-based line-search methods will converge linearly to a critical point of the QP-OC problem. Then, as our secondary contribution, we propose a stochastic variance-reduced gradient (SVRG) method called Stiefel-SVRG for solving the QP-OC problem and present a novel Łojasiewicz inequality-based linear convergence analysis of the method. An important feature of Stiefel-SVRG is that it allows for general retractions and does not require the computation of any vector transport on the Stiefel manifold. As such, it is computationally more advantageous than other recently-proposed SVRG-type algorithms for manifold optimization.},
	language = {en},
	number = {1},
	urldate = {2021-10-31},
	journal = {Mathematical Programming},
	author = {Liu, Huikang and So, Anthony Man-Cho and Wu, Weijie},
	month = nov,
	year = {2019},
	keywords = {90C26, 65K05, 15B10, 58C05, 58C40, Line-search methods, Linear convergence, Łojasiewicz inequality, Quadratic optimization with orthogonality constraints, Stochastic variance-reduced gradient method},
	pages = {215--262},
	file = {Liu et al. - 2019 - Quadratic optimization with orthogonality constrai.pdf:/Users/brent/Zotero/storage/5ZRDUUR2/Liu et al. - 2019 - Quadratic optimization with orthogonality constrai.pdf:application/pdf},
}

@article{chen_complexity_2014,
	title = {Complexity of unconstrained {$L_2-L_p$} minimization},
	volume = {143},
	issn = {0025-5610, 1436-4646},
	url = {http://link.springer.com/10.1007/s10107-012-0613-0},
	doi = {10.1007/s10107-012-0613-0},
	language = {en},
	number = {1-2},
	urldate = {2022-03-17},
	journal = {Mathematical Programming},
	author = {Chen, Xiaojun and Ge, Dongdong and Wang, Zizhuo and Ye, Yinyu},
	month = feb,
	year = {2014},
	pages = {371--383},
	file = {Chen et al. - 2014 - Complexity of unconstrained \$\$L_2-L_p\$\$ minimizati.pdf:/Users/brent/Zotero/storage/5BRRMTW6/Chen et al. - 2014 - Complexity of unconstrained \$\$L_2-L_p\$\$ minimizati.pdf:application/pdf},
}

@misc{de_sa_accelerated_2017,
	title = {Accelerated {Stochastic} {Power} {Iteration}},
	url = {http://arxiv.org/abs/1707.02670},
	abstract = {Principal component analysis (PCA) is one of the most powerful tools in machine learning. The simplest method for PCA, the power iteration, requires \${\textbackslash}mathcal O(1/{\textbackslash}Delta)\$ full-data passes to recover the principal component of a matrix with eigen-gap \${\textbackslash}Delta\$. Lanczos, a significantly more complex method, achieves an accelerated rate of \${\textbackslash}mathcal O(1/{\textbackslash}sqrt\{{\textbackslash}Delta\})\$ passes. Modern applications, however, motivate methods that only ingest a subset of available data, known as the stochastic setting. In the online stochastic setting, simple algorithms like Oja's iteration achieve the optimal sample complexity \${\textbackslash}mathcal O({\textbackslash}sigma{\textasciicircum}2/{\textbackslash}Delta{\textasciicircum}2)\$. Unfortunately, they are fully sequential, and also require \${\textbackslash}mathcal O({\textbackslash}sigma{\textasciicircum}2/{\textbackslash}Delta{\textasciicircum}2)\$ iterations, far from the \${\textbackslash}mathcal O(1/{\textbackslash}sqrt\{{\textbackslash}Delta\})\$ rate of Lanczos. We propose a simple variant of the power iteration with an added momentum term, that achieves both the optimal sample and iteration complexity. In the full-pass setting, standard analysis shows that momentum achieves the accelerated rate, \${\textbackslash}mathcal O(1/{\textbackslash}sqrt\{{\textbackslash}Delta\})\$. We demonstrate empirically that naively applying momentum to a stochastic method, does not result in acceleration. We perform a novel, tight variance analysis that reveals the "breaking-point variance" beyond which this acceleration does not occur. By combining this insight with modern variance reduction techniques, we construct stochastic PCA algorithms, for the online and offline setting, that achieve an accelerated iteration complexity \${\textbackslash}mathcal O(1/{\textbackslash}sqrt\{{\textbackslash}Delta\})\$. Due to the embarassingly parallel nature of our methods, this acceleration translates directly to wall-clock time if deployed in a parallel environment. Our approach is very general, and applies to many non-convex optimization problems that can now be accelerated using the same technique.},
	language = {en},
	urldate = {2022-08-05},
	publisher = {arXiv},
	author = {De Sa, Christopher and He, Bryan and Mitliagkas, Ioannis and Ré, Christopher and Xu, Peng},
	month = jul,
	year = {2017},
	note = {arXiv:1707.02670 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control, Computer Science - Data Structures and Algorithms, Mathematics - Numerical Analysis},
	file = {De Sa et al. - 2017 - Accelerated Stochastic Power Iteration.pdf:/Users/brent/Zotero/storage/C64DQU5L/De Sa et al. - 2017 - Accelerated Stochastic Power Iteration.pdf:application/pdf},
}

@inproceedings{xu_second-order_2020,
	title = {Second-order optimization for non-convex machine learning: {An} empirical study},
	shorttitle = {Second-order optimization for non-convex machine learning},
	booktitle = {Proceedings of the 2020 {SIAM} {International} {Conference} on {Data} {Mining}},
	publisher = {SIAM},
	author = {Xu, Peng and Roosta, Fred and Mahoney, Michael W.},
	year = {2020},
	pages = {199--207},
	file = {Full Text:/Users/brent/Zotero/storage/DV5V6AK3/Xu et al. - 2020 - Second-order optimization for non-convex machine l.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/D82PHJ8C/1.9781611976236.html:text/html},
}

@misc{babanezhad_stop_2015,
	title = {Stop {Wasting} {My} {Gradients}: {Practical} {SVRG}},
	shorttitle = {Stop {Wasting} {My} {Gradients}},
	url = {http://arxiv.org/abs/1511.01942},
	doi = {10.48550/arXiv.1511.01942},
	abstract = {We present and analyze several strategies for improving the performance of stochastic variance-reduced gradient (SVRG) methods. We first show that the convergence rate of these methods can be preserved under a decreasing sequence of errors in the control variate, and use this to derive variants of SVRG that use growing-batch strategies to reduce the number of gradient calculations required in the early iterations. We further (i) show how to exploit support vectors to reduce the number of gradient computations in the later iterations, (ii) prove that the commonly-used regularized SVRG iteration is justified and improves the convergence rate, (iii) consider alternate mini-batch selection strategies, and (iv) consider the generalization error of the method.},
	urldate = {2022-08-05},
	publisher = {arXiv},
	author = {Babanezhad, Reza and Ahmed, Mohamed Osama and Virani, Alim and Schmidt, Mark and Konečný, Jakub and Sallinen, Scott},
	month = nov,
	year = {2015},
	note = {arXiv:1511.01942 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control, Statistics - Computation},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/LFRN582K/Babanezhad et al. - 2015 - Stop Wasting My Gradients Practical SVRG.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/ZA2DSPZP/1511.html:text/html},
}

@article{auslender_how_1997,
	title = {How to deal with the unbounded in optimization: {Theory} and algorithms},
	volume = {79},
	issn = {1436-4646},
	shorttitle = {How to deal with the unbounded in optimization},
	url = {https://doi.org/10.1007/BF02614308},
	doi = {10.1007/BF02614308},
	abstract = {The aim of this survey is to show how the unbounded arises in optimization problems and how it leads to fundamental notions which are not only useful for proving theoretical results such as convergence of algorithms and the existence of optimal solutions, but also for constructing new methods.},
	language = {en},
	number = {1},
	urldate = {2022-08-04},
	journal = {Mathematical Programming},
	author = {Auslender, A.},
	month = oct,
	year = {1997},
	keywords = {Convex analysis, Convex and linear programming, Existence of optimal solutions, Penalty and barrier methods, Recession functions},
	pages = {3--18},
	file = {Full Text PDF:/Users/brent/Zotero/storage/DRR8EXKR/Auslender - 1997 - How to deal with the unbounded in optimization Th.pdf:application/pdf},
}

@article{jiang_unified_nodate,
	title = {A {UNIFIED} {ADAPTIVE} {TENSOR} {APPROXIMATION} {SCHEME} {TO} {ACCELERATE} {COMPOSITE} {CONVEX} {OPTIMIZATION}{\textbackslash}ast},
	abstract = {In this paper, we propose a unified two-phase scheme to accelerate any high-order regularized tensor approximation approach on the smooth part of a composite convex optimization model. The proposed scheme has the advantage of not needing to assume any prior knowledge of the Lipschitz constants for the gradient, the Hessian, and/or high-order derivatives. This is achieved by tuning the parameters used in the algorithm adaptively in its process of progression, which has been successfully incorporated in high-order nonconvex optimization [C. Cartis, N. I. M. Gould, and Ph. L. Toint, Found. Comput. Math., 18 (2018), pp. 1073--1107; E. G. Birgin et al., Math. Program., 163 (2017), pp. 359--368]. By adopting a similar approximate measure of the subproblem in [E. G. Birgin et al., Math. Program., 163 (2017), pp. 359--368] for nonconvex optimization, we establish the overall iteration complexity bounds for three specific algorithms to obtain an {\textbackslash}epsilon-optimal solution for composite convex problems. In general, we show that the adaptive high-order method has an iteration bound of O {\textbackslash}bigl( 1/{\textbackslash}epsilon1/(p+1){\textbackslash}bigr)  if the first pth-order derivative information is used in the approximation, which has the same iteration complexity as in [M. Baes, Estimate Sequence Methods: Extensions and Approximations, Institute for Operations Research, ETH, Zu{\textbackslash}"rich, 2009; Y. Nesterov, Math. Program., published online Nov. 21, 2019, https://doi.org/10.1007/s10107-019-01449-1], where the Lipschitz constants are assumed to be known, and the subproblems are assumed to be solved exactly. Thus, our results partially address the problem of incorporating adaptive strategies into the highorder accelerated methods raised by Nesterov in [Math. Program., published online Nov. 21, 2019, https://doi.org/10.1007/s10107-019-01449-1], although our strategies cannot ensure the convexity of the auxiliary problem, and such adaptive strategies are already popular in high-order nonconvex optimization [C. Cartis, N. I. M. Gould, and Ph. L. Toint, Found. Comput. Math., 18 (2018), pp. 1073--1107; E. G. Birgin et al., Math. Program., 163 (2017), pp. 359--368]. Specifically, we show that the gradient method achieves an iteration complexity on the order of O {\textbackslash}bigl( 1/{\textbackslash}epsilon1/2{\textbackslash}bigr) , which is known to be best possible (cf. [Y. Nesterov, Lectures on Convex Optimization, 2nd ed., Springer, 2018]), while the adaptive cubic regularization methods with the exact/inexact Hessian matrix achieve an iteration complexity on the order of O {\textbackslash}bigl( 1/{\textbackslash}epsilon1/3{\textbackslash}bigr) , which matches that of the original accelerated cubic regularization method presented in [Y. Nesterov, Math. Program., 112 (2008), pp. 159--181]. The results of our numerical experiment clearly show the effect of the acceleration displayed in the adaptive Newton's method with cubic regularization on a set of regularized logistic regression instances.},
	language = {en},
	author = {Jiang, Bo and Lin, Tianyi and Zhang, Shuzhong},
	pages = {30},
	file = {Jiang et al. - A UNIFIED ADAPTIVE TENSOR APPROXIMATION SCHEME TO .pdf:/Users/brent/Zotero/storage/ABI7WWDR/Jiang et al. - A UNIFIED ADAPTIVE TENSOR APPROXIMATION SCHEME TO .pdf:application/pdf},
}

@misc{salehkaleybar_adaptive_2022,
	title = {Adaptive {Momentum}-{Based} {Policy} {Gradient} with {Second}-{Order} {Information}},
	url = {http://arxiv.org/abs/2205.08253},
	abstract = {The variance reduced gradient estimators for policy gradient methods has been one of the main focus of research in the reinforcement learning in recent years as they allow acceleration of the estimation process. We propose a variance reduced policy gradient method, called SGDHessPG, which incorporates second-order information into stochastic gradient descent (SGD) using momentum with an adaptive learning rate. SGDHessPG algorithm can achieve -approximate ﬁrstorder stationary point with O˜( −3) number of trajectories, while using a batch size of O(1) at each iteration. Unlike most previous work, our proposed algorithm does not require importance sampling techniques which can compromise the advantage of variance reduction process. Our extensive experimental results show the effectiveness of the proposed algorithm on various control tasks and its advantage over the state of the art in practice.},
	language = {en},
	urldate = {2022-08-03},
	publisher = {arXiv},
	author = {Salehkaleybar, Saber and Khorasani, Sadegh and Kiyavash, Negar and He, Niao and Thiran, Patrick},
	month = may,
	year = {2022},
	note = {arXiv:2205.08253 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Salehkaleybar et al. - 2022 - Adaptive Momentum-Based Policy Gradient with Secon.pdf:/Users/brent/Zotero/storage/UQI9XIV8/Salehkaleybar et al. - 2022 - Adaptive Momentum-Based Policy Gradient with Secon.pdf:application/pdf},
}

@article{chen_understanding_2020,
	title = {Understanding gradient clipping in private {SGD}: {A} geometric perspective},
	volume = {33},
	shorttitle = {Understanding gradient clipping in private {SGD}},
	journal = {Advances in Neural Information Processing Systems},
	author = {Chen, Xiangyi and Wu, Steven Z. and Hong, Mingyi},
	year = {2020},
	pages = {13773--13782},
	file = {Full Text:/Users/brent/Zotero/storage/WI7JZQM4/Chen et al. - 2020 - Understanding gradient clipping in private SGD A .pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/RQ7VFJZ5/9ecff5455677b38d19f49ce658ef0608-Abstract.html:text/html},
}

@article{karimi_nonlinear_2021,
	title = {Nonlinear conjugate gradient for smooth convex functions},
	journal = {arXiv preprint arXiv:2111.11613},
	author = {Karimi, Sahar and Vavasis, Stephen},
	year = {2021},
	file = {Full Text:/Users/brent/Zotero/storage/NL5GKVCY/Karimi and Vavasis - 2021 - Nonlinear conjugate gradient for smooth convex fun.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/685WL237/2111.html:text/html},
}

@misc{gupta_shampoo_2018,
	title = {Shampoo: {Preconditioned} {Stochastic} {Tensor} {Optimization}},
	shorttitle = {Shampoo},
	url = {http://arxiv.org/abs/1802.09568},
	doi = {10.48550/arXiv.1802.09568},
	abstract = {Preconditioned gradient methods are among the most general and powerful tools in optimization. However, preconditioning requires storing and manipulating prohibitively large matrices. We describe and analyze a new structure-aware preconditioning algorithm, called Shampoo, for stochastic optimization over tensor spaces. Shampoo maintains a set of preconditioning matrices, each of which operates on a single dimension, contracting over the remaining dimensions. We establish convergence guarantees in the stochastic convex setting, the proof of which builds upon matrix trace inequalities. Our experiments with state-of-the-art deep learning models show that Shampoo is capable of converging considerably faster than commonly used optimizers. Although it involves a more complex update rule, Shampoo's runtime per step is comparable to that of simple gradient methods such as SGD, AdaGrad, and Adam.},
	urldate = {2022-08-02},
	publisher = {arXiv},
	author = {Gupta, Vineet and Koren, Tomer and Singer, Yoram},
	month = mar,
	year = {2018},
	note = {arXiv:1802.09568 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/IFK68LQD/Gupta et al. - 2018 - Shampoo Preconditioned Stochastic Tensor Optimiza.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/KU8JVBYJ/1802.html:text/html},
}

@misc{curtis_worst-case_2022,
	title = {Worst-{Case} {Complexity} of an {SQP} {Method} for {Nonlinear} {Equality} {Constrained} {Stochastic} {Optimization}},
	url = {http://arxiv.org/abs/2112.14799},
	doi = {10.48550/arXiv.2112.14799},
	abstract = {A worst-case complexity bound is proved for a sequential quadratic optimization (commonly known as SQP) algorithm that has been designed for solving optimization problems involving a stochastic objective function and deterministic nonlinear equality constraints. Barring additional terms that arise due to the adaptivity of the monotonically nonincreasing merit parameter sequence, the proved complexity bound is comparable to that known for the stochastic gradient algorithm for unconstrained nonconvex optimization. The overall complexity bound, which accounts for the adaptivity of the merit parameter sequence, shows that a result comparable to the unconstrained setting (with additional logarithmic factors) holds with high probability.},
	urldate = {2022-08-02},
	publisher = {arXiv},
	author = {Curtis, Frank E. and O'Neill, Michael J. and Robinson, Daniel P.},
	month = jan,
	year = {2022},
	note = {arXiv:2112.14799 [math]},
	keywords = {Mathematics - Optimization and Control, 49M37, 65K05, 65K10, 90C15, 90C30, 90C55},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/6ZZ432I5/Curtis et al. - 2022 - Worst-Case Complexity of an SQP Method for Nonline.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/JJ5HSVZE/2112.html:text/html},
}

@article{cartis_evaluation_2012,
	title = {Evaluation complexity of adaptive cubic regularization methods for convex unconstrained optimization},
	volume = {27},
	issn = {1055-6788},
	url = {https://doi.org/10.1080/10556788.2011.602076},
	doi = {10.1080/10556788.2011.602076},
	abstract = {The adaptive cubic regularization algorithms described in Cartis, Gould and Toint [Adaptive cubic regularisation methods for unconstrained optimization Part II: Worst-case function- and derivative-evaluation complexity, Math. Program. (2010), doi:10.1007/s10107-009-0337-y (online)]; [Part I: Motivation, convergence and numerical results, Math. Program. 127(2) (2011), pp. 245–295] for unconstrained (nonconvex) optimization are shown to have improved worst-case efficiency in terms of the function- and gradient-evaluation count when applied to convex and strongly convex objectives. In particular, our complexity upper bounds match in order (as a function of the accuracy of approximation), and sometimes even improve, those obtained by Nesterov [Introductory Lectures on Convex Optimization, Kluwer Academic Publishers, Dordrecht, 2004; Accelerating the cubic regularization of Newton's method on convex problems, Math. Program. 112(1) (2008), pp. 159–181] and Nesterov and Polyak [Cubic regularization of Newton's method and its global performance, Math. Program. 108(1) (2006), pp. 177–205] for these same problem classes, without requiring exact Hessians or exact or global solution of the subproblem. An additional outcome of our approximate approach is that our complexity results can naturally capture the advantages of both first- and second-order methods.},
	number = {2},
	urldate = {2022-08-01},
	journal = {Optimization Methods and Software},
	author = {Cartis, Coralia and Gould, Nicholas   I.M. and Toint, Philippe   L.},
	month = apr,
	year = {2012},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10556788.2011.602076},
	keywords = {nonlinear optimization, cubic regularization, Newton's method},
	pages = {197--219},
	file = {Full Text:/Users/brent/Zotero/storage/3CMCZ7YF/Cartis et al. - 2012 - Evaluation complexity of adaptive cubic regulariza.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/MFYAUBLE/10556788.2011.html:text/html},
}

@article{stella_newton-type_2018,
	title = {Newton-type alternating minimization algorithm for convex optimization},
	volume = {64},
	number = {2},
	journal = {IEEE transactions on automatic control},
	author = {Stella, Lorenzo and Themelis, Andreas and Patrinos, Panagiotis},
	year = {2018},
	note = {Publisher: IEEE},
	pages = {697--711},
	file = {Stella et al. - 2018 - Newton-type alternating minimization algorithm for.pdf:/Users/brent/Zotero/storage/X34T67GF/Stella et al. - 2018 - Newton-type alternating minimization algorithm for.pdf:application/pdf},
}

@inproceedings{hermans_qpalm_2019,
	title = {{QPALM}: a {Newton}-type proximal augmented {Lagrangian} method for quadratic programs},
	shorttitle = {{QPALM}},
	booktitle = {2019 {IEEE} 58th {Conference} on {Decision} and {Control} ({CDC})},
	publisher = {IEEE},
	author = {Hermans, Ben and Themelis, Andreas and Patrinos, Panagiotis},
	year = {2019},
	pages = {4325--4330},
	file = {Hermans et al. - 2019 - QPALM a Newton-type proximal augmented Lagrangian.pdf:/Users/brent/Zotero/storage/3C2NYHIF/Hermans et al. - 2019 - QPALM a Newton-type proximal augmented Lagrangian.pdf:application/pdf},
}

@article{themelis_douglasrachford_2020,
	title = {Douglas–{Rachford} splitting and {ADMM} for nonconvex optimization: {Tight} convergence results},
	volume = {30},
	shorttitle = {Douglas–{Rachford} splitting and {ADMM} for nonconvex optimization},
	number = {1},
	journal = {SIAM Journal on Optimization},
	author = {Themelis, Andreas and Patrinos, Panagiotis},
	year = {2020},
	note = {Publisher: SIAM},
	pages = {149--181},
}

@article{stella_forwardbackward_2017,
	title = {Forward–backward quasi-{Newton} methods for nonsmooth optimization problems},
	volume = {67},
	number = {3},
	journal = {Computational Optimization and Applications},
	author = {Stella, Lorenzo and Themelis, Andreas and Patrinos, Panagiotis},
	year = {2017},
	note = {Publisher: Springer},
	pages = {443--487},
}

@article{themelis_douglasrachford_2022,
	title = {Douglas–{Rachford} splitting and {ADMM} for nonconvex optimization: accelerated and {Newton}-type linesearch algorithms},
	volume = {82},
	issn = {1573-2894},
	shorttitle = {Douglas–{Rachford} splitting and {ADMM} for nonconvex optimization},
	url = {https://doi.org/10.1007/s10589-022-00366-y},
	doi = {10.1007/s10589-022-00366-y},
	abstract = {Although the performance of popular optimization algorithms such as the Douglas–Rachford splitting (DRS) and the ADMM is satisfactory in convex and well-scaled problems, ill conditioning and nonconvexity pose a severe obstacle to their reliable employment. Expanding on recent convergence results for DRS and ADMM applied to nonconvex problems, we propose two linesearch algorithms to enhance and robustify these methods by means of quasi-Newton directions. The proposed algorithms are suited for nonconvex problems, require the same black-box oracle of DRS and ADMM, and maintain their (subsequential) convergence properties. Numerical evidence shows that the employment of L-BFGS in the proposed framework greatly improves convergence of DRS and ADMM, making them robust to ill conditioning. Under regularity and nondegeneracy assumptions at the limit point, superlinear convergence is shown when quasi-Newton Broyden directions are adopted.},
	language = {en},
	number = {2},
	urldate = {2022-08-01},
	journal = {Computational Optimization and Applications},
	author = {Themelis, Andreas and Stella, Lorenzo and Patrinos, Panagiotis},
	month = jun,
	year = {2022},
	keywords = {90C26, 90C25, 90C06, 49J52, 49J53, ADMM, Douglas–Rachford splitting, Nonsmooth nonconvex optimization, Quasi-Newton methods},
	pages = {395--440},
	file = {Full Text PDF:/Users/brent/Zotero/storage/MUPPCL3M/Themelis et al. - 2022 - Douglas–Rachford splitting and ADMM for nonconvex .pdf:application/pdf},
}

@inproceedings{staib_escaping_2019,
	title = {Escaping saddle points with adaptive gradient methods},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Staib, Matthew and Reddi, Sashank and Kale, Satyen and Kumar, Sanjiv and Sra, Suvrit},
	year = {2019},
	pages = {5956--5965},
	file = {Full Text:/Users/brent/Zotero/storage/4B23C9Q6/Staib et al. - 2019 - Escaping saddle points with adaptive gradient meth.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/6LH6U7Z6/staib19a.html:text/html},
}

@article{liu_adaptive_2018,
	title = {Adaptive negative curvature descent with applications in non-convex optimization},
	volume = {31},
	journal = {Advances in Neural Information Processing Systems},
	author = {Liu, Mingrui and Li, Zhe and Wang, Xiaoyu and Yi, Jinfeng and Yang, Tianbao},
	year = {2018},
	file = {Full Text:/Users/brent/Zotero/storage/UJABINQQ/Liu et al. - 2018 - Adaptive negative curvature descent with applicati.pdf:application/pdf;Liu et al. - Supplementary Material for “Adaptive Negative Curv.pdf:/Users/brent/Zotero/storage/PUYQ95PM/Liu et al. - Supplementary Material for “Adaptive Negative Curv.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/9MZPDLWD/f52854cc99ae1c1966b0a21d0127975b-Abstract.html:text/html},
}

@article{jin_nonconvex_2021,
	title = {On nonconvex optimization for machine learning: {Gradients}, stochasticity, and saddle points},
	volume = {68},
	shorttitle = {On nonconvex optimization for machine learning},
	number = {2},
	journal = {Journal of the ACM (JACM)},
	author = {Jin, Chi and Netrapalli, Praneeth and Ge, Rong and Kakade, Sham M. and Jordan, Michael I.},
	year = {2021},
	note = {Publisher: ACM New York, NY, USA},
	pages = {1--29},
	file = {Full Text:/Users/brent/Zotero/storage/8J22TK29/Jin et al. - 2021 - On nonconvex optimization for machine learning Gr.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/ULVQJBIU/3418526.html:text/html},
}

@article{zhang_escape_2021,
	title = {Escape saddle points by a simple gradient-descent based algorithm},
	volume = {34},
	journal = {Advances in Neural Information Processing Systems},
	author = {Zhang, Chenyi and Li, Tongyang},
	year = {2021},
	pages = {8545--8556},
	file = {Full Text:/Users/brent/Zotero/storage/EIZ25IRA/Zhang and Li - 2021 - Escape saddle points by a simple gradient-descent .pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/LDMGF2ZJ/47bd8ac1becf213f155a82244b4a696a-Abstract.html:text/html},
}

@inproceedings{jin_how_2017,
	title = {How to escape saddle points efficiently},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Jin, Chi and Ge, Rong and Netrapalli, Praneeth and Kakade, Sham M. and Jordan, Michael I.},
	year = {2017},
	pages = {1724--1732},
	file = {Full Text:/Users/brent/Zotero/storage/M2I6KA8Q/Jin et al. - 2017 - How to escape saddle points efficiently.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/76ZIWTV2/jin17a.html:text/html},
}

@inproceedings{xie_adaptive_2022,
	title = {Adaptive inertia: {Disentangling} the effects of adaptive learning rate and momentum},
	shorttitle = {Adaptive inertia},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Xie, Zeke and Wang, Xinrui and Zhang, Huishuai and Sato, Issei and Sugiyama, Masashi},
	year = {2022},
	pages = {24430--24459},
	file = {Full Text:/Users/brent/Zotero/storage/BDQZZTWK/Xie et al. - 2022 - Adaptive inertia Disentangling the effects of ada.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/QMVHRUNA/xie22d.html:text/html},
}

@inproceedings{li_validity_2021,
	title = {On the {Validity} of {Modeling} {SGD} with {Stochastic} {Differential} {Equations} ({SDEs})},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper/2021/hash/69f62956429865909921fa916d61c1f8-Abstract.html},
	abstract = {It is generally recognized that finite learning rate (LR), in contrast to infinitesimal LR, is important for good generalization in real-life deep nets. Most attempted explanations propose approximating finite-LR SGD with Itô Stochastic Differential Equations (SDEs), but formal justification for this approximation (e.g., Li et al., 2019) only applies to SGD with tiny LR. Experimental verification of the approximation appears computationally infeasible. The current paper clarifies the picture with the following contributions: (a) An efficient simulation algorithm SVAG that provably converges to the conventionally used Itô SDE approximation. (b) A theoretically motivated testable necessary condition for the SDE approximation and its most famous implication, the linear scaling rule (Goyal et al., 2017), to hold.(c) Experiments using this simulation to demonstrate that the previously proposed SDE approximation can meaningfully capture the training and generalization properties of common deep nets.},
	urldate = {2022-07-31},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Li, Zhiyuan and Malladi, Sadhika and Arora, Sanjeev},
	year = {2021},
	pages = {12712--12725},
	file = {Full Text PDF:/Users/brent/Zotero/storage/YKWG5NEC/Li et al. - 2021 - On the Validity of Modeling SGD with Stochastic Di.pdf:application/pdf},
}

@article{ye_complexity_1998,
	title = {On the complexity of approximating a {KKT} point of quadratic programming},
	volume = {80},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/BF01581726},
	doi = {10.1007/BF01581726},
	abstract = {We present a potential reduction algorithm to approximate a Karush—Kuhn—Tucker (KKT) point of general quadratic programming (QP). We show that the algorithm is a fully polynomial-time approximation scheme, and its running-time dependency on accuracy ε ∈ (0, 1) is O((l/ε) log(l/ε) log(log(l/ε))), compared to the previously best-known result O((l/ε)2). Furthermore, the limit of the KKT point satisfies the second-order necessary optimality condition of being a local minimizer. © 1998 The Mathematical Programming Society, Inc. Published by Elsevier Science B.V.},
	language = {en},
	number = {2},
	urldate = {2021-09-28},
	journal = {Mathematical Programming},
	author = {Ye, Yinyu},
	month = jan,
	year = {1998},
	pages = {195--211},
	file = {Ye - 1998 - On the complexity of approximating a KKT point of .pdf:/Users/brent/Zotero/storage/N6HAX3FN/Ye - 1998 - On the complexity of approximating a KKT point of .pdf:application/pdf},
}

@inproceedings{he_deep_2016,
	title = {Deep residual learning for image recognition},
	booktitle = {Proceedings of the {IEEE} conference on computer vision and pattern recognition},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year = {2016},
	pages = {770--778},
	file = {Full Text:/Users/brent/Zotero/storage/LY459IU5/He et al. - 2016 - Deep residual learning for image recognition.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/MWFN8HU8/He_Deep_Residual_Learning_CVPR_2016_paper.html:text/html},
}

@article{zhang_nonmonotone_2004,
	title = {A nonmonotone line search technique and its application to unconstrained optimization},
	volume = {14},
	number = {4},
	journal = {SIAM journal on Optimization},
	author = {Zhang, Hongchao and Hager, William W.},
	year = {2004},
	note = {Publisher: SIAM},
	pages = {1043--1056},
}

@incollection{ye_new_1991,
	title = {A {New} {Complexity} {Result} on {Minimization} of a {Quadratic} {Function} with a {Sphere} {Constraint}},
	volume = {176},
	isbn = {978-1-4008-6252-8},
	url = {https://www.degruyter.com/document/doi/10.1515/9781400862528.19/html},
	abstract = {A New Complexity Result on Minimization of a Quadratic Function with a Sphere Constraint was published in Recent Advances in Global Optimization on page 19.},
	language = {en},
	urldate = {2022-07-27},
	booktitle = {Recent {Advances} in {Global} {Optimization}},
	publisher = {Princeton University Press},
	author = {Ye, Yinyu},
	year = {1991},
	doi = {10.1515/9781400862528.19},
	pages = {19--31},
	file = {Full Text PDF:/Users/brent/Zotero/storage/VUZ76KRC/Ye - 2014 - A New Complexity Result on Minimization of a Quadr.pdf:application/pdf},
}

@article{nesterov_accelerating_2008,
	title = {Accelerating the cubic regularization of {Newton}’s method on convex problems},
	volume = {112},
	number = {1},
	journal = {Mathematical Programming},
	author = {Nesterov, Yu},
	year = {2008},
	note = {Publisher: Springer},
	keywords = {49M37, 90C30, 90C25, Convex optimization, 49M15, Worst-case complexity, 58C15, Condition number, Cubic regularization, Global complexity bounds, Newton’s method, Non-degenerate problems, Unconstrained minimization},
	pages = {159--181},
	file = {Full Text PDF:/Users/brent/Zotero/storage/NGEF5GEG/Nesterov - 2008 - Accelerating the cubic regularization of Newton’s .pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/KXFQWFFZ/s10107-006-0089-x.html:text/html},
}

@inproceedings{sutskever_importance_2013,
	title = {On the importance of initialization and momentum in deep learning},
	booktitle = {International conference on machine learning},
	publisher = {PMLR},
	author = {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
	year = {2013},
	pages = {1139--1147},
	file = {Full Text:/Users/brent/Zotero/storage/L7SWNV38/Sutskever et al. - 2013 - On the importance of initialization and momentum i.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/KBLUK58I/sutskever13.html:text/html},
}

@misc{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	doi = {10.48550/arXiv.1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2022-07-28},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv:1412.6980 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/WAUX9DZT/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/PLKJNJF4/1412.html:text/html},
}

@book{goos_isaac_nodate,
	title = {{ISAAC} 2010},
	language = {en},
	author = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M and Kobsa, Alfred and Mattern, Friedemann and Mitchell, John C and Naor, Moni and Nierstrasz, Oscar and Rangan, C Pandu and Steffen, Bernhard},
	file = {Goos et al. - Lecture Notes in Computer Science.pdf:/Users/brent/Zotero/storage/KVRE8SE9/Goos et al. - Lecture Notes in Computer Science.pdf:application/pdf;Goos et al. - Lecture Notes in Computer Science.pdf:/Users/brent/Zotero/storage/922P4QT6/Goos et al. - Lecture Notes in Computer Science.pdf:application/pdf},
}

@book{bertsekas_nonlinear_2016,
	edition = {3},
	title = {Nonlinear programming},
	publisher = {Athena Scientific},
	author = {Bertsekas, Dimitri P},
	year = {2016},
	keywords = {Nonlinear optimization, Mathematics / Optimization},
	file = {a-few-proofs-on-subgradient.pdf:/Users/brent/Zotero/storage/JAGKBKQE/a-few-proofs-on-subgradient.pdf:application/pdf;Bertsekas - Nonlinear Programming 3rd Edition.pdf:/Users/brent/Zotero/storage/7PE4MNTV/Bertsekas - Nonlinear Programming 3rd Edition.pdf:application/pdf},
}

@inproceedings{schulman_trust_2015,
	title = {Trust region policy optimization},
	booktitle = {International conference on machine learning},
	publisher = {PMLR},
	author = {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
	year = {2015},
	pages = {1889--1897},
}

@article{pilanci_newton_2017,
	title = {Newton sketch: {A} near linear-time optimization algorithm with linear-quadratic convergence},
	volume = {27},
	shorttitle = {Newton sketch},
	number = {1},
	journal = {SIAM Journal on Optimization},
	author = {Pilanci, Mert and Wainwright, Martin J.},
	year = {2017},
	note = {Publisher: SIAM},
	pages = {205--245},
	file = {Full Text:/Users/brent/Zotero/storage/3H5ZFNCM/Pilanci and Wainwright - 2017 - Newton sketch A near linear-time optimization alg.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/ZGFEH6WH/15M1021106.html:text/html},
}

@misc{na_hessian_2022,
	title = {Hessian {Averaging} in {Stochastic} {Newton} {Methods} {Achieves} {Superlinear} {Convergence}},
	url = {http://arxiv.org/abs/2204.09266},
	doi = {10.48550/arXiv.2204.09266},
	abstract = {We consider minimizing a smooth and strongly convex objective function using a stochastic Newton method. At each iteration, the algorithm is given an oracle access to a stochastic estimate of the Hessian matrix. The oracle model includes popular algorithms such as the Subsampled Newton and Newton Sketch, which can efficiently construct stochastic Hessian estimates for many tasks. Despite using second-order information, these existing methods do not exhibit superlinear convergence, unless the stochastic noise is gradually reduced to zero during the iteration, which would lead to a computational blow-up in the per-iteration cost. We address this limitation with Hessian averaging: instead of using the most recent Hessian estimate, our algorithm maintains an average of all past estimates. This reduces the stochastic noise while avoiding the computational blow-up. We show that this scheme enjoys local \$Q\$-superlinear convergence with a non-asymptotic rate of \$({\textbackslash}Upsilon{\textbackslash}sqrt\{{\textbackslash}log (t)/t\}{\textbackslash},){\textasciicircum}\{t\}\$, where \${\textbackslash}Upsilon\$ is proportional to the level of stochastic noise in the Hessian oracle. A potential drawback of this (uniform averaging) approach is that the averaged estimates contain Hessian information from the global phase of the iteration, i.e., before the iterates converge to a local neighborhood. This leads to a distortion that may substantially delay the superlinear convergence until long after the local neighborhood is reached. To address this drawback, we study a number of weighted averaging schemes that assign larger weights to recent Hessians, so that the superlinear convergence arises sooner, albeit with a slightly slower rate. Remarkably, we show that there exists a universal weighted averaging scheme that transitions to local convergence at an optimal stage, and still enjoys a superlinear convergence{\textasciitilde}rate nearly (up to a logarithmic factor) matching that of uniform Hessian averaging.},
	urldate = {2022-07-27},
	publisher = {arXiv},
	author = {Na, Sen and Dereziński, Michał and Mahoney, Michael W.},
	month = apr,
	year = {2022},
	note = {arXiv:2204.09266 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/9SZNNACV/Na et al. - 2022 - Hessian Averaging in Stochastic Newton Methods Ach.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/VIQAN2ZI/2204.html:text/html},
}

@misc{ye_second_2005-1,
	title = {Second {Order} {Optimization} {Algorithms} {I}},
	url = {https://web.stanford.edu/class/msande311/lecture12.pdf},
	language = {en},
	author = {Ye, Yinyu},
	year = {2005},
	file = {Ye - Second Order Optimization Algorithms I.pdf:/Users/brent/Zotero/storage/EAAJED64/Ye - Second Order Optimization Algorithms I.pdf:application/pdf},
}

@misc{goldfarb_practical_2021,
	title = {Practical {Quasi}-{Newton} {Methods} for {Training} {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2006.08877},
	doi = {10.48550/arXiv.2006.08877},
	abstract = {We consider the development of practical stochastic quasi-Newton, and in particular Kronecker-factored block-diagonal BFGS and L-BFGS methods, for training deep neural networks (DNNs). In DNN training, the number of variables and components of the gradient \$n\$ is often of the order of tens of millions and the Hessian has \$n{\textasciicircum}2\$ elements. Consequently, computing and storing a full \$n {\textbackslash}times n\$ BFGS approximation or storing a modest number of (step, change in gradient) vector pairs for use in an L-BFGS implementation is out of the question. In our proposed methods, we approximate the Hessian by a block-diagonal matrix and use the structure of the gradient and Hessian to further approximate these blocks, each of which corresponds to a layer, as the Kronecker product of two much smaller matrices. This is analogous to the approach in KFAC, which computes a Kronecker-factored block-diagonal approximation to the Fisher matrix in a stochastic natural gradient method. Because the indefinite and highly variable nature of the Hessian in a DNN, we also propose a new damping approach to keep the upper as well as the lower bounds of the BFGS and L-BFGS approximations bounded. In tests on autoencoder feed-forward neural network models with either nine or thirteen layers applied to three datasets, our methods outperformed or performed comparably to KFAC and state-of-the-art first-order stochastic methods.},
	urldate = {2022-07-23},
	publisher = {arXiv},
	author = {Goldfarb, Donald and Ren, Yi and Bahamou, Achraf},
	month = jan,
	year = {2021},
	note = {arXiv:2006.08877 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/VDQ95MG2/Goldfarb et al. - 2021 - Practical Quasi-Newton Methods for Training Deep N.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/28EZYVTI/2006.html:text/html},
}

@incollection{powell_new_1970,
	title = {A {New} {Algorithm} for {Unconstrained} {Optimization}},
	isbn = {978-0-12-597050-1},
	url = {https://www.sciencedirect.com/science/article/pii/B9780125970501500063},
	abstract = {A new algorithm is described for calculating the least value of a given differentiable function of several variables. The user must program the evaluation of the function and its first derivatives. Some convergence theorems are given that impose very mild conditions on the objective function. These theorems, together with some numerical results, indicate that the new method may be preferable to current algorithms for solving many unconstrained minimization problems.},
	language = {en},
	urldate = {2022-07-22},
	booktitle = {Nonlinear {Programming}},
	publisher = {Academic Press},
	author = {Powell, M. J. D.},
	editor = {Rosen, J. B. and Mangasarian, O. L. and Ritter, K.},
	month = jan,
	year = {1970},
	doi = {10.1016/B978-0-12-597050-1.50006-3},
	pages = {31--65},
	file = {ScienceDirect Full Text PDF:/Users/brent/Zotero/storage/UGU3AYP5/Powell - 1970 - A New Algorithm for Unconstrained Optimization.pdf:application/pdf;ScienceDirect Snapshot:/Users/brent/Zotero/storage/N78CWQYA/B9780125970501500063.html:text/html},
}

@article{shultz_family_1985,
	title = {A {Family} of {Trust}-{Region}-{Based} {Algorithms} for {Unconstrained} {Minimization} with {Strong} {Global} {Convergence} {Properties}},
	volume = {22},
	issn = {0036-1429},
	url = {https://epubs.siam.org/doi/abs/10.1137/0722003},
	doi = {10.1137/0722003},
	abstract = {This paper has two aims: to exhibit very general conditions under which members of a broad class of unconstrained minimization algorithms are globally convergent in a strong sense, and to propose several new algorithms that use second derivative information and achieve such convergence. In the first part of the paper we present a general trust-region-based algorithm schema that includes an undefined step selection strategy. We give general conditions on this step selection strategy under which limit points of the algorithm will satisfy first and second order necessary conditions for unconstrained minimization. Our algorithm schema is sufficiently broad to include line search algorithms as well. Next, we show that a wide range of step selection strategies satisfy the requirements of our convergence theory. This leads us to propose several new algorithms that use second derivative information and achieve strong global convergence, including an indefinite line search algorithm, several indefinite dogleg algorithms, and a modified "optimal-step" algorithm. Finally, we propose an implementation of one such indefinite dogleg algorithm.},
	number = {1},
	urldate = {2022-07-22},
	journal = {SIAM Journal on Numerical Analysis},
	author = {Shultz, Gerald A. and Schnabel, Robert B. and Byrd, Richard H.},
	month = feb,
	year = {1985},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {47--67},
	file = {Full Text PDF:/Users/brent/Zotero/storage/IBZX9MT8/Shultz et al. - 1985 - A Family of Trust-Region-Based Algorithms for Unco.pdf:application/pdf},
}

@article{byrd_approximate_1988,
	title = {Approximate solution of the trust region problem by minimization over two-dimensional subspaces},
	volume = {40},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/BF01580735},
	doi = {10.1007/BF01580735},
	abstract = {The trust region problem, minimization of a quadratic function subject to a spherical trust region constraint, occurs in many optimization algorithms. In a previous paper, the authors introduced an inexpensive approximate solution technique for this problem that involves the solution of a two-dimensional trust region problem. They showed that using this approximation in an unconstrained optimization algorithm leads to the same theoretical global and local convergence properties as are obtained using the exact solution to the trust region problem. This paper reports computational results showing that the two-dimensional minimization approach gives nearly optimal reductions in then-dimension quadratic model over a wide range of test cases. We also show that there is very little difference, in efficiency and reliability, between using the approximate or exact trust region step in solving standard test problems for unconstrained optimization. These results may encourage the application of similar approximate trust region techniques in other contexts.},
	language = {en},
	number = {1},
	urldate = {2022-07-22},
	journal = {Mathematical Programming},
	author = {Byrd, Richard H. and Schnabel, Robert B. and Shultz, Gerald A.},
	month = jan,
	year = {1988},
	keywords = {trust region, Unconstrained optimization},
	pages = {247--263},
	file = {Full Text PDF:/Users/brent/Zotero/storage/H9J8QN6Y/Byrd et al. - 1988 - Approximate solution of the trust region problem b.pdf:application/pdf},
}

@article{hestenes_methods_1952,
	title = {Methods of conjugate gradients for solving},
	volume = {49},
	number = {6},
	journal = {Journal of research of the National Bureau of Standards},
	author = {Hestenes, Magnus R. and Stiefel, Eduard},
	year = {1952},
	pages = {409},
	file = {Full Text:/Users/brent/Zotero/storage/A4GQUWWE/books.html:text/html},
}

@article{polyak_methods_1964,
	title = {Some methods of speeding up the convergence of iteration methods},
	volume = {4},
	issn = {0041-5553},
	url = {https://www.sciencedirect.com/science/article/pii/0041555364901375},
	doi = {10.1016/0041-5553(64)90137-5},
	abstract = {For the solution of the functional equation P (x) = 0 (1) (where P is an operator, usually linear, from B into B, and B is a Banach space) iteration methods are generally used. These consist of the construction of a series x0, …, xn, …, which converges to the solution (see, for example [1]). Continuous analogues of these methods are also known, in which a trajectory x(t), 0 ⩽ t ⩽ ∞ is constructed, which satisfies the ordinary differential equation in B and is such that x(t) approaches the solution of (1) as t → ∞ (see [2]). We shall call the method a k-step method if for the construction of each successive iteration xn+1 we use k previous iterations xn, …, xn−k+1. The same term will also be used for continuous methods if x(t) satisfies a differential equation of the k-th order or k-th degree. Iteration methods which are more widely used are one-step (e.g. methods of successive approximations). They are generally simple from the calculation point of view but often converge very slowly. This is confirmed both by the evaluation of the speed of convergence and by calculation in practice (for more details see below). Therefore the question of the rate of convergence is most important. Some multistep methods, which we shall consider further, which are only slightly more complicated than the corresponding one-step methods, make it possible to speed up the convergence substantially. Note that all the methods mentioned below are applicable also to the problem of minimizing the differentiable functional (x) in Hilbert space, so long as this problem reduces to the solution of the equation grad (x) = 0.},
	language = {en},
	number = {5},
	urldate = {2022-07-22},
	journal = {USSR Computational Mathematics and Mathematical Physics},
	author = {Polyak, B. T.},
	month = jan,
	year = {1964},
	pages = {1--17},
	file = {ScienceDirect Full Text PDF:/Users/brent/Zotero/storage/6P5R3JN4/Polyak - 1964 - Some methods of speeding up the convergence of ite.pdf:application/pdf;ScienceDirect Snapshot:/Users/brent/Zotero/storage/ZXUTZJ8T/0041555364901375.html:text/html},
}

@misc{xiao_fashion-mnist_2017,
	title = {Fashion-{MNIST}: a {Novel} {Image} {Dataset} for {Benchmarking} {Machine} {Learning} {Algorithms}},
	author = {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
	month = aug,
	year = {2017},
	note = {arXiv: cs.LG/1708.07747},
}

@article{chen_accelerating_2022,
	title = {Accelerating adaptive cubic regularization of {Newton}’s method via random sampling},
	journal = {J. Mach. Learn. Res},
	author = {Chen, Xi and Jiang, Bo and Lin, Tianyi and Zhang, Shuzhong},
	year = {2022},
	file = {Full Text:/Users/brent/Zotero/storage/6U7A7BYW/Chen et al. - 2022 - Accelerating adaptive cubic regularization of Newt.pdf:application/pdf},
}

@article{xu_newton-type_2020,
	title = {Newton-type methods for non-convex optimization under inexact {Hessian} information},
	volume = {184},
	issn = {0025-5610, 1436-4646},
	url = {http://link.springer.com/10.1007/s10107-019-01405-z},
	doi = {10.1007/s10107-019-01405-z},
	abstract = {We consider variants of trust-region and adaptive cubic regularization methods for non-convex optimization, in which the Hessian matrix is approximated. Under certain condition on the inexact Hessian, and using approximate solution of the corresponding sub-problems, we provide iteration complexity to achieve ε-approximate second-order optimality which have been shown to be tight. Our Hessian approximation condition offers a range of advantages as compared with the prior works and allows for direct construction of the approximate Hessian with a priori guarantees through various techniques, including randomized sampling methods. In this light, we consider the canonical problem of ﬁnite-sum minimization, provide appropriate uniform and non-uniform sub-sampling strategies to construct such Hessian approximations, and obtain optimal iteration complexity for the corresponding sub-sampled trust-region and adaptive cubic regularization methods.},
	language = {en},
	number = {1-2},
	urldate = {2022-07-20},
	journal = {Mathematical Programming},
	author = {Xu, Peng and Roosta, Fred and Mahoney, Michael W.},
	month = nov,
	year = {2020},
	pages = {35--70},
	file = {Xu et al. - 2020 - Newton-type methods for non-convex optimization un.pdf:/Users/brent/Zotero/storage/JKQVR9GM/Xu et al. - 2020 - Newton-type methods for non-convex optimization un.pdf:application/pdf},
}

@inproceedings{agarwal_finding_2017,
	title = {Finding approximate local minima faster than gradient descent},
	booktitle = {Proceedings of the 49th {Annual} {ACM} {SIGACT} {Symposium} on {Theory} of {Computing}},
	author = {Agarwal, Naman and Allen-Zhu, Zeyuan and Bullins, Brian and Hazan, Elad and Ma, Tengyu},
	year = {2017},
	pages = {1195--1199},
	file = {Full Text:/Users/brent/Zotero/storage/6EZA85PZ/Agarwal et al. - 2017 - Finding approximate local minima faster than gradi.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/4VKTUVEI/3055399.html:text/html},
}

@article{dai_nonlinear_1999,
	title = {A {Nonlinear} {Conjugate} {Gradient} {Method} with a {Strong} {Global} {Convergence} {Property}},
	volume = {10},
	issn = {1052-6234},
	url = {https://epubs.siam.org/doi/abs/10.1137/S1052623497318992},
	doi = {10.1137/S1052623497318992},
	abstract = {Conjugate gradient methods are widely used for unconstrained optimization, especially large scale problems. The strong Wolfe conditions are usually used in the analyses and implementations of conjugate gradient methods. This paper presents a new version of the conjugate gradient method, which converges globally, provided the line search satisfies the standard Wolfe conditions. The conditions on the objective function are also weak, being similar to those required by the Zoutendijk condition.},
	number = {1},
	urldate = {2022-07-09},
	journal = {SIAM Journal on Optimization},
	author = {Dai, Y. H. and Yuan, Y.},
	month = jan,
	year = {1999},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {global convergence, 65K, 90C, new conjugate gradient method, unconstrained optimization, Wolfe conditions},
	pages = {177--182},
	file = {Full Text PDF:/Users/brent/Zotero/storage/44XMTMZW/Dai and Yuan - 1999 - A Nonlinear Conjugate Gradient Method with a Stron.pdf:application/pdf},
}

@article{carmon_accelerated_2018,
	title = {Accelerated {Methods} for {NonConvex} {Optimization}},
	volume = {28},
	issn = {1052-6234, 1095-7189},
	url = {https://epubs.siam.org/doi/10.1137/17M1114296},
	doi = {10.1137/17M1114296},
	abstract = {We present an accelerated gradient method for nonconvex optimization problems with Lipschitz continuous ﬁrst and second derivatives. In a time O( −7/4 log(1/ )), the method ﬁnds an -stationary point, meaning a point x such that ∇f (x) ≤ . The method improves upon the O( −2) complexity of gradient descent and provides the additional second-order guarantee that λmin(∇2f (x)) − 1/2 for the computed x. Furthermore, our method is Hessian free, i.e., it only requires gradient computations, and is therefore suitable for large-scale applications.},
	language = {en},
	number = {2},
	urldate = {2022-07-05},
	journal = {SIAM Journal on Optimization},
	author = {Carmon, Yair and Duchi, John C. and Hinder, Oliver and Sidford, Aaron},
	month = jan,
	year = {2018},
	pages = {1751--1772},
	file = {Carmon et al. - 2018 - Accelerated Methods for NonConvex Optimization.pdf:/Users/brent/Zotero/storage/7PHAG97H/Carmon et al. - 2018 - Accelerated Methods for NonConvex Optimization.pdf:application/pdf},
}

@article{royer_complexity_2018,
	title = {Complexity analysis of second-order line-search algorithms for smooth nonconvex optimization},
	volume = {28},
	number = {2},
	journal = {SIAM Journal on Optimization},
	author = {Royer, Clément W. and Wright, Stephen J.},
	year = {2018},
	note = {Publisher: SIAM},
	pages = {1448--1477},
	file = {Royer and Wright - 2018 - Complexity analysis of second-order line-search al.pdf:/Users/brent/Zotero/storage/7YD6VWLT/Royer and Wright - 2018 - Complexity analysis of second-order line-search al.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/N2KAPNB6/17M1134329.html:text/html},
}

@inproceedings{becchetti_oblivious_2019,
	title = {Oblivious dimension reduction for k-means: beyond subspaces and the {Johnson}-{Lindenstrauss} lemma},
	shorttitle = {Oblivious dimension reduction for k-means},
	booktitle = {Proceedings of the 51st annual {ACM} {SIGACT} symposium on theory of computing},
	author = {Becchetti, Luca and Bury, Marc and Cohen-Addad, Vincent and Grandoni, Fabrizio and Schwiegelshohn, Chris},
	year = {2019},
	pages = {1039--1050},
	file = {Full Text:/Users/brent/Zotero/storage/XX87FPT4/Becchetti et al. - 2019 - Oblivious dimension reduction for k-means beyond .pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/6LN9D8YJ/3313276.html:text/html},
}

@article{curtis_concise_2018,
	title = {Concise complexity analyses for trust region methods},
	volume = {12},
	issn = {1862-4480},
	url = {https://doi.org/10.1007/s11590-018-1286-2},
	doi = {10.1007/s11590-018-1286-2},
	abstract = {Concise complexity analyses are presented for simple trust region algorithms for solving unconstrained optimization problems. In contrast to a traditional trust region algorithm, the algorithms considered in this paper require certain control over the choice of trust region radius after any successful iteration. The analyses highlight the essential algorithm components required to obtain certain complexity bounds. In addition, a new update strategy for the trust region radius is proposed that offers a second-order complexity bound.},
	language = {en},
	number = {8},
	urldate = {2022-06-30},
	journal = {Optimization Letters},
	author = {Curtis, Frank E. and Lubberts, Zachary and Robinson, Daniel P.},
	month = dec,
	year = {2018},
	keywords = {Nonlinear optimization, Global convergence, Unconstrained optimization, Nonconvex optimization, Trust region methods, Worst-case evaluation complexity, Worst-case iteration complexity},
	pages = {1713--1724},
	file = {Full Text PDF:/Users/brent/Zotero/storage/F5JCA3EH/Curtis et al. - 2018 - Concise complexity analyses for trust region metho.pdf:application/pdf},
}

@article{curtis_trust_2017,
	title = {A trust region algorithm with a worst-case iteration complexity of {$\mathcal O(\epsilon^{-3/2})$}for nonconvex optimization},
	volume = {162},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-016-1026-2},
	doi = {10.1007/s10107-016-1026-2},
	abstract = {We propose a trust region algorithm for solving nonconvex smooth optimization problems. For any \$\${\textbackslash}overline\{{\textbackslash}epsilon \}{\textbackslash}in (0,{\textbackslash}infty )\$\$, the algorithm requires at most \$\${\textbackslash}mathcal\{O\}({\textbackslash}epsilon {\textasciicircum}\{-3/2\})\$\$iterations, function evaluations, and derivative evaluations to drive the norm of the gradient of the objective function below any \$\${\textbackslash}epsilon {\textbackslash}in (0,{\textbackslash}overline\{{\textbackslash}epsilon \}]\$\$. This improves upon the \$\${\textbackslash}mathcal\{O\}({\textbackslash}epsilon {\textasciicircum}\{-2\})\$\$bound known to hold for some other trust region algorithms and matches the \$\${\textbackslash}mathcal\{O\}({\textbackslash}epsilon {\textasciicircum}\{-3/2\})\$\$bound for the recently proposed Adaptive Regularisation framework using Cubics, also known as the arc algorithm. Our algorithm, entitled trace, follows a trust region framework, but employs modified step acceptance criteria and a novel trust region update mechanism that allow the algorithm to achieve such a worst-case global complexity bound. Importantly, we prove that our algorithm also attains global and fast local convergence guarantees under similar assumptions as for other trust region algorithms. We also prove a worst-case upper bound on the number of iterations, function evaluations, and derivative evaluations that the algorithm requires to obtain an approximate second-order stationary point.},
	language = {en},
	number = {1},
	urldate = {2022-06-30},
	journal = {Mathematical Programming},
	author = {Curtis, Frank E. and Robinson, Daniel P. and Samadi, Mohammadreza},
	month = mar,
	year = {2017},
	keywords = {49M37, 65K10, 90C30, Nonlinear optimization, 65K05, 49M15, 68Q25, 90C60, Global convergence, 58C15, Unconstrained optimization, Nonconvex optimization, Trust region methods, Worst-case evaluation complexity, Worst-case iteration complexity, 65Y20, Local convergence},
	pages = {1--32},
	file = {Full Text PDF:/Users/brent/Zotero/storage/RZEILH2G/Curtis et al. - 2017 - A trust region algorithm with a worst-case iterati.pdf:application/pdf},
}

@article{nesterov_cubic_2006,
	title = {Cubic regularization of {Newton} method and its global performance},
	volume = {108},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-006-0706-8},
	doi = {10.1007/s10107-006-0706-8},
	abstract = {In this paper, we provide theoretical analysis for a cubic regularization of Newton method as applied to unconstrained minimization problem. For this scheme, we prove general local convergence results. However, the main contribution of the paper is related to global worst-case complexity bounds for different problem classes including some nonconvex cases. It is shown that the search direction can be computed by standard linear algebra technique.},
	language = {en},
	number = {1},
	urldate = {2022-06-29},
	journal = {Mathematical Programming},
	author = {Nesterov, Yurii and Polyak, B.T.},
	month = aug,
	year = {2006},
	keywords = {49M37, 90C30, 90C25, Newton method, 49M15, Trust-region methods, 58C15, Global complexity bounds, Unconstrained optimization, General nonlinear optimization, Global rate of convergence},
	pages = {177--205},
	file = {Full Text PDF:/Users/brent/Zotero/storage/L2JXITG2/Nesterov and Polyak - 2006 - Cubic regularization of Newton method and its glob.pdf:application/pdf},
}

@article{clason_acceleration_2019,
	title = {Acceleration and {Global} {Convergence} of a {First}-{Order} {Primal}-{Dual} {Method} for {Nonconvex} {Problems}},
	volume = {29},
	issn = {1052-6234, 1095-7189},
	url = {https://epubs.siam.org/doi/10.1137/18M1170194},
	doi = {10.1137/18M1170194},
	abstract = {The primal-dual hybrid gradient method, modiﬁed (PDHGM, also known as the Chambolle–Pock method), has proved very successful for convex optimization problems involving linear operators arising in image processing and inverse problems. In this paper, we analyze an extension to nonconvex problems that arise if the operator is nonlinear. Based on the idea of testing, we derive new step-length parameter conditions for the convergence in inﬁnite-dimensional Hilbert spaces and provide acceleration rules for suitably (locally and/or partially) monotone problems. Importantly, we prove linear convergence rates as well as global convergence in certain cases. We demonstrate the eﬃcacy of these step-length rules for PDE-constrained optimization problems.},
	language = {en},
	number = {1},
	urldate = {2022-04-18},
	journal = {SIAM Journal on Optimization},
	author = {Clason, Christian and Mazurenko, Stanislav and Valkonen, Tuomo},
	month = jan,
	year = {2019},
	pages = {933--963},
	file = {Clason et al. - 2019 - Acceleration and Global Convergence of a First-Ord.pdf:/Users/brent/Zotero/storage/TMSCYQPS/Clason et al. - 2019 - Acceleration and Global Convergence of a First-Ord.pdf:application/pdf},
}

@article{cartis_dimensionality_2022,
	title = {A dimensionality reduction technique for unconstrained global optimization of functions with low effective dimensionality},
	volume = {11},
	issn = {2049-8772},
	url = {https://academic.oup.com/imaiai/article/11/1/167/6278168},
	doi = {10.1093/imaiai/iaab011},
	abstract = {Abstract
            We investigate the unconstrained global optimization of functions with low effective dimensionality, which are constant along certain (unknown) linear subspaces. Extending the technique of random subspace embeddings in Wang et al. (2016, J. Artificial Intelligence Res., 55, 361–387), we study a generic Random Embeddings for Global Optimization (REGO) framework that is compatible with any global minimization algorithm. Instead of the original, potentially large-scale optimization problem, within REGO, a Gaussian random, low-dimensional problem with bound constraints is formulated and solved in a reduced space. We provide novel probabilistic bounds for the success of REGO in solving the original, low effective-dimensionality problem, which show its independence of the (potentially large) ambient dimension and its precise dependence on the dimensions of the effective and embedding subspaces. These results significantly improve existing theoretical analyses by providing the exact distribution of a reduced minimizer and its Euclidean norm and by the general assumptions required on the problem. We validate our theoretical findings by extensive numerical testing of REGO with three types of global optimization solvers, illustrating the improved scalability of REGO compared with the full-dimensional application of the respective solvers.},
	language = {en},
	number = {1},
	urldate = {2022-06-29},
	journal = {Information and Inference: A Journal of the IMA},
	author = {Cartis, Coralia and Otemissov, Adilet},
	month = mar,
	year = {2022},
	pages = {167--201},
	file = {Cartis and Otemissov - 2022 - A dimensionality reduction technique for unconstra.pdf:/Users/brent/Zotero/storage/YBK42FTN/Cartis and Otemissov - 2022 - A dimensionality reduction technique for unconstra.pdf:application/pdf},
}

@article{cartis_optimal_nodate,
	title = {Optimal {Newton}-type methods for nonconvex smooth optimization problems},
	abstract = {We consider a general class of second-order iterations for unconstrained optimization that includes regularization and trust-region variants of Newton’s method. For each method in this class, we exhibit a smooth, bounded-below objective function, whose gradient is globally Lipschitz continuous within an open convex set containing any iterates encountered and whose Hessian is α−Ho¨lder continuous (for given α ∈ [0, 1]) on the path of the iterates, for which the method in question takes at least ⌊ǫ−(2+α)/(1+α)⌋ function-evaluations to generate a ﬁrst iterate whose gradient is smaller than ǫ in norm. This provides a lower bound on the evaluation complexity of second-order methods in our class when applied to smooth problems satisfying our assumptions. Furthermore, for α = 1, this lower bound is of the same order in ǫ as the upper bound on the evaluation complexity of cubic regularization, thus implying cubic regularization has optimal worst-case evaluation complexity within our class of second-order methods.},
	language = {en},
	author = {Cartis, Coralia and Gould, Nicholas I M and Toint, Philippe L},
	pages = {22},
	file = {Cartis et al. - Optimal Newton-type methods for nonconvex smooth o.pdf:/Users/brent/Zotero/storage/65GSQE3Z/Cartis et al. - Optimal Newton-type methods for nonconvex smooth o.pdf:application/pdf},
}

@article{cartis_how_nodate,
	title = {How much patience do you have? {A} worst-case perspective on smooth nonconvex optimization},
	language = {en},
	author = {Cartis, Coralia and Gould, Nicholas I M and Toint, Philippe L},
	pages = {17},
	file = {Cartis et al. - How much patience do you have A worst-case perspe.pdf:/Users/brent/Zotero/storage/M5U5FKWL/Cartis et al. - How much patience do you have A worst-case perspe.pdf:application/pdf},
}

@article{cartis_complexity_2010,
	title = {On the {Complexity} of {Steepest} {Descent}, {Newton}'s and {Regularized} {Newton}'s {Methods} for {Nonconvex} {Unconstrained} {Optimization} {Problems}},
	volume = {20},
	issn = {1052-6234},
	url = {https://epubs.siam.org/doi/abs/10.1137/090774100},
	doi = {10.1137/090774100},
	abstract = {It is shown that the steepest-descent and Newton's methods for unconstrained nonconvex optimization under standard assumptions may both require a number of iterations and function evaluations arbitrarily close to \$O({\textbackslash}epsilon{\textasciicircum}\{-2\})\$ to drive the norm of the gradient below \${\textbackslash}epsilon\$. This shows that the upper bound of \$O({\textbackslash}epsilon{\textasciicircum}\{-2\})\$ evaluations known for the steepest descent is tight and that Newton's method may be as slow as the steepest-descent method in the worst case. The improved evaluation complexity bound of \$O({\textbackslash}epsilon{\textasciicircum}\{-3/2\})\$ evaluations known for cubically regularized Newton's methods is also shown to be tight.},
	number = {6},
	urldate = {2022-06-28},
	journal = {SIAM Journal on Optimization},
	author = {Cartis, Coralia and Gould, Nicholas I. M. and Toint, Philippe L.},
	month = jan,
	year = {2010},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {nonlinear optimization, 49M37, 90C30, 65K05, 49M15, 68Q25, 90C60, cubic regularization, Newton's method, 58C15, unconstrained optimization, 49M05, global complexity bounds, global rate of convergence, steepest-descent method, trust-region methods},
	pages = {2833--2852},
	file = {Cartis et al. - 2010 - On the Complexity of Steepest Descent, Newton's an.pdf:/Users/brent/Zotero/storage/Z3ANRZG5/Cartis et al. - 2010 - On the Complexity of Steepest Descent, Newton's an.pdf:application/pdf},
}

@article{agarwal_reinforcement_nodate,
	title = {Reinforcement {Learning}: {Theory} and {Algorithms}},
	language = {en},
	author = {Agarwal, Alekh and Jiang, Nan and Kakade, Sham M and Sun, Wen},
	pages = {205},
	file = {Agarwal et al. - Reinforcement Learning Theory and Algorithms.pdf:/Users/brent/Zotero/storage/4HUUGVXB/Agarwal et al. - Reinforcement Learning Theory and Algorithms.pdf:application/pdf},
}

@article{xue_drsom_nodate,
	title = {{DRSOM} for {Reinforcement} {Learning}},
	language = {en},
	author = {Xue, Chenyu},
	pages = {9},
	file = {Xue - DRSOM for Reinforcement Learning.pdf:/Users/brent/Zotero/storage/UEBTTZDY/Xue - DRSOM for Reinforcement Learning.pdf:application/pdf},
}

@misc{zhang_drsom_2022,
	title = {{DRSOM}: {A} {Dimension} {Reduced} {Second}-{Order} {Method} and {Preliminary} {Analyses}},
	copyright = {All rights reserved},
	shorttitle = {{DRSOM}},
	url = {http://arxiv.org/abs/2208.00208},
	abstract = {We introduce a Dimension-Reduced Second-Order Method (DRSOM) for convex and nonconvex unconstrained optimization. Under a trust-region-like framework our method preserves the convergence of the second-order method while using only Hessian-vector products in two directions. Moreover, the computational overhead remains comparable to the ﬁrst-order such as the gradient descent method. We show that the method has a complexity of O( −3/2) to satisfy the ﬁrst-order and second-order conditions in the subspace. The applicability and performance of DRSOM are exhibited by various computational experiments in logistic regression, L2 − Lp minimization, sensor network localization, and neural network training. For neural networks, our preliminary implementation seems to gain computational advantages in terms of training accuracy and iteration complexity over state-ofthe-art ﬁrst-order methods including SGD and ADAM.},
	language = {en},
	urldate = {2022-08-12},
	publisher = {arXiv},
	author = {Zhang, Chuwen and Ge, Dongdong and Jiang, Bo and Ye, Yinyu},
	month = jul,
	year = {2022},
	note = {arXiv:2208.00208 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
	file = {proof2.v0.pdf:/Users/brent/Zotero/storage/T8YYX4Z7/proof2.v0.pdf:application/pdf;Zhang et al. - 2022 - DRSOM A Dimension Reduced Second-Order Method and.pdf:/Users/brent/Zotero/storage/72RUCBTZ/Zhang et al. - 2022 - DRSOM A Dimension Reduced Second-Order Method and.pdf:application/pdf},
}

@article{hager_survey_2006,
	title = {A survey of nonlinear conjugate gradient methods},
	volume = {2},
	number = {1},
	journal = {Pacific journal of Optimization},
	author = {Hager, William W. and Zhang, Hongchao},
	year = {2006},
	pages = {35--58},
}

@article{hager_new_2005,
	title = {A new conjugate gradient method with guaranteed descent and an efficient line search},
	volume = {16},
	number = {1},
	journal = {SIAM Journal on optimization},
	author = {Hager, William W. and Zhang, Hongchao},
	year = {2005},
	note = {Publisher: SIAM},
	pages = {170--192},
	file = {Hager and Zhang - 2005 - A new conjugate gradient method with guaranteed de.pdf:/Users/brent/Zotero/storage/I6JVVEWU/Hager and Zhang - 2005 - A new conjugate gradient method with guaranteed de.pdf:application/pdf},
}

@article{hager_algorithm_2006,
	title = {Algorithm 851: {CG}\_DESCENT, a conjugate gradient method with guaranteed descent},
	volume = {32},
	shorttitle = {Algorithm 851},
	number = {1},
	journal = {ACM Transactions on Mathematical Software (TOMS)},
	author = {Hager, William W. and Zhang, Hongchao},
	year = {2006},
	note = {Publisher: ACM New York, NY, USA},
	pages = {113--137},
}

@misc{yousefi_efficiency_2022,
	title = {On the efficiency of {Stochastic} {Quasi}-{Newton} {Methods} for {Deep} {Learning}},
	url = {http://arxiv.org/abs/2205.09121},
	doi = {10.48550/arXiv.2205.09121},
	abstract = {While first-order methods are popular for solving optimization problems that arise in large-scale deep learning problems, they come with some acute deficiencies. To diminish such shortcomings, there has been recent interest in applying second-order methods such as quasi-Newton based methods which construct Hessians approximations using only gradient information. The main focus of our work is to study the behaviour of stochastic quasi-Newton algorithms for training deep neural networks. We have analyzed the performance of two well-known quasi-Newton updates, the limited memory Broyden-Fletcher-Goldfarb-Shanno (BFGS) and the Symmetric Rank One (SR1). This study fills a gap concerning the real performance of both updates and analyzes whether more efficient training is obtained when using the more robust BFGS update or the cheaper SR1 formula which allows for indefinite Hessian approximations and thus can potentially help to better navigate the pathological saddle points present in the non-convex loss functions found in deep learning. We present and discuss the results of an extensive experimental study which includes the effect of batch normalization and network's architecture, the limited memory parameter, the batch size and the type of sampling strategy. we show that stochastic quasi-Newton optimizers are efficient and able to outperform in some instances the well-known first-order Adam optimizer run with the optimal combination of its numerous hyperparameters.},
	urldate = {2022-08-15},
	publisher = {arXiv},
	author = {Yousefi, Mahsa and Martinez, Angeles},
	month = may,
	year = {2022},
	note = {arXiv:2205.09121 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, 90C30, 90C06, 90C53, 90C90, 65K05},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/KR57497J/Yousefi and Martinez - 2022 - On the efficiency of Stochastic Quasi-Newton Metho.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/YPZ7E384/2205.html:text/html},
}

@article{rodomanov_greedy_2021,
	title = {Greedy {Quasi}-{Newton} {Methods} with {Explicit} {Superlinear} {Convergence}},
	volume = {31},
	issn = {1052-6234},
	url = {https://epubs.siam.org/doi/abs/10.1137/20M1320651},
	doi = {10.1137/20M1320651},
	abstract = {In this paper, we study greedy variants of quasi-Newton methods. They are based on the updating formulas from a certain subclass of the Broyden family. In particular, this subclass includes the well-known DFP, BFGS, and SR1 updates. However, in contrast to the classical quasi-Newton methods, which use the difference of successive iterates for updating the Hessian approximations, our methods apply basis vectors, greedily selected so as to maximize a certain measure of progress. For greedy quasi-Newton methods, we establish an explicit nonasymptotic bound on their rate of local superlinear convergence, as applied to minimizing strongly convex and strongly self-concordant functions (and, in particular, to strongly convex functions with Lipschitz continuous Hessian). The established superlinear convergence rate contains a contraction factor, which depends on the square of the iteration counter. We also show that greedy quasi-Newton methods produce Hessian approximations whose deviation from the exact Hessians linearly converges to zero.},
	number = {1},
	urldate = {2022-08-15},
	journal = {SIAM Journal on Optimization},
	author = {Rodomanov, Anton and Nesterov, Yurii},
	month = jan,
	year = {2021},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {90C30, 68Q25, 90C53, BFGS, Broyden family, DFP, local coverage, quasi-Newton methods, rate of convergence, SR1, superlinear convergence},
	pages = {785--811},
	file = {Full Text PDF:/Users/brent/Zotero/storage/9PQT4EFY/Rodomanov and Nesterov - 2021 - Greedy Quasi-Newton Methods with Explicit Superlin.pdf:application/pdf},
}

@article{rodomanov_new_2021,
	title = {New {Results} on {Superlinear} {Convergence} of {Classical} {Quasi}-{Newton} {Methods}},
	volume = {188},
	issn = {1573-2878},
	url = {https://doi.org/10.1007/s10957-020-01805-8},
	doi = {10.1007/s10957-020-01805-8},
	abstract = {We present a new theoretical analysis of local superlinear convergence of classical quasi-Newton methods from the convex Broyden class. As a result, we obtain a significant improvement in the currently known estimates of the convergence rates for these methods. In particular, we show that the corresponding rate of the Broyden–Fletcher–Goldfarb–Shanno method depends only on the product of the dimensionality of the problem and the logarithm of its condition number.},
	language = {en},
	number = {3},
	urldate = {2022-08-15},
	journal = {Journal of Optimization Theory and Applications},
	author = {Rodomanov, Anton and Nesterov, Yurii},
	month = mar,
	year = {2021},
	keywords = {90C30, 68Q25, Quasi-Newton methods, Rate of convergence, Local convergence, 90C53, BFGS, DFP, Convex Broyden class, Superlinear convergence},
	pages = {744--769},
	file = {Full Text PDF:/Users/brent/Zotero/storage/NZGWVCAT/Rodomanov and Nesterov - 2021 - New Results on Superlinear Convergence of Classica.pdf:application/pdf},
}

@article{rodomanov_rates_2022,
	title = {Rates of superlinear convergence for classical quasi-{Newton} methods},
	volume = {194},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-021-01622-5},
	doi = {10.1007/s10107-021-01622-5},
	abstract = {We study the local convergence of classical quasi-Newton methods for nonlinear optimization. Although it was well established a long time ago that asymptotically these methods converge superlinearly, the corresponding rates of convergence still remain unknown. In this paper, we address this problem. We obtain first explicit non-asymptotic rates of superlinear convergence for the standard quasi-Newton methods, which are based on the updating formulas from the convex Broyden class. In particular, for the well-known DFP and BFGS methods, we obtain the rates of the form \$\$({\textbackslash}frac\{n L{\textasciicircum}2\}\{{\textbackslash}mu {\textasciicircum}2 k\}){\textasciicircum}\{k/2\}\$\$and \$\$({\textbackslash}frac\{n L\}\{{\textbackslash}mu k\}){\textasciicircum}\{k/2\}\$\$respectively, where k is the iteration counter, n is the dimension of the problem, \$\${\textbackslash}mu \$\$is the strong convexity parameter, and L is the Lipschitz constant of the gradient.},
	language = {en},
	number = {1},
	urldate = {2022-08-15},
	journal = {Mathematical Programming},
	author = {Rodomanov, Anton and Nesterov, Yurii},
	month = jul,
	year = {2022},
	keywords = {90C30, 68Q25, Quasi-Newton methods, Rate of convergence, Local convergence, 90C53, BFGS, DFP, Convex Broyden class, Superlinear convergence},
	pages = {159--190},
	file = {Full Text PDF:/Users/brent/Zotero/storage/S5B7DBBG/Rodomanov and Nesterov - 2022 - Rates of superlinear convergence for classical qua.pdf:application/pdf},
}

@inproceedings{apostolopoulou_memoryless_2009,
	address = {Cardiff, Wales, UK},
	title = {A memoryless {BFGS} neural network training algorithm},
	isbn = {978-1-4244-3759-7},
	url = {http://ieeexplore.ieee.org/document/5195806/},
	doi = {10.1109/INDIN.2009.5195806},
	abstract = {We present a new curvilinear algorithmic model for training neural networks which is based on a modiﬁcations of the memoryless BFGS method that incorporates a curvilinear search. The proposed model exploits the nonconvexity of the error surface based on information provided by the eigensystem of memoryless BFGS matrices using a pair of directions; a memoryless quasi-Newton direction and a direction of negative curvature. In addition, the computation of the negative curvature direction is accomplished by avoiding any storage and matrix factorization. Simulations results verify that the proposed modiﬁcation signiﬁcantly improves the eﬃciency of the training process.},
	language = {en},
	urldate = {2022-08-15},
	booktitle = {2009 7th {IEEE} {International} {Conference} on {Industrial} {Informatics}},
	publisher = {IEEE},
	author = {Apostolopoulou, M.S. and Sotiropoulos, D.G. and Livieris, I.E. and Pintelas, P.},
	month = jun,
	year = {2009},
	pages = {216--221},
	file = {Apostolopoulou et al. - 2009 - A memoryless BFGS neural network training algorith.pdf:/Users/brent/Zotero/storage/BLELAZKG/Apostolopoulou et al. - 2009 - A memoryless BFGS neural network training algorith.pdf:application/pdf},
}

@article{more_use_1979,
	title = {On the use of directions of negative curvature in a modified newton method},
	volume = {16},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/BF01582091},
	doi = {10.1007/BF01582091},
	abstract = {We present a modified Newton method for the unconstrained minimization problem. The modification occurs in non-convex regions where the information contained in the negative eigenvalues of the Hessian is taken into account by performing a line search along a path which is initially tangent to a direction of negative curvature. We give termination criteria for the line search and prove that the resulting iterates are guaranteed to converge, under reasonable conditions, to a critical point at which the Hessian is positive semidefinite. We also show how the Bunch and Parlett decomposition of a symmetric indefinite matrix can be used to give entirely adequate directions of negative curvature.},
	language = {en},
	number = {1},
	urldate = {2022-08-15},
	journal = {Mathematical Programming},
	author = {Moré, Jorge J. and Sorensen, Danny C.},
	month = dec,
	year = {1979},
	keywords = {Unconstrained Optimization, Descent Pairs, Directions of Negative Curvature, Modified Newton's Method, Steplength Algorithm, Symmetric Indefinite Factorization},
	pages = {1--20},
	file = {Full Text PDF:/Users/brent/Zotero/storage/AI7V5IY6/Moré and Sorensen - 1979 - On the use of directions of negative curvature in .pdf:application/pdf},
}

@misc{schulman_proximal_2017,
	title = {Proximal {Policy} {Optimization} {Algorithms}},
	url = {http://arxiv.org/abs/1707.06347},
	doi = {10.48550/arXiv.1707.06347},
	abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
	urldate = {2022-08-21},
	publisher = {arXiv},
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	month = aug,
	year = {2017},
	note = {arXiv:1707.06347 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/GGVCDJDD/Schulman et al. - 2017 - Proximal Policy Optimization Algorithms.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/4WJUMT8F/1707.html:text/html},
}

@article{ren_kronecker-factored_2021,
	title = {Kronecker-factored quasi-newton methods for convolutional neural networks},
	journal = {arXiv preprint arXiv:2102.06737},
	author = {Ren, Yi and Goldfarb, Donald},
	year = {2021},
	file = {Full Text:/Users/brent/Zotero/storage/XEU5VQRS/Ren and Goldfarb - 2021 - Kronecker-factored quasi-newton methods for convol.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/SVTFBVPF/2102.html:text/html},
}

@article{gao_block_2018,
	title = {Block {BFGS} methods},
	volume = {28},
	number = {2},
	journal = {SIAM Journal on Optimization},
	author = {Gao, Wenbo and Goldfarb, Donald},
	year = {2018},
	note = {Publisher: SIAM},
	pages = {1205--1231},
	file = {Full Text:/Users/brent/Zotero/storage/2Z2JCUNA/Gao and Goldfarb - 2018 - Block BFGS methods.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/GGLVVTVE/16M1092106.html:text/html},
}

@inproceedings{gower_stochastic_2016,
	title = {Stochastic block {BFGS}: {Squeezing} more curvature out of data},
	shorttitle = {Stochastic block {BFGS}},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Gower, Robert and Goldfarb, Donald and Richtárik, Peter},
	year = {2016},
	pages = {1869--1878},
	file = {Full Text:/Users/brent/Zotero/storage/N3URNHTF/Gower et al. - 2016 - Stochastic block BFGS Squeezing more curvature ou.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/SUGWM3JX/gower16.html:text/html},
}

@article{curtis_inexact_2018,
	title = {An inexact regularized {Newton} framework with a worst-case iteration complexity of {O}(ε−3/2) for nonconvex optimization},
	language = {en},
	author = {Curtis, Frank E and Robinson, Daniel P},
	year = {2018},
	pages = {32},
	file = {Curtis and Robinson - 2018 - An inexact regularized Newton framework with a wor.pdf:/Users/brent/Zotero/storage/HJPZ63BV/Curtis and Robinson - 2018 - An inexact regularized Newton framework with a wor.pdf:application/pdf},
}

@article{bandeira_convergence_2014,
	title = {Convergence of {Trust}-{Region} {Methods} {Based} on {Probabilistic} {Models}},
	volume = {24},
	issn = {1052-6234},
	url = {https://epubs.siam.org/doi/abs/10.1137/130915984},
	doi = {10.1137/130915984},
	abstract = {In this paper we consider the use of probabilistic or random models within a classical trust-region framework for optimization of deterministic smooth general nonlinear functions. Our method and setting differs from many stochastic optimization approaches in two principal ways. Firstly, we assume that the value of the function itself can be computed without noise, in other words, that the function is deterministic. Second, we use random models of higher quality than those produced by the usual stochastic gradient methods. In particular, a first order model based on random approximation of the gradient is required to provide sufficient quality of approximation with probability 
≥1/2
≥1/2
. This is in contrast with stochastic gradient approaches, where the model is assumed to be “correct” only in expectation. As a result of this particular setting, we are able to prove convergence, with probability one, of a trust-region method which is almost identical to the classical method. Moreover, the new method is simpler than its deterministic counterpart as it does not require a criticality step. Hence we show that a standard optimization framework can be used in cases when models are random and may or may not provide good approximations, as long as “good” models are more likely than “bad” models. Our results are based on the use of properties of martingales. Our motivation comes from using random sample sets and interpolation models in derivative-free optimization. However, our framework is general and can be applied with any source of uncertainty in the model. We discuss various applications for our methods in the paper.},
	number = {3},
	urldate = {2022-08-28},
	journal = {SIAM Journal on Optimization},
	author = {Bandeira, A. S. and Scheinberg, K. and Vicente, L. N.},
	month = jan,
	year = {2014},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {global convergence, 90C30, unconstrained optimization, trust-region methods, 68W20, 90C56, derivative-free optimization, probabilistic models},
	pages = {1238--1264},
	file = {Submitted Version:/Users/brent/Zotero/storage/KULQ9VET/Bandeira et al. - 2014 - Convergence of Trust-Region Methods Based on Proba.pdf:application/pdf},
}

@article{blanchet_convergence_2019,
	title = {Convergence {Rate} {Analysis} of a {Stochastic} {Trust}-{Region} {Method} via {Supermartingales}},
	volume = {1},
	issn = {2575-1484},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/ijoo.2019.0016},
	doi = {10.1287/ijoo.2019.0016},
	abstract = {We propose a novel framework for analyzing convergence rates of stochastic optimization algorithms with adaptive step sizes. This framework is based on analyzing properties of an underlying generic stochastic process; in particular, we derive a bound on the expected stopping time of this process. We utilize this framework to analyze the expected global convergence rates of a stochastic variant of a traditional trust-region method. Although traditional trust-region methods rely on exact computations of the gradient, Hessian, and values of the objective function, this method assumes that these values are available only up to some dynamically adjusted accuracy. Moreover, this accuracy is assumed to hold only with some sufficiently large—but fixed—probability without any additional restrictions on the variance of the errors. This setting applies, for example, to standard stochastic optimization and machine learning formulations. Improving upon prior analysis, we show that the stochastic process defined by the trust-region method satisfies the assumptions of our proposed general framework. The stopping time in this setting is defined by an iterate satisfying a first-order accuracy condition. We demonstrate the first global complexity bound for a stochastic trust-region method under the assumption of sufficiently accurate stochastic gradients. Finally, we apply the same framework to derive second-order complexity bounds under additional assumptions.},
	number = {2},
	urldate = {2022-08-28},
	journal = {INFORMS Journal on Optimization},
	author = {Blanchet, Jose and Cartis, Coralia and Menickelly, Matt and Scheinberg, Katya},
	month = apr,
	year = {2019},
	note = {Publisher: INFORMS},
	keywords = {trust-region methods, convergence rates, stochastic optimization, stochastic processes, supermartingales},
	pages = {92--119},
	file = {Full Text PDF:/Users/brent/Zotero/storage/S3WTDWKX/Blanchet et al. - 2019 - Convergence Rate Analysis of a Stochastic Trust-Re.pdf:application/pdf},
}

@article{gratton_complexity_2018,
	title = {Complexity and global rates of trust-region methods based on probabilistic models},
	volume = {38},
	issn = {0272-4979},
	url = {https://doi.org/10.1093/imanum/drx043},
	doi = {10.1093/imanum/drx043},
	abstract = {Trust-region algorithms have been proved to globally converge with probability 1 when the accuracy of the trust-region models is imposed with a certain probability conditioning on the iteration history. In this article, we study the complexity of such methods, providing global rates and worst-case complexity bounds on the number of iterations (with overwhelmingly high probability), for both first- and second-order measures of optimality. Such results are essentially the same as the ones known for trust-region methods based on deterministic models. The derivation of the global rates and worst-case complexity bounds follows closely from a study of direct search methods based on the companion notion of probabilistic descent.},
	number = {3},
	urldate = {2022-08-28},
	journal = {IMA Journal of Numerical Analysis},
	author = {Gratton, Serge and Royer, Clément W and Vicente, Luís N and Zhang, Zaikun},
	month = jul,
	year = {2018},
	pages = {1579--1597},
	file = {Full Text PDF:/Users/brent/Zotero/storage/3B7KAM2V/Gratton et al. - 2018 - Complexity and global rates of trust-region method.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/TJ7JQXZE/4084726.html:text/html},
}

@article{fletcher_nonlinear_2002,
	title = {Nonlinear programming without a penalty function},
	volume = {91},
	number = {2},
	journal = {Mathematical programming},
	author = {Fletcher, Roger and Leyffer, Sven},
	year = {2002},
	note = {Publisher: Springer},
	pages = {239--269},
	file = {Full Text:/Users/brent/Zotero/storage/VB7YIPJQ/Fletcher and Leyffer - 2002 - Nonlinear programming without a penalty function.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/BCFT4FMW/s101070100244.html:text/html},
}

@article{liu_sequential_2011,
	title = {A sequential quadratic programming method without a penalty function or a filter for nonlinear equality constrained optimization},
	volume = {21},
	number = {2},
	journal = {SIAM Journal on Optimization},
	author = {Liu, Xinwei and Yuan, Yaxiang},
	year = {2011},
	note = {Publisher: SIAM},
	pages = {545--571},
	file = {Snapshot:/Users/brent/Zotero/storage/EMI75SSY/080739884.html:text/html},
}

@article{gould_nonlinear_2010,
	title = {Nonlinear programming without a penalty function or a filter},
	volume = {122},
	number = {1},
	journal = {Mathematical Programming},
	author = {Gould, Nicholas IM and Toint, Ph L.},
	year = {2010},
	note = {Publisher: Springer},
	pages = {155--196},
	file = {Full Text:/Users/brent/Zotero/storage/VF3N93FV/Gould and Toint - 2010 - Nonlinear programming without a penalty function o.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/T9MWC789/s10107-008-0244-7.html:text/html},
}

@article{bandeira_computation_2012,
	title = {Computation of sparse low degree interpolating polynomials and their application to derivative-free optimization},
	volume = {134},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-012-0578-z},
	doi = {10.1007/s10107-012-0578-z},
	abstract = {Interpolation-based trust-region methods are an important class of algorithms for Derivative-Free Optimization which rely on locally approximating an objective function by quadratic polynomial interpolation models, frequently built from less points than there are basis components. Often, in practical applications, the contribution of the problem variables to the objective function is such that many pairwise correlations between variables are negligible, implying, in the smooth case, a sparse structure in the Hessian matrix. To be able to exploit Hessian sparsity, existing optimization approaches require the knowledge of the sparsity structure. The goal of this paper is to develop and analyze a method where the sparse models are constructed automatically. The sparse recovery theory developed recently in the field of compressed sensing characterizes conditions under which a sparse vector can be accurately recovered from few random measurements. Such a recovery is achieved by minimizing the ℓ1-norm of a vector subject to the measurements constraints. We suggest an approach for building sparse quadratic polynomial interpolation models by minimizing the ℓ1-norm of the entries of the model Hessian subject to the interpolation conditions. We show that this procedure recovers accurate models when the function Hessian is sparse, using relatively few randomly selected sample points. Motivated by this result, we developed a practical interpolation-based trust-region method using deterministic sample sets and minimum ℓ1-norm quadratic models. Our computational results show that the new approach exhibits a promising numerical performance both in the general case and in the sparse one.},
	language = {en},
	number = {1},
	urldate = {2022-08-28},
	journal = {Mathematical Programming},
	author = {Bandeira, A. S. and Scheinberg, K. and Vicente, L. N.},
	month = aug,
	year = {2012},
	keywords = {90C30, 90C90, Compressed sensing, 90C56, 65D05, Derivative-free optimization, Interpolation-based trust-region methods, ℓ 1-Minimization, Random sampling, Sparse recovery},
	pages = {223--257},
	file = {Full Text PDF:/Users/brent/Zotero/storage/NY5S8YGQ/Bandeira et al. - 2012 - Computation of sparse low degree interpolating pol.pdf:application/pdf},
}

@article{drineas_randnla_2016,
	title = {{RandNLA}: randomized numerical linear algebra},
	volume = {59},
	issn = {0001-0782},
	shorttitle = {{RandNLA}},
	url = {https://doi.org/10.1145/2842602},
	doi = {10.1145/2842602},
	abstract = {Randomization offers new benefits for large-scale linear algebra computations.},
	number = {6},
	urldate = {2022-08-28},
	journal = {Communications of the ACM},
	author = {Drineas, Petros and Mahoney, Michael W.},
	month = may,
	year = {2016},
	pages = {80--90},
}

@article{mahoney_randomized_2011,
	title = {Randomized algorithms for matrices and data},
	volume = {3},
	number = {2},
	journal = {Foundations and Trends® in Machine Learning},
	author = {Mahoney, Michael W.},
	year = {2011},
	note = {Publisher: Now Publishers, Inc.},
	pages = {123--224},
	file = {Full Text:/Users/brent/Zotero/storage/NPPCWELA/Mahoney - 2011 - Randomized algorithms for matrices and data.pdf:application/pdf;Mahoney - 2011 - Randomized algorithms for matrices and data.pdf:/Users/brent/Zotero/storage/2VZL36DL/Mahoney - 2011 - Randomized algorithms for matrices and data.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/UP2AQ428/MAL-035.html:text/html},
}

@article{woodruff_sketching_2014,
	title = {Sketching as a tool for numerical linear algebra},
	volume = {10},
	number = {1–2},
	journal = {Foundations and Trends® in Theoretical Computer Science},
	author = {Woodruff, David P.},
	year = {2014},
	note = {Publisher: Now Publishers, Inc.},
	pages = {1--157},
	file = {Full Text:/Users/brent/Zotero/storage/J8HK8ED2/Woodruff - 2014 - Sketching as a tool for numerical linear algebra.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/Q8S9FN2R/TCS-060.html:text/html},
}

@misc{he_survey_nodate,
	title = {A {Survey} on {Randomized} {Numerical} {Linear} {Algebra}},
	abstract = {Drineas, P., Kannan, R. and Mahoney, M.W., 2006. Fast Monte Carlo algorithms for matrices I: Approximating matrix multiplication. SIAM Journal on Computing, 36(1), pp.132-157.},
	language = {en},
	author = {He, Chang},
	file = {He - A Survey on Randomized Numerical Linear Algebra.pdf:/Users/brent/Zotero/storage/MSNDXZIZ/He - A Survey on Randomized Numerical Linear Algebra.pdf:application/pdf},
}

@article{curtis_exploiting_2019,
	title = {Exploiting negative curvature in deterministic and stochastic optimization},
	volume = {176},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-018-1335-8},
	doi = {10.1007/s10107-018-1335-8},
	abstract = {This paper addresses the question of whether it can be beneficial for an optimization algorithm to follow directions of negative curvature. Although prior work has established convergence results for algorithms that integrate both descent and negative curvature steps, there has not yet been extensive numerical evidence showing that such methods offer consistent performance improvements. In this paper, we present new frameworks for combining descent and negative curvature directions: alternating two-step approaches and dynamic step approaches. The aspect that distinguishes our approaches from ones previously proposed is that they make algorithmic decisions based on (estimated) upper-bounding models of the objective function. A consequence of this aspect is that our frameworks can, in theory, employ fixed stepsizes, which makes the methods readily translatable from deterministic to stochastic settings. For deterministic problems, we show that instances of our dynamic framework yield gains in performance compared to related methods that only follow descent steps. We also show that gains can be made in a stochastic setting in cases when a standard stochastic-gradient-type method might make slow progress.},
	language = {en},
	number = {1},
	urldate = {2022-08-28},
	journal = {Mathematical Programming},
	author = {Curtis, Frank E. and Robinson, Daniel P.},
	month = jul,
	year = {2019},
	keywords = {49M37, 90C26, 90C30, 65K05, 90C15, 49M15, Nonconvex optimization, 49M05, 90C53, Machine learning, Modified Newton methods, Negative curvature, Second-order methods, Stochastic optimization},
	pages = {69--94},
	file = {Curtis and Robinson - 2019 - Exploiting negative curvature in deterministic and.pdf:/Users/brent/Zotero/storage/6NP4XH52/Curtis and Robinson - 2019 - Exploiting negative curvature in deterministic and.pdf:application/pdf},
}

@article{erway_subspace_2010,
	title = {A {Subspace} {Minimization} {Method} for the {Trust}-{Region} {Step}},
	volume = {20},
	issn = {1052-6234, 1095-7189},
	url = {http://epubs.siam.org/doi/10.1137/08072440X},
	doi = {10.1137/08072440X},
	abstract = {We consider methods for large-scale unconstrained minimization based on ﬁnding an approximate minimizer of a quadratic function subject to a two-norm trust-region constraint. The Steihaug–Toint method uses the conjugate-gradient method to minimize the quadratic over a sequence of expanding subspaces until the iterates either converge to an interior point or cross the constraint boundary. However, if the conjugate-gradient method is used with a preconditioner, the Steihaug–Toint method requires that the trust-region norm be deﬁned in terms of the preconditioning matrix. If a diﬀerent preconditioner is used for each subproblem, the shape of the trust-region can change substantially from one subproblem to the next, which invalidates many of the assumptions on which standard methods for adjusting the trust-region radius are based. In this paper we propose a method that allows the trust-region norm to be deﬁned independently of the preconditioner. The method solves the inequality constrained trust-region subproblem over a sequence of evolving lowdimensional subspaces. Each subspace includes an accelerator direction deﬁned by a regularized Newton method for satisfying the optimality conditions of a primal-dual interior method. A crucial property of this direction is that it can be computed by applying the preconditioned conjugategradient method to a positive-deﬁnite system in both the primal and dual variables of the trustregion subproblem. Numerical experiments on problems from the CUTEr test collection indicate that the method can require signiﬁcantly fewer function evaluations than other methods. In addition, experiments with general-purpose preconditioners show that it is possible to signiﬁcantly reduce the number of matrix-vector products relative to those required without preconditioning.},
	language = {en},
	number = {3},
	urldate = {2022-08-28},
	journal = {SIAM Journal on Optimization},
	author = {Erway, Jennifer B. and Gill, Philip E.},
	month = jan,
	year = {2010},
	pages = {1439--1461},
	file = {Erway and Gill - 2010 - A Subspace Minimization Method for the Trust-Regio.pdf:/Users/brent/Zotero/storage/2BAGJA4P/Erway and Gill - 2010 - A Subspace Minimization Method for the Trust-Regio.pdf:application/pdf},
}

@misc{curtis_worst-case_2022-1,
	title = {Worst-{Case} {Complexity} of {TRACE} with {Inexact} {Subproblem} {Solutions} for {Nonconvex} {Smooth} {Optimization}},
	url = {http://arxiv.org/abs/2204.11322},
	doi = {10.48550/arXiv.2204.11322},
	abstract = {An algorithm for solving nonconvex smooth optimization problems is proposed, analyzed, and tested. The algorithm is an extension of the Trust Region Algorithm with Contractions and Expansions (TRACE) [Math. Prog. 162(1):132, 2017]. In particular, the extension allows the algorithm to use inexact solutions of the arising subproblems, which is an important feature for solving large-scale problems. Inexactness is allowed in a manner such that the optimal iteration complexity of \$\{{\textbackslash}cal O\}({\textbackslash}epsilon{\textasciicircum}\{-3/2\})\$ for attaining an \${\textbackslash}epsilon\$-approximate first-order stationary point is maintained while the worst-case complexity in terms of Hessian-vector products may be significantly improved as compared to the original TRACE. Numerical experiments show the benefits of allowing inexact subproblem solutions and that the algorithm compares favorably to a state-of-the-art technique.},
	urldate = {2022-08-28},
	publisher = {arXiv},
	author = {Curtis, Frank E. and Wang, Qi},
	month = apr,
	year = {2022},
	note = {arXiv:2204.11322 [math]},
	keywords = {Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/YV243GLW/Curtis and Wang - 2022 - Worst-Case Complexity of TRACE with Inexact Subpro.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/PLJELMCL/2204.html:text/html},
}

@incollection{wang_subspace_nodate,
	title = {A subspace trust-region method for large-scale unconstrained optimization},
	author = {Wang, Zhou-hong and Wen, Zaiwen and Yuan, Yaxiang},
	file = {wanwenyuan.pdf:/Users/brent/Zotero/storage/4FXXPIQZ/wanwenyuan.pdf:application/pdf},
}

@article{wang_subspace_2006,
	title = {A subspace implementation of quasi-{Newton} trust region methods for unconstrained optimization},
	volume = {104},
	issn = {0945-3245},
	url = {https://doi.org/10.1007/s00211-006-0021-6},
	doi = {10.1007/s00211-006-0021-6},
	abstract = {This paper studies subspace properties of trust region methods for unconstrained optimization, assuming the approximate Hessian is updated by quasi- Newton formulae and the initial Hessian approximation is appropriately chosen. It is shown that the trial step obtained by solving the trust region subproblem is in the subspace spanned by all the gradient vectors computed. Thus, the trial step can be defined by minimizing the quasi-Newton quadratic model in the subspace. Based on this observation, some subspace trust region algorithms are proposed and numerical results are also reported.},
	language = {en},
	number = {2},
	urldate = {2022-08-28},
	journal = {Numerische Mathematik},
	author = {Wang, Zhou-Hong and Yuan, Ya-Xiang},
	month = aug,
	year = {2006},
	keywords = {65K05, 90C53},
	pages = {241--269},
	file = {Wang and Yuan - 2006 - A subspace implementation of quasi-Newton trust re.pdf:/Users/brent/Zotero/storage/Z66QAGXZ/Wang and Yuan - 2006 - A subspace implementation of quasi-Newton trust re.pdf:application/pdf},
}

@article{liu_null-space_2010,
	title = {A null-space primal-dual interior-point algorithm for nonlinear optimization with nice convergence properties},
	volume = {125},
	number = {1},
	journal = {Mathematical programming},
	author = {Liu, Xinwei and Yuan, Yaxiang},
	year = {2010},
	note = {Publisher: Springer},
	pages = {163--193},
	file = {Full Text:/Users/brent/Zotero/storage/6IKJYEXH/Liu and Yuan - 2010 - A null-space primal-dual interior-point algorithm .pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/QPVIVCMY/s10107-009-0272-y.html:text/html},
}

@article{lee_subspace_2019,
	title = {A subspace {SQP} method for equality constrained optimization},
	volume = {74},
	issn = {1573-2894},
	url = {https://doi.org/10.1007/s10589-019-00109-6},
	doi = {10.1007/s10589-019-00109-6},
	abstract = {In this paper, we present a subspace method for solving large scale nonlinear equality constrained optimization problems. The proposed method is based on a SQP method combined with the limited-memory BFGS update formula. Each subproblem is solved in a theoretically suitable subspace. In the case of few constraints, we show that our search direction in the subspace is equivalent to that of the SQP subproblem in the full space. In the case of many constraints, we reduce the number of constraints in the subproblem and we show that the solution of the subspace subproblem is a descent direction of a particular exact penalty function. Global convergence properties of the proposed method are given for both cases. Numerical results are given to illustrate the soundness of the proposed model.},
	language = {en},
	number = {1},
	urldate = {2022-08-28},
	journal = {Computational Optimization and Applications},
	author = {Lee, Jae Hwa and Jung, Yoon Mo and Yuan, Ya-xiang and Yun, Sangwoon},
	month = sep,
	year = {2019},
	keywords = {90C30, 65K05, 90C06, 90C55, Damped limited-memory BFGS update, Equality constrained optimization, Large scale problems, SQP method, Subspace techniques},
	pages = {177--194},
	file = {Full Text PDF:/Users/brent/Zotero/storage/GPUBR7HR/Lee et al. - 2019 - A subspace SQP method for equality constrained opt.pdf:application/pdf},
}

@article{yang_sketch-based_2022,
	title = {Sketch-{Based} {Empirical} {Natural} {Gradient} {Methods} for {Deep} {Learning}},
	volume = {92},
	issn = {0885-7474, 1573-7691},
	url = {https://link.springer.com/10.1007/s10915-022-01911-x},
	doi = {10.1007/s10915-022-01911-x},
	abstract = {In this paper, we develop an efﬁcient sketch-based empirical natural gradient method (SENG) for large-scale deep learning problems. The empirical Fisher information matrix is usually low-rank since the sampling is only practical on a small amount of data at each iteration. Although the corresponding natural gradient direction lies in a small subspace, both the computational cost and memory requirement are still not tractable due to the high dimensionality. We design randomized techniques for different neural network structures to resolve these challenges. For layers with a reasonable dimension, sketching can be performed on a regularized least squares subproblem. Otherwise, since the gradient is a vectorization of the product between two matrices, we apply sketching on the low-rank approximations of these matrices to compute the most expensive parts. A distributed version of SENG is also developed for extremely large-scale applications. Global convergence to stationary points is established under mild assumptions and a fast linear convergence is analyzed under the neural tangent kernel (NTK) case. Extensive experiments on convolutional neural networks show the competitiveness of SENG compared with the state-of-the-art methods. On the task ResNet50 with ImageNet-1k, SENG achieves 75.9\% Top-1 testing accuracy within 41 epochs.},
	language = {en},
	number = {3},
	urldate = {2022-08-29},
	journal = {Journal of Scientific Computing},
	author = {Yang, Minghan and Xu, Dong and Wen, Zaiwen and Chen, Mengyun and Xu, Pengxiang},
	month = sep,
	year = {2022},
	pages = {94},
	file = {Yang et al. - 2022 - Sketch-Based Empirical Natural Gradient Methods fo.pdf:/Users/brent/Zotero/storage/N25EX83I/Yang et al. - 2022 - Sketch-Based Empirical Natural Gradient Methods fo.pdf:application/pdf},
}

@article{dembot_inexact_nodate,
	title = {Inexact {Newton} {Methods}},
	language = {en},
	author = {Dembot, RON S and Eisenstat, Stanley C and Steihaug, Trond},
	pages = {9},
	file = {DEMBOt et al. - Inexact Newton Methods.pdf:/Users/brent/Zotero/storage/7E7NG3VG/DEMBOt et al. - Inexact Newton Methods.pdf:application/pdf},
}

@misc{mahoney_lecture_2016,
	title = {Lecture {Notes} on {Randomized} {Linear} {Algebra}},
	url = {http://arxiv.org/abs/1608.04481},
	abstract = {These are lecture notes that are based on the lectures from a class I taught on the topic of Randomized Linear Algebra (RLA) at UC Berkeley during the Fall 2013 semester.},
	language = {en},
	urldate = {2022-08-30},
	publisher = {arXiv},
	author = {Mahoney, Michael W.},
	month = aug,
	year = {2016},
	note = {arXiv:1608.04481 [cs, stat]},
	keywords = {Statistics - Machine Learning, Computer Science - Data Structures and Algorithms},
	file = {Mahoney - 2016 - Lecture Notes on Randomized Linear Algebra.pdf:/Users/brent/Zotero/storage/QZBE4WHU/Mahoney - 2016 - Lecture Notes on Randomized Linear Algebra.pdf:application/pdf},
}

@misc{clarkson_low_2013,
	title = {Low {Rank} {Approximation} and {Regression} in {Input} {Sparsity} {Time}},
	url = {http://arxiv.org/abs/1207.6365},
	abstract = {We design a new distribution over poly(rε−1) × n matrices S so that for any ﬁxed n × d matrix A of rank r, with probability at least 9/10, SAx 2 = (1 ± ε) Ax 2 simultaneously for all x ∈ Rd. Such a matrix S is called a subspace embedding. Furthermore, SA can be computed in O(nnz(A))time, where nnz(A) is the number of non-zero entries of A. This improves over all previous subspace embeddings, which required at least Ω(nd log d) time to achieve this property. We call our matrices S sparse embedding matrices.},
	language = {en},
	urldate = {2022-08-30},
	publisher = {arXiv},
	author = {Clarkson, Kenneth L. and Woodruff, David P.},
	month = apr,
	year = {2013},
	note = {arXiv:1207.6365 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {Clarkson and Woodruff - 2013 - Low Rank Approximation and Regression in Input Spa.pdf:/Users/brent/Zotero/storage/X9RP2KMG/Clarkson and Woodruff - 2013 - Low Rank Approximation and Regression in Input Spa.pdf:application/pdf},
}

@misc{jin_short_2019,
	title = {A {Short} {Note} on {Concentration} {Inequalities} for {Random} {Vectors} with {SubGaussian} {Norm}},
	url = {http://arxiv.org/abs/1902.03736},
	abstract = {In this note, we derive concentration inequalities for random vectors with subGaussian norm (a generalization of both subGaussian random vectors and norm bounded random vectors), which are tight up to logarithmic factors.},
	language = {en},
	urldate = {2022-08-30},
	publisher = {arXiv},
	author = {Jin, Chi and Netrapalli, Praneeth and Ge, Rong and Kakade, Sham M. and Jordan, Michael I.},
	month = feb,
	year = {2019},
	note = {arXiv:1902.03736 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Probability},
	file = {Jin et al. - 2019 - A Short Note on Concentration Inequalities for Ran.pdf:/Users/brent/Zotero/storage/S798RK8L/Jin et al. - 2019 - A Short Note on Concentration Inequalities for Ran.pdf:application/pdf},
}

@article{drineas_fast_nodate,
	title = {{FAST} {MONTE} {CARLO} {ALGORITHMS} {FOR} {MATRICES} {II}: {COMPUTING} {A} {LOW}-{RANK} {APPROXIMATION} {TO} {A} {MATRIX}},
	language = {en},
	author = {Drineas, Petros and Kannan, Ravi and Mahoney, Michael W},
	pages = {26},
	file = {Drineas et al. - FAST MONTE CARLO ALGORITHMS FOR MATRICES II COMPU.pdf:/Users/brent/Zotero/storage/5DJJDN5D/Drineas et al. - FAST MONTE CARLO ALGORITHMS FOR MATRICES II COMPU.pdf:application/pdf},
}

@article{vershynin_high-dimensional_nodate,
	title = {High-{Dimensional} {Probability}},
	language = {en},
	author = {Vershynin, Roman},
	pages = {301},
	file = {Vershynin - High-Dimensional Probability.pdf:/Users/brent/Zotero/storage/2SDY4ECE/Vershynin - High-Dimensional Probability.pdf:application/pdf},
}

@misc{zhao_stochastic_2019,
	title = {A {Stochastic} {Trust}-{Region} {Framework} for {Policy} {Optimization}},
	url = {http://arxiv.org/abs/1911.11640},
	abstract = {In this paper, we study a few challenging theoretical and numerical issues on the well known trust region policy optimization for deep reinforcement learning. The goal is to ﬁnd a policy that maximizes the total expected reward when the agent acts according to the policy. The trust region subproblem is constructed with a surrogate function coherent to the total expected reward and a general distance constraint around the latest policy. We solve the subproblem using a preconditioned stochastic gradient method with a line search scheme to ensure that each step promotes the model function and stays in the trust region. To overcome the bias caused by sampling to the function estimations under the random settings, we add the empirical standard deviation of the total expected reward to the predicted increase in a ratio in order to update the trust region radius and decide whether the trial point is accepted. Moreover, for a Gaussian policy which is commonly used for continuous action space, the maximization with respect to the mean and covariance is performed separately to control the entropy loss. Our theoretical analysis shows that the deterministic version of the proposed algorithm tends to generate a monotonic improvement of the total expected reward and the global convergence is guaranteed under moderate assumptions. Comparisons with the stateof-the-art methods demonstrate the eﬀectiveness and robustness of our method over robotic controls and game playings from OpenAI Gym.},
	language = {en},
	urldate = {2022-08-31},
	publisher = {arXiv},
	author = {Zhao, Mingming and Li, Yongfeng and Wen, Zaiwen},
	month = nov,
	year = {2019},
	note = {arXiv:1911.11640 [math]},
	keywords = {Mathematics - Optimization and Control},
	file = {Zhao et al. - 2019 - A Stochastic Trust-Region Framework for Policy Opt.pdf:/Users/brent/Zotero/storage/529UPW4V/Zhao et al. - 2019 - A Stochastic Trust-Region Framework for Policy Opt.pdf:application/pdf},
}

@article{gould_cutest_2015,
	title = {{CUTEst}: a {Constrained} and {Unconstrained} {Testing} {Environment} with safe threads for mathematical optimization},
	volume = {60},
	issn = {1573-2894},
	shorttitle = {{CUTEst}},
	url = {https://doi.org/10.1007/s10589-014-9687-3},
	doi = {10.1007/s10589-014-9687-3},
	abstract = {We describe the most recent evolution of our constrained and unconstrained testing environment and its accompanying SIF decoder. Code-named SIFDecode and CUTEst, these updated versions feature dynamic memory allocation, a modern thread-safe Fortran modular design, a new Matlab interface and a revised installation procedure integrated with GALAHAD.},
	language = {en},
	number = {3},
	urldate = {2022-08-31},
	journal = {Computational Optimization and Applications},
	author = {Gould, Nicholas I. M. and Orban, Dominique and Toint, Philippe L.},
	month = apr,
	year = {2015},
	keywords = {Optimization, Modeling, Benchmarking, CUTE, CUTEr, CUTEst},
	pages = {545--557},
	file = {Full Text PDF:/Users/brent/Zotero/storage/YGASWRKY/Gould et al. - 2015 - CUTEst a Constrained and Unconstrained Testing En.pdf:application/pdf},
}

@article{gould_solving_2010,
	title = {On solving trust-region and other regularised subproblems in optimization},
	volume = {2},
	number = {1},
	journal = {Mathematical Programming Computation},
	author = {Gould, Nicholas IM and Robinson, Daniel P. and Thorne, H. Sue},
	year = {2010},
	note = {Publisher: Springer},
	pages = {21--57},
	file = {Snapshot:/Users/brent/Zotero/storage/8K72P3FA/s12532-010-0011-7.html:text/html},
}

@article{hazan_linear-time_2016,
	title = {A linear-time algorithm for trust region problems},
	volume = {158},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-015-0933-y},
	doi = {10.1007/s10107-015-0933-y},
	abstract = {We consider the fundamental problem of minimizing a general quadratic function over an ellipsoidal domain, also known as the trust region (sub)problem. We give the first provable linear-time (in the number of non-zero entries of the input) algorithm for approximately solving this problem. Specifically, our algorithm returns an \$\${\textbackslash}epsilon \$\$-approximate solution in runtime of order N/\$\${\textbackslash}sqrt\{{\textbackslash}epsilon \}\$\$, where N is the number of non-zero entries in the input. This matches the runtime of Nesterov’s accelerated gradient descent, suitable for the special case in which the quadratic objective is convex, and the runtime of the Lanczos method which is applicable when the problem is purely quadratic.},
	language = {en},
	number = {1},
	urldate = {2022-09-01},
	journal = {Mathematical Programming},
	author = {Hazan, Elad and Koren, Tomer},
	month = jul,
	year = {2016},
	keywords = {90C26, Approximation algorithms, 90C20, Semidefinite programming, 90C22, Trust region methods, 68W25, Linear time complexity, Trust region subproblem},
	pages = {363--381},
	file = {Full Text PDF:/Users/brent/Zotero/storage/TIYDNSS7/Hazan and Koren - 2016 - A linear-time algorithm for trust region problems.pdf:application/pdf},
}

@misc{cartis_evaluation_nodate,
	title = {Evaluation complexity of algorithms for nonconvex optimization},
	language = {en},
	author = {Cartis, Coralia},
	file = {Cartis - Evaluation complexity of algorithms for nonconvex .pdf:/Users/brent/Zotero/storage/6ADJTLCK/Cartis - Evaluation complexity of algorithms for nonconvex .pdf:application/pdf},
}

@article{wang_generalized_2022,
	title = {The generalized trust region subproblem: solution complexity and convex hull results},
	volume = {191},
	issn = {1436-4646},
	shorttitle = {The generalized trust region subproblem},
	url = {https://doi.org/10.1007/s10107-020-01560-8},
	doi = {10.1007/s10107-020-01560-8},
	abstract = {We consider the generalized trust region subproblem (GTRS) of minimizing a nonconvex quadratic objective over a nonconvex quadratic constraint. A lifting of this problem recasts the GTRS as minimizing a linear objective subject to two nonconvex quadratic constraints. Our first main contribution is structural: we give an explicit description of the convex hull of this nonconvex set in terms of the generalized eigenvalues of an associated matrix pencil. This result may be of interest in building relaxations for nonconvex quadratic programs. Moreover, this result allows us to reformulate the GTRS as the minimization of two convex quadratic functions in the original space. Our next set of contributions is algorithmic: we present an algorithm for solving the GTRS up to an \$\${\textbackslash}epsilon \$\$additive error based on this reformulation. We carefully handle numerical issues that arise from inexact generalized eigenvalue and eigenvector computations and establish explicit running time guarantees for these algorithms. Notably, our algorithms run in linear (in the size of the input) time. Furthermore, our algorithm for computing an \$\${\textbackslash}epsilon \$\$-optimal solution has a slightly-improved running time dependence on \$\${\textbackslash}epsilon \$\$over the state-of-the-art algorithm. Our analysis shows that the dominant cost in solving the GTRS lies in solving a generalized eigenvalue problem—establishing a natural connection between these problems. Finally, generalizations of our convex hull results allow us to apply our algorithms and their theoretical guarantees directly to equality-, interval-, and hollow-constrained variants of the GTRS. This gives the first linear-time algorithm in the literature for these variants of the GTRS.},
	language = {en},
	number = {2},
	urldate = {2022-09-01},
	journal = {Mathematical Programming},
	author = {Wang, Alex L. and Kılınç-Karzan, Fatma},
	month = feb,
	year = {2022},
	keywords = {90C26, 90C25, 65F15, 90C20, 90C22, Linear time complexity, Convex hull, Generalized trust region subproblem},
	pages = {445--486},
	file = {Full Text PDF:/Users/brent/Zotero/storage/6GDDAVMQ/Wang and Kılınç-Karzan - 2022 - The generalized trust region subproblem solution .pdf:application/pdf},
}

@article{jiang_novel_2019,
	title = {Novel {Reformulations} and {Efficient} {Algorithms} for the {Generalized} {Trust} {Region} {Subproblem}},
	volume = {29},
	issn = {1052-6234, 1095-7189},
	url = {https://epubs.siam.org/doi/10.1137/18M1174313},
	doi = {10.1137/18M1174313},
	abstract = {We present a new solution framework to solve the generalized trust region subproblem (GTRS) of minimizing a quadratic objective over a quadratic constraint. More speciﬁcally, we derive a convex quadratic reformulation (CQR) via minimizing a linear objective over two convex quadratic constraints for the GTRS. We show that an optimal solution of the GTRS can be recovered from an optimal solution of the CQR. We further prove that this CQR is equivalent to minimizing the maximum of the two convex quadratic functions derived from the CQR for the case under investigation. Although the latter minimax problem is nonsmooth, it is well structured and convex. We thus develop two steepest descent algorithms corresponding to two diﬀerent line search rules. We prove global sublinear convergence rates for both algorithms. We also obtain a local linear convergence rate of the ﬁrst algorithm by estimating the Kurdyka–Lojasiewicz exponent at any optimal solution under mild conditions. We ﬁnally demonstrate the eﬃciency of our algorithms with numerical experiments.},
	language = {en},
	number = {2},
	urldate = {2022-09-01},
	journal = {SIAM Journal on Optimization},
	author = {Jiang, Rujun and Li, Duan},
	month = jan,
	year = {2019},
	pages = {1603--1633},
	file = {Jiang and Li - 2019 - Novel Reformulations and Efficient Algorithms for .pdf:/Users/brent/Zotero/storage/XE3GWGT6/Jiang and Li - 2019 - Novel Reformulations and Efficient Algorithms for .pdf:application/pdf},
}

@article{jiang_linear-time_2020,
	title = {A {Linear}-{Time} {Algorithm} for {Generalized} {Trust} {Region} {Subproblems}},
	volume = {30},
	issn = {1052-6234, 1095-7189},
	url = {https://epubs.siam.org/doi/10.1137/18M1215165},
	doi = {10.1137/18M1215165},
	abstract = {In this paper, we provide the ﬁrst provable linear-time (in terms of the number of nonzero entries of the input) algorithm for approximately solving the generalized trust region subproblem (GTRS) of minimizing a quadratic function over a quadratic constraint under some regularity condition. Our algorithm is motivated by and extends a recent linear-time algorithm for the trust region subproblem by Hazan and Koren [Math. Program., 158 (2016), pp. 363–381]. However, due to the nonconvexity and noncompactness of the feasible region, such an extension is nontrivial. Our main contribution is to demonstrate that under some regularity condition, the optimal solution is in a compact and convex set and lower and upper bounds of the optimal value can be computed in linear time. Using these properties, we develop a linear-time algorithm for the GTRS.},
	language = {en},
	number = {1},
	urldate = {2022-09-01},
	journal = {SIAM Journal on Optimization},
	author = {Jiang, Rujun and Li, Duan},
	month = jan,
	year = {2020},
	pages = {915--932},
	file = {Jiang and Li - 2020 - A Linear-Time Algorithm for Generalized Trust Regi.pdf:/Users/brent/Zotero/storage/87KFIF6S/Jiang and Li - 2020 - A Linear-Time Algorithm for Generalized Trust Regi.pdf:application/pdf},
}

@article{brown_convergence_2006,
	title = {Convergence {Theory} of {Nonlinear} {Newton}–{Krylov} {Algorithms}},
	copyright = {Copyright © 1994 Society for Industrial and Applied Mathematics},
	url = {https://epubs.siam.org/doi/10.1137/0804017},
	doi = {10.1137/0804017},
	abstract = {This paper presents some convergence theory for nonlinear Krylov subspace methods. The basic idea of these methods, which have been described by the authors in an earlier paper, is to use variants of Newton’s iteration in conjunction with a Krylov subspace method for solving the Jacobian linear systems. These methods are variants of inexact Newton methods where the approximate Newton direction is taken from a subspace of small dimension. The main focus of this paper is to analyze these methods when they are combined with global strategies such as linesearch techniques and model trust region algorithms. Most of the convergence results are formulated for projection onto general subspaces rather than just Krylov subspaces.},
	language = {en},
	urldate = {2022-09-05},
	journal = {SIAM Journal on Optimization},
	author = {Brown, Peter N. and Saad, Youcef},
	month = jul,
	year = {2006},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	file = {Brown and Saad - 2006 - Convergence Theory of Nonlinear Newton–Krylov Algo.pdf:/Users/brent/Zotero/storage/MBPEB6GP/Brown and Saad - 2006 - Convergence Theory of Nonlinear Newton–Krylov Algo.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/9GB54DH7/0804017.html:text/html},
}

@article{bindel_continuation_2008,
	title = {Continuation of {Invariant} {Subspaces} in {Large} {Bifurcation} {Problems}},
	volume = {30},
	issn = {1064-8275},
	url = {https://epubs.siam.org/doi/abs/10.1137/060654219},
	doi = {10.1137/060654219},
	abstract = {We summarize an algorithm for computing a smooth orthonormal basis for an invariant subspace of a parameter-dependent matrix, and describe how to extend it for numerical bifurcation analysis. We adapt the continued subspace to track behavior relevant to bifurcations, and use projection methods to deal with large problems. To test our ideas, we have integrated our code into MATCONT, a program for numerical continuation and bifurcation analysis.},
	number = {2},
	urldate = {2022-09-05},
	journal = {SIAM Journal on Scientific Computing},
	author = {Bindel, David and Demmel, James and Friedman, Mark},
	month = jan,
	year = {2008},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {65F15, 37M20, 65F50, 65H20, bifurcation analysis, continuation, invariant subspaces, Ritz-Galerkin methods, smooth eigendecompositions},
	pages = {637--656},
	file = {Full Text PDF:/Users/brent/Zotero/storage/3TLJ6YYP/Bindel et al. - 2008 - Continuation of Invariant Subspaces in Large Bifur.pdf:application/pdf},
}

@inproceedings{dieci_path_2006,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Path {Following} by {SVD}},
	isbn = {978-3-540-34386-8},
	doi = {10.1007/11758549_92},
	abstract = {In this paper, we propose a path-following method for computing a curve of equilibria of a dynamical system, based upon the smooth Singular Value Decomposition (SVD) of the Jacobian matrix. Our method is capable of detecting fold points, and continuing past folds. It is also able to detect branch points and to switch branches at such points. Algorithmic details and examples are given.},
	language = {en},
	booktitle = {Computational {Science} – {ICCS} 2006},
	publisher = {Springer},
	author = {Dieci, Luca and Gasparo, Maria Grazia and Papini, Alessandra},
	editor = {Alexandrov, Vassil N. and van Albada, Geert Dick and Sloot, Peter M. A. and Dongarra, Jack},
	year = {2006},
	keywords = {65F99, 65F15},
	pages = {677--684},
	file = {Full Text PDF:/Users/brent/Zotero/storage/JVFN9RZI/Dieci et al. - 2006 - Path Following by SVD.pdf:application/pdf},
}

@incollection{van_vleck_continuous_2015,
	address = {Cham},
	title = {Continuous {Matrix} {Factorizations}},
	isbn = {978-3-319-15260-8},
	url = {https://doi.org/10.1007/978-3-319-15260-8_11},
	abstract = {Continuous matrix factorizations show great promise in a number of contexts. In this chapter we survey results on continuous matrix factorizations paying particular attention to smooth matrix factorizations of fundamental matrix solutions of linear differential equations and differential-algebraic equations with special emphasis on smooth QR and smooth SVD.},
	language = {en},
	urldate = {2022-09-05},
	booktitle = {Numerical {Algebra}, {Matrix} {Theory}, {Differential}-{Algebraic} {Equations} and {Control} {Theory}: {Festschrift} in {Honor} of {Volker} {Mehrmann}},
	publisher = {Springer International Publishing},
	author = {Van Vleck, Erik S.},
	editor = {Benner, Peter and Bollhöfer, Matthias and Kressner, Daniel and Mehl, Christian and Stykel, Tatjana},
	year = {2015},
	doi = {10.1007/978-3-319-15260-8_11},
	keywords = {Exponential Dichotomy, Fundamental Matrix Solution, Lyapunov Exponent, Matrix Function, Singular Value Decomposition},
	pages = {299--318},
	file = {Full Text PDF:/Users/brent/Zotero/storage/3E88VJ3N/Van Vleck - 2015 - Continuous Matrix Factorizations.pdf:application/pdf},
}

@article{dieci_continuation_2001,
	title = {Continuation of invariant subspaces},
	volume = {8},
	number = {5},
	journal = {Numerical Linear Algebra with Applications},
	author = {Dieci, Luca and Friedman, Mark J.},
	year = {2001},
	pages = {317--327},
	file = {Full Text:/Users/brent/Zotero/storage/Y26U2PRQ/Dieci and Friedman - 2001 - Continuation of invariant subspaces.pdf:application/pdf},
}

@article{carmon_analysis_2018,
	title = {Analysis of {Krylov} subspace solutions of regularized non-convex quadratic problems},
	volume = {31},
	journal = {Advances in Neural Information Processing Systems},
	author = {Carmon, Yair and Duchi, John C.},
	year = {2018},
	file = {Full Text:/Users/brent/Zotero/storage/LYUHWT7W/Carmon and Duchi - 2018 - Analysis of Krylov subspace solutions of regulariz.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/KAZTEX5I/349f36aa789af083b8e26839bd498af9-Abstract.html:text/html},
}

@article{bianconcini_use_2015,
	title = {On the use of iterative methods in cubic regularization for unconstrained optimization},
	volume = {60},
	issn = {1573-2894},
	url = {https://doi.org/10.1007/s10589-014-9672-x},
	doi = {10.1007/s10589-014-9672-x},
	abstract = {In this paper we consider the problem of minimizing a smooth function by using the adaptive cubic regularized (ARC) framework. We focus on the computation of the trial step as a suitable approximate minimizer of the cubic model and discuss the use of matrix-free iterative methods. Our approach is alternative to the implementation proposed in the original version of ARC, involving a linear algebra phase, but preserves the same worst-case complexity count. Further we introduce a new stopping criterion in order to properly manage the “over-solving” issue arising whenever the cubic model is not an adequate model of the true objective function. Numerical experiments conducted by using a nonmonotone gradient method as inexact solver are presented. The obtained results clearly show the effectiveness of the new variant of ARC algorithm.},
	language = {en},
	number = {1},
	urldate = {2022-09-05},
	journal = {Computational Optimization and Applications},
	author = {Bianconcini, Tommaso and Liuzzi, Giampaolo and Morini, Benedetta and Sciandrone, Marco},
	month = jan,
	year = {2015},
	keywords = {Worst-case complexity, Cubic regularization, Unconstrained optimization, Matrix-free subproblem solvers},
	pages = {35--57},
	file = {Full Text PDF:/Users/brent/Zotero/storage/Q3EMQ846/Bianconcini et al. - 2015 - On the use of iterative methods in cubic regulariz.pdf:application/pdf},
}

@article{byrd_stochastic_2016,
	title = {A {Stochastic} {Quasi}-{Newton} {Method} for {Large}-{Scale} {Optimization}},
	volume = {26},
	issn = {1052-6234},
	url = {https://epubs.siam.org/doi/abs/10.1137/140954362},
	doi = {10.1137/140954362},
	abstract = {The question of how to incorporate curvature information into stochastic approximation methods is challenging. The direct application of classical quasi-Newton updating techniques for deterministic optimization leads to noisy curvature estimates that have harmful effects on the robustness of the iteration. In this paper, we propose a stochastic quasi-Newton method that is efficient, robust, and scalable. It employs the classical BFGS update formula in its limited memory form, and is based on the observation that it is beneficial to collect curvature information pointwise, and at spaced intervals. One way to do this is through (subsampled) Hessian-vector products. This technique differs from the classical approach that would compute differences of gradients at every iteration, and where controlling the quality of the curvature estimates can be difficult. We present numerical results on problems arising in machine learning that suggest that the proposed method shows much promise.},
	number = {2},
	urldate = {2022-09-05},
	journal = {SIAM Journal on Optimization},
	author = {Byrd, R. H. and Hansen, S. L. and Nocedal, Jorge and Singer, Y.},
	month = jan,
	year = {2016},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {90C30, 65K05, 90C06, stochastic optimization, 90C55, large scale optimization, quasi-Newton, sub sampling},
	pages = {1008--1031},
	file = {Full Text PDF:/Users/brent/Zotero/storage/CAQD5DQU/Byrd et al. - 2016 - A Stochastic Quasi-Newton Method for Large-Scale O.pdf:application/pdf},
}

@inproceedings{beyn_continuation_2001,
	address = {Berlin, Heidelberg},
	title = {Continuation of {Low}-{Dimensional} {Invariant} {Subspaces} in {Dynamical} {Systems} of {Large} {Dimension}},
	isbn = {978-3-642-56589-2},
	doi = {10.1007/978-3-642-56589-2_3},
	abstract = {We present a continuation method for low-dimensional invariant subspaces of a parameterized family of large and sparse real matrices. Such matrices typically occur when linearizing about branches of steady states in dynamical systems that are obtained by spatial discretization of time-dependent PDE’s. The main interest is in subspaces that belong to spectral sets close the imaginary axis. Our continuation procedure provides bases of the invariant subspaces that depend smoothly on the parameter as long as the continued spectral subset does not collide with another eigenvalue. Generalizing results from [32] we show that this collision generically occurs when a real eigenvalue from the continued spectral set meets another eigenvalue from outside to form a complex conjugate pair. Such a situation relates to a turning point of the subspace problem and and we develop a method to inflate the subspace at such points.},
	language = {en},
	booktitle = {Ergodic {Theory}, {Analysis}, and {Efficient} {Simulation} of {Dynamical} {Systems}},
	publisher = {Springer},
	author = {Beyn, Wolf-Jürgen and Kleß, Winfried and Thümmler, Vera},
	editor = {Fiedler, Bernold},
	year = {2001},
	keywords = {Essential Spectrum, Invariant Manifold, Invariant Subspace, Real Eigenvalue, Turning Point},
	pages = {47--72},
	file = {Full Text PDF:/Users/brent/Zotero/storage/2UFKKR76/Beyn et al. - 2001 - Continuation of Low-Dimensional Invariant Subspace.pdf:application/pdf},
}

@article{lan_bundle-level_2015,
	title = {Bundle-level type methods uniformly optimal for smooth and nonsmooth convex optimization},
	volume = {149},
	number = {1},
	journal = {Mathematical Programming},
	author = {Lan, Guanghui},
	year = {2015},
	note = {Publisher: Springer},
	keywords = {90C25, 90C15, 68Q25, Complexity, 62L20, Bundle-level, Convex programming, Optimal methods},
	pages = {1--45},
	file = {Full Text:/Users/brent/Zotero/storage/B4K28H2V/s10107-013-0737-x.html:text/html;Full Text PDF:/Users/brent/Zotero/storage/NE2SRCZP/Lan - 2015 - Bundle-level type methods uniformly optimal for sm.pdf:application/pdf},
}

@misc{carmon_complexity_nodate,
	title = {The complexity of ﬁnding stationary points of nonconvex functions},
	language = {en},
	author = {Carmon, Yair and Duchi, John and Sidford, Aaron},
	file = {Carmon et al. - The complexity of ﬁnding stationary points of nonc.pdf:/Users/brent/Zotero/storage/AI6AMTC7/Carmon et al. - The complexity of ﬁnding stationary points of nonc.pdf:application/pdf},
}

@article{haeser_optimality_2019,
	title = {Optimality condition and complexity analysis for linearly-constrained optimization without differentiability on the boundary},
	volume = {178},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-018-1290-4},
	doi = {10.1007/s10107-018-1290-4},
	abstract = {In this paper we consider the minimization of a continuous function that is potentially not differentiable or not twice differentiable on the boundary of the feasible region. By exploiting an interior point technique, we present first- and second-order optimality conditions for this problem that reduces to classical ones when the derivative on the boundary is available. For this type of problems, existing necessary conditions often rely on the notion of subdifferential or become non-trivially weaker than the KKT condition in the (twice-)differentiable counterpart problems. In contrast, this paper presents a new set of first- and second-order necessary conditions that are derived without the use of subdifferential and reduce to exactly the KKT condition when (twice-)differentiability holds. As a result, these conditions are stronger than some existing ones considered for the discussed minimization problem when only non-negativity constraints are present. To solve for these optimality conditions in the special but important case of linearly constrained problems, we present two novel interior point trust-region algorithms and show that their worst-case computational efficiency in achieving the potentially stronger optimality conditions match the best known complexity bounds. Since this work considers a more general problem than those in the literature, our results also indicate that best known existing complexity bounds are actually held for a wider class of nonlinear programming problems. This new development is significant since optimality conditions play a fundamental role in computational optimization and more and more nonlinear and nonconvex problems need to be solved in practice.},
	language = {en},
	number = {1},
	urldate = {2022-09-16},
	journal = {Mathematical Programming},
	author = {Haeser, Gabriel and Liu, Hongcheng and Ye, Yinyu},
	month = nov,
	year = {2019},
	keywords = {Nonconvex programming, 90C30, 68Q25, 90C60, 90C51, Constrained optimization, First order algorithm, Interior point method, Nonsmooth problems},
	pages = {263--299},
	file = {Full Text PDF:/Users/brent/Zotero/storage/IYJPSWMX/Haeser et al. - 2019 - Optimality condition and complexity analysis for l.pdf:application/pdf},
}

@article{bian_complexity_2015,
	title = {Complexity analysis of interior point algorithms for non-{Lipschitz} and nonconvex minimization},
	volume = {149},
	number = {1},
	journal = {Mathematical Programming},
	author = {Bian, Wei and Chen, Xiaojun and Ye, Yinyu},
	year = {2015},
	note = {Publisher: Springer},
	pages = {301--327},
	file = {Full Text:/Users/brent/Zotero/storage/A2VKZ2CQ/Bian et al. - 2015 - Complexity analysis of interior point algorithms f.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/IZHIKTZB/s10107-014-0753-5.html:text/html},
}

@article{ge_improved_2017,
	title = {An improved algorithm for the {$L_2-L_p$} minimization problem},
	volume = {166},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-016-1107-2},
	doi = {10.1007/s10107-016-1107-2},
	abstract = {In this paper we consider a class of non-Lipschitz and non-convex minimization problems which generalize the \$\$L\_2\$\$–\$\$L\_p\$\$minimization problem. We propose an iterative algorithm that decides the next iteration based on the local convexity/concavity/sparsity of its current position. We show that our algorithm finds an \$\${\textbackslash}epsilon \$\$-KKT point within \$\$O({\textbackslash}log \{{\textbackslash}epsilon {\textasciicircum}\{-1\}\})\$\$iterations from certain initial points. The same result is also applied to the problem with general linear constraints under mild conditions.},
	language = {en},
	number = {1},
	urldate = {2022-09-16},
	journal = {Mathematical Programming},
	author = {Ge, Dongdong and He, Rongchuan and He, Simai},
	month = nov,
	year = {2017},
	keywords = {49M37, 90C26, 90C30, 65K05, Nonconvex optimization, Bridge regression, Complexity analysis, Nonsmooth optimization},
	pages = {131--158},
	file = {Full Text PDF:/Users/brent/Zotero/storage/GG9MJ7HI/Ge et al. - 2017 - An improved algorithm for the \$\$L_2\$\$–\$\$L_p\$\$minim.pdf:application/pdf},
}

@misc{carmon_convex_2017,
	title = {"{Convex} {Until} {Proven} {Guilty}": {Dimension}-{Free} {Acceleration} of {Gradient} {Descent} on {Non}-{Convex} {Functions}},
	shorttitle = {"{Convex} {Until} {Proven} {Guilty}"},
	url = {http://arxiv.org/abs/1705.02766},
	doi = {10.48550/arXiv.1705.02766},
	abstract = {We develop and analyze a variant of Nesterov's accelerated gradient descent (AGD) for minimization of smooth non-convex functions. We prove that one of two cases occurs: either our AGD variant converges quickly, as if the function was convex, or we produce a certificate that the function is "guilty" of being non-convex. This non-convexity certificate allows us to exploit negative curvature and obtain deterministic, dimension-free acceleration of convergence for non-convex functions. For a function \$f\$ with Lipschitz continuous gradient and Hessian, we compute a point \$x\$ with \${\textbackslash}{\textbar}{\textbackslash}nabla f(x){\textbackslash}{\textbar} {\textbackslash}le {\textbackslash}epsilon\$ in \$O({\textbackslash}epsilon{\textasciicircum}\{-7/4\} {\textbackslash}log(1/ {\textbackslash}epsilon) )\$ gradient and function evaluations. Assuming additionally that the third derivative is Lipschitz, we require only \$O({\textbackslash}epsilon{\textasciicircum}\{-5/3\} {\textbackslash}log(1/ {\textbackslash}epsilon) )\$ evaluations.},
	urldate = {2022-09-16},
	publisher = {arXiv},
	author = {Carmon, Yair and Hinder, Oliver and Duchi, John C. and Sidford, Aaron},
	month = may,
	year = {2017},
	note = {arXiv:1705.02766 [math]},
	keywords = {Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/8WBUTKFN/Carmon et al. - 2017 - Convex Until Proven Guilty Dimension-Free Accel.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/XNB9ASJV/1705.html:text/html},
}

@article{cartis_scalable_2022,
	title = {Scalable subspace methods for derivative-free nonlinear least-squares optimization},
	issn = {0025-5610, 1436-4646},
	url = {https://link.springer.com/10.1007/s10107-022-01836-1},
	doi = {10.1007/s10107-022-01836-1},
	abstract = {We introduce a general framework for large-scale model-based derivative-free optimization based on iterative minimization within random subspaces. We present a probabilistic worst-case complexity analysis for our method, where in particular we prove high-probability bounds on the number of iterations before a given optimality is achieved. This framework is specialized to nonlinear least-squares problems, with a model-based framework based on the Gauss–Newton method. This method achieves scalability by constructing local linear interpolation models to approximate the Jacobian, and computes new steps at each iteration in a subspace with user-determined dimension. We then describe a practical implementation of this framework, which we call DFBGN. We outline efﬁcient techniques for selecting the interpolation points and search subspace, yielding an implementation that has a low per-iteration linear algebra cost (linear in the problem dimension) while also achieving fast objective decrease as measured by evaluations. Extensive numerical results demonstrate that DFBGN has improved scalability, yielding strong performance on large-scale nonlinear leastsquares problems.},
	language = {en},
	urldate = {2022-09-17},
	journal = {Mathematical Programming},
	author = {Cartis, Coralia and Roberts, Lindon},
	month = jun,
	year = {2022},
	file = {Cartis and Roberts - 2022 - Scalable subspace methods for derivative-free nonl.pdf:/Users/brent/Zotero/storage/4IYT7XW3/Cartis and Roberts - 2022 - Scalable subspace methods for derivative-free nonl.pdf:application/pdf},
}

@article{yuan_subspace_1995,
	title = {A subspace study on conjugate gradient algorithms},
	volume = {75},
	number = {1},
	journal = {ZAMM-Journal of Applied Mathematics and Mechanics/Zeitschrift für Angewandte Mathematik und Mechanik},
	author = {Yuan, Y.-X. and Stoer, J.},
	year = {1995},
	note = {Publisher: Wiley Online Library},
	pages = {69--77},
	file = {Snapshot:/Users/brent/Zotero/storage/BYT2Z5RA/zamm.html:text/html;Yuan and Stoer - 1995 - A subspace study on conjugate gradient algorithms.pdf:/Users/brent/Zotero/storage/BJI7DKQV/Yuan and Stoer - 1995 - A subspace study on conjugate gradient algorithms.pdf:application/pdf},
}

@inproceedings{yuan_review_2014,
	title = {A review on subspace methods for nonlinear optimization},
	booktitle = {Proceedings of the {International} {Congress} of {Mathematics}},
	author = {Yuan, Ya-xiang},
	year = {2014},
	pages = {807--827},
	file = {Yuan - A review on subspace methods for nonlinear optimiz.pdf:/Users/brent/Zotero/storage/UMRR3HWC/Yuan - A review on subspace methods for nonlinear optimiz.pdf:application/pdf},
}

@article{liu_subspace_nodate,
	title = {Subspace {Methods} for {Nonlinear} {Optimization}},
	author = {Liu, Xin and Wen, Zaiwen and Yuan, Yaxiang},
	file = {Liu et al. - Subspace Methods for Nonlinear Optimization.pdf:/Users/brent/Zotero/storage/IBW362MM/Liu et al. - Subspace Methods for Nonlinear Optimization.pdf:application/pdf},
}

@inproceedings{nesterov_method_1983,
	title = {A method for solving the convex programming problem with convergence rate {O} (1/k{\textasciicircum} 2)},
	volume = {269},
	booktitle = {Dokl. akad. nauk {Sssr}},
	author = {Nesterov, Yurii E.},
	year = {1983},
	pages = {543--547},
}

@article{dennis_quasi-newton_1977,
	title = {Quasi-{Newton} methods, motivation and theory},
	volume = {19},
	number = {1},
	journal = {SIAM review},
	author = {Dennis, John E. and Moré, Jorge J.},
	year = {1977},
	note = {Publisher: SIAM},
	pages = {46--89},
	file = {Full Text:/Users/brent/Zotero/storage/EPDSK5EC/Dennis and Moré - 1977 - Quasi-Newton methods, motivation and theory.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/DCMNMMD9/1019005.html:text/html},
}

@inproceedings{peng_solving_2021,
	title = {Solving sparse linear systems faster than matrix multiplication},
	booktitle = {Proceedings of the 2021 {ACM}-{SIAM} {Symposium} on {Discrete} {Algorithms} ({SODA})},
	publisher = {SIAM},
	author = {Peng, Richard and Vempala, Santosh},
	year = {2021},
	pages = {504--521},
	file = {Full Text:/Users/brent/Zotero/storage/6386BJQQ/Peng and Vempala - 2021 - Solving sparse linear systems faster than matrix m.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/UT4T44II/1.9781611976465.html:text/html},
}

@article{luksan_bundle-newton_1998,
	title = {A bundle-{Newton} method for nonsmooth unconstrained minimization},
	volume = {83},
	number = {1},
	journal = {Mathematical Programming},
	author = {Lukšan, Ladislav and Vlček, Jan},
	year = {1998},
	note = {Publisher: Springer},
	pages = {373--391},
	file = {BF02680566.pdf:/Users/brent/Zotero/storage/NGBHLJS8/BF02680566.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/3FR6CLQE/BF02680566.html:text/html},
}

@article{dang_linearly_2013,
	title = {Linearly {Convergent} {First}-{Order} {Algorithms} for {Semi}-definite {Programming}},
	journal = {arXiv preprint arXiv:1309.2251},
	author = {Dang, Cong D. and Lan, Guanghui},
	year = {2013},
	file = {Full Text:/Users/brent/Zotero/storage/UMP99B29/Dang and Lan - 2013 - Linearly Convergent First-Order Algorithms for Sem.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/PEDLSFUU/1309.html:text/html},
}

@article{mifflin_quasi-newton_1998,
	title = {Quasi-{Newton} {Bundle}-{Type} {Methods} for {Nondifferentiable} {Convex} {Optimization}},
	volume = {8},
	issn = {1052-6234, 1095-7189},
	url = {http://epubs.siam.org/doi/10.1137/S1052623496303329},
	doi = {10.1137/S1052623496303329},
	abstract = {In this paper we provide implementable methods for solving nondiﬀerentiable convex optimization problems. A typical method minimizes an approximate Moreau–Yosida regularization using a quasi-Newton technique with inexact function and gradient values which are generated by a ﬁnite inner bundle algorithm. For a BFGS bundle-type method global and superlinear convergence results for the outer iteration sequence are obtained.},
	language = {en},
	number = {2},
	urldate = {2022-09-26},
	journal = {SIAM Journal on Optimization},
	author = {Mifflin, Robert and Sun, Defeng and Qi, Liqun},
	month = may,
	year = {1998},
	pages = {583--603},
	file = {Mifflin et al. - 1998 - Quasi-Newton Bundle-Type Methods for Nondifferenti.pdf:/Users/brent/Zotero/storage/2AEJLXQ8/Mifflin et al. - 1998 - Quasi-Newton Bundle-Type Methods for Nondifferenti.pdf:application/pdf},
}

@article{karimi_relationship_2014,
	title = {On the relationship between conjugate gradient and optimal first-order methods for convex optimization},
	author = {Karimi, Sahar},
	year = {2014},
	note = {Publisher: University of Waterloo},
	file = {Full Text:/Users/brent/Zotero/storage/LWN7GN5K/Karimi - 2014 - On the relationship between conjugate gradient and.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/R3YIU4AK/8189.html:text/html},
}

@misc{carmon_lower_2019,
	title = {Lower {Bounds} for {Finding} {Stationary} {Points} {I}},
	url = {http://arxiv.org/abs/1710.11606},
	doi = {10.48550/arXiv.1710.11606},
	abstract = {We prove lower bounds on the complexity of finding \${\textbackslash}epsilon\$-stationary points (points \$x\$ such that \${\textbackslash}{\textbar}{\textbackslash}nabla f(x){\textbackslash}{\textbar} {\textbackslash}le {\textbackslash}epsilon\$) of smooth, high-dimensional, and potentially non-convex functions \$f\$. We consider oracle-based complexity measures, where an algorithm is given access to the value and all derivatives of \$f\$ at a query point \$x\$. We show that for any (potentially randomized) algorithm \${\textbackslash}mathsf\{A\}\$, there exists a function \$f\$ with Lipschitz \$p\$th order derivatives such that \${\textbackslash}mathsf\{A\}\$ requires at least \${\textbackslash}epsilon{\textasciicircum}\{-(p+1)/p\}\$ queries to find an \${\textbackslash}epsilon\$-stationary point. Our lower bounds are sharp to within constants, and they show that gradient descent, cubic-regularized Newton's method, and generalized \$p\$th order regularization are worst-case optimal within their natural function classes.},
	urldate = {2022-10-09},
	publisher = {arXiv},
	author = {Carmon, Yair and Duchi, John C. and Hinder, Oliver and Sidford, Aaron},
	month = aug,
	year = {2019},
	note = {arXiv:1710.11606 [math]},
	keywords = {Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/G6EUHXJQ/Carmon et al. - 2019 - Lower Bounds for Finding Stationary Points I.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/QLIWWW7H/1710.html:text/html},
}

@misc{carmon_lower_2017,
	title = {Lower {Bounds} for {Finding} {Stationary} {Points} {II}: {First}-{Order} {Methods}},
	shorttitle = {Lower {Bounds} for {Finding} {Stationary} {Points} {II}},
	url = {http://arxiv.org/abs/1711.00841},
	doi = {10.48550/arXiv.1711.00841},
	abstract = {We establish lower bounds on the complexity of finding \${\textbackslash}epsilon\$-stationary points of smooth, non-convex high-dimensional functions using first-order methods. We prove that deterministic first-order methods, even applied to arbitrarily smooth functions, cannot achieve convergence rates in \${\textbackslash}epsilon\$ better than \${\textbackslash}epsilon{\textasciicircum}\{-8/5\}\$, which is within \${\textbackslash}epsilon{\textasciicircum}\{-1/15\}{\textbackslash}log{\textbackslash}frac\{1\}\{{\textbackslash}epsilon\}\$ of the best known rate for such methods. Moreover, for functions with Lipschitz first and second derivatives, we prove no deterministic first-order method can achieve convergence rates better than \${\textbackslash}epsilon{\textasciicircum}\{-12/7\}\$, while \${\textbackslash}epsilon{\textasciicircum}\{-2\}\$ is a lower bound for functions with only Lipschitz gradient. For convex functions with Lipschitz gradient, accelerated gradient descent achieves the rate \${\textbackslash}epsilon{\textasciicircum}\{-1\}{\textbackslash}log{\textbackslash}frac\{1\}\{{\textbackslash}epsilon\}\$, showing that finding stationary points is easier given convexity.},
	urldate = {2022-10-09},
	publisher = {arXiv},
	author = {Carmon, Yair and Duchi, John C. and Hinder, Oliver and Sidford, Aaron},
	month = nov,
	year = {2017},
	note = {arXiv:1711.00841 [math]},
	keywords = {Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/I9HKV4YA/Carmon et al. - 2017 - Lower Bounds for Finding Stationary Points II Fir.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/9KTF9E8B/1711.html:text/html},
}

@book{lattimore_bandit_2020,
	edition = {1},
	title = {Bandit {Algorithms}},
	isbn = {978-1-108-57140-1 978-1-108-48682-8},
	url = {https://www.cambridge.org/core/product/identifier/9781108571401/type/book},
	language = {en},
	urldate = {2022-10-08},
	publisher = {Cambridge University Press},
	author = {Lattimore, Tor and Szepesvári, Csaba},
	month = jul,
	year = {2020},
	doi = {10.1017/9781108571401},
	file = {Lattimore and Szepesvári - 2020 - Bandit Algorithms.pdf:/Users/brent/Zotero/storage/TZFANWSC/Lattimore and Szepesvári - 2020 - Bandit Algorithms.pdf:application/pdf},
}

@article{kuczynski_estimating_1992,
	title = {Estimating the {Largest} {Eigenvalue} by the {Power} and {Lanczos} {Algorithms} with a {Random} {Start}},
	volume = {13},
	issn = {0895-4798, 1095-7162},
	url = {http://epubs.siam.org/doi/10.1137/0613066},
	doi = {10.1137/0613066},
	abstract = {Abstract. This paper addresses the problem of computing an approximation to the largest eigenvalue of an n n large symmetric positive definite matrix with relative error at most e. Only algorithms that use Krylov information b, Ab, A kb] consisting of k matrix-vector multiplications for some unit vector b are considered. If the vector b is chosen deterministically, then the problem cannot be solved no matter how many matrixvector multiplications are performed and what algorithm is used. If, however, the vector b is chosen randomly with respect to the uniform distribution over the unit sphere, then the problem can be solved on the average and probabilistically. More precisely, for a randomly chosen vector b, the power and Lanczos algorithms are studied. For the power algorithm (method), sharp bounds on the average relative error and on the probabilistic relative failure are proven. For the Lanczos algorithm only upper bounds are presented. In particular, In (n)/k characterizes the average relative error of the power algorithm, whereas O((ln (n)/k)a) is an upper bound on the average relative error of the Lanczos algorithm. In the probabilistic case, the algorithm is characterized by its probabilistic relative failure, which is defined as the measure of the set of vectors b for which the algorithm V fails. It is shown that the probabilistic relative failure goes to zero roughly as e)k for the power algorithm and at most as fe-tak-) for the Lanczos algorithm. These bounds are for a worst case distribution of eigenvalues which may depend on k. The behavior in the average and probabilistic cases of the two algorithms for a fixed matrix A is also studied as the number of matrix-vector multiplications k increases. The bounds for the power algorithm depend then on the ratio of the two largest eigenvalues and their multiplicities. The bounds for the Lanczos algorithm depend on the ratio between the difference of the two largest eigenvalues and the difference of the largest and the smallest eigenvalues.},
	language = {en},
	number = {4},
	urldate = {2022-10-13},
	journal = {SIAM Journal on Matrix Analysis and Applications},
	author = {Kuczyński, J. and Woźniakowski, H.},
	month = oct,
	year = {1992},
	pages = {1094--1122},
	file = {Kuczyński and Woźniakowski - 1992 - Estimating the Largest Eigenvalue by the Power and.pdf:/Users/brent/Zotero/storage/XA5WJE8I/Kuczyński and Woźniakowski - 1992 - Estimating the Largest Eigenvalue by the Power and.pdf:application/pdf},
}

@article{li_restarted_nodate,
	title = {Restarted {Nonconvex} {Accelerated} {Gradient} {Descent}: {No} {More} {Polylogarithmic} {Factor} in the {O}(ϵ−7/4) {Complexity}},
	language = {en},
	author = {Li, Huan and Lin, Zhouchen},
	pages = {16},
	file = {Li and Lin - Restarted Nonconvex Accelerated Gradient Descent .pdf:/Users/brent/Zotero/storage/W2F9GM3V/Li and Lin - Restarted Nonconvex Accelerated Gradient Descent .pdf:application/pdf},
}

@article{carmon_first-order_2020,
	title = {First-{Order} {Methods} for {Nonconvex} {Quadratic} {Minimization}},
	volume = {62},
	issn = {0036-1445, 1095-7200},
	url = {https://epubs.siam.org/doi/10.1137/20M1321759},
	doi = {10.1137/20M1321759},
	abstract = {We consider minimization of indefinite quadratics with either trust-region (norm) constraints or cubic regularization. Despite the nonconvexity of these problems we prove that, under mild assumptions, gradient descent converges to their global solutions and give a nonasymptotic rate of convergence for the cubic variant. We also consider Krylov subspace solutions and establish sharp convergence guarantees to the solutions of both trust-region and cubic-regularized problems. Our rates mirror the behavior of these methods on convex quadratics and eigenvector problems, highlighting their scalability. When we use Krylov subspace solutions to approximate the cubic-regularized Newton step, our results recover the strongest known convergence guarantees to approximate second-order stationary points of general smooth nonconvex functions.},
	language = {en},
	number = {2},
	urldate = {2022-10-17},
	journal = {SIAM Review},
	author = {Carmon, Yair and Duchi, John C.},
	month = jan,
	year = {2020},
	pages = {395--436},
	file = {Carmon and Duchi - 2020 - First-Order Methods for Nonconvex Quadratic Minimi.pdf:/Users/brent/Zotero/storage/57V3QA4D/Carmon and Duchi - 2020 - First-Order Methods for Nonconvex Quadratic Minimi.pdf:application/pdf},
}

@article{sorensen_minimization_1997,
	title = {Minimization of a {Large}-{Scale} {Quadratic} {Function} {Subject} to a {Spherical} {Constraint}},
	volume = {7},
	issn = {1052-6234, 1095-7189},
	url = {http://epubs.siam.org/doi/10.1137/S1052623494274374},
	doi = {10.1137/S1052623494274374},
	abstract = {An important problem in linear algebra and optimization is the trust-region subproblem: minimize a quadratic function subject to an ellipsoidal or spherical constraint. This basic problem has several important large-scale applications including seismic inversion and forcing convergence in optimization methods. Existing methods to solve the trust-region subproblem require matrix factorizations, which are not feasible in the large-scale setting. This paper presents an algorithm for solving the large-scale trust-region subproblem that requires a ﬁxed-size limited storage proportional to the order of the quadratic and that relies only on matrix-vector products. The algorithm recasts the trust-region subproblem in terms of a parameterized eigenvalue problem and adjusts the parameter with a superlinearly convergent iteration to ﬁnd the optimal solution from the eigenvector of the parameterized problem. Only the smallest eigenvalue and corresponding eigenvector of the parameterized problem needs to be computed. The implicitly restarted Lanczos method is well suited to this subproblem.},
	language = {en},
	number = {1},
	urldate = {2022-10-23},
	journal = {SIAM Journal on Optimization},
	author = {Sorensen, D. C.},
	month = feb,
	year = {1997},
	pages = {141--161},
	file = {Sorensen - 1997 - Minimization of a Large-Scale Quadratic FunctionSu.pdf:/Users/brent/Zotero/storage/3BAW36MK/Sorensen - 1997 - Minimization of a Large-Scale Quadratic FunctionSu.pdf:application/pdf},
}

@article{rojas_new_2001,
	title = {A {New} {Matrix}-{Free} {Algorithm} for the {Large}-{Scale} {Trust}-{Region} {Subproblem}},
	volume = {11},
	issn = {1052-6234},
	url = {https://epubs.siam.org/doi/abs/10.1137/S105262349928887X},
	doi = {10.1137/S105262349928887X},
	abstract = {We present a new method for the large-scale trust-region subproblem. The method is matrix-free in the sense that only matrix-vector products are required. We recast the trust-region subproblem as a parameterized eigenvalue problem and compute an optimal value for the parameter. We then find the solution of the trust-region subproblem from the eigenvectors associated with two of the smallest eigenvalues of the parameterized eigenvalue problem corresponding to the optimal parameter. The new algorithm uses a different interpolating scheme than existing methods and introduces a unified iteration that naturally includes the so-called hard case. We show that the new iteration is well defined and convergent at a superlinear rate. We present computational results to illustrate convergence properties and robustness of the method.},
	number = {3},
	urldate = {2022-10-23},
	journal = {SIAM Journal on Optimization},
	author = {Rojas, Marielba and Santos, Sandra A. and Sorensen, Danny C.},
	month = jan,
	year = {2001},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {65F15, trust region, 65G05, constrained quadratic optimization, Lanczos method, regularization},
	pages = {611--646},
	file = {Rojas et al. - 2001 - A New Matrix-Free Algorithm for the Large-Scale Tr.pdf:/Users/brent/Zotero/storage/X4EZF45D/Rojas et al. - 2001 - A New Matrix-Free Algorithm for the Large-Scale Tr.pdf:application/pdf},
}

@misc{zhu_how_2022,
	title = {How {Small} {Amount} of {Data} {Sharing} {Benefits} {Distributed} {Optimization} and {Learning}},
	url = {http://arxiv.org/abs/2208.09735},
	doi = {10.48550/arXiv.2208.09735},
	abstract = {While distributed optimization algorithms have the merits in parallel processing and protecting local data security, they often suffer from slow convergence compared with centralized optimization algorithms. This paper focuses on how small amount of data sharing could benefit distributed optimization and learning for more advanced optimization algorithms. Specifically, we consider how data sharing could benefit distributed multi-block alternating direction method of multipliers (ADMM) and preconditioned conjugate gradient method (PCG) with application in machine learning tasks of linear and logistic regression. These algorithms are commonly known as algorithms between the first and the second order methods, and we show that data sharing could hugely boost the convergence speed for this class of the algorithms. Theoretically, we prove that a small amount of data share leads to improvements from near-worst to near-optimal convergence rate when applying ADMM and PCG methods to machine learning tasks. We further propose a meta randomized data-sharing scheme and provide its tailored applications in multi-block ADMM and PCG methods in order to enjoy both the benefit from data-sharing and from the efficiency of distributed computing. From the numerical evidences, we are convinced that our algorithms provide good quality of estimators in both the least square and the logistic regressions within much fewer iterations by only sharing 5\% of pre-fixed data, while purely distributed optimization algorithms may take hundreds more times of iterations to converge. We hope that the discovery resulted from this paper would encourage even small amount of data sharing among different regions to combat difficult global learning problems.},
	urldate = {2022-10-24},
	publisher = {arXiv},
	author = {Zhu, Mingxi and Ye, Yinyu},
	month = aug,
	year = {2022},
	note = {arXiv:2208.09735 [math]},
	keywords = {Mathematics - Optimization and Control, 90C06 (Primary), 90C25, 68U04 (Secondary)},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/XGTZDJ24/Zhu and Ye - 2022 - How Small Amount of Data Sharing Benefits Distribu.pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/HG8W7M2R/2208.html:text/html},
}

@article{xu_first-order_2018,
	title = {First-order stochastic algorithms for escaping from saddle points in almost linear time},
	volume = {31},
	journal = {Advances in neural information processing systems},
	author = {Xu, Yi and Jin, Rong and Yang, Tianbao},
	year = {2018},
	file = {Full Text:/Users/brent/Zotero/storage/D8WNUX66/Xu et al. - 2018 - First-order stochastic algorithms for escaping fro.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/S2YXDQWS/217e342fc01668b10cb1188d40d3370e-Abstract.html:text/html},
}

@misc{grishchenko_proximal_2020,
	title = {Proximal {Gradient} methods with {Adaptive} {Subspace} {Sampling}},
	url = {http://arxiv.org/abs/2004.13356},
	doi = {10.48550/arXiv.2004.13356},
	abstract = {Many applications in machine learning or signal processing involve nonsmooth optimization problems. This nonsmoothness brings a low-dimensional structure to the optimal solutions. In this paper, we propose a randomized proximal gradient method harnessing this underlying structure. We introduce two key components: i) a random subspace proximal gradient algorithm; ii) an identification-based sampling of the subspaces. Their interplay brings a significant performance improvement on typical learning problems in terms of dimensions explored.},
	urldate = {2022-11-05},
	publisher = {arXiv},
	author = {Grishchenko, Dmitry and Iutzeler, Franck and Malick, Jérôme},
	month = apr,
	year = {2020},
	note = {arXiv:2004.13356 [math]},
	keywords = {Mathematics - Optimization and Control},
	file = {arXiv.org Snapshot:/Users/brent/Zotero/storage/BQJZ3NIK/2004.html:text/html;Grishchenko et al. - 2020 - Proximal Gradient methods with Adaptive Subspace S.pdf:/Users/brent/Zotero/storage/UA2AXDUV/Grishchenko et al. - 2020 - Proximal Gradient methods with Adaptive Subspace S.pdf:application/pdf},
}

@article{beck_globally_2018,
	title = {Globally {Solving} the {Trust} {Region} {Subproblem} {Using} {Simple} {First}-{Order} {Methods}},
	volume = {28},
	issn = {1052-6234, 1095-7189},
	url = {https://epubs.siam.org/doi/10.1137/16M1150281},
	doi = {10.1137/16M1150281},
	abstract = {We consider the trust region subproblem which is given by a minimization of a quadratic, not necessarily convex, function over the Euclidean ball. Based on the well-known secondorder necessary and suﬃcient optimality conditions for this problem, we present two suﬃcient optimality conditions deﬁned solely in terms of the primal variables. Each of these conditions corresponds to one of two possible scenarios that occur in this problem, commonly referred to in the literature as the presence or absence of the “hard case”. We consider a family of ﬁrst-order methods, which includes the projected and conditional gradient methods. We show that any method belonging to this family produces a sequence which is guaranteed to converge to a stationary point of the trust region subproblem. Based on this result and the established suﬃcient optimality conditions, we show that convergence to an optimal solution can be also guaranteed as long as the method is properly initialized. In particular, if the method is initialized with the zeros vector and reinitialized with a randomly generated feasible point, then the best of the two obtained vectors is an optimal solution of the problem with probability 1.},
	language = {en},
	number = {3},
	urldate = {2022-11-05},
	journal = {SIAM Journal on Optimization},
	author = {Beck, Amir and Vaisbourd, Yakov},
	month = jan,
	year = {2018},
	pages = {1951--1967},
	file = {Beck and Vaisbourd - 2018 - Globally Solving the Trust Region Subproblem Using.pdf:/Users/brent/Zotero/storage/762J5TQB/Beck and Vaisbourd - 2018 - Globally Solving the Trust Region Subproblem Using.pdf:application/pdf},
}

@book{parlett_symmetric_1998,
	title = {The symmetric eigenvalue problem},
	publisher = {SIAM},
	author = {Parlett, Beresford N},
	year = {1998},
	file = {Parlett - 1998 - The symmetric eigenvalue problem.pdf:/Users/brent/Zotero/storage/3Q7VRTL8/Parlett - 1998 - The symmetric eigenvalue problem.pdf:application/pdf},
}

@article{curtis_self-correcting_2020,
	title = {A {Self}-{Correcting} {Variable}-{Metric} {Algorithm} {Framework} for {Nonsmooth} {Optimization}},
	volume = {40},
	url = {https://academic.oup.com/imajna/article/40/2/1154/5369122?guestAccessKey=b7a4f0fe-8dc4-4bd7-9418-8b1e3335813d},
	number = {2},
	journal = {IMA Journal of Numerical Analysis},
	author = {Curtis, Frank E. and Robinson, Daniel P. and Zhou, Baoyu},
	year = {2020},
	pages = {1154--1187},
	file = {Curtis et al. - 2020 - A Self-Correcting Variable-Metric Algorithm Framew.pdf:/Users/brent/Zotero/storage/JT54V8I9/Curtis et al. - 2020 - A Self-Correcting Variable-Metric Algorithm Framew.pdf:application/pdf},
}

@article{tao_random_2010,
	title = {Random {Matrices}: the {Distribution} of the {Smallest} {Singular} {Values}},
	volume = {20},
	issn = {1420-8970},
	shorttitle = {Random {Matrices}},
	url = {https://doi.org/10.1007/s00039-010-0057-8},
	doi = {10.1007/s00039-010-0057-8},
	abstract = {Let ξ be a real-valued random variable of mean zero and variance 1. Let Mn(ξ) denote the n × n random matrix whose entries are iid copies of ξ and σn(Mn(ξ)) denote the least singular value of Mn(ξ). The quantity σn(Mn(ξ))2 is thus the least eigenvalue of the Wishart matrix \$\$\{M\_nM\_n{\textasciicircum}{\textbackslash}ast\}\$\$.},
	language = {en},
	number = {1},
	urldate = {2022-11-08},
	journal = {Geometric and Functional Analysis},
	author = {Tao, Terence and Vu, Van},
	month = jun,
	year = {2010},
	keywords = {Random matrices, 15B52, 60B20, condition number, distribution, least singular value},
	pages = {260--297},
	file = {Full Text PDF:/Users/brent/Zotero/storage/P6UP5TUQ/Tao and Vu - 2010 - Random Matrices the Distribution of the Smallest .pdf:application/pdf},
}

@incollection{mathai_quadratic_1992,
	title = {Quadratic {Forms} in {Random} {Variables}: {Theory} and {Applications}},
	volume = {87},
	shorttitle = {Quadratic {Forms} in {Random} {Variables}},
	booktitle = {Journal of the {American} {Statistical} {Association}},
	author = {Mathai, Arak and Provost, Serge},
	month = dec,
	year = {1992},
	doi = {10.2307/2290674},
	note = {Journal Abbreviation: Journal of the American Statistical Association},
	file = {Full Text PDF:/Users/brent/Zotero/storage/Z5UVGIW9/Mathai and Provost - 1992 - Quadratic Forms in Random Variables Theory and Ap.pdf:application/pdf},
}

@article{forchini_distribution_2005,
	title = {The {Distribution} of a {Ratio} of {Quadratic} {Forms} in {Noncentral} {Normal} {Variables}},
	volume = {34},
	issn = {0361-0926, 1532-415X},
	url = {http://www.tandfonline.com/doi/abs/10.1081/STA-200056855},
	doi = {10.1081/STA-200056855},
	language = {en},
	number = {5},
	urldate = {2022-11-09},
	journal = {Communications in Statistics - Theory and Methods},
	author = {Forchini, G.},
	month = may,
	year = {2005},
	pages = {999--1008},
	file = {Forchini - 2005 - The Distribution of a Ratio of Quadratic Forms in .pdf:/Users/brent/Zotero/storage/G98SL9PK/Forchini - 2005 - The Distribution of a Ratio of Quadratic Forms in .pdf:application/pdf},
}

@article{gurland_distribution_1953,
	title = {Distribution of quadratic forms and ratios of quadratic forms},
	journal = {The Annals of Mathematical Statistics},
	author = {Gurland, John},
	year = {1953},
	note = {Publisher: JSTOR},
	pages = {416--427},
	file = {Full Text:/Users/brent/Zotero/storage/QCGDU4XW/Gurland - 1953 - Distribution of quadratic forms and ratios of quad.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/RK3NPI2T/2236291.html:text/html},
}

@article{magnus_exact_1986,
	title = {The exact moments of a ratio of quadratic forms in normal variables},
	journal = {Annales d'Economie et de Statistique},
	author = {Magnus, Jan R.},
	year = {1986},
	note = {Publisher: JSTOR},
	pages = {95--109},
	file = {Full Text:/Users/brent/Zotero/storage/8UTGYJTI/Magnus - 1986 - The exact moments of a ratio of quadratic forms in.pdf:application/pdf},
}

@article{hillier_density_2001,
	title = {The density of a quadratic form in a vector uniformly distributed on the n-sphere},
	volume = {17},
	number = {1},
	journal = {Econometric Theory},
	author = {Hillier, Grant},
	year = {2001},
	note = {Publisher: Cambridge University Press},
	pages = {1--28},
	file = {Hillier - 2001 - The density of a quadratic form in a vector unifor.pdf:/Users/brent/Zotero/storage/EHAQPS8F/Hillier - 2001 - The density of a quadratic form in a vector unifor.pdf:application/pdf;Snapshot:/Users/brent/Zotero/storage/NC6IKKIF/69BEBD63D85C33E45428D97EBA2C1852.html:text/html},
}

@article{kim_analytic_2006,
	title = {Analytic, {Computational}, and {Approximate} {Forms} for {Ratios} of {Noncentral} and {Central} {Gaussian} {Quadratic} {Forms}},
	volume = {15},
	issn = {1061-8600},
	url = {https://doi.org/10.1198/106186006X112954},
	doi = {10.1198/106186006X112954},
	abstract = {Many useful statistics equal the ratio of a possibly noncentral chi-square to a quadratic form in Gaussian variables with all positive weights. Expressing the density and distribution function as positively weighted sums of corresponding F functions has many advantages. The mixture forms have analytic value when embedded within a more complex problem. The mixture forms also have computational value. The expansions work well with quadratic forms having few components and small degrees of freedom. A more general algorithm from earlier literature can take longer or fail to converge in the same setting. Many approximations have been suggested for the problem. A positively weighted noncentral quadratic form can always have two moments matched to a noncentral chi-square. For a single quadratic form, the noncentral form performs neither uniformly more or less accurately than older approximations. The approach also gives a noncentral F approximation for any ratio of a positively weighted noncentral form to a positively weighted central quadratic form. The method provides better accuracy for noncentral ratios than approximations based on a single chi-square. The accuracy suffices for many practical applications, such as power analysis, even with few degrees of freedom. Naturally the approximation proves much faster and simpler to compute than any exact method. Embedding the approximation in analytic expressions provides simple forms which correctly guarantee only positive values have nonzero probabilities, and also automatically reduce to partially or fully exact results when either quadratic form has only one term.},
	number = {2},
	urldate = {2022-11-09},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Kim, Hae-Young and Gribbin, Matthew J and Muller, Keith E and Taylor, Douglas J},
	month = jun,
	year = {2006},
	pmid = {23843686},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/106186006X112954},
	keywords = {Correction, Cumulative distribution function, Mixture distribution, Noncentral F},
	pages = {443--459},
	file = {Kim et al. - 2006 - Analytic, Computational, and Approximate Forms for.pdf:/Users/brent/Zotero/storage/6NNF55SP/Kim et al. - 2006 - Analytic, Computational, and Approximate Forms for.pdf:application/pdf},
}

@article{he_quaternion_2022,
	title = {Quaternion matrix decomposition and its theoretical implications},
	journal = {Journal of Global Optimization},
	author = {He, Chang and Jiang, Bo and Zhu, Xihua},
	year = {2022},
	note = {Publisher: Springer},
	pages = {1--18},
}

@book{parlett_symmetric_1998-1,
	title = {The symmetric eigenvalue problem},
	publisher = {SIAM},
	author = {Parlett, Beresford N},
	year = {1998},
}


@misc{li_restarted_2022,
	title = {Restarted {Nonconvex} {Accelerated} {Gradient} {Descent}: {No} {More} {Polylogarithmic} {Factor} in the {$O(\epsilon^{-7/4})$} {Complexity}},
	shorttitle = {Restarted {Nonconvex} {Accelerated} {Gradient} {Descent}},
	url = {http://arxiv.org/abs/2201.11411},
	doi = {10.48550/arXiv.2201.11411},
	abstract = {Nonconvex optimization with great demand of fast solvers is ubiquitous in modern machine learning. This paper studies two simple accelerated gradient methods, restarted accelerated gradient descent (AGD) and restarted heavy ball (HB) method, for general nonconvex problems under the gradient Lipschitz and Hessian Lipschitz conditions. We establish that the two algorithms find an \${\textbackslash}epsilon\$-approximate first-order stationary point in \$O({\textbackslash}epsilon{\textasciicircum}\{-7/4\})\$ gradient computations with simple proofs. Our complexity does not hide any polylogarithmic factors, and thus it improves over the state-of-the-art one by the \$O({\textbackslash}log{\textbackslash}frac\{1\}\{{\textbackslash}epsilon\})\$ factor. Our algorithms are simple in the sense that they only consist of Nesterov's classical AGD or Polyak's HB iterations, as well as a restart mechanism. They do not need the negative curvature exploitation or the minimization of regularized surrogate functions. Our simple proofs only use very elementary analysis, and in contrast with existing analysis, we do not invoke the analysis of the strongly convex AGD or HB.},
	urldate = {2022-11-14},
	publisher = {arXiv},
	author = {Li, Huan and Lin, Zhouchen},
	month = may,
	year = {2022},
	note = {arXiv:2201.11411 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
	annote = {Comment: Only change the template},
	file = {arXiv Fulltext PDF:/Users/brent/Zotero/storage/2ABKPUQV/Li and Lin - 2022 - Restarted Nonconvex Accelerated Gradient Descent .pdf:application/pdf;arXiv.org Snapshot:/Users/brent/Zotero/storage/PYSX337N/2201.html:text/html},
}
