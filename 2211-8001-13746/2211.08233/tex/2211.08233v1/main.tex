% Template for ICASSP-2021 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% New package
\usepackage{color,xcolor}
\usepackage{booktabs}
\usepackage{xspace}
\usepackage{newtxmath}
\usepackage{rotating}
\usepackage{multirow}
\usepackage{subfigure} 
\usepackage{url}
\newlength\savewidth\newcommand\shline{\noalign{\global\savewidth\arrayrulewidth
  \global\arrayrulewidth 1.5pt}\hline\noalign{\global\arrayrulewidth\savewidth}}
%% customized commands
\usepackage[colorlinks,citecolor=citecolor, linkcolor=linkcolor, bookmarks=false]{hyperref}
\definecolor{citecolor}{HTML}{1F801F}
\definecolor{linkcolor}{HTML}{ED1C24}
\newcommand{\methodname}{TIM-Net\xspace}
\newcommand{\T}{^{\textrm T}} % transpose
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\vct}[1]{\boldsymbol{#1}} % vector
\newcommand{\mat}[1]{\boldsymbol{#1}} % matrix
\newcommand{\etal}{\textit{et al}.\xspace}
\newcommand{\ie}{\textit{i}.\textit{e}.\xspace}
\newcommand{\eg}{\textit{e}.\textit{g}.\xspace}
\newcommand{\tabincell}[1]{\begin{tabular}[l]{@{}c@{}} #1\end{tabular}}
\newcommand{\addline}[1]{\multicolumn{1}{c|}{#1}}
%\newcommand{\onecell}{2}{ {#1}, {#2}}
\makeatletter
\DeclareRobustCommand{\cev}[1]{%
  {\mathpalette\do@cev{#1}}%
}
\newcommand{\do@cev}[2]{%
  \vbox{\offinterlineskip
    \sbox\z@{$\m@th#1 x$}%
    \ialign{##\cr
      \hidewidth\reflectbox{$\m@th#1\vec{}\mkern4mu$}\hidewidth\cr
      \noalign{\kern-\ht\z@}
      $\m@th#1#2$\cr
    }%
  }%
}

% Title.
% ------
\title{Temporal Modeling Matters: A Novel Temporal Emotional Modeling Approach for Speech Emotion Recognition}

\name{Jiaxin Ye$^1$, Xincheng Wen$^2$, Yujie Wei$^1$, Yong Xu$^3$, Kunhong Liu$^{4,\dagger}$, Hongming Shan$^{1,\dagger}$\thanks{$\dagger$: Corresponding author.}}
\address{$^1$ Fudan University\quad $^2$ Harbin Institute of Technology (Shenzhen) \\$^3$ Fujian University of Technology\quad $^4$ Xiamen University}

\setlength{\belowcaptionskip}{0.cm}
\begin{document}

\maketitle

\input{0_abs}% Abstract

\input{1_intro}% Introduction


\input{2_method}% Proposed Method

\input{3_exp}% Experiment

\input{4_conclu}% Conclusion

\vfill\pagebreak


{\small
\begin{thebibliography}{10}

\bibitem{schuller2018speech}
Bj{\"o}rn~W Schuller,
\newblock ``Speech emotion recognition: Two decades in a nutshell, benchmarks,
  and ongoing trends,''
\newblock {\em Commun. ACM}, vol. 61, no. 5, pp. 90--99, 2018.

\bibitem{TSP_INCA}
T{\"{u}}rker Tuncer, Seng{\"{u}}l Dogan, and U.~Rajendra Acharya,
\newblock ``Automated accurate speech emotion recognition system using twine
  shuffle pattern and iterative neighborhood component analysis techniques,''
\newblock {\em Knowl. Based Syst.}, vol. 211, pp. 106547, 2021.

\bibitem{INCA_CNN}
Mustaqeem and Soonil Kwon,
\newblock ``Optimal feature selection based speech emotion recognition using
  two-stream deep convolutional neural network,''
\newblock {\em Int. J. Intell. Syst.}, vol. 36, no. 9, pp. 5116--5135, 2021.

\bibitem{RM_CNN}
Ilyas Ozer,
\newblock ``Pseudo-colored rate map representation for speech emotion
  recognition,''
\newblock {\em Biomed. Signal Process. Control.}, vol. 66, pp. 102502, 2021.

\bibitem{SER_CNN_intro}
Aneesh Muppidi and Martin Radfar,
\newblock ``Speech emotion recognition using quaternion convolutional neural
  networks,''
\newblock in {\em {ICASSP} 2021, Toronto, ON, Canada, June 6-11, 2021}. 2021,
  pp. 6309--6313, {IEEE}.

\bibitem{GRU_ser1}
Srividya~Tirunellai Rajamani, Kumar~T. Rajamani, Adria Mallol{-}Ragolta,
  et~al.,
\newblock ``A novel attention-based gated recurrent unit and its efficacy in
  speech emotion recognition,''
\newblock in {\em {ICASSP} 2021, Toronto, ON, Canada, June 6-11, 2021}. 2021,
  pp. 6294--6298, {IEEE}.

\bibitem{Dual_LSTM}
Jianyou Wang, Michael Xue, Ryan Culhane, et~al.,
\newblock ``Speech emotion recognition with dual-sequence {LSTM}
  architecture,''
\newblock in {\em {ICASSP} 2020, Barcelona, Spain, May 4-8, 2020}. 2020, pp.
  6474--6478, {IEEE}.

\bibitem{bilstm_ser3}
Ziping Zhao, Yu~Zheng, Zixing Zhang, and othersi,
\newblock ``Exploring spatio-temporal representations by integrating
  attention-based bidirectional-lstm-rnns and fcns for speech emotion
  recognition,''
\newblock in {\em Interspeech 2018, Hyderabad, India, 2-6 September 2018}.
  2018, pp. 272--276, {ISCA}.

\bibitem{IEMOCAP_GRU}
Ying Zhong, Ying Hu, Hao Huang, and Wushour Silamu,
\newblock ``A lightweight model based on separable convolution for speech
  emotion recognition,''
\newblock in {\em Interspeech 2020, Virtual Event, Shanghai, China, 25-29
  October 2020}. 2020, pp. 3331--3335, {ISCA}.

\bibitem{draw_back2}
Yi~Luo, Zhuo Chen, and Takuya Yoshioka,
\newblock ``Dual-path {RNN:} efficient long sequence modeling for time-domain
  single-channel speech separation,''
\newblock in {\em {ICASSP} 2020, Barcelona, Spain, May 4-8, 2020}. 2020, pp.
  46--50, {IEEE}.

\bibitem{Markov}
Steffen Jung, Isabel Schlangen, and Alexander Charlish,
\newblock ``A mnemonic kalman filter for non-linear systems with extensive
  temporal dependencies,''
\newblock {\em IEEE Signal Processing Letters}, vol. 27, pp. 1005--1009, 2020.

\bibitem{IEMOCAP_CNN1}
Zixuan Peng, Yu~Lu, Shengfeng Pan, et~al.,
\newblock ``Efficient speech emotion recognition using multi-scale {CNN} and
  attention,''
\newblock in {\em {ICASSP} 2021, Toronto, ON, Canada, June 6-11, 2021}. 2021,
  pp. 3020--3024, {IEEE}.

\bibitem{DT_SVM}
Linhui Sun, Sheng Fu, and Fu~Wang,
\newblock ``Decision tree {SVM} model with fisher feature selection for speech
  emotion recognition,''
\newblock {\em {EURASIP} J. Audio Speech Music. Process.}, vol. 2019, pp. 2,
  2019.

\bibitem{TLFMRF}
Luefeng Chen, Wanjuan Su, Yu~Feng, et~al.,
\newblock ``Two-layer fuzzy multiple random forest for speech emotion
  recognition in human-robot interaction,''
\newblock {\em Inf. Sci.}, vol. 509, pp. 150--163, 2020.

\bibitem{GM_TCNet}
JiaXin Ye, XinCheng Wen, XuanZe Wang, et~al.,
\newblock ``{GM}-{TCNet}: {Gated} {Multi}-scale {Temporal} {Convolutional}
  {Network} using {Emotion} {Causality} for {Speech} {Emotion} {Recognition},''
\newblock {\em Speech Communication}, 2022.

\bibitem{MFMC_SVM}
J~Ancilin and A~Milton,
\newblock ``Improved speech emotion recognition with mel frequency magnitude
  coefficient,''
\newblock {\em Applied Acoustics}, vol. 179, pp. 108046, 2021.

\bibitem{IEMOCAP_CNN2}
Arya Aftab, Alireza Morsali, Shahrokh Ghaemmaghami, et~al.,
\newblock ``{LIGHT-SERNET:} {A} lightweight fully convolutional neural network
  for speech emotion recognition,''
\newblock in {\em {ICASSP} 2022, Virtual and Singapore, 23-27 May 2022}. 2022,
  pp. 6912--6916, {IEEE}.

\bibitem{CPAC_IJCAI}
XinCheng Wen, JiaXin Ye, Yan Luo, et~al.,
\newblock ``{CTL-MTNet}: {A} novel capsnet and transfer learning-based mixed
  task net for single-corpus and cross-corpus speech emotion recognition,''
\newblock in {\em {IJCAI} 2022, Vienna, Austria, 23-29 July 2022}, 2022, pp.
  2305--2311.

\bibitem{IEMOCAP_DRN}
Runnan Li, Zhiyong Wu, Jia Jia, et~al.,
\newblock ``Dilated residual network with multi-head self-attention for speech
  emotion recognition,''
\newblock in {\em {ICASSP} 2019, Brighton, United Kingdom, May 12-17, 2019}.
  2019, pp. 6675--6679, {IEEE}.

\bibitem{3D_CNN}
Noushin Hajarolasvadi and Hasan Demirel,
\newblock ``3d cnn-based speech emotion recognition using k-means clustering
  and spectrograms,''
\newblock {\em Entropy}, vol. 21, no. 5, pp. 479, 2019.

\bibitem{CASIA}
Jianhua Tao, Fangzhou Liu, Meng Zhang, and Huibin Jia,
\newblock ``Design of speech corpus for mandarin text to speech,''
\newblock in {\em The Blizzard Challenge 2008 workshop}, 2008.

\bibitem{EMODB}
Felix Burkhardt, Astrid Paeschke, M.~Rolfes, et~al.,
\newblock ``A database of german emotional speech,''
\newblock in {\em {INTERSPEECH} 2005, Lisbon, Portugal, September 4-8, 2005},
  2005, vol.~5, pp. 1517--1520.

\bibitem{EMOVO}
Giovanni Costantini, Iacopo Iaderola, Andrea Paoloni, and Massimiliano Todisco,
\newblock ``Emovo corpus: an italian emotional speech database,''
\newblock in {\em {LREC} 2014}, 2014, pp. 3501--3504.

\bibitem{IEMOCAP}
Carlos Busso, Murtaza Bulut, Chi{-}Chun Lee, et~al.,
\newblock ``{IEMOCAP:} interactive emotional dyadic motion capture database,''
\newblock {\em Lang. Resour. Evaluation}, vol. 42, no. 4, pp. 335--359, 2008.

\bibitem{RAVDE}
Steven~R Livingstone and Frank~A Russo,
\newblock ``The ryerson audio-visual database of emotional speech and song
  (ravdess): A dynamic, multimodal set of facial and vocal expressions in north
  american english,''
\newblock {\em PLOS ONE}, vol. 13, no. 5, pp. e0196391, 2018.

\bibitem{SAVEE}
Philip Jackson and SJUoSG Haq,
\newblock ``Surrey audio-visual expressed emotion (savee) database,''
\newblock {\em University of Surrey: Guildford, UK}, 2014.

\bibitem{librosa}
Brian McFee, Colin Raffel, Dawen Liang, Daniel~PW Ellis, Matt McVicar, Eric
  Battenberg, and Oriol Nieto,
\newblock ``librosa: Audio and music signal analysis in python,''
\newblock in {\em Proceedings of the 14th Python in Science Conference}, 2015,
  vol.~8, pp. 18--25.

\bibitem{T-SNE}
Laurens Van~der Maaten and Geoffrey Hinton,
\newblock ``Visualizing data using t-sne.,''
\newblock {\em J. Mach. Learn. Res.}, vol. 9, no. 11, 2008.

\end{thebibliography}


}

\input{appendix}
\end{document}
