\section{EXPERIMENTS}
\label{EXPERIMENTS}

\subsection{Experimental Setup}
\noindent\textbf{Datasets.}\quad
To demonstrate the effectiveness of the proposed \methodname, we compare \methodname with State-Of-The-Art (SOTA) methods on 6 benchmark SER corpora, including 
Chinese corpus CASIA~\cite{CASIA}, 
German corpus EMODB~\cite{EMODB}, 
Italian corpus EMOVO~\cite{EMOVO}, 
English corpora IEMOCAP~\cite{IEMOCAP}, RAVDESS~\cite{RAVDE}, and SAVEE~\cite{SAVEE}. %; see Appendix~\ref{sec:details} for the detailed summary of datasets.

\noindent\textbf{Implementation details.}\quad
In the experiments, 39-dimensional MFCCs are extracted from the Librosa toolbox~\cite{librosa}. The cross-entropy criterion is used as the objective function. Adam algorithm is adopted to optimize the model with an initial learning rate $\alpha$ = $0.001$, and a batch size of 64. To avoid over-fitting during the training phase, we implement label smoothing with factor 0.1 as a form of regularization and set the spatial dropout rate to 0.1. 
For fair comparisons with the SOTA approaches, we perform 10-fold cross-validation (CV) as well as previous works~\cite{IEMOCAP_CNN2,CPAC_IJCAI,IEMOCAP_DRN} in experiments. The source code is available at~\url{https://github.com/Jiaxin-Ye/TIM-Net_SER}.

\noindent\textbf{Evaluation metrics.}\quad Due to the class imbalance, we use two widely-used metrics, Weighted Average Recall (WAR) (\ie accuracy) and Unweighted Average Recall (UAR), to evaluate the performance of each method. WAR uses the class probabilities to balance the recall metric of different classes while UAR treats each class equally; see Appendix~\ref{sec:details} for summary of datasets and definitions of evaluation metrics.

\begin{figure}[t]
	\centering
	\includegraphics[width=1\linewidth]{Figure/matrix.pdf}
	\caption{The confusion matrices obtained by \methodname under 10-fold CV, with the related WAR scores.}
	\label{fig:matrix}
\end{figure}
\subsection{Results and Analysis}
\noindent\textbf{Comparison with SOTA methods.}\quad
Table~\ref{tab:SOTA} presents the overall results on 6 benchmark datasets, showing that our method significantly and consistently outperforms all these compared methods by a large margin. 
Remarkably, our approach gains 2.34\% and 2.61\% improvements of the average UAR and WAR scores than the second-best on each corpus.
In addition, the confusion matrices on CASIA and EMODB datasets shown in Fig.~\ref{fig:matrix} further confirm that \methodname achieves excellent class-discriminative performance, with over 90\% on each emotion class.
\begin{figure}[t]
	\centering
	\includegraphics[width=1.0\linewidth]{Figure/TSNE.pdf}
	\caption{t-SNE visualizations of features learned from SOTA method GM-TCN and \methodname. The score denotes WAR.}
	\label{fig:tsne}
\end{figure}

\input{Table/Generalizability}

\noindent\textbf{Visualization of learned affective representation.}\quad
To investigate the impact of \methodname on representation learning, we visualize the representations learned by \methodname and GM-TCN~\cite{GM_TCNet} through the t-SNE technique~\cite{T-SNE} in Fig.~\ref{fig:tsne}. 
For a fair comparison, we first use the same 8:2 hold-out validation on CASIA corpus for the two methods, and visualize the representations of the same test data after an identical training phase. 
Although GM-TCN also focuses on multi-scale and temporal modeling, Fig.~\ref{fig:tsne}(a) shows heavy overlapping between \emph{Fear} and \emph{Sad} or \emph{Angry} and \emph{Surprise}.
In contrast, Fig.~\ref{fig:tsne}(b) shows that the different representations are clustered with clear classification boundaries. The results confirm that the \methodname provides more class-discriminative representations to support superior performance. 


\noindent\textbf{Domain generalization analysis.}\quad
Due to various languages and speakers, the SER corpora, although sharing the same emotion, have considerably significant domain shifts. The generalization of the model to unseen domain is critically important for SER. Inspired by the domain-adaptation study in CAAM~\cite{CPAC_IJCAI}, we likewise validate the generalizability of \methodname on the cross-corpus SER task, following the same experimental setting as CAAM except that \methodname does not have access to the target domain. Specifically, we likewise choose 5 classes for a fair comparison, \ie \emph{angry}, \emph{fear}, \emph{happy}, \emph{neutral}, and \emph{sad}, shared among these 5 corpora (except for IEMOCAP, which has only 4 emotions). These 5 corpora form 20 cross-corpus combinations. And we report the average UAR and WAR, and their standard deviation from 10 random runs for each task in Table~\ref{tab:generalization}; see Appendix~\ref{sec:cross-corpus} for detailed results. 

The performance of TCN over different corpora is close to random guessing with odds equal to 25\%, and \methodname has a significant improvement over TCN. Surprisingly, \methodname outperforms CAAM, one latest task-specific domain-adaptation method. The results suggest that our \methodname is effective in modeling emotion with strong generalizability.


\subsection{Ablation Study}

We conduct ablation studies on all the corpus datasets, including the following variations of \methodname: \textbf{TCN}: the \methodname is replaced with TCN; \textbf{w/o BD}: the backward TABs are removed while keeping the forward TABs; \textbf{w/o MS}: the multi-scale fusion is removed and $\vct{g}_n$ is used as $\vct{g}_{\text{drf}}$ corresponding to max-scale receptive field; \textbf{w/o DF}: the average fusion is used to confirm the advantages of dynamic fusion. The results of ablation studies are  shown in Table~\ref{tab:ablation}. We have the following observations. 

\emph{First}, all components contribute positively to the overall performance. 
\emph{Second}, our method achieves 8.31\% and 8.41\% performance gains in UAR and WAR over TCN that also utilizes DC Conv. 
\emph{Third}, when removing the backward TABs or multi-scale strategy, the results substantially drop due to the weaker capacity to model temporal dependencies and perceive the sentimental features with different scales. 
\emph{Finally}, \methodname without dynamic fusion performs worse than \methodname, which verifies the benefits of deploying dynamic fusion to adjust the model adaptively. 
\input{Table/Ablation}






