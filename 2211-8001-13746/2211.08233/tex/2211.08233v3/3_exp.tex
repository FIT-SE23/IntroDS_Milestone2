\section{EXPERIMENTS}
\label{EXPERIMENTS}

\subsection{Experimental Setup}
\noindent\textbf{Datasets.}\quad
To demonstrate the effectiveness of the proposed \methodname, we compare \methodname with State-Of-The-Art (SOTA) methods on 6 benchmark SER corpora. 
CASIA~\cite{CASIA} is a Chinese corpus collected from 4 Chinese speakers exhibiting 6 emotional states. EMODB~\cite{EMODB} is a German corpus that covers 7 emotions by 10 German speakers. EMOVO~\cite{EMOVO} is an Italian corpus recorded by 6 Italian speakers simulating 7 emotional states. IEMOCAP~\cite{IEMOCAP} is an English corpus that covers 4 emotions from 10 American speakers. RAVDESS~\cite{RAVDE} is an English corpus of 8 emotions by 24 British speakers. SAVEE~\cite{SAVEE} is an English corpus recorded by 4 British speakers in 7 emotions. 

\begin{figure*}[t]
	\centering
	\includegraphics[width=1.0\textwidth]{Figure/RAVDESS_log.pdf}
	\caption{The accuracy and loss curves for 10-fold cross validation$^{*}$ on the RAVDESS corpus.}
	\label{fig:log}
\end{figure*}

\noindent\textbf{Implementation details.}\quad
In the experiments, 39-dimensional MFCCs are extracted from the Librosa toolbox~\cite{librosa}. The cross-entropy criterion is used as the objective function and the overall epoch is set to 500. Adam algorithm is adopted to optimize the model with an initial learning rate $\alpha$ = $0.001$, and a batch size of 64. To avoid over-fitting during the training phase, we implement label smoothing with factor 0.1 as a form of regularization. For the $j$-th TAB $\mathcal{T}_j$, there are 39 kernels of size 2 in Conv layers, the dropout rate is 0.1, and the dilated rate is $2^{j-1}$. To guarantee that the maximal receptive field covers the input sequences, we set the number of TAB $n$ in both directions to 10 for IEMOCAP and 8 for others. 
For fair comparisons with the SOTA approaches in experiments, following previous works~\cite{TSP_INCA,IEMOCAP_CNN2,IEMOCAP_DRN}, we mainly perform 10-fold cross-validation (CV) with 90\% training data and 10\% testing data in one fold to evaluate fitting ability of the model. To evaluate the generalization ability of the model, we further conduct experiments on six corpora under another evaluation setting. As shown in Table~\ref{tab:SOTA}, the superscript `$^{*}$' implies a 10-fold CV with 90\% and 10\% samples in train and test sets, whose model is only evaluated at the last epoch using the testing set.

\noindent\textbf{Evaluation metrics.}\quad Due to the class imbalance, we use two widely-used metrics, Weighted Average Recall (WAR) (\ie accuracy) and Unweighted Average Recall (UAR), to evaluate the performance of each method. WAR uses the class probabilities to balance the recall metric of different classes while UAR treats each class equally.



\subsection{Results and Analysis}
\noindent\textbf{Comparison with SOTA methods.}\quad
To demonstrate the effectiveness of our approach on each corpus, we select representative approaches on each corpus following the 10-fold CV strategy.  
Table~\ref{tab:SOTA} presents the overall results on 6 corpora, showing that our method significantly and consistently outperforms all these compared methods by a large margin. Remarkably, our approach gains 2.34\% and 2.61\% improvements of the average UAR and WAR scores than the second-best on each corpus under the second evaluating setting. However, most previous methods focus on evaluating the fitting ability of the model, leading to overfitting issues. 
We further evaluate the generalization ability of the model under another evaluation setting. As shown in Table~\ref{tab:SOTA}, although performance has declined, the \methodname still has competitive performance and good generalization ability on several corpora. Fig.~\ref{fig:log} shows that \methodname does not exhibit significant overfitting issues, and its convergence curves remain relatively stable. 
Moreover, it can be observed that the affective discrimination ability of \methodname in short-term speech (\eg CASIA, EMODB, EMOVO, and RAVDESS) is generally stronger than that in long-term speech (\eg IEMOCAP and SAVEE), which means that long-term dependence is still a challenging issue. 
Please refer to our GitHub repo\footnote{\url{https://github.com/Jiaxin-Ye/TIM-Net_SER}} for extra experimental details and results. 


\begin{figure}[t]
	\centering
	\includegraphics[width=1.0\linewidth]{Figure/TSNE.pdf}
	\caption{t-SNE visualizations of features learned from SOTA method GM-TCN and \methodname. The score denotes WAR.}
	\label{fig:tsne}
\end{figure}

\input{Table/Generalizability}


\noindent\textbf{Visualization of learned affective representation.}\quad
To investigate the impact of \methodname on representation learning, we visualize the representations learned by \methodname and GM-TCN~\cite{GM_TCNet} through the t-SNE technique~\cite{T-SNE} in Fig.~\ref{fig:tsne}. 
For a fair comparison, we first use the same 8:2 hold-out validation on CASIA corpus for the two methods, and visualize the representations of the same test data after an identical training phase. 
Although GM-TCN also focuses on multi-scale and temporal modeling. Fig.~\ref{fig:tsne}(a) shows heavy overlapping between \emph{Fear} and \emph{Sad} or \emph{Angry} and \emph{Surprise}.
In contrast, Fig.~\ref{fig:tsne}(b) shows that the different representations are clustered with clear classification boundaries. 
The results confirm that the \methodname provides more class-discriminative representations to support superior performance by capturing intra- and inter-dependencies at different temporal scales. 


\noindent\textbf{Domain generalization analysis.}\quad
Due to various languages and speakers, the SER corpora, although sharing the same emotion, have considerably significant domain shifts. The generalization of the model to unseen domain/corpus is critically important for SER. Inspired by the domain-adaptation study in CAAM~\cite{CPAC_IJCAI}, we likewise validate the generalizability of \methodname on the cross-corpus SER task, following the same experimental setting as CAAM except that \methodname does not have access to the target domain. Specifically, we likewise choose 5 emotional classes for a fair comparison, \ie \emph{angry}, \emph{fear}, \emph{happy}, \emph{neutral}, and \emph{sad}, shared among these 5 corpora (except for IEMOCAP, which has only 4 emotions). These 5 corpora form 20 cross-corpus combinations. And we report the average UAR and WAR, and their standard deviation from 10 random runs for each task in Table~\ref{tab:generalization}. 

The performance of TCN over different corpora is close to random guessing with odds equal to 25\%, and \methodname has a significant improvement over TCN. Surprisingly, \methodname outperforms CAAM, one latest task-specific domain-adaptation method. The results suggest that our \methodname is effective in modeling emotion with strong generalizability.

\subsection{Ablation Study}
We conduct ablation studies on all the corpus datasets, including the following variations of \methodname: \textbf{TCN}: the \methodname is replaced with TCN; \textbf{w/o BD}: the backward TABs are removed while keeping the forward TABs; \textbf{w/o MS}: the multi-scale fusion is removed and $\vct{g}_n$ is used as $\vct{g}_{\text{drf}}$ corresponding to max-scale receptive field; \textbf{w/o DF}: the average fusion is used to confirm the advantages of dynamic fusion. The results of ablation studies are  shown in Table~\ref{tab:ablation}. We have the following observations. 

\emph{First}, all components contribute positively to the overall performance. 
\emph{Second}, our method achieves 8.31\% and 8.41\% performance gains in UAR and WAR over TCN that also utilizes DC Conv. Since the inability of TCN to capture contextual multi-scale features, capturing intra- and inter-dependencies at different temporal scales is critical to SER.
\emph{Third}, when removing the backward TABs or multi-scale strategy, the results substantially drop due to the weaker capacity to model temporal dependencies and perceive the sentimental features with different scales. 
\emph{Finally}, \methodname without dynamic fusion performs worse than \methodname, which verifies the benefits of deploying dynamic fusion to adjust the model adaptively. 
\input{Table/Ablation}






