@article{DT_2021,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{TT_2021,
  title={Offline Reinforcement Learning as One Big Sequence Modeling Problem},
  author={Janner, Michael and Li, Qiyang and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{Sergey,
  author    = {Sergey Levine},
  title     = {Understanding the World Through Action},
  journal   = {CoRR},
  volume    = {abs/2110.12543},
  year      = {2021}
}

@article{BC,
  title={Behavioral cloning from observation},
  author={Torabi, Faraz and Warnell, Garrett and Stone, Peter},
  journal={arXiv preprint arXiv:1805.01954},
  year={2018}
}

@article{IQL,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@inproceedings{BCQ,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}

@article{AWR,
  title={Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{BRAC,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{ICQ,
  title={Believe what you see: Implicit constraint approach for offline multi-agent reinforcement learning},
  author={Yang, Yiqin and Ma, Xiaoteng and Chenghao, Li and Zheng, Zewu and Zhang, Qiyuan and Huang, Gao and Yang, Jun and Zhao, Qianchuan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{CQL,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@article{UWAC,
  title={Uncertainty weighted actor-critic for offline reinforcement learning},
  author={Wu, Yue and Zhai, Shuangfei and Srivastava, Nitish and Susskind, Joshua and Zhang, Jian and Salakhutdinov, Ruslan and Goh, Hanlin},
  journal={arXiv preprint arXiv:2105.08140},
  year={2021}
}

@article{MOPO,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14129--14142},
  year={2020}
}

@article{MOREL,
  title={Morel: Model-based offline reinforcement learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21810--21823},
  year={2020}
}

@inproceedings{PEARL,
  title={Efficient off-policy meta-reinforcement learning via probabilistic context variables},
  author={Rakelly, Kate and Zhou, Aurick and Finn, Chelsea and Levine, Sergey and Quillen, Deirdre},
  booktitle={International Conference on Machine Learning},
  pages={5331--5340},
  year={2019},
  organization={PMLR}
}

@article{FOCAL,
  title={Focal: Efficient fully-offline meta-reinforcement learning via distance metric learning and behavior regularization},
  author={Li, Lanqing and Yang, Rui and Luo, Dijun},
  journal={arXiv preprint arXiv:2010.01112},
  year={2020}
}

@article{BOReL,
  title={Offline meta learning of exploration},
  author={Dorfman, Ron and Shenfeld, Idan and Tamar, Aviv},
  journal={arXiv preprint arXiv:2008.02598},
  year={2020}
}

@inproceedings{MACAW,
  title={Offline meta-reinforcement learning with advantage weighting},
  author={Mitchell, Eric and Rafailov, Rafael and Peng, Xue Bin and Levine, Sergey and Finn, Chelsea},
  booktitle={International Conference on Machine Learning},
  pages={7780--7791},
  year={2021},
  organization={PMLR}
}

@article{SMAC,
  title={Offline Meta-Reinforcement Learning with Online Self-Supervision},
  author={Pong, Vitchyr H and Nair, Ashvin and Smith, Laura and Huang, Catherine and Levine, Sergey},
  journal={arXiv preprint arXiv:2107.03974},
  year={2021}
}

@article{FOCAL++,
  title={Provably Improved Context-Based Offline Meta-RL with Attention and Contrastive Learning},
  author={Li, Lanqing and Huang, Yuanhao and Chen, Mingzhe and Luo, Siteng and Luo, Dijun and Huang, Junzhou},
  journal={arXiv e-prints},
  pages={arXiv--2102},
  year={2021}
}

@article{MBML,
  title={Multi-task batch reinforcement learning with metric learning},
  author={Li, Jiachen and Vuong, Quan and Liu, Shuang and Liu, Minghua and Ciosek, Kamil and Christensen, Henrik and Su, Hao},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6197--6210},
  year={2020}
}

@article{MerPO,
  title={Model-Based Offline Meta-Reinforcement Learning with Regularization},
  author={Lin, Sen and Wan, Jialin and Xu, Tengyu and Liang, Yingbin and Zhang, Junshan},
  journal={arXiv preprint arXiv:2202.02929},
  year={2022}
}

@article{Xland,
  title={Open-ended learning leads to generally capable agents},
  author={Team, Open Ended Learning and Stooke, Adam and Mahajan, Anuj and Barros, Catarina and Deck, Charlie and Bauer, Jakob and Sygnowski, Jakub and Trebacz, Maja and Jaderberg, Max and Mathieu, Michael and others},
  journal={arXiv preprint arXiv:2107.12808},
  year={2021}
}

@article{MADT,
  title={Offline Pre-trained Multi-Agent Decision Transformer: One Big Sequence Model Conquers All StarCraftII Tasks},
  author={Meng, Linghui and Wen, Muning and Yang, Yaodong and Le, Chenyang and Li, Xiyun and Zhang, Weinan and Wen, Ying and Zhang, Haifeng and Wang, Jun and Xu, Bo},
  journal={arXiv preprint arXiv:2112.02845},
  year={2021}
}

@article{curriculumImitation,
  title={Curriculum offline imitating learning},
  author={Liu, Minghuan and Zhao, Hanye and Yang, Zhengyu and Shen, Jian and Zhang, Weinan and Zhao, Li and Liu, Tie-Yan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@book{RLintro,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{prompt,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and others},
  journal={arXiv},
  year={2021}
}


@article{SwinTransformer,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and others},
  journal={Proceedings of the IEEE/CVF ICCV},
  year={2021}
}

@article{bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  journal={Proceedings of NAACL-HLT},
  year={2019}
}

@article{brown2020gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom and others},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@article{scalingVIT,
  author    = {Xiaohua Zhai and
               Alexander Kolesnikov and
               Neil Houlsby and
               Lucas Beyer},
  title     = {Scaling Vision Transformers},
  journal   = {CoRR},
  volume    = {abs/2106.04560},
  year      = {2021}
}

@article{infoNCE,
  title={Representation learning with contrastive predictive coding},
  author={Van den Oord, Aaron and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv e-prints},
  pages={arXiv--1807},
  year={2018}
}

@article{SayCan,
  title={Do As I Can, Not As I Say: Grounding Language in Robotic Affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}

@misc{gato,
    title={A Generalist Agent},
    author={Scott Reed and Konrad Zolna and Emilio Parisotto and Sergio Gomez Colmenarejo and Alexander Novikov and Gabriel Barth-Maron and Mai Gimenez and Yury Sulsky and Jackie Kay and Jost Tobias Springenberg and Tom Eccles and Jake Bruce and Ali Razavi and Ashley Edwards and Nicolas Heess and Yutian Chen and Raia Hadsell and Oriol Vinyals and Mahyar Bordbar and Nando de Freitas},
    year={2022},
    eprint={2205.06175},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@article{levine2020offline,
  title={Offline Reinforcement Learning: Tutorial, Review},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={and Perspectives on Open Problems},
  year={2020}
}

@article{TD_BC,
  title={A minimalist approach to offline reinforcement learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{identify_offlinemeta,
  title={Offline Meta Reinforcement Learning--Identifiability Challenges and Effective Data Collection Strategies},
  author={Dorfman, Ron and Shenfeld, Idan and Tamar, Aviv},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{prefix-tune,
  title={Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author={Li, Xiang Lisa and Liang, Percy},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={4582--4597},
  year={2021}
}
@inproceedings{fu2020towards,
  title={Towards Effective Context for Meta-Reinforcement Learning: an Approach based on Contrastive Learning},
  author={Fu, Haotian and Tang, Hongyao and Hao, Jianye and Chen, Chen and Feng, Xidong and Li, Dong and Liu, Wulong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={7457--7465},
  year={2021}
}

@article{d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@inproceedings{mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@inproceedings{samvelyan2019starcraft,
  title={The StarCraft Multi-Agent Challenge},
  author={Samvelyan, Mikayel and Rashid, Tabish and Schroeder de Witt, Christian and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  booktitle={Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={2186--2188},
  year={2019}
}

@inproceedings{xu2022prompting,
  title={Prompting decision transformer for few-shot policy generalization},
  author={Xu, Mengdi and Shen, Yikang and Zhang, Shun and Lu, Yuchen and Zhao, Ding and Tenenbaum, Joshua and Gan, Chuang},
  booktitle={International Conference on Machine Learning},
  pages={24631--24645},
  year={2022},
  organization={PMLR}
}

@article{MAT,
  title={Multi-Agent Reinforcement Learning is a Sequence Modeling Problem},
  author={Wen, Muning and Kuba, Jakub Grudzien and Lin, Runji and Zhang, Weinan and Wen, Ying and Wang, Jun and Yang, Yaodong},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}