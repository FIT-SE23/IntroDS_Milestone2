% START OF SIDDHARTH's ZOTERO

@dataset{margnet_dataset,
  author       = {Chaini, Siddharth and Bagul, Atharva and Deshpande, Anish and Gondkar, Rishi and Sharma, Kaushal and Vivek, M. and Kembhavi, Ajit},
  title        = {{Photometric and Image Dataset for Faint and Compact Galaxies, Stars and Qausars}},
  month        = jun,
  year         = 2022,
  publisher    = {Zenodo},
  version      = {Version 4.3},
  doi          = {10.5281/zenodo.6659435},
  url          = {https://doi.org/10.5281/zenodo.6659435}
}

@article{ballRobustMachineLearning2006,
  title = {Robust {{Machine Learning Applied}} to {{Astronomical Data Sets}}. {{I}}. {{Star}}-{{Galaxy Classification}} of the {{Sloan Digital Sky Survey DR3 Using Decision Trees}}},
  author = {Ball, Nicholas M. and Brunner, Robert J. and Myers, Adam D. and Tcheng, David},
  year = {2006},
  month = oct,
  journal = {\apj},
  volume = {650},
  number = {1},
  pages = {497--509},
  issn = {0004-637X, 1538-4357},
  doi = {10.1086/507440},
  langid = {english},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\ICV6C8KF\\Ball et al. - 2006 - Robust Machine Learning Applied to Astronomical Da.pdf}
}

@article{soumagnacStarGalaxySeparation2015,
  title = {Star/Galaxy Separation at Faint Magnitudes: Application to a Simulated {{Dark Energy Survey}}},
  shorttitle = {Star/Galaxy Separation at Faint Magnitudes},
  author = {Soumagnac, M. T. and Abdalla, F. B. and Lahav, O. and Kirk, D. and Sevilla, I. and Bertin, E. and Rowe, B. T. P. and Annis, J. and Busha, M. T. and Da Costa, L. N. and Frieman, J. A. and Gaztanaga, E. and Jarvis, M. and Lin, H. and Percival, W. J. and Santiago, B. X. and Sabiu, C. G. and Wechsler, R. H. and Wolz, L. and Yanny, B.},
  year = {2015},
  month = jun,
  journal = {\mnras},
  volume = {450},
  number = {1},
  pages = {666--680},
  issn = {0035-8711, 1365-2966},
  doi = {10.1093/mnras/stu1410},
  langid = {english}
}

@article{clarkeIdentifyingGalaxiesQuasars2020,
  title = {Identifying Galaxies, Quasars, and Stars with Machine Learning: A New Catalogue of Classifications for 111 Million {{SDSS}} Sources without Spectra},
  shorttitle = {Identifying Galaxies, Quasars, and Stars with Machine Learning},
  author = {Clarke, A. O. and Scaife, A. M. M. and Greenhalgh, R. and Griguta, V.},
  year = {2020},
  month = jul,
  journal = {\aap},
  volume = {639},
  eprint = {1909.10963},
  eprinttype = {arxiv},
  pages = {A84},
  issn = {0004-6361, 1432-0746},
  doi = {10.1051/0004-6361/201936770},
  abstract = {We used 3.1 million spectroscopically labelled sources from the Sloan Digital Sky Survey (SDSS) to train an optimised random forest classifier using photometry from the SDSS and the Widefield Infrared Survey Explorer (WISE). We applied this machine learning model to 111 million previously unlabelled sources from the SDSS photometric catalogue which did not have existing spectroscopic observations. Our new catalogue contains 50.4 million galaxies, 2.1 million quasars, and 58.8 million stars. We provide individual classification probabilities for each source, with 6.7 million galaxies (13\%), 0.33 million quasars (15\%), and 41.3 million stars (70\%) having classification probabilities greater than 0.99; and 35.1 million galaxies (70\%), 0.72 million quasars (34\%), and 54.7 million stars (93\%) having classification probabilities greater than 0.9. Precision, Recall, and F1 score were determined as a function of selected features and magnitude error. We investigate the effect of class imbalance on our machine learning model and discuss the implications of transfer learning for populations of sources at fainter magnitudes than the training set. We used a non-linear dimension reduction technique, Uniform Manifold Approximation and Projection (UMAP), in unsupervised, semi-supervised, and fully-supervised schemes to visualise the separation of galaxies, quasars, and stars in a two-dimensional space. When applying this algorithm to the 111 million sources without spectra, it is in strong agreement with the class labels applied by our random forest model.},
  archiveprefix = {arXiv},
  keywords = {Astrophysics - Astrophysics of Galaxies},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\IPEV8W79\\Clarke et al. - 2020 - Identifying galaxies, quasars, and stars with mach.pdf;C\:\\Users\\sidch\\Zotero\\storage\\Y2WPE9GI\\1909.html}
}

@article{dielemanRotationinvariantConvolutionalNeural2015,
  title = {Rotation-Invariant Convolutional Neural Networks for Galaxy Morphology Prediction},
  author = {Dieleman, Sander and Willett, Kyle W. and Dambre, Joni},
  year = {2015},
  month = jun,
  journal = {\mnras},
  volume = {450},
  number = {2},
  pages = {1441--1459},
  issn = {1365-2966, 0035-8711},
  doi = {10.1093/mnras/stv632},
  langid = {english},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\G3E3H36R\\Dieleman et al. - 2015 - Rotation-invariant convolutional neural networks f.pdf}
}

@article{dominguezsanchezImprovingGalaxyMorphologies2018,
  title = {Improving Galaxy Morphologies for {{SDSS}} with {{Deep Learning}}},
  author = {Dom{\'i}nguez S{\'a}nchez, H and {Huertas-Company}, M and Bernardi, M and Tuccillo, D and Fischer, J L},
  year = {2018},
  month = may,
  journal = {\mnras},
  volume = {476},
  number = {3},
  pages = {3661--3676},
  issn = {0035-8711, 1365-2966},
  doi = {10.1093/mnras/sty338},
  abstract = {Abstract             We present a morphological catalogue for {$\sim$}670\,000 galaxies in the Sloan Digital Sky Survey in two flavours: T-type, related to the Hubble sequence, and Galaxy Zoo 2 (GZ2 hereafter) classification scheme. By combining accurate existing visual classification catalogues with machine learning, we provide the largest and most accurate morphological catalogue up to date. The classifications are obtained with Deep Learning algorithms using Convolutional Neural Networks (CNNs). We use two visual classification catalogues, GZ2 and Nair \& Abraham (2010), for training CNNs with colour images in order to obtain T-types and a series of GZ2 type questions (disc/features, edge-on galaxies, bar signature, bulge prominence, roundness, and mergers). We also provide an additional probability enabling a separation between pure elliptical (E) from S0, where the T-type model is not so efficient. For the T-type, our results show smaller offset and scatter than previous models trained with support vector machines. For the GZ2 type questions, our models have large accuracy (\&gt;97\,per\,cent), precision and recall values (\&gt;90\,per\,cent), when applied to a test sample with the same characteristics as the one used for training. The catalogue is publicly released with the paper.},
  langid = {english}
}

@article{miyazakiSubaruPrimeFocus2002,
  title = {Subaru {{Prime Focus Camera}} \textemdash{} {{Suprime}}-{{Cam}}},
  author = {Miyazaki, Satoshi and Komiyama, Yutaka and Sekiguchi, Maki and Okamura, Sadanori and Doi, Mamoru and Furusawa, Hisanori and Hamabe, Masaru and Imi, Katsumi and Kimura, Masahiko and Nakata, Fumiaki and Okada, Norio and Ouchi, Masami and Shimasaku, Kazuhiro and Yagi, Masafumi and Yasuda, Naoki},
  year = {2002},
  month = dec,
  journal = {\pasj},
  volume = {54},
  number = {6},
  pages = {833--853},
  issn = {0004-6264, 2053-051X},
  doi = {10.1093/pasj/54.6.833},
  langid = {english},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\MKZBQJ5J\\Miyazaki et al. - 2002 - Subaru Prime Focus Camera — Suprime-Cam.pdf}
}

@article{abrahamDetectionBarsGalaxies2018,
  title = {Detection of Bars in Galaxies Using a Deep Convolutional Neural Network},
  author = {Abraham, Sheelu and Aniyan, A K and Kembhavi, Ajit K and Philip, N S and Vaghmare, Kaustubh},
  year = {2018},
  month = jun,
  journal = {\mnras},
  volume = {477},
  number = {1},
  pages = {894--903},
  issn = {0035-8711, 1365-2966},
  doi = {10.1093/mnras/sty627},
  langid = {english}
}

@article{abrahamPhotometricCatalogueQuasars2012,
  title = {A Photometric Catalogue of Quasars and Other Point Sources in the {{Sloan Digital Sky Survey}}: A Photometric Catalogue},
  shorttitle = {A Photometric Catalogue of Quasars and Other Point Sources in the {{Sloan Digital Sky Survey}}},
  author = {Abraham, Sheelu and Philip, Ninan Sajeeth and Kembhavi, Ajit and Wadadekar, Yogesh G. and Sinha, Rita},
  year = {2012},
  month = jan,
  journal = {\mnras},
  volume = {419},
  number = {1},
  pages = {80--94},
  issn = {00358711},
  doi = {10.1111/j.1365-2966.2011.19674.x},
  langid = {english},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\RKT5H5PJ\\Abraham et al. - 2012 - A photometric catalogue of quasars and other point.pdf}
}

@article{philipDifferenceBoostingNeural2002,
  title = {A Difference Boosting Neural Network for Automated Star-Galaxy Classification},
  author = {Philip, N. S. and Wadadekar, Y. and Kembhavi, A. and Joseph, K. B.},
  year = {2002},
  month = apr,
  journal = {\aap},
  volume = {385},
  number = {3},
  pages = {1119--1126},
  issn = {0004-6361, 1432-0746},
  doi = {10.1051/0004-6361:20020219}
}

@article{ahumadaSixteenthDataRelease2020,
  title = {The 16th {{Data Release}} of the {{Sloan Digital Sky Surveys}}: {{First Release}} from the {{APOGEE-2 Southern Survey}} and {{Full Release}} of {{eBOSS Spectra}}},
  shorttitle = {The 16th {{Data Release}} of the {{Sloan Digital Sky Surveys}}},
  author = {Ahumada, Romina and Prieto, Carlos Allende and Almeida, Andr{\'e}s and Anders, Friedrich and Anderson, Scott F. and Andrews, Brett H. and Anguiano, Borja and Arcodia, Riccardo and Armengaud, Eric and Aubert, Marie and Avila, Santiago and {Avila-Reese}, Vladimir and Badenes, Carles and Balland, Christophe and Barger, Kat and {Barrera-Ballesteros}, Jorge K. and Basu, Sarbani and Bautista, Julian and Beaton, Rachael L. and Beers, Timothy C. and Benavides, B. Izamar T. and Bender, Chad F. and Bernardi, Mariangela and Bershady, Matthew and Beutler, Florian and Bidin, Christian Moni and Bird, Jonathan and Bizyaev, Dmitry and Blanc, Guillermo A. and Blanton, Michael R. and Boquien, M{\'e}d{\'e}ric and Borissova, Jura and Bovy, Jo and Brandt, W. N. and Brinkmann, Jonathan and Brownstein, Joel R. and Bundy, Kevin and Bureau, Martin and Burgasser, Adam and Burtin, Etienne and {Cano-D{\'i}az}, Mariana and Capasso, Raffaella and Cappellari, Michele and Carrera, Ricardo and Chabanier, Sol{\`e}ne and Chaplin, William and Chapman, Michael and Cherinka, Brian and Chiappini, Cristina and Doohyun Choi, Peter and Chojnowski, S. Drew and Chung, Haeun and Clerc, Nicolas and Coffey, Damien and Comerford, Julia M. and Comparat, Johan and {da Costa}, Luiz and Cousinou, Marie-Claude and Covey, Kevin and Crane, Jeffrey D. and Cunha, Katia and Ilha, Gabriele da Silva and Dai, Yu Sophia and Damsted, Sanna B. and Darling, Jeremy and Davidson, Jr., James W. and Davies, Roger and Dawson, Kyle and De, Nikhil and {de la Macorra}, Axel and De Lee, Nathan and Queiroz, Anna B{\'a}rbara de Andrade and Deconto Machado, Alice and {de la Torre}, Sylvain and Dell'Agli, Flavia and {du Mas des Bourboux}, H{\'e}lion and {Diamond-Stanic}, Aleksandar M. and Dillon, Sean and Donor, John and Drory, Niv and Duckworth, Chris and Dwelly, Tom and Ebelke, Garrett and Eftekharzadeh, Sarah and Davis Eigenbrot, Arthur and Elsworth, Yvonne P. and Eracleous, Mike and Erfanianfar, Ghazaleh and Escoffier, Stephanie and Fan, Xiaohui and Farr, Emily and {Fern{\'a}ndez-Trincado}, Jos{\'e} G. and Feuillet, Diane and Finoguenov, Alexis and Fofie, Patricia and {Fraser-McKelvie}, Amelia and Frinchaboy, Peter M. and Fromenteau, Sebastien and Fu, Hai and Galbany, Llu{\'i}s and Garcia, Rafael A. and {Garc{\'i}a-Hern{\'a}ndez}, D. A. and Oehmichen, Luis Alberto Garma and Ge, Junqiang and Maia, Marcio Antonio Geimba and Geisler, Doug and Gelfand, Joseph and Goddy, Julian and {Gonzalez-Perez}, Violeta and Grabowski, Kathleen and Green, Paul and Grier, Catherine J. and Guo, Hong and Guy, Julien and Harding, Paul and Hasselquist, Sten and Hawken, Adam James and Hayes, Christian R. and Hearty, Fred and Hekker, S. and Hogg, David W. and Holtzman, Jon A. and Horta, Danny and Hou, Jiamin and Hsieh, Bau-Ching and Huber, Daniel and Hunt, Jason A. S. and Chitham, J. Ider and Imig, Julie and Jaber, Mariana and Angel, Camilo Eduardo Jimenez and Johnson, Jennifer A. and Jones, Amy M. and J{\"o}nsson, Henrik and Jullo, Eric and Kim, Yerim and Kinemuchi, Karen and Kirkpatrick, IV, Charles C. and Kite, George W. and Klaene, Mark and Kneib, Jean-Paul and Kollmeier, Juna A. and Kong, Hui and Kounkel, Marina and Krishnarao, Dhanesh and Lacerna, Ivan and Lan, Ting-Wen and Lane, Richard R. and Law, David R. and Le Goff, Jean-Marc and Leung, Henry W. and Lewis, Hannah and Li, Cheng and Lian, Jianhui and Lin, Lihwai and Long, Dan and {Longa-Pe{\~n}a}, Pen{\'e}lope and Lundgren, Britt and Lyke, Brad W. and Ted Mackereth, J. and MacLeod, Chelsea L. and Majewski, Steven R. and Manchado, Arturo and Maraston, Claudia and Martini, Paul and Masseron, Thomas and Masters, Karen L. and Mathur, Savita and McDermid, Richard M. and Merloni, Andrea and Merrifield, Michael and M{\'e}sz{\'a}ros, Szabolcs and Miglio, Andrea and Minniti, Dante and Minsley, Rebecca and Miyaji, Takamitsu and Mohammad, Faizan Gohar and Mosser, Benoit and Mueller, Eva-Maria and Muna, Demitri and {Mu{\~n}oz-Guti{\'e}rrez}, Andrea and Myers, Adam D. and Nadathur, Seshadri and Nair, Preethi and Nandra, Kirpal and {do Nascimento}, Janaina Correa and Nevin, Rebecca Jean and Newman, Jeffrey A. and Nidever, David L. and Nitschelm, Christian and Noterdaeme, Pasquier and O'Connell, Julia E. and Olmstead, Matthew D. and Oravetz, Daniel and Oravetz, Audrey and Osorio, Yeisson and Pace, Zachary J. and Padilla, Nelson and {Palanque-Delabrouille}, Nathalie and Palicio, Pedro A. and Pan, Hsi-An and Pan, Kaike and Parker, James and Paviot, Romain and Peirani, Sebastien and Ram{\'r}ez, Karla Pe{\~n}a and Penny, Samantha and Percival, Will J. and {Perez-Fournon}, Ismael and {P{\'e}rez-R{\`a}fols}, Ignasi and Petitjean, Patrick and Pieri, Matthew M. and Pinsonneault, Marc and Poovelil, Vijith Jacob and Povick, Joshua Tyler and Prakash, Abhishek and {Price-Whelan}, Adrian M. and Raddick, M. Jordan and Raichoor, Anand and Ray, Amy and Rembold, Sandro Barboza and Rezaie, Mehdi and Riffel, Rogemar A. and Riffel, Rog{\'e}rio and Rix, Hans-Walter and Robin, Annie C. and {Roman-Lopes}, A. and {Rom{\'a}n-Z{\'u}{\~n}iga}, Carlos and Rose, Benjamin and Ross, Ashley J. and Rossi, Graziano and Rowlands, Kate and Rubin, Kate H. R. and Salvato, Mara and S{\'a}nchez, Ariel G. and {S{\'a}nchez-Menguiano}, Laura and {S{\'a}nchez-Gallego}, Jos{\'e} R. and Sayres, Conor and Schaefer, Adam and Schiavon, Ricardo P. and Schimoia, Jaderson S. and Schlafly, Edward and Schlegel, David and Schneider, Donald P. and Schultheis, Mathias and Schwope, Axel and Seo, Hee-Jong and Serenelli, Aldo and Shafieloo, Arman and Shamsi, Shoaib Jamal and Shao, Zhengyi and Shen, Shiyin and Shetrone, Matthew and Shirley, Raphael and Aguirre, V{\'i}ctor Silva and Simon, Joshua D. and Skrutskie, M. F. and Slosar, An{\v z}e and Smethurst, Rebecca and Sobeck, Jennifer and Sodi, Bernardo Cervantes and Souto, Diogo and Stark, David V. and Stassun, Keivan G. and Steinmetz, Matthias and Stello, Dennis and Stermer, Julianna and {Storchi-Bergmann}, Thaisa and Streblyanska, Alina and Stringfellow, Guy S. and Stutz, Amelia and Su{\'a}rez, Genaro and Sun, Jing and {Taghizadeh-Popp}, Manuchehr and Talbot, Michael S. and Tayar, Jamie and Thakar, Aniruddha R. and Theriault, Riley and Thomas, Daniel and Thomas, Zak C. and Tinker, Jeremy and Tojeiro, Rita and Toledo, Hector Hernandez and Tremonti, Christy A. and Troup, Nicholas W. and Tuttle, Sarah and {Unda-Sanzana}, Eduardo and Valentini, Marica and {Vargas-Gonz{\'a}lez}, Jaime and {Vargas-Maga{\~n}a}, Mariana and {V{\'a}zquez-Mata}, Jose Antonio and Vivek, M. and Wake, David and Wang, Yuting and Weaver, Benjamin Alan and Weijmans, Anne-Marie and Wild, Vivienne and Wilson, John C. and Wilson, Robert F. and Wolthuis, Nathan and {Wood-Vasey}, W. M. and Yan, Renbin and Yang, Meng and Y{\`e}che, Christophe and Zamora, Olga and Zarrouk, Pauline and Zasowski, Gail and Zhang, Kai and Zhao, Cheng and Zhao, Gongbo and Zheng, Zheng and Zheng, Zheng and Zhu, Guangtun and Zou, Hu},
  year = {2020},
  month = jul,
  journal = {\apjs},
  volume = {249},
  pages = {3},
  issn = {0067-0049},
  doi = {10.3847/1538-4365/ab929e},
  abstract = {This paper documents the 16th data release (DR16) from the Sloan Digital Sky Surveys (SDSS), the fourth and penultimate from the fourth phase (SDSS-IV). This is the first release of data from the Southern Hemisphere survey of the Apache Point Observatory Galactic Evolution Experiment 2 (APOGEE-2); new data from APOGEE-2 North are also included. DR16 is also notable as the final data release for the main cosmological program of the Extended Baryon Oscillation Spectroscopic Survey (eBOSS), and all raw and reduced spectra from that project are released here. DR16 also includes all the data from the Time Domain Spectroscopic Survey and new data from the SPectroscopic IDentification of ERosita Survey programs, both of which were co-observed on eBOSS plates. DR16 has no new data from the Mapping Nearby Galaxies at Apache Point Observatory (MaNGA) survey (or the MaNGA Stellar Library "MaStar"). We also preview future SDSS-V operations (due to start in 2020), and summarize plans for the final SDSS-IV data release (DR17).},
  keywords = {1174,1378,1624,1630,2002,786,83,Astronomy databases,Astrophysics - Astrophysics of Galaxies,Astrophysics - Cosmology and Nongalactic Astrophysics,Astrophysics - Instrumentation and Methods for Astrophysics,Galactic abundances,Infrared astronomy,Optical telescopes,Redshift surveys,Stellar properties,Stellar spectral lines},
  annotation = {ADS Bibcode: 2020ApJS..249....3A}
}

@article{dawsonSDSSIVExtendedBaryon2016,
  title = {The {{SDSS}}-{{IV}} Extended {{Baryon Oscillation Spectroscopic Survey}}: {{Overview}} and {{Early Data}}},
  shorttitle = {The {{SDSS}}-{{IV}} Extended {{Baryon Oscillation Spectroscopic Survey}}},
  author = {Dawson, Kyle S. and Kneib, Jean-Paul and Percival, Will J. and Alam, Shadab and Albareti, Franco D. and Anderson, Scott F. and Armengaud, Eric and Aubourg, Eric and Bailey, Stephen and Bautista, Julian E. and Berlind, Andreas A. and Bershady, Matthew A. and Beutler, Florian and Bizyaev, Dmitry and Blanton, Michael R. and Blomqvist, Michael and Bolton, Adam S. and Bovy, Jo and Brandt, W. N. and Brinkmann, Jon and Brownstein, Joel R. and Burtin, Etienne and Busca, N. G. and Cai, Zheng and Chuang, Chia-Hsun and Clerc, Nicolas and Comparat, Johan and Cope, Frances and Croft, Rupert A. C. and {Cruz-Gonzalez}, Irene and {da Costa}, Luiz N. and Cousinou, Marie-Claude and Darling, Jeremy and {de la Macorra}, Axel and {de la Torre}, Sylvain and Delubac, Timothee and des Bourboux, Helion du Mas and Dwelly, Tom and Ealet, Anne and Eisenstein, Daniel J. and Eracleous, Michael and Escoffier, S. and Fan, Xiaohui and Finoguenov, Alexis and {Font-Ribera}, Andreu and Frinchaboy, Peter and Gaulme, Patrick and Georgakakis, Antonis and Green, Paul and Guo, Hong and Guy, Julien and Ho, Shirley and Holder, Diana and Huehnerhoff, Joe and Hutchinson, Timothy and Jing, Yipeng and Jullo, Eric and Kamble, Vikrant and Kinemuchi, Karen and Kirkby, David and Kitaura, Francisco-Shu and Klaene, Mark A. and Laher, Russ R. and Lang, Dustin and Laurent, Pierre and Goff, Jean-Marc Le and Li, Cheng and Liang, Yu and Lima, Marcos and Lin, Qiufan and Lin, Weipeng and Lin, Yen-Ting and Long, Daniel C. and Lundgren, Britt and MacDonald, Nicholas and Maia, Marcio Antonio Geimba and Malanushenko, Elena and Malanushenko, Viktor and Mariappan, Vivek and McBride, Cameron K. and McGreer, Ian D. and Menard, Brice and Merloni, Andrea and Meza, Andres and {Montero-Dorta}, Antonio D. and Muna, Demitri and Myers, Adam D. and Nandra, Kirpal and Naugle, Tracy and Newman, Jeffrey A. and Noterdaeme, Pasquier and Nugent, Peter and Ogando, Ricardo and Olmstead, Matthew D. and Oravetz, Audrey and Oravetz, Daniel J. and Padmanabhan, Nikhil and {Palanque-Delabrouille}, Nathalie and Pan, Kaike and Parejko, John K. and Paris, Isabelle and Peacock, John A. and Petitjean, Patrick and Pieri, Matthew M. and Pisani, Alice and Prada, Francisco and Prakash, Abhishek and Raichoor, Anand and Reid, Beth and Rich, James and Ridl, Jethro and {Rodriguez-Torres}, Sergio and Rosell, Aurelio Carnero and Ross, Ashley J. and Rossi, Graziano and Ruan, John and Salvato, Mara and Sayres, Conor and Schneider, Donald P. and Schlegel, David J. and Seljak, Uros and Seo, Hee-Jong and Sesar, Branimir and Shandera, Sarah and Shu, Yiping and Slosar, Anze and Sobreira, Flavia and Streblyanska, Alina and Suzuki, Nao and Tao, Charling and Taylor, Donna and Tinker, Jeremy L. and Tojeiro, Rita and {Vargas-Magana}, Mariana and Wang, Yuting and Weaver, Benjamin A. and Weinberg, David H. and White, Martin and {Wood-Vasey}, W. M. and Yeche, Christophe and Zhai, Zhongxu and Zhao, Cheng and Zhao, Gong-bo and Zheng, Zheng and Zhu, Guangtun Ben and Zou, Hu},
  year = {2016},
  month = feb,
  volume = {151},
  pages = {44},
  issn = {1538-3881},
  doi = {10.3847/0004-6256/151/2/44},
  abstract = {The Extended Baryon Oscillation Spectroscopic Survey (eBOSS) will conduct novel cosmological observations using the BOSS spectrograph at Apache Point Observatory. Observations will be simultaneous with the Time Domain Spectroscopic Survey (TDSS) designed for variability studies and the Spectroscopic Identification of eROSITA Sources (SPIDERS) program designed for studies of X-ray sources. eBOSS will use four different tracers to measure the distance-redshift relation with baryon acoustic oscillations (BAO). Using more than 250,000 new, spectroscopically confirmed luminous red galaxies at a median redshift z=0.72, we project that eBOSS will yield measurements of \$d\_A(z)\$ to an accuracy of 1.2\% and measurements of H(z) to 2.1\% when combined with the z{$>$}0.6 sample of BOSS galaxies. With \textasciitilde 195,000 new emission line galaxy redshifts, we expect BAO measurements of \$d\_A(z)\$ to an accuracy of 3.1\% and H(z) to 4.7\% at an effective redshift of z= 0.87. A sample of more than 500,000 spectroscopically-confirmed quasars will provide the first BAO distance measurements over the redshift range 0.9},
  archiveprefix = {arXiv},
  eprint = {1508.04473},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\LKGAUQLC\\Dawson et al. - 2016 - The SDSS-IV extended Baryon Oscillation Spectrosco.pdf;C\:\\Users\\sidch\\Zotero\\storage\\YLL9IANH\\1508.html},
  journal = {\aj},
  keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics},
  number = {2}
}

@article{disantoPhotometricRedshiftEstimation2018,
  title = {Photometric Redshift Estimation via Deep Learning: {{Generalized}} and Pre-Classification-Less, Image Based, Fully Probabilistic Redshifts},
  shorttitle = {Photometric Redshift Estimation via Deep Learning},
  author = {D'Isanto, A. and Polsterer, K. L.},
  year = {2018},
  month = jan,
  volume = {609},
  pages = {A111},
  issn = {0004-6361, 1432-0746},
  doi = {10.1051/0004-6361/201731326},
  abstract = {Context.               The need to analyze the available large synoptic multi-band surveys drives the development of new data-analysis methods. Photometric redshift estimation is one field of application where such new methods improved the results, substantially. Up to now, the vast majority of applied redshift estimation methods have utilized photometric features.                                         Aims.               We aim to develop a method to derive probabilistic photometric redshift directly from multi-band imaging data, rendering pre-classification of objects and feature extraction obsolete.                                         Methods.               A modified version of a deep convolutional network was combined with a mixture density network. The estimates are expressed as Gaussian mixture models representing the probability density functions (PDFs) in the redshift space. In addition to the traditional scores, the continuous ranked probability score (CRPS) and the probability integral transform (PIT) were applied as performance criteria. We have adopted a feature based random forest and a plain mixture density network to compare performances on experiments with data from SDSS (DR9).                                         Results.               We show that the proposed method is able to predict redshift PDFs independently from the type of source, for example galaxies, quasars or stars. Thereby the prediction performance is better than both presented reference methods and is comparable to results from the literature.                                         Conclusions.               The presented method is extremely general and allows us to solve of any kind of probabilistic regression problems based on imaging data, for example estimating metallicity or star formation rate of galaxies. This kind of methodology is tremendously important for the next generation of surveys.},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\LK7XV8RC\\D’Isanto and Polsterer - 2018 - Photometric redshift estimation via deep learning.pdf},
  journal = {\aap}
}

@article{fukugitaSloanDigitalSky1996,
  title = {The {{Sloan Digital Sky Survey Photometric System}}},
  author = {Fukugita, M. and Ichikawa, T. and Gunn, J. E. and Doi, M. and Shimasaku, K. and Schneider, D. P.},
  year = {1996},
  month = apr,
  volume = {111},
  pages = {1748},
  issn = {00046256},
  doi = {10.1086/117915},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\LG5MUGAJ\\Fukugita et al. - 1996 - The Sloan Digital Sky Survey Photometric System.pdf},
  journal = {\aj}
}

@article{ghoshGalaxyMorphologyNetwork2020,
  title = {Galaxy {{Morphology Network}}: {{A Convolutional Neural Network Used}} to {{Study Morphology}} and {{Quenching}} in \$\textbackslash sim 100,000\$ {{SDSS}} and \$\textbackslash sim 20,000\$ {{CANDELS Galaxies}}},
  shorttitle = {Galaxy {{Morphology Network}}},
  author = {Ghosh, Aritra and Urry, C. Megan and Wang, Zhengdong and Schawinski, Kevin and Turp, Dennis and Powell, Meredith C.},
  year = {2020},
  month = jun,
  volume = {895},
  pages = {112},
  issn = {1538-4357},
  doi = {10.3847/1538-4357/ab8a47},
  abstract = {We examine morphology-separated color-mass diagrams to study the quenching of star formation in \$\textbackslash sim 100,000\$ (\$z\textbackslash sim0\$) Sloan Digital Sky Survey (SDSS) and \$\textbackslash sim 20,000\$ (\$z\textbackslash sim1\$) Cosmic Assembly Near-Infrared Deep Extragalactic Legacy Survey (CANDELS) galaxies. To classify galaxies morphologically, we developed Galaxy Morphology Network (GaMorNet), a convolutional neural network that classifies galaxies according to their bulge-to-total light ratio. GaMorNet does not need a large training set of real data and can be applied to data sets with a range of signal-to-noise ratios and spatial resolutions. GaMorNet's source code as well as the trained models are made public as part of this work ( http://www.astro.yale.edu/aghosh/gamornet.html ). We first trained GaMorNet on simulations of galaxies with a bulge and a disk component and then transfer learned using \$\textbackslash sim25\textbackslash\%\$ of each data set to achieve misclassification rates of \$\textbackslash lesssim5\textbackslash\%\$. The misclassified sample of galaxies is dominated by small galaxies with low signal-to-noise ratios. Using the GaMorNet classifications, we find that bulge- and disk-dominated galaxies have distinct color-mass diagrams, in agreement with previous studies. For both SDSS and CANDELS galaxies, disk-dominated galaxies peak in the blue cloud, across a broad range of masses, consistent with the slow exhaustion of star-forming gas with no rapid quenching. A small population of red disks is found at high mass (\$\textbackslash sim14\textbackslash\%\$ of disks at \$z\textbackslash sim0\$ and \$2\textbackslash\%\$ of disks at \$z \textbackslash sim 1\$). In contrast, bulge-dominated galaxies are mostly red, with much smaller numbers down toward the blue cloud, suggesting rapid quenching and fast evolution across the green valley. This inferred difference in quenching mechanism is in agreement with previous studies that used other morphology classification techniques on much smaller samples at \$z\textbackslash sim0\$ and \$z\textbackslash sim1\$.},
  archiveprefix = {arXiv},
  eprint = {2006.14639},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\Z7KDQXW2\\Ghosh et al. - 2020 - Galaxy Morphology Network A Convolutional Neural .pdf;C\:\\Users\\sidch\\Zotero\\storage\\K5URGBV9\\2006.html},
  journal = {\apj},
  keywords = {Astrophysics - Astrophysics of Galaxies,Astrophysics - Instrumentation and Methods for Astrophysics},
  number = {2}
}

@article{hicksonSystematicPropertiesCompact1982,
  title = {Systematic Properties of Compact Groups of Galaxies},
  author = {Hickson, P.},
  year = {1982},
  month = apr,
  volume = {255},
  pages = {382},
  issn = {0004-637X, 1538-4357},
  doi = {10.1086/159838},
  journal = {\apj},
  language = {en}
}

@article{kimStarGalaxyClassification2017,
  title = {Star\textendash Galaxy Classification Using Deep Convolutional Neural Networks},
  author = {Kim, Edward J. and Brunner, Robert J.},
  year = {2017},
  month = feb,
  volume = {464},
  pages = {4463--4475},
  issn = {0035-8711, 1365-2966},
  doi = {10.1093/mnras/stw2672},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\VLDPL6CQ\\Kim and Brunner - 2017 - Star–galaxy classification using deep convolutiona.pdf},
  journal = {\mnras},
  language = {en},
  number = {4}
}

@article{menouMorphoPhotometricRedshifts2019,
  title = {Morpho-{{Photometric Redshifts}}},
  author = {Menou, Kristen},
  year = {2019},
  month = nov,
  volume = {489},
  pages = {4802--4808},
  issn = {0035-8711, 1365-2966},
  doi = {10.1093/mnras/stz2477},
  abstract = {Machine learning (ML) is a standard approach for estimating the redshifts of galaxies when only photometric information is available. ML photo-z solutions have traditionally ignored the morphological information available in galaxy images or partly included it in the form of hand-crafted features, with mixed results. We train a morphology-aware photometric redshift machine using modern deep learning tools. It uses a custom architecture that jointly trains on galaxy fluxes, colors and images. Galaxy-integrated quantities are fed to a Multi-Layer Perceptron (MLP) branch while images are fed to a convolutional (convnet) branch that can learn relevant morphological features. This split MLP-convnet architecture, which aims to disentangle strong photometric features from comparatively weak morphological ones, proves important for strong performance: a regular convnet-only architecture, while exposed to all available photometric information in images, delivers comparatively poor performance. We present a cross-validated MLP-convnet model trained on 130,000 SDSS-DR12 galaxies that outperforms a hyperoptimized Gradient Boosting solution (hyperopt+XGBoost), as well as the equivalent MLP-only architecture, on the redshift bias metric. The 4-fold cross-validated MLP-convnet model achieves a bias \$\textbackslash delta z / (1+z) =-0.70 \textbackslash pm 1 \textbackslash times 10\^\{-3\} \$, approaching the performance of a reference ANNZ2 ensemble of 100 distinct models trained on a comparable dataset. The relative performance of the morphology-aware and morphology-blind models indicates that galaxy morphology does improve ML-based photometric redshift estimation.},
  archiveprefix = {arXiv},
  eprint = {1811.06374},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\BI2CZ5FR\\Menou - 2019 - Morpho-Photometric Redshifts.pdf;C\:\\Users\\sidch\\Zotero\\storage\\QMJ3MJQI\\1811.html},
  journal = {\mnras},
  keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics,Astrophysics - Instrumentation and Methods for Astrophysics},
  number = {4}
}

@article{pasquetPhotometricRedshiftsSDSS2019a,
  title = {Photometric Redshifts from {{SDSS}} Images Using a Convolutional Neural Network},
  author = {Pasquet, Johanna and Bertin, E. and Treyer, M. and Arnouts, S. and Fouchez, D.},
  year = {2019},
  month = jan,
  volume = {621},
  pages = {A26},
  issn = {0004-6361, 1432-0746},
  doi = {10.1051/0004-6361/201833617},
  abstract = {We developed a deep convolutional neural network (CNN), used as a classifier, to estimate photometric redshifts and associated probability distribution functions (PDF) for galaxies in the Main Galaxy Sample of the Sloan Digital Sky Survey at               z               \;{$<$} \;0.4. Our method exploits all the information present in the images without any feature extraction. The input data consist of 64 \texttimes{} 64 pixel               ugriz               images centered on the spectroscopic targets, plus the galactic reddening value on the line-of-sight. For training sets of 100k objects or more ({$\geq$}20\% of the database), we reach a dispersion               {$\sigma$}               MAD               \;{$<$} \;0.01, significantly lower than the current best one obtained from another machine learning technique on the same sample. The bias is lower than 10               -4               , independent of photometric redshift. The PDFs are shown to have very good predictive power. We also find that the CNN redshifts are unbiased with respect to galaxy inclination, and that               {$\sigma$}               MAD               decreases with the signal-to-noise ratio (S/N), achieving values below 0.007 for               S               /               N               \;{$>$} \;100, as in the deep stacked region of Stripe 82. We argue that for most galaxies the precision is limited by the S/N of SDSS images rather than by the method. The success of this experiment at low redshift opens promising perspectives for upcoming surveys.},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\9R3IV232\\Pasquet et al. - 2019 - Photometric redshifts from SDSS images using a con.pdf},
  journal = {\aap}
}

@misc{szegedyGoingDeeperConvolutions2014,
  author    = {Christian Szegedy and
               Wei Liu and
               Yangqing Jia and
               Pierre Sermanet and
               Scott E. Reed and
               Dragomir Anguelov and
               Dumitru Erhan and
               Vincent Vanhoucke and
               Andrew Rabinovich},
  title     = {Going Deeper with Convolutions},
  journal   = {CoRR},
  volume    = {abs/1409.4842},
  year      = {2014},
  eprinttype = {arXiv},
  eprint    = {1409.4842},
  timestamp = {Mon, 13 Aug 2018 16:48:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SzegedyLJSRAEVR14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{tanoglidisDeepShadowsSeparatingLow2020,
  title = {{{DeepShadows}}: {{Separating Low Surface Brightness Galaxies}} from {{Artifacts}} Using {{Deep Learning}}},
  shorttitle = {{{DeepShadows}}},
  author = {Tanoglidis, Dimitrios and {\'C}iprijanovi{\'c}, Aleksandra and {Drlica-Wagner}, Alex},
  year = {2020},
  month = nov,
  abstract = {Searches for low-surface-brightness galaxies (LSBGs) in galaxy surveys are plagued by the presence of a large number of artifacts (e.g., objects blended in the diffuse light from stars and galaxies, Galactic cirrus, star-forming regions in the arms of spiral galaxies, etc.) that have to be rejected through time consuming visual inspection. In future surveys, which are expected to collect hundreds of petabytes of data and detect billions of objects, such an approach will not be feasible. We investigate the use of convolutional neural networks (CNNs) for the problem of separating LSBGs from artifacts in survey images. We take advantage of the fact that, for the first time, we have available a large number of labeled LSBGs and artifacts from the Dark Energy Survey, that we use to train, validate, and test a CNN model. That model, which we call DeepShadows, achieves a test accuracy of \$92.0 \textbackslash\%\$, a significant improvement relative to feature-based machine learning models. We also study the ability to use transfer learning to adapt this model to classify objects from the deeper Hyper-Suprime-Cam survey, and we show that after the model is retrained on a very small sample from the new survey, it can reach an accuracy of \$87.6\textbackslash\%\$. These results demonstrate that CNNs offer a very promising path in the quest to study the low-surface-brightness universe.},
  archiveprefix = {arXiv},
  eprint = {2011.12437},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\LFMWXI43\\Tanoglidis et al. - 2020 - DeepShadows Separating Low Surface Brightness Gal.pdf;C\:\\Users\\sidch\\Zotero\\storage\\L7CXAG8V\\2011.html},
  journal = {arXiv:2011.12437 [astro-ph]},
  keywords = {Astrophysics - Astrophysics of Galaxies,Astrophysics - Cosmology and Nongalactic Astrophysics,Astrophysics - Instrumentation and Methods for Astrophysics,Computer Science - Computer Vision and Pattern Recognition},
  primaryclass = {astro-ph}
}


@article{doiPHOTOMETRICRESPONSEFUNCTIONS2010,
  title = {{{PHOTOMETRIC RESPONSE FUNCTIONS OF THE SLOAN DIGITAL SKY SURVEY IMAGER}}},
  author = {Doi, Mamoru and Tanaka, Masayuki and Fukugita, Masataka and Gunn, James E. and Yasuda, Naoki and Ivezi{\'c}, {\v Z}eljko and Brinkmann, Jon and {de Haars}, Ernst and Kleinman, S. J. and Krzesinski, Jurek and Leger, R. French},
  year = {2010},
  month = apr,
  journal = {\aj},
  volume = {139},
  number = {4},
  pages = {1628--1648},
  issn = {0004-6256, 1538-3881},
  doi = {10.1088/0004-6256/139/4/1628},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\GJST5B8Z\\Doi et al. - 2010 - PHOTOMETRIC RESPONSE FUNCTIONS OF THE SLOAN DIGITA.pdf}
}

@article{gunnSloanDigitalSky1998,
  title = {The {{Sloan Digital Sky Survey Photometric Camera}}},
  author = {Gunn, J. E. and Carr, M. and Rockosi, C. and Sekiguchi, M. and Berry, K. and Elms, B. and {de Haas}, E. and Ivezi{\'c}, {\v Z}. and Knapp, G. and Lupton, R. and Pauls, G. and Simcoe, R. and Hirsch, R. and Sanford, D. and Wang, S. and York, D. and Harris, F. and Annis, J. and Bartozek, L. and Boroski, W. and Bakken, J. and Haldeman, M. and Kent, S. and Holm, S. and Holmgren, D. and Petravick, D. and Prosapio, A. and Rechenmacher, R. and Doi, M. and Fukugita, M. and Shimasaku, K. and Okada, N. and Hull, C. and Siegmund, W. and Mannery, E. and Blouke, M. and Heidtman, D. and Schneider, D. and Lucinio, R. and Brinkman, J.},
  year = {1998},
  month = dec,
  journal = {\aj},
  volume = {116},
  number = {6},
  pages = {3040--3081},
  issn = {00046256},
  doi = {10.1086/300645},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\KNIX98VN\\Gunn et al. - 1998 - The Sloan Digital Sky Survey Photometric Camera.pdf}
}

@article{gunnTelescopeSloanDigital2006,
  title = {The 2.5 m {{Telescope}} of the {{Sloan Digital Sky Survey}}},
  author = {Gunn, James E. and Siegmund, Walter A. and Mannery, Edward J. and Owen, Russell E. and Hull, Charles L. and Leger, R. French and Carey, Larry N. and Knapp, Gillian R. and York, Donald G. and Boroski, William N. and Kent, Stephen M. and Lupton, Robert H. and Rockosi, Constance M. and Evans, Michael L. and Waddell, Patrick and Anderson, John E. and Annis, James and Barentine, John C. and Bartoszek, Larry M. and Bastian, Steven and Bracker, Stephen B. and Brewington, Howard J. and Briegel, Charles I. and Brinkmann, Jon and Brown, Yorke J. and Carr, Michael A. and Czarapata, Paul C. and Drennan, Craig C. and Dombeck, Thomas and Federwitz, Glenn R. and Gillespie, Bruce A. and Gonzales, Carlos and Hansen, Sten U. and Harvanek, Michael and Hayes, Jeffrey and Jordan, Wendell and Kinney, Ellyne and Klaene, Mark and Kleinman, S. J. and Kron, Richard G. and Kresinski, Jurek and Lee, Glenn and Limmongkol, Siriluk and Lindenmeyer, Carl W. and Long, Daniel C. and Loomis, Craig L. and McGehee, Peregrine M. and Mantsch, Paul M. and Neilsen, Jr., Eric H. and Neswold, Richard M. and Newman, Peter R. and Nitta, Atsuko and Peoples, Jr., John and Pier, Jeffrey R. and Prieto, Peter S. and Prosapio, Angela and Rivetta, Claudio and Schneider, Donald P. and Snedden, Stephanie and Wang, Shu-i},
  year = {2006},
  month = apr,
  journal = {\aj},
  volume = {131},
  number = {4},
  pages = {2332--2359},
  issn = {0004-6256, 1538-3881},
  doi = {10.1086/500975},
  langid = {english},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\3YYJGV4L\\Gunn et al. - 2006 - The 2.5 m Telescope of the Sloan Digital Sky Surve.pdf}
}

@article{smeeMULTIOBJECTFIBERFEDSPECTROGRAPHS2013,
  title = {{{THE MULTI}}-{{OBJECT}}, {{FIBER}}-{{FED SPECTROGRAPHS FOR THE SLOAN DIGITAL SKY SURVEY AND THE BARYON OSCILLATION SPECTROSCOPIC SURVEY}}},
  author = {Smee, Stephen A. and Gunn, James E. and Uomoto, Alan and Roe, Natalie and Schlegel, David and Rockosi, Constance M. and Carr, Michael A. and Leger, French and Dawson, Kyle S. and Olmstead, Matthew D. and Brinkmann, Jon and Owen, Russell and Barkhouser, Robert H. and Honscheid, Klaus and Harding, Paul and Long, Dan and Lupton, Robert H. and Loomis, Craig and Anderson, Lauren and Annis, James and Bernardi, Mariangela and Bhardwaj, Vaishali and Bizyaev, Dmitry and Bolton, Adam S. and Brewington, Howard and Briggs, John W. and Burles, Scott and Burns, James G. and Castander, Francisco Javier and Connolly, Andrew and Davenport, James R. A. and Ebelke, Garrett and Epps, Harland and Feldman, Paul D. and Friedman, Scott D. and Frieman, Joshua and Heckman, Timothy and Hull, Charles L. and Knapp, Gillian R. and Lawrence, David M. and Loveday, Jon and Mannery, Edward J. and Malanushenko, Elena and Malanushenko, Viktor and Merrelli, Aronne James and Muna, Demitri and Newman, Peter R. and Nichol, Robert C. and Oravetz, Daniel and Pan, Kaike and Pope, Adrian C. and Ricketts, Paul G. and Shelden, Alaina and Sandford, Dale and Siegmund, Walter and Simmons, Audrey and Smith, D. Shane and Snedden, Stephanie and Schneider, Donald P. and SubbaRao, Mark and Tremonti, Christy and Waddell, Patrick and York, Donald G.},
  year = {2013},
  month = jul,
  journal = {\aj},
  volume = {146},
  number = {2},
  pages = {32},
  issn = {0004-6256, 1538-3881},
  doi = {10.1088/0004-6256/146/2/32}
}

@article{yorkSloanDigitalSky2000,
  title = {The {{Sloan Digital Sky Survey}}: {{Technical Summary}}},
  shorttitle = {The {{Sloan Digital Sky Survey}}},
  author = {York, Donald G. and Adelman, J. and Anderson, Jr., John E. and Anderson, Scott F. and Annis, James and Bahcall, Neta A. and Bakken, J. A. and Barkhouser, Robert and Bastian, Steven and Berman, Eileen and Boroski, William N. and Bracker, Steve and Briegel, Charlie and Briggs, John W. and Brinkmann, J. and Brunner, Robert and Burles, Scott and Carey, Larry and Carr, Michael A. and Castander, Francisco J. and Chen, Bing and Colestock, Patrick L. and Connolly, A. J. and Crocker, J. H. and Csabai, Istv{\'a}n and Czarapata, Paul C. and Davis, John Eric and Doi, Mamoru and Dombeck, Tom and Eisenstein, Daniel and Ellman, Nancy and Elms, Brian R. and Evans, Michael L. and Fan, Xiaohui and Federwitz, Glenn R. and Fiscelli, Larry and Friedman, Scott and Frieman, Joshua A. and Fukugita, Masataka and Gillespie, Bruce and Gunn, James E. and Gurbani, Vijay K. and {de Haas}, Ernst and Haldeman, Merle and Harris, Frederick H. and Hayes, J. and Heckman, Timothy M. and Hennessy, G. S. and Hindsley, Robert B. and Holm, Scott and Holmgren, Donald J. and Huang, Chi-hao and Hull, Charles and Husby, Don and Ichikawa, Shin-Ichi and Ichikawa, Takashi and Ivezi{\'c}, {\v Z}eljko and Kent, Stephen and Kim, Rita S. J. and Kinney, E. and Klaene, Mark and Kleinman, A. N. and Kleinman, S. and Knapp, G. R. and Korienek, John and Kron, Richard G. and Kunszt, Peter Z. and Lamb, D. Q. and Lee, B. and Leger, R. French and Limmongkol, Siriluk and Lindenmeyer, Carl and Long, Daniel C. and Loomis, Craig and Loveday, Jon and Lucinio, Rich and Lupton, Robert H. and MacKinnon, Bryan and Mannery, Edward J. and Mantsch, P. M. and Margon, Bruce and McGehee, Peregrine and McKay, Timothy A. and Meiksin, Avery and Merelli, Aronne and Monet, David G. and Munn, Jeffrey A. and Narayanan, Vijay K. and Nash, Thomas and Neilsen, Eric and Neswold, Rich and Newberg, Heidi Jo and Nichol, R. C. and Nicinski, Tom and Nonino, Mario and Okada, Norio and Okamura, Sadanori and Ostriker, Jeremiah P. and Owen, Russell and Pauls, A. George and Peoples, John and Peterson, R. L. and Petravick, Donald and Pier, Jeffrey R. and Pope, Adrian and Pordes, Ruth and Prosapio, Angela and Rechenmacher, Ron and Quinn, Thomas R. and Richards, Gordon T. and Richmond, Michael W. and Rivetta, Claudio H. and Rockosi, Constance M. and Ruthmansdorfer, Kurt and Sandford, Dale and Schlegel, David J. and Schneider, Donald P. and Sekiguchi, Maki and Sergey, Gary and Shimasaku, Kazuhiro and Siegmund, Walter A. and Smee, Stephen and Smith, J. Allyn and Snedden, S. and Stone, R. and Stoughton, Chris and Strauss, Michael A. and Stubbs, Christopher and SubbaRao, Mark and Szalay, Alexander S. and Szapudi, Istvan and Szokoly, Gyula P. and Thakar, Anirudda R. and Tremonti, Christy and Tucker, Douglas L. and Uomoto, Alan and Vanden Berk, Dan and Vogeley, Michael S. and Waddell, Patrick and Wang, Shu-i and Watanabe, Masaru and Weinberg, David H. and Yanny, Brian and Yasuda, Naoki},
  year = {2000},
  month = sep,
  volume = {120},
  pages = {1579--1587},
  issn = {00046256},
  doi = {10.1086/301513},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\GCSHFAEP\\York et al. - 2000 - The Sloan Digital Sky Survey Technical Summary.pdf},
  journal = {\aj},
  number = {3}
}


@article{mollerSuperNNovaOpensourceFramework2020,
  title = {{{SuperNNova}}: An Open-Source Framework for {{Bayesian}}, {{Neural Network}} Based Supernova Classification},
  shorttitle = {{{SuperNNova}}},
  author = {M{\"o}ller, Anais and {de Boissi{\`e}re}, Thibault},
  year = {2020},
  month = jan,
  volume = {491},
  pages = {4277--4293},
  issn = {0035-8711, 1365-2966},
  doi = {10.1093/mnras/stz3312},
  abstract = {We introduce SuperNNova, an open source supernova photometric classification framework which leverages recent advances in deep neural networks. Our core algorithm is a recurrent neural network (RNN) that is trained to classify light-curves using photometric information only. Additional information such as host-galaxy redshift can be incorporated to improve performance. We evaluate our framework using realistic supernovae simulations that include survey detection. We show that our method, for the type Ia vs. non Ia supernovae classification problem, reaches accuracies greater than 96.92 +- 0.09 without any redshift information and up to 99.55 +- 0.06 when redshift, either photometric or spectroscopic, is available. Further, we show that our method attains unprecedented performance for classification of incomplete light-curves, reaching accuracies {$>$}86.4 +- 0.1 ({$>$}93.5 +- 0.8) without host-galaxy redshift (with redshift information) two days before maximum light. In contrast with previous methods, there is no need for time-consuming feature engineering and we show that our method scales to very large datasets with a modest computing budget. In addition, we investigate often neglected pitfalls of machine learning algorithms. We show that commonly used algorithms suffer from poor calibration and overconfidence on out-of-distribution samples when applied to supernovae data. We devise extensive tests to estimate the robustness of classifiers and cast the learning procedure under a Bayesian light, demonstrating a much better handling of uncertainties. We study the benefits of Bayesian RNNs for SN Ia cosmology. Our code is open-sourced and available on https://github.com/supernnova/SuperNNova.},
  archiveprefix = {arXiv},
  eprint = {1901.06384},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\7GFYYP35\\Möller and de Boissière - 2020 - SuperNNova an open-source framework for Bayesian,.pdf;C\:\\Users\\sidch\\Zotero\\storage\\MTELQYJZ\\1901.html},
  journal = {\mnras},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
  number = {3}
}


@article{sharmaApplicationConvolutionalNeural2020,
  title = {Application of {{Convolutional Neural Networks}} for {{Stellar Spectral Classification}}},
  author = {Sharma, Kaushal and Kembhavi, Ajit and Kembhavi, Aniruddha and Sivarani, T. and Abraham, Sheelu and Vaghmare, Kaustubh},
  year = {2020},
  month = jan,
  volume = {491},
  pages = {2280--2300},
  issn = {0035-8711, 1365-2966},
  doi = {10.1093/mnras/stz3100},
  abstract = {Due to the ever-expanding volume of observed spectroscopic data from surveys such as SDSS and LAMOST, it has become important to apply artificial intelligence (AI) techniques for analysing stellar spectra to solve spectral classification and regression problems like the determination of stellar atmospheric parameters Teff, log g, [Fe/H]. We propose an automated approach for the classification of stellar spectra in the optical region using Convolutional Neural Networks. Traditional machine learning (ML) methods with "shallow" architecture (usually up to 2 hidden layers) have been trained for these purposes in the past. However, deep learning methods with a larger number of hidden layers allow the use of finer details in the spectrum which results in improved accuracy and better generalisation. Studying finer spectral signatures also enables us to determine accurate differential stellar parameters and find rare objects. We examine various machine and deep learning algorithms like Artificial Neural Networks (ANN), Random Forest (RF), and Convolutional Neural Network (CNN) to classify stellar spectra using the Jacoby Atlas, ELODIE and MILES spectral libraries as training samples. We test the performance of the trained networks on the Indo-U.S. Library of Coude Feed Stellar Spectra (CFLIB). We show that using convolutional neural networks, we are able to lower the error up to 1.23 spectral sub-classes as compared to that of 2 sub-classes achieved in the past studies with ML approach. We further apply the trained model to classify stellar spectra retrieved from the SDSS database with SNR{$>$}20.},
  archiveprefix = {arXiv},
  eprint = {1909.05459},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\R2ZIXIFM\\Sharma et al. - 2020 - Application of Convolutional Neural Networks for S.pdf;C\:\\Users\\sidch\\Zotero\\storage\\HQN85L87\\1909.html},
  journal = {\mnras},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics,Astrophysics - Solar and Stellar Astrophysics},
  number = {2}
}

@article{sharmaStellarSpectralInterpolation2020,
  title = {Stellar {{Spectral Interpolation}} Using {{Machine Learning}}},
  author = {Sharma, Kaushal and Singh, Harinder P. and Gupta, Ranjan and Kembhavi, Ajit and Vaghmare, Kaustubh and Shi, Jianrong and Zhao, Yongheng and Zhang, Jiannan and Wu, Yue},
  year = {2020},
  month = aug,
  volume = {496},
  pages = {5002--5016},
  issn = {0035-8711, 1365-2966},
  doi = {10.1093/mnras/staa1809},
  abstract = {Theoretical stellar spectra rely on model stellar atmospheres computed based on our understanding of the physical laws at play in the stellar interiors. These models, coupled with atomic and molecular line databases, are used to generate theoretical stellar spectral libraries (SSLs) comprising of stellar spectra over a regular grid of atmospheric parameters (temperature, surface gravity, abundances) at any desired resolution. Another class of SSLs is referred to as empirical spectral libraries; these contain observed spectra at limited resolution. SSLs play an essential role in deriving the properties of stars and stellar populations. Both theoretical and empirical libraries suffer from limited coverage over the parameter space. This limitation is overcome to some extent by generating spectra for specific sets of atmospheric parameters by interpolating within the grid of available parameter space. In this work, we present a method for spectral interpolation in the optical region using machine learning algorithms that are generic, easily adaptable for any SSL without much change in the model parameters, and computationally inexpensive. We use two machine learning techniques, Random Forest (RF) and Artificial Neural Networks (ANN), and train the models on the MILES library. We apply the trained models to spectra from the CFLIB for testing and show that the performance of the two models is comparable. We show that both the models achieve better accuracy than the existing methods of polynomial based interpolation and the Gaussian radial basis function (RBF) interpolation.},
  archiveprefix = {arXiv},
  eprint = {2006.11463},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\CKBPF8CH\\Sharma et al. - 2020 - Stellar Spectral Interpolation using Machine Learn.pdf;C\:\\Users\\sidch\\Zotero\\storage\\PN8IY897\\2006.html},
  journal = {\mnras},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics,Astrophysics - Solar and Stellar Astrophysics},
  number = {4}
}


@article{kuntzerStellarClassificationSingleband2016,
  title = {Stellar Classification from Single-Band Imaging Using Machine Learning},
  author = {Kuntzer, T. and Tewes, M. and Courbin, F.},
  year = {2016},
  month = jul,
  volume = {591},
  pages = {A54},
  issn = {0004-6361, 1432-0746},
  doi = {10.1051/0004-6361/201628660},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\WQ9NBRKP\\Kuntzer et al. - 2016 - Stellar classification from single-band imaging us.pdf},
  journal = {\aap}
}


@article{barchiMachineDeepLearning2020,
  title = {Machine and {{Deep Learning Applied}} to {{Galaxy Morphology}} -- {{A Comparative Study}}},
  author = {Barchi, P. H. and {de Carvalho}, R. R. and Rosa, R. R. and Sautter, R. and {Soares-Santos}, M. and Marques, B. A. D. and Clua, E. and Gon{\c c}alves, T. S. and {de S{\'a}-Freitas}, C. and Moura, T. C.},
  year = {2020},
  month = jan,
  volume = {30},
  pages = {100334},
  issn = {22131337},
  doi = {10.1016/j.ascom.2019.100334},
  abstract = {Morphological classification is a key piece of information to define samples of galaxies aiming to study the large-scale structure of the universe. In essence, the challenge is to build up a robust methodology to perform a reliable morphological estimate from galaxy images. Here, we investigate how to substantially improve the galaxy classification within large datasets by mimicking human classification. We combine accurate visual classifications from the Galaxy Zoo project with machine and deep learning methodologies. We propose two distinct approaches for galaxy morphology: one based on non-parametric morphology and traditional machine learning algorithms; and another based on Deep Learning. To measure the input features for the traditional machine learning methodology, we have developed a system called CyMorph, with a novel non-parametric approach to study galaxy morphology. The main datasets employed comes from the Sloan Digital Sky Survey Data Release 7 (SDSS-DR7). We also discuss the class imbalance problem considering three classes. Performance of each model is mainly measured by Overall Accuracy (OA). A spectroscopic validation with astrophysical parameters is also provided for Decision Tree models to assess the quality of our morphological classification. In all of our samples, both Deep and Traditional Machine Learning approaches have over 94.5\% OA to classify galaxies in two classes (elliptical and spiral). We compare our classification with state-of-the-art morphological classification from literature. Considering only two classes separation, we achieve 99\% of overall accuracy in average when using our deep learning models, and 82\% when using three classes. We provide a catalog with 670,560 galaxies containing our best results, including morphological metrics and classification.},
  archiveprefix = {arXiv},
  eprint = {1901.07047},
  eprinttype = {arxiv},
  journal = {Astronomy and Computing},
  keywords = {Astrophysics - Astrophysics of Galaxies,Astrophysics - Instrumentation and Methods for Astrophysics}
}

@article{walmsleyGalaxyZooProbabilistic2020,
  title = {Galaxy {{Zoo}}: {{Probabilistic Morphology}} through {{Bayesian CNNs}} and {{Active Learning}}},
  shorttitle = {Galaxy {{Zoo}}},
  author = {Walmsley, Mike and Smith, Lewis and Lintott, Chris and Gal, Yarin and Bamford, Steven and Dickinson, Hugh and Fortson, Lucy and Kruk, Sandor and Masters, Karen and Scarlata, Claudia and Simmons, Brooke and Smethurst, Rebecca and Wright, Darryl},
  year = {2020},
  month = jan,
  volume = {491},
  pages = {1554--1574},
  issn = {0035-8711, 1365-2966},
  doi = {10.1093/mnras/stz2816},
  abstract = {We use Bayesian convolutional neural networks and a novel generative model of Galaxy Zoo volunteer responses to infer posteriors for the visual morphology of galaxies. Bayesian CNN can learn from galaxy images with uncertain labels and then, for previously unlabelled galaxies, predict the probability of each possible label. Our posteriors are well-calibrated (e.g. for predicting bars, we achieve coverage errors of 11.8\% within a vote fraction deviation of 0.2) and hence are reliable for practical use. Further, using our posteriors, we apply the active learning strategy BALD to request volunteer responses for the subset of galaxies which, if labelled, would be most informative for training our network. We show that training our Bayesian CNNs using active learning requires up to 35-60\% fewer labelled galaxies, depending on the morphological feature being classified. By combining human and machine intelligence, Galaxy Zoo will be able to classify surveys of any conceivable scale on a timescale of weeks, providing massive and detailed morphology catalogues to support research into galaxy evolution.},
  archiveprefix = {arXiv},
  eprint = {1905.07424},
  eprinttype = {arxiv},
  journal = {\mnras},
  keywords = {Astrophysics - Astrophysics of Galaxies,Computer Science - Computer Vision and Pattern Recognition},
  number = {2}
}

@article{baquiMiniJPASSurveyStargalaxy2021,
  title = {The {{miniJPAS}} Survey: Star-Galaxy Classification Using Machine Learning},
  shorttitle = {The {{miniJPAS}} Survey},
  author = {Baqui, P. O. and Marra, V. and Casarini, L. and Angulo, R. and {D{\'i}az-Garc{\'i}a}, L. A. and {Hern{\'a}ndez-Monteagudo}, C. and Lopes, P. A. A. and {L{\'o}pez-Sanjuan}, C. and Muniesa, D. and Placco, V. M. and Quartin, M. and Queiroz, C. and Sobral, D. and Solano, E. and Tempel, E. and Varela, J. and V{\'i}lchez, J. M. and Abramo, R. and Alcaniz, J. and Benitez, N. and Bonoli, S. and Carneiro, S. and Cenarro, A. J. and {Crist{\'o}bal-Hornillos}, D. and {de Amorim}, A. L. and {de Oliveira}, C. M. and Dupke, R. and Ederoclite, A. and Gonz{\'a}lez Delgado, R. M. and {Mar{\'i}n-Franch}, A. and Moles, M. and V{\'a}zquez Rami{\'o}, H. and Sodr{\'e}, L. and Taylor, K.},
  year = {2021},
  month = jan,
  volume = {645},
  pages = {A87},
  issn = {0004-6361, 1432-0746},
  doi = {10.1051/0004-6361/202038986},
  abstract = {Context.               Future astrophysical surveys such as J-PAS will produce very large datasets, the so-called ``big data'', which will require the deployment of accurate and efficient machine-learning (ML) methods. In this work, we analyze the miniJPAS survey, which observed about {$\sim$}1\hspace{0.166em}deg               2               of the AEGIS field with 56 narrow-band filters and 4               u               g               r               i               broad-band filters. The miniJPAS primary catalog contains approximately 64 000 objects in the               r               detection band (mag                                A                 B                              \;{$\lessequivlnt$}\;24), with forced-photometry in all other filters.                                         Aims.               We discuss the classification of miniJPAS sources into extended (galaxies) and point-like (e.g., stars) objects, which is a step required for the subsequent scientific analyses. We aim at developing an ML classifier that is complementary to traditional tools that are based on explicit modeling. In particular, our goal is to release a value-added catalog with our best classification.                                         Methods.               In order to train and test our classifiers, we cross-matched the miniJPAS dataset with SDSS and HSC-SSP data, whose classification is trustworthy within the intervals 15\;{$\leq$}\;               r               \;{$\leq$}\;20 and 18.5\;{$\leq$}\;               r               \;{$\leq$}\;23.5, respectively. We trained and tested six different ML algorithms on the two cross-matched catalogs: K-nearest neighbors, decision trees, random forest (RF), artificial neural networks, extremely randomized trees (ERT), and an ensemble classifier. This last is a hybrid algorithm that combines artificial neural networks and RF with the J-PAS stellar and galactic loci classifier. As input for the ML algorithms we used the magnitudes from the 60 filters together with their errors, with and without the morphological parameters. We also used the mean point spread function in the               r               detection band for each pointing.                                         Results.               We find that the RF and ERT algorithms perform best in all scenarios. When the full magnitude range of 15\;{$\leq$}\;               r               \;{$\leq$}\;23.5 is analyzed, we find an area under the curve AUC\;=\;0.957 with RF when photometric information alone is used, and AUC\;=\;0.986 with ERT when photometric and morphological information is used together. When morphological parameters are used, the full width at half maximum is the most important feature. When photometric information is used alone, we observe that broad bands are not necessarily more important than narrow bands, and errors (the width of the distribution) are as important as the measurements (central value of the distribution). In other words, it is apparently important to fully characterize the measurement.                                         Conclusions.               ML algorithms can compete with traditional star and galaxy classifiers; they outperform the latter at fainter magnitudes (               r               \;{$\greaterequivlnt$}\;21). We use our best classifiers, with and without morphology, in order to produce a value-added catalog.},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\R2RMUYVJ\\Baqui et al. - 2021 - The miniJPAS survey star-galaxy classification us.pdf},
  journal = {\aap}
}

@article{gonzalezGalaxyDetectionIdentification2018,
  title = {Galaxy Detection and Identification Using Deep Learning and Data Augmentation},
  author = {Gonz{\'a}lez, R.E. and Mu{\~n}oz, R.P. and Hern{\'a}ndez, C.A.},
  year = {2018},
  month = oct,
  volume = {25},
  pages = {103--109},
  issn = {22131337},
  doi = {10.1016/j.ascom.2018.09.004},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\WGA76FY2\\González et al. - 2018 - Galaxy detection and identification using deep lea.pdf},
  journal = {Astronomy and Computing},
  language = {en}
}

@article{tanoglidisDeepShadowsSeparatingLow2020a,
  title = {{{DeepShadows}}: {{Separating Low Surface Brightness Galaxies}} from {{Artifacts}} Using {{Deep Learning}}},
  shorttitle = {{{DeepShadows}}},
  author = {Tanoglidis, Dimitrios and {\'C}iprijanovi{\'c}, Aleksandra and {Drlica-Wagner}, Alex},
  year = {2020},
  month = nov,
  abstract = {Searches for low-surface-brightness galaxies (LSBGs) in galaxy surveys are plagued by the presence of a large number of artifacts (e.g., objects blended in the diffuse light from stars and galaxies, Galactic cirrus, star-forming regions in the arms of spiral galaxies, etc.) that have to be rejected through time consuming visual inspection. In future surveys, which are expected to collect hundreds of petabytes of data and detect billions of objects, such an approach will not be feasible. We investigate the use of convolutional neural networks (CNNs) for the problem of separating LSBGs from artifacts in survey images. We take advantage of the fact that, for the first time, we have available a large number of labeled LSBGs and artifacts from the Dark Energy Survey, that we use to train, validate, and test a CNN model. That model, which we call DeepShadows, achieves a test accuracy of \$92.0 \textbackslash\%\$, a significant improvement relative to feature-based machine learning models. We also study the ability to use transfer learning to adapt this model to classify objects from the deeper Hyper-Suprime-Cam survey, and we show that after the model is retrained on a very small sample from the new survey, it can reach an accuracy of \$87.6\textbackslash\%\$. These results demonstrate that CNNs offer a very promising path in the quest to study the low-surface-brightness universe.},
  archiveprefix = {arXiv},
  eprint = {2011.12437},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\67573G9J\\Tanoglidis et al. - 2020 - DeepShadows Separating Low Surface Brightness Gal.pdf;C\:\\Users\\sidch\\Zotero\\storage\\Z35I5QLQ\\2011.html},
  journal = {arXiv:2011.12437 [astro-ph]},
  keywords = {Astrophysics - Astrophysics of Galaxies,Astrophysics - Cosmology and Nongalactic Astrophysics,Astrophysics - Instrumentation and Methods for Astrophysics,Computer Science - Computer Vision and Pattern Recognition},
  primaryclass = {astro-ph}
}

% END OF SIDDHARTH's ZOTERO

% Put other refs below this

@misc{resnet,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{alexnet,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
title = {ImageNet Classification with Deep Convolutional Neural Networks},
year = {2012},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.},
booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
pages = {1097–1105},
numpages = {9},
location = {Lake Tahoe, Nevada},
series = {NIPS'12}
}


@misc{vcgnet,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@ARTICLE{zwickycompact1978,
       author = {{Fairall}, A.~P.},
        title = "{What are Zwicky's compact galaxies?}",
      journal = {The Observatory},
     keywords = {Compact Galaxies, Elliptical Galaxies, Galactic Structure, Spatial Distribution, Spiral Galaxies, Astronomical Photometry, Astronomical Spectroscopy, Luminous Intensity, Sky Surveys (Astronomy), Star Distribution, Astronomy},
         year = 1978,
        month = feb,
       volume = {98},
        pages = {1-7},
       adsurl = {https://ui.adsabs.harvard.edu/abs/1978Obs....98....1F},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{darkenergysurvey,
author = {Flaugher, Brenna},
title = {The Dark Energy Survey},
journal = {International Journal of Modern Physics A},
volume = {20},
number = {14},
pages = {3121-3123},
year = {2005},
doi = {10.1142/S0217751X05025917},

URL = { 
        https://doi.org/10.1142/S0217751X05025917
    
},
eprint = { 
        https://doi.org/10.1142/S0217751X05025917
    
}
,
    abstract = { Dark Energy is the dominant constituent of the universe and we have little understanding of it. We describe a new project aimed at measuring the dark energy equation of state parameter, w, to a statistical precision of ~5\% with four separate techniques. The survey will image 5000 deg2 in the southern sky and collect 300 million galaxies, 30,000 galaxy clusters, and 2000 Type Ia supernovae. The survey will be carried out using a new 3 deg2 mosaic camera mounted at the prime focus of the 4m Blanco telescope at CTIO. }
}


@misc{bellmZwickyTransientFacility2014,
title = "{The Zwicky Transient Facility}",
author = {{Bellm}, E.},
year={2014},
eprint={1410.8185},
archivePrefix={arXiv},
primaryClass={astro-ph.IM}
}



@article{ivezicLSSTScienceDrivers2019,
  title = {{{LSST}}: From {{Science Drivers}} to {{Reference Design}} and {{Anticipated Data Products}}},
  shorttitle = {{{LSST}}},
  author = {Ivezi{\'c}, {\v Z}eljko and Kahn, Steven M. and Tyson, J. Anthony and Abel, Bob and Acosta, Emily and Allsman, Robyn and Alonso, David and AlSayyad, Yusra and Anderson, Scott F. and Andrew, John and Angel, James Roger P. and Angeli, George Z. and Ansari, Reza and Antilogus, Pierre and Araujo, Constanza and Armstrong, Robert and Arndt, Kirk T. and Astier, Pierre and Aubourg, {\'E}ric and Auza, Nicole and Axelrod, Tim S. and Bard, Deborah J. and Barr, Jeff D. and Barrau, Aurelian and Bartlett, James G. and Bauer, Amanda E. and Bauman, Brian J. and Baumont, Sylvain and Becker, Andrew C. and Becla, Jacek and Beldica, Cristina and Bellavia, Steve and Bianco, Federica B. and Biswas, Rahul and Blanc, Guillaume and Blazek, Jonathan and Blandford, Roger D. and Bloom, Josh S. and Bogart, Joanne and Bond, Tim W. and Borgland, Anders W. and Borne, Kirk and Bosch, James F. and Boutigny, Dominique and Brackett, Craig A. and Bradshaw, Andrew and Brandt, William Nielsen and Brown, Michael E. and Bullock, James S. and Burchat, Patricia and Burke, David L. and Cagnoli, Gianpietro and Calabrese, Daniel and Callahan, Shawn and Callen, Alice L. and Chandrasekharan, Srinivasan and {Charles-Emerson}, Glenaver and Chesley, Steve and Cheu, Elliott C. and Chiang, Hsin-Fang and Chiang, James and Chirino, Carol and Chow, Derek and Ciardi, David R. and Claver, Charles F. and {Cohen-Tanugi}, Johann and Cockrum, Joseph J. and Coles, Rebecca and Connolly, Andrew J. and Cook, Kem H. and Cooray, Asantha and Covey, Kevin R. and Cribbs, Chris and Cui, Wei and Cutri, Roc and Daly, Philip N. and Daniel, Scott F. and Daruich, Felipe and Daubard, Guillaume and Daues, Greg and Dawson, William and Delgado, Francisco and Dellapenna, Alfred and {de Peyster}, Robert and {de Val-Borro}, Miguel and Digel, Seth W. and Doherty, Peter and Dubois, Richard and {Dubois-Felsmann}, Gregory P. and Durech, Josef and Economou, Frossie and Eracleous, Michael and Ferguson, Henry and Figueroa, Enrique and {Fisher-Levine}, Merlin and Focke, Warren and Foss, Michael D. and Frank, James and Freemon, Michael D. and Gangler, Emmanuel and Gawiser, Eric and Geary, John C. and Gee, Perry and Geha, Marla and Gessner, Charles J. B. and Gibson, Robert R. and Gilmore, D. Kirk and Glanzman, Thomas and Glick, William and Goldina, Tatiana and Goldstein, Daniel A. and Goodenow, Iain and Graham, Melissa L. and Gressler, William J. and Gris, Philippe and Guy, Leanne P. and Guyonnet, Augustin and Haller, Gunther and Harris, Ron and Hascall, Patrick A. and Haupt, Justine and Hernandez, Fabio and Herrmann, Sven and Hileman, Edward and Hoblitt, Joshua and Hodgson, John A. and Hogan, Craig and Huang, Dajun and Huffer, Michael E. and Ingraham, Patrick and Innes, Walter R. and Jacoby, Suzanne H. and Jain, Bhuvnesh and Jammes, Fabrice and Jee, James and Jenness, Tim and Jernigan, Garrett and Jevremovi{\'c}, Darko and Johns, Kenneth and Johnson, Anthony S. and Johnson, Margaret W. G. and Jones, R. Lynne and {Juramy-Gilles}, Claire and Juri{\'c}, Mario and Kalirai, Jason S. and Kallivayalil, Nitya J. and Kalmbach, Bryce and Kantor, Jeffrey P. and Karst, Pierre and Kasliwal, Mansi M. and Kelly, Heather and Kessler, Richard and Kinnison, Veronica and Kirkby, David and Knox, Lloyd and Kotov, Ivan V. and Krabbendam, Victor L. and Krughoff, K. Simon and Kub{\'a}nek, Petr and Kuczewski, John and Kulkarni, Shri and Ku, John and Kurita, Nadine R. and Lage, Craig S. and Lambert, Ron and Lange, Travis and Langton, J. Brian and Guillou, Laurent Le and Levine, Deborah and Liang, Ming and Lim, Kian-Tat and Lintott, Chris J. and Long, Kevin E. and Lopez, Margaux and Lotz, Paul J. and Lupton, Robert H. and Lust, Nate B. and MacArthur, Lauren A. and Mahabal, Ashish and Mandelbaum, Rachel and Marsh, Darren S. and Marshall, Philip J. and Marshall, Stuart and May, Morgan and McKercher, Robert and McQueen, Michelle and Meyers, Joshua and Migliore, Myriam and Miller, Michelle and Mills, David J. and Miraval, Connor and Moeyens, Joachim and Monet, David G. and Moniez, Marc and Monkewitz, Serge and Montgomery, Christopher and Mueller, Fritz and Muller, Gary P. and Arancibia, Freddy Mu{\~n}oz and Neill, Douglas R. and Newbry, Scott P. and Nief, Jean-Yves and Nomerotski, Andrei and Nordby, Martin and O'Connor, Paul and Oliver, John and Olivier, Scot S. and Olsen, Knut and O'Mullane, William and Ortiz, Sandra and Osier, Shawn and Owen, Russell E. and Pain, Reynald and Palecek, Paul E. and Parejko, John K. and Parsons, James B. and Pease, Nathan M. and Peterson, J. Matt and Peterson, John R. and Petravick, Donald L. and Petrick, M. E. Libby and Petry, Cathy E. and Pierfederici, Francesco and Pietrowicz, Stephen and Pike, Rob and Pinto, Philip A. and Plante, Raymond and Plate, Stephen and Price, Paul A. and Prouza, Michael and Radeka, Veljko and Rajagopal, Jayadev and Rasmussen, Andrew P. and Regnault, Nicolas and Reil, Kevin A. and Reiss, David J. and Reuter, Michael A. and Ridgway, Stephen T. and Riot, Vincent J. and Ritz, Steve and Robinson, Sean and Roby, William and Roodman, Aaron and Rosing, Wayne and Roucelle, Cecille and Rumore, Matthew R. and Russo, Stefano and Saha, Abhijit and Sassolas, Benoit and Schalk, Terry L. and Schellart, Pim and Schindler, Rafe H. and Schmidt, Samuel and Schneider, Donald P. and Schneider, Michael D. and Schoening, William and Schumacher, German and Schwamb, Megan E. and Sebag, Jacques and Selvy, Brian and Sembroski, Glenn H. and Seppala, Lynn G. and Serio, Andrew and Serrano, Eduardo and Shaw, Richard A. and Shipsey, Ian and Sick, Jonathan and Silvestri, Nicole and Slater, Colin T. and Smith, J. Allyn and Smith, R. Chris and Sobhani, Shahram and Soldahl, Christine and {Storrie-Lombardi}, Lisa and Stover, Edward and Strauss, Michael A. and Street, Rachel A. and Stubbs, Christopher W. and Sullivan, Ian S. and Sweeney, Donald and Swinbank, John D. and Szalay, Alexander and Takacs, Peter and Tether, Stephen A. and Thaler, Jon J. and Thayer, John Gregg and Thomas, Sandrine and Thukral, Vaikunth and Tice, Jeffrey and Trilling, David E. and Turri, Max and Van Berg, Richard and Berk, Daniel Vanden and Vetter, Kurt and Virieux, Francoise and Vucina, Tomislav and Wahl, William and Walkowicz, Lucianne and Walsh, Brian and Walter, Christopher W. and Wang, Daniel L. and Wang, Shin-Yawn and Warner, Michael and Wiecha, Oliver and Willman, Beth and Winters, Scott E. and Wittman, David and Wolff, Sidney C. and {Wood-Vasey}, W. Michael and Wu, Xiuqin and Xin, Bo and Yoachim, Peter and Zhan, Hu},
  year = {2019},
  month = mar,
  volume = {873},
  pages = {111},
  issn = {1538-4357},
  doi = {10.3847/1538-4357/ab042c},
  abstract = {(Abridged) We describe here the most ambitious survey currently planned in the optical, the Large Synoptic Survey Telescope (LSST). A vast array of science will be enabled by a single wide-deep-fast sky survey, and LSST will have unique survey capability in the faint time domain. The LSST design is driven by four main science themes: probing dark energy and dark matter, taking an inventory of the Solar System, exploring the transient optical sky, and mapping the Milky Way. LSST will be a wide-field ground-based system sited at Cerro Pach\textbackslash '\{o\}n in northern Chile. The telescope will have an 8.4 m (6.5 m effective) primary mirror, a 9.6 deg\$\^2\$ field of view, and a 3.2 Gigapixel camera. The standard observing sequence will consist of pairs of 15-second exposures in a given field, with two such visits in each pointing in a given night. With these repeats, the LSST system is capable of imaging about 10,000 square degrees of sky in a single filter in three nights. The typical 5\$\textbackslash sigma\$ point-source depth in a single visit in \$r\$ will be \$\textbackslash sim 24.5\$ (AB). The project is in the construction phase and will begin regular survey operations by 2022. The survey area will be contained within 30,000 deg\$\^2\$ with \$\textbackslash delta{$<$}+34.5\^\textbackslash circ\$, and will be imaged multiple times in six bands, \$ugrizy\$, covering the wavelength range 320--1050 nm. About 90\textbackslash\% of the observing time will be devoted to a deep-wide-fast survey mode which will uniformly observe a 18,000 deg\$\^2\$ region about 800 times (summed over all six bands) during the anticipated 10 years of operations, and yield a coadded map to \$r\textbackslash sim27.5\$. The remaining 10\textbackslash\% of the observing time will be allocated to projects such as a Very Deep and Fast time domain survey. The goal is to make LSST data products, including a relational database of about 32 trillion observations of 40 billion objects, available to the public and scientists around the world.},
  archiveprefix = {arXiv},
  eprint = {0805.2366},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\NYALM3GL\\Ivezić et al. - 2019 - LSST from Science Drivers to Reference Design and.pdf;C\:\\Users\\sidch\\Zotero\\storage\\Y4UB8WLK\\0805.html},
  journal = {\apj},
  keywords = {Astrophysics},
  number = {2}
}

@article{hao2017stacked,
title = {Stacked Denoising Autoencoders Applied to Star/Galaxy Classification},
journal = {Chinese Astronomy and Astrophysics},
volume = {41},
number = {2},
pages = {282-292},
year = {2017},
issn = {0275-1062},
doi = {https://doi.org/10.1016/j.chinastron.2017.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S0275106217300656},
author = {Qin Hao-ran and Lin Ji-ming and Wang Jun-yi},
keywords = {methods: data analysis, galaxies: fundamental parameters, stars: fundamental parameters, cosmology: observations},
abstract = {In recent years, the deep learning algorithm, with the characteristics of strong adaptability, high accuracy, and structural complexity, has become more and more popular, but it has not yet been used in astronomy. In order to solve the problem that the star/galaxy classification accuracy is high for the bright source set, but low for the faint source set of the Sloan Digital Sky Survey (SDSS) data, we introduced the new deep learning algorithm, namely the SDA (stacked denoising autoencoder) neural network and the dropout fine-tuning technique, which can greatly improve the robustness and antinoise performance. We randomly selected respectively the bright source sets and faint source sets from the SDSS DR12 and DR7 data with spectroscopic measurements, and made preprocessing on them. Then, we randomly selected respectively the training sets and testing sets without replacement from the bright source sets and faint source sets. At last, using these training sets we made the training to obtain the SDA models of the bright sources and faint sources in the SDSS DR7 and DR12, respectively. We compared the test result of the SDA model on the DR12 testing set with the test results of the Library for Support Vector Machines (LibSVM), J48 decision tree, Logistic Model Tree (LMT), Support Vector Machine (SVM), Logistic Regression, and Decision Stump algorithm, and compared the test result of the SDA model on the DR7 testing set with the test results of six kinds of decision trees. The experiments show that the SDA has a better classification accuracy than other machine learning algorithms for the faint source sets of DR7 and DR12. Especially, when the completeness function is used as the evaluation index, compared with the decision tree algorithms, the correctness rate of SDA has improved about 15% for the faint source set of SDSS-DR7.}
}
@inproceedings{kennamer2018contextnet,
  title={ContextNet: Deep learning for star galaxy classification},
  author={Kennamer, Noble and Kirkby, David and Ihler, Alexander and Sanchez-Lopez, Francisco Javier},
  booktitle={International conference on machine learning},
  pages={2582--2590},
  year={2018},
  organization={PMLR}
}
@article{sebok1986angular,
       author = {{Sebok}, William L.},
        title = "{The Angular Correlation Function of Galaxies as a Function of Magnitude}",
      journal = {\apjs},
     keywords = {Angular Correlation, Astronomical Photometry, Galactic Clusters, Photographic Plates, Astronomical Photography, Classifications, Magnitude, Astrophysics, COSMOLOGY, GALAXIES: CLUSTERING, GALAXIES: PHOTOMETRY},
         year = 1986,
        month = oct,
       volume = {62},
        pages = {301},
          doi = {10.1086/191142},
       adsurl = {https://ui.adsabs.harvard.edu/abs/1986ApJS...62..301S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@techreport{rosenblatt1961principles,
  title={Principles of neurodynamics. perceptrons and the theory of brain mechanisms},
  author={Rosenblatt, Frank},
  year={1961},
  institution={Cornell Aeronautical Lab Inc Buffalo NY}
}
@misc{aggarwal2014algorithms,
  title={Algorithms and Applications},
  author={Aggarwal, Charu C and Clustering, CK Reddy Data},
  year={2014},
  publisher={CRC Press Taylor and Francis Group}
}
@inproceedings{nair2010rectified,
author = {Nair, Vinod and Hinton, Geoffrey E.},
title = {Rectified Linear Units Improve Restricted Boltzmann Machines},
year = {2010},
isbn = {9781605589077},
publisher = {Omnipress},
address = {Madison, WI, USA},
abstract = {Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these "Stepped Sigmoid Units" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.},
booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
pages = {807–814},
numpages = {8},
location = {Haifa, Israel},
series = {ICML'10}
}

@inproceedings{maas2013rectifier,
  title={Rectifier nonlinearities improve neural network acoustic models},
  author={Maas, Andrew L and Hannun, Awni Y and Ng, Andrew Y},
  booktitle={Proc. icml},
  volume={30},
  number={1},
  pages={3},
  year={2013},
  organization={Citeseer}
}

@InProceedings{pmlr-v80-kennamer18a,
  title = 	 {{C}ontext{N}et: Deep learning for Star Galaxy Classification},
  author =       {Kennamer, Noble and Kirkby, David and Ihler, Alexander and Sanchez-Lopez, Francisco Javier},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2582--2590},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/kennamer18a/kennamer18a.pdf},
  url = 	 {http://proceedings.mlr.press/v80/kennamer18a.html},
  abstract = 	 {We present a framework to compose artificial neural networks in cases where the data cannot be treated as independent events. Our particular motivation is star galaxy classification for ground based optical surveys. Due to a turbulent atmosphere and imperfect instruments, a single image of an astronomical object is not enough to definitively classify it as a star or galaxy. Instead the context of the surrounding objects imaged at the same time need to be considered in order to make an optimal classification. The model we present is divided into three distinct ANNs: one designed to capture local features about each object, the second to compare these features across all objects in an image, and the third to make a final prediction for each object based on the local and compared features. By exploiting the ability to replicate the weights of an ANN, the model can handle an arbitrary and variable number of individual objects embedded in a larger exposure. We train and test our model on simulations of a large up and coming ground based survey, the Large Synoptic Survey Telescope (LSST). We compare to the state of the art approach, showing improved overall performance as well as better performance for a specific class of objects that is important for the LSST.}
}


@article{georgeDeepLearningRealtime2018,
  title = {Deep {{Learning}} for {{Real}}-Time {{Gravitational Wave Detection}} and {{Parameter Estimation}}: {{Results}} with {{Advanced LIGO Data}}},
  shorttitle = {Deep {{Learning}} for {{Real}}-Time {{Gravitational Wave Detection}} and {{Parameter Estimation}}},
  author = {George, Daniel and Huerta, E. A.},
  year = {2018},
  month = mar,
  volume = {778},
  pages = {64--70},
  issn = {03702693},
  doi = {10.1016/j.physletb.2017.12.053},
  abstract = {The recent Nobel-prize-winning detections of gravitational waves from merging black holes and the subsequent detection of the collision of two neutron stars in coincidence with electromagnetic observations have inaugurated a new era of multimessenger astrophysics. To enhance the scope of this emergent field of science, we pioneered the use of deep learning with convolutional neural networks, that take time-series inputs, for rapid detection and characterization of gravitational wave signals. This approach, Deep Filtering, was initially demonstrated using simulated LIGO noise. In this article, we present the extension of Deep Filtering using real data from LIGO, for both detection and parameter estimation of gravitational waves from binary black hole mergers using continuous data streams from multiple LIGO detectors. We demonstrate for the first time that machine learning can detect and estimate the true parameters of real events observed by LIGO. Our results show that Deep Filtering achieves similar sensitivities and lower errors compared to matched-filtering while being far more computationally efficient and more resilient to glitches, allowing real-time processing of weak time-series signals in non-stationary non-Gaussian noise with minimal resources, and also enables the detection of new classes of gravitational wave sources that may go unnoticed with existing detection algorithms. This unified framework for data analysis is ideally suited to enable coincident detection campaigns of gravitational waves and their multimessenger counterparts in real-time.},
  archiveprefix = {arXiv},
  eprint = {1711.03121},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\LYE22K2J\\George and Huerta - 2018 - Deep Learning for Real-time Gravitational Wave Det.pdf;C\:\\Users\\sidch\\Zotero\\storage\\QNQQAN89\\1711.html},
  journal = {Physics Letters B},
  keywords = {Astrophysics - High Energy Astrophysical Phenomena,Astrophysics - Instrumentation and Methods for Astrophysics,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,General Relativity and Quantum Cosmology}
}

@article{chengIdentifyingStrongLenses2020,
  title = {Identifying {{Strong Lenses}} with {{Unsupervised Machine Learning}} Using {{Convolutional Autoencoder}}},
  author = {Cheng, Ting-Yun and Li, Nan and Conselice, Christopher J. and {Arag{\'o}n-Salamanca}, Alfonso and Dye, Simon and Metcalf, Robert B.},
  year = {2020},
  month = may,
  volume = {494},
  pages = {3750--3765},
  issn = {0035-8711, 1365-2966},
  doi = {10.1093/mnras/staa1015},
  abstract = {In this paper we develop a new unsupervised machine learning technique comprised of a feature extractor, a convolutional autoencoder (CAE), and a clustering algorithm consisting of a Bayesian Gaussian mixture model (BGM). We apply this technique to visual band space-based simulated imaging data from the Euclid Space Telescope using data from the Strong Gravitational Lenses Finding Challenge. Our technique promisingly captures a variety of lensing features such as Einstein rings with different radii, distorted arc structures, etc, without using predefined labels. After the clustering process, we obtain several classification clusters separated by different visual features which are seen in the images. Our method successfully picks up \$\textbackslash sim\$63\textbackslash{} percent of lensing images from all lenses in the training set. With the assumed probability proposed in this study, this technique reaches an accuracy of \$77.25\textbackslash pm 0.48\$\textbackslash\% in binary classification using the training set. Additionally, our unsupervised clustering process can be used as the preliminary classification for future surveys of lenses to efficiently select targets and to speed up the labelling process. As the starting point of the astronomical application using this technique, we not only explore the application to gravitationally lensed systems, but also discuss the limitations and potential future uses of this technique.},
  archiveprefix = {arXiv},
  eprint = {1911.04320},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\7GMJII5Y\\Cheng et al. - 2020 - Identifying Strong Lenses with Unsupervised Machin.pdf;C\:\\Users\\sidch\\Zotero\\storage\\W3C85VJ2\\1911.html},
  journal = {\mnras},
  keywords = {Astrophysics - Astrophysics of Galaxies,Astrophysics - Cosmology and Nongalactic Astrophysics,Astrophysics - Instrumentation and Methods for Astrophysics},
  number = {3}
}

@article{vasconcellosDecisionTreeClassifiers2010,
       author = {{Vasconcellos}, E.~C. and {de Carvalho}, R.~R. and {Gal}, R.~R. and {LaBarbera}, F.~L. and {Capelato}, H.~V. and {Frago Campos Velho}, H. and {Trevisan}, M. and {Ruiz}, R.~S.~R.},
        title = "{Decision Tree Classifiers for Star/Galaxy Separation}",
      journal = {\aj},
     keywords = {catalogs, methods: data analysis, surveys, virtual observatory tools, Astrophysics - Cosmology and Nongalactic Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics},
         year = 2011,
        month = jun,
       volume = {141},
       number = {6},
          eid = {189},
        pages = {189},
          doi = {10.1088/0004-6256/141/6/189},
archivePrefix = {arXiv},
       eprint = {1011.1951},
 primaryClass = {astro-ph.CO},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2011AJ....141..189V},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{lochnerPhotometricSupernovaClassification2016,
       author = {{Lochner}, Michelle and {McEwen}, Jason D. and {Peiris}, Hiranya V. and {Lahav}, Ofer and {Winter}, Max K.},
        title = "{Photometric Supernova Classification with Machine Learning}",
      journal = {\apjs},
     keywords = {cosmology: observations, methods: data analysis, supernovae: general, Astrophysics - Instrumentation and Methods for Astrophysics, Astrophysics - Cosmology and Nongalactic Astrophysics},
         year = 2016,
        month = aug,
       volume = {225},
       number = {2},
          eid = {31},
        pages = {31},
          doi = {10.3847/0067-0049/225/2/31},
archivePrefix = {arXiv},
       eprint = {1603.00882},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016ApJS..225...31L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{hinnersMachineLearningTechniques2018,
  title = {Machine {{Learning Techniques}} for {{Stellar Light Curve Classification}}},
  author = {Hinners, Trisha and Tat, Kevin and Thorp, Rachel},
  year = {2018},
  month = jun,
  volume = {156},
  pages = {7},
  issn = {1538-3881},
  doi = {10.3847/1538-3881/aac16d},
  abstract = {We apply machine learning techniques in an attempt to predict and classify stellar properties from noisy and sparse time series data. We preprocessed over 94 GB of Kepler light curves from MAST to classify according to ten distinct physical properties using both representation learning and feature engineering approaches. Studies using machine learning in the field have been primarily done on simulated data, making our study one of the first to use real light curve data for machine learning approaches. We tuned our data using previous work with simulated data as a template and achieved mixed results between the two approaches. Representation learning using a Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN) produced no successful predictions, but our work with feature engineering was successful for both classification and regression. In particular, we were able to achieve values for stellar density, stellar radius, and effective temperature with low error (\textasciitilde{} 2 - 4\%) and good accuracy (\textasciitilde{} 75\%) for classifying the number of transits for a given star. The results show promise for improvement for both approaches upon using larger datasets with a larger minority class. This work has the potential to provide a foundation for future tools and techniques to aid in the analysis of astrophysical data.},
  archiveprefix = {arXiv},
  eprint = {1710.06804},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\2TF9S78W\\Hinners et al. - 2018 - Machine Learning Techniques for Stellar Light Curv.pdf;C\:\\Users\\sidch\\Zotero\\storage\\XXTATC78\\1710.html},
  journal = {\aj},
  keywords = {85,Astrophysics - Instrumentation and Methods for Astrophysics},
  number = {1}
}

@article{mahabalMachineLearningZwicky2019,
  title = {Machine {{Learning}} for the {{Zwicky Transient Facility}}},
  author = {Mahabal, Ashish and Rebbapragada, Umaa and Walters, Richard and Masci, Frank J. and Blagorodnova, Nadejda and {van Roestel}, Jan and Ye, Quan-Zhi and Biswas, Rahul and Burdge, Kevin and Chang, Chan-Kao and Duev, Dmitry A. and Golkhou, V. Zach and Miller, Adam A. and Nordin, Jakob and Ward, Charlotte and Adams, Scott and Bellm, Eric C. and Branton, Doug and Bue, Brian and Cannella, Chris and Connolly, Andrew and Dekany, Richard and Feindt, Ulrich and Hung, Tiara and Fortson, Lucy and Frederick, Sara and Fremling, C. and Gezari, Suvi and Graham, Matthew and Groom, Steven and Kasliwal, Mansi M. and Kulkarni, Shrinivas and Kupfer, Thomas and Lin, Hsing Wen and Lintott, Chris and Lunnan, Ragnhild and Parejko, John and Prince, Thomas A. and Riddle, Reed and Rusholme, Ben and Saunders, Nicholas and Sedaghat, Nima and Shupe, David L. and Singer, Leo P. and Soumagnac, Maayane T. and Szkody, Paula and Tachibana, Yutaro and Tirumala, Kushal and {van Velzen}, Sjoert and Wright, Darryl},
  year = {2019},
  month = mar,
  volume = {131},
  pages = {038002},
  issn = {0004-6280, 1538-3873},
  doi = {10.1088/1538-3873/aaf3fa},
  abstract = {The Zwicky Transient Facility is a large optical survey in multiple filters producing hundreds of thousands of transient alerts per night. We describe here various machine learning (ML) implementations and plans to make the maximal use of the large data set by taking advantage of the temporal nature of the data, and further combining it with other data sets. We start with the initial steps of separating bogus candidates from real ones, separating stars and galaxies, and go on to the classification of real objects into various classes. Besides the usual methods (e.g., based on features extracted from light curves) we also describe early plans for alternate methods including the use of domain adaptation, and deep learning. In a similar fashion we describe efforts to detect fast moving asteroids. We also describe the use of the Zooniverse platform for helping with classifications through the creation of training samples, and active learning. Finally we mention the synergistic aspects of ZTF and LSST from the ML perspective.},
  archiveprefix = {arXiv},
  eprint = {1902.01936},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\Z6BY8AMK\\Mahabal et al. - 2019 - Machine Learning for the Zwicky Transient Facility.pdf;C\:\\Users\\sidch\\Zotero\\storage\\3T3JYQKZ\\1902.html},
  journal = {Publications of the Astronomical Society of the Pacific},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
  number = {997}
}

@article{booneAvocadoPhotometricClassification2019,
  title = {Avocado: {{Photometric Classification}} of {{Astronomical Transients}} with {{Gaussian Process Augmentation}}},
  shorttitle = {Avocado},
  author = {Boone, Kyle},
  year = {2019},
  month = jul,
  doi = {10.3847/1538-3881/ab5182},
  abstract = {Upcoming astronomical surveys such as the Large Synoptic Survey Telescope (LSST) will rely on photometric classification to identify the majority of the transients and variables that they discover. We present a set of techniques for photometric classification that can be applied even when the training set of spectroscopically-confirmed objects is heavily biased towards bright, low-redshift objects. Using Gaussian process regression to model arbitrary light curves in all bands simultaneously, we "augment" the training set by generating new versions of the original light curves covering a range of redshifts and observing conditions. We train a boosted decision tree classifier on features extracted from the augmented light curves, and we show how such a classifier can be designed to produce classifications that are independent of the redshift distributions of objects in the training sample. Our classification algorithm was the best-performing among the 1,094 models considered in the blinded phase of the Photometric LSST Astronomical Time-Series Classification Challenge (PLAsTiCC), scoring 0.468 on the organizers' logarithmic-loss metric with flat weights for all object classes in the training set, and achieving an AUC of 0.957 for classification of Type Ia supernovae. Our results suggest that spectroscopic campaigns used for training photometric classifiers should focus on typing large numbers of well-observed, intermediate redshift transients instead of attempting to type a sample of transients that is directly representative of the full dataset being classified. All of the algorithms described in this paper are implemented in the avocado software package.},
  archiveprefix = {arXiv},
  eprint = {1907.04690},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\52WPETNA\\Boone - 2019 - Avocado Photometric Classification of Astronomica.pdf;C\:\\Users\\sidch\\Zotero\\storage\\AEX96A6R\\1907.html},
  journal = {arXiv:1907.04690 [astro-ph]},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
  primaryclass = {astro-ph}
}

@article{vanroestelZTFSourceClassification2021,
  title = {The {{ZTF Source Classification Project}}: {{I}}. {{Methods}} and {{Infrastructure}}},
  shorttitle = {The {{ZTF Source Classification Project}}},
  author = {{van Roestel}, Jan and Duev, Dmitry A. and Mahabal, Ashish A. and Coughlin, Michael W. and Mr{\'o}z, Przemek and Burdge, Kevin and Drake, Andrew and Graham, Matthew J. and Hillenbrand, Lynne and Fremling, C. and Hale, David and Laher, Russ R. and Masci, Frank J. and Riddle, Reed and Rosnet, Philippe and Rusholme, Ben and Smith, Roger and Soumagnac, Maayane T. and Walters, Richard and Prince, Thomas A. and Kulkarni, S. R.},
  year = {2021},
  month = feb,
  abstract = {The Zwicky Transient Facility (ZTF) has been observing the entire northern sky since the start of 2018 down to a magnitude of 20.5 (\$5 \textbackslash sigma\$ for 30s exposure) in \$g\$, \$r\$, and \$i\$ filters. Over the course of two years, ZTF has obtained light curves of more than a billion sources, each with 50-1000 epochs per light curve in \$g\$ and \$r\$, and fewer in \$i\$. To be able to use the information contained in the light curves of variable sources for new scientific discoveries, an efficient and flexible framework is needed to classify them. In this paper, we introduce the methods and infrastructure which will be used to classify all ZTF light curves. Our approach aims to be flexible and modular and allows the use of a dynamical classification scheme and labels, continuously evolving training sets, and the use of different machine learning classifier types and architectures. With this setup, we are able to continuously update and improve the classification of ZTF light curves as new data becomes available, training samples are updated, and new classes need to be incorporated.},
  archiveprefix = {arXiv},
  eprint = {2102.11304},
  eprinttype = {arxiv},
  file = {C\:\\Users\\sidch\\Zotero\\storage\\CJTJE7XF\\van Roestel et al. - 2021 - The ZTF Source Classification Project I. Methods .pdf;C\:\\Users\\sidch\\Zotero\\storage\\PADV8W89\\2102.html},
  journal = {arXiv:2102.11304 [astro-ph]},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics,Astrophysics - Solar and Stellar Astrophysics},
  primaryclass = {astro-ph}
}
@article{weir1995automated,
  title={Automated star/galaxy classification for digitized POSS-II},
  author={Weir, Nicholas and Fayyad, Usama M and Djorgovski, S},
  journal={\aj},
  volume={109},
  pages={2401},
  year={1995}
}
@article{xu2015empirical,
  author    = {Bing Xu and
               Naiyan Wang and
               Tianqi Chen and
               Mu Li},
  title     = {Empirical Evaluation of Rectified Activations in Convolutional Network},
  journal   = {CoRR},
  volume    = {abs/1505.00853},
  year      = {2015},
  url       = {http://arxiv.org/abs/1505.00853},
  eprinttype = {arXiv},
  eprint    = {1505.00853},
  timestamp = {Mon, 13 Aug 2018 16:48:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/XuWCL15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{Abazajian2009,
       author = {{Abazajian}, Kevork N. and {Adelman-McCarthy}, Jennifer K. and {Ag{\"u}eros}, Marcel A. and {Allam}, Sahar S. and {Allende Prieto}, Carlos and {An}, Deokkeun and {Anderson}, Kurt S.~J. and {Anderson}, Scott F. and {Annis}, James and {Bahcall}, Neta A. and {Bailer-Jones}, C.~A.~L. and {Barentine}, J.~C. and {Bassett}, Bruce A. and {Becker}, Andrew C. and {Beers}, Timothy C. and {Bell}, Eric F. and {Belokurov}, Vasily and {Berlind}, Andreas A. and {Berman}, Eileen F. and {Bernardi}, Mariangela and {Bickerton}, Steven J. and {Bizyaev}, Dmitry and {Blakeslee}, John P. and {Blanton}, Michael R. and {Bochanski}, John J. and {Boroski}, William N. and {Brewington}, Howard J. and {Brinchmann}, Jarle and {Brinkmann}, J. and {Brunner}, Robert J. and {Budav{\'a}ri}, Tam{\'a}s and {Carey}, Larry N. and {Carliles}, Samuel and {Carr}, Michael A. and {Castander}, Francisco J. and {Cinabro}, David and {Connolly}, A.~J. and {Csabai}, Istv{\'a}n and {Cunha}, Carlos E. and {Czarapata}, Paul C. and {Davenport}, James R.~A. and {de Haas}, Ernst and {Dilday}, Ben and {Doi}, Mamoru and {Eisenstein}, Daniel J. and {Evans}, Michael L. and {Evans}, N.~W. and {Fan}, Xiaohui and {Friedman}, Scott D. and {Frieman}, Joshua A. and {Fukugita}, Masataka and {G{\"a}nsicke}, Boris T. and {Gates}, Evalyn and {Gillespie}, Bruce and {Gilmore}, G. and {Gonzalez}, Belinda and {Gonzalez}, Carlos F. and {Grebel}, Eva K. and {Gunn}, James E. and {Gy{\"o}ry}, Zsuzsanna and {Hall}, Patrick B. and {Harding}, Paul and {Harris}, Frederick H. and {Harvanek}, Michael and {Hawley}, Suzanne L. and {Hayes}, Jeffrey J.~E. and {Heckman}, Timothy M. and {Hendry}, John S. and {Hennessy}, Gregory S. and {Hindsley}, Robert B. and {Hoblitt}, J. and {Hogan}, Craig J. and {Hogg}, David W. and {Holtzman}, Jon A. and {Hyde}, Joseph B. and {Ichikawa}, Shin-ichi and {Ichikawa}, Takashi and {Im}, Myungshin and {Ivezi{\'c}}, {\v{Z}}eljko and {Jester}, Sebastian and {Jiang}, Linhua and {Johnson}, Jennifer A. and {Jorgensen}, Anders M. and {Juri{\'c}}, Mario and {Kent}, Stephen M. and {Kessler}, R. and {Kleinman}, S.~J. and {Knapp}, G.~R. and {Konishi}, Kohki and {Kron}, Richard G. and {Krzesinski}, Jurek and {Kuropatkin}, Nikolay and {Lampeitl}, Hubert and {Lebedeva}, Svetlana and {Lee}, Myung Gyoon and {Lee}, Young Sun and {French Leger}, R. and {L{\'e}pine}, S{\'e}bastien and {Li}, Nolan and {Lima}, Marcos and {Lin}, Huan and {Long}, Daniel C. and {Loomis}, Craig P. and {Loveday}, Jon and {Lupton}, Robert H. and {Magnier}, Eugene and {Malanushenko}, Olena and {Malanushenko}, Viktor and {Mandelbaum}, Rachel and {Margon}, Bruce and {Marriner}, John P. and {Mart{\'\i}nez-Delgado}, David and {Matsubara}, Takahiko and {McGehee}, Peregrine M. and {McKay}, Timothy A. and {Meiksin}, Avery and {Morrison}, Heather L. and {Mullally}, Fergal and {Munn}, Jeffrey A. and {Murphy}, Tara and {Nash}, Thomas and {Nebot}, Ada and {Neilsen}, Eric H., Jr. and {Newberg}, Heidi Jo and {Newman}, Peter R. and {Nichol}, Robert C. and {Nicinski}, Tom and {Nieto-Santisteban}, Maria and {Nitta}, Atsuko and {Okamura}, Sadanori and {Oravetz}, Daniel J. and {Ostriker}, Jeremiah P. and {Owen}, Russell and {Padmanabhan}, Nikhil and {Pan}, Kaike and {Park}, Changbom and {Pauls}, George and {Peoples}, John, Jr. and {Percival}, Will J. and {Pier}, Jeffrey R. and {Pope}, Adrian C. and {Pourbaix}, Dimitri and {Price}, Paul A. and {Purger}, Norbert and {Quinn}, Thomas and {Raddick}, M. Jordan and {Re Fiorentin}, Paola and {Richards}, Gordon T. and {Richmond}, Michael W. and {Riess}, Adam G. and {Rix}, Hans-Walter and {Rockosi}, Constance M. and {Sako}, Masao and {Schlegel}, David J. and {Schneider}, Donald P. and {Scholz}, Ralf-Dieter and {Schreiber}, Matthias R. and {Schwope}, Axel D. and {Seljak}, Uro{\v{s}} and {Sesar}, Branimir and {Sheldon}, Erin and {Shimasaku}, Kazu and {Sibley}, Valena C. and {Simmons}, A.~E. and {Sivarani}, Thirupathi and {Allyn Smith}, J. and {Smith}, Martin C. and {Smol{\v{c}}i{\'c}}, Vernesa and {Snedden}, Stephanie A. and {Stebbins}, Albert and {Steinmetz}, Matthias and {Stoughton}, Chris and {Strauss}, Michael A. and {SubbaRao}, Mark and {Suto}, Yasushi and {Szalay}, Alexander S. and {Szapudi}, Istv{\'a}n and {Szkody}, Paula and {Tanaka}, Masayuki and {Tegmark}, Max and {Teodoro}, Luis F.~A. and {Thakar}, Aniruddha R. and {Tremonti}, Christy A. and {Tucker}, Douglas L. and {Uomoto}, Alan and {Vanden Berk}, Daniel E. and {Vandenberg}, Jan and {Vidrih}, S. and {Vogeley}, Michael S. and {Voges}, Wolfgang and {Vogt}, Nicole P. and {Wadadekar}, Yogesh and {Watters}, Shannon and {Weinberg}, David H. and {West}, Andrew A. and {White}, Simon D.~M. and {Wilhite}, Brian C. and {Wonders}, Alainna C. and {Yanny}, Brian and {Yocum}, D.~R. and {York}, Donald G. and {Zehavi}, Idit and {Zibetti}, Stefano and {Zucker}, Daniel B.},
        title = "{The Seventh Data Release of the Sloan Digital Sky Survey}",
      journal = {\apjs},
     keywords = {atlases, catalogs, surveys, Astrophysics},
         year = 2009,
        month = jun,
       volume = {182},
       number = {2},
        pages = {543-558},
          doi = {10.1088/0067-0049/182/2/543},
archivePrefix = {arXiv},
       eprint = {0812.0649},
 primaryClass = {astro-ph},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2009ApJS..182..543A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@article{Fadely_Hogg_Willman_2012, title={Star-Galaxy Classification in Multi-Band Optical Imaging}, volume={760}, url={http://arxiv.org/abs/1206.4306}, DOI={10.1088/0004-637X/760/1/15}, abstractNote={Ground-based optical surveys such as PanSTARRS, DES, and LSST, will produce large catalogs to limiting magnitudes of r > 24. Star-galaxy separation poses a major challenge to such surveys because galaxies---even very compact galaxies---outnumber halo stars at these depths. We investigate photometric classification techniques on stars and galaxies with intrinsic FWHM < 0.2 arcsec. We consider unsupervised spectral energy distribution template fitting and supervised, data-driven Support Vector Machines (SVM). For template fitting, we use a Maximum Likelihood (ML) method and a new Hierarchical Bayesian (HB) method, which learns the prior distribution of template probabilities from the data. SVM requires training data to classify unknown sources; ML and HB don’t. We consider i.) a best-case scenario (SVM_best) where the training data is (unrealistically) a random sampling of the data in both signal-to-noise and demographics, and ii.) a more realistic scenario where training is done on higher signal-to-noise data (SVM_real) at brighter apparent magnitudes. Testing with COSMOS ugriz data we find that HB outperforms ML, delivering ~80 \% completeness, with purity of ~60-90\% for both stars and galaxies, respectively. We find no algorithm delivers perfect performance, and that studies of metal-poor main-sequence turnoff stars may be challenged by poor star-galaxy separation. Using the Receiver Operating Characteristic curve, we find a best-to-worst ranking of SVM_best, HB, ML, and SVM_real. We conclude, therefore, that a well trained SVM will outperform template-fitting methods. However, a normally trained SVM performs worse. Thus, Hierarchical Bayesian template fitting may prove to be the optimal classification method in future surveys.}, note={arXiv: 1206.4306}, number={1}, journal={\apj}, author={Fadely, Ross and Hogg, David W. and Willman, Beth}, year={2012}, month={Nov}, pages={15}
}

@inproceedings {deVaucouleurs1948,
  title = {Research on extragalactic nebulas},
  author = {de Vaucouleurs, Gerard},
  booktitle = {Annals of Astrophysics},
  volume = {11},
  pages = {247},
  year = {1948}
}

@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  howpublished={\url{https://keras.io}},
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@Article{matplotlib,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python for
  application development, interactive scripting, and publication-quality
  image generation across user interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi       = {10.1109/MCSE.2007.55},
  year      = 2007
}

@conference{jupyter,
	Author = {Thomas Kluyver and Benjamin Ragan-Kelley and Fernando P{\'e}rez and Brian Granger and Matthias Bussonnier and Jonathan Frederic and Kyle Kelley and Jessica Hamrick and Jason Grout and Sylvain Corlay and Paul Ivanov and Dami{\'a}n Avila and Safia Abdalla and Carol Willing},
	Booktitle = {Positioning and Power in Academic Publishing: Players, Agents and Agendas},
	Editor = {F. Loizides and B. Schmidt},
	Organization = {IOS Press},
	Pages = {87 - 90},
	Title = {Jupyter Notebooks -- a publishing format for reproducible computational workflows},
	Year = {2016}}

@ARTICLE{scipy,
       author = {{Virtanen}, Pauli and {Gommers}, Ralf and {Oliphant},
         Travis E. and {Haberland}, Matt and {Reddy}, Tyler and
         {Cournapeau}, David and {Burovski}, Evgeni and {Peterson}, Pearu
         and {Weckesser}, Warren and {Bright}, Jonathan and {van der Walt},
         St{\'e}fan J.  and {Brett}, Matthew and {Wilson}, Joshua and
         {Jarrod Millman}, K.  and {Mayorov}, Nikolay and {Nelson}, Andrew
         R.~J. and {Jones}, Eric and {Kern}, Robert and {Larson}, Eric and
         {Carey}, CJ and {Polat}, {\.I}lhan and {Feng}, Yu and {Moore},
         Eric W. and {Vand erPlas}, Jake and {Laxalde}, Denis and
         {Perktold}, Josef and {Cimrman}, Robert and {Henriksen}, Ian and
         {Quintero}, E.~A. and {Harris}, Charles R and {Archibald}, Anne M.
         and {Ribeiro}, Ant{\^o}nio H. and {Pedregosa}, Fabian and
         {van Mulbregt}, Paul and {Contributors}, SciPy 1. 0},
        title = "{SciPy 1.0: Fundamental Algorithms for Scientific
                  Computing in Python}",
      journal = {Nature Methods},
      year = "2020",
      volume={17},
      pages={261--272},
      adsurl = {https://rdcu.be/b08Wh},
      doi = {https://doi.org/10.1038/s41592-019-0686-2},
}

@article{numpy,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}


@ARTICLE{numpy2,
  author={S. {van der Walt} and S. C. {Colbert} and G. {Varoquaux}},
  journal={Computing in Science   Engineering}, 
  title={The NumPy Array: A Structure for Efficient Numerical Computation}, 
  year={2011},
  volume={13},
  number={2},
  pages={22-30},}



@misc{pandas,
  title = {Pandas-Dev/Pandas: {{Pandas}} 1.4.2},
  shorttitle = {Pandas-Dev/Pandas},
  author = {Reback, Jeff and Jbrockmendel and McKinney, Wes and Van Den Bossche, Joris and Augspurger, Tom and Roeschke, Matthew and Hawkins, Simon and Cloud, Phillip and Gfyoung and Sinhrks and Hoefler, Patrick and Klein, Adam and Terji Petersen and Tratner, Jeff and She, Chang and Ayd, William and Naveh, Shahar and JHM Darbyshire and Garcia, Marc and Shadrach, Richard and Schendel, Jeremy and Hayden, Andy and Saxton, Daniel and Gorelli, Marco Edward and Fangchen Li and Zeitlin, Matthew and Jancauskas, Vytautas and McMaster, Ali and W{\"o}rtwein, Torsten and Battiston, Pietro},
  year = {2022},
  month = apr,
  doi = {10.5281/ZENODO.6408044},
  abstract = {This is a patch release in the 1.4.x series and includes some regression and bug fixes. We recommend that all users upgrade to this version. See the full whatsnew for a list of all the changes. The release will be available on the defaults and conda-forge channels: &lt;code&gt;conda install pandas &lt;/code&gt; Or via PyPI: &lt;code&gt;python3 -m pip install --upgrade pandas &lt;/code&gt; Please report any issues with the release on the pandas issue tracker.},
  copyright = {Open Access},
  howpublished = {Zenodo}
}

@InProceedings{pandas2,
  author    = { {W}es {M}c{K}inney },
  title     = { {D}ata {S}tructures for {S}tatistical {C}omputing in {P}ython },
  booktitle = { {P}roceedings of the 9th {P}ython in {S}cience {C}onference },
  pages     = { 56 - 61 },
  year      = { 2010 },
  editor    = { {S}t\'efan van der {W}alt and {J}arrod {M}illman },
  doi       = { 10.25080/Majora-92bf1922-00a }
}

@book{python3,
 author = {Van Rossum, Guido and Drake, Fred L.},
 title = {Python 3 Reference Manual},
 year = {2009},
 isbn = {1441412697},
 publisher = {CreateSpace},
 address = {Scotts Valley, CA}
}

@misc{tensorflow,
title={{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={http://tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dan~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}


%% Citations for the ML supervised etc explanation part:

@inproceedings{howard2017machine,
  title={Machine learning algorithms in Astronomy},
  author={Howard, EM},
  booktitle={Astronomical Data Analysis Software and Systems XXV},
  volume={512},
  pages={245},
  year={2017}
}

@misc{baron2019machine,
title={Machine Learning in Astronomy: a practical overview},
author={Dalya Baron},
year={2019},
eprint={1904.07248},
archivePrefix={arXiv},
primaryClass={astro-ph.IM}
}

%%DATA AUGMENTATION

%%DATA AUGMENTATION CITATIONS
@misc{perez2017effectiveness,
      title={The Effectiveness of Data Augmentation in Image Classification using Deep Learning}, 
      author={Luis Perez and Jason Wang},
      year={2017},
      eprint={1712.04621},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{gal2016theoretically,
      title={A Theoretically Grounded Application of Dropout in Recurrent Neural Networks}, 
      author={Yarin Gal and Zoubin Ghahramani},
      year={2016},
      eprint={1512.05287},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{witten,
author = {Witten, Ian H. and Frank, Eibe},
title = {Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations},
year = {2002},
issue_date = {March 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {0163-5808},
url = {https://doi.org/10.1145/507338.507355},
doi = {10.1145/507338.507355},
journal = {SIGMOD Rec.},
month = mar,
pages = {76–77},
numpages = {2}
}

@misc{kubo2017compacting,
      title={Compacting Neural Network Classifiers via Dropout Training}, 
      author={Yotaro Kubo and George Tucker and Simon Wiesler},
      year={2017},
      eprint={1611.06148},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{lupton2001astronomical,
  title={Astronomical Data Analysis Software and Systems X},
  author={Lupton, R and Gunn, JE and Ivezi{\'c}, Z and Knapp, GR and Kent, S and Yasuda, N and Harnden, FR and Primini, FA and Payne, HE},
  booktitle={ASP conf. Ser},
  volume={238},
  pages={269},
  year={2001}
}

@article{cabayol2019pau,
       author = {{Cabayol}, L. and {Sevilla-Noarbe}, I. and {Fern{\'a}ndez}, E. and {Carretero}, J. and {Eriksen}, M. and {Serrano}, S. and {Alarc{\'o}n}, A. and {Amara}, A. and {Casas}, R. and {Castander}, F.~J. and {de Vicente}, J. and {Folger}, M. and {Garc{\'\i}a-Bellido}, J. and {Gaztanaga}, E. and {Hoekstra}, H. and {Miquel}, R. and {Padilla}, C. and {S{\'a}nchez}, E. and {Stothert}, L. and {Tallada}, P. and {Tortorelli}, L.},
        title = "{The PAU survey: star-galaxy classification with multi narrow-band data}",
      journal = {\mnras},
     keywords = {methods: data analysis, techniques: photometric, Astrophysics - Instrumentation and Methods for Astrophysics},
         year = 2019,
        month = feb,
       volume = {483},
       number = {1},
        pages = {529-539},
          doi = {10.1093/mnras/sty3129},
archivePrefix = {arXiv},
       eprint = {1806.08545},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019MNRAS.483..529C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@misc{weisstein2004affine,
  title = {"{{Affine Function}}." {{From MathWorld--A Wolfram Web Resource}}, Created by {{Eric W}}. {{Weisstein}}.},
  author = {Gallini, Alberto},
  url = {https://mathworld.wolfram.com/AffineFunction.html}
}




@article{SrivastavaDropout,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929-1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@ARTICLE{2009ApJS..180...67R,
       author = {{Richards}, Gordon T. and {Myers}, Adam D. and {Gray}, Alexander G. and {Riegel}, Ryan N. and {Nichol}, Robert C. and {Brunner}, Robert J. and {Szalay}, Alexander S. and {Schneider}, Donald P. and {Anderson}, Scott F.},
        title = "{Efficient Photometric Selection of Quasars from the Sloan Digital Sky Survey. II. \raisebox{-0.5ex}\textasciitilde1,000,000 Quasars from Data Release 6}",
      journal = {\apjs},
     keywords = {catalogs, quasars: general, Astrophysics},
         year = 2009,
        month = jan,
       volume = {180},
       number = {1},
        pages = {67-83},
          doi = {10.1088/0067-0049/180/1/67},
archivePrefix = {arXiv},
       eprint = {0809.3952},
 primaryClass = {astro-ph},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2009ApJS..180...67R},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@ARTICLE{2014yCat....102023S,
       author = {{Skiff}, B.~A.},
        title = "{VizieR Online Data Catalog: Catalogue of Stellar Spectral Classifications (Skiff, 2009-2014)}",
      journal = {VizieR Online Data Catalog},
     keywords = {Spectral types, MK spectral classification},
         year = 2014,
        month = oct,
          eid = {B/mk},
        pages = {B/mk},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2014yCat....102023S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@article{nair2022fraction,
       author = {{Nair}, A. and {Vivek}, M.},
        title = "{Fraction of broad absorption line quasars in different radio morphologies}",
      journal = {\mnras},
     keywords = {methods: data analysis, galaxies: jets, quasars: absorption lines, quasars: general, Astrophysics - Astrophysics of Galaxies, Astrophysics - Cosmology and Nongalactic Astrophysics},
         year = 2022,
        month = apr,
       volume = {511},
       number = {4},
        pages = {4946-4962},
          doi = {10.1093/mnras/stac204},
archivePrefix = {arXiv},
       eprint = {2201.09901},
 primaryClass = {astro-ph.GA},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022MNRAS.511.4946N},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}
@article{mcculloch1943logical,
  title={A logical calculus of the ideas immanent in nervous activity},
  author={McCulloch, Warren S and Pitts, Walter},
  journal={The bulletin of mathematical biophysics},
  volume={5},
  number={4},
  pages={115--133},
  year={1943},
  publisher={Springer}
}
@inproceedings{xiong2018ai,
  title={AI-NET: Attention inception neural networks for hyperspectral image classification},
  author={Xiong, Zhitong and Yuan, Yuan and Wang, Qi},
  booktitle={IGARSS 2018-2018 IEEE International Geoscience and Remote Sensing Symposium},
  pages={2647--2650},
  year={2018},
  organization={IEEE}
}
@article{JMLR:v15:srivastava14a,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929--1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}
@ARTICLE{nakazono,
       author = {{Nakazono}, L. and {Mendes de Oliveira}, C. and {Hirata}, N.~S.~T. and {Jeram}, S. and {Queiroz}, C. and {Eikenberry}, Stephen S. and {Gonzalez}, A.~H. and {Abramo}, R. and {Overzier}, R. and {Espadoto}, M. and {Martinazzo}, A. and {Sampedro}, L. and {Herpich}, F.~R. and {Almeida-Fernandes}, F. and {Werle}, A. and {Barbosa}, C.~E. and {Sodr{\'e}}, L., Jr. and {Lima}, E.~V. and {Buzzo}, M.~L. and {Cortesi}, A. and {Men{\'e}ndez-Delmestre}, K. and {Akras}, S. and {Alvarez-Candal}, Alvaro and {Lopes}, A.~R. and {Telles}, E. and {Schoenell}, W. and {Kanaan}, A. and {Ribeiro}, T.},
        title = "{On the discovery of stars, quasars, and galaxies in the Southern Hemisphere with S-PLUS DR2}",
      journal = {\mnras},
     keywords = {methods: data analysis, catalogues, surveys, stars: general, galaxies: general, quasars: general, Astrophysics - Astrophysics of Galaxies, Astrophysics - Cosmology and Nongalactic Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics, Astrophysics - Solar and Stellar Astrophysics},
         year = 2021,
        month = nov,
       volume = {507},
       number = {4},
        pages = {5847-5868},
          doi = {10.1093/mnras/stab1835},
archivePrefix = {arXiv},
       eprint = {2106.11986},
 primaryClass = {astro-ph.GA},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2021MNRAS.507.5847N},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@article{Xiaoqing2020ClassificationOS,
  title={Classification of star/galaxy/QSO and star spectral types from LAMOST data release 5 with machine learning approaches},
  author={Wen Xiao-qing and Yang Jin-Meng},
  journal={Chinese Journal of Physics},
  year={2020}
}

@article{lamost,
       author = {{Cui}, Xiang-Qun and {Zhao}, Yong-Heng and {Chu}, Yao-Quan and {Li}, Guo-Ping and {Li}, Qi and {Zhang}, Li-Ping and {Su}, Hong-Jun and {Yao}, Zheng-Qiu and {Wang}, Ya-Nan and {Xing}, Xiao-Zheng and {Li}, Xin-Nan and {Zhu}, Yong-Tian and {Wang}, Gang and {Gu}, Bo-Zhong and {Luo}, A. -Li and {Xu}, Xin-Qi and {Zhang}, Zhen-Chao and {Liu}, Gen-Rong and {Zhang}, Hao-Tong and {Yang}, De-Hua and {Cao}, Shu-Yun and {Chen}, Hai-Yuan and {Chen}, Jian-Jun and {Chen}, Kun-Xin and {Chen}, Ying and {Chu}, Jia-Ru and {Feng}, Lei and {Gong}, Xue-Fei and {Hou}, Yong-Hui and {Hu}, Hong-Zhuan and {Hu}, Ning-Sheng and {Hu}, Zhong-Wen and {Jia}, Lei and {Jiang}, Fang-Hua and {Jiang}, Xiang and {Jiang}, Zi-Bo and {Jin}, Ge and {Li}, Ai-Hua and {Li}, Yan and {Li}, Ye-Ping and {Liu}, Guan-Qun and {Liu}, Zhi-Gang and {Lu}, Wen-Zhi and {Mao}, Yin-Dun and {Men}, Li and {Qi}, Yong-Jun and {Qi}, Zhao-Xiang and {Shi}, Huo-Ming and {Tang}, Zheng-Hong and {Tao}, Qing-Sheng and {Wang}, Da-Qi and {Wang}, Dan and {Wang}, Guo-Min and {Wang}, Hai and {Wang}, Jia-Ning and {Wang}, Jian and {Wang}, Jian-Ling and {Wang}, Jian-Ping and {Wang}, Lei and {Wang}, Shu-Qing and {Wang}, You and {Wang}, Yue-Fei and {Xu}, Ling-Zhe and {Xu}, Yan and {Yang}, Shi-Hai and {Yu}, Yong and {Yuan}, Hui and {Yuan}, Xiang-Yan and {Zhai}, Chao and {Zhang}, Jing and {Zhang}, Yan-Xia and {Zhang}, Yong and {Zhao}, Ming and {Zhou}, Fang and {Zhou}, Guo-Hua and {Zhu}, Jie and {Zou}, Si-Cheng},
        title = "{The Large Sky Area Multi-Object Fiber Spectroscopic Telescope (LAMOST)}",
      journal = {Research in Astronomy and Astrophysics},
         year = 2012,
        month = sep,
       volume = {12},
       number = {9},
        pages = {1197-1242},
          doi = {10.1088/1674-4527/12/9/003},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2012RAA....12.1197C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{wise2010,
       author = {{Wright}, Edward L. and {Eisenhardt}, Peter R.~M. and {Mainzer}, Amy K. and {Ressler}, Michael E. and {Cutri}, Roc M. and {Jarrett}, Thomas and {Kirkpatrick}, J. Davy and {Padgett}, Deborah and {McMillan}, Robert S. and {Skrutskie}, Michael and {Stanford}, S.~A. and {Cohen}, Martin and {Walker}, Russell G. and {Mather}, John C. and {Leisawitz}, David and {Gautier}, Thomas N., III and {McLean}, Ian and {Benford}, Dominic and {Lonsdale}, Carol J. and {Blain}, Andrew and {Mendez}, Bryan and {Irace}, William R. and {Duval}, Valerie and {Liu}, Fengchuan and {Royer}, Don and {Heinrichsen}, Ingolf and {Howard}, Joan and {Shannon}, Mark and {Kendall}, Martha and {Walsh}, Amy L. and {Larsen}, Mark and {Cardon}, Joel G. and {Schick}, Scott and {Schwalm}, Mark and {Abid}, Mohamed and {Fabinsky}, Beth and {Naes}, Larry and {Tsai}, Chao-Wei},
        title = "{The Wide-field Infrared Survey Explorer (WISE): Mission Description and Initial On-orbit Performance}",
      journal = {\aj},
     keywords = {infrared: general, space vehicles, surveys, Astrophysics - Instrumentation and Methods for Astrophysics},
         year = 2010,
        month = dec,
       volume = {140},
       number = {6},
        pages = {1868-1881},
          doi = {10.1088/0004-6256/140/6/1868},
archivePrefix = {arXiv},
       eprint = {1008.0031},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2010AJ....140.1868W},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{seaborn,
    doi = {10.21105/joss.03021},
    url = {https://doi.org/10.21105/joss.03021},
    year = {2021},
    publisher = {The Open Journal},
    volume = {6},
    number = {60},
    pages = {3021},
    author = {Michael L. Waskom},
    title = {seaborn: statistical data visualization},
    journal = {Journal of Open Source Software}
 }

@misc{kerastuner,
    title        = {KerasTuner},
    author       = {O'Malley, Tom and Bursztein, Elie and Long, James and Chollet, Fran\c{c}ois and Jin, Haifeng and Invernizzi, Luca and others},
    year         = 2019,
    howpublished = {\url{https://github.com/keras-team/keras-tuner}}
}

@software{tqdm,
  author       = {Casper da Costa-Luis and
                  Stephen Karl Larroque and
                  Kyle Altendorf and
                  Hadrien Mary and
                  richardsheridan and
                  Mikhail Korobov and
                  Noam Raphael and
                  Ivan Ivanov and
                  Marcel Bargull and
                  Nishant Rodrigues and
                  Guangshuo Chen and
                  Antony Lee and
                  Charles Newey and
                  CrazyPython and
                  JC and
                  Martin Zugnoni and
                  Matthew D. Pagel and
                  mjstevens777 and
                  Mikhail Dektyarev and
                  Alex Rothberg and
                  Alexander Plavin and
                  Daniel Panteleit and
                  Fabian Dill and
                  FichteFoll and
                  Gregor Sturm and
                  HeoHeo and
                  Hugo van Kemenade and
                  Jack McCracken and
                  MapleCCC and
                  Max Nordlund},
  title        = {{tqdm: A fast, Extensible Progress Bar for Python 
                   and CLI}},
  month        = sep,
  year         = 2022,
  publisher    = {Zenodo},
  version      = {v4.64.1},
  doi          = {10.5281/zenodo.7046742},
  url          = {https://doi.org/10.5281/zenodo.7046742}
}


@article{splus,
    author = {Mendes de Oliveira, C and Ribeiro, T and Schoenell, W and Kanaan, A and Overzier, R A and Molino, A and Sampedro, L and Coelho, P and Barbosa, C E and Cortesi, A and Costa-Duarte, M V and Herpich, F R and Hernandez-Jimenez, J A and Placco, V M and Xavier, H S and Abramo, L R and Saito, R K and Chies-Santos, A L and Ederoclite, A and Lopes de Oliveira, R and Gonçalves, D R and Akras, S and Almeida, L A and Almeida-Fernandes, F and Beers, T C and Bonatto, C and Bonoli, S and Cypriano, E S and Vinicius-Lima, E and de Souza, R S and Fabiano de Souza, G and Ferrari, F and Gonçalves, T S and Gonzalez, A H and Gutiérrez-Soto, L A and Hartmann, E A and Jaffe, Y and Kerber, L O and Lima-Dias, C and Lopes, P A A and Menendez-Delmestre, K and Nakazono, L M I and Novais, P M and Ortega-Minakata, R A and Pereira, E S and Perottoni, H D and Queiroz, C and Reis, R R R and Santos, W A and Santos-Silva, T and Santucci, R M and Barbosa, C L and Siffert, Beatriz B and Sodré, L, Jr and Torres-Flores, S and Westera, P and Whitten, D D and Alcaniz, J S and Alonso-García, Javier and Alencar, S and Alvarez-Candal, A and Amram, P and Azanha, L and Barbá, R H and Bernardinelli, P H and Borges Fernandes, M and Branco, V and Brito-Silva, D and Buzzo, M L and Caffer, J and Campillay, A and Cano, Z and Carvano, J M and Castejon, M and Cid Fernandes, R and Dantas, M L L and Daflon, S and Damke, G and de la Reza, R and de Melo de Azevedo, L J and De Paula, D F and Diem, K G and Donnerstein, R and Dors, O L and Dupke, R and Eikenberry, S and Escudero, Carlos G and Faifer, Favio R and Farías, H and Fernandes, B and Fernandes, C and Fontes, S and Galarza, A and Hirata, N S T and Katena, L and Gregorio-Hetem, J and Hernández-Fernández, J D and Izzo, L and Jaque Arancibia, M and Jatenco-Pereira, V and Jiménez-Teja, Y and Kann, D A and Krabbe, A C and Labayru, C and Lazzaro, D and Lima Neto, G B and Lopes, Amanda R and Magalhães, R and Makler, M and de Menezes, R and Miralda-Escudé, J and Monteiro-Oliveira, R and Montero-Dorta, A D and Muñoz-Elgueta, N and Nemmen, R S and Nilo Castellón, J L and Oliveira, A S and Ortíz, D and Pattaro, E and Pereira, C B and Quint, B and Riguccini, L and Rocha Pinto, H J and Rodrigues, I and Roig, F and Rossi, S and Saha, Kanak and Santos, R and Schnorr Müller, A and Sesto, Leandro A and Silva, R and Smith Castelli, Analia V and Teixeira, R and Telles, E and Thom de Souza, R C and Thöne, C and Trevisan, M and de Ugarte Postigo, A and Urrutia-Viscarra, F and Veiga, C H and Vika, M and Vitorelli, A Z and Werle, A and Werner, S V and Zaritsky, D},
    title = "{The Southern Photometric Local Universe Survey (S-PLUS): improved SEDs, morphologies, and redshifts with 12 optical filters}",
    journal = {Monthly Notices of the Royal Astronomical Society},
    volume = {489},
    number = {1},
    pages = {241-267},
    year = {2019},
    month = {08},
    abstract = "{The Southern Photometric Local Universe Survey (S-PLUS) is imaging ∼9300 deg2 of the celestial sphere in 12 optical bands using a dedicated 0.8 m robotic telescope, the T80-South, at the Cerro Tololo Inter-american Observatory, Chile. The telescope is equipped with a 9.2k × 9.2k e2v detector with 10 \\$\\rm \\{\\mu m\\}\\$ pixels, resulting in a field of view of 2 deg2 with a plate scale of 0.55 arcsec pixel−1. The survey consists of four main subfields, which include two non-contiguous fields at high Galactic latitudes (|b| \\&gt; 30°, 8000 deg2) and two areas of the Galactic Disc and Bulge (for an additional 1300 deg2). S-PLUS uses the Javalambre 12-band magnitude system, which includes the 5 ugriz broad-band filters and 7 narrow-band filters centred on prominent stellar spectral features: the Balmer jump/[OII], Ca H + K, H δ, G band, Mg b triplet, H α, and the Ca triplet. S-PLUS delivers accurate photometric redshifts (δz/(1 + z) = 0.02 or better) for galaxies with r \\&lt; 19.7 AB mag and z \\&lt; 0.4, thus producing a 3D map of the local Universe over a volume of more than \\$1\\, (\\mathrm\\{Gpc\\}/h)^3\\$. The final S-PLUS catalogue will also enable the study of star formation and stellar populations in and around the Milky Way and nearby galaxies, as well as searches for quasars, variable sources, and low-metallicity stars. In this paper we introduce the main characteristics of the survey, illustrated with science verification data highlighting the unique capabilities of S-PLUS. We also present the first public data release of ∼336 deg2 of the Stripe 82 area, in 12 bands, to a limiting magnitude of r = 21, available at datalab.noao.edu/splus.}",
    issn = {0035-8711},
    doi = {10.1093/mnras/stz1985},
    url = {https://doi.org/10.1093/mnras/stz1985},
    eprint = {https://academic.oup.com/mnras/article-pdf/489/1/241/29206521/stz1985.pdf},
}


