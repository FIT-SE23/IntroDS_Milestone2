\section{Background and related work}
\label{sec_related_work}
This work builds on two vast bodies of literature: exponential family learning and unit-level counterfactual inference with unobserved confounding. For a detailed literature overview of the former, we refer the readers to \cite{bresler2015efficiently,klivans2017learning,VuffrayML2022,ShahSW2021A} (for a special sub-class, Markov random fields (MRFs)\footnote{MRFs can be naturally represented as exponential family distributions with certain sparsity constraints on the parameters via the principle of maximum entropy  \citep{wainwright2008graphical}.}) and \cite{ShahSW2021B} for general exponential families. For an introduction to counterfactual inference, see the books \cite{imbens2015causal, hernan2020causal} for settings with no unobserved confounding and \cite{Pearl2009,Pearl2016} for settings with known causal mechanism (in the form of a causal graph). 
%


%
%

\paragraph{Exponential family learning}
There is a series of works for learning Ising models, a special MRF with binary variables and an instance of a pair-wise exponential family, from a single sample. Such a model has two distinct sets of parameters capturing the contribution of nodes and edges in the underlying undirected graph, referred to as the external field and the interaction matrix.\footnote{E.g., in our model (defined later in \cref{eq_joint_distribution_zvay}), $\phi$ and $\Phi$ correspond to the external field  and the interaction matrix, respectively.} Many strategies exist  for learning such a model when the interaction matrix is known up to a constant and under varying assumptions on the external field; see, e.g., \cite{chatterjee2007estimation,bhattacharya2018inference,daskalakis2019regression,ghosal2020joint,KandirosDDGD2021,mukherjee2021high}. More recently, \cite{DaganDDA2021} provide guarantees for learning the interaction matrix from a single sample when the external field is known. \cite{KandirosDDGD2021} and \cite{mukherjee2021high} extend the tools in \cite{DaganDDA2021} to learn the external field for an Ising model with a known interaction matrix (up to a scalar multiple). Notably, all of these works are based on the pseudo-likelihood estimation \citep{besag1975statistical}. Our work extends the techniques and results from \cite{DaganDDA2021} to learn the external field from one sample of continuous variables with an estimated interaction matrix.
%
%

%
%
\cite{vuffray2016interaction} introduced a novel loss different than pseudo-likelihood for learning Ising models from many independent and identically distributed samples.\cite{VuffrayML2022} and \cite{ShahSW2021A} generalize it to learn general MRFs with multi-ary discrete and continuous variables, respectively.
%
%
%
We contribute to this line of work by generalizing that loss function further to learn MRFs with discrete, continuous, and mixed variables with independent but not identically distributed samples.
%
%
%

 For settings closer to our work, namely, exponential families with unobserved variables, the two common modeling approaches include  restricted Boltzmann machines \citep{bresler2019learning, goel2020learning, bresler2020learning} and latent variable Gaussian graphical models; see, e.g., \cite{chandrasekaran2010latent,ma2013alternating,vinyes2018learning,wang2021learning}.
%
While the former assumes a bipartite structure with edges only across observed and unobserved variables, the latter imposes a Gaussian generative model. 
 %
%
In this thread, most related to our set-up is the work by \cite{taeb2020learning} as they consider the same exponential family with unobserved variables as ours. They provide empirically promising results for recovering the underlying graph and the number of unobserved variables (assumed to be small), albeit with limited theoretical guarantees. In contrast, here we provide parameter estimation error in the presence of unobserved variables (notably, we cover all the models they considered). 

%


%
%
%

%

%
%

%

\paragraph{Unit-level counterfactual inference} Recent years have seen an active interest in developing different strategies for unit-level inference with unobserved confounding. 


For the settings with univariate outcomes for each unit, a common approach to deal with unobserved confounding is the instrumental variable (IV) method~\citep{imbens1994identification} when one has access to a variable---the IV---that induces changes in intervention assignment but has no independent effect on outcomes allowing causal effect estimation. Recent works for IV methods with unit-level inference include
%
\cite{hartford2017deep,athey2019generalized,syrgkanis2019machine,singh2019kernel,xu2020learning,semenova2021debiased,wang2022instrumental}. 
Another approach for univariate outcomes, called causal sensitivity analysis \citep{rosenbaum1983assessing}, estimates the worst-case effect on the causal estimand as a function of the extent of unobserved confounding in a given dataset under varying assumptions on the generative model. For such analysis with unit-level guarantees, see, e.g., 
%
\cite{yadlowsky2018bounds,kallus2019interval,yin2021conformal,jin2021sensitivity,jesson2021quantifying}.
%
%

%



Closer to our work are those on panel or longitudinal data settings, where one observes multiple outcomes for each unit. For such settings, a common approach is factor modeling, where  potential outcomes and interventions (binary or multi-ary) are assumed to be independent conditional on some latent factors. See, e.g., difference-in-difference methods~\citep{bertrand2004much, angrist2009mostly}, synthetic control ~\citep{abadie1, abadie2}, its variants~\cite{arkhangelsky2021synthetic,dwivedi2022doubly}, and extensions to multi-ary interventions in synthetic interventions \citep{agarwal2020synthetic} and sequential experiments~\citep{dwivedi2022counterfactual}. 
%
%
Notably, these works directly estimate average or unit-level effects for finitely many interventions, while we focus on learning the counterfactual distributions while allowing for multi-ary discrete and continuous interventions. 
In this thread, our work is most related to \cite{arkhangelsky2018role}, who also use an exponential family to model the unit-wise distribution of the observed variables and interventions conditioned on the unobserved variables.
%
They connect this model to the commonly used fixed effects model in latent factor modeling~\citep{angrist2009mostly} and provide estimates for the average treatment effect given multiple units with the same set of unobserved covariates. Our work generalizes their set-up by allowing each unit to have a different set of unobserved covariates and provides the first unit-level counterfactual inference guarantee with an exponential family model.



%
%
%

%
%
%

%

%

%
%
%

%

%


%
%
%
%
%
%

%



%
%
%
%
%

%
%
%
%
%

%
%
%
%
%

%



%


%





%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%

%
%


%
%
%
%

%




%
%

%
%
%
%



%
%
%
%
%


%


%

%


%
%

%

%

%

%

 %



 %
 %
%
%


%
%
%



%
%
%
%
 %
 %
 %
 %
%
%
%
%


%
%
%
%
%

%
%
%
%
%

%
%


%
%
%


%
%