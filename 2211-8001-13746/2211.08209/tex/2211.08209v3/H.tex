\section{Supporting concentration results}
%
In this section, we provide a corollary of \cref{thm_main_concentration} that is used to prove the concentration results in \cref{lemma_concentration_psi} and \cref{lemma_concentration_bar_psi}. To show any concentration result for the random vector $\rvbx$ conditioned on $\rvbz$ via \cref{thm_main_concentration}, we need $\rvbx | \rvbz$ to satisfy the logarithmic Sobolev inequality (defined in \cref{eq_LSI_definition}). From \cref{thm_LSI_main}, for this to be true, we need the random vector $\rvx_t$ conditioned on $(\rvbx_{-t}, \rvbz)$ to satisfy the logarithmic Sobolev inequality for all $t \in [p]$. In the result below, we show this holds with a proof in \cref{proof_lsi_one_dim}. We define a $\tau \defeq (\aGM, \eGM, \xmax, \ParameterMatrix)$-dependent constant:
\begin{align}
\cthree \defn  \exp{(\xmax(\aGM+ 2\eGM \xmax))}. \label{eq_constants_3_cont}
\end{align}

%
%
\newcommand{\lsionedimresultname}{Logarithmic Sobolev inequality for $\rvx_t | \rvbx_{-t}, \rvbz$}
\begin{lemma}[{\lsionedimresultname}]
	\label{lemma_lsi_one_dim}
	Given a pair of random vectors $\braces{\rvbx, \rvbz}$ supported on $\cX^p \times \cZ^{p_z}$ that is a $\tSGM$ (\cref{def:tau_sgm}) with $\dGM \defn (\aGM, \eGM, \xmax, \ParameterMatrix)$, $\rvx_t | \rvbx_{-t}, \rvbz$ satisfies $\mathrm{LSI}_{\rvx_t | \rvbx_{-t} = \svbx_{-t} , \rvbz = \svbz}\Big(\frac{8\xmax^2}{\pi^2} \cthree[2]\Big)$ for all $t \in [p]$, $\svbx_{-t} \in \cX^{p-1}$, and $\svbz \in \cZ^{p_z}$.
	
	%
	%
	%
	%
	%
\end{lemma}

\noindent Now, we state the desired corollary of \cref{thm_main_concentration} with a proof in \cref{proof_of_coro}. The corollary makes use of some $\tau \defeq (\aGM, \eGM, \xmax, \ParameterMatrix)$-dependent constants:
\begin{align}
\cfour \defn 1 + \aGM \xmax + 4\xmax^2 \eGM \qtext{and} \cfive \defn \frac{32\xmax^3\cthree[4]}{\pi^2}.\label{eq_constants_4_cont}
\end{align}
\newcommand{\suppconcresultname}{Supporting concentration bounds}
\begin{corollary}[{\suppconcresultname}]\label{coro}
	Suppose a pair of random vectors $\braces{\rvbx, \rvbz}$ supported on $\cX^p \times \cZ^{p_z}$ corresponds to a $\tSGM$ (\cref{def:tau_sgm}) with $\dGM \defn (\aGM, \eGM, \xmax, \ParameterMatrix)$, and $\rvbx$ conditioned on $\rvbz$ satisfies the Dobrushin's uniqueness condition (\cref{def_dobrushin_condition}) with coupling matrix $\bParameterMatrix$. For any $\ExternalField, \bExternalField \in \ParameterSet_{\ExternalField}$ and $\ParameterMatrix \in \ParameterSet_{\ParameterMatrix}$, define the functions $q_1$ and $q_2$ as
	\begin{align}
	q_1(\rvbx) \defeq \sump \normalparenth{\omt \rvx_t}^2
	\qtext{and}
	q_2(\rvbx) \defeq \sump \omt \rvx_t \exp\Bigparenth{-\normalbrackets{\ExternalFieldt + 2 \ParameterRowttt\tp \rvbx_{-t}} \rvx_t - \ParameterTU[tt] \crx_t},
	\end{align}
	where $\om =  \bExternalField - \ExternalField$ and $\crx_t \defn \rvx_t^2 - \xmax^2/3$.
	Then, for any $\varepsilon > 0$
	\begin{align}
	\Probability\Bigbrackets{\bigabs{q_i(\rvbx) - \Expectation\bigbrackets{q_i(\rvbx) \big| \rvbz}} & \geq \varepsilon \Big| \rvbz} \leq \exp\biggparenth{ \dfrac{-c\bigparenth{1-\opnorm{\bParameterMatrix}}^4\varepsilon^2}{c_i \stwonorm{\om}^2}}
	\qtext{for} i = 1, 2, \label{eq_coro_combined}
	%
	%
	%
	%
	\end{align}
	where $c$ is a universal constant, $c_1 \defn 16 \aGM^2\xmax^2 \cfive[2]$, and $c_2 \defn \cthree[2] \cfour[2] \cfive[2]$ with $\cthree$ defined in \cref{eq_constants_3_cont} and $\cfour$ and $\cfive$ defined in \cref{eq_constants_4_cont}.
\end{corollary}


\subsection{Proof of \cref{lemma_lsi_one_dim}: \lsionedimresultname}
\label{proof_lsi_one_dim}
Let $\rvu$ be the uniform distribution on $\cX$. Then, $\rvu$ satisfies $\mathrm{LSI}_{\rvu}\Big(\frac{8\xmax^2}{\pi^2}\Big)$ (see \citet[Corollary. 2.4]{ghang2014sharp}). Then, using the Holley-Stroock perturbation principle (see \citet[Page. 31]{HS1986}, \citet[Lemma. 1.2]{Ledoux2001}), for every $t\in [p]$, $\svbx_{-t} \in \cX^{p-1}$, and $\svbz \in \cZ^{p_z}$, $\rvx_t | \rvbx_{-t} = \svbx_{-t}, \rvbz = \svbz$ satisfies the logarithmic Sobolev inequality with a 
%
%
constant bounded by $$\frac{8\xmax^2 \exp(\sup_{x_t \in \cX} \psi(x_t; \svbx_{-t}, \svbz) - \inf_{x_t \in \cX} \psi(x_t; \svbx_{-t}, \svbz))}{\pi^2},$$ where $\psi(x_t; \svbx_{-t}, \svbz) \defn - \normalbrackets{\ExternalFieldt(\svbz) + 2\ParameterRowttt\tp \svbx_{-t}} x_t - \ParameterTU[tt] \cx_t$ where $\cx_t = x_t^2 - \xmax^2/3$. We have
\begin{align}
\exp(\sup_{x_t \in \cX} \psi(x_t; \svbx_{-t}, \svbz) \!-\! \inf_{x_t \in \cX} \psi(x_t; \svbx_{-t}, \svbz))
& \sless{(a)} \!   \exp\bigparenth{ 2\bigabs{\ExternalFieldt(\svbz)\! +\! 2\ParameterRowttt\tp \svbx_{-t}} \xmax \!+\! \ParameterTU[tt] \xmax^2}\\ &\sless{(b)} \exp\big((2\aGM + 4\eGM\xmax)\xmax\big) \sequal{\cref{eq_constants_3_cont}} \cthree[2],
\end{align}
where $(a)$ follows from \cref{def:tau_sgm} and $(b)$ follows by using \cref{def:tau_sgm} along with triangle inequality and Cauchy–Schwarz inequality.


\subsection{Proof of \cref{coro}: \suppconcresultname}
\label{proof_of_coro}
To apply \cref{thm_main_concentration} to the random vector $\rvbx$ conditioned on $\rvbz$, we need $\rvbx | \rvbz$ to satisfy the logarithmic Sobolev inequality. From \cref{thm_LSI_main}, this is true if (i) $f_{\min} = \min_{t \in [p], \svbx \in \cX^p, \svbz \in \cX^{p_z}}$ $f_{\rvx_t | \rvbx_{-t}, \rvbz}(x_t | \svbx_{-t}, \svbz) > 0$ (see \cref{eq:smin}), (ii) $\rvbx | \rvbz$ satisfies the Dobrushin’s uniqueness condition, and (iii) $\rvx_t | \rvbx_{-t}, \rvbz$ satisfies the logarithmic Sobolev inequality for all $t \in [p]$. By assumption,  $\rvbx | \rvbz$ satisfies the Dobrushin’s uniqueness condition with coupling matrix $\bParameterMatrix$. From \cref{lemma_lsi_one_dim}, $\rvx_t | \rvbx_{-t}, \rvbz$ satisfies $\mathrm{LSI}_{\rvx_t | \rvbx_{-t} = \svbx_{-t} , \rvbz = \svbz}\Big(\frac{8\xmax^2\cthree[2]}{\pi^2}\Big)$. It remains to show that $f_{\min} > 0$. Consider any $t \in [p]$, any $\svbx \in \cX^p$, and any $\svbz \in \cX^{p_z}$. Let $\cx_t = x_t^2 - \xmax^2/3$. We have
\begin{align}
f_{\rvx_t | \rvbx_{-t}, \rvbz}(x_t | \svbx_{-t}, \svbz) 
& \sequal{(a)}  \frac{\exp\Bigparenth{\normalbrackets{\ExternalFieldt(\svbz) + 2\ParameterRowttt\tp \svbx_{-t} } x_t  + \ParameterTU[tt] \cx_t}}{
	\int_{\cX}
	\exp\Bigparenth{\normalbrackets{\ExternalFieldt(\svbz) + 2\ParameterRowttt\tp \svbx_{-t}} x_t + \ParameterTU[tt] \cx_t} d x_t} \\
& \sgreat{(b)}  \frac{\exp\Bigparenth{-\normalabs{\ExternalFieldt(\svbz) + 2\ParameterRowttt\tp \svbx_{-t}} \xmax - \ParameterTU[tt] \xmax^2}}{
	\int_{\cX}
	\exp\Bigparenth{\normalabs{\ExternalFieldt(\svbz) + 2\ParameterRowttt\tp \svbx_{-t}} \xmax + \ParameterTU[tt] \xmax^2} d x_t}\\
& \sgreat{(c)}  \frac{\exp\Bigparenth{-\bigparenth{\normalabs{\ExternalField(\svbz)} + 2\sonenorm{\ParameterRowttt} \sinfnorm{\svbx}} \xmax - \ParameterTU[tt] \xmax^2}}{
	\int_{\cX}
	\exp\Bigparenth{\bigparenth{\normalabs{\ExternalField(\svbz)} + 2\sonenorm{\ParameterRowttt} \sinfnorm{\svbx}} \xmax + \ParameterTU[tt] \xmax^2} d x_t}\\
& \sgreat{(d)} \frac{\exp\Bigparenth{-\normalparenth{\aGM + 2\eGM \xmax} \xmax}}{
	\int_{\cX}
	\exp\Bigparenth{\normalparenth{\aGM + 2\eGM \xmax} \xmax} d x_t} \sequal{(e)} \frac{1}{2\xmax \cthree[2]},
\end{align}
where $(a)$ follows from \cref{eq_conditional_dist}, $(b)$ and $(d)$ follow from \cref{def:tau_sgm}, $(c)$ follows by triangle inequality and Cauchy–Schwarz inequality, and $(e)$ follows because $\int_{\cX} dx_t = 2\xmax$. Therefore, $f_{\min} = \frac{1}{2\xmax \cthree[2]}$. Putting (i), (ii), and (iii) together, and using \cref{thm_LSI_main}, we see that $\rvbx | \rvbz$ satisfies $\mathrm{LSI}_{\rvbx}\Bigparenth{\frac{\cfive}{\normalparenth{1-\opnorm{\bParameterMatrix}}^2}}$ where $\cfive$ was defined in \cref{eq_constants_4_cont}. 

Now, we apply \cref{thm_main_concentration} to $q_1$ and $q_2$ one-by-one. The general strategy is to choose appropriate pseudo derivatives and pseudo Hessians for both $q_1$ and $q_2$, and evaluate the corresponding terms appearing in \cref{thm_main_concentration}.

\paragraph{Concentration for $q_1$}
%
%
Fix any $\svbx \in \cX^p$. We start by decomposing $q_1(\svbx)$ as follows
%
\begin{align}
q_1(\svbx) = \bom \tp r(\svbx), \label{eq_decomposition_cont_quad}
\end{align}
where $\bom \defn (\omt[1]^2, \cdots, \omt[p]^2)$ and $r(\svbx) \defn (r_1(\svbx), \cdots, r_p(\svbx))$ with $r_t(\svbx) = x_t^2$ for every $t \in [p]$. Next, we define $H : \cX^p \to \Reals^{p \times p}$ such that 
\begin{align}
H_{tu}(\svbx) = \frac{dr_u(\svbx)}{dx_t}  \qtext{for every $t,u \in [p]$.} \label{eq_H_matrix_cont_quad}
\end{align}

\paragraph{Pseudo derivative}
We bound the $\ell_2$ norm of the gradient of $q_1(\svbx)$ as follows
\begin{align}
\twonorm{\nabla q_1(\svbx)}^2 = \sump \Bigparenth{\frac{d q_1(\svbx)}{dx_t}}^2 & \sequal{\cref{eq_decomposition_cont_quad}} \sump \Bigparenth{\frac{\bom \tp d r(\svbx)}{dx_t}}^2 \\
& \sequal{\cref{eq_H_matrix_cont_quad}} \twonorm{H(\svbx) \bom}^2 \\
& \sless{(a)} \opnorm{H(\svbx)}^2 \twonorm{\bom}^2  \sless{(b)} \onematnorm{H(\svbx)}  \infmatnorm{H(\svbx)} \twonorm{\bom}^2, \label{eq:pseudo_derivative_cont_quad}
\end{align}
where $(a)$ follows because induced matrix norms are submultiplicative and $(b)$ follows because the matrix operator norm is bounded by square root of the product of matrix one norm and matrix infinity norm. Now, we claim that the one norm and the infinity norm of $H(\svbx)$ are bounded as follows
\begin{align}
\max\braces{\max_{\svbx \in \cX^p} \onematnorm{H(\svbx)}, \max_{\svbx \in \cX^p} \infmatnorm{H(\svbx)}} \leq 2\xmax. \label{eq_H_one_inf_bound_cont_quad}
\end{align}
Taking this claim as given at the moment, we continue with our proof. Combining \cref{eq:pseudo_derivative_cont_quad,eq_H_one_inf_bound_cont_quad}, we have 
%
%
%
\begin{align}
\max_{\svbx \in \cX^p} \twonorm{\nabla q_1(\svbx)}^2 \leq  4\xmax^2 \twonorm{\bom}^2 = 4\xmax^2 \!\sump\! \omt^4 \leq 4\xmax^2 \maxp[u] \omt[u]^2 \sump\! \omt^2 \!\sless{(a)}\! 16 \xmax^2 \aGM^2 \twonorm{\om}^2,
\end{align}
where $(a)$ follows because $\om \in 2\ParameterSet_{\ExternalField}$. Therefore, we choose the pseudo derivative (see \cref{def_pseudo_der_hes}) as follows
\begin{align}
\tnabla q_1(\svbx) = 4\xmax \aGM \twonorm{\om}. \label{eq_chosen_pseudo_der_cont_quad}
\end{align}

\paragraph{Pseudo Hessian}
Fix any $\rho \in \Reals$. We bound $\stwonorm{\nabla(\rho\tp \tnabla  q_1(\svbx))}^2$ (see \cref{def_pseudo_der_hes}) as follows
\begin{align}
\stwonorm{\nabla(\rho\tp \tnabla  q_1(\svbx))}^2 = \sump[u] \Bigparenth{\frac{d \rho\tp \tnabla  q_1(\svbx)}{dx_u}}^2 \sequal{\cref{eq_chosen_pseudo_der_cont_quad}} 0.
\end{align}
Therefore, we choose the pseudo Hessian (see \cref{def_pseudo_der_hes}) as follows
\begin{align}
\tnabla^2 q_1(\svbx) = 0. \label{eq_chosen_pseudo_Hess_cont_quad}
\end{align}
The concentration result in \cref{eq_coro_combined} for $q_1$ follows by applying \cref{thm_main_concentration} with the pseudo discrete derivative defined in \cref{eq_chosen_pseudo_der_cont_quad} and the pseudo discrete Hessian defined in \cref{eq_chosen_pseudo_Hess_cont_quad}.\\

%
%
%
%

\noindent It remains to show that the one-norm and the infinity-norm of $H(\svbx)$ are bounded as in \cref{eq_H_one_inf_bound_cont_quad}.
\paragraph{Bounds on the one-norm and the infinity-norm of $H(\svbx)$} We have 
\begin{align}\label{eq_matrix_H_quad}
H_{tu}(\svbx) = 
\begin{cases}
2x_t \qtext{if} t = u, \\
0 \qtext{otherwise.}
\end{cases}
\end{align}
Therefore,
\begin{align}
\onematnorm{H(\svbx)} 
& = \max_{u \in [p]} \sum_{t \in [p]} \normalabs{H_{tu}(\svbx)} \sless{\cref{eq_matrix_H_quad}} \max_{u \in [p]} 2 \normalabs{x_u} \sless{(a)} 2\xmax \qtext{and}\\
\infmatnorm{H(\svbx)} 
& = \max_{t \in [p]} \sum_{u \in [p]} |H_{tu}(\svbx)|  \sless{\cref{eq_matrix_H_quad}} \max_{t \in [p]} 2 \normalabs{x_t} \sless{(a)} 2\xmax,
\end{align}
where $(a)$ follows from \cref{def:tau_sgm}.

\paragraph{Concentration for $q_2$}
%
%
Fix any $\svbx \in \cX^p$. We start by decomposing $q_2(\svbx)$ as follows
%
\begin{align}
q_2(\svbx) = \om\tp r(\svbx), \label{eq_decomposition_cont}
\end{align}
where $r(\svbx) \defn (r_1(\svbx), \cdots, r_p(\svbx))$ with $r_t(\svbx) = x_t \exp\bigparenth{-\normalbrackets{\ExternalFieldt + 2 \ParameterRowttt\tp \svbx_{-t}} x_t - \ParameterTU[tt] \cx_t}$ for every $t \in [p]$. Next, we define $H : \cX^p \to \Reals^{p \times p}$ such that 
\begin{align}
H_{tu}(\svbx) = \frac{dr_u(\svbx)}{dx_t}  \qtext{for every $t,u \in [p]$.} \label{eq_H_matrix_cont}
\end{align}

\paragraph{Pseudo derivative}
We bound the $\ell_2$ norm of the gradient of $q_2(\svbx)$ as follows
\begin{align}
\twonorm{\nabla q_2(\svbx)}^2  = \sump \Bigparenth{\frac{d q_2(\svbx)}{dx_t}}^2 & \sequal{\cref{eq_decomposition_cont}} \sump \Bigparenth{\frac{\om\tp d r(\svbx)}{dx_t}}^2 \\ & \sequal{\cref{eq_H_matrix_cont}} \twonorm{H(\svbx) \om}^2 \\
& \sless{(a)} \opnorm{H(\svbx)}^2 \twonorm{\om}^2 \sless{(b)} \onematnorm{H(\svbx)}  \infmatnorm{H(\svbx)} \twonorm{\om}^2, \label{eq:pseudo_derivative_cont}
\end{align}
where $(a)$ follows because induced matrix norms are submultiplicative and $(b)$ follows because the matrix operator norm is bounded by square root of the product of matrix one norm and matrix infinity norm. Now, we claim that the one norm and the infinity norm of $H(\svbx)$ are bounded as follows
\begin{align}
\max\braces{\max_{\svbx \in \cX^p} \onematnorm{H(\svbx)}, \max_{\svbx \in \cX^p} \infmatnorm{H(\svbx)}} \leq \cthree \cfour. \label{eq_H_one_inf_bound_cont}
\end{align}
where $\cthree$ and $\cfour$ were defined in \cref{eq_constants_3_cont} and \cref{eq_constants_4_cont} respectively. Taking this claim as given at the moment, we continue with our proof. Combining \cref{eq:pseudo_derivative_cont,eq_H_one_inf_bound_cont}, we have 
\begin{align}
\max_{\svbx \in \cX^p} \twonorm{\nabla q_2(\svbx)}^2 \leq \cthree[2] \cfour[2] \twonorm{\om}^2.
\end{align}
Therefore, we choose the pseudo derivative (see \cref{def_pseudo_der_hes}) as follows
\begin{align}
\tnabla q_2(\svbx) = \cthree \cfour \twonorm{\om}. \label{eq_chosen_pseudo_der_cont}
\end{align}

\paragraph{Pseudo Hessian}
Fix any $\rho \in \Reals$. We bound $\stwonorm{\nabla(\rho\tp \tnabla  q_2(\svbx))}^2$ (see \cref{def_pseudo_der_hes}) as follows
\begin{align}
\stwonorm{\nabla(\rho\tp \tnabla  q_2(\svbx))}^2 = \sump[u] \Bigparenth{\frac{d \rho\tp \tnabla  q_2(\svbx)}{dx_u}}^2 \sequal{\cref{eq_chosen_pseudo_der_cont}} 0.
\end{align}
Therefore, we choose the pseudo Hessian (see \cref{def_pseudo_der_hes}) as follows
\begin{align}
\tnabla^2 q_2(\svbx) = 0. \label{eq_chosen_pseudo_Hess_cont}
\end{align}
%
The concentration result in \cref{eq_coro_combined} for $q_1$ follows by applying \cref{thm_main_concentration} with the pseudo discrete derivative defined in \cref{eq_chosen_pseudo_der_cont} and the pseudo discrete Hessian defined in \cref{eq_chosen_pseudo_Hess_cont}.\\

%
%
%
%

\noindent It remains to show that the one-norm and the infinity-norm of $H(\svbx)$ are bounded as in \cref{eq_H_one_inf_bound_cont}.
\paragraph{Bounds on the one-norm and the infinity-norm of $H$} We have 
\begin{align}\label{eq_matrix_H}
H_{tu}(\svbx) = 
\begin{cases}
\bigbrackets{1 - \normalbrackets{\ExternalFieldt[u] + 2\ParameterRowt[u]\tp \svbx} x_u}  \exp\bigparenth{-\normalbrackets{\ExternalFieldt[u] + 2\ParameterRowttt[u]\tp \svbx_{-u}} x_u - \ParameterTU[uu] \cx_u}  \qtext{if} t = u, \\
-2\ParameterTU[tu] x_u^2 \exp\bigparenth{-\normalbrackets{\ExternalFieldt[u] + 2\ParameterRowttt[u]\tp \svbx_{-u}} x_u - \ParameterTU[uu] \cx_u} \qquad\qquad\qquad \qtext{otherwise.}
\end{cases}
\end{align}
Therefore,
\begin{align}
\onematnorm{H(\svbx)} 
& = \max_{u \in [p]} \sum_{t \in [p]} \normalabs{H_{tu}(\svbx)} \\
& \sequal{\cref{eq_matrix_H}} \max_{u \in [p]} \bigabs{1 \!-\! \normalbrackets{\ExternalFieldt[u] \!+\! 2\ParameterRowt[u]\tp \svbx} x_u} \exp\bigparenth{-\normalbrackets{\ExternalFieldt[u] + 2\ParameterRowttt[u]\tp \svbx_{-u}} x_u - \ParameterTU[uu] \cx_u}  \\
& \qquad \qquad + 2\max_{u \in [p]} x_u^2  \exp\bigparenth{-\normalbrackets{\ExternalFieldt[u] + 2\ParameterRowttt[u]\tp \svbx_{-u}} x_u - \ParameterTU[uu] \cx_u}  \sum_{t \neq u}  \normalabs{\ParameterTU[tu]}\\
& \sless{(a)} (1 + \aGM \xmax + 4\xmax^2 \eGM) \exp{(\xmax(\aGM+ 2\eGM \xmax))} \sequal{(b)}  \cthree \cfour,
\end{align}
where $(a)$ follows from \cref{def:tau_sgm} along with triangle inequality and Cauchy–Schwarz inequality and $(b)$ follows from \cref{eq_constants_3_cont,eq_constants_4_cont}. Similarly, we have
\begin{align}
\infmatnorm{H(\svbx)} 
& = \max_{t \in [p]} \sum_{u \in [p]} |H_{tu}(\svbx)|  \\
& \sequal{\cref{eq_matrix_H}} \max_{t \in [p]} \bigabs{1 \!-\! \normalbrackets{\ExternalFieldt \!+\! 2\ParameterRowt\tp \svbx} x_t} \exp\bigparenth{-\normalbrackets{\ExternalFieldt[t] + 2\ParameterRowttt[t]\tp \svbx_{-t}} x_t - \ParameterTU[tt] \cx_t} \\
& \qquad \qquad + 2\max_{t \in [p]} \sum_{u \neq t}  \normalabs{\ParameterTU[tu]} x_u^2  \exp\bigparenth{-\normalbrackets{\ExternalFieldt[u] + 2\ParameterRowttt[u]\tp \svbx_{-u}} x_u - \ParameterTU[uu] \cx_u} \\
& \sless{(a)} (1 + \aGM \xmax + 4\xmax^2 \eGM) \exp{(\xmax(\aGM+ 2\eGM \xmax))} \sequal{(b)} \cthree \cfour,
\end{align}
where $(a)$ follows from \cref{def:tau_sgm} along with triangle inequality and Cauchy–Schwarz inequality and $(b)$ follows from \cref{eq_constants_3_cont,eq_constants_4_cont}.