\section{Main results}
\label{sec_main_results}
In this section, we provide our analysis and main results. First, 
we provide our guarantee on estimating the unit-level and the population-level parameters in \cref{eq_parameters_of_interest}. 
Next, we provide our guarantee on estimating the causal estimand of interest in \cref{eq_causal_estimand}. 
%
Our guarantees depend on the metric entropy of the set $\ParameterSet_{\ExternalField}$ which provides some notion of the richness of $\ParameterSet_{\ExternalField}$. To that end, we define the notions of $\varepsilon$-covering number and metric entropy.

\begin{definition}[$\varepsilon$-covering number and metric entropy]\label{def_covering_number_metric_entropy}
Given a set $\cV \subset \Reals^p$ and a scalar $\varepsilon > 0$, we use $\cC(\cV, \varepsilon)$ to denote the $\varepsilon$-covering number of $\cV$ with respect to $\stwonorm{\cdot}$, i.e., $\cC(\cV, \varepsilon)$ denotes the minimum cardinality over all possible covers $\cU \subset \cV$ that satisfy
\begin{align}
    \cV \subset \cup_{u \in \cU} \ball(u; \varepsilon),
\end{align}
where $\ball(u; \varepsilon) \defn \braces{v \in \Reals^p: \stwonorm{u-v} \leq \varepsilon}$ denotes a ball of radius $\varepsilon$ in $\Reals^p$ centered at $u$. Further, we use $\metric(\cV, \varepsilon)$ to denote the metric entropy of $\cV$, i.e., $\metric(\cV, \varepsilon) \defn \log \cC(\cV, \varepsilon)$. 
Lastly, we use the shorthand notation $\metric_{\ExternalField}(\varepsilon) = \metric(\ParameterSet_{\ExternalField},\varepsilon)$ to denote the metric entropy of $\ParameterSet_{\ExternalField}$.
\end{definition}

%
%
%
%
%

\newcommand{\edgeparammainresultname}{Recovering population-level parameter}
\newcommand{\parammainresultname}{Guarantee on parameter estimate}
\newcommand{\nodeparammainresultname}{Recovering unit-level parameters}
%
\noindent The following result provides the estimation error for the estimate $\ExtendedEstimatedParameterMatrix$ obtained in \cref{eq_estimated_parameters}. We divide the proof across \cref{sec:proof_of_theorem_parameters} and \cref{sec_proof_thm_node_parameters_recovery}
where \cref{sec:proof_of_theorem_parameters} analyzes the estimate $\EstimatedParameterMatrix$ of the population-level parameter $\TrueParameterMatrix$ and  \cref{sec_proof_thm_node_parameters_recovery} analyzes the estimates $\EstimatedExternalFieldI[1], \cdots, \EstimatedExternalFieldI[n]$ of the unit-level parameters $\TrueExternalFieldI[1], \cdots, \TrueExternalFieldI[n]$.\footnote{To simplify presentation, we use $c$ and $c'$ to denote universal constants or constants that depend on the model-parameters $\aGM$ and $\xmax$, and can take a different value in each appearance.}


\begin{theorem}[\tbf{\parammainresultname}]
\label{theorem_parameters}
Fix an $\varepsilon > 0$ and $\delta \in (0,1)$, and define
\begin{align}
R(\varepsilon, \delta) \!\defn\! \max \sbraces{ ce^{c'\bGM} \sqrt{\log\log(2p/\delta)) \!+\! \metric_{\ExternalField}( \radius) }, \varepsilon \ratio}, \ \,  \radius \!\defn\! \frac{ce^{-c'\bGM}}{\ratio},
\stext{and}
\ratio\!\defn\! \max_{\ExternalField, \bExternalField \in \ParameterSet_{\ExternalField}} \dfrac{\sonenorm{\ExternalField \!-\! \bExternalField}}{\stwonorm{\ExternalField \!-\! \bExternalField}}.
\label{eq_radius_node_thm}
\end{align}
Then, with probability at least $1-\delta$, the 
%
estimates $\EstimatedParameterMatrix,  \EstimatedExternalFieldI[1], \cdots, \EstimatedExternalFieldI[n]$ defined in \cref{eq_estimated_parameters}
%
%
satisfy
%
%
%
%
\begin{align}
    \max_{t\in[p]}\stwonorm{\EstimatedParameterRowt \!-\! \TrueParameterRowt} &\leq \varepsilon
    %
    \qquad \quad \ \, \qtext{whenever}
    %
    %
    n \geq \frac{ce^{c'\bGM}\log\frac{p}{\delta}}{\varepsilon^4} \qtext{and} \\
%
%
%
%
%
%
%
%
    %
    \max_{i\in[n]}\stwonorm{\EstimatedExternalFieldI \!-\! \TrueExternalFieldI} &\leq R(\varepsilon, \delta/n) \qtext{whenever} n \geq \frac{ce^{c'\bGM}  (\log \frac{np}{\delta} + \metric_{\ExternalField}(\radius)) }{\varepsilon^4}.
    %
    %
%
%
%
%
\end{align}
%
%
\end{theorem}
%
%
%
%
%
\noindent The following result provides the estimation error for the estimate $\what{\mu}^{(i)}(\wtil{\svba}^{(i)})$ (see \cref{eq_causal_estimate}) of the expected potential outcomes for any unit $i \in [n]$ under an alternate intervention $\wtil{\svba}^{(i)} \in \cA^{p_a}$. The result requires the operator norms of the following matrices to remain bounded for minor perturbation in the parameters: (i) the covariance matrix of $\rvby$ conditioned on $\rvba$, $\rvbz$, and $\rvbv$ and (ii) the cross-covariance matrix of $\rvby$ and $\rvy_t \rvby$ conditioned on $\rvba$, $\rvbz$, and $\rvbv$ for all $t \in [p_y]$.
%
We note that the expectation in the aforementioned covariance matrix and cross-covariance matrices 
%
is with respect to the conditional distribution of $\rvby$ conditioned on $\rvba = \svba$, $\rvbz = \svbz$, and $\rvbv = \svbv$ which is fully parameterized by $\ExternalField$ and $\ParameterMatrix$, i.e., replace $\ExternalField(\svbz)$ by $\ExternalField$ in \cref{eq_conditional_distribution_vay}, and we require the operator norms of these matrices to remain bounded for perturbations in $\ExternalField$ and $\ParameterMatrix$. 
%
Formally, for perturbations in $\ExternalField$ and $\ParameterMatrix$ such that $\ExternalField, \ParameterMatrix$ belong to the set $\mbb B$, we have
\begin{align}
  \sup\limits_{\ExternalField, \ParameterMatrix \in \mbb B} \max\Bigbraces{\opnorm{\Covariance_{\ExternalField,\ParameterMatrix}(\rvby, \rvby | {\svba}, \svbz, \svbv)}, \max\limits_{t \in [p_y]} \opnorm{\Covariance_{\ExternalField,\ParameterMatrix}(\rvby, \rvy_t \rvby | {\svba}, \svbz, \svbv)}} \leq M(\mbb B), \label{eq_cov_constraint}
\end{align}
where $M(\mbb B)$ is a constant that depends on the set $\mbb B$.
%
%
%
For simplicity, we assume $p_v = p_a = p_y$. See the proof in \cref{sec_proof_causal_estimand} for the general case. 
\newcommand{\outcomemainresultname}{Guarantee on outcome estimate}
\begin{theorem}[\tbf{\outcomemainresultname}]
\label{thm_causal_estimand}
Fix an $\varepsilon > 0$ and $\delta \in (0,1)$. 
%
Then, with probability at least $1-\delta$, the estimates $\sbraces{\what{\mu}^{(i)}(\wtil{\svba}^{(i)})}_{i=1}^n$ defined in \cref{eq_causal_estimate} for any $\sbraces{\wtil{\svba}^{(i)} \in \cA^{p_a}}_{i=1}^n$ satisfy
\begin{align}
    %
    \max_{i\in[n]} \frac{\stwonorm{\mu^{(i)}(\wtil{\svba}^{(i)}) - \what{\mu}^{(i)}(\wtil{\svba}^{(i)})}}{M(\mbb B_i)} 
    \!\leq\!  R(\varepsilon, \delta/n) \!+\! p \varepsilon \!\!\qtext{whenever} \!\!n\! \geq \!\frac{ce^{c'\bGM}  (\log \frac{np}{\delta} \!+\! \metric_{\ExternalField}( \radius)) }{\varepsilon^4},
\end{align}
where $R(\varepsilon, \delta)$ and $\radius$ were defined in \cref{eq_radius_node_thm}, $M(\mbb B)$ was defined in \cref{eq_cov_constraint}, and
\begin{align}
\mbb B_i \defeq \bigbraces{\ExternalField \in \Lambda_{\theta}: \stwonorm{\ExternalField \!-\! \TrueExternalFieldI} \leq R(\varepsilon, \delta/n)} \times \bigbraces{\ParameterMatrix \in \Lambda_{\Theta}: \max_{t\in[p]}\stwonorm{\ParameterRowt \!-\! \TrueParameterRowt} \leq \varepsilon}.
\end{align}
%
%
%
\end{theorem}

%
\noindent \textbf{Example.} Consider the case where $\TrueExternalFieldI$ is $s$-sparse linear combination of $k$ known vectors for all $i \in [n]$, i.e., $\TrueExternalFieldI = \tbf{B} \tbf{a}^{(i) }$ for a known matrix $\tbf{B} \in \Reals^{p \times k}$ and $\tbf{a}^{(i)} \in \Reals^{k \times 1}$ with $\szeronorm{\tbf{a}^{(i)}} \leq s$ such that $\sinfnorm{\TrueExternalFieldI}\leq \alpha$. Then, the parameter set $\ParameterSet_{\ExternalField}$ can be re-parameterized as the set 
%
$\ParameterSet_{\tbf{a}} = \braces{\tbf{a} \in \Reals^{k \times 1}: \szeronorm{\tbf{a}} \leq s \stext{and} \sinfnorm{\tbf{B} \tbf{a}} \leq \aGM}$ whose metric entropy is given by $\metric_{\tbf{a}}(\radius) = \log \Bigbrackets{\bigparenth{1+\frac{c}{\radius}}^s \binom{k}{s}}$ for some constant $c$ \cite[Corollary 4]{DaganDDA2021}. Using this bound, and substituting the worst case $\ratio = \sqrt{p}$, the guarantees in \cref{theorem_parameters} and \cref{thm_causal_estimand} simplify. We capture these guarantees in the following corollary by focusing on the mean squared error.
\begin{corollary}\label{cor_sparse_node_params}
Fix an $\varepsilon > 0$ and $\delta \in (0,1)$. Suppose $\TrueExternalFieldI$ is $s$-sparse linear combination of $k$ known vectors for all $i \in [n]$. Then, with probability at least $1-\delta$, the estimates $\normalbraces{\EstimatedExternalFieldI[i]}_{i = 1}^{n}$ defined in \cref{eq_estimated_parameters} satisfy
\begin{align}
    %
    %
    %
    \max_{i\in[n]}
    \mathrm{MSE}(\EstimatedExternalFieldI, \TrueExternalFieldI)
    %
    &\leq \dfrac{\max\{\varepsilon^2, ce^{c'\bGM} s\log pk\} }{p} \qtext{whenever} n \geq \frac{ce^{c'\bGM} sp^2 \log \frac{npk}{\delta}}{\varepsilon^4}.
\end{align}
Further, the estimates $\sbraces{\what{\mu}^{(i)}(\wtil{\svba}^{(i)})}_{i=1}^n$ defined in \cref{eq_causal_estimate} for any $\sbraces{\wtil{\svba}^{(i)} \in \cA^{p_a}}_{i=1}^n$ satisfy
\begin{align}
    \max_{i\in[n]}
    \mathrm{MSE}(\mu^{(i)}(\wtil{\svba}^{(i)}), \what{\mu}^{(i)}(\wtil{\svba}^{(i)}))
    \leq  \dfrac{\varepsilon^2 +  ce^{c'\bGM} s\log pk }{p} \qtext{whenever} n \geq \frac{ce^{c'\bGM} sp^2 \log \frac{npk}{\delta}}{\varepsilon^4}.
\end{align}
\end{corollary}
\noindent As a result, we see that the unit-wise mean squared error for parameter estimation and outcome estimation scale as $O(s\log k)/p$ when (i) the true parameters are $s$-sparse linear combination of $k$ known vectors and (ii) $n$ scales as $O(s p^2\log spk)$.
%
%
%
%
%
%
%
%
%
%
%
%
    %
    %
    %
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%

%
\newcommand{\gm}{\texttt{GM}}
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%

%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%


%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
\pagebreak
