%\section*{Additional Experiments} \label{app}
\begin{table}[t]
\centering
\caption{Impacts of stay point duration (mins) for \texttt{DeepSEI}.}
\vspace{-3mm}
\setlength{\tabcolsep}{6pt}
\begin{tabular}{lccccc}
\hline
Parameter & 30 & 60 & 90 & 120 & 150 \\ \hline
%\# Training instances &   1,485  &   1,396  &   1,360  &   1,336  &  1,315   \\
%\# Testing instances &   637  &   599  &  584   &   573  &  564   \\
Classification   &74.3     &  78.9   &  \textbf{86.1}  &  82.6   &  81.9   \\
Clustering   & 80.9    &  81.9   &  \textbf{83.2}  &   81.9  &  81.8  \\ \hline
\label{tab:duration}
\end{tabular}
\vspace*{-4mm}
\end{table}

\begin{table}[t]
\centering
\caption{Impacts of cell size (m) for \texttt{DeepSEI}.}
\vspace{-3mm}
\setlength{\tabcolsep}{6.5pt}
\begin{tabular}{lccccc}
\hline
Parameter & 100 & 200 & 300 & 400 & 500 \\ \hline
%\# Location tokens & 4,460    &  3,080   &  2,378   &  1,995   &  1,707   \\
Classification   &82.3     &  \textbf{86.1}   &  83.6  &  81.5   &   79.8  \\ 
Clustering   &82.0     &  \textbf{83.2}   &  81.2  &  80.5   & 79.4    \\ \hline
\end{tabular}
\label{tab:cellsize}
\vspace*{-4mm}
\end{table}

\begin{table}[t]
\centering
\caption{Impacts of spatiality granularity for \texttt{DeepSEI}.}
\vspace{-3mm}
\setlength{\tabcolsep}{7.9pt}
\begin{tabular}{lccccc}
\hline
Parameter & 100 & 200 & 300 & 400 & 500 \\ \hline
%\# Spatiality tokens & 81 & 40 & 27 & 20 & 16   \\
Classification & 84.1 & 85.9 & \textbf{86.1} & 85.6 & 83.8 \\ 
Clustering & 82.1 & 81.9 & \textbf{83.2} & 82.7 & 82.0  \\ \hline
\end{tabular}
\label{tab:spatiality}
\vspace*{-4mm}
\end{table}

\noindent \textbf{(3) Parameter study (varying stay point duration $S_t$).}
The stay point duration parameter $S_t$ controls the time threshold of the stay point detection algorithm, where the points in a trajectory will be merged as one stay point if the duration of the first point (called anchor point) and the last point in the trajectory is within $S_t$. We vary the $S_t$ from 30 minutes to 150 minutes, and the results are reported in Table~\ref{tab:ablation}. As expected, with the increase of $S_t$, less stay points are detected, which corresponds to less training and testing instances are generated.
%
We observe that our model performs the best when $S_t$ is set to 90 minutes with the $F_1$-score of 86.1\% and ARI of 83.2\%. This is because with a small $S_t$, the detected stay points cannot accurately reflect the users' activities, it falsely takes some trivial behaviors such as ``walking'' as the users' activities, which prevents the model to learn useful information. With a large $S_t$, many stay points cannot be detected, which causes the model performance degrades as many features that are associated with the stay points are missing.

\begin{table}[t]
\centering
\caption{Impacts of temporality and activity granularity for \texttt{DeepSEI}.}
\vspace{-3mm}
\setlength{\tabcolsep}{7.5pt}
\begin{tabular}{lccccc}
\hline
Parameter & 0.1 & 0.3 & 0.5 & 0.7 & 0.9 \\ \hline
%\# Temporality tokens &  57   & 28    & 11    &  8   &  6   \\
%\# Activity tokens &  53   &  27   &  10   &  7   &   5  \\
Classification   &72.3     &  78.6   &  \textbf{86.1}  &  83.8   &  81.6   \\ 
Clustering   &80.4     & 81.5    & \textbf{83.2}   &  81.8   & 80.8    \\\hline
\label{tab:embtokens}
\end{tabular}
\vspace*{-6mm}
\end{table}

\noindent \textbf{(4) Parameter study (varying cell size).}
In Table~\ref{tab:cellsize}, we study the effect of cell size by varying the size from 100 meters to 500 meters. Here, the effect of cell size is mainly in two aspects: 1) for spatiality, each grids contains a set of stay points; with a large size, more stay points will be indexed to the same grid, which results many stay points share the same mobility embedding; 2) for activity, we infer the activity of a stay point using the POIs in 8 neighbouring grids of the grid, where the stay point is located; then, a large cell size, corresponds to a large grid, which takes more POIs into consideration. Based on the results, we observe that the cell size 200 meters fits our model best. With the smallest cell size (100 meters), the model degrades. This is because a small cell size generates more tokens, which makes the model difficult to train. On the other hand, a large cell size causes a lower resolution of the stay points, and overlooks the differences of mobility features. In addition, as more POIs are considered in a large grid, those POIs may generate noise to interfere with POI inference and this is in line with our intuition.

\noindent \textbf{(5) Parameter study (varying spatiality diversity granularity).} 
We study the effect of spatiality granularity in Table~\ref{tab:spatiality}. We vary the granularity from 100 to 500, and report the effectiveness in terms of classification and clustering. The parameter captures the resolution of the spatial range of users' daily activities. A smaller value provides a higher resolution but incurs more tokens, which affects the model training. With a larger value, the capability of model to distinguish different spatial diversities will degrade. We set it to 300, which leads to the best effectiveness.

\noindent \textbf{(6) Parameter study (varying temporality and activity diversity granularity).}
We study the effect of diversity granularity for two entropy-based indicators, i.e., temporality diversity and activity diversity. We vary the granularity parameter from 0.1 to 0.9, and the results are reported in Table~\ref{tab:embtokens}. Temporality diversity and activity diversity are two features with continuous numerical values, dividing their ranges with a small granularity will generate too many tokens, and causes the model difficult to learn the features; with a large granularity, the capability of the model to identify the diversity from users' mobility patterns will degrade, which is as expected. overall, a moderate setting with the value of 0.5 provides the best effectiveness.
