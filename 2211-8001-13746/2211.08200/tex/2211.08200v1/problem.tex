\section{Problem Description}
\label{sec:preliminary}


In this paper, we aim to infer users' socioeconomic statuses from their mobility records.
%
% This is motivated by two considerations. 
% First, users' socioeconomic statuses are closely linked to where they live or work, both of which could be potentially reflected by their mobility records. Second, users' socioeconomic statuses can sometimes be disclosed by the places they visit, especially those they visit during weekends, and the patterns of they visit these places, which again could be revealed by their mobility records. 
%
Here, a user's socioeconomic status can refer to many different indicators, such as the price range of the user's living house~\cite{xu2018human,ding2019estimating}, the likelihood that the user will pay a car loan installment on time, or the user's income, etc. Constrained by the availability of datasets and privacy concerns, in this paper, we infer the home location of a user based on his/her mobility records (i.e., Geolife) and then crawl the house price data from the Web based on the home location as the indicator of the user's socioeconomic status. 
%
{\newadd{Many studies~\cite{xu2018human,ding2019estimating,mohamed2016clustering} show that the house price data reflects users' socioeconomic statuses well. For example, in~\cite{xu2018human}, it reveals that a user's house price is strongly correlated with a user's monthly income.}}
%
More specifically, we model the socioeconomic status inference task as a multi-class classification task, where each class corresponds to a range of house prices. In experiments, we vary the number of classes from 2 to 5.
%
Since both the mobility records data and the house price data are publicly available, no privacy will be broken.% in this study.

\if 0
One of the major goals of this paper is to infer users' socioeconomic statuses with their mobility records.
%
The hypothesis is that users’ mobility records reflect users’ socioeconomic statuses, which has been observed in the literature.
%
Specifically, this paper will explore the solution with deep neural networks, {\newadd{which take the features extracted in terms of three aspects as inputs, namely spatiality, temporality and activity, and output the users' socioeconomic classes as a classification problem (e.g., a binary classification indicating two socioeconomic classes of users).
}}
%

We use the house price data collected from Lianjia~\cite{lianjia} to define users' socioeconomic class labels (the details will be presented in Section~\ref{sec:setup}). 
{\newadd{Many studies~\cite{xu2018human,ding2019estimating,mohamed2016clustering} show that the house price data is the evidence to represent users' socioeconomic statuses, e.g., in~\cite{xu2018human}, it reveals that the house price is strongly correlated to a user's monthly income with 0.88.}}

%
With the labels, we train our model in a supervised manner, and use the trained model for predicting other data, whose socioeconomic class label is unknown. In addition, we collect the learned embeddings from the model. We expect that the embeddings have incorporated socioeconomic context well, and we use them to explore more socioeconomically related tasks, such as clustering.
\fi

\if 0
\subsection{Learning Representations with Skip-Gram}
\label{sec:skip}
Our proposed method involves deep representation learning techniques. Here, we borrow the idea from Skip-Gram model~\cite{mikolov2013efficient} for learning the representations of extracted features, and we provide a preliminary of Skip-Gram model.

Skip-Gram model is proposed to learn word embeddings in natural language processing. 
Let $<x_1, x_2, ..., x_n>$ be a sequence, where $x_i$ ($1 \leq i \leq n$) denotes a token (e.g., a word in a sentence or a sampled point in a trajectory) and $n$ denotes the length of the sequence. Skip-Gram model provides pre-trained embeddings (i.e., vectors) of those tokens.
%
An essential idea of Skip-Gram is on how to capture the context of a token that is modeled, where the tokens occurring in the same context tend to have similar embeddings.
%
Based on this, Skip-Gram uses an $m$-size window, and the context of a token $x_i$ can be defined as the tokens of forward-looking and backward-looking $m$ points of the token $x_i$.
%
Formally, given a token $x_i$ and a $m$-size window, the context of $x_i$ is $<d_{i-m},...,d_{i-1},d_{i+1},...,d_{i+m}>$, where the $d_i$ is called a target token and a token $d_{i+w}$ $(-m \le w \le m)$ in its $m$-size window context is called a context token. The aim of Skip-Gram model is to learn embeddings of the tokens such that it could infer the context tokens given a target token with the maximum probability, that is

\begin{equation}
    \mathcal{L} = -\frac{1}{n} \sum\limits_{i=1}^{n} \sum\limits_{-m \le w \le m} \log P(x_{i+w}| x_{i}),
\end{equation}
where $\mathcal{L}$ denotes the aggregating loss on the input sequence. 
%, we can construct contexts for each spatial-temporal point and to learn its representation more efficiently with the negative sampling algorithm~\cite{mikolov2013distributed}. The learned spatial-temporal point representations are used to initialize the embedding layer of Trajectory Representation Network, and they can be further optimized with the model training.

\section{Datasets}
\label{sec:dataset}
% We study the problem on real-world dataset. 
The dataset used in this work contains three parts, the first part is the mobility data (i.e., GPS trajectories) generated by users.
%
The second part is POI contexts, which are used to capture users' activity features.
%
The third part is house price considered as the socioeconomic information, which is used to construct labels to reflect the socioeconomic status of users for evaluation. We collect the last two parts of data through web map services and web crawlers.

\begin{table}[]
\setlength{\tabcolsep}{4pt}
\centering
\caption{Dataset statistics.}
\vspace*{-2mm}
\begin{tabular}{c|c}
\hline
\textbf{Statistics}                & \textbf{Geolife} \\ \hline
 \# of trajectories                 & 17,621 \\
Total \# of points                 & 24,876,978 \\
Ave. \# of points per trajectory & 1,412 \\
Sampling rate                      & 1s $\sim$ 5s \\
Average distance                   & 9.96m \\ \hline
\end{tabular}
\label{tab:dataset}
\vspace*{-2mm}
\end{table}

\subsection{Mobility Data}
The mobility records correspond to a sequence of time-stamped locations sampled by the GPS device. For each record, it captures the location (i.e., latitude and longitude) of a user at a timestamp. We use the Geolife dataset~\cite{zheng2010geolife} for the mobility data. It collects the trajectories of 182 users in a period of five years, where the trajectory data is distributed in over 30 cities of China, and the majority part was generated in Beijing. The detailed statistic of the dataset is summarized in Table~\ref{tab:dataset}. {\newadd{We note that the dataset is publicly available without any personal information, avoiding possible privacy concerns.
}}

\if 0
We conduct the experiments on two real-world trajectory datasets, i.e., Geolife and T-Drive. Geolife collects the trajectories of 182 users in a period of five years (2007 - 2012), where the trajectory data is distributed in over 30 cities of China, and the majority part was created in Beijing. T-Drive collects the trajectories of 10,357 taxis during a period of one week within Beijing. The two datasets are widely used in the previous trajectory simplification works~\cite{zhang2018trajectory,wang2021trajectory,long2014trajectory}, and the detailed statistics are shown in Table~\ref{tab:dataset}.
\subsection{Ground Truth Labels}
The loan data records the basic information such as car price, deposit (an initial partial payment for the purchase of the car), loan term. In addition, for each mobility record, it is associated with a binary tag (i.e., 0 or 1) indicating the user's loan status, i.e., whether the user is currently overdue for the loan payment. We take the tags as the ground truth labels for the prediction task, where there are 78 (resp. 295) users are identified as the overdue in the total of 749 (resp. 2,989) loan users in Shenzhen (resp. Chengdu), with the overdue proportion of $78/749=10.4\%$ and $295/2989=9.9\%$ for Shenzhen and Chengdu, respectively.
\fi

%\subsection{Other Collected Data} 
%We also collect other data for capturing the contexts of users’ activities (e.g., %Point-Of-Interest (POI)) and economic context data (e.g., house prices). 

\subsection{POI Data} 
We collect Point-of-Interest (POI) data through Amap Map API~\cite{api}, which contains 156,653 records in Beijing. For each POI record, it provides the following attributes, including venue name, category, location with latitude and longitude information. We consider 11 major POI categories in this work, namely working, residence, food and drink, attractions, community, shopping, education,  hospitals, lodging, traffic, and recreation. We collect the POI data between 2011 and 2012, corresponding to the period of the mobility records on Geolife.
%In addition, we include a special category called {\newCommentZheng{``other''}} for the other POI categories that are not included.

\begin{figure}
\centering
\begin{tabular}{c}
   \begin{minipage}{0.95\linewidth}
    \includegraphics[width=\linewidth]{figures/vor_fig1_bj.pdf}
    \end{minipage}
\end{tabular}
\vspace*{-2mm}
\caption{House price of Beijing, where the Voronoi polygons are generated based on the spatial distribution of the collected residential locations from Lianjia.}
\label{fig:region}
\vspace*{-3mm}
\end{figure}

\subsection{House Price Data} 
\label{sec:house}
For house price, we collect the data by crawling online housing agents, i.e., Lianjia~\cite{lianjia}, which is the largest Chinese real-estate brokerage company that provides a comprehensive coverage of housing properties. We crawl 8,124 residential sale prices in Beijing. For each transaction, it records the residential name, sale price, floor size and residential address with latitude and longitude information we collected from Amap Map~\cite{api}. Here, the house prices correspond to the average prices with the unit of rmb/$m^2$. We illustrate the collected house price in Figure~\ref{fig:region}.

By following~\cite{xu2018human,ding2019estimating}, we use the house price data to denote users' socioeconomic status. In particular, the range of collected average house price is from 10,588 to 113,224 in Beijing. {\nnCommentZheng{To study multiple-class classification, we take the binary classification for example. We define a binary label with the median threshold of the range (i.e., $\frac{10,588+113,224}{2}=61,891$), we set label 0 for the users, whose house prices are smaller than the threshold; label 1 otherwise. }}
Here, we find users' home locations by following the previous studies~\cite{csaji2013exploring,phithakkitnukoon2012socio,xu2018human}, the home of a user is inferred as the location visited the most frequently during nighttime from 22:00 to 07:00.
\fi