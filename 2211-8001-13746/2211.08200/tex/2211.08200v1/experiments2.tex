\subsection{Experimental Results}
\label{sec:result}

\if 0
\begin{table*}[]
\centering
\caption{Effectiveness evaluation and running time.}
%\setlength{\tabcolsep}{5pt}
\begin{tabular}{|l|ccccccccc|ccccccccc|}
\hline
\multicolumn{1}{|c|}{Method}                  & \multicolumn{9}{c|}{Classification}                                                                                                                                                                                                                                                       & \multicolumn{9}{c|}{Clustering}                                                                                                                                                                                                                                                                                                                                                                                                               \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{Metric}} & \multicolumn{2}{c|}{2}                             & \multicolumn{2}{c|}{3}                             & \multicolumn{2}{c|}{4}                             & \multicolumn{2}{c|}{5}                             & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Time \\ (ms)\end{tabular}} & \multicolumn{2}{c|}{2}                                                                  & \multicolumn{2}{c|}{3}                                                                  & \multicolumn{2}{c|}{4}                                                                  & \multicolumn{2}{c|}{5}                                                                  & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Time \\ (ms)\end{tabular}} \\ \cline{2-9} \cline{11-18}
\multicolumn{1}{|c|}{}                        & \multicolumn{1}{c|}{F1} & \multicolumn{1}{c|}{Acc} & \multicolumn{1}{c|}{F1} & \multicolumn{1}{c|}{Acc} & \multicolumn{1}{c|}{F1} & \multicolumn{1}{c|}{Acc} & \multicolumn{1}{c|}{F1} & \multicolumn{1}{c|}{Acc} &                                                                       & \multicolumn{1}{c|}{ARI}                   & \multicolumn{1}{c|}{AMI}                   & \multicolumn{1}{c|}{ARI}                   & \multicolumn{1}{c|}{AMI}                   & \multicolumn{1}{c|}{ARI}                   & \multicolumn{1}{c|}{AMI}                   & \multicolumn{1}{c|}{ARI}                   & \multicolumn{1}{c|}{AMI}                   &                                                                       \\ \hline
SES (RF)                                      & \multicolumn{1}{c|}{59.3}   & \multicolumn{1}{c|}{68.9}    & \multicolumn{1}{c|}{42.4}   & \multicolumn{1}{c|}{44.6}    & \multicolumn{1}{c|}{32.1}   & \multicolumn{1}{c|}{37.2}    & \multicolumn{1}{c|}{25.6}   & \multicolumn{1}{c|}{30.3}    &                                                        213.51               & \multicolumn{1}{c|}{\multirow{2}{*}{-0.7}} & \multicolumn{1}{c|}{\multirow{2}{*}{0.3}} & \multicolumn{1}{c|}{\multirow{2}{*}{-0.1}} & \multicolumn{1}{c|}{\multirow{2}{*}{0.4}} & \multicolumn{1}{c|}{\multirow{2}{*}{-1.2}} & \multicolumn{1}{c|}{\multirow{2}{*}{1.4}} & \multicolumn{1}{c|}{\multirow{2}{*}{-0.2}} & \multicolumn{1}{c|}{\multirow{2}{*}{0.6}} & \multirow{2}{*}{43.9}                                                     \\ \cline{1-10}
SES (XGBoost)                                 & \multicolumn{1}{c|}{60.0}   & \multicolumn{1}{c|}{60.3}    & \multicolumn{1}{c|}{41.0}   & \multicolumn{1}{c|}{43.3}    & \multicolumn{1}{c|}{32.6}   & \multicolumn{1}{c|}{36.4}    & \multicolumn{1}{c|}{23.9}   & \multicolumn{1}{c|}{27.8}    &                      268.3                                                 & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      &                                                                       \\ \hline
DIF (RF)                                      & \multicolumn{1}{c|}{69.1}   & \multicolumn{1}{c|}{69.3}    & \multicolumn{1}{c|}{57.1}   & \multicolumn{1}{c|}{59.6}    & \multicolumn{1}{c|}{50.3}   & \multicolumn{1}{c|}{53.0}    & \multicolumn{1}{c|}{47.1}   & \multicolumn{1}{c|}{48.5}    &                                             250.7                          & \multicolumn{1}{c|}{\multirow{2}{*}{20.5}} & \multicolumn{1}{c|}{\multirow{2}{*}{13.7}} & \multicolumn{1}{c|}{\multirow{2}{*}{15.6}}     & \multicolumn{1}{c|}{\multirow{2}{*}{11.8}}     & \multicolumn{1}{c|}{\multirow{2}{*}{7.9}}     & \multicolumn{1}{c|}{\multirow{2}{*}{5.2}}     & \multicolumn{1}{c|}{\multirow{2}{*}{1.3}}     & \multicolumn{1}{c|}{\multirow{2}{*}{0.8}}     & \multirow{2}{*}{50.7}                                                     \\ \cline{1-10}
DIF (XGBoost)                                 & \multicolumn{1}{c|}{70.3}   & \multicolumn{1}{c|}{75.5}    &  \multicolumn{1}{c|}{61.6}    & \multicolumn{1}{c|}{63.5}   & \multicolumn{1}{c|}{52.6}    & \multicolumn{1}{c|}{55.7}   & \multicolumn{1}{c|}{42.6}    & 
\multicolumn{1}{c|}{49.3}   &   290.8
& \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      &                                                                       \\ \hline
L2P (RF)                                      & \multicolumn{1}{c|}{67.8}   & \multicolumn{1}{c|}{72.2}    & \multicolumn{1}{c|}{55.2}   & \multicolumn{1}{c|}{56.4}    & \multicolumn{1}{c|}{46.1}   & \multicolumn{1}{c|}{48.2}    & \multicolumn{1}{c|}{41.5}   & \multicolumn{1}{c|}{44.3}    &                                           4,130.0                            & \multicolumn{1}{c|}{\multirow{2}{*}{13.2}} & \multicolumn{1}{c|}{\multirow{2}{*}{10.9}} & \multicolumn{1}{c|}{\multirow{2}{*}{7.5}}     & \multicolumn{1}{c|}{\multirow{2}{*}{6.8}}     & \multicolumn{1}{c|}{\multirow{2}{*}{2.3}}     & \multicolumn{1}{c|}{\multirow{2}{*}{1.5}}     & \multicolumn{1}{c|}{\multirow{2}{*}{-0.7}}     & \multicolumn{1}{c|}{\multirow{2}{*}{-0.1}}     & \multirow{2}{*}{76.3}                                                     \\ \cline{1-10}
L2P (XGBoost)                                 & \multicolumn{1}{l|}{68.2}   & \multicolumn{1}{l|}{67.8}    & \multicolumn{1}{l|}{58.4}   & \multicolumn{1}{l|}{59.3}    & \multicolumn{1}{l|}{47.7}   & \multicolumn{1}{l|}{49.0}    & \multicolumn{1}{l|}{40.2}   & \multicolumn{1}{l|}{42.2}    & \multicolumn{1}{l|}{4,616.7}                                                 & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      &                                                                       \\ \hline
DeepSEI                                       & \multicolumn{1}{c|}{\textbf{84.1}}   & \multicolumn{1}{c|}{\textbf{90.4}}    & \multicolumn{1}{c|}{\textbf{80.2}}   & \multicolumn{1}{c|}{\textbf{80.4}}    & \multicolumn{1}{c|}{\textbf{63.9}}   & \multicolumn{1}{c|}{\textbf{64.2}}    & \multicolumn{1}{c|}{\textbf{53.3}}   & \multicolumn{1}{c|}{\textbf{58.8}}    &                                 343,846.7                                  & \multicolumn{1}{c|}{64.1}                      & \multicolumn{1}{c|}{55.0}                      & \multicolumn{1}{c|}{61.7}                      & \multicolumn{1}{c|}{43.8}                      & \multicolumn{1}{c|}{41.2}                      & \multicolumn{1}{c|}{40.5}                      & \multicolumn{1}{c|}{38.4}                      & \multicolumn{1}{c|}{28.7}                      &                       48.7                                                \\ \hline
\end{tabular}
\label{tab:deepmodels}
\end{table*}
\fi

\if 0
\begin{table}[h]
\centering
\caption{Impacts of stay point duration (mins) for \texttt{DeepSEI}.}
\begin{tabular}{lccccc}
\hline
Parameter & 30 & 60 & 90 & 120 & 150 \\ \hline
\# Training instances &   1,485  &   1,396  &   1,360  &   1,336  &  1,315   \\
\# Testing instances &   637  &   599  &  584   &   573  &  564   \\
Classification   &74.3     &  78.9   &  \textbf{86.1}  &  82.6   &  81.9   \\
Clustering   & 80.9    &  81.9   &  \textbf{83.2}  &   81.9  &  81.8  \\ \hline
\label{tab:duration}
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Impacts of cell size (m) for \texttt{DeepSEI}.}
\begin{tabular}{lccccc}
\hline
Parameter & 100 & 200 & 300 & 400 & 500 \\ \hline
\# Location tokens & 4,460    &  3,080   &  2,378   &  1,995   &  1,707   \\
Classification   &82.3     &  \textbf{86.1}   &  83.6  &  81.5   &   79.8  \\ 
Clustering   &82.0     &  \textbf{83.2}   &  81.2  &  80.5   & 79.4    \\ \hline
\end{tabular}
\label{tab:cellsize}
\end{table}

\begin{table}[h]
\centering
\caption{Impacts of spatiality granularity for \texttt{DeepSEI}.}
\begin{tabular}{lccccc}
\hline
Parameter & 100 & 200 & 300 & 400 & 500 \\ \hline
\# Spatiality tokens & 81 & 40 & 27 & 20 & 16   \\
Classification & 84.1 & 85.9 & \textbf{86.1} & 85.6 & 83.8 \\ 
Clustering & 82.1 & 81.9 & \textbf{83.2} & 82.7 & 82.0  \\ \hline
\end{tabular}
\label{tab:spatiality}
\end{table}

\begin{table}[h]
\centering
\caption{Impacts of temporality and activity granularity for \texttt{DeepSEI}.}
\begin{tabular}{lccccc}
\hline
Parameter & 0.1 & 0.3 & 0.5 & 0.7 & 0.9 \\ \hline
\# Temporality tokens &  57   & 28    & 11    &  8   &  6   \\
\# Activity tokens &  53   &  27   &  10   &  7   &   5  \\
Classification   &72.3     &  78.6   &  \textbf{86.1}  &  83.8   &  81.6   \\ 
Clustering   &80.4     & 81.5    & \textbf{83.2}   &  81.8   & 80.8    \\\hline
\label{tab:embtokens}
\end{tabular}
\end{table}
\fi

\if 0
\begin{table}[h]
\centering
\caption{Impacts of socioeconomic granularity for \texttt{DeepLPP}.}
\begin{tabular}{lccccc}
\hline
Parameter & 50 & 100 & 150 & 200 & 250 \\ \hline
\# Region socioeconomic tokens &  3,865   &  1,932   &  1,288   &  966   &   733  \\
\# PMT tokens &  335   &  168   &   112  &   84  &   67  \\
PR-AUC  & 0.951  &  \textbf{0.972}   &  0.943   &  0.943   & 0.937         \\ \hline
\label{tab:economypar}
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\begin{tabular}{c c}
   \begin{minipage}{0.45\linewidth}
    \includegraphics[width=\linewidth]{figures/pretrain_f.pdf}
    \end{minipage}
    &
    \begin{minipage}{0.45\linewidth}
    \includegraphics[width=\linewidth]{figures/pretrain_time.pdf}
    \end{minipage}
    \\
    (a) Pre-training (Accuracy)
    &
    (b) Pre-training (Time cost)
    \\
      \begin{minipage}{0.45\linewidth}
    \includegraphics[width=\linewidth]{figures/train_f.pdf}
    \end{minipage}
    &
    \begin{minipage}{0.45\linewidth}
    \includegraphics[width=\linewidth]{figures/train_time.pdf}
    \end{minipage}
    \\
    (c) Training (Accuracy)
    &
    (d) Training (Time cost)
\end{tabular}
\vspace*{-2mm}
\caption{Training cost on Geolife.}
\label{fig:train}
\vspace*{-2mm}
\end{figure}
\fi
\noindent \textbf{(1) Effectiveness evaluation (comparison with different classifiers).}
We compare the \texttt{DeepSEI} model with the baselines. In Table~\ref{tab:deepmodels}, we report their effectiveness in terms of $F_1$-score(\%) and accuracy(\%) for classification and ARI(\%) and AMI(\%) for clustering. Overall, our \texttt{DeepSEI} model consistently outperforms the baselines, e.g., in binary classification and clustering, it outperforms the best baseline (i.e., DIF) by 22.5\% and 37.9\%, respectively. 
%
The reasons are mainly two-fold: 1) the \texttt{DeepSEI} model is with more comprehensive features to infer the users' socioeconomic statuses from three aspects, i.e., spatiality, temporality and activity; 2) the two networks that are incorporated by DeepSEI can capture the features effectively as they capture the features at both the coarse and detailed levels.
% we study a deep learning based solution to incorporate those features with two well-designed networks, i.e., deep network and recurrent network. The two networks are capable to capture the context and mobility records generated with GPS instead of the mobile phone data that are used as the existing studies. 
%
% In addition, we observe the effectiveness of XGBoost and Gradient Boosting is close to 0.6. For the other models, their PR-AUCs are below 0.4 in general, which indicates that the simple traditional machine learning models may not applicable to the real loan payment prediction task, where the real-world mobility data is variety, complexity and sequential correlation of the sampled locations, which cannot be well handled with the classifiers.

% \noindent \textbf{(2) Efficiency evaluation (prediction time).}
% We further report the average prediction time of each trajectory in Table~\ref{tab:deepmodels}.
% %
% We observe the \texttt{DeepLPP} is slower than the traditional machine learning models mainly in two aspects: 1) the \texttt{DeepLPP} incorporates more features in terms of mobility, temporality, activity and economy; 2) the \texttt{DeepLPP} contains two networks for the task, where more operations are required. Overall, the traditional models have similar running times in general, and the \texttt{DeepLPP} runs reasonably fast with the best effectiveness.
% %
% In addition, the prediction on Chengdu needs more time since its trajectory contains more stay points.

\noindent \textbf{(2) Ablation study.}
We conduct an ablation study to evaluate the effect of each network (i.e., deep network or recurrent network) and features in the \texttt{DeepSEI} model, and the comparing results are reported in Table~\ref{tab:ablation}. Overall, we can see all these networks and features contribute to the final result.
%
For the recurrent Network, w/o Recurrent Network corresponding to the case that only Deep Network is kept, the result performs the worst with $F_1$-score of 33.4\% and ARI of 60.4\%. This is because it captures a sequence of users' daily activities, which is essential to infer users' socioeconomic statuses.
%
For the deep network, we observe the spatiality diversity is with the most effect, e.g., when the spatiality is removed, the $F_1$-score is 78.8, which drops by 9.3\%. This is because users' socioeconomic statuses are highly linked to the range of their activity territory, which has been verified in previous studies~\cite{xu2018human}.

\input{appendix}

\begin{figure}[t]
\centering
%\vspace*{-3mm}
\begin{tabular}{c c}
   \begin{minipage}{0.47\linewidth}
    \includegraphics[width=\linewidth]{figures/pretrain_f.pdf}
    \end{minipage}
    &
    \begin{minipage}{0.47\linewidth}
    \includegraphics[width=\linewidth]{figures/pretrain_time.pdf}
    \end{minipage}
    \\
    (a) Pre-training ($F_1$-score)
    &
    (b) Pre-training (Time cost)
    \\
      \begin{minipage}{0.47\linewidth}
    \includegraphics[width=\linewidth]{figures/train_f.pdf}
    \end{minipage}
    &
    \begin{minipage}{0.47\linewidth}
    \includegraphics[width=\linewidth]{figures/train_time.pdf}
    \end{minipage}
    \\
    (c) Training ($F_1$-score)
    &
    (d) Training (Time cost)
\end{tabular}
\vspace*{-2mm}
\caption{Training cost on Geolife.}
\label{fig:train}
\vspace*{-3mm}
\end{figure}
\noindent \textbf{(7) Training time.} In Figure~\ref{fig:train}, we report the times and the corresponding effectiveness with the default setup in Section~\ref{sec:setup}. We generate 50 epochs for both pre-training and training.
% , respectively. 
We observe that the effectiveness improves with the number of epochs and the corresponding training time increases almost linearly. In pre-training, the recurrent network takes more time because it has a more complex network architecture (i.e., hierarchical LSTM). In training, the \texttt{DeepSEI} model incorporates the two networks and obtains a further improvement after 32 epochs. We observe that the \texttt{DeepSEI} model converges after 41 epochs, and we use the trained model for other experiments.

\begin{figure*}[ht]
	\centering
	\begin{tabular}{c c c c}
		\begin{minipage}{0.24\linewidth}%5.5
			\includegraphics[width=\linewidth]{figures/rich1.pdf}
		\end{minipage}
		&
		\begin{minipage}{0.23\linewidth}
			\includegraphics[width=\linewidth]{figures/rich2.pdf}
		\end{minipage}
		&
		\begin{minipage}{0.24\linewidth}
			\includegraphics[width=\linewidth]{figures/poor1.pdf}
		\end{minipage}
		&
		\begin{minipage}{0.23\linewidth}
			\includegraphics[width=\linewidth]{figures/poor2.pdf}
		\end{minipage}
		\\
		(a) User 1 (richer)
		&
		(b) User 2 (richer)
		&
		(c) User 3 (poorer)
		&
		(d) User 4 (poorer)
	\end{tabular}
	\vspace*{-3mm}
	\caption{Illustration of stay points for four users with different socioeconomic statuses.}
	\label{fig:case}
	\vspace*{-3mm}
\end{figure*}

\begin{table*}
\centering
\caption{Case study, DS, DT and DA denote the features captured via the deep network for spatiality diversity, temporality diversity and activity diversity; RT and RS denote that via the recurrent network for temporal (time bin) and semantic features.}
\vspace*{-3mm}
\setlength{\tabcolsep}{11pt}
\begin{tabular}{|c|cc|cc|cc|cc|}
\hline
Case          & \multicolumn{2}{c|}{User 1 (richer)} & \multicolumn{2}{c|}{User 2 (richer)} & \multicolumn{2}{c|}{User 3 (poorer)} & \multicolumn{2}{c|}{User 4 (poorer)} \\ \hline
DS, DT and DA & \multicolumn{2}{c|}{9.62, 1.30 and 2.16}                 & \multicolumn{2}{c|}{5.52, 3.14 and 2.20}                 & \multicolumn{2}{c|}{14.29, 4.45 and 2.77}                 & \multicolumn{2}{c|}{10.38, 4.89 and 5.12}                 \\ \hline
Stay points   & \multicolumn{1}{c|}{RT}      & RS     & \multicolumn{1}{c|}{RT}      & RS     & \multicolumn{1}{c|}{RT}      & RS     & \multicolumn{1}{c|}{RT}      & RS     \\ \hline
$s_1$       & \multicolumn{1}{c|}{18}        & residence       &  \multicolumn{1}{c|}{20}        & residence      & \multicolumn{1}{c|}{9}        & working        & \multicolumn{1}{c|}{32}        & hospital       \\ \hline
$s_2$       & \multicolumn{1}{c|}{7}        &  recreation      & \multicolumn{1}{c|}{12}        & food and drink      & \multicolumn{1}{c|}{10}        & traffic        & \multicolumn{1}{c|}{35}        & traffic        \\ \hline
$s_3$       & \multicolumn{1}{c|}{9}        & education       & \multicolumn{1}{c|}{12}        & traffic      & \multicolumn{1}{c|}{12}        & food and drink        & \multicolumn{1}{c|}{36}        & food and drink       \\ \hline
$s_4$       & \multicolumn{1}{c|}{10}        &  working      & \multicolumn{1}{c|}{14}        &    working & \multicolumn{1}{c|}{13}        & working        & \multicolumn{1}{c|}{40}        & community       \\ \hline
$s_5$       & \multicolumn{1}{c|}{13}        &  education      & \multicolumn{1}{c|}{19}        & lodging      & \multicolumn{1}{c|}{18}        & residence        & \multicolumn{1}{c|}{41}        &    residence    \\ \hline
$s_6$       & \multicolumn{1}{c|}{17}        &  residence      & \multicolumn{1}{c|}{37}        & residence     & \multicolumn{1}{c|}{7}        &  traffic        & \multicolumn{1}{c|}{34}        & attractions       \\ \hline
$s_7$       & \multicolumn{1}{c|}{9}        & working       & \multicolumn{1}{c|}{8}        &   working  & \multicolumn{1}{c|}{8}        &   working        & \multicolumn{1}{c|}{43}        & residence       \\ \hline
\end{tabular}
\label{tab:case}
\vspace*{-2mm}
\end{table*}
\noindent \textbf{(8) Case study.} We conduct a case study. We select four cases for the study, where User 1 and 2 are identified as the richer users in the same class 1, and User 3 and 4 are identified as the poorer users in another class 2.
%
In Figure~\ref{fig:case}, we visualize the locations of their stay points on the map. In Table~\ref{tab:case}, we list the features captured by the deep network and recurrent network. We observe the following insights that may explain the relationship between their mobility patterns and socioeconomic statuses.
\\
\emph{\underline{Insight 1}: Richer users tend to travel shorter.} In Table~\ref{tab:case}, we observe the richer users (User 1 and User 2) are generally with the smaller spatiality diversities (e.g., 9.62 and 5.52) than poorer users. This insight is in line with the intuition from the previous study~\cite{xu2018human}, and the reason could be that rich people are busy with work and have limited time for travelling.
\\
\emph{\underline{Insight 2}: Richer users are generally with lower temporality/activity diversity of daily activities.} Temporality/Activity diversity is an entropy-based feature to reveal the regularity of users' daily activities. 
%
In Table~\ref{tab:case}, we observe the regularity of User 1 and User 2 are high, corresponding to the smaller values. For example, in Figure~\ref{fig:case}, User 1  mainly commutes between home (``residence'' POI) and office (``working'' POI) regularly, and he/she is with the least temporality diversity 1.30. In contrast, the User 4 is irregular, e.g., he/she visits many places instead of staying somewhere and working. 
% In addition, we note that their work and rest schedules are irregular, e.g., the User 1 usually visit some restaurants (``F\&D'' POI) near the Shenzhen airport in the early morning, which is reflected on a larger temporality diversity, i.e., 6.29.
\\
\emph{\underline{Insight 3}: Richer users are with secure jobs.} We infer the users' employment statuses based on the data extracted from their stay points. We infer that User 1 is with a steady job since he/she works (at 09:00 am - 05:00 pm) and stay homes (at 05:00 pm - 07:00 am) regularly. In this situation, he/she has a stable source of income (e.g., we infer that he/she may be a faculty at an university based on the stay points on the map), and the status is reflected on his/her house price data accordingly.
%
% may be a driver using the loaned car because the user is generally visit the places near the Shenzhen airport in the early morning, where the travel regions near the airport are wealthy (i.e., 70,700 rmb/$m^2$) but his/her residence (i.e., rmb/$m^2$) is poor.

