\section{EXPERIMENTS}
\label{sec:experiment}
\subsection{Experimental Setup}
\label{sec:setup}

\noindent \textbf{Datasets.}
% We study the problem on real-world dataset. 
The dataset used in this work contains three parts. 
The first part is the mobility data (i.e., GPS trajectories) generated by users.
%
The second part is POI data, which are used to capture users' activity features.
%
The third part is house price data, which is used to construct labels to reflect the socioeconomic statuses of users for evaluation. We collect the last two parts of data through web map services and web crawlers, respectively.
\if 0
\begin{table}[]
\setlength{\tabcolsep}{4pt}
\centering
\caption{Dataset statistics.}
\vspace*{-2mm}
\begin{tabular}{c|c}
\hline
\textbf{Statistics}                & \textbf{Geolife} \\ \hline
 \# of trajectories                 & 17,621 \\
Total \# of points                 & 24,876,978 \\
Ave. \# of points per trajectory & 1,412 \\
Sampling rate                      & 1s $\sim$ 5s \\
Average distance                   & 9.96m \\ \hline
\end{tabular}
\label{tab:dataset}
\vspace*{-3mm}
\end{table}
\fi

\noindent \textbf{1) Mobility Data.}
The mobility records correspond to a sequence of time-stamped locations sampled by the GPS device. For each record, it captures the location (i.e., latitude and longitude) of a user at a timestamp. We use the Geolife dataset~\cite{zheng2010geolife} for the mobility data. It contains 24,876,978 records in a period of five years, where the data is distributed in over 30 cities of China, and the majority part was generated in Beijing. %The detailed statistic of the dataset is summarized in Table~\ref{tab:dataset}. 
{\newadd{We note that the dataset is publicly available without any personal information, avoiding possible privacy concerns.
}}

\noindent \textbf{2) POI Data.} 
We collect Point-of-Interest (POI) data through Amap Map API~\cite{api}, which contains 156,653 records in Beijing. For each POI record, it provides many attributes, including venue name, category, location with latitude and longitude information. We consider 11 major POI categories in this work, namely working, residence, food and drink, attractions, community, shopping, education,  hospitals, lodging, traffic, and recreation. We collect the POI data between 2011 and 2012, corresponding to the period of the mobility records on Geolife.
%In addition, we include a special category called {\newCommentZheng{``other''}} for the other POI categories that are not included.
\if 0
\begin{figure}
\centering
\begin{tabular}{c}
   \begin{minipage}{0.95\linewidth}
    \includegraphics[width=\linewidth]{figures/vor_fig1_bj.pdf}
    \end{minipage}
\end{tabular}
\vspace*{-2mm}
\caption{House price of Beijing, where the Voronoi polygons are generated based on the spatial distribution of the collected residential locations from Lianjia.}
\label{fig:region}
\vspace*{-3mm}
\end{figure}
\fi

\noindent \textbf{3) House Price Data.} 
We collect the house price data by crawling online housing agents, i.e., Lianjia~\cite{lianjia}, which is the largest Chinese real-estate brokerage company that provides a comprehensive coverage of housing properties. We crawl 8,124 residential sale prices in Beijing. For each transaction, it records the residential name, sale price, floor size and residential address with latitude and longitude information we collected from Amap Map~\cite{api}. Here, the house prices correspond to the average prices with the unit of rmb/$m^2$. %We illustrate the collected house price in Figure~\ref{fig:region}.
%
By following~\cite{xu2018human,ding2019estimating}, we use the house price data to indicate users' socioeconomic statuses. In particular, the range of collected average house price is from 10,588 to 113,224 in Beijing. {\nnCommentZheng{To study multiple-class classification, we take the binary classification for example. We define a binary label with the median threshold of the range (i.e., $\frac{10,588+113,224}{2}=61,891$), we set label 0 for the users, whose house prices are smaller than the threshold; label 1 otherwise. }}
Here, we find users' home locations by following the previous studies~\cite{phithakkitnukoon2012socio,xu2018human}, i.e., the home of a user is inferred as the location visited the most frequently during nighttime from 22:00 to 07:00.

\noindent \textbf{Tasks.
% ~\footnote{Our \texttt{DeepSEI} model has been tested on real FinTech industry projects, and achieved satisfactory results. This part involves user privacy and details are eliminated from this paper.}
} 
We explore two tasks with the \texttt{DeepSEI} model. One is classification. We consider the number of classes from 2 to 5 by evenly partitioning the house price range to 2 - 5 equal intervals, as the corresponding socioeconomic class labels. The other is clustering. We collect the concatenated embeddings outputted by deep network and recurrent network, where the embeddings are learnt from the previous classification task, and thus they have incorporated socioeconomic context from the users.
% , for serving other socioeconomically related tasks. 
We then explore $k$-means clustering on the concatenated embeddings, and vary the $k$ from 2 to 5. The class labels from 2 to 5 in the classification task are re-used as the ground truth for evaluating the clustering with $k$ from 2 to 5, respectively.

%We consider the learned embeddings, which have incorporated socioeconomic context from the users, and can serve other socioeconomically related tasks. We explore $k$-means clustering in this paper, and vary the $k$ from 2 to 5. Similarly, the constructed labels are used as the ground truth for the clustering.

\begin{table*}[ht]
\centering
\caption{Effectiveness evaluation, where 2-5 denote the \# of classes or clusters.}
\vspace{-3mm}
\setlength{\tabcolsep}{5pt}
\begin{tabular}{|l|cccccccc|cccccccc|}
\hline
\multicolumn{1}{|c|}{Method}                  & \multicolumn{8}{c|}{Classification}                                                                                                                                                                            & \multicolumn{8}{c|}{Clustering}                                                                                                                                                                                                                                                                                                                  \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{Metric}} & \multicolumn{2}{c|}{2}                             & \multicolumn{2}{c|}{3}                             & \multicolumn{2}{c|}{4}                             & \multicolumn{2}{c|}{5}                          & \multicolumn{2}{c|}{2}                                                                  & \multicolumn{2}{c|}{3}                                                                  & \multicolumn{2}{c|}{4}                                                                  & \multicolumn{2}{c|}{5}                                             \\ \cline{2-17} 
\multicolumn{1}{|c|}{}                        & \multicolumn{1}{c|}{F1} & \multicolumn{1}{c|}{Acc} & \multicolumn{1}{c|}{F1} & \multicolumn{1}{c|}{Acc} & \multicolumn{1}{c|}{F1} & \multicolumn{1}{c|}{Acc} & \multicolumn{1}{c|}{F1} & Acc                   & \multicolumn{1}{c|}{ARI}                   & \multicolumn{1}{c|}{AMI}                   & \multicolumn{1}{c|}{ARI}                   & \multicolumn{1}{c|}{AMI}                   & \multicolumn{1}{c|}{ARI}                   & \multicolumn{1}{c|}{AMI}                   & \multicolumn{1}{c|}{ARI}                   & AMI                   \\ \hline
SES(RF)                                      & \multicolumn{1}{c|}{59.3}   & \multicolumn{1}{c|}{68.9}    & \multicolumn{1}{c|}{42.4}   & \multicolumn{1}{c|}{44.6}    & \multicolumn{1}{c|}{32.1}   & \multicolumn{1}{c|}{37.2}    & \multicolumn{1}{c|}{25.6}   & 30.3                      & \multicolumn{1}{c|}{\multirow{2}{*}{49.7}} & \multicolumn{1}{c|}{\multirow{2}{*}{50.2}} & \multicolumn{1}{c|}{\multirow{2}{*}{50.0}} & \multicolumn{1}{c|}{\multirow{2}{*}{50.2}} & \multicolumn{1}{c|}{\multirow{2}{*}{49.4}} & \multicolumn{1}{c|}{\multirow{2}{*}{50.7}} & \multicolumn{1}{c|}{\multirow{2}{*}{49.9}} & \multirow{2}{*}{50.3} \\ \cline{1-9}
SES(XGBoost)                                 & \multicolumn{1}{c|}{60.0}   & \multicolumn{1}{c|}{60.3}    & \multicolumn{1}{c|}{41.0}   & \multicolumn{1}{c|}{43.3}    & \multicolumn{1}{c|}{32.6}   & \multicolumn{1}{c|}{36.4}    & \multicolumn{1}{c|}{23.9}   &  27.8                     & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      &                       \\ \hline
DIF(RF)                                      & \multicolumn{1}{c|}{69.1}   & \multicolumn{1}{c|}{69.3}    & \multicolumn{1}{c|}{57.1}   & \multicolumn{1}{c|}{59.6}    & \multicolumn{1}{c|}{50.3}   & \multicolumn{1}{c|}{53.0}    & \multicolumn{1}{c|}{47.1}   & 48.5                      & \multicolumn{1}{c|}{\multirow{2}{*}{60.3}} & \multicolumn{1}{c|}{\multirow{2}{*}{56.9}} & \multicolumn{1}{c|}{\multirow{2}{*}{57.8}}     & \multicolumn{1}{c|}{\multirow{2}{*}{55.9}}     & \multicolumn{1}{c|}{\multirow{2}{*}{54.0}}     & \multicolumn{1}{c|}{\multirow{2}{*}{52.6}}     & \multicolumn{1}{c|}{\multirow{2}{*}{50.7}}     & \multirow{2}{*}{50.4}     \\ \cline{1-9}
DIF(XGBoost)                                 & \multicolumn{1}{c|}{70.3}   & \multicolumn{1}{c|}{75.5}    &  \multicolumn{1}{c|}{61.6}    & \multicolumn{1}{c|}{63.5}   & \multicolumn{1}{c|}{52.6}    & \multicolumn{1}{c|}{55.7}   & \multicolumn{1}{c|}{42.6}    &   49.3                    & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      &                       \\ \hline
L2P(RF)                                      & \multicolumn{1}{c|}{67.8}   & \multicolumn{1}{c|}{72.2}    & \multicolumn{1}{c|}{55.2}   & \multicolumn{1}{c|}{56.4}    & \multicolumn{1}{c|}{46.1}   & \multicolumn{1}{c|}{48.2}    & \multicolumn{1}{c|}{41.5}   &  44.3                     & \multicolumn{1}{c|}{\multirow{2}{*}{56.6}} & \multicolumn{1}{c|}{\multirow{2}{*}{55.5}} & \multicolumn{1}{c|}{\multirow{2}{*}{53.8}}     & \multicolumn{1}{c|}{\multirow{2}{*}{53.4}}     & \multicolumn{1}{c|}{\multirow{2}{*}{51.2}}     & \multicolumn{1}{c|}{\multirow{2}{*}{50.8}}     & \multicolumn{1}{c|}{\multirow{2}{*}{49.7}}     & \multirow{2}{*}{50.0}     \\ \cline{1-9}
L2P(XGBoost)                                 & \multicolumn{1}{l|}{68.2}   & \multicolumn{1}{l|}{67.8}    & \multicolumn{1}{l|}{58.4}   & \multicolumn{1}{l|}{59.3}    & \multicolumn{1}{l|}{47.7}   & \multicolumn{1}{l|}{49.0}    & \multicolumn{1}{l|}{40.2}   & 42.2  & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c|}{}                      &                       \\ \hline
DeepSEI                                       & \multicolumn{1}{c|}{\textbf{86.1}}   & \multicolumn{1}{c|}{\textbf{90.2}}    & \multicolumn{1}{c|}{\textbf{80.2}}   & \multicolumn{1}{c|}{\textbf{80.4}}    & \multicolumn{1}{c|}{\textbf{63.9}}   & \multicolumn{1}{c|}{\textbf{64.2}}    & \multicolumn{1}{c|}{\textbf{53.3}}   &   \textbf{58.8}                    & \multicolumn{1}{c|}{\textbf{83.2}}                      & \multicolumn{1}{c|}{\textbf{77.5}}           
& \multicolumn{1}{c|}{\textbf{80.9}}                      & \multicolumn{1}{c|}{\textbf{71.9}}                      & \multicolumn{1}{c|}{\textbf{70.6}}                      & \multicolumn{1}{c|}{\textbf{70.3}}                      & \multicolumn{1}{c|}{\textbf{69.2}}                      &  \multicolumn{1}{c|}{\textbf{64.4}}                     \\ \hline
\end{tabular}
\vspace{-4mm}
\label{tab:deepmodels}
\end{table*}

\begin{table}[]
\centering
\caption{Ablation study for \texttt{DeepSEI}.}
\vspace{-3mm}
\begin{tabular}{l|cl|cl}
\hline
\multicolumn{1}{c|}{Method}     & \multicolumn{2}{c|}{Classification} & \multicolumn{2}{c}{Clustering} \\ \hline
\texttt{DeepSEI}                         & \multicolumn{2}{c|}{86.1}               & \multicolumn{2}{c}{83.2}           \\ \hline
w/o Deep Network                & \multicolumn{2}{c|}{73.7}               & \multicolumn{2}{c}{78.2}           \\
w/o Spatiality Diversity                  & \multicolumn{2}{c|}{78.8}               & \multicolumn{2}{c}{80.0}           \\
w/o Temporality Diversity                & \multicolumn{2}{c|}{82.5}               & \multicolumn{2}{c}{81.9}           \\
w/o Activity Diversity                    & \multicolumn{2}{c|}{82.8}               & \multicolumn{2}{c}{81.9}           \\ \hline
w/o Recurrent Network           & \multicolumn{2}{c|}{33.4}               & \multicolumn{2}{c}{60.4}           \\
w/o Spatial Feature          & \multicolumn{2}{c|}{75.7}               & \multicolumn{2}{c}{78.1}           \\
w/o Temporal Feature       & \multicolumn{2}{c|}{82.8}               & \multicolumn{2}{c}{80.5}           \\
w/o Semantic Feature & \multicolumn{2}{c|}{68.6}               & \multicolumn{2}{c}{77.9}           \\ \hline
\end{tabular}
\vspace{-5mm}
\label{tab:ablation}
\end{table}
\noindent \textbf{Baselines.} 
The following baselines are adapted.

\noindent $\bullet$ SES~\cite{xu2018human}. The study verified users' socioeconomic statuses can be reflected by their mobility patterns. 
%For example, it has been found that users that are generally richer tend to travel shorter. 
Inspired by the study, we extract the mobility indicators including (1) radius of gyration, (2) number of activity locations, (3) activity entropy, (4) travel diversity, (5) K-radius of gyration, (6) unicity. %These indicators capture how regularly, broadly, frequently, and intensively a user would travel within a city. 
%Detailed definitions of these indicators could be found in~\cite{xu2018human}. 
% Based on these indicators, 
Based on the features, we explore the following 10 classifiers for the classification task, including RBFSVM, LinearSVM, Logistic Regression, K-Nearest Neighbors (KNN), Decision Tree, Random Forest, Bayes, Adaboost, Gradient Boost and XGBoost. {\newadd{We grid search the best hyperparameters of the classifiers based on a development set.}}
Among them, we select two classifiers with the best effectiveness, namely SES (Random Forest) and SES (XGBoost). In addition, we concatenate those mobility indicators as a vector for the clustering task.

\noindent $\bullet$ DIF~\cite{wu2019inferring}. The study proposes a framework of inferring users’ demographics (e.g., gender, martial status or age) from their trajectories and geographical context. Other than the feature (1), (2), (3), (4), (6) studied in SES, it further incorporates (7) number of unique stay points, (8) centroid of stay points, (9) number of travels and (10) land use. Similarly, we explore the aforementioned 10 classifiers based on the features, and DIF (Random Forest) and DIF (XGBoost) dominate others in terms of the effectiveness. For clustering, we concatenate these features as the input.

\noindent $\bullet$ L2P~\cite{zhong2015you}. The study investigates users’ demographics and proposes a general location-to-profile (L2P) framework. L2P extracts the features from users' check-ins in terms of spatiality, temporality, and location knowledge (e.g., POI categories). It constructs a three-way tensor based on the extracted features, and adopts Tucker tensor decomposition to obtain a feature vector for each user. Based on the feature vectors, we still explore the aforementioned 10 classifiers, and L2P (Random Forest) and L2P (XGBoost) stand out. Those feature vectors can also be used for clustering.

\noindent \textbf{Evaluation Metrics.} 
Our paper involves two tasks: classification and clustering. For classification, we use the $F_1$-score and accuracy as the evaluation metric by following~\cite{zhong2015you}. 
% The two metrics are widely used for classification task and can evaluate the imbalanced cases effectively~\cite{zhang2023online,li2021effective}. 
For clustering, we use the metrics of Adjusted Rand Index (ARI) and Adjusted Mutual Information (AMI). They measure the correlation between the clustered result and the ground truth. Their values lie in the range of $[-1,1]$, and we normalize their values in $[0,1]$ for the ease of reading, where a higher ARI or AMI indicates a better result.
% ~\cite{zhang2022predicting}. 

\noindent \textbf{Parameter Setting.}
Our \texttt{DeepSEI} model consists of deep network and recurrent network. For deep network, we embed the features of (1) spatiality diversity, (2) temporality diversity and (3) activity diversity into {\newCommentZheng{32-dimensional vectors}}, and concatenate them as a long vector with dimension {\newCommentZheng{$32*3=96$}} as the output. For recurrent network, we embed the features of (4) spatiality, (5) temporality and (6) activity into {\newCommentZheng{32-dimensional vectors}}, and feed the concatenation as a {\newCommentZheng{$96$-dimensional vector (i.e., $32*3=96$)}}, into a hierarchical LSTM. To implement the hierarchical LSTM, we use a low-level LSTM with {\newCommentZheng{64 hidden units}} and a high-level LSTM with {\newCommentZheng{64 hidden units}}. The hidden vector at the last step of the high-level LSTM is then fed into a fully connected layer with {\newCommentZheng{32 neurons}}. Thus, the output of recurrent network is a {\newCommentZheng{32-dimensional vector}}. Further, the outputs of deep network and recurrent network are concatenated as a {\newCommentZheng{$128$-dimensional vector (i.e., $96+32=128$)}}, which is fed into a fully connected layer with the softmax function as the activation function. We train the networks with Adam stochastic gradient descent and an initial learning rate of {\newCommentZheng{0.001.}} 

The default parameters of stay point radius $S_d$ and stay point duration $S_t$ are set to {\newCommentZheng{100m and 60 min}}, respectively. Here, we vary the parameter $S_d$ from {\newCommentZheng{100m to 300m}}, since the results are similar and we use the setting of {\newCommentZheng{$S_d=100$m.}} The setting of the parameter $S_t$ will be studied in experiments. For extracting the above features from (1) to (6), the following parameters are involved: the cell size for the feature (4), the spatiality granularity for the feature (1) and the temporality granularity and activity granularity for the feature (2,3). We use the settings of cell size, spatiality granularity, temporality granularity and activity granularity as {\newCommentZheng{200m, 100, 0.5 and 0.5}}, respectively. The results of their effects are shown in experiments.

\if 0
In addition, we notice that the datasets are highly imbalanced, e.g., the proportion of overdue users is around 10\%. {\CommentZheng{We consider the following strategies proposed for imbalanced classification into the \texttt{DeepLPP} model that are introduced in the tutorial~\cite{imbalance}, including (1) bias initialization: we set initial output layer's bias to reflect the imbalanced datasets, where the bias is calculated as the logarithmic ratio between the positive and negative samples;
%
(2) calculating class weights: we weight the minority class with few samples (i.e., overdue samples) according to the formula in~\cite{imbalance}, which causes the model to pay more attention to samples from the minority class.}}
\fi


\noindent \textbf{Evaluation Platform.}
We implement \texttt{DeepSEI} and other baselines in Python 3.6 and Tensorflow 2.3.0. 
The experiments are conducted on {\newCommentZheng{a desktop with Intel(R) Core(TM) i5-8265U CPU @ 1.60GHz 1.80 GHz and a 32 GB memory.}}
%
%The datasets are located in a secure offline server
% , which may access by requesting our collaborators from 
%maintained by WeBank,
%
The codes can be downloaded via the link~\footnote{\url{https://github.com/zhengwang125/DeepSEI}}.%https://www.dropbox.com/sh/70y4zx7gvxx1zyb/AACtw3hhoni47iaH-PecCi\_Na?dl=0

\if 0
\noindent \textbf{Evaluation Platform.}
We implement \texttt{DeepSEI} and other baselines in Python 3.6 and Tensorflow 2.3.0. 
The experiments are conducted on {\newCommentZheng{a desktop with Intel(R) Core(TM) i5-8265U CPU @ 1.60GHz   1.80 GHz and a 8 GB memory.}}
%
%The datasets are located in a secure offline server
% , which may access by requesting our collaborators from 
%maintained by WeBank,
%
The codes can be downloaded via the link~\footnote{\url{https://www.dropbox.com/sh/70y4zx7gvxx1zyb/AACtw3hhoni47iaH-PecCi\_Na?dl=0}}.
\fi
