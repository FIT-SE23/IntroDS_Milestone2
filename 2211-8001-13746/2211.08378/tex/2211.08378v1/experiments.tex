\section{Experiments}
\label{sec:experiments}

\head{Experimental Setup and Metrics}
The \encoder{} employs a GNN with 200 hidden dimensions for node states, layers with skip-connection, sum aggregation, and batch-normalization. We tune hyper-parameters by cross-validation on a rolling basis and search the hyper-parameters over \textbf{(i)} the numbers of layers (1 to 5); \textbf{(ii)} learning rate (0.001 to 0.01); and \textbf{(iii)} the margin $\gamma$ (in increments of 0.05 in the range 0.3 to 0.7). The values of the hyper-parameters are reported in \autoref{tab:config} in \autoref{app:config}. We implement \model{} with the GraphGym library~\cite{GraphGym} and use an NVIDIA V100 GPU in the experiments. We use the AUC (the area under the ROC curve) as the metric of comparison. The higher AUC value indicates the high quality of the method.

\input{dataset_table.tex}
\head{Datasets}
We use nine real-world public datasets~\cite{RM, FirmTruss, ofori2021topological, DKPol, bitcoin_alpha, amazon_dataset_main} whose domains cover social, co-authorship, blockchain, and co-purchasing networks.
We summarize their statistics in \autoref{tab:datastat} and provide detailed descriptions in~\autoref{app:datasets-details}. Since the ground truth for anomaly detection is difficult to obtain~\cite{anomaly-survey2}, we extend the methodology in existing studies~\cite{NetWalk, AddGraph, anomaly-survey2} to multiplex networks and propose a new approach to inject anomalous edges into our datasets (more details in \autoref{app:datasets-details}). Note that the DKPol and RM datasets are static multiplex networks, and we use them to show the effectiveness of \model{} in capturing content and structural features. 

\head{Baselines}
Since there is no prior work on edge anomaly detection in multiplex networks, we first compare \model{} with single-layer edge anomaly detection methods: GOutlier~\cite{anomaly_prob2} builds a generative model for edges in a node cluster. CM-Sketch~\cite{anomaly_distance4} uses a Count-Min sketch for approximating global and local structural properties. NetWalk~\cite{NetWalk} uses a random walk to learn a unified embedding for each node and then dynamically clusters the nodes' embeddings. AddGraph~\cite{AddGraph} is an end-to-end approach that uses an extended GCN in temporal networks.
Finally, we  compare with two multiplex network embedding baselines, ML-GCN~\cite{CS-MLGCN} and MNE~\cite{scalable-ml-embedding}. We apply $K$-means clustering on their obtained node embeddings for anomaly detection~\cite{NetWalk}.

\vspace*{-3ex}
\input{table_ML}
\head{Results on Multiplex Networks}
We compare \model{} with the baseline methods on both dynamic and static multiplex networks with different percentages of anomalous edges (i.e., $1\%$, $5\%$). \autoref{tab:ML-results} reports the AUC for both the baselines and \model{}. Our method outperforms \emph{all} baselines in all datasets and improves the best baseline results by $8.18\%$ on average. There are three reasons for \model{}'s superior performance: \textbf{(1)} it outperforms competitors for static datasets because it can learn structural anomaly patterns in the network, rather than depending on pre-defined patterns/roles. \textbf{(2)} \model{} outperforms single-layer methods due to its attention mechanism that incorporates complementary information from different relation types. \textbf{(3)} \model{} outperforms multiplex methods as it is an end-to-end method and is optimized for anomaly detection. It is also a dynamic method and can take advantage of the temporal properties of the network.

% \vspace*{-1ex}
\input{table_SL}
\head{Results on Single-layer Dynamic Networks}
We also compare \model{} with single-layer method baselines on single-layer dynamic datasets. \autoref{tab:SL-results} summarizes the results. Once again, we see that \model{} outperforms all the baselines, even in single-layer graphs, by $2.46\%$ on average. This is mainly due to \encoder{}'s architecture, which enables our method to incorporate the outputs of GNN layers after each layer and recurrently update them over time by a GRU cell.



\head{Ablation Study}
Next, we conduct experiments to show that the \model{} architecture design is effective in boosting performance. We examine the effect of GRU cells by replacing them with a 2-layer MLP. We also investigate the effect of the attention mechanism by \textbf{(1)} removing the attention, learning node embeddings in each relation-type separately and \textbf{(2)} aggregating the information of different relation types by summation (without weights). \autoref{tab:ablation_study} summarizes the results. We found that both our attention mechanism and the GRU cells are important for \model{}, producing significant performance boosts.

Additional experimental results on the effect of the training ratio can be found in \ref{app:additional_experiment}.



\begin{figure}[t]
\hspace*{-7ex}
\parbox{.83\linewidth}{
    \centering
    \includegraphics[width=0.95\linewidth]{event_detection.pdf}
    \vspace{2ex}
    \caption{Event detection in Ethereum network.}
    \label{fig:event_detection}
}~
\hspace*{-15ex}~\vspace{-1ex}~
\parbox{.50\linewidth}{
\centering
    \hspace{3ex}
    \vspace{-1mm}
    \includegraphics[width=0.4\linewidth]{brain_anomalies.png}
    \caption{Anomalous edges in BN.}
    \label{fig:brain}
}
\vspace{-2ex}
\end{figure}


\head{Effectiveness in Detecting Events}
Next, we evaluate how well \model{} detects events in the Ethereum transaction network. In each timestamp, we calculate the anomaly score for all the edges in the snapshot. We then compute the average of the top-15 edge anomaly scores and report them in \autoref{fig:event_detection}. We find that the top-4 local optimums all coincide with major events annotated in the figure. 

\head{Case Study of Brain Networks}
Behavioral disturbances in ADHD are thought to be caused by the dysfunction of spatially distributed, interconnected neural systems~\cite{SVM_ADHD}. We used \model{} to detect anomalous connections in the brain network (BN) of people with ADHD. Anomalous functional correlations between BN of people  with ADHD compared to those without can help us understand which brain regions are involved in ADHD. Our dataset~\cite{brain_main_dataset} is derived from the functional magnetic resonance imaging (fMRI) of 40 individuals (20 individuals in the condition group, labeled  ADHD, and 20 individuals in the control group, labeled  TD) with the same methodology used by~\citet{Brain_network_fmri}. Here, each layer (relation type) is the BN of an individual person, where nodes are brain regions, and each edge measures the statistical association between the functionality of its endpoints. We present two results: \textbf{(1)} 74\% of all detected anomalies are edges in the BNs of people in ADHD group. \textbf{(2)} 69\% of all found anomalies in the ADHD group correspond to edges in the frontal and occipital cortex of the brain. \autoref{fig:brain} visualizes the anomalous edges in the brain network of an individual in the ADHD group. These findings show an unexpected functional correlation of occipital and frontal lobes regions with other parts, which are consistent with previous studies on ADHD~\cite{brain_result, anomaly_brain1, brain_result}. More results and visualizations are reported in~\autoref{app:additional_experiment}.
