\section{Introduction}

Serverless computing, and microservices have recently gained in popularity to
deploy cloud services. They improve developer productivity by focusing on
business logic and separating functional services. Function-as-a-Service (FaaS)
is a special form of serverless computing. In an extreme case microservices
implement functional decomposition similar to FaaS. With FaaS offering the
smallest services, the techniques are on a spectrum for service size. Throughout this
paper we will refer to serverless computing, microservices and FaaS
interchangeably and refer to the application as a service. Cloud Service
Providers (CSPs) run and provide the infrastructure software connecting each
service. This abstraction comes at the cost of about 25\% infrastructure tax as
reported by Google~\cite{warehousescalecomputing, fbcommunication}, consisting
of various overheads due to small units communicating frequently over network.
Large CSPs react by shifting the infrastructure software into Infrastructure
Processing Units (IPUs), which operate more cost effectively than traditional
server CPUs offering higher performance for workloads. While this shifts the
burden and reduces cost, this approach does not reduce the communication cost,
or provide a software architecture eliminating the inherent overheads associated
with this deployment model. Alternatively, CSPs built special purpose
environments relying on memory-safe
languages~\cite{fastly-wasm,cloudflare-workers} which require specific compiler
and runtime environments and deny their optimizations to legacy applications.

To avoid the inherent overheads in today's hardware and software architecture,
we suggest leveraging memory-safe languages for performance and investigate
hardware optimizations generalize the environment. Memory-safe languages (e.g.,
Rust) and runtimes (e.g., Wasm) rely on the compiler to generate binary code
preventing memory access violations via static and runtime checks. Their
performance is comparable to native execution in case of Rust~\cite{perfrust}
and shows moderate overheads for Webassembly (Wasm)~\cite{perfwasm}. Serverless
computing could benefit from this environment by running all services in the
same process with near-zero communication cost while being isolated from each
other. At the same time, the runtime specializes functionality to, e.g., access
devices avoiding OS overheads.

These two infliction points, the advance in serverless computing and memory-safe
languages, suggests that we should revisit and explore a memory-safe software
and hardware architecture providing a general-purpose runtime environment to
specialize functionality when needed and strongly isolate services. Our goal is
to leverage memory-safe software guarantees where possible, and describe the
required hardware to further improve performance and security. The solution
needs to generalize to legacy and memory-safe services and offer easy adoption.
We will analyze the path of a new Single Address Space Operating System (SASOS)
using Rust and Wasm, as well as a library Operating System (library OS) allowing
multiple services to execute in parallel while also depending on a traditional
host OS. While this idea is not new and was tried in industry~\cite{midori,
singularity}, we believe the serverless and other cloud workloads demand a
drastic change in hardware and software.

\begin{figure*}[t]
    \includegraphics*[]{mssa_comparison.drawio}
    %\subfigure[VM-based]{\includegraphics{mssa_comparison_vm.drawio}}
    %\hspace{1em}
    %\subfigure[Memory-Safe Userspace]{\includegraphics{mssa_comparison_fastly.drawio}}
    %\hspace{1em}
    %\subfigure[\arch]{\includegraphics{mssa_comparison_mssa.drawio}}
    \caption{Comparison between cloud software architecture}
    \label{fig:mssa_comparison}
\end{figure*}

By leveraging memory-safe languages our architecture can benefit from a single
memory abstraction to drastically improve switching and communication between
services. This is in harsh contrast to traditional hardware and software
abstractions which rigidly isolate processes, operating systems (OS), address
spaces, and privilege levels. To achieve this goal, services and OS
functionality execute in the same address spaces and privilege level. Sharing
becomes instant between a service and the OS. Existing research~\cite{lwc, smv,
secage, nestedkernel, dune} on improving process-based isolation suffers from
too high runtime overheads. Research has focused on SASOS~\cite{singularity} and
library OSes ~\cite{demikernel, graphene, ix, arrakis, redleaf,akkus2018sand} as
the two alternative approaches to bridge this gap. SASOS overcome existing
inefficiencies in traditional OSes by executing the OS and the service in the
same address space while offering modularity. Recent advances in memory-safe
languages and runtimes offer the building blocks to restart SASOS efforts, but
require extensive engineering effort to build a new OS and further improvements
to secure memory-safe environments to prevent advanced attacks (e.g., transient
execution attacks~\cite{narayan2021swivel}). In contrast, library OSes move
kernel functionality into the userspace and offer specialized alternatives like
kernel-bypasses for networking~\cite{demikernel}. Instead of writing an OS from
scratch, library OSes focus on a specific technique and use the host OS to
support the remaining functionality. These approaches typically lack the support
for running multiple services at the same time while properly isolating their
execution.

We discuss the main beneficiaries of \archshort including microservices, FaaS
and memory-bandwidth intensive workloads such as machine learning. An
inefficient software architecture causes the infrastructure tax to be up to 25\%
~\cite{warehousescalecomputing}. The remainder of this paper discusses how to
build and optimize \archshort for such workloads.