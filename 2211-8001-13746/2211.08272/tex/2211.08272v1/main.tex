
%% bare_jrnl.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% see http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[draftcls,onecolumn]{IEEEtran}
% \documentclass[journal]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[journal]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
\usepackage{amsmath}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
\ifCLASSOPTIONcompsoc
  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\else
  \usepackage[caption=false,font=footnotesize]{subfig}
\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley, Jeff Goldberg and 
% Axel Sommerfeldt. This package may be useful when used in conjunction with 
% IEEEtran.cls'  captionsoff option. Some IEEE journals/societies require that
% submissions have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.4.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/pkg/endfloat
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a 
% page by themselves.




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


\usepackage{multirow}
\usepackage{hyperref}
\usepackage{makecell}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Low-Thrust Orbital Transfer using Dynamics-Agnostic Reinforcement Learning}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{Carlos~M.~Casas,~%\IEEEmembership{Member,~IEEE,}
        Belén~Carro,~%\IEEEmembership{Fellow,~OSA,}
        and~Antonio~Sánchez-Esguevillas%,~\IEEEmembership{Life~Fellow,~IEEE}% <-this % stops a space
\thanks{Carlos M. Casas, Belén Carro and Antonio Sánchez-Esguevillas are with the Department TSyCeIT, ETSIT, University of Valladolid, Spain.}% <-this % stops a space
%%%%%e-mail: carlosmarcelino.casas@alumnos.uva.es.
\thanks{© 20xx IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.}
%\thanks{J. Doe and J. Doe are with Anonymous University.}% <-this % stops a space
%\thanks{Manuscript received April 19, 2005; revised August 26, 2015.}
}

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers
\markboth{IEEE}%
{Shell \MakeLowercase{\textit{et al.}}: Low-Thrust Orbital Transfer using Dynamics-Agnostic Reinforcement Learning}
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.




% If you want to put a publisher's ID mark on the page you can do it like
% this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2015 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.



% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
Low-thrust trajectory design and in-flight control remain two of the most challenging topics for new-generation satellite operations. Most of the solutions currently implemented are based on reference trajectories and lead to sub-optimal fuel usage. Other solutions are based on simple guidance laws that need to be updated periodically, increasing the cost of operations. Whereas some optimization strategies leverage \emph{Artificial Intelligence} methods, all of the approaches studied so far need either previously generated data or a strong \textit{a priori} knowledge of the satellite dynamics. This study uses model-free \emph{Reinforcement Learning} to train an agent on a \emph{constrained} pericenter raising scenario for a low-thrust medium-Earth-orbit satellite. The agent does not have any prior knowledge of the environment dynamics, which makes it unbiased from classical trajectory optimization patterns. The trained agent is then used to design a trajectory and to autonomously control the satellite during the cruise. Simulations show that a dynamics-agnostic agent is able to learn a quasi-optimal guidance law and responds well to uncertainties in the environment dynamics. The results obtained open the door to the usage of \emph{Reinforcement Learning} on more complex scenarios, multi-satellite problems, or to explore trajectories in environments where a reference solution is not known.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
artificial intelligence, space vehicle control, optimal control.
\end{IEEEkeywords}






% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps.
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by the IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.

\IEEEPARstart{S}{atellites} require a large initial investment to build and place in the desired orbit. For that reason, a successful mission is usually exploited way beyond the initial expected operational life. One of the main factors that restricts the lifetime of a satellite is the available fuel on-board, mainly used to change or correct its trajectory. Therefore, optimising the fuel consumption is of the utmost importance.

Traditionally, satellites are equipped with thrusters that produce a large force during a short amount of time, in the order of seconds, sometimes minutes. Control problems typically need to find out the optimal direction of the thrust and the start and end of the manoeuvre. Since the duration is expected to be short, the direction of the thrust is either constant or follows a simple parametric guidance law. Due to the low number of free variables and the well-known dynamics throughout the environment, these problems are relatively simple to solve, either mathematically or numerically. An experienced flight dynamics engineer can develop some sort of intuition of what a good initial guess for the parameters can be, so the optimization problems only require a local search around that initial guess.

Some satellites already equip low-thrust devices, such as electric propulsion systems or solar sails, and their use is being generalised. Scientific missions have used them for a few years, the latest examples being \emph{ESA/JAXA}'s \emph{BepiColombo} \cite{garcia2006bepi} launched on 2018 currently on its way to Mercury; and \emph{NASA}'s \emph{NEA Scout} \cite{mcnutt2014neascout} scheduled for launch in 2021. In the commercial sector, some companies like \emph{OHB System} \cite{lubberstedt2014electric} or \emph{Boeing} \cite{feuerborn2013finding} have started to build satellite platforms fully based on electric propulsion for geostationary satellites. Mega-constellations of small satellites on low-Earth orbit such as \emph{SpaceX}'s \emph{Starlink} \cite{potrivitu2020review} also have a similar architecture.

Low-thrust devices produce a small force that can be maintained for a long period of time, even days or weeks. On the one hand, they end up spending much less fuel than a traditional propulsion system for the same impulse, thus increasing the lifetime or range of the satellite. On the other hand, the control problems are much more difficult to solve, being numerical methods virtually the only way to achieve an acceptable solution. Moreover, it is difficult for a flight dynamics engineer to give an initial guess on what the optimal solution will be, so a thorough exploration phase needs to be performed. Thus the need to find a brand new set of tools to find near-optimal solutions.

The most commonly used approach for optimizing low-thrust trajectories consists on dividing the trajectory into arcs and optimising them separately (e.g. \cite{novak2011design, whiffen2006mystic}), each of them with its own parametric law. If not enough laws are defined then the trajectory is sub-optimal; and if too many laws are defined then the number of free variables is very large, the computation time increases massively, and the problem becomes intractable. Some methods have been developed to solve these problems, such as \emph{Discrete Mechanics and Optimal Control} (\emph{DMOC}) \cite{junge2005dmoc} where the original problem is transformed into a linear constrained optimization problem with thousands of free variables representing position and force on intermediate points, and constraints represent the approximate dynamics of the problem; or \emph{Evolutionary Algorithms} such as genetic algorithms or swarm optimization \cite{shirazi2017evolutionary}, where potential solutions are coded and mixed together to produce new candidate solutions.

All these methods heavily rely on the knowledge of the dynamics and on the definition of astute intermediate checkpoints. On top of that, the obtained solutions do not adapt to changes in the problem conditions. The control problem needs to be re-solved every few days after the latest observations of the satellite have been received, so that the free parameters are re-tuned. In order to improve the autonomy of satellites, trajectory control has been looking into the \emph{Artificial Intelligence} field \cite{izzo2019ml}. Some attempts consist on approximating certain aspects of the trajectory, such as the cost function or the guidance law, using \emph{Supervised Learning} \cite{perez2021ml}; or training an agent based on pre-created failure scenarios \cite{rubinsztejn2019nn}. This requires a lot of ad-hoc created data, and the outcome is a trajectory that just replicates what it has been fed with. Other studies used several aspects of \emph{Artificial Intelligence} to explore the space of possible arcs and design a trajectory to be refined by other means \cite{dasstuart2018rapid}. Finally, a few studies tried to directly train an agent using \emph{Reinforcement Learning} \cite{miller2019rl}, but they heavily relied on the knowledge of the problem dynamics, up to the point to reward the agent at each step depending on the distance to a target trajectory.

The goal of this article is to study the feasibility of a simpler more direct \emph{Reinforcement Learning} approach, where an agent is left free to act the thrusters of the satellite in a particular environment without intermediate rewards. The agent does not have any \emph{a priori} knowledge of the dynamics and it does not make any assumptions about the best coordinate system to represent the problem, making it totally unbiased from any classical control pattern. After being trained, the agent is used to create the full quasi-optimal trajectory, and to control the satellite all along the trajectory without any further update on the agent parameters, resulting in a totally autonomous fault-resilient satellite.

Note that the novelty of this study lies on the simplicity of the method used to obtain an optimal guidance law and not on the scenario under analysis. In this particular case, a pericenter raising is typically planned using a simple law that maximizes the time-rate of the pericenter radius. Nevertheless, the characteristics of the platform and the addition of a constraint on the apocenter radius transform such a classical approach into an over-complicated solution.
% You must have at least 2 lines in the paragraph with the drop letter
% (should never be an issue)

%\hfill mds
 
%\hfill August 26, 2015

%\subsection{Subsection Heading Here}
%Subsection text here.

% needed in second column of first page if using \IEEEpubid
%\IEEEpubidadjcol

%\subsubsection{Subsubsection Heading Here}
%Subsubsection text here.

\section{Material and Methods}

\emph{Reinforcement Learning} \cite{kaelbling1996rl} is an area of \emph{Machine Learning} focused on studying optimization problems where an entity (agent) iteratively acts on a dynamical system (environment) to maximize a particular metric (rewards), with the goal to learn an optimal set of actions (policy). Contrary to \emph{Supervised Learning}, a \emph{Reinforcement Learning} algorithm does not need pre-generated data. Instead, it learns interacting directly with the environment.

\begin{figure}[!t]
\centering
\includegraphics[width=2.5in]{figures/rl}
\caption{\emph{Reinforcement Learning} model.}
\label{figure:rl}
\end{figure}

The communication between the agent and the environment is performed as shown in Figure \ref{figure:rl}: the environment feeds the initial observation to the agent. In each step, the agent decides the best action to take and informs the environment about it. Then the environment rewards (or penalizes) the latest action and returns the new observation to the agent. This process is repeated until the environment considers that the scenario is over. All the steps together are considered an episode.

Through exploring different actions in different episodes, the agent is able to identify which actions produce better rewards, effectively learning a control logic. As in every trial-and-error method, there needs to be a balance between exploration and explotation: an agent that explores too much does not typically focus on fine-tuning any particular solution in the search for the local minimum, whereas an agent too aggressive could miss a better solution in an unexplored area.

\subsection{Environment Definition}

The scenario under study is a constrained pericenter\footnote{Pericenter is the closest point of the orbit from the Earth} raising of a medium-Earth-orbit (MEO) satellite with an orbital plane tilted with respect to the principal axis of the inertial \emph{Geocentric Celestial Reference Frame} (GCRF). The satellite has an inertial orientation with three pairs of thrusters aligned with the principal directions of GCRF\footnote{Traditionally, satellites have one main engine for orbit control that is oriented towards the selected direction. Nevertheless, since the orientation is set by the needs of the maneuver, it prevents any other activity from happening at the same time. In order to prevent that off-time during the long maneuvering periods, the satellite under study has a configuration with three pair of thrusters where no special orientation of the satellite is needed.}. The full set of forces and other environment parameters can be found in Table \ref{table:environment}. In order to prevent the agent from learning a guidance law purely depending on the time, the initial mean anomaly of the satellite is selected randomly at the beginning of each episode.

\begin{figure}[!t]
\centering
\includegraphics[width=2.5in]{figures/orbit}
\caption{Pericenter raising scenario of a MEO satellite.}
\label{figure:orbit}
\end{figure}

Each temporal step has the same duration. During that step, the force of each of the thrusters is constant and selected by the agent. Each episode has a fixed number of steps\footnote{A fixed number of steps is needed to obtain an unbiased measure of the achieved goal at the end of the episode. If the episode length was variable, longer episodes would get better rewards for the same control law.}, long enough to proof the agent across a whole number of revolutions of the orbit\footnote{\label{footnote:whole_orbits}The episode duration has been chosen to approximately represent a whole number of revolutions to reduce the dependence of the reward due to a different initial state.}, but short enough not to drag the episode unnecessarily. Rewards are given only at the end of the episode depending on the final satellite state. The reward has three components. First, reward is higher the more the pericenter is raised. Second, there is a penalty for mass consumption to prevent the agent from over-consuming fuel, e.g. firing the thrusters in directions irrelevant to the main objective. Finally, the environment penalizes any change in the apocenter\footnote{Apocenter is the furthest point of the orbit from the Earth.} radius. This penalty effectively enforces a soft constraint in the problem\footnote{This is a soft constraint because the agent could potentially learn to violate it if the overall reward is greater than the penalty due to the constraint. In practice, the optimum solution to the problem under study does not compromise the constraint that way.}.

\begin{table*}[!t]
% increase table row spacing, adjust to taste
\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
\caption{Parameters Used in the Environment}
\label{table:environment}
\centering
% Some packages, such as MDW tools, offer better commands for making tables
% than the plain LaTeX2e tabular which is used here.
\begin{tabular}{clrl}
\cline{2-4}
& Magnitude & Value & Units \\
\hline
\multirow{4}{*}{\shortstack{Dynamical parameters \\ for training}}
& Earth gravity field & Point mass & \\
& Third bodies & None & \\
& Solar radiation pressure & None & \\
& Thruster error & None & \\
\hline
\multirow{4}{*}{\shortstack{Dynamical parameters \\ for evaluation}}
& Earth gravity field & Spherical, $16$x$16$ & \\
& Third bodies & Sun and Moon & \\
& Solar radiation pressure & Yes & \\
& Thruster error & N(0, 10) & $\lbrack \% \rbrack$ \\
\hline
\multirow{4}{*}{\shortstack{Numerical \\ integration}}
& Method & Dormand-Prince & \\
& Order & $8$ ($5$, $3$) & \\
& Step size & $\lbrack 1, 1000\rbrack$ & $\lbrack s\rbrack$ (adaptative)\\
& Maximum position error & $1$ & $\lbrack m\rbrack$ \\
\hline
\multirow{8}{*}{\shortstack{Initial \\ state vector}}
& $t_0$ & 2022-06-16 00:00:00 & $\lbrack$UTC$\rbrack$ \\
& $r_{a_0}$ & $11000$ & $\lbrack km\rbrack$ \\
& $r_{p_0}$ & $9000$ & $\lbrack km\rbrack$ \\
& $i_0$ & $\pi/3$ & $\lbrack rad\rbrack$ \\
& $\Omega_0$ & $2\pi/3$ & $\lbrack rad\rbrack$ \\
& $\omega_0$ & $4\pi/3$ & $\lbrack rad\rbrack$ \\
& $M_0$ & $U(0 , 2\pi)$ & $\lbrack rad\rbrack$ \\
& $m_0$ & $100$ & $\lbrack kg\rbrack$ \\
\hline
\multirow{4}{*}{\shortstack{Satellite \\ parameters}}
& $F_{max}$ & $10$ & $\lbrack mN\rbrack$ \\
& $I_s$ & $4000$ & $\lbrack s\rbrack$ \\
& Area & $1$ & $\lbrack m^2\rbrack$ \\
& Reflection coef. & 2 & $\lbrack -\rbrack$ \\
\hline
\multirow{5}{*}{\shortstack{Scenario \\ parameters}}
& $\Delta t$ & $5$ & $\lbrack min\rbrack$ \\
& $N$ & $166$ & $\lbrack$steps$\rbrack$ $(\sim 5$ orbits$)$\\
& $W_{m}$ & $0.1$ & $\lbrack km^{-1}\rbrack $ \\
& $W_{r_a}$ & $0.1$ & $\lbrack km^{-1}\rbrack $ \\
& $W_{r_p}$ & $20$ & $\lbrack kg^{-1}\rbrack $ \\
\hline
\end{tabular}
\end{table*}

The main goal of this study is to analyse the behaviour of a dynamics-agnostic agent acting in that environment. In order to achieve that, one of the main points to avoid is for the environment to leak any kind of dynamic-related information to the agent, either explicit in the data themselves or implicit in the data representation. The interaction between the environment and the agent is performed through three channels: observations, actions and rewards.

Each observation contains the full state vector of the satellite: eight magnitudes representing time, position ($3$), velocity ($3$) and mass. Time (or rather elapsed time) was included following the results of \cite{pardo2018time} to prevent the violation of the Markov property. The position and velocity are expressed in GCRF in Cartesian coordinates. Using any other type of coordinates traditionally used in orbital dynamics, such as Keplerian elements or spherical coordinates, would give the agent some unintended knowledge of the dynamics of the problem. Finally, observations are normalised in the range $[-1, 1]$ using characteristic magnitudes of the problem, that is, total episode duration, maximum expected distance, maximum expected velocity, and initial mass.

The action consists of three magnitudes representing the normalised force (in the interval $[-1, 1]$) performed by each of the three pairs of thrusters of the satellite. As mentioned before, the orientation of the satellite is assumed constant in an inertial frame, and each pair of thrusters is installed parallel to each of the main directions of GCRF. This frame is not aligned with any relevant direction for the problem dynamics nor the orbit of the satellite.

The reward is one for the whole duration of each episode. The single reward is provided after the last action of the episode is performed. No intermediate or partial rewards are given to prevent biasing the learning of the agent towards those checkpoints. Note that, when computing the reward, there is no \emph{ground truth} to compare against; instead, the reward is given depending purely on the fulfillment of the objectives, the larger the better those objectives are achieved. The reward is computed as shown in Equation \ref{equation:reward}. Such a function rewards any increment of the pericenter radius, while penalises any change in the apocenter radius and any mass consumption. The weights $W_i$ for each component can be seen in Table \ref{table:environment} and have been selected to describe a trade off between pericenter raising and mass consumption, while keeping the reward value in a unitary order of magnitude.

\begin{equation}
\label{equation:reward}
R_i = 
\begin{cases}
0, & i \neq N \\
W_{r_p}\Delta r_{p} - W_{r_a} \abs{\Delta r_{a}} + W_m \Delta m, & i = N \\
\end{cases}
\end{equation}

For the purpose of this study, a simulator has been developed to interact with the agent. The simulator consists of an orbit propagator that integrates numerically the trajectory that the satellite would have had if it performed the selected actions. The simulator has been developed in Python using the Java-based orbital mechanics library \emph{Orekit} \cite{maisonobe2010orekit}. The environment has been chosen to follow \emph{OpenAI}'s \emph{Gym} specification \cite{brockman2016openai}, which allows the use of standard libraries and eases the possibility for other researchers to reuse it. The environment's source code and installation instructions have been published in \emph{GitHub}\footnote{\url{https://github.com/zampanteymedio/gym-satellite-trajectory}}.

\subsection{Agent}

The election of the agent is of the utmost importance for the resolution of the problem. This study assumes that the agent does not have any prior knowledge, implicit or explicit, of the dynamics of the problem or the shape of the reward. Therefore, the chosen actor must follow a model-free pattern, also called trial-and-error algorithms.

In the last few years, there has been a great development of different model-free algorithms to improve both the obtained solution and the time necessary to reach it. Those algorithms are divided in two groups: \emph{policy-based algorithms} seek to directly obtain and refine an optimum guidance law, whereas \emph{value-based} algorithms go after an understanding of the future rewards (or accumulated reward) at each possible observation after each possible action has been taken.

The selected algorithm is the \emph{Advantage Actor Critic} (A2C), a synchronous variant of the \emph{Asynchronous Advantage Actor Critic} (A3C) algorithm \cite{mnih2016asynchronous}. It leverages the benefits of both policy-based and value-based algorithms by estimating two functions on each step: one for the policy (actor) and one for the value (critic). On top of that, it supports continuous observation spaces and continuous actions, necessary for acting in the environment under study.

\begin{figure*}[!t]
\centering
\subfloat[]{\includegraphics[width=2.5in]{figures/a2c}%
\label{figure:a2cenv}}
\hfil
\subfloat[]{\includegraphics[width=2.5in]{figures/a2cnn}%
\label{figure:a2cnn}}
\caption{A2C agent.}
\label{figure:a2c}
\end{figure*}

% \begin{figure}[hbt!]

% \begin{subfigure}{0.49\textwidth}
% \includegraphics[width=0.9\linewidth]{figures/a2c} 
% \caption{A2C agent and the environment.}
% \label{figure:a2cenv}
% \end{subfigure}
% %
% \begin{subfigure}{0.49\textwidth}
% \includegraphics[width=0.9\linewidth]{figures/a2cnn}
% \caption{Neural network estimators for the A2C agent.}
% \label{figure:a2cnn}
% \end{subfigure}

% \caption{A2C agent.}
% \label{figure:a2c}
% \end{figure}

For the purposes of this study, both actor and critic estimators have been modeled as fully-connected neural networks with 8 nodes in the input layer (observations) and one hidden layer with 200 nodes, as represented in Figure \ref{figure:a2cnn}. As showed in \cite{hornik1991approximation}, this configuration of feed-forward neural network is a universal approximator that can learn continuous mappings over compact input sets.

The activation function for the hidden layer is \emph{leaky ReLU}. It introduces non-linearities in the network and it prevents zones with zero slope, which could kill the training process. For the actor estimator, the output layer has three nodes (one per action dimension) with a \emph{tanh} activation function. This choice normalizes the actions in the interval $[-1, 1]$, as the environment requires. For the critic estimator, the output layer has one node with a linear activation function to keep it unbounded. Although \emph{A2C} allows for some of the hidden layers to be shared between the actor and the critic estimators, that capability was not considered necessary in this study due to the simple nature of the problem under study.

Due to the particular reward pattern of the environment, the discount factor of the agent has been set to $1$. This value prevents the reward obtained in the last episode from fading when accounting for it in the early steps of the episode. The learning rate has been adjusted after a manual exploration to be large enough to reduce the computation time and small enough to be able to refine the solution around the found minimum. The chosen algorithm to optimise the parameters of the neural networks is the Adam optimiser, due to its good general behaviour for this kind of problems. Other relevant parameters for the A2C agent are specified in Table \ref{table:a2c}.

The \emph{A2C} algorithm has been implemented using \emph{PyTorch} and the open-source library stable-baselines3 \cite{stable-baselines3}. As a proven solution widely chosen by the research community, using it reduces the probability of bugs and boosts the development speed. That allows the researcher to focus on the problem to solve and not on the algorithm used to solve it. All the code used for this study is published in \emph{GitHub}\footnote{\url{https://github.com/zampanteymedio/phd-satellite-trajectory-public}}.

\section{Results}

\subsection{Training Process}

Table \ref{table:a2c} shows the selected agent parameters after the parameter tuning exercise. On the one hand, some parameters have been pre-selected based on the unique characteristics of the problem. The discount factor $\gamma$ has been set to $1$ so that the steps at the beginning of the episode do not lose the information about the reward provided at the end. On the other hand, other parameters have been set after performing a manual exploration. The number of nodes in the hidden layer has been set to 200 as a compromise between computation speed, training speed and quality of the solution. Higher number of nodes only provides a marginal gain, whereas a lower number of nodes degrades the quality of the solution and requires a higher number of steps to reach the solution\footnote{An agent with a hidden layer of only 10 nodes eventually learns a fairly good behaviour after more than 2 million steps.}. The learning rate $\alpha$ has been set to $10^{-3}$, since higher rates lead to instability and lower rates just slow down the convergence.

\begin{table}[!t]
% increase table row spacing, adjust to taste
\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
\caption{Parameters Used in the Environment}
\label{table:a2c}
\centering
% Some packages, such as MDW tools, offer better commands for making tables
% than the plain LaTeX2e tabular which is used here.
\begin{tabular}{cll}
\cline{2-3}
& Parameter & Value \\
\hline
\multirow{3}{*}{A2C parameters}
& $\gamma$ & $1.0$ \\
& $\alpha$ & $10^{-3}$ \\
& optimizer & Adam \\
\hline
\multirow{3}{*}{Actor network}
& nodes in hidden layer & $200$ \\
& act. fun. in hidden layer & leaky ReLU \\
& act. fun. in output & tanh \\
& distribution for output & diagonal Gaussian \\
\hline
\multirow{3}{*}{Critic network}
& nodes in hidden layer & $200$ \\
& act. fun. in hidden layer & leaky ReLU \\
& act. fun. in output & linear \\
\hline
\multirow{1}{*}{Learning parameters}
& number of training steps & $5 \cdot 10^5$ \\
\hline
\end{tabular}
\end{table}

% \begin{table}[hbt!]
% \centering
% \resizebox{\textwidth}{!}{%
% }
% \caption{\label{table:a2c} A2C agent parameters and values used for training.}
% \end{table}

In order to reduce the uncertainty due to random behaviours typically associated with AI models, 14 agents with different random seeds have been trained. The rewards obtained by the evaluation of the agents mid-training are shown in Figure \ref{figure:training}\footnote{After every 5 training episodes, the agent is evaluated using a new episode and the reward is obtained and plotted. This evaluation episode is not used for training purposes.}. There is a first phase before $10^5$ steps where agents are in an exploration phase and are able to learn how to increase the reward. Beyond $10^5$ steps, agents stop learning and only replay solutions very close to the optimal policy. After $5 \cdot 10^5$ steps, all the agents arrive to a similar solution very close to the best ever achieved\footnote{The best reward ever achieved by any agent is $1.68$. This corresponds to an increase of the pericenter radius of $24.0 km$ using $35 g$ of fuel and with a deviation of $0.2km$ of the apocenter radius.}. Although increasing the number of steps could bring that final agent all the way up to the best ever achieved solution, the gain of doing so would be marginal and the computational cost excessive.

\begin{figure}[!t]
\centering
\includegraphics[width=2.5in]{figures/training}
\caption{Evaluation during training for 14 agents.}
\label{figure:training}
\end{figure}

\subsection{Planned Trajectory}

After the training exercise, the best solution ever achieved by any agent has been selected and used to generate a trajectory in an environment without perturbations. As Figure \ref{figure:planned} shows, the apocenter radius stays controlled around the initial value while the pericenter radius monotonically increases. Given that thrusters are constantly firing in all directions, mass decreases over time.

\begin{figure*}[!t]
\centering
\subfloat[]{\includegraphics[width=2.5in]{figures/plan_ra}%
\label{figure:planned_ra}}
\hfil
\subfloat[]{\includegraphics[width=2.5in]{figures/plan_rp}%
\label{figure:planned_rp}}
\hfil
\subfloat[]{\includegraphics[width=2.5in]{figures/plan_m}%
\label{figure:planned_mass}}
\hfil
\subfloat[]{\includegraphics[width=2.5in]{figures/plan_action}%
\label{figure:planned_action}}
\caption{Trajectory planned by the selected agent.}
\label{figure:planned}
\end{figure*}

Figure \ref{figure:planned_action} shows the actions taken by the agent along the episode. Since an episode consists of five full orbits\footnote{See footnote \ref{footnote:whole_orbits}.}, the agent applies five times a similar thrusting pattern. During each orbit, one of the thrusters is constantly firing nearly at full force in one direction, while the other two alternate magnitude and direction in different moments of the orbit. Although this solution naturally appears as the control commanded by the trained agent, it is very challenging to model this kind of patterns with a full analytic or parametric law, bringing out the power of \emph{Reinforcement Learning} compared to traditional methods.

\subsection{Performance during Cruise}

The final step on the evaluation of the agent is to assess its performance if used as a satellite controller in real time, in an environment that contains small perturbations with respect to the one the agent trained in. The dynamical model of the new environment considers the perturbations described in Table \ref{table:environment}: a non-spherical Earth, solar radiation pressure, and Sun and Moon gravity forces. On top of that, the thrusters of the satellite have a random mis-performance.

\begin{figure*}[!t]
\centering
\subfloat[]{\includegraphics[width=2.5in]{figures/real_ra}%
\label{figure:real_ra}}
\hfil
\subfloat[]{\includegraphics[width=2.5in]{figures/real_rp}%
\label{figure:real_rp}}
\hfil
\subfloat[]{\includegraphics[width=2.5in]{figures/real_m}%
\label{figure:real_mass}}
\hfil
\subfloat[]{\includegraphics[width=2.5in]{figures/real_action}%
\label{figure:real_action}}
\caption{Trajectory achieved by the selected agent on an environment with perturbations.}
\label{figure:real}
\end{figure*}

Figure \ref{figure:real} shows the variation of the relevant parameters of the trajectory of the satellite. When plotting the osculating pericenter and apocenter radii\footnote{Due to the new forces in the environment, the orbital elements representing the instant (osculating) pericenter and apocenter radii are not constant even in absence of thrust. Instead, they periodically change along the orbit.}, it can be seen that the trend of those elements remains the same: apocenter radius remains stable while pericenter radius increases. Moreover, the increase rate is in line with the planned figure. Therefore, the agent is performing as planned in an environment even if it was not exactly the same environment used for training, opening the possibility to be used as a real-time on-board controller. This also shows that simplified environments can be considered during training as long as they capture the main characteristics of the real environment, reducing the total computation time.

\section{Discussion}

This study demonstrates that \emph{Reinforcement Learning} is a valid tool for the optimisation of the trajectory of satellites equipped with a low-thrust propulsion system. It also proves that an \emph{a priori} knowledge of the dynamics of the problem or an intuition of the optimum are not necessary for an agent to learn an optimal control law.

The guidance law produced by a trained agent appears naturally as a result of its training. Nevertheless, it would have been very challenging to model this kind of guidance with a full analytic or parametric law, bringing out the power of \emph{Reinforcement Learning} compared to traditional methods.

The simplicity of the approach described in this study is in clear opposition to all the studies performed so far. Most of the other methods using traditional optimization or \emph{Artificial Intelligence} share the need to have a strong knowledge of the problem, its optimal solution or a ground truth, such as a previously-generated optimal set of actions or a reference trajectory. This defeats the purpose of using \emph{Artificial Intelligence} because the agent will just replicate that ground truth without challenging its purpose and without trying to find better ways to achieve the wanted result. Moreover, that blind faith of the agent in the ground truth could lead to unexpected situations like fuel over-consumption due to the desire to follow a non-physically-feasible reference trajectory.

This study focuses on solving the problem in question using the simple original needs: increase of the pericenter radius and minimizing the fuel consumption, while keeping the apocenter radius constant. No previous data are required to solve the constrained optimization problem since the agent generates its own data from the environment during training and it autonomously learns what the best approach to achieve the original needs is. During the control phase, the agent does not blindly follow the planned trajectory; instead, it adapts the trajectory keeping the original needs in mind.

In order to create, train and use the agent described in this study, there is no need to have a deep understanding in maths or space dynamics. On top of that, the analysis has been performed using open-source tools and no expensive computational resources. This effectively broadens the profile of researchers and engineers that can work on the field of satellite trajectory optimization and reduces the costs associated to satellite control.

On the other hand, totally ignoring the knowledge on the dynamics of the problem is a too radical approach. This knowledge could potentially be used by future studies or operational systems to shape the agent and make it learn faster, better and in a more general set of scenarios. In the case under study, the use of Keplerian elements as input parameters would seem like the obvious choice, since they contain most of the information about the dynamics of the problem. Nevertheless, this kind of decisions needs to be assessed with care: a bias preventing the agent from exploring freely could be introduced, resulting in a sub-optimal solution.

Finally, this study proves that the same agent used to obtain the planned trajectory can be used to autonomously control the propulsion system in real-time, further reducing the operational costs of the satellite. Although preliminary results are very positive, this approach still needs to be tested thoroughly before it can be used operationally due to the high value at risk inherent to the space sector: overusing on-board resources or even losing the satellite.

\section{Conclusion}

This study demonstrates that \emph{Reinforcement Learning} is a promising method for satellite trajectory optimization. It has been shown that it is not strictly necessary to know the dynamics of the problem or an \emph{a priori} solution in order for a trained agent to learn a quasi-optimal thrusting law. It has also been presented how such a trained agent can be used to both plan a trajectory and to control the satellite along that trajectory in real time, even when unforeseen perturbations occur. This has been achieved using an agent with a surprisingly low number of parameters, well far from the millions of parameters used in other areas such as artificial vision or speech recognition, which leads to think that a similar approach could be used for more complex scenarios without a great increment of the needed computational power.

There are a few aspects of the study that could lead to better solutions or faster training times before the proposed approach is used operationally. For example, a more exhaustive hyper-parameter tuning campaign, other neural network configurations or alternative \emph{Reinforcement Learning} algorithms could be analysed.

Overall, this study opens the door to using \emph{Reinforcement Learning} to more complicated problems where it is very challenging to describe an optimal solution analytically, such as interplanetary flight arcs, or environments with non-Keplerian dynamics like Lagrangian points or around a comet. This approach could also be used to explore new strategies in other areas where solutions have room for improvement, such as collision avoidance, geostationary satellite co-location or multi-satellite formation.


% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.




% \section{Conclusion}
% The conclusion goes here.





\appendix[Nomenclature]

\begin{tabular}{ll}
$A_i$ & action taken by the agent at step $i$ \\
$F_{max}$ & maximum force of each thruster \\
$i$ & inclination \\
$I_s$ & specific impulse of the thrusters \\
$m_i$ & mass of the satellite at step $i$\\
$M$ & mean anomaly \\
$N$ & number of steps per episode \\
$r_a$ & apocenter radius \\
$R_i$ & \makecell[l]{reward given by the environment after the \\ ~~~~action at step $i$} \\
$r_p$ & pericenter radius \\
$S_i$ & \makecell[l]{observation representing the state of the \\ ~~~~environment at step $i$ } \\
$W_i$ & weight in the reward function for feature $i$ \\
$\alpha$ & learning rate of the agent \\
$\Delta t$ & duration of environment simulation step\\
$\gamma$ & discount factor used by the agent \\
$\Omega$ & right ascension of ascending node \\
$\omega$ & argument of pericenter
\end{tabular}

% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%


% \appendices
% \section{Proof of the First Zonklar Equation}
% Appendix one text goes here.

% you can choose not to have a title for an appendix
% if you want by leaving the argument blank
% \section{}
% Appendix two text goes here.


% use section* for acknowledgment
% \section*{Acknowledgment}


% The authors would like to thank...


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\bibliography{main}
% \begin{thebibliography}{1}

% \bibitem{IEEEhowto:kopka}
% H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%   0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

% \end{thebibliography}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

%%%%%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{figures/ccasas}}]{Carlos M. Casas} received a M.Sc. on aerospace engineering in 2006 and a M.Sc. on computer engineering in 2013. He worked as a consultant for the European Space Agency on the interplanetary trajectory optimization team. He also worked as a software development engineer at Amazon. He is currently a Ph.D. student in the Universidad de Valladolid researching about the applicability of machine learning and artificial intelligence techniques for satellite flight dynamics.
%%%%%\end{IEEEbiography}

% if you will not have a photo at all:
%%%%%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{figures/bcarro}}]{Belén Carro} received a Ph.D. degree in the field of broadband access networks from the Universidad de Valladolid, Spain, in 2001. She is Professor and Director of the Communications Systems and Networks (SRC) laboratory at Universidad de Valladolid, working as Research Manager in NGN communications and services, VoIP/QoS and machine learning. She has supervised a dozen Ph.D. students and has extensive research publications experience, as author, reviewer and editor.
%%%%%\end{IEEEbiography}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

%%%%%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{figures/asanchez}}]{Antonio Sánchez-Esguevillas} received a Ph.D. degree in 2004. He has managed innovation at Telefonica, has been Adjunct Professor and Honorary Collaborator at the University of Valladolid, supervising several Ph.D. students. He has coordinated very large international R\&D projects, has over 50 international publications and several patents. His current research interest focuses on artificial intelligence.
%%%%%\end{IEEEbiography}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}
