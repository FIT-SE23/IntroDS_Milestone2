\begin{abstract}
This paper proposes a probabilistic deep metric learning (PDML) framework for hyperspectral image classification, which aims to predict the category of each pixel for an image captured by hyperspectral sensors.
The core problem for hyperspectral image classification is the spectral variability between intraclass materials and the spectral similarity between interclass materials, motivating the further incorporation of spatial information to differentiate a pixel based on its surrounding patch.
However, different pixels and even the same pixel in one patch might not encode the same material due to the low spatial resolution of most hyperspectral sensors, leading to an inconsistent judgment of a specific pixel. 
To address this issue, we propose a probabilistic deep metric learning framework to model the categorical uncertainty of the spectral distribution of an observed pixel. 
We propose to learn a global probabilistic distribution for each pixel in the patch and a probabilistic metric to model the distance between distributions.
We treat each pixel in a patch as a training sample, enabling us to exploit more information from the patch compared with conventional methods.
Our framework can be readily applied to existing hyperspectral image classification methods with various network architectures and loss functions. 
Extensive experiments on four widely used datasets including IN, UP, KSC, and Houston 2013 datasets demonstrate that our framework improves the performance of existing methods and further achieves the state of the art. 
Code is available at: \url{https://github.com/wzzheng/PDML}.
\end{abstract}