%%%%%%%%%%%%%%%%% Models used for results %%%%%%%%%%%%%%%%%%
%% Autoencoder: 20220611-203103365077
%% Equivalent expression: 20220611-170824504558
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experiments}
We consider two models for our experiments:
\begin{itemize}
    \itemsep0em
    \item \expembe{} is the model trained on disparate but mathematically equivalent expression pairs.
    \item \expemba{} refers to an autoencoder that is trained to generate the same expression as the input.
\end{itemize}
While the focus of this work is to demonstrate the efficacy of \expembe{}, the autoencoder approach serves as an important contrast, demonstrating that \expembe{} yields representations that better describe \textit{semantics} and are superior for clustering, retrieval, and analogy tasks. We use the model shown in Figure \ref{fig:model_architecture} for our experiments.

% In this section, we conduct a series of experiemnts that demonstrate the following qualities of our approach: 
% \begin{enumerate}
%     \item \expemba{} learns to generate the input expression exactly
%     \item \expembe{} learns to generate an expression that is mathematically equivalent to the input expression. The intent behind this experiment is to establish that \expemba{} and \expembe{} perform well on their original tasks.
% \end{enumerate}

%The overall purpose of these experiments is to 

%In this section, we present the results of our experiments on \expemba{} and \expembe{}. For our experiments, we use the Equivalent Expressions Dataset and the datasets introduced by \citet{allamanisLearningContinuousSemantic2017}. The latter is referred to as the \semvec{} datasets hereafter. The datasets are discussed in detail in section \ref{sec:datasets}. We perform quantitative and qualitative evaluations on our models. We first show that for a given input expression (1) \expemba{} learns to generate the input expression exactly and (2) \expembe{} learns to generate an expression that is mathematically equivalent to the input expression. The intent behind this experiment is to establish that \expemba{} and \expembe{} perform well on their original tasks. For this experiment, we use the Equivalent Expressions Dataset. For the next experiment, we use the \semvec{} datasets. The objective of this experiment is to analyze the semantic properties of representations generated by \expemba{} and \expembe{} encoders. The results of these experiments are discussed in section \ref{sec:quant_results}. Furthermore, we plot and compare the vector representations generated by \expemba{} and \expembe{}. We use these representations to find five closest expressions to a given test expression. We also perform embedding algebra on the representations generated by models trained in both of these settings. We use the Equivalent Expressions Dataset for these experiments and discuss the results in section \ref{sec:qual_results}.

% \subsection{Datasets}
% \label{sec:datasets}

% \paragraph{\semvec{} Datasets.}
% Published in \citet{allamanis2017learning}, these datasets contain equivalent expressions from the boolean (\textsc{Bool}) and polynomial (\textsc{Poly}) domains. In these datasets, a class is defined by an expression and all the equivalent expressions belong to the same class. The datasets are split into training, validation, and test sets and contain two test sets: (1) \textsc{SeenEqClass} containing classes that are present in the training set (2) \textsc{UnseenEqClass} containing classes that are not present in the training set. To transform the training set into the input-output format used by \expembe{}, we generate all possible pairs for the expressions belonging to the same class. To limit the size of the generated training set, we select a maximum of 100,000 random pairs from each class. For \expemba{}, we use all the expressions present in the training set. See Appendix \ref{appendix:semvec_datasets} for details.

% \subsection{Training}
% We use the model shown in \ref{fig:model_architecture} for our training. Refer to Appendix \ref{appendix:model_arch} for dimensions of different layers in our architecture. We train \expemba{} with $H = 128$ and \expembe{} with $H = 1024$ on the Equivalent Expressions Dataset. For the \semvec{} datasets, we train both \expemba{} and \expembe{} with $H = 64, 128, 256, 512, 1024$. We use the AdamW optimizer \citep{loshchilovDecoupledWeightDecay2019} for training. See Appendix \ref{appendix:training_details} for details.

\subsection{Equivalent Expression Generation}
\label{sec:equiv_exp_gen_results}
The first objective is to show that \expembe{} can learn to generate equivalent expressions for a given input. To evaluate if two expressions $\mathbf{x}_1$ and $\mathbf{x}_2$ are mathematically equivalent, we simplify their difference $\mathbf{x}_1 - \mathbf{x}_2$ using SymPy and compare it to 0. In this setting, if the model produces an expression that is the same as the input, we do not count it as a model success. There are instances in which SymPy takes significant time to simplify an expression and eventually fails with out-of-memory errors. To handle these cases, we put a threshold on its execution time. If the simplification operation takes more time than the threshold, we count it as a model failure. We also evaluate \expemba{} and verify that it learns to generate the input exactly. This serves as an important contrast to \expembe{} and is useful in understanding how well a sequence-to-sequence model understands the mathematical structure. During the evaluation, we use the beam search algorithm to generate output expressions. As an output can be verified programmatically, we consider all the outputs in the beam. If any of the outputs are correct, we count it as a model success.

We train \expemba{} with $H = 128$ and \expembe{} with $H = 1024$ for this experiment where $H$ is the model dimension (see Appendix \ref{appendix:model}). The accuracy of these models is shown in Table \ref{tab:results_autoenc_encdec}. First, we note that \expemba{} is easily able to encode and generate the input expression and achieves a near-perfect accuracy with $H = 128$ and greedy decoding (beam size = 1). Second, the \expembe{} results demonstrate that generating equivalent expressions is a significantly harder task. For this setting, the greedy decoding does not perform well. We observe an improvement of 35\% for a beam size of 50. However, we also see a jump in the number of invalid expressions being assigned high log probabilities with this beam size. This experiment demonstrates that both \expemba{} and \expembe{} are capable of learning the mathematical structure, and \expembe{} can learn to generate expressions that are mathematically equivalent to the input expression. While \expembe{} achieves a lower accuracy than \expemba{}, we see in Section \ref{sec:qual_results} that the former exhibits some interesting properties and is more useful for retrieval tasks.

\begin{table}[]
    \centering
    \begin{tabular}{lrr}
        \toprule
        Beam Size & \expemba{} & \expembe{} \\
        \midrule
        1 & 0.9994 & 0.5188 \\
        10 & 1.0000 & 0.7736 \\
        50 & 1.0000 & 0.8666 \\
        \bottomrule
    \end{tabular}
    \caption{Accuracy of \expemba{} and \expembe{} on the datasets with expressions containing a maximum of 5 operators (sequence length $16.18 \pm 4.29$ for the training dataset).}
    \label{tab:results_autoenc_encdec}
\end{table}

\begin{figure*}[t]
    \centering
    \begin{subfigure}{0.49\textwidth}
        \centering
        \fontsize{7}{10}\selectfont
        \includesvg[scale=0.29]{img/pca_emb_plot_autoenc.svg}
        \caption{\expemba{}}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
        \centering
        \fontsize{7}{10}\selectfont
        \includesvg[scale=0.29]{img/pca_emb_plot_equiv_exp.svg}
        \caption{\expembe{}}
    \end{subfigure}
    \caption{Plots for the representations generated by \expemba{} and \expembe{}. PCA is used to reduce the dimensionality from 128 (\expemba{}) and 1024 (\expembe{}) to 2. The proposed approach, \expembe{}, groups expressions with similar operations together, whereas \expemba{} groups expressions mainly based on their structure. Interactive version of these plots are available on our \href{https://mlpgroup.github.io/expemb}{project page}.}
    \label{fig:pca_plots}
\end{figure*}

\subsection{Embedding Evaluation}
\label{sec:qual_results}
Next, we evaluate the usefulness of the representations generated by the \expembe{} model. Unlike the natural language textual embedding problem \citep{wangGLUEMultiTaskBenchmark2019}, there do not exist standard tests to quantitatively measure the embedding performance of methods built for mathematical expressions. Hence, our analysis in this section must be more qualitative in nature. These experiments show some interesting properties of the representations generated by the \expemba{} and \expembe{} models and demonstrate the efficacy of the proposed approach.

\paragraph{Embedding Plots.}
To gauge if similar expressions are clustered in the embedding vector space, we plot and compare the representations generated by the \expembe{} and \expemba{} models. For this experiment, we use 8,000 simple expressions that belong to one of the following categories: hyperbolic, trigonometric, polynomial, and logarithmic/exponential. Each expression is either polynomial or contains hyperbolic, trigonometric, or logarithmic/exponential operators. Below are a few examples of expressions belonging to each of these classes:
\begin{itemize}
    \itemsep0em
    \item Polynomial: $x^{2} + 2 x + 5$, $2 x + 2$
    \item Trigonometric: $\sin{\left(x \right)} \tan{\left(x \right)}$, $\cos^{5}{\left(4 x \right)}$
    \item Hyperbolic: $\cosh{\left(x - 4 \right)}$, $\sinh{\left(x \cos{\left(2 \right)} \right)}$
    \item Log/Exp: $e^{- 2 x - 4}$, $\log{\left(x + 3 \right)}^{3}$
\end{itemize}

We use Principal Component Analysis (PCA) for dimensionality reduction. Figure \ref{fig:pca_plots} shows the plots for \expemba{} and \expembe{}. We observe from these plots that the clusters in the \expembe{} plot are more distinguishable compared to the \expemba{} plot and \expembe{} does a better job at grouping similar expressions together. For \expembe{}, there is an overlap between expressions belonging to hyperbolic and logarithmic/exponential classes. This is expected because hyperbolic operators can be written in terms of the exponential operator. Furthermore, \expemba{} focuses on just the structure of expressions and groups together expressions that follow the same structure. For example, representations generated by \expemba{} for $x^{2} - 2 x$, $\log{\left(2 x + 5 \right)}$, $\tanh{\left(3 x + 4 \right)}$, $\atanh{\left(3 x + 4 \right)}$, $x^{2} \left(x + 5\right)$, $2 x - 5$, $\log{\left(8 - 4 x \right)}$, $4 x + 8$, and $\cos{\left(5 x + 15 \right)}$ are grouped together. On the other hand, representations generated by \expembe{} capture semantics in addition to the overall structure.

\paragraph{Distance Analysis.}
To understand the applicability of the embeddings for the information retrieval task, we perform distance analysis on a sample of 10,000 expressions. The similarity between two expressions is defined as the inverse of the cosine distance between their representations. We find the five closest expressions to a given query. Table \ref{tab:distance_analysis} shows the results of this experiment. We observe that the closest expressions computed using \expembe{} are more similar to the query in terms of the overall structure and operators. On the other hand, \expemba{} focuses on a part of the query and finds other expressions that share that particular feature. For example, the first query in Table \ref{tab:distance_analysis} consists of polynomial and trigonometric expressions. The closest expressions computed using \expembe{} follow the same structure, whereas the expressions computed using \expemba{} seem to focus on the polynomial part of the query. This behavior is also apparent in the second example. We believe that the ability of \expembe{} to group similar expressions together can prove useful in information retrieval problems where the aim is to find similar expressions to a given query. Refer to Appendix \ref{appendix:distance_analysis} for more examples.

\begin{table*}[t]
    \centering
    \begin{tabular}{l l l}
        \toprule
        Query & \expemba{} & \expembe{} \\ 
        \midrule 
        % $\cos{\left(x + 1 \right)} + \frac{1}{2}$ & 1.~$32 \tan{\left(x + 1 \right)}$ & 1.~$\frac{\sin{\left(x + 1 \right)}}{2} + \frac{3}{2}$ \\ 
        % \addlinespace[0.3em] & 2.~$6 \cos{\left(x + 1 \right)}$ & 2.~$4 x + \cos{\left(x + 1 \right)} + 3$ \\ 
        % \addlinespace[0.3em] & 3.~$\tan{\left(x + 1 \right)} + 125$ & 3.~$6 \cos{\left(x + 1 \right)}$ \\ 
        % \addlinespace[0.3em] & 4.~$\sinh{\left(x + 1 \right)} + 6$ & 4.~$\frac{4 x \cos{\left(x + 1 \right)}}{5}$ \\ 
        % \addlinespace[0.3em] & 5.~$\sqrt{x + 1} - 3$ & 5.~$\cos{\left(x + 4 \right)} + \operatorname{acos}{\left(5 \right)}$ \\

        % \midrule
        
        % $x \left(x \cos{\left(5 \right)} + \operatorname{asinh}{\left(x \right)}\right)$ & 1.~$x + \left(x + \operatorname{asinh}{\left(5 \right)}\right) \operatorname{asinh}{\left(x \right)}$ & 1.~$x \left(- x \cos{\left(x \right)} + x + \operatorname{acos}{\left(x \right)}\right)$ \\ 
        % \addlinespace[0.3em] & 2.~$x \left(x + e^{\operatorname{asinh}{\left(x \right)} + 5}\right)$ & 2.~$x \left(x + \cos{\left(2 \right)}\right) + \operatorname{asin}{\left(x \right)}$ \\ 
        % \addlinespace[0.3em] & 3.~$\sqrt{x + \tan{\left(5 \right)}} + \operatorname{asinh}{\left(x \right)}$ & 3.~$x^{2} \cos{\left(x \right)} + x + \operatorname{asin}{\left(x \right)} + 2$ \\ 
        % \addlinespace[0.3em] & 4.~$x \sin{\left(5 \right)} + x + \log{\left(x \right)}$ & 4.~$x \sin{\left(1 \right)} + 3 x + \operatorname{acosh}{\left(x \right)}$ \\ 
        % \addlinespace[0.3em] & 5.~$\left(\sqrt{2} x + 3\right) \sin{\left(x \right)}$ & 5.~$x \left(x \operatorname{asinh}{\left(3 \right)} + \cos{\left(x \right)}\right)$ \\ 
        
        % \midrule
        
        % $2 x^{2} \left(x + \operatorname{acos}{\left(2 x \right)} + 5\right)$ & 1.~$4 x^{2} \left(\sqrt{x} + 2 x + 2\right)$ & 1.~$2 x \left(6 x + \operatorname{atanh}{\left(2 x \right)} + 3\right)$ \\ 
        % \addlinespace[0.3em] & 2.~$2 x - \sin{\left(\operatorname{asinh}{\left(x \right)} \right)} + 5$ & 2.~$\left(x + 3\right) \left(x + \operatorname{asin}{\left(2 x \right)} + 1\right)$ \\ 
        % \addlinespace[0.3em] & 3.~$2 x + \cos{\left(x \right)} + \tan{\left(2 x \right)} + 3$ & 3.~$x^{2} \left(\operatorname{asinh}{\left(2 x \right)} + 2\right)$ \\ 
        % \addlinespace[0.3em] & 4.~$x \operatorname{asin}{\left(2 x \right)} + 2 x + 3$ & 4.~$x \left(2 x + \operatorname{atanh}{\left(2 x \right)} - 1\right)$ \\ 
        % \addlinespace[0.3em] & 5.~$\frac{\sqrt{x} + 2 x - 5}{x^{4}}$ & 5.~$x \left(x + \sinh{\left(2 x \right)} + 4\right) + x$ \\ 

        % \midrule
        
        $21 x - 3 \sin{\left(x \right)}$ & 1.~$11 x - 2 e^{x}$ & 1.~$52 x + 4 \sin{\left(x \right)}$ \\ 
        \addlinespace[0.3em] & 2.~$2 x + \operatorname{acosh}{\left(11 x \right)}$ & 2.~$75 x + 25 \sin{\left(x \right)}$ \\ 
        \addlinespace[0.3em] & 3.~$- x + e^{11 x}$ & 3.~$257 x + 256 \cos{\left(x \right)}$ \\ 
        \addlinespace[0.3em] & 4.~$x e^{- 21 x}$ & 4.~$7 x - 7 \sin{\left(x \right)}$ \\ 
        \addlinespace[0.3em] & 5.~$\sin{\left(\operatorname{asinh}{\left(x + 21 \right)} \right)}$ & 5.~$7 x - \tan{\left(4 \right)}$ \\ 
        
        \midrule
        
        $\frac{3 x}{4} + \cos{\left(x \right)} + 9$ & 1.~$2 x \left(\frac{5 x}{4} + \cos{\left(x \right)}\right)$ & 1.~$\frac{x}{25} + \cos{\left(x \right)} + 2$ \\ 
        \addlinespace[0.3em] & 2.~$\left(\frac{x}{4} - 1\right) \cos{\left(x \right)}$ & 2.~$3 x + \cos{\left(x \right)} + \frac{5}{4}$ \\ 
        \addlinespace[0.3em] & 3.~$24 x + \cos{\left(x \right)} + 3$ & 3.~$- x + \cos{\left(x \right)} + 7$ \\ 
        \addlinespace[0.3em] & 4.~$\cos{\left(x \right)} + 3 \tan{\left(\frac{x}{3} \right)}$ & 4.~$6 x + \cos{\left(x \right)} + 17$ \\ 
        \addlinespace[0.3em] & 5.~$x \left(2 x + 7\right) \cos{\left(x \right)}$ & 5.~$3 x + \cos{\left(x \right)} + 12$ \\ 

        \bottomrule
    \end{tabular}
    \caption{Expressions closest to a given query computed using representations generated by \expemba{} and \expembe{} models. It is evident that \expembe{} does a better job at learning the semantics and overall structure of the expressions than \expemba{}.}
    \label{tab:distance_analysis}
\end{table*}

\begin{table*}[t]
    \centering
    \begin{tabular}{llllll}
        \toprule
        $\mathbf{x}_1$ & $\mathbf{y}_1$ & $\mathbf{y}_2$ & $\mathbf{x}_2$ (expected) & \expemba{} & \expembe{} \\
        \midrule
        $\cos(x)$ & $\sin(x)$ & $\csc(x)$ & $\sec(x)$ & $\cosh^{-1}(x)$ & $\sec(x)$ \\
        $\sin(x)$ & $\cos(x)$ & $\cosh(x)$ & $\sinh(x)$ & $ex$ & $\sinh(x)$ \\
        $\sin(x)$ & $\csc(x)$ & $\sec(x)$ & $\cos(x)$ & $\cos(x)$ & $\cos(x)$ \\
        $x^2 - 1$ & $x + 1$ & $x + 2$ & $x^2 - 4$ & $\frac{x}{\log(x)^2}$ & $x^2 - 4$ \\
        $x^2 - 1$ & $x + 1$ & $2x + 2$ & $4x^2 - 4$ & $\log(x^{\frac{3}{22}})$ & $x^2 - 4$ \\
        $\sin(x)$ & $\sinh(x)$ & $\cosh(x)$ & $\cos(x)$ & $\pi x$ & $\cosh(\sinh(x))$ \\
        $x^2$ & $x$ & $\sin(x)$ & $\sin^{2}(x)$ & $10 x^2$ & $x^2 \sin(x)$ \\
        \bottomrule
    \end{tabular}
    \caption{Examples of embedding algebra on the representations generated by \expemba{} and \expembe{}. \expembe{} gets the first four analogies correct and generates reasonably close outputs for the remaining compared to \expemba{}.}
    \label{tab:emb_algebra}
\end{table*}


\paragraph{Embedding Algebra.}
Word representations generated by methods like word2vec \citep{mikolovEfficientEstimationWord2013} and GloVe \citep{penningtonGloVeGlobalVectors2014} exhibit an interesting property that simple algebraic operations on the representations can be used to solve analogies of the form ``$\mathbf{x}_1$ is to $\mathbf{y}_1$ as $\mathbf{x}_2$ is to $\mathbf{y}_2$''.  Following along the same lines, we perform simple algebraic operations on the representations generated by our model. For a given triplet of expressions $\mathbf{x}_1$, $\mathbf{y}_1$, and $\mathbf{y}_2$, we compute $\mathbf{z} = \textrm{emb}(\mathbf{x}_1) - \textrm{emb}(\mathbf{y}_1) + \textrm{emb}(\mathbf{y}_2)$ and find the expression with representation closest to $\mathbf{z}$ in terms of cosine similarity. Here, $\mathrm{emb}$ represents a function that returns the vector representation for an input expression. For this experiment, we use the entire training set and ensure that all the expressions required for an analogy are present in this set. Table \ref{tab:emb_algebra} shows the results for \expemba{} and \expembe{}. It is interesting that \expembe{} works for the first four examples and returns the expected expressions. This demonstrates a degree of semantic learning. Unsurprisingly, \expemba{} performs very poorly on this task, demonstrating the value of the \expembe{} approach. There are cases for which neither \expembe{} nor \expemba{} generates the expected output, but even in these cases, the \expemba{} results are very poor compared to \expembe{}. \textit{Overall, the results of this analysis further bolster the efficacy of the \expembe{} embedding approach.}

\begin{table*}[t]
    \centering
    \begin{tabular}{lrrrrrr}
        \toprule
        Dataset & \eqnet{} & \eqnetl{} & \multicolumn{2}{c}{\expemba{}} & \multicolumn{2}{c}{\expembe{}} \\
        & $score_5(\%)$ & $score_5(\%)$ & $score_5(\%)$ & $H$ & $score_5(\%)$ & $H$ \\
        \midrule
        \textsc{SimpBool8} & 97.4 & - & 27.1 & 1024 & 99.5 & 1024 \\
        \textsc{SimpBool10} & 99.1 & - & 16.3 & 128 & 80.9 & 256 \\
        \textsc{Bool5} & 65.8 & 73.7 & 25.1 & 256 & 57.1 & 64 \\
        \textsc{Bool8} & 58.1 & - & 22.5 & 512 & 100.0 & 1024 \\
        \textsc{Bool10} & 71.4 & - & 4.6 & 1024 & 77.5 & 1024 \\
        \textsc{SimpBoolL5} & 85.0 & 72.1 & 28.5 & 64 & 79.7 & 128 \\
        \textsc{BoolL5} & 75.2 & - & 15.5 & 1024 & 70.4 & 256 \\
        \textsc{SimpPoly5} & 65.6 & 56.3 & 12.5 & 256 & 31.2 & 1024 \\
        \textsc{SimpPoly8} & 98.9 & 98.0 & 31.3 & 64 & 97.2 & 256 \\
        \textsc{SimpPoly10} & 99.3 & - & 28.7 & 1024 & 100.0 & 256 \\
        \textsc{oneV-Poly10} & 81.3 & 80.0 & 55.8 & 1024 & 75.5 & 1024 \\
        \textsc{oneV-Poly13} & 90.4 & - & 28.2 & 128 & 99.7 & 512 \\
        \textsc{Poly5} & 55.3 & - & 22.0 & 1024 & 48.1 & 128 \\
        \textsc{Poly8} & 86.2 & 87.1 & 19.8 & 512 & 76.6 & 512 \\
        \bottomrule
    \end{tabular}
    \caption{$score_5(\%)$ for \textsc{UnseenEqClass} of the \textsc{SemVec} datasets. The scores for \eqnet{} and \eqnetl{} are from their published work \citep{allamanis2017learning, liu2022eqnet}. For \expemba{} and \expembe{}, the best scores and the corresponding model dimensions $H$ are shown.}
    \label{tab:semvec_comparison}
\end{table*}

\subsection{Comparison with Existing Methods}
As discussed in Section \ref{sec:related}, prior works have examined if machine learning models can generate semantic representations for equivalent expressions. This historical perspective serves as an established evaluation of if \expemba{} and \expembe{} encoders learn to generate representations \textit{that capture semantics and not just the syntactic structure}. This property is measured as the proportion of $k$ nearest neighbors of each test expression that belong to the same class \citep{allamanis2017learning}. For a test expression $q$ belonging to a class $c$, the score is defined as
\begin{equation}
    score_k(q) = \frac{| \mathbb{N}_k(q) \cap c |}{\textrm{min}(k, |c|)}
\end{equation}
where $\mathbb{N}_k(q)$ represents $k$ nearest neighbors of $q$ based on cosine similarity.

We use the datasets published by \citet{allamanis2017learning} for this evaluation. These datasets contain equivalent expressions from the Boolean (\textsc{Bool}) and polynomial (\textsc{Poly}) domains. In these datasets, a class is defined by an expression, and all the equivalent expressions belong to the same class. The datasets are split into training, validation, and test sets and contain two test sets: (1) \textsc{SeenEqClass} containing classes that are present in the training set, and (2) \textsc{UnseenEqClass} containing classes that are not present in the training set. To transform the training set into the input-output format used by \expembe{}, we generate all possible pairs for the expressions belonging to the same class. To limit the size of the generated training set, we select a maximum of 100,000 random pairs from each class. For \expemba{}, we use all the expressions present in the training set. See Appendix \ref{appendix:semvec_datasets} for the dataset details.

Both \expemba{} and \expembe{} are trained with $H = 64, 128, 256, 512, 1024$. For evaluating our models, we use the \textsc{UnseenEqClass} test set. Table \ref{tab:semvec_comparison} shows the scores achieved by our approach. This table shows the best scores and corresponding model dimensions $H$ for \expemba{} and \expembe{}. Refer to Appendix \ref{appendix:semvec_datasets} for the scores achieved by our model with different values of $H$. We observe that (1) \textit{the representations learned by \expembe{} capture semantics and not just the syntactic structure} (2) \expemba{} does not perform as well as \expembe{}. We further observe that \expembe{} achieves a similar performance as \eqnet{} and \eqnetl{} on most of the datasets. Also, \expembe{} performs better than \eqnet{} and \eqnetl{} on the datasets with sufficiently large training sets. Though the representation sizes (synonymous with model dimension $H$ in our approach) are higher for \expembe{} than the one used in \eqnet{} and \eqnetl{}, our encoder is very simple compared to both of these approaches. Our encoder consists of a GRU layer, whereas \eqnet{} and \eqnetl{} use \textsc{TreeNN}-based encoders. Additionally, the training for \eqnet{} and \eqnetl{} explicitly pushes the representations of expressions belonging to the same class closer, whereas our approach leaves it to the model to infer from the dataset.
