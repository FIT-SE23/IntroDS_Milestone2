\documentclass[11pt]{article}

\pdfoutput=1
\usepackage{fullpage}           % layout
\usepackage{amsfonts}           % \mathbb
\usepackage{amsthm, amssymb}             % proof
\usepackage{xspace}             % \xspace
\usepackage{graphicx}
\usepackage{adjustbox}          % \adjustbox 
\usepackage{multicol}            
\usepackage{url}
\usepackage{enumerate, enumitem}  %enumerate environment with optional argument
\usepackage{subcaption}
\usepackage[usenames]{xcolor} % for coordinating edits
\newcommand{\sout}[1]{\st{#1}}
%% \usepackage{hyperref}
\usepackage{amsmath, hyperref, nicefrac}
\usepackage[capitalize]{cleveref}
\usepackage{thm-restate}
\usepackage{parskip}
\usepackage{mathtools}
\usepackage{multirow}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}

\colorlet{darkgreen}{green!45!black}



\newcommand{\set}[1]{\{#1\}}
\newcommand{\etal}{et al.\xspace}
\newcommand{\eps}{\varepsilon}
\newcommand{\opt}{\text{OPT}}
\newcommand{\cost}{\text{cost}}
\newcommand{\calS}{\mathcal{S}}
\newcommand{\calP}{\mathcal{P}}
\newcommand{\calL}{\mathcal{L}}
\newcommand{\calR}{\mathcal{R}}
\newcommand{\calT}{\mathcal{T}}
\newcommand{\calE}{\mathcal{E}}

\newcommand{\by}{\mathbf{p}}

\newcommand{\rank}{\textbf{rank}}
\newcommand{\dist}{\text{dist}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\pr}{\mathbb{P}}
%\newcommand{\calE}{\mathcal{E}}
\newcommand{\calF}{\mathcal{F}}
\newcommand{\calX}{\mathcal{X}}
\newcommand{\bI}{\bar{I}_i}
\newcommand{\cand}{\mathbb{C}}
\newcommand{\greedy}{\mathcal{A}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\poly}{\text{poly}}
\newcommand{\alg}{\greedy}
\newcommand{\centers}{\mathcal{C}}
\newcommand{\coreset}{\Omega}
\newcommand{\offset}{F}
\newcommand{\weight}{f}
\newcommand{\inner}{R_I}
\newcommand{\out}{R_O}
\newcommand{\main}{R_M}
\newcommand{\size}{\Gamma}
\newcommand{\polylog}{\text{polylog}}


\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\argmax}{argmax}
\DeclareMathOperator{\argmin}{argmin}

\newcommand{\valuedelta}{\frac{\log^2 1/\eps}{2^{O(z\log z)}\min(\eps^2, \eps^z)}\left(k \log |\cand| + \log \log (1/\eps) + \log(1/\pi)\right)}

\newtheorem{lemma}{Lemma}
\newtheorem{observation}{Observation}
\newtheorem{theorem}{Theorem}
%% \newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{definition}{Definition}
%% \newtheorem{axiom}[theorem]{Axiom}
\newtheorem{fact}{Fact}
%% \newtheorem{observation}[theorem]{Observation}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{question}{Question}

\usepackage{wrapfig}
\newcommand{\erclogowrapped}[1]{%
\setlength\intextsep{0pt}%
\begin{wrapfigure}[3]{r}{#1*\real{1.1}}%
\includegraphics[width=#1]{LOGO_ERC-FLAG_EU_crop.jpg}%
\end{wrapfigure}%
}

\newcounter{sideremark}
\newcommand{\marrow}{\stepcounter{sideremark}\marginpar{$
\longleftarrow\scriptstyle\arabic{sideremark}$}}
\newcommand{\blue}[1]{{\color{blue}\bf #1}}
 \newcommand{\david}[1]{
 %  \ifdraft{
    \textsf{\blue{*** (David) \marrow #1 ***}}
 %  }
 %  \fi
 }

\newcommand{\red}[1]{{\color{red}\bf #1}}
 \newcommand{\vincent}[1]{
 %  \ifdraft{
    \textsf{\red{*** (Vincent) \marrow #1 ***}}
 %  }
 %  \fi
 }
 
 
 \newcommand{\green}[1]{{\color{green}\bf #1}}
 \newcommand{\chris}[1]{
 %  \ifdraft{
    \textsf{\green{*** (Chris) \marrow #1 ***}}
 %  }
 %  \fi
 }


\usepackage{amsmath}
\title{Improved Coresets for Euclidean $k$-Means\footnote{An extended abstract appeared at NeurIPS 2022.}}
\author{Vincent Cohen-Addad \and Kasper Green Larsen \and 
  David Saulpic
  \and
  Chris Schwiegelshohn \and Omar Ali Sheikh-Omar
}
\date{}


\begin{document}


\maketitle


\begin{abstract}
Given a set of $n$ points in $d$ dimensions, the Euclidean $k$-means problem (resp. the Euclidean $k$-median problem) consists of finding $k$ centers such that the sum of squared distances (resp. sum of distances) from every point to its closest center is minimized. The arguably most popular way of dealing with this problem in the big data setting is to first compress the data by computing a weighted subset known as a coreset and then run any algorithm on this subset. The guarantee of the coreset is that for any candidate solution, the ratio between coreset cost and the cost of the original instance is less than a $(1\pm \varepsilon)$ factor. The current state of the art  coreset size is $\tilde O(\min(k^{2} \cdot \varepsilon^{-2},k\cdot \varepsilon^{-4}))$ for Euclidean $k$-means and $\tilde O(\min(k^{2} \cdot \varepsilon^{-2},k\cdot \varepsilon^{-3}))$ for Euclidean $k$-median. The best known lower bound for both problems is $\Omega(k \varepsilon^{-2})$. In this paper, we improve the upper bounds $\tilde O(\min(k^{3/2} \cdot \varepsilon^{-2},k\cdot \varepsilon^{-4}))$ for $k$-means and $\tilde O(\min(k^{4/3} \cdot \varepsilon^{-2},k\cdot \varepsilon^{-3}))$ for $k$-median. In particular, ours is the first provable bound that breaks through the $k^2$ barrier while retaining an optimal dependency on $\varepsilon$. 
\end{abstract}


\input{intro}
%\input{coreset}
\input{chaining}
%\input{DP}

\section{Disclosure of Funding Acknowledgements}
Kapser Green Larsen was partially supported by the Independent Research Fund Denmark (DFF) under a Sapere Aude Research Leader grant No 9064-00068B. 

\erclogowrapped{5\baselineskip}David Saulpic has received funding from
the European Research Council (ERC) under the European Union's Horizon 2020
research and innovation programme (Grant agreement No.\ 101019564
``The Design of Modern Fully Dynamic Data Structures (MoDynStruct)''.

Chris Schwiegelshohn was partially supported by the Independent Research Fund Denmark (DFF) under a Sapere Aude Research Leader grant No 1051-00106B and the Innovation Fund Denmark under grant agreement No 0153-00233A. 

Omar Ali Sheikh-Omar was partially supported by the Innovation Fund Denmark under grant agreement No 0153-00233A.


\bibliographystyle{plain}
\bibliography{reference}
\newpage


%\appendix
%%
%%
%%\section{Analysis Details}
%
%
%\input{app_chaining}
%\input{supplementary/experiments}
%
%
%Optionally include extra information (complete proofs, additional experiments and plots) in the appendix.
%This section will often be part of the supplemental material.


\end{document}