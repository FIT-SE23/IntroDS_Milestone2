\begin{table}[t]
\center
\small
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\ \midrule
ELECTRA-small   & \textbf{15.17}  & 42.48  & \textbf{20.54} \\
ELECTRA-large   & 14.61     &\textbf{43.96}  & 20.23 \\
BERT-large      & 12.97     & 40.33  & 18.14 \\
ALBERT-base     & 13.12     & 39.43  & 18.10 \\
T5-large        & 12.78     & 39.09  & 17.74 \\
ELECTRA-base    & 12.87     & 37.73  & 17.66 \\
T5-base         & 12.69     & 37.98  & 17.42 \\
BART-base       & 12.16     & 36.76  & 16.79 \\
BERT-base       & 11.97     & 36.17  & 16.53 \\
T5-small        & 12.03     & 35.41  & 16.49 \\
BART-large      & 11.68     & 36.23  & 16.25 \\
XLNet-large     & 11.63     & 36.38  & 16.18 \\
RoBERTa-base    & 10.68     & 34.29  & 14.94 \\
DistilBERT-base & 10.56     & 31.87  & 14.55 \\
GPT2-large      & 10.24     & 31.54  & 14.10  \\
GPT2-medium     & 10.20     & 30.68  & 13.94 \\
XLNet-base      & 9.86      & 30.90   & 13.68 \\
GPT2            & 9.63      & 28.53  & 13.11 \\
RoBERTa-large   & 7.93      & 27.88  & 11.45 \\ \bottomrule
\end{tabular}
\caption{The average F1 score of the rationale overlap on three sentiment analysis tasks sorts the table.}
\label{tab:decay_ratio}
\end{table}