% % \begin{table*}[t]
% % \centering
% % % \small
% % \begin{adjustbox}{width=\textwidth}
% % % Please add the following required packages to your document preamble:
% % % \usepackage{multirow}
% % \begin{tabular}{lrrrrrrr}
% % \toprule
% % \multirow{2}{*}{\textbf{Pre-trained Models}}                 & \textbf{Avg}                    & \textbf{Avg}         & \textbf{Avg}         & \textbf{F-Rank}     & \textbf{F-Rank}     & \textbf{Rank} & \textbf{PARAM} \\
% %                                                     &
% % \method & GLUE        & $\Delta$↓   & OOD        & ID        &        & (M)          \\ \hline
% % ELECTRA-large \cite{electra}       & \textbf{69.68}            & \textbf{89.18} & \textbf{21.87}                           & \textbf{2.25} & \textbf{2.25} & \textbf{1}    & 334.09                         \\
% % T5-large \cite{t5}                 & 67.62                                      & 87.70                           & 22.90                           & 3.13                           & 3.00                           & 2                              & 737.67                         \\
% % RoBERTa-large \cite{roberta}       & 67.03                                      & 87.83                           & 23.68                           & 5.00                           & 3.00                           & 4                              & 355.36                         \\
% % BART-large \cite{bart}             & 66.15                                      & 87.05                           & 24.01                           & 4.88                           & 3.63                           & 7                              & 406.29                         \\
% % XLNet-large \cite{xlnet}           & 65.80                                      & 86.75                           & 24.15                           & 5.75                           & 4.63                           & 8                              & 360.27                         \\
% % T5-base \cite{t5}                  & 65.45                                      & 85.92                           & 23.82                           & 6.13                           & 6.13                           & 6                              & 222.90                         \\
% % RoBERTa-base \cite{roberta}        & 64.46                                      & 85.27                           & 24.40                           & 8.25                           & 6.63                           & 9                              & 124.65                         \\
% % ELECTRA-base  \cite{electra}       & 64.15                                      & 85.92                           & 25.34                           & 9.75                           & 8.63                           & 16                             & 108.89                         \\
% % GPT2-large  \cite{gpt2}            & 62.76                                      & 83.57                           & 24.90                           & 11.13                          & 11.50                          & 12                             & \textbf{774.03}                         \\
% % BART-base  \cite{bart}             & 62.35                                      & 83.04                           & 24.92                           & 10.75                          & 11.00                          & 13                             & 139.42                         \\
% % ELECTRA-small  \cite{electra}      & 62.12                                      & 81.50                           & 23.78                           & 13.63                          & 16.13                          & 5                              & 13.48                          \\
% % ALBERT-base  \cite{albert}         & 62.06                                      & 82.58                           & 24.85                           & 12.63                          & 13.25                          & 11                             & 11.68                          \\
% % GPT2-medium  \cite{gpt2}           & 61.86                                      & 81.84                           & 24.41                           & 12.38                          & 13.63                          & 10                             & 354.82                         \\
% % T5-small  \cite{t5}                & 61.55                                      & 80.35                           & 23.40 & 11.75                          & 15.00                          & 3                              & 60.51                          \\
% % XLNet-base  \cite{xlnet}           & 61.53                                      & 82.26                           & 25.20                           & 13.00                          & 12.13                          & 15                             & 116.72                         \\
% % BERT-large  \cite{bert}            & 61.52                                      & 83.26                           & 26.11                           & 13.00                          & 10.38                          & 18                             & 335.14                         \\
% % BERT-base  \cite{bert}             & 60.87                                      & 82.08                           & 25.84                           & 14.50                          & 13.88                          & 17                             & 109.48                         \\
% % GPT2  \cite{gpt2}                  & 59.49                                      & 79.30                           & 24.98                           & 15.25                          & 17.88                          & 14                             & 124.44                         \\
% % DistilBERT-base  \cite{distilbert} & 58.94                                      & 80.21                           & 26.52                           & 16.88                          & 17.38                          & 19                             & 66.36                          \\ \bottomrule
% % \end{tabular}
% % 	\end{adjustbox}
% % \caption{Overall performance sorted by the \method performance. The average accuracy shown in the table is the mean average score of the OOD performance for each task. The average \textbf{$\Delta$↓} indicates the decreased ratio from the average ID accuracy to OOD accuracy. We also provide the Friedman rank \cite{friedman1940comparison} for OOD and ID tests (shown as F-Rank). The robustness rank is sorted by the average ratio of performance decay in ascending order.} 
% % \label{tab:overall_per}
% % \end{table*}


% \begin{table*}[t]
% \centering
% \begin{adjustbox}{width=\textwidth}
% \begin{tabular}{lrrrrrrr}
% \toprule
% \multirow{2}{*}{\textbf{Pre-trained Models}}                 & \textbf{Avg}                    & \textbf{Avg}         & \textbf{Avg}         & \textbf{F-Rank}     & \textbf{F-Rank}     & \textbf{Rank} & \textbf{PARAM} \\
%                                                     &
% \method & GLUE        & $\Delta$↓   & OOD        & ID        &        & (M)          \\ \hline
% ELECTRA-large \cite{electra}       & \textbf{74.62}            & \textbf{89.18} & \textbf{14.56}                           & \textbf{2.13} & \textbf{2.25} & \textbf{1}    & 334.09                         \\
% T5-large \cite{t5}                 & 72.81                                      & 87.70                           & 14.89                           & 2.38                           & 3.00                           & 2                              & 737.67                         \\
% RoBERTa-large \cite{roberta}       & 71.62                                      & 87.83                           & 16.21                           & 4.00                           & 3.00                           & 3                              & 355.36                         \\
% BART-large \cite{bart}             & 70.38                                      & 87.05                           & 16.67                           & 5.00                           & 3.63                           & 6                              & 406.29                         \\
% T5-base \cite{t5}                  & 70.05                                      & 85.92                           & 15.87                           & 5.88                           & 6.13                           & 4                              & 222.90                         \\
% XLNet-large \cite{xlnet}           & 69.69                                      & 86.75                           & 17.06                           & 6.00                           & 4.63                           & 8                              & 360.27                         \\
% RoBERTa-base \cite{roberta}        & 68.73                                      & 85.27                           & 16.54                           & 7.00                           & 6.63                           & 7                              & 124.65                         \\
% ELECTRA-base  \cite{electra}       & 67.78                                      & 85.92                           & 18.14                           & 9.63                           & 8.63                           & 15                             & 108.89                         \\
% GPT2-large  \cite{gpt2}            & 66.46                                      & 83.57                           & 17.11                           & 10.88                          & 11.50                          & 10                             & \textbf{774.03}                         \\
% BART-base  \cite{bart}             & 65.89                                      & 83.04                           & 17.15                           & 11.00                          & 11.00                          & 12                             & 139.42                         \\
% BERT-large  \cite{bert}            & 65.80                                      & 83.26                           & 17.46                           & 11.38                          & 10.38                          & 14                             & 335.14                         \\
% T5-small  \cite{t5}                & 65.43                                      & 80.35                           & 14.92 & 12.63                          & 15.00                          & 5                              & 60.51                          \\
% ALBERT-base  \cite{albert}         & 65.30                                      & 82.58                           & 17.28                           & 12.88                          & 13.25                          & 13                             & 11.68                          \\
% ELECTRA-small  \cite{electra}      & 65.06                                      & 81.50                           & 16.44                           & 13.88                          & 16.13                          & 9                              & 13.48                          \\
% GPT2-medium  \cite{gpt2}           & 65.03                                      & 81.84                           & 16.81                           & 12.88                          & 13.63                          & 11                             & 354.82                         \\
% XLNet-base  \cite{xlnet}           & 64.57                                      & 82.26                           & 17.69                           & 12.75                          & 12.13                          & 16                             & 116.72                         \\
% BERT-base  \cite{bert}             & 64.10                                      & 82.08                           & 17.98                           & 13.88                          & 13.88                          & 17                             & 109.48                         \\
% DistilBERT-base  \cite{distilbert} & 61.94                                      & 80.21                           & 18.27                           & 17.75                          & 17.38                          & 18                             & 66.36                          \\
% GPT2  \cite{gpt2}                  & 61.16                                      & 79.30                           & 18.14                           & 18.13                          & 17.88                          & 19                             & 124.44                         \\ \bottomrule
% \end{tabular}
% \end{adjustbox}
% \caption{Overall performance sorted by the \method performance. The average accuracy shown in the table is the mean average score of the OOD performance for each task. The average \textbf{$\Delta$↓} indicates the decreased ratio from the average ID accuracy to OOD accuracy. We also provide the Friedman rank \cite{friedman1940comparison} for OOD and ID tests (shown as F-Rank). The robustness rank is sorted by the average ratio of performance decay in ascending order.} 
% \label{tab:overall_per}
% \end{table*}

\begin{table*}[t]
\centering
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{lrrrrrrr}
\toprule
\multirow{2}{*}{\textbf{Pre-trained Models}}                 & \textbf{Avg}                    & \textbf{Avg}         & \textbf{Avg}         & \textbf{F-Rank}     & \textbf{F-Rank}     & \textbf{Rank} & \textbf{PARAM} \\
                                                    &
\method & GLUE        & $\Delta$↓   & OOD        & ID      & $\Delta$↓        & (M)          \\ \hline
ELECTRA-large \cite{electra}       & \textbf{74.62}            & \textbf{89.18} & \textbf{16.33}                           & \textbf{2.13} & \textbf{2.25} & \textbf{1}    & 334.09                         \\
T5-large \cite{t5}                 & 72.81                                      & 87.70                           & 16.98                           & 2.38                           & 3.00                           & 2                              & 737.67                         \\
RoBERTa-large \cite{roberta}       & 71.62                                      & 87.83                           & 18.46                           & 4.00                           & 3.00                           & 3                              & 355.36                         \\
BART-large \cite{bart}             & 70.38                                      & 87.05                           & 19.15                           & 5.00                           & 3.63                           & 6                              & 406.29                         \\
T5-base \cite{t5}                  & 70.05                                      & 85.92                           & 18.47                           & 5.88                           & 6.13                           & 4                              & 222.90                         \\
XLNet-large \cite{xlnet}           & 69.69                                      & 86.75                           & 19.67                           & 6.00                           & 4.63                           & 8                              & 360.27                         \\
RoBERTa-base \cite{roberta}        & 68.73                                      & 85.27                           & 19.40                           & 7.00                           & 6.63                           & 7                              & 124.65                         \\
ELECTRA-base  \cite{electra}       & 67.78                                      & 85.92                           & 21.11                           & 9.63                           & 8.63                           & 15                             & 108.89                         \\
GPT2-large  \cite{gpt2}            & 66.46                                      & 83.57                           & 20.47                           & 10.88                          & 11.50                          & 10                             & \textbf{774.03}                         \\
BART-base  \cite{bart}             & 65.89                                      & 83.04                           & 20.65                           & 11.00                          & 11.00                          & 12                             & 139.42                         \\
BERT-large  \cite{bert}            & 65.80                                      & 83.26                           & 20.97                           & 11.38                          & 10.38                          & 14                             & 335.14                         \\
T5-small  \cite{t5}                & 65.43                                      & 80.35                           & 18.57 & 12.63                          & 15.00                          & 5                              & 60.51                          \\
ALBERT-base  \cite{albert}         & 65.30                                      & 82.58                           & 20.93                           & 12.88                          & 13.25                          & 13                             & 11.68                          \\
ELECTRA-small  \cite{electra}      & 65.06                                      & 81.50                           & 20.17                           & 13.88                          & 16.13                          & 9                              & 13.48                          \\
GPT2-medium  \cite{gpt2}           & 65.03                                      & 81.84                           & 20.54                           & 12.88                          & 13.63                          & 11                             & 354.82                         \\
XLNet-base  \cite{xlnet}           & 64.57                                      & 82.26                           & 21.50                           & 12.75                          & 12.13                          & 16                             & 116.72                         \\
BERT-base  \cite{bert}             & 64.10                                      & 82.08                           & 21.91                           & 13.88                          & 13.88                          & 17                             & 109.48                         \\
DistilBERT-base  \cite{distilbert} & 61.94                                      & 80.21                           & 22.78                           & 17.75                          & 17.38                          & 18                             & 66.36                          \\
GPT2  \cite{gpt2}                  & 61.16                                      & 79.30                           & 22.88                           & 18.13                          & 17.88                          & 19                             & 124.44                         \\ \bottomrule
\end{tabular}
\end{adjustbox}
\caption{Overall performance sorted by the \method performance. The average accuracy shown in the table is the mean average score of the OOD performance for each task. The average \textbf{$\Delta$↓} indicates the decreased ratio from the average ID accuracy to OOD accuracy. We also provide the Friedman rank \cite{friedman1940comparison} for OOD and ID tests (shown as F-Rank). The robustness rank is sorted by the average ratio of performance decay in ascending order.} 
\label{tab:overall_per}
\end{table*}


