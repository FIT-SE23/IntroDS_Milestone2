\begin{table*}[t]
\centering
% \small
\begin{adjustbox}{width=\textwidth}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{tabular}{lrrrrrr}
\hline
\multirow{2}{*}{\textbf{Pre-trained Models}}                & \multicolumn{1}{c}{\textbf{Avg}}                    & \multicolumn{1}{c}{\textbf{Avg}}  & \multicolumn{1}{c}{\textbf{Avg}}       & \multicolumn{1}{l}{\textbf{Friedman}} & \multicolumn{1}{l}{\textbf{Friedman}} & \multicolumn{1}{l}{\textbf{Robustness}} \\
                                                   & \multicolumn{1}{l}{\textbf{\method}} & \multicolumn{1}{l}{\textbf{GLUE}} & \multicolumn{1}{l}{\textbf{$\Delta$↓}} & \multicolumn{1}{l}{\textbf{OOD Rank}} & \multicolumn{1}{l}{\textbf{ID Rank}}  & \multicolumn{1}{l}{\textbf{Rank}}       \\ \hline
ELECTRA-large \cite{electra} & \textbf{69.68} & \textbf{89.38} & 19.50                          & \textbf{2.25}          & \textbf{2.25}                                                   & \textbf{1}                              \\
T5-large \cite{t5}           & 67.62                                      & 87.70                     & 20.08                         & 3.13                                                   & 3.00                                                      & 2                              \\
RoBERTa-large \cite{roberta}  & 67.03                                      & 87.83                    & 20.80                          & 5.00                                                      & 3.00                                                      & 4                              \\
BART-large \cite{bart}       & 66.15                                      & 87.05                    & 20.90                          & 4.88                                                   & 3.63                                                   & 7                              \\
XLNet-large \cite{xlnet}     & 65.80                                       & 86.75                    & 20.95                         & 5.75                                                   & 4.63                                                   & 8                              \\
T5-base \cite{t5}            & 65.45                                      & 85.92                    & 20.47                         & 6.13                                                   & 6.13                                                   & 6                              \\
RoBERTa-base \cite{roberta}   & 64.46                                      & 85.27                    & 20.81                         & 8.25                                                   & 6.63                                                   & 9                              \\
ELECTRA-base  \cite{electra}       & 64.15                                      & 85.92                    & 21.77                         & 9.75                                                   & 8.63                                                   & 16                             \\
GPT2-large  \cite{gpt2}            & 62.76                                      & 83.57                    & 20.81                         & 11.13                                                  & 11.50                                                   & 12                             \\
BART-base  \cite{bart}             & 62.35                                      & 83.04                    & 20.69                         & 10.75                                                  & 11.00                                                     & 13                             \\
ELECTRA-small  \cite{electra}      & 62.12                                      & 81.50                     & 19.38                         & 13.63                                                  & 16.13                                                  & 5                              \\
ALBERT-base  \cite{albert}         & 62.06                                      & 82.58                    & 20.52                         & 12.63                                                  & 13.25                                                  & 11                             \\
GPT2-medium  \cite{gpt2}           & 61.86                                      & 81.84                    & 19.98                         & 12.38                                                  & 13.63                                                  & 10                             \\
T5-small  \cite{t5}                & 61.55                                      & 80.35                    & \textbf{18.80}                & 11.75                                                  & 15.00                                                     & 3                              \\
XLNet-base  \cite{xlnet}           & 61.53                                      & 82.26                    & 20.73                         & 13.00                                                     & 12.13                                                  & 15                             \\
BERT-large  \cite{bert}            & 61.52                                      & 83.26                    & 21.74                         & 13.00                                                     & 10.38                                                  & 18                             \\
BERT-base  \cite{bert}             & 60.87                                      & 82.08                    & 21.21                         & 14.50                                                   & 13.88                                                  & 17                             \\
GPT2  \cite{gpt2}                  & 59.49                                      & 79.30                     & 19.81                         & 15.25                                                  & 17.88                                                  & 14                             \\
DistilBERT-base  \cite{distilbert} & 58.94                                      & 80.21                    & 21.27                         & 16.88                                                  & 17.38                                                  & 19                             \\ \hline
\end{tabular}
	\end{adjustbox}
\caption{Overall performance sorted by the \method performance. The average accuracy shown in the table is the mean average score of the OOD performance for each task. The average \textbf{$\Delta$↓} indicates the decreased ratio from the average ID accuracy to OOD accuracy. We also provide the Friedman rank \cite{friedman1940comparison} for both OOD and ID tests. The robustness rank is sorted by the decreased ratio of the model performance.}
\label{tab:overall_per}
\end{table*}