\begin{table*}[t]
\centering
\small
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{lcccccccccc}
\toprule
\multirow{2}{*}{\textbf{Model}} & \multicolumn{1}{c}{\textbf{SST-2}} & \multicolumn{1}{c}{\textbf{MNLI}} & \multicolumn{1}{c}{\textbf{QNLI}} & \multicolumn{1}{c}{\textbf{RTE}} & \multicolumn{1}{c}{\textbf{MRPC}} & \multicolumn{1}{c}{\textbf{QQP}} & \multicolumn{1}{c}{\textbf{STS-B}} & \multicolumn{1}{c}{\textbf{CoLA}} & \multicolumn{1}{c}{\textbf{Avg}} & \textbf{Avg}       \\
                       & \multicolumn{1}{c}{OOD}   & \multicolumn{1}{c}{OOD}  & \multicolumn{1}{c}{OOD} & \multicolumn{1}{c}{OOD}  & \multicolumn{1}{c}{OOD} & \multicolumn{1}{c}{OOD}   & \multicolumn{1}{c}{OOD}  & \multicolumn{1}{c}{OOD} & \multicolumn{1}{c}{OOD} & $\Delta$â†“ 
                       \\ \midrule
\multicolumn{10}{l}{Human Performance}   \\ \midrule
& 92.36 & \textit{84.13} & 81.10 & \textit{83.47} & \textit{84.70} & \textit{85.43} & 80.28 & \textit{58.98} & \textit{81.31} & \textit{5.79}
                       \\ \midrule
\multicolumn{10}{l}{State-of-the-art Pre-trained Language Models}                                                                                                                                                                                         \\ \midrule
ELECTRA-large          & \textbf{95.14}                     & 76.94                    & 80.44                   & 71.40                    & 53.61                   & \textbf{60.94}                     & \textbf{81.14}                   & \textbf{37.85}         & \textbf{69.68}                   & \textbf{21.87}                                             \\
T5-large               & 94.35                     & 76.36                    & \textbf{81.72}                   & \textbf{73.98}                    & 53.96                   & 56.42                     & 77.86                    & 26.30                    & 67.62                   & 22.90                                             \\
RoBERTa-large          & 93.48                     & 77.28                    & 79.67                   & 71.35                    & 49.94                   & 60.74                     & 77.91                    & 25.90                    & 67.03                   & 23.68                                             \\
BART-large             & 93.78                     & 76.09                    & 80.45                   & 69.83                    & 54.69                   & 57.23                     & 76.03                    & 21.06                    & 66.15                   & 24.01                                             \\
XLNet-large            & 94.20                     & \textbf{77.59}                    & 79.98                   & 69.81                    & 52.76                   & 52.47                     & 76.86                    & 22.76                    & 65.80                   & 24.15                                             \\
T5-base                & 93.65                     & 73.76                    & 80.29                   & 68.85                    & \textbf{54.87}                   & 57.27                     & 74.98                    & 19.94                    & 65.45                   & 23.82                                             \\
RoBERTa-base           & 92.70                     & 74.21                    & 79.55                   & 66.71                    & 51.99                   & 52.76                     & 74.90                    & 22.81                    & 64.46                   & 24.40                                             \\
ELECTRA-base           & 90.11                     & 75.33                    & 78.10                   & 70.55                    & 49.01                   & 51.81                     & 77.10                    & 21.23                    & 64.15                   & 25.34                                             \\
GPT2-large             & 91.57                     & 73.62                    & 75.77                   & 62.45                    & 51.84                   & 58.91                     & 70.61                    & 17.32                    & 62.76                   & 24.90                                             \\
BART-base              & 91.76                     & 74.32                    & 78.77                   & 64.75                    & 52.19                   & 51.69                     & 72.46                    & 12.90                    & 62.35                   & 24.92                                             \\
ELECTRA-small          & 89.08                     & 70.57                    & 75.02                   & 65.90                    & 49.90                   & 51.64                     & 72.36                    & 22.48                    & 62.12                   & 23.78                                             \\
ALBERT-base            & 89.70                     & 70.95                    & 77.31                   & 61.45                    & 49.98                   & 57.72                     & 72.17                    & 17.18                    & 62.06                   & 24.85                                             \\
GPT2-medium            & 91.18                     & 72.82                    & 77.70                   & 59.28                    & 52.68                   & 54.76                     & 69.16                    & 17.26                    & 61.86                   & 24.41                                             \\
T5-small               & 89.00                     & 70.67                    & 77.44                   & 63.28                    & 54.91                   & 53.94                     & 72.58                    & 10.55                    & 61.55                   & 23.40                                             \\
XLNet-base             & 91.41                     & 74.75                    & 76.87                   & 64.52                    & 51.39                   & 51.47                     & 68.29                    & 13.53                    & 61.53                   & 25.20                                             \\
BERT-large             & 91.21                     & 73.33                    & 78.79                   & 59.71                    & 49.37                   & 53.23                     & 69.76                    & 16.77                    & 61.52                   & 26.11                                             \\
BERT-base              & 88.88                     & 70.92                    & 78.31                   & 61.52                    & 50.90                   & 51.11                     & 67.68                    & 17.66                    & 60.87                   & 25.84                                             \\
GPT2                   & 86.02                     & 69.67                    & 76.41                   & 59.64                    & 54.27                   & 53.42                     & 66.26                    & 10.22                    & 59.49                   & 24.98                                             \\
DistilBERT-base        & 86.50                     & 70.27                    & 74.27                   & 57.41                    & 53.05                   & 51.45                     & 66.18                    & 12.37                    & 58.94                   & 26.52                                            \\ \bottomrule

\end{tabular}
\end{adjustbox}
\caption{Detailed OOD performance for each task in \method. Evaluation metrics for each task are the same as GLUE (the average results are reported for those tasks considering two metrics). The best performance is shown in bold. Human evaluation is simulated in a similar OOD setting by receiving instructions from ID samples while predicting data from OOD datasets. It will be shown in italic when it beats the best model performance.}
\label{tab:detail}
\end{table*}