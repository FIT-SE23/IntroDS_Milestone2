\begin{table*}[t]
\centering
% \small
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{lcccccc}
\toprule
\multirow{2}{*}{\textbf{Pre-trained Models}} & \multicolumn{1}{l}{\textbf{Avg}} & \multicolumn{1}{l}{\textbf{Avg}}  & \multicolumn{1}{l}{\textbf{Avg}} & \textbf{Friedman} & \textbf{Friedman} & \multicolumn{1}{l}{\textbf{Robustness}} \\
                       & \multicolumn{1}{l}{\textbf{\method}} & \multicolumn{1}{l}{\textbf{GLUE}} & \multicolumn{1}{l}{\textbf{$\Delta$↓}} & \textbf{OOD Rank} & \textbf{ID Rank}& \multicolumn{1}{l}{\textbf{Rank}}       \\ \midrule
% \multicolumn{7}{l}{State-of-the-art Pre-trained Language Models}                                                                                                                      \\ \hline
RoBERTa-large \cite{roberta}         & \textbf{65.10} & 86.60  & \textbf{24.83} & 3.43  & 2 & 1  \\ 
T5-large \cite{t5}               & 63.93 & \textbf{86.71} & 26.27 & 4     & 2     & 9  \\
XLNet-large  \cite{xlnet}           & 63.81 & 85.63 & 25.48 & 5     & 4.14  & 2  \\
BART-large  \cite{bart}           & 63.32 & 86.56 & 26.85 & 4.86  & 2.43  & 12  \\
T5-base      \cite{t5}           & 62.20 & 85.00 & 26.82 & 5.71  & 5.29  & 11 \\
RoBERTa-base \cite{roberta}            & 62.07 & 84.08 & 26.18 & 6.86  & 5.57  & 8  \\
GPT2-large    \cite{gpt2}        & 61.45 & 82.64 & 25.64 & 7.86  & 9.86  & 3  \\
ALBERT-base    \cite{albert}         & 60.51 & 81.61 & 25.85 & 9.86  & 10.86 & 6 \\
BART-base     \cite{bart}          & 60.11 & 82.27 & 26.94 & 9.71  & 9.14  & 13 \\
BERT-large   \cite{bert}           & 59.95 & 82.45 & 27.29 & 10.43 & 8.71  & 14 \\
GPT2-medium \cite{gpt2}            & 59.92 & 80.60  & 25.66 & 9.57  & 12    & 4 \\
XLnet-base \cite{xlnet}              & 59.91 & 80.77 & 25.83 & 10    & 10.29 & 5 \\
BERT-base \cite{bert}       & 58.73 & 80.83 & 27.34 & 11.86 & 11.71 & 15 \\
T5-small  \cite{t5}              & 57.99 & 78.86 & 26.46 & 11    & 12.43 & 10 \\
GPT2 \cite{gpt2}                   & 57.70  & 77.91 & 25.94 & 12.14 & 15.14 & 7 \\
DistilBERT-base \cite{distilbert}        & 56.46 & 78.91 & 28.45 & 13.71 & 14.43 & 16\\ \bottomrule
\end{tabular}
	\end{adjustbox}
\caption{Overall performance sorted by the \method performance. The average accuracy is calculated by the weighted sum in terms of the size of test instances for each task. The average \textbf{$\Delta$↓} indicates the decrease ratio from the average ID accuracy to OOD accuracy. We also provide the Friedman rank for both OOD and ID test. The robustness rank is sorted by the decrease ratio of the model performance.}
\label{tab:overall_per}
\end{table*}