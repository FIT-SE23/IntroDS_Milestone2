





































(This is a deprecated version of intro... the whole intro section needs to be re-written... Please see the method first)



% Answering complex reading comprehension questions often requires understanding relations between entities. For example, to answer a question ``When was Bill Gate's wife born?'' \YX{Please change the example to something else than Bill Gates wife.. they have divorced}, it is required to conduct two-hop relational reasoning with the following $\lambda$-calculus logical query~\cite{barendregt1984lambda}: $\lambda x \lambda y.\ Spouse(Bill Gates, x) \land BirthDate(x, y)$. 
% If these entities and relations appear in a knowledge base (KB, e.g., Freebase~\cite{DBLP:conf/sigmod/BollackerEPST08}, 
% and WikiData~\cite{DBLP:journals/cacm/VrandecicK14}), 
% the parsed query can then be executed on the KB and to identify the answer. This procedure, which we refer to as relational reasoning, has been widely studied in Knowledge Base Question Answering (KBQA) literature. Recent KBQA systems \cite{DBLP:conf/emnlp/BerantCFL13,DBLP:conf/acl/YihCHG15,DBLP:journals/tacl/ReddyTCKDSL16,DBLP:journals/corr/abs-1709-00103,DBLP:conf/acl/LiangBLFL17,DBLP:conf/nips/HamiltonBZJL18} have shown impressive results in answering very complex questions that require multi-hop reasoning and involve multiple constraints. However, constructing KBs requires heavy human curation and existing KBs suffer from low coverage of certain entities and relations. This restricts the existing KBQA systems to be applied in answering open-ended questions.

% %and existing KB suffers from low coverage of the entities and relations required for open-ended questions. These limitations restrict the use of KBQA systems.


% As an alternative setting, open-domain QA system generates the answer from large-scale unstructured text corpus (e.g., Wikipedia). Most systems~\cite{DBLP:conf/acl/ChenFWB17,DBLP:conf/emnlp/NieWB19,DBLP:conf/iclr/DasDZM19,DBLP:conf/iclr/AsaiHHSX20} adopt a two-stage pipeline to: 1) retrieve relevant documents from the unstructured corpus; 2) read the retrieved documents and extract a text span from them as the answer. 
% % As traditional term-based retrieval methods, such as TF-IDF and BM-25, cannot capture the semantics of the question beyond exact lexical matching, 

% To empower the QA model to capture subtle relation information for answering complex questions, in this paper, we propose the Knowledge Graph Reasoning Integrated Language Model (\method) to explicitly model the relations between entities across multiple documents. In particular, 
% %In this way, for complex questions, we can use 
% \method construct an entity-relation reasoning graph that provides explicit guidelines to answer an complex question that requires multi-hop and logical reasoning %With the constructed reasoning graph, we can get the answer that requires multi-hop and complex logical reasoning.
% %in this paper, we aim at exploring explicit and differentiable relational reasoning over entity embeddings for answering complex open-domain questions. 

% % study the following research question: \textit{Can we learn the structured relation knowledge purely over the unstructured text corpus, and conduct explicit and differentiable relational reasoning for open-domain questions?}
% To construct the reasoning graph, \method first identifies all the source entities involved in the question, and then infers their relations to next-hop target entities. Then, \method adopts relational operators to retrieve a set of target entities that fulfill the conjunction of all relation constraints. By iteratively conducting this entity retrieval step, \method reaches the entity that can be used to answer the question. 


% % For example, to answer ``The oberoi family is part of a hotel company that has a head office in what city?", \method start from seed entity within the question ``The oberoi family" and detect relational phrase ``part of". Then it retrieves a target entity ``Oberoi Group" from the wikipedia that has a relation "belong to" with source entity ``Oberoi Family". Then treat it as the current source entity to repeat the retrieval process, finding the target location that ``the oberoi group" has a relation ``has a office''


% One key component of \method\ is to model the relations between entities. In contrast to KBQA methods, \method\ does not require a given knowledge graph. Instead, it models and learns the relations from the weak supervision provided by the question-answer pairs. Specifically, \method extracts text spans from the contexts of source entity as relational keys.
% %a relational key extractor model that takes the source entity's contextual embedding as a query to extract text spans from the contexts as relational keys. 
% %Another challenge is to learn different relations without extra supervision in a differentiable manner. We 
% Then it adopts an EM-based clustering algorithm to identify a variety types of relations based on the relational keys. For example, geographical key phrases as ``besides'', ``next to'' extracted from documents all belong to relation cluster ``Location''. With the learned relation clusters, \method\ can identify the relation between entities and the corresponding operators of each relation to map source entities to their next-hop target. 















































% One of the most knowledge-intensive tasks in natural language processing is open-domain question answering (ODQA).