\section{Data Storage in Hadoop and HBase}
\label{sec:5}

\subsection{Data formats in Hadoop}
\label{sec:58}

All data are stored in Hadoop MapFile format \cite{MapFile} on the Hadoop file system provided by CERN. The MapFile format is a basic Hadoop storage format with two related SequenceFiles \cite{SequenceFile} (another basic Hadoop storage format), one with data, the other being an index. Both SequenceFiles consist of key:value pairs ordered by key. In the data file the values are the payload, in the index file the values are the positions of the keys in the data file. The index file contains a fraction of the keys so that it can be kept in memory. The MapFiles allow fast random data access by the key that we use to query the data.

Some MapFiles contain full Event Index records, others contain various derived entities and records. This mechanism is transparent to the users, as all MapFiles are treated in the same way.
Search results are also stored as MapFiles to be available for later reuse.

All MapFiles are registered in the Catalog, which is implemented as an HBase \cite{HBase} table. The Catalog contains all information about each MapFile, its status, properties, history and relations to other MapFiles.


\begin{figure}
\centering
  \includegraphics[width=0.48\textwidth]{Data.png}
\caption{The overall data flow within the Hadoop system. The sequential files, one per dataset, written by the Consumers are imported into MapFile format and registered in the Catalog. A subset of the information is stored also in the event lookup table in HBase. Consistency checks are applied and derived information is saved also in Mapfiles. Trigger decoding information is imported from Oracle to HBase for local use. All actions are recorded in the journal.}
\label{fig:data} 
\end{figure}

MapFiles can be searched in three ways:
\begin{enumerate}
\item Key-based search on (sequence of intervals of) keys. This method gives almost immediate results. The primary key for MapFiles containing event records consists of the RunNumber-EventNumber pair, that is unique within each MapFile, as it corresponds to a dataset. Derived MapFiles can have different primary keys. Further, more detailed selections can follow after the key-based search.
\item Full Map/Reduce search. The search clause may contain Java code  or complete Java classes implementing the Mapper and Reducer steps of the Map/ Reduce process.
\item Full scan search. It is the slowest way, but it is useful to understand the details of the search process.
\end{enumerate}
Most search and formatting options can contain any legal Java code using MapFile variables.

\subsection{Compression of MapFiles}
\label{sec:50}

Initially we used uncompressed MapFiles. However the storage space taken up grew and we had to consider compressing the data file of each MapFile.

In the record-compressed SequenceFile format,
each record is compressed separately, but the keys are not compressed.
With the default codec (the "deflate" format) the space savings compared to uncompressed files are in our case non-negligible: a factor of 2 to 4, depending on the data type.

Using the block-compressed SequenceFile format,
groups or blocks of keys and records are compressed together.
If keys and records have similarities, this sort of compression may be much more
efficient than in record-compressed format.
The block size for compression is configurable;
this is the size of uncompressed keys plus values that become compressed and written to the storage as a block.
In our case, with the default block size (128 MB) and compression codec we reduced the file size by a factor 10.

For any tool reading the files as standard MapFiles, the
change of compression type of the SequenceFiles is transparent through the interfaces.
In block-compressed format, to read one record one has to read the whole block; however, querying the data we did not see measurable differences relative to the record-compressed data files. We decided to use the block-compressed format for all MapFiles, so that the average size per event was reduced to 100 bytes, with the largest datasets so far (100 million events) residing in 10 GB files, still a manageable size.

\subsection{Data import to MapFiles and copy to HBase}
\label{sec:51}

The Consumers (section \ref{sec:44}) write in Hadoop one sequential file for each dataset. These files are converted into MapFile format and copied into their dedicated space. All those MapFiles are then registered in the Catalog, which is implemented as an HBase table.

After each successful dataset import, the  event information (without trigger record, for space and performance reasons) is uploaded to an auxiliary HBase table for fast event lookup operations.

All import and search operations are also registered in the system journal, together with all relevant information. The journal is also implemented as an HBase table. The full data flow within the Hadoop system is shown in Figure \ref{fig:data}.


\subsection{Duplicate event detection}
\label{sec:52}

After each import, the MapFiles consistency is verified and all potential problems are notified to the relevant users. The most important inconsistency is the presence of the events stored several times in the same dataset MapFile, which is usually a consequence of a problem in the previous stages of data processing. When duplicated events are found, the production managers are automatically notified by email.

\subsection{Trigger decoding}
\label{sec:53}

The trigger record for each event is transferred as a bitmap, where each bit corresponds to a trigger chain. In order to store the trigger data in Hadoop in an easily searchable and retrievable way, it has to be decoded with the help of the trigger mask for the given dataset, which in turn can be retrieved from the trigger database using the trigger key (SMK) of the dataset.
The trigger tables are available in different databases: the COMA (COnditions MetadatA) database \cite{COMA} contains all trigger information for real data and the MonteCarlo Trigger DB (TriggerDBMC) in Oracle contains the data for MC simulation.

\begin{figure}
\centering
  \includegraphics[width=0.48\textwidth]{TriggerDecoding2.png}
\caption{Trigger information decoding data flow. The EventIndex information in the Hadoop file system (HDFS) contains the trigger key for each event, which is used to retrieve the copy of the relevant trigger table stored in HBase. The event trigger mask is then decoded using this trigger table and the result is stored back with the event record in Hadoop.}
\label{fig:trigger} 
\end{figure}

The EventIndex replicates the trigger tables from COMA and TriggerDBMC to HBase tables and then uses them for trigger decoding \cite{TrigInfo}. If the SMK is absent in the event record it is possible to obtain it from the run number for the real data and from the reconstruction tag for MonteCarlo simulation. This information is also replicated to the HBase tables in the Hadoop store.

\begin{figure*}
\centering
  \includegraphics[width=0.99\textwidth]{Graph.png}
\caption{Screenshot of the EventIndex Graphical Web Service. It allows the navigation of graphs
of data entities. Datasets with event overlaps are shown in this example. The graph can
be further explored, other relations can be shown and operations on the vertices
and edges can be executed - either from the web service itself or by calling
other ATLAS services. The example shows possible actions available for a dataset
and the tabular view of the dataset trigger statistics.}
\label{fig:WS} 
\end{figure*}


The trigger decoding data flow is presented in Figure  \ref{fig:trigger}. The trigger masks from event records are decoded \cite{TrigInfo} using HBase tables, converting chain counters to chain names. The list of trigger chain names obtained after decoding are then stored in updated event records. The information obtained is used for trigger-based selections or to calculate trigger overlaps, helping the trigger chain optimization.


\subsection{Derived statistics and correlation tables}
\label{sec:55}

After the dataset import and successful verification, several derived tables are created automatically:
\begin{itemize}
    \item The dataset overlap table contains the numbers of common events between different datasets in the dataset derivation chain.
    \item The trigger overlap table contains for each dataset the number of trigger chain pairs which were fired simultaneously.
    \item The trigger statistics table contains for each dataset the number of fired trigger chains of each type. While this table is created separately, it can be seen as a subtable of the trigger overlaps table.
\end{itemize}
All derived tables can be interrogated with the standard tools because they are implemented as normal MapFiles. Overlap tables can be also visualised as Graphs (see Figure \ref{fig:WS}).

\subsection{Command line interface}
\label{sec:56}

Several commands were implemented to give access to the stored data:

\begin{itemize}
\item Catalog ({\tt catalog}) to search and modify Catalog entries.
\item EventIndex ({\tt ei}) to search all datasets using either direct searches or complex Map/Reduce jobs. The EventIndex command allows the use of any legal Java code as a search or result clause. 
\item EventLookup ({\tt el}) for fast search of the physical datasets corresponding to an event (specified as a pair of run number and event number).
\item TriggerInfo ({\tt ti}) to perform search and analyses of the trigger information.
\item Inspector ({\tt inspect}) to see the actual content of a MapFile.
\end{itemize}

Commands to access the EventIndex store are available directly in the CERN Hadoop cluster for the data management tasks. The commands that do not modify the store contents are available also on the CERN Linux machines as well as in the ATLAS CVMFS \cite{CVMFS} environment. These remote invocations pass via a Tomcat \cite{Tomcat} based web service. 

\subsection{Web interface}
\label{sec:57}

All provided commands are also available via a Tomcat-based standard REST \cite{REST} Web Service. On top of the simple form-based interface corresponding to the command arguments, high level graphical and interactive Web Services have been implemented. They offer several graphical ways (histograms, Venn diagrams, Graphs etc.) to display the data contents and their relations, as shown in Figure \ref{fig:WS}.

\subsection{Event lookup or ``event picking''}
\label{sec:54}

Event lookup is the most important and heavily used functionality. It returns the GUIDs and optionally the stream type, dataset name and other parameters for user specified sets of real or simulated events, identified by run and event numbers. The search can be narrowed by specifying the trigger stream, data format and version. By default, the lookup is performed in the HBase table, the best performing back-end. It is also possible to run identical queries against the MapFiles from which the data is ingested into the HBase table, as described in section~\ref{sec:51}, and which were historically the first event lookup implementation. 

\subsection{Comment on Free and Open-Source Software}
\label{sec:59}

When it became necessary to convert all MapFiles to the block compressed SequenceFile format (see Section~\ref{sec:50}), it turned out that
random access queries were not working on the block compressed files. Thanks to the availability of the source code, we were able to fully investigate the issue and track it down to a bug in a MapFile method.
Having resolved the problem and incorporated the patched version into the EventIndex, we contributed the patch to the Hadoop project; the patch was accepted and we also had a chance to learn the Hadoop project practices.

The Hadoop project software is released under the Apache License 2.0 \cite{AL2}, which is a free software license according to the Free Software Definition \cite{FSDEF}, and this turned out to be a crucial point.
Hadoop has created an efficient infrastructure and stimulating atmosphere for project contributors with easy access to the full build and test environment, the
  use of modern compilers and build tools,
  extensive use of unit testing and of advanced code quality assurance tools,
  systematic and consistent use of an issue tracker,
  an automated contribution testing system, and
  expert and friendly contribution reviewers.

It is worth mentioning that, apart from Oracle (see section \ref{sec:6}),  all the software we use is free and open-source software.
