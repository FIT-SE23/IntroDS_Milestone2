\section{Solutions}
\label{sec:solutions}
% \david{AVOID USING SHOULDER ABDUCTION EXERCISE AS OUR SOLUTION}
% \meiyi{need a subsection on problem formulation?}

\begin{figure}%
    \centering
    \subfloat[\centering Exercise Qualitative Feedback on Patients' GUI]
    {{\includegraphics[scale=.085]{Figures/iPhoneApp0.png} }}%
    \qquad
    \subfloat[\centering TO-DO list on Patients' GUI]
    {{\includegraphics[scale=.085]{Figures/iPhoneApp2.png} }}%
    \qquad
    \subfloat[\centering Doctors' GUI on Patients' tasks]
    {{\includegraphics[scale=.085]{Figures/iPhoneApp3.png} }}%
    \caption{PhysiQ on Smartphone Graphical User Interface (GUI) for patients and doctors. Leftmost GUI demonstrates the patients' progress tab and how they make progress throughout the months; rightmost GUI demonstrates the doctor' tab to monitor patients' results and how much they improve or aggravate with visualization of the data.}%
     \label{fig:PhysiQ_GUI}%
\end{figure}

We build PhysiQ to continuously monitor users' off-site exercise activity and quantitatively measure the quality. We particularly measure the quality of exercises in three metrics of \textit{range of motion}, \textit{stability}, and \textit{repetition}. The framework is shown in Fig. \ref{fig:SystemStructure}. 
PhysiQ apps run on three platforms. 
Users first perform activities wearing a smartwatch. The PhysiQ app on the smartwatch extracts the sensory data and syncs the data with the smartphone and cloud in real time. Then, the model on the cloud generates scores for the exercises in different manners, such as range of motion and stability. Based on the scores, the model sends feedback, such as, ``The score for a range of motion of this exercise is 150, which means you did a good job on range of motion. '' and recommendations, such as ``You could do 3 more repetitions!'' on the PhysiQ app on user's smartphone. Meanwhile, it also uploads the user's progress to the cloud for the therapist to review. We present some of the graphical user interfaces (GUI) of our app on the phone in Figure \ref{fig:PhysiQ_GUI}. In the rest of this section, we first formalize our problem, then present how we digitalize the exercise metrics on sensory data, and finally elaborate on the details of our multi-task spatio-temporal SNN-based quality measurement model. 

\subsection{Problem Formulation}\label{subsec:solutions:problem} %what is input and output: output is quality?
We formalize the problem as follows: given the smartwatch with built-in IMU sensors, it returns the input of IMU sensory data $\mathbb{X}^j_i$ by $j$-th participant and $i$-th sample. Each data $\mathbb{X}^j$ contains $T^j$ number of samples \{$x^j_1$, ..., $x^j_{T^{j}}$\}. Each $x^j_i$ is comprised of 3-axis of accelerometer data ($A^x, A^y, A^z$) and 3-axis of gyroscope data ($G^x, G^y, G^z$). Our model outputs a similarity score $s$.



We further divide our problem into three folds for three metrics: 

% Assuming there are $n$ repetitions in $N$, 

(1) Our problem input is $x^j_i$ and output is a set of $X' = \{x'\}$ with $x'$ represents one repetition and $n$ represents total repetitions. 


(2) In \textit{range of motion} metrics, we divide it into an absolute and relative value. First, we formalize our problem under the same problem of input sensory data, $x' \in \mathbb{X}^j_i$. In absolute value, for each $x'$, we define $y_{rom}(x')$ as the absolute score of \textit{range of motion}. Secondly, in relative value, we define the relative value, $s_{rom}(x'_i, x'_{i*})$, as similarity score under \textit{range of motion} metrics, where $i*$ is the anchor exercise's index.



(3) For $x' \in \mathbb{X}^j_i$, We define the relative value, $s_{stability}(x'_i, x'_{i*})$, as similarity score of \textit{stability} metrics.


%. After pre-segmented the exercises by repetitions with length $N$, we pad each divided exercise by its maximum length to $N'$. As a result, with the ground truth labels $y$ of $rom^j_i$ and $instability^j_i$, we use 3-axis of accelerometer data ($A^x, A^y, A^z$) and 3-axis of gyroscope data ($G^x, G^y, G^z$) as our input, denoted $N' \times 6$, shown in Fig. \ref{fig:ExerciseMetrics}. 

% divide into three problem, formalize sub-problems repetition, range of motion, and stability$

% \change{
% In the similarity comparison problem, let us define $X^* \in \mathbb{X}^j_i$ to be the anchor exercise. We assume this is the perfect exercise performed by patient $j$ with label $Y^*$. We perform a statistical combination to review every scenario between signal $x^j_i$ (or $S_a$) and anchor exercise $x^{*j}_i$ (or $S_b$) with ground truth labels $y^j_i$ and $y^{*j}_i$, or $y_a$ and $y_b$.
% %absolute and relative: the sec problem: sub-first problem is absolute, and sub-second problem is relative.$
% %stability: third problem$
% Lastly, we have a classification problem with the input $x^j_i$, the ground truth labels $y$ of $rom^j_i$ and $instability^j_i$, as shown in Section \ref{sec:data collection}.
% }

% \change{
% Our objectives are two: first, we aim to use the labeled dataset $\mathbb{X}^j_i$ to compare against $X^* \in \mathbb{X}$ with the ground truth labels using our similarity metrics. Secondly, labeled dataset $\mathbb{X}^j_i$ should be a classification problem that branches out within the same model. We aim to make our model a definitive HAQR classifier and regressive improvement score system.
% }
\begin{figure}[t]
    \centering
    \includegraphics[scale=.5]{./Figures/structure_of_models.png}
    \caption{Overview of PhysiQ framework}
    % Structure of Data Collection and Analysis: This figure demonstrates an overall run through. First of all, we have users who perform exercises guided by our app, the app collects data through smartwatch, which later transfer into the smartphone. Smartphone has an internal model that is capable of analyzing the data and provide qualitative feedback to the users. At the same time, data from the smartphone is uploaded to the cloud for a close-up diagnostic and model updates.
    \label{fig:SystemStructure}
\end{figure}

% [TODO: update the figure "actor" to "participants", change "apple watch" to smart watch",  change the diagram (smart watch) -> (smart phone), put the app into the red box.
% [NOTE: 16 subject 90 ROM has a clean cut for figures!]
% preprocess is an action

% objects:: watch -> phone -> server 
% actions:: 

% pretrained model and continual model all happened in the server levels.

% hardware and software, two colors 
% actions on arrows
% actions on iPhone recommendation feedback. 

% actions to therapists/doctors from feedback

% We envisioned this system run in real scenarios
% ]

\subsection{Digitalizing Exercise Metrics and Ground Truth} % FIX THIS LABEL U MIGHT REFER SOME OTHER PLACES! 
\label{subsec:solution:digitalizingExerMetrics}
\label{subsec:data_collection:gt}


% [todo: 
% how do you know im done with one sessions to do server upload?
% design choice (frequency) -> how does your algorithm works? is there a dramatic change in signals for stopping the exercises? Give instructions? Ex: Keep App?
% ]

% ]
% quotation examples:
% "PT"
% ``PT'' 

% \change{We collect accelerometers of x, y, and z-axis ($A^x$, $A^y$, $A^z$) and gyroscope of x, y, and z-axis ($G^x$, $G^y$, $G^z$) data from built-in sensors in a smartwatch, sampling at $f_s$ = 50 Hz. Then, when users perform PT exercises in repetition, we segment the exercises into numbers of one repetition using our novel energy detection formula from accelerometer data. As a result, our input is represented as $B \times N' \times 6$, where $B$ is the batch size.} 
\subsubsection{Repetition}
We implement a novel energy function to segment the exercise's repetitions. We calculate the energy as shown below:
\begin{equation} E(i) = \frac{1}{f_s+1}\left(h(i) + \sum_{n=-T}^{T} \sqrt{h(n+i)}\right),  \mbox{where} \: f_s = 50 Hz, T = \frac{f_s \lambda N}{2000} 
\end{equation}

\begin{equation} h(i) = |A^x(i) * W^x| + |A^y(i)* W^y| + |A^z(i)* W^z|
\end{equation}
In the formula above, $i$ is the positional index to calculate the energy throughout the signals, and $N$ is the actual length of the signals in 10 repetitions. As shown in Fig. \ref{fig:energy}, we use this method of calculation to find the cutting position to semi-automatically segment the signal of 10 repetitions to the number of 1 repetition. Noted, since some exercises have a low and high amplitude signal, we use hyper-parameters $W^x, W^y, W^z$, and $\lambda$ weights to adjust the smoothness of the energy. The purpose of the energy is to merge two peaks from the previous and next repetition to form a significant energy level to identify the cutting position. As a result, good hyper-parameters are required to pre-process the segmentation of the data. 
% \change{\st{Moreover, we use our intuition to decide on the cutting point for segmentation because the cutting point might be at the maximum or the minimum.}}


\begin{figure}%
    \centering
    \subfloat[\centering Energy Plot with Accelerometer Data]
    {{\includegraphics[width=7cm, height=5cm]{Figures/segmentation0.png} }\label{fig:energy:a}}%
    \qquad
    \subfloat[\centering Potential Cutting Position with Energy Plot]
    {{\includegraphics[width=7cm, height=5cm]{Figures/segmentation1.png} }\label{fig:energy:b}}%
    \caption{These two figures show how the energy plot suggests the cutting positions for the repetition of 10 exercises. For Fig. \ref{fig:energy:a}, the energy is plotted in a red dashed line. The specialist manually does the exercises' beginning and ending cut-off procedure. In Fig. \ref{fig:energy:b}, we change the original data colors to black and emphasize the color of the cutting position for segmentation and energy plot for visualization purposes.}%
    \label{fig:energy}%
\end{figure}


% \begin{figure}[hbt!]
%     \centering
%     \includegraphics[scale=.5]{./Figures/10 segmentation.png}
%     \caption{In each exercise, we ask participants to perform 10 repetitions of each exercise. For example, we define 5 Range of Motion (ROMs) metrics for Shoulder Abduction, participants perform 10 repetition of all 5 ROM. We then segment the exercises based on each exercises ground truth of the signal's patterns.}
%     \label{10Exercises}
% \end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[scale=.5]{./Figures/Exercise_Metrics.png}
    \caption{Exercises Metrics: we first identify the type of exercise to perform and which sensory data is collected. Based on the signal data gathered from participants, we measure them against our metrics. The framework assesses the quality of exercises based on the \textit{range of motion}, \textit{stability}, and \textit{repetition}.}
    % \meiyi{remove the upper part}}
    \label{fig:ExerciseMetrics}
\end{figure}

\subsubsection{Range of Motion}
After using the energy method to segment the signal of participants' exercises, we annotate each exercise according to its labels and positions. In our case, we have three potential labels: \textit{range of motion}, \textit{stability}, and \textit{repetition}. We modify our method to generate \textit{stability} using Equation \ref{eq:gt-stb} as our ground truth for stability. \textit{Range of motion} metrics are collected through participants' exercises under the supervision of experimenters. We examine the participants' range of motion as they performed and verify with recorded videos. \textit{Repetition} is labeled based on the number of repetitions merged together. We target one particular exercise to build our framework and use two additional exercises to verify its competency: shoulder abduction (SA), external rotation (ER), and forward flexion (FF). We explain the process in Section \ref{sec:evaluation}. Due to different muscle activation of \textit{range of motion}, we examine shoulder abduction as our initial exercise to design our metrics and framework. Additionally, we classify shoulder exercises into two main categories: half arm span (HAS) and half-half arm span (HHAS). HAS contains exercises that require both forearm and arm into motion. HHAS only requires forearm or arm into motion.

In shoulder abduction exercise, it involves the glenohumeral joint and scapulothoracic articulation in different \textit{range of motion}. At first 20 to 30 degrees of motion, subjects do not use the scapulothoracic joint motion, and the supraspinatus tendon should be the only muscle helping during this. Deltoid muscles are activated to support from 30 to 120 degrees of range of motion. Lastly, beyond 120 degrees, a full abduction is considered when the arm is externally rotated with the humerus activating. Different range with different muscles activation inspires us to finalize five different \textit{range of motion} and \textit{stability} (we mentioned on how to create stability in Section \ref{sec:data collection}) as our categories to understand the quality of exercises with Fig. \ref{fig:shoulderjoint} \cite{muscle:shoulder, muscle:deltoid, muscle:serratusanterior, muscle:trapezius}.
\begin{figure}
    \centering
    \subfloat[\centering Shoulder anatomy, front view]
    {{\includegraphics[width=5cm]{Figures/muscle_shoulder_joint.png} }}%
    \qquad
    \subfloat[\centering Serratus anterior muscle]
    {{\includegraphics[width=5cm]{Figures/muscle_serratus_anterior.png} }}%
    \qquad
    \subfloat[\centering Deltoid muscle]
    {{\includegraphics[width=5cm]{Figures/muscle_deltoid.png} }}%
    \qquad
    \subfloat[\centering Trapezius muscle]
    {{\includegraphics[width=5cm]{Figures/muscle_trapezius.png} }}%
    \caption{This is a visualization of how shoulder with joints, tendons, and muscles work in a close look \cite{muscle:shoulder, muscle:deltoid, muscle:serratusanterior, muscle:trapezius}.}
    \label{fig:shoulderjoint}
\end{figure}

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=.5]{Figures/SiameseNetwork3.png}
    \caption{Multi-task Spatio-temporal SNN: First of all, we have 2 one repetition exercises feed into our network as signal and anchor exercise. Signal exercise can be compared against anchor and vice versa. After Sliding Windows Segmentation, Spatial and Temporal encoding, we feed our model into an attention mechanism. Finally, we compare these two hidden features representation and output its similarity score using cosine similarity. Additionally, the hidden feature of the signal exercise is processed into a MLP network to get result of classification based on the metrics of \textit{range of motion}, \textit{stability}, or \textit{repetition}.}
    \label{fig:SiameseNetwork}
\end{figure}

\noindent\textit{Range of Motion for HAS Exercise Muscular Activation }
\begin{itemize}
    \item 30 degree ROM: supraspinatus muscles 
    \item 60 degree ROM: deltoid muscles
    \item 90 degree ROM: deltoid muscles, transition to trapezius muscle
    \item 120 degree ROM: trapezius and serratus anterior muscle
    \item 150 degree ROM: trapezius, serratus anterior muscle, and humerus activation
\end{itemize}


In external rotation exercise, the rotator cuff is used to perform this exercise. The rotator cuff consists of four muscles that stabilize the shoulder in external rotation, infraspinatus, teres minor, supraspinatus, and subscapularis as shown in Fig. \ref{fig:shoulderjoint}. As in external rotation, the infraspinatus muscle stabilizes the shoulder joint and acts as the prime mover in this exercise \cite{jang2014changes}.


\noindent\textit{Range of Motion for HHAS Exercise Muscular Activation}
\begin{itemize}
    \item 45 degree ROM: minimally infraspinatus muscle
    \item 90 degree ROM: infraspinatus muscle, posterior deltoid
    \item 150 degree ROM: infraspinatus muscle, posterior deltoid, and all other muscles in rotator cuff.
\end{itemize}


Similarly, in forward flexion exercise, the muscle activation includes supraspinatus, infraspinatus, and anterior deltoid. We classify \textit{range of motion} into 5 similarly to shoulder abduction because these two exercises are considered half arm span exercise. 


\subsubsection{Stability}
Initially, we defined our ground truth of stability using resistance bands relative to the participants' strength. For example, if the participant is strong, we progressively find his or her maximum strength with the resistance band and create two different instability based on that, labeled as two classes. However, this method does not guarantee that stability correlates with the levels of resistance bands. Furthermore, as we visualize and evaluate it, we do not find the difference between the two different resistance bands. Therefore, we define the stability metrics using a low pass filter and coefficient of variation through a mathematical methodology. By doing so, we can measure stability of all the exercises performed by participants. Low pass filter is used to differentiate what is human motion and signal noise since our IMU sensors captures at 50 Hz. As suggested by Khusainov et al., human activity frequencies are between 0 and 20 Hz, and 98\% are below 10 Hz \cite{khusainov2013real}. Therefore, for maximal capturing of stability, we use 20 Hz as our parameter for the low pass filter function.


\begin{equation} \label{eq:gt-stb}
instability(S) = Tanh\left(|\:CV(\mbox{lps}(S, \:\mbox{f=20}))\:|\right), \mbox{where} \: S = [A^x, A^y, A^z, G^x, G^y, G^z]\mbox{.T} \end{equation}
\begin{equation} \label{eq:gt-stb-sub1}
CV(S) = \frac{\mu_S}{\sigma_S} \end{equation}



In the formula above, the lps represents the trivial low pass filter function we used to filter some noises. 


\noindent\textit{Stability Muscular Activation}
\begin{itemize}
    \item 0.0 stability: stable and perform normal exercises
    \item in-between 0.0-1.0 stability: rotator cuff
    \item 1.0 stability: (unstable) supraspinatus, infraspinatus, teres minor, and subscapularis 
\end{itemize}


% \footnotetext{https://en.wikipedia.org/wiki/Shoulder}

\subsection{Spatio-temporal Feature Representation}

% \begin{figure}[hbt!]
%     \centering
%     \includegraphics[scale=.5]{Figures/SiameseNetwork3.png}
%     \caption{Multi-task Spatio-temporal SNN: First of all, we have 2 one repetition exercises feed into our network as signal and anchor exercise. Signal exercise can be compared against anchor and vice versa. After Sliding Windows Segmentation, Spatial and Temporal encoding, we feed our model into an attention mechanism. Finally, we compare these two hidden features representation and output its similarity score using cosine similarity. Additionally, the hidden feature of the signal exercise is processed into a MLP network to get result of classification based on the metrics of \textit{range of motion}\change{, \textit{stability}, or \textit{repetition}.}}
%     \label{fig:SiameseNetwork}
% \end{figure}
% \subsubsection{Neural Network Architecture}. 
% \meiyi{formula}\david{figure 6 should be in the beging of this section, maybe talk about spatiotemporal first then talk about it separately.}

As shown in Fig. \ref{fig:SiameseNetwork}, we develop a method of combining spatial and temporal representation to recognize the shape of signals of exercises \cite{murahari2018attention, chen2019multi, bhattacharya2020step, peng2018aroma}. We use the attention mechanism as a method of message passing to understand relationships in different hidden features of sliding window segments in one repetition. 

To discern and recognize the details of the signals and find the correlation between metrics and exercises, we tackle the problem in two different aspects: time and space. The exercises performed by users are the input of temporal signals. The signals result in a pattern in space to depict different angles of the exercises. 
% We determine best algorithms for temporal and spatial problems are Convolutional Neural Network (CNN/ConvNet) and Long Short-Term Memory (LSTM), respectively. 

We build a CNN-based spatial encoder as: 

\begin{equation}
    CNN(w) = (\sigma(sum(W_1 \odot  w) + b_1), \ldots, \sigma(sum(W_n \odot w ) + b_n)),
\end{equation}
where $W_1, W_2, \ldots, W_n$ are learnable weights matrices, $b_1, b_2, \ldots, b_n$ are biases, $\odot$ is element-wise multiplication, $sum$ is element-wise summation, and $\sigma$ is the activation function such as ReLu. CNN is capable of effectively interpreting spatial information and transforming it into a hidden pattern. It has the potential to compress information to represent into a smaller space, and it is very effective to compress sliding windows of signals. This provides a feature extraction mechanism across windows with specific weight matrices and biases. What is important in spatial encoding is by using a feature extraction method, our model can interpret the importance of each window given its features. 
Additionally, a max pooling is applied in our CNN model to reduce the signal's dimension.

However, understanding the features in each window is not enough to distinguish any temporal knowledge due to the property of time series, such as trends, and seasonal or non-seasonal cycles. Next, we employ Long Short Term Memory networks (LSTM) for temporal encoding as \cite{hochreiter1997long}:
% , a special kind of recurrent neural networks (RNN) that uses gates to decide the importance of information, is implemented with the following steps:
% \vspace{2mm}

\begin{equation}
    f_t = \sigma(W_f  x_t + U_f h_{t-1} + b_f)
\end{equation}
\begin{equation}
    i_t = \sigma(W_i  x_t + U_i h_{t-1} + b_i)
\end{equation}
\begin{equation}
    o_t = \sigma(W_o x_t + U_o h_{t-1} + b_o)
\end{equation}
\begin{equation}
    \tilde{c_t} = tanh(W_c x_t + U_c h_{t-1} + b_c)
\end{equation}
\begin{equation}
    c_t = f_t c_{t-1} + i_t \tilde{c_t}
\end{equation}
\begin{equation}
    h^r_t = o_t tanh(c_t),
\end{equation}

where, $U$ $W$, and $b$ are weights and biases that is not time dependent, $\sigma$ is a sigmoid activation function, and $i$,$f$,$o$ are input, forget, and output gates respectively. Lastly, $c$ and $h$ are the cell and hidden states vector given the time $t$.

Next, attention mechanism on a set of queries, keys of dimension $d_k$, and values are calculated using the matrix of output as shown below:

\begin{equation}
    Attention(Q, K, V) = softmax\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\end{equation}

Instead of performing one attention function, we apply multi-head attention where head is the number of paralleled attention mechanism. Multi-head attention allows our model to attend information with different representation at different locations in time and space. We use $H$ as the number of head in multi-head attention:

\begin{equation}
    MultiHead(Q, K, V) = concat(head_1,\ldots, head_h)W^O
\end{equation}
\begin{equation}
    head_i = Attention (QW_i^Q, KW_i^K, VW_i^V)
\end{equation}

In our work, we use $H$ = 16 heads of paralleled attention layers. Additionally, we use $d_{model}$ = 256; therefore, each $d_k = d_v = d_{model}/H = 16$.


As a result, we describe our model, PhysiQ. It takes advantage of the fact that every sliding windows $w$ of size $k$ x 6 can be interpreted as a frame in time. Using this, we feed each window $w$ into the CNN to output $h^c$ as $z^c$ x 1. Additionally, we feed $h^c$ into LSTM to get $h^r$ with a size of $z^r$ x 1. The LSTM creates a sequence of hidden states $[h^r_0, \ldots, h^r_n]$, acted similar to a positional encoding to understand the temporal information. We pass the sequence into the attention mechanism returning our hidden representation, $A$ that has both temporal spatial information, and relational message passing knowledge. 
% \begin{figure}[hbt!]
%     \centering
%     \includegraphics[scale=.7]{Figures/LSTM cell.png}
%     \caption{This is an illustration of how LSTM works. With its current input $x_t$ and previous $h_{t-1}$, $c_{t-1}$, a current output $o_t$ is generated with $h_t$, $c_t$}
%     \label{fig:LSTMCell}
% \end{figure}

\begin{algorithm}
	\caption{PhysiQ Framework Encoder} 
	\begin{algorithmic}[1]
	\STATE {Def: $A = ENCODER(e)$, s.t. exercise segment $e$ passes in, return $A$, where $A$ has $n$ number of hidden presentation as $h^r_0, \ldots, h^r_{n-1}$}
    \STATE \textbf{Input}: $e$, exercise segment
    \STATE \textbf{Output}: $A$, hidden representation of one exercise segment
        % \State $w_i  \subseteq 0,1, \ldots, n$ //
        \STATE ${w_0, w_1, \ldots, w_{n-1}}= SLIDE(e)$    \\ $SLIDE$ takes an exercise $e$ and return $W$, where $W$ is the size of $n$ x $k$ x 6, $n$ number of sliding windows.
        \STATE $W = {w_0, w_1, \ldots, w_{n-1}}$
        % \State 
	    \FOR {each $w_i$ in $W$}
	        
	        \STATE $h^c_i = CNN(w_i)$
	        \STATE $h^r_i = LSTM(h^c_i)$
	    \ENDFOR
	    \STATE $H=[h^r_0,h^r_1, \ldots,h^r_{n-1}]$
        \STATE $A = Attention(H, H, H)$
        \STATE return $A$

	\end{algorithmic} 
	\label{algo:encoder}
\end{algorithm}

\begin{algorithm}
	\caption{PhysiQ Similarity Comparison} 
	\begin{algorithmic}[1]
	\STATE {Def: $s_{ij} = SIMILARITY(e_i, e_j)$, where $s$ is the similarity score and $e$ is the signal segment}
    \STATE \textbf{Input}: $e_i, e_j$, a pair of exercise segments
    \STATE \textbf{Output}: $s_{ij}$ is the similarity score between a pair of exercises 
    % \meiyi{what's the output? score? }
    
    \STATE $A_i = ENCODER(e_i)$
    \STATE $A_j = ENCODER(e_j)$
    \STATE $ s_{ij} = Cosine(A_i, A_j) = A_i \cdot A_j / ||A_i|| * ||A_j||$ 
    % \meiyi{``is'' is not a formal description in alg.}
    \STATE return $s_{ij}$ 
    % \meiyi{do you return score? then why MLP(score)? }
	\end{algorithmic} 
\end{algorithm}


% [TODO: 
% raw from total repetition to 1 repetition.
% siamese..

% show back-propagation 

% repetiton formula, stability formula, 

% Siamese section more and more and more!

% Simaese Modules.
% ]

\subsection{Similarity Comparison}
%We give a real number to compare it 
The supervised learning framework has recently improved dramatically on 1-D and 2-D healthcare signal processing tasks. However, it does not leverage the framework to understand the relationship between the inputs. Significantly, how can patients improve without an anchor comparison from the previous performance? By comparing their day-to-day performance, PhysiQ understands whether participants enhance their performance based on the result of their exercises and how the patients are improving. To address this issue, we utilize the Siamese Neural Network, a type of contrastive learning framework that can extract useful features from data itself without the need for large handcrafted labels. On top of that, we design a data collection strategy to gather multi-modality of data for future evaluation analysis.


Siamese Neural Network (SNN) is a neural network that shares and contains two identical networks with the same configuration and the sharing of the weights. The identical model is used to find the similarity between two inputs. At the same time, the advantages of the SNN are more robust to the class imbalance in the data, learning a tremendous hidden and embedding deeply semantic similarity; however, it does not necessarily output probabilities but the distance between classes. We re-design the network and make it to fit the problem of reference comparison in Fig. \ref{fig:ExerciseMetrics}. We formulate a regressive distance between two exercises as the ground truth label to train SNN with a prior assumption of a maximum of the \textit{range of motion} of $R$ in shoulder abduction, as shown below:

\begin{equation}\label{eq:rom}
s_{rom}(m_a, m_b) = 1 - |\frac{m_a}{R} - \frac{m_b}{R}| \end{equation}


With the Equation \ref{eq:gt-stb} to get the signal's \textit{stability}, we can measure the similarity:

\begin{equation} \label{eq:stb}
s_{stability}(S_a, S_b) = 1 - |instability(S_b) - instability(S_b)| \end{equation}
%, \mbox{where } I_a = instability(S_b), \: I_b = instability(S_b)



Lastly, with the assumption of maximum of repetition $M$, we can measure the similarity of \textit{repetition}:
\begin{equation}
    s_{repetition}(r_a, r_b) = 1 - |\frac{r_a}{M} - \frac{r_b}{M}|,
\end{equation}
where $r_a$, $r_b$ represent the number of repetition of signal and anchor exercise.

% Similarly with \textit{repetition}, assuming the maximum of repetitions is 5: \david{repetition needs to  re-consider with our algorithms!}

% \begin{equation} D(i) = 1 - |\frac{y_a}{5} - \frac{y_b}{5}| \end{equation}

The SNN is very popular and used to solve various problems in research. However, to accommodate our specific problem, we aim to improve our accuracy by carefully designing our feature extraction in spatial and temporal aspects. Therefore, 
% encouraged and inspired by the tremendous success of the NLP, HAR, and sleep quality, 
we adapt the SNN for our signal comparison because there is an underlying knowledge and information that the deep learning method interprets and understands. Additionally, we leverage the temporal encoding, spatial encoding, and attention mechanism to generalize the model with our metrics. Additionally, we use cosine similarity as our similarity measurement because of its ability to differentiate orientation distance between two encoded exercise features.


% There are four main techniques: local connections, parameter sharing, pooling, and multi-layers. Local connections is a method to connect to pixel values in the input images using filters and stride, a local focus to de-sample the information from the image and extract it as hidden features to channels. Parameter sharing is to use to same weights across the images when we convolve the features. These parameters can be adjusted through the process of backpropagation and gradient descent. Pooling, also known as downsampling, is a method to dimensionally reduce the number of parameters in the input; this method is also referred as invariant transformation. Lastly a multi-layers method is used to increase the complexity of the model and further improve the deep neural network to learn more complex tasks. One key point is that stacking of convolutional layers does not prohibit the hierarchical decomposition of the input but helps to classify complex tasks in various setting. A sophisticated augmentation, also known as equivariant transformation, usually applies to further complex the dataset, such as rotation, scale, shift, etc. As a result, CNN is really helpful in understanding the spatial information. In our problem, CNN model should comprehend the overall signals' amplitude, frequency, and pattern in a large-scale approach. However, spatial information does not resolve the problem inclusively. Information regarding time is still not included as part of the network. In CNN, spatial information is processed in a way that the model assume it has all the signal data. But in reality, this might not be true, and this is why we also need to introduce recurrent neural network.


