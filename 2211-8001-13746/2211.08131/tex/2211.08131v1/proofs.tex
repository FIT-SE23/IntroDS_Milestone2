\begin{proof}[Proof of Proposition \ref{prop1}]
Remark that one can rewrite 
\[
\mathbb{E}_{\theta^{*}} \left[ G_{2}(m)  \right] = \mathbb{E}_{\theta^{*}} \left[ \sum_{k=1}^{K} \mathbf{1}_{Z=k}  \left\| X - m_{k} \right\|   \right] 
\]
and this function is Frechet-differentiable with 
\[
\nabla_{m_{k}} \mathbb{E}_{\theta^{*}} \left[ G_{2}(m)  \right] = - \mathbf{E}_{\theta^{*}} \left[   \frac{X - m_{k}}{\left\| X - m_{k} \right\|} \mathbf{1}_{Z=k}   \right] .
\]
and the zero of the gradient of $G_{2}$ correspond to the median of the classes.
Since $X |Z =k$ is symmetric, one has $\nabla_{m_{k}}\mathbb{E}_{\theta^{*}} \left[G_{2} \left( \mu_{k}^{*} \right) \right] = 0$, i.e $\mu_{k}^{*} = m_{k}^{*}$. In a same way, one has
\begin{align*}
\nabla_{V_{k}} \mathbb{E}_{\theta^{*}} \left[ G_{3}(V) \right]  & = - \mathbb{E}_{\theta^{*}} \left[  \frac{\left( X - m_{k}^{*} \right)\left( X - m_{k}^{*} \right)^{T} - V}{\left\|   \left( X - m_{k}^{*} \right)\left( X - m_{k}^{*} \right)^{T} - V  \right\|_{F} }  \mathbf{1}_{Z = k} \right] 
\end{align*}
and the zero of the gradient correspond to the MCM of the class $V_{k}^{*}$. Then, since $X|Z =k$ is symmetric,  the zero of the gradient satisfies $\Sigma_{k}^{*} = \Psi \left( V_{k}^{*} \right)$.
\end{proof}


\begin{proof}[Proof of Proposition \ref{prop:fixpoint}]

Since $\pi^{*}$ is a zero of the gradient of the Lagrangian, one has $\pi_{k}^{*} = \mathbb{E}\left[ \tau_{k}(X) \right]$, i.e one has $\pi^{*} = g_{1}\left( \pi^{*} \right)$. In a same way, $m_{k}^{*}$ is a zero of $\nabla_{m_{k}} G_{2} $, where $\nabla_{m_{k}}$ denotes the partial gradient with respect to $m_{k}$. Furthermore,
\begin{align*}
\nabla_{m_{k}}G_{2}(m) & = - \mathbb{E}\left[ \tau_{k}(X)\frac{\left( X - m_{k} \right)}{\left\| X - m_{k} \right\|  } \right] = 0  & 
& \Leftrightarrow & 
\mathbb{E}\left[ \tau_{k}(X) \frac{X}{\left\| X - m_{k} \right\|} \right] 
& = m_{k} \mathbb{E}\left[ \tau_{k}(X) \frac{1}{\left\| X - m_{k} \right\|} \right] \\
& & & \Leftrightarrow & 
m_{k} & = g_{2,k}\left( m_{k} \right) ,
\end{align*}
and in a particular case, $m^{*}$ is a minimizer of $G_{2}$ if and only if $m^{*} = g_{2}\left( m^{*} \right)$.
In a same way, denoting by $\nabla_{V_{k}}$ the gradient of $G_{3}$ with respect to $V_{k}$, one has
\begin{align*}
0 = \nabla_{V_{k}}G_{3}(m^{*},V) & = - \mathbb{E}\left[ \tau_{k}(X) \frac{\left( X - m_{k}^{*} \right) \left( X - m_{k}^{*} \right) - V_{k}}{\left\| \left( X - m_{k}^{*} \right) \left( X - m_{k}^{*} \right) - V_{k} \right\|_{F} }\right]  \\
\Leftrightarrow \quad \mathbb{E}\left[ \tau_{k}(X) \frac{\left( X - m_{k}^{*} \right) \left( X - m_{k}^{*} \right) }{\left\| \left( X - m_{k}^{*} \right) \left( X - m_{k}^{*} \right) - V_{k} \right\|_{F}} \right] & = V_{k} \mathbb{E}\left[ \tau_{k}(X) \frac{1}{\left\| \left( X - m_{k}^{*} \right) \left( X - m_{k}^{*} \right) - V_{k} \right\|_{F}} \right] ,
\end{align*}
which concludes the proof.

\end{proof}
