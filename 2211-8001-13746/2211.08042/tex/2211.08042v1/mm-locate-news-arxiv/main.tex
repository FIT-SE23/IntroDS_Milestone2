%%%%%%%%%%%%%%%%%%%% author.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample root file for your "contribution" to a proceedings volume
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%% Springer %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass{svproc}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{siunitx}
\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont
\usepackage{pbox}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\usepackage{caption}
\usepackage{hyperref}
%
% RECOMMENDED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\let\OLDthebibliography\thebibliography
\renewcommand\thebibliography[1]{
  \OLDthebibliography{#1}
  \setlength{\parskip}{0pt}
  \setlength{\itemsep}{0pt plus 0.3ex}
}

% to typeset URLs, URIs, and DOIs
\usepackage{url}
\def\UrlFont{\rmfamily}

\begin{document}
\mainmatter              % start of a contribution
%
\title{MM-Locate-News: Multimodal Focus Location Estimation in News}
%
\titlerunning{MM-Locate-News: Multimodal Focus Location Estimation in News}

\newcommand\orcid[1]{\href{https://orcid.org/#1}{\includegraphics[height=\fontcharht\font`A]{images/ORCID_iD}}}

\author{Golsa Tahmasebzadeh\inst{1,2}\orcid{0000-0003-1084-5552} \and  
Eric M\"uller-Budack\inst{1,2}\orcid{0000-0002-6802-1241} \and 
Sherzod Hakimov\inst{3}\orcid{0000-0002-7421-6213} \and
Ralph Ewerth\inst{1,2}\orcid{0000-0003-0918-6297}}
%
\authorrunning{G. Tahmasebzadeh et al.}
\institute{TIB--Leibniz Information Centre for Science and Technology, Hannover, Germany \and
L3S Research Center, Leibniz University Hannover, Germany
\and
University of Postdam, Germany \\
\email{\{golsa.tahmasebzadeh, eric.mueller, ralph.ewerth\}@tib.eu, sherzod.hakimov@uni-potsdam.de}}


%
% \author{First Author\inst{1}\orcidID{0000-1111-2222-3333} \and
% Second Author\inst{2,3}\orcidID{1111-2222-3333-4444} \and
% Third Author\inst{3}\orcidID{2222--3333-4444-5555}}
% %
% \authorrunning{F. Author et al.}
% % First names are abbreviated in the running head.
% % If there are more than two authors, 'et al.' is used.
% %
% \institute{Princeton University, Princeton NJ 08544, USA \and
% Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany
% \email{lncs@springer.com}\\
% \url{http://www.springer.com/gp/computer-science/lncs} \and
% ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
% \email{\{abc,lncs\}@uni-heidelberg.de}}
% %


\maketitle              % typeset the title of the contribution

\begin{abstract}
The consumption of news has changed significantly as the Web has become the most influential medium for information. To analyze and contextualize the large amount of news published every day, the geographic focus of an article is an important aspect in order to enable content-based news retrieval. 
There are methods and datasets for geolocation estimation from text or photos, but they are typically considered as separate tasks. However, the photo might lack geographical cues and text can include multiple locations, making it challenging to recognize the focus location using a single modality. In this paper, a novel dataset called Multimodal Focus Location of News (MM-Locate-News) is introduced. We evaluate state-of-the-art methods on the new benchmark dataset and suggest novel models to predict the focus location of news using both textual and image content. The experimental results show that the multimodal model outperforms unimodal models. 
% features from a single modality. 

\keywords{% geolocation estimation, 
% geolocalization, 
multimodal geolocation estimation, news analytics, computer vision, natural language processing}
\end{abstract}
%
\section{Introduction}\label{sec:intro}
With the rapidly growing amount of information on the Web and social media, news articles are increasingly conveyed in multimodal form; apart from text, images and videos have become inseparable from news to report on events. 
Besides, there is an increasing research interest in the geographical content of news in fields like information retrieval or Web science. 
% The respective events in the news usually correspond to at least one location. These locations directly associated with an event are called \textit{focus} locations~\cite{profile}.
Although a news article might mention many locations it is important to determine the location of the main story. The concept of \textit{focus} location is a piece of metadata which indicates the geographic focus of a news article~\cite{clavin}. 
%In this paper, we extend the concept of focus location by defining some criteria to frame it in a multimodal setting where both image and body text of news have a role in specifying the focus location. 
The focus locations are vital, for instance, to identify the location of a natural disaster for crisis management or to analyse political or social events across the world.
Even if the news article focuses on one particular event, the text usually mentions various locations which are not the focus locations~(see Figure~\ref{fig:sample_outputs}b). 
On the other hand, a news image alone usually does not include sufficient geo-representative features to identify the focus location reliably~(see Figure~\ref{fig:sample_outputs}a).
Therefore, approaches for multimodal geolocation estimation are required to bridge these gaps. 

\begin{figure}[t]
% \small
% \captionsetup{font=footnotesize}
  \includegraphics[trim=0cm 0.2cm 0cm 0cm,clip,width=\textwidth]{images/mufl_1st_page.pdf}  \caption[width=0.5\textwidth]{  Samples from the MM-Locate-News dataset. (a) The proposed visual model fails due to lack of visual geo-representative clues. (b) The proposed textual model fails due to various locations in the text. In both cases, the combination of visual and textual features helps specify the correct location. Images are replaced with similar ones due to license restrictions.}
  \label{fig:sample_outputs}
\end{figure}


% approaches
% unimodal approaches
% 1-2 sentences per modality
% drawback: However, as mentioned before cases where there are not visual features, or too many locations in text where image could help specify -> In both cases, the combination of visual and textual features helps specify the correct location.
% Unfortunately, only few multimodal approaches
% details how they work
% Problem 1: do not make use of state-of-the-art approaches from text (BERT) and imageb (ISNs) or even multimodal transformers such as CLIP
% Although there are large-scale datasets for text-based geolocation estimation, they unfortunately do not provide the accompanying image. So far, there are only a few multimodal datasets labeled for locations. To the best of our knowledge, BreakingNews is the biggest dataset ... 
% Problem 2: no multimodal news datasets with high-quality focus location labels
% transition to "In this paper" section

% % approaches
% Most of previous approaches depend on either text \cite{clavin,mordecai,profile} or image~\cite{kim2017learned,hierarchical,mvmf}, and only a few methods are process multiple modalities~\cite{kordopatis2017geotagging,placing_language_model}.
% % text
% The majority of text-based approaches assign geo-coordinates to the focus location at the document level~\cite{clavin,mahali} and very few are based on events~\cite{mordecai,profile}. 
% % image
% While many image-based methods focus on certain environments such as cities~\cite{kim2017learned,DBLP:conf/eccv/GordoARL16}, only few proposals~\cite{hierarchical,DBLP:conf/cvpr/LinBH13,cplanet} treat geolocalization at global scale without any prior assumptions. To avoid bias, they typically subdivide the earth into geographical cells and predict the corresponding geographical cell for a given photo~\cite{hierarchical,cplanet}. All these approaches are essentially dependent on the landmark images hence not tailored for images in the news domain.
% % multimodal
% There are only a few multimodal approaches~\cite{kordopatis2017geotagging,placing_language_model,DBLP:conf/www/CrandallBHK09,breakingnews,DBLP:conf/sigir/SerdyukovMZ09}
% % most of which are based on the \textit{YFCC} dataset~\cite{yfcc100m} 
% most of which generate large-scale geographical language models based on global textual tag \cite{kordopatis2017geotagging,placing_language_model,DBLP:conf/sigir/SerdyukovMZ09}.
% % In the multimodal approaches usually one modality disambiguates the predicted location using the other modality.

% % datasets
% % text
% There are several datasets 
% Some of the datasets at the document level are Local-Global Lexicon (LGL)~\cite{lgl}, GeoVirus~\cite{geovirus} with news articles of disease outbreaks from WikiNews and GeoWebNews~\cite{GeoWebNews}.
% On the other hand, at the event level, there are very limited datasets like Atrocity Event Data~\cite{event_data} or a subset of political news from New York Times~\cite{profile}. Since these datasets do not provide the accompanying images, the multimodal focus location estimation is unachievable.
% % image?
% % multimodal
% Some of the relevant multimodal datasets are the \textit{MediaEval Placing Task} benchmark datasets~\cite{mediaeval2} that include images, videos, and metadata to estimate locations represented in multimedia. 
% Uzkent et al.~\cite{BurakEvan} propose another dataset that contains Wikipedia text combined with satellite images. 
% Another existing multimodal dataset is called Multiple Languages and Modalities (MLM)~\cite{mlm}, where images-text pairs are provided with the corresponding geo-coordinates from Wikidata~\cite{DBLP:journals/cacm/VrandecicK14}. 
% These datasets are not useful for multimodal focus location estimation in news because they do not address the complications of news articles such as multiple entities in the text or lack of geo-representative features in the images. 
% % Therefore, a multimodal dataset comprising news articles is required for the task.

% % Existing news datasets for focus geolocation estimation~\cite{lgl,geovirus} but do not include the news images along with text, making a multimodal approach not feasible. 
% BreakingNews~\cite{breakingnews} is one of the existing multimodal datasets that covers news domain. This dataset is comprised of images, text, captions of the images, and metadata such as geo-coordinates and popularity of the news. In this dataset, the geolocation labels are primarily extracted based on the RSS summary and, if not available, on heuristics such as the publisher location or story text~\cite{breakingnews}. The limiting factor with this dataset is that from the list of provided locations for each news article the focus location is not determined. that
% % So the motivation behind \textit{MM-Locate-News} dataset is to automatically generate the focus location labels based on the multimodal news content and then apply various post-processing steps to discard the samples with unreliable labels. 

% % As presented in Figure~\ref{fig:sample_outputs}~(a), news images may lack clues related to specific places, making it challenging to geolocalize directly. While the text is bound with various information about the image, for instance, named entities such as persons, locations, organizations, or events, most of this information might not be directly relevant to the corresponding image (see Figure.~\ref{fig:sample_outputs}~(b)). 

% As mentioned above, usually news images present limited visual geo-representative clues, on the other hand, body text of news entails excessive information about the news such as locations, person names or events which make it hard to predict the focus location directly based on either of the modalities.

% In this paper, we address the task of focus location estimation of news in a multimodal fashion. To this end, a weakly-supervised approach is proposed for the dataset collection. In contrast to previous approaches, the acquired dataset benefits from the multimodal content of news to label the corresponding focus locations. For the task of focus location estimation, a novel approach is presented where both the visual and textual content of news are integrated to highlight the multimodal context of news documents.

% approaches
Most of previous approaches for geolocation estimation depend on either text \cite{clavin,mordecai,profile,kulkarni2021multi} or image~\cite{mvmf,kim2017learned,hierarchical}.
% text
Text-based approaches assign geo-coordinates to the focus location at the document level~\cite{clavin,andogah2012every} or based on specific events~\cite{mordecai,profile}. 
% image
On the other hand, the majority of image-based methods focus on locating photos from certain environments such as cities~\cite{kim2017learned,DBLP:conf/eccv/GordoARL16}. In recent years, several deep learning approaches have been introduced for geolocation estimation at global scale without any prior assumptions~\cite{DBLP:conf/cvpr/LinBH13,hierarchical,cplanet,googlelandmarkdataset}.
% 
However, information from image and text are required for a more robust focus location estimation in multimodal news, as the examples in Figure~\ref{fig:sample_outputs} illustrate. But, so far, only a few methods have considered multiple modalities for geolocation estimation~\cite{kordopatis2017geotagging,placing_language_model}.
% details how they work
Overall, these methods suffer from two major limitations:
% Problem 1: 
(1)~They do not make use of recent multimodal transformer models~\cite{clip} or other unimodal state-of-the-art approaches to extract rich textual~(e.g., \cite{bert}) and visual information~(e.g., \cite{hierarchical});
% Problem 2: no multimodal news datasets with high-quality focus location labels
% unimodal
(2)~Although there are various large-scale datasets for text-based geolocation estimation of news at document level~(e.g., Local-Global Lexicon~(LGL)~\cite{lgl},  GeoVirus~\cite{geovirus}), or based on events~(e.g., Atrocity Event Data~\cite{event_data}, political news from New York Times~\cite{profile}), they do not provide the accompanying images and thus do not allow for multimodal focus location. 
% multimodal but not news-related

Some multimodal datasets, such as the \textit{MediaEval Placing Task} benchmark datasets~\cite{mediaeval2}, WikiSatNet~\cite{BurakEvan}, or \textit{Multiple Languages and Modalities (MLM)}~\cite{mlm}, contain image-text pairs with the corresponding geo-coordinates, but do not cover news articles and consequently do not address the related challenges such as multiple entities in the text or the lack of geo-representative features in the images.
%
To the best of our knowledge, \textit{BreakingNews}~\cite{breakingnews} is the biggest dataset of multimodal news articles with corresponding location information. However, the locations are primarily extracted based on the \textit{Rich Site Summary}~(RSS) and, if not available, on heuristics such as the publisher location or story text~\cite{breakingnews}. As a result, each document is provided with a number of potential locations that do not necessarily correspond to the focus location, are inaccurate, or even wrong in some cases. 
% transition to "In this paper" section
In summary, there is a clear need for multimodal datasets of news articles with image and text and high-quality focus location labels. In addition, a multimodal approach is required which benefits from state-of-the-art approaches to provide rich visual and textual features for news documents.

In this paper, we address the task of focus location estimation; specifically, we target the gap between lack of visual geo-representative clues in news images and multiple location mentions in the body text of news. 
% % addressing the dataset problem
% First, we present a weakly-supervised method for dataset collection. The acquired dataset addresses the drawbacks of previous dataset such as BreakingNews~\cite{breakingnews} as it considers the multimodal content of the news to label the corresponding location. Furthermore, test data with high-quality ground-truth labels are obtained from manual annotations. 
% % addressing the problem of multimodal approaches that do not make use of state-of-the-art 
% Next, we present a novel approach for multimodal location estimation in the news by integrating the multimodal interplay visual and textual content using features from state-of-the-art approaches. 
%
Our contributions are summarized as follows. 
% 
(1)~We present the \textit{MM-Locate-News (Multimodal Focus Location of News)} dataset that consists of \num{6395} news articles covering \num{237} cities and \num{152} countries across all continents as well as multiple domains such as \textit{health}, % \textit{business}, \textit{society}, \
\textit{environment}, and \textit{politics}. 
The dataset is collected in a weakly-supervised manner, and multiple data cleaning steps are applied to remove articles with potential inaccurate geolocation information. The acquired dataset addresses drawbacks of other datasets such as BreakingNews~\cite{breakingnews} as it considers multimodal content of news to label the corresponding location. 
Furthermore, we provide a test set of \num{591} manually annotated news articles. % \\
\noindent(2)~We propose several neural network models that, unlike previous work~\cite{kordopatis2017geotagging,placing_language_model,DBLP:conf/www/CrandallBHK09,breakingnews,DBLP:conf/sigir/SerdyukovMZ09}, exploit state-of-the-art image-based~\cite{hierarchical,zhouplaces}, text-based~\cite{bert}, and multimodal approaches~\cite{clip} to extract embeddings % to model the multimodal interplay 
for multimodal geolocation estimation of news. % \\
\noindent(3)~Experimental results and comparisons to existing solutions on the proposed dataset and on BreakingNews~\cite{breakingnews} demonstrate the feasibility of the proposed approach.
% \noindent(4)~We compare our proposed models against baselines provided by the BreakingNews~\cite{breakingnews} paper.

The remainder of the paper is structured as follows. Section~\ref{sec:mmg_news} describes the dataset acquisition, while the proposed model for multimodal geolocation estimation is presented in Section~\ref{sec:baseline_models}. We discuss the experimental results in Section~\ref{sec:results}. Section~\ref{sec:conc} concludes the paper and outlines potential directions for future work.




\section{MM-Locate-News Dataset}
\label{sec:mmg_news}
In this section, we present our novel dataset called \textit{Multimodal Focus Location of News (MM-Locate-News)}\footnote{Source code: \url{https://github.com/TIBHannover/mm-locate-news}}. % for multimodal focus location estimation of news. 
% 
As discussed in Section~\ref{sec:intro}, existing datasets for geolocation estimation are either not related to news~\cite{mediaeval2,BurakEvan,DBLP:journals/cacm/VrandecicK14}, do not provide images along with news texts~\cite{lgl,geovirus}, or contain unreliable labels for locations extracted from the news feed~\cite{breakingnews}.
In contrast, MM-Locate-News includes image-text pairs of news and the location focus at different geospatial resolutions, such as city, country, and continent. 
In the sequel, data collection and cleaning steps~(Figure~\ref{fig:data_collection}) as well as annotation process and dataset statistics are presented.

\begin{figure}[t]
% \small
\centering
  \includegraphics[width=0.8\linewidth]{images/data_collection.pdf}
  \caption{MM-Locate-News data collection and filtering steps.}
  \label{fig:data_collection}
\end{figure}


\textbf{Data Collection}: The dataset has been collected in a weakly-supervised fashion. To cover a variety of locations from all six continents, we extract all countries, capitals, highly populated cities~(minimum population of \num{500000}; minimum area of $200\,\textnormal{km}^2$), and medium populated cities~(population between \num{20000} and \num{500000}; area between $100\,\textnormal{km}^2$ and $200\,\textnormal{km}^2$) from Wikidata~\cite{DBLP:journals/cacm/VrandecicK14}. 
% Country and city labels are queried using the \textit{EventRegistry}\footnote{\url{http://eventregistry.org/}} API to match to events between 2016 and 2020 including the queried term in their title. 
% These events are defined by \textit{EventRegistry} as \textit{centroids} of news article clusters that correspond to the same event. 
For each location, we query \textit{EventRegistry}\footnote{\url{http://eventregistry.org/}} for events between 2016 and 2020 from the following categories: \textit{sports}, \textit{business}, \textit{environment}, \textit{society}, \textit{health}, and \textit{politics}. 
% 
Note that \textit{EventRegistry} automatically clusters news articles reporting on the same (or similar) events and that the news title of the cluster centroid represents the event name. To ensure the quality, we filter out events that do not include the location in their name or when their \textit{category relevance} and \textit{query relevance} scores, provided by \textit{EventRegistry}, are below the average scores of all events per query location. The intuition behind this step is that an event with a location mentioned in its name more likely provides news articles focusing on the queried location. 
% 
Finally, we extract all news articles from the remaining event clusters.


\textbf{Data Filtering}: We apply the following steps to remove irrelevant samples.\\
\noindent\textit{1) Named Entity -- Query Location Match:} We assume that an article is related to a query location if it is geographically close to at least one named entity. 
% Therefore, we extract the named entities using \emph{spaCy}~\cite{spacy} and use \textit{Wikifier}~\cite{wikifier} to link them to \textit{Wikidata} entities for disambiguation. 
%
Following related work~\cite{DBLP:journals/ijmir/Muller-BudackTD21}, we extract the named entities using \emph{spaCy}~\cite{spacy} and use \textit{Wikifier}~\cite{wikifier} to link them to \textit{Wikidata} for disambiguation. 
% 
We extract \textit{coordinate location}~(\textit{Wikidata Property P625}), which is available primarily for locations~(e.g., landmarks, cities, or countries). 
For persons, we extract the \textit{place of birth}~(\textit{Wikidata Property P19}) as they likely act in the respective country~(or even city). % 
We compute the Great Circle Distance~(GCD) between the geographical coordinates of the query location and the extracted entity locations.
%
We keep news articles that include at least one named entity whose GCD from the query location is smaller than $\sqrt[k]{a}$ where $a$ is the area~(\textit{Wikidata Property P2046}) of the query location, and $k$ is a hyperparameter as defined in Section~\ref{sec:results}.\\
%
\noindent\textit{2) Event -- News Article Distance:} Each news article in \textit{EventRegistry} is assigned a similarity measure that represents the closeness to an event. 
We discard articles with a lower similarity than the average similarity of all articles of the same cluster to keep the news articles that are most related to the respective event.\\
\noindent\textit{3) Redundancy Removal:} We compute the similarity between news articles using TF-IDF vectors (Term Frequency; Inverse Document Frequency) and discard one of the articles when the similarity is higher than \num{0.5} to remove redundancy.\\
\noindent\textit{4) Filtering of Rare Locations:} After applying the filtering step 1-3, we remove rare locations~(and corresponding articles) with less than five articles as they contain too few articles for training. % so that we have at least one article per location for the validation set.


\textbf{Dataset Statistics}:
In total, we queried \num{853} locations and extracted \num{13143} news articles. 
After the data cleaning steps, we end up with \num{6395} news articles for \num{389} locations (237 cities and 152 countries).
We divided the \emph{MM-Locate-News} dataset into train, validation and test data splits by equally distributing news articles among locations as given in Table~\ref{tab:data_world}, yielding approximately 80:10:10 splits (see Figure~\ref{fig:sample_outputs} for samples from the dataset).
% Among all continents, \textit{Asia}(35\%) and \textit{Europe}(30\%) have the most number of articles.


\begin{table}[t]
\begin{center}
% \captionsetup{font=footnotesize}
\parbox{.48\linewidth}{
\caption{Distribution of train, validation and test samples in MM-Locate-News among continents~(AF: Africa, SA: South America, EU: Europe, AS: Asia, NA: North America, OC: Oceania)}
\label{tab:data_world}
\resizebox{0.48\columnwidth}{!}{
\begin{tabular}{  l | c  c  c  c  c  c | c } \hline  
& \textbf{AF} & \textbf{SA} & \textbf{EU} & \textbf{AS} & \textbf{NA} & \textbf{OC} & \textbf{Total} \\ \hline  
\textbf{Train}& 854& 216& \num{1604}& \num{1842}& 589& 161& \num{5266} \\  
\textbf{Val}& 93& 24& 147& 160& 88& 23& 535 \\  
\textbf{Test}& 84& 29& 179& 202& 71& 26& 591 \\  \hline  
\end{tabular} 
}
}
\hfill
\parbox{.48\linewidth}{
\caption{Manual annotation criteria~(C) for the MM-Locate-News test set variants~(T). Answers “yes”, “no" or “unsure" are denoted as “-”, while “u" and “\cmark" denote “unsure" and “yes".}
\label{tab:test_data} 
\resizebox{0.48\columnwidth}{!}{
\begin{tabular}{  l |  c  c  c  c } \hline  
&  \textbf{T1} & \textbf{T2} & \textbf{T3} \\ \hline 
\textbf{C1:} Image depicts query location & - & \cmark& u \\  \hline
\textbf{C2:} Text focuses on query location & \cmark& \cmark& \cmark \\ 
\hline
\textbf{C3:} Image and text conceptually related& -& -& \cmark \\ \hline 
\textbf{Number of samples}& 591& 65& 154 \\  \hline  
\end{tabular} 
}
}
\end{center} 
% \vspace{-8mm}
\end{table}



\textbf{Data Annotation}: The test split of the dataset is manually annotated. Users annotated a given news article along with its image and the query location to provide “yes", “no", or “unsure" labels to three criteria~(\textit{C1 -- C3}) given in Table~\ref{tab:test_data}. Different criteria depending on the answers are turned into a different variant of the test data to evaluate the geolocation estimation models.
In the \textit{T1} version, the text focuses on the query location, and in the \textit{T2} both image and text represent the query location. Since it was difficult to find images where the query location is shown, we made the \textit{T3} version where the annotators were not certain about whether the image shows the location. Thus, in cases where the text focuses on the location and the image and text are related, we assume that the image also shows the location.


\textbf{Annotator Agreement}: A total of three users annotated the test set, where two users annotated each sample. % We selected samples where both agreed regarding the conditions for each test data variant. 
The inter-coder agreement for the criteria \textit{C1}, \textit{C2}, and \textit{C3} is \num{0.44}, \num{0.38}, and \num{0.55}, respectively (according to Krippendorff's alpha~\cite{krippendorff2011computing}).
Despite relatively moderate agreement scores, we noticed that the agreement in percent is  quite high: \textit{C2} and \textit{C3} are \num{80}\% and \textit{C1} is \num{66.6}\%. This is caused by the annnotators' bias towards the answer “yes" for all criteria.



\section{Multimodal Focus Location Estimation}\label{sec:baseline_models}

We define focus location estimation as a classification problem where for each article, i.e., image-text pair, the total number of $n$~query locations (country or city) are considered as target classes. 
%
The $n$-dimensional one-hot encoded ground truth vector~\mbox{$\mathbf{y} = \langle y_1, y_2, \dots , y_n \rangle \in \{0, 1\}^n$} represents the query location. 
%To solve the task, 
We extract textual and visual features as follows.


\textbf{Visual Features}: The visual \textit{Scene} descriptor (representing a place in a general sense) is based on ResNet-152 model~\cite{resnet} to recognize 365 places (pre-trained on the Places365 dataset~\cite{zhouplaces}). 
The \textit{Location} descriptor, $base(M, f^*)$, is taken from a state-of-the-art photo geolocation estimation approach~\cite{hierarchical}. 
The \textit{Object} descriptor utilizes the ResNet-152 model~\cite{resnet} pre-trained on the Image\-Net dataset~\cite{deng2009imagenet}. 
% Eventually, 
The \textit{CLIP$_i$} descriptor is extracted using CLIP (Contrastive Language-Image Pretraining)~\cite{clip} image encoder.
% that has been pre-trained on over 400 million image-text pairs. 

\textbf{Textual Features}: A pre-trained BERT~(Bidirectional Encoder Representations from Transformers)~\cite{bert} model is used to extract two distinct feature vectors. 
The first one represents the whole body text (BERT-Body), while the other refers to mentions of named entities and averages the individual word embeddings of all named entities (BERT-Entities).
% To include the frequency of named entities in the text, the 

\textbf{Multimodal Architecture}: As shown in Figure~\ref{fig:models}, the textual and visual embeddings are concatenated and passed to the fully connected (FC) layers with an output size of 1024, followed by a \textit{ReLU} layer. 
Next, the outputs are fed to another \textit{FC} layer followed by a $\tanh(u_i^l)$ layer. 
The norm function with clamp $\min=10^{-12}$ is applied to extract the visual~$\hat{\mathbf{y}}_v$ and textual vector~$\hat{\mathbf{y}}_t$ with size of $n=389$ (number of locations). 
We obtain the multimodal output~$\hat{\mathbf{y}}_m$ using the maximum probabilities of the visual~$\hat{\mathbf{y}}_v$ and textual~$\hat{\mathbf{y}}_t$ outputs.

%
\begin{figure}[t]
\centering
% \captionsetup{font=footnotesize}
% \small
  \includegraphics[width=0.9\linewidth]{images/models.pdf}
  \caption{The model architecture for multimodal focus location estimation in news.}
  \label{fig:models}
\end{figure}
%


\textbf{Network Optimization}:
During training, the models are optimized as follows. 
For unimodal models, the cross-entropy loss between the ground truth one-hot encoded vector~$\mathbf{y}$ to one~($\hat{\mathbf{y}}_v$ or $\hat{\mathbf{y}}_t$) is optimized. For multimodal models, the same procedure is applied, but on both vectors $\hat{\mathbf{y}}_v$ and $\hat{\mathbf{y}}_t$. 
We freeze the weights of the visual models during training.

\section{Experimental Setup and Results}\label{sec:results}
In this section, the evaluation setup~(Section~\ref{sec:eval_setup}) and experimental results including a comparison with state-of-the-art approaches on the \emph{MM-Locate-News}~(Section~\ref{sec:res_mufl}) and \textit{BreakingNews}~\cite{breakingnews}~(Section~\ref{sec:res_breakingnews}) datasets are reported.


\subsection{Evaluation Setup}
\label{sec:eval_setup}

\textbf{Evaluation Metrics}:
We use the geographical location of the class with highest probability in the network output~($\hat{\mathbf{y}}_v$, $\hat{\mathbf{y}}_t$, or $\hat{\mathbf{y}}_m$) as the prediction and measure the Great Circle Distance (GCD) to the ground truth location. 
%
As suggested by Hays and Efros~\cite{Hays2008}, the models are evaluated with respect to the percentage of samples predicted within different accuracy levels: \textit{city}, \textit{region}, \textit{country}, and \textit{continent} with maximum tolerable GCD to the ground location of \num{25}, \num{200}, \num{750}, and \num{2500} kilometers, respectively. 
% All models are tested on the \textit{T1}, \textit{T2}, and \textit{T3} variants of the dataset. 
For the evaluation on BreakingNews~(Section~\ref{sec:res_breakingnews}), we use mean and median GCD metrics as suggested by Ramisa et al.~\cite{breakingnews}.


\textbf{Hyperparameters}: % We use cross-entropy as an objective function with 
We use the Adam optimizer, learning rate of \num{e-4}, and batch size of \num{128} for optimization. We train the models for 500 epochs and perform validation after every epoch. The best model is used based on the highest mean accuracy in city and region GCD thresholds on the validation set. We set the parameter for data filtering to $k=\num{6}$ (Section~\ref{sec:mmg_news}) based on an empirical evaluation of a small subset (150 samples) of the dataset.

\textbf{Compared Systems}: We evaluate different combinations of the proposed model based on the feature modalities. We also compare against two popular text-based methods \textit{Cliff-clavin}~\cite{clavin}, \textit{Mordecai}~\cite{mordecai} and one image-based state-of-the-art model %for photo geolocalitzation 
(\textit{ISNs: Individual Scene Networks}~\cite{hierarchical}). % We evaluate the proposed models on the BreakingNews dataset regarless of the fact that the BreakingNews data samples are not labeled based on the focus locations. We would like to see if our proposed focus location estimation architectures obtain comparative results. The dataset includes \num{33376}, \num{11209}, and \num{10580} samples for train, validation, and test splits, respectively. In the original paper the geolocation estimation task is treated as a regression problem where the exact geo-coordinates are predicted. In order to be able to evaluate BreakingNews we map the provided geo-coordinates to all the city, country and continent classes in MM-Locate-News dataset.

\subsection{Experimental Results on MM-Locate-News}
\label{sec:res_mufl}
The results are reported in Table~\ref{table:eval} and %are discussed for each modality in the following.
discussed below.



\begin{table}[t]
\begin{center}
% \captionsetup{font=footnotesize}
\caption{Accuracy~[\%] of focus location estimates for Cliff-clavin~\cite{clavin}, Mordecai~\cite{mordecai}, ISNs~\cite{hierarchical} and baselines on different test variants of MM-Locate-News (best results for each modality is highlighted per GCD accuracy levels). Text features: BERT-Body (B-Bd), BERT-Entities (B-Et). Visual Features: Location (Lo), Object (Ob), Scene (Sc), CLIP$_i$. GCD accuracy levels: City (CI, max. 25\,km GCD to the ground truth location), Region (RE, max. 200\,km), Country (CR, max. 750\,km), Continent (CT, max. 2500\,km)}
\label{table:eval}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{  l | c | c  c  c  c | c  c  c  c | c  c  c  c } \hline 


&  &\multicolumn{4}{c|}{T1} & \multicolumn{4}{c|}{T2} & \multicolumn{4}{c}{T3}  \\
  \cline{3-14}
\textbf{Approach} &\textbf{Modality} & \textbf{CI} & \textbf{RE} & \textbf{CR} & \textbf{CT} & \textbf{CI} & \textbf{RE} & \textbf{CR} & \textbf{CT} & \textbf{CI} & \textbf{RE} & \textbf{CR} & \textbf{CT} \\ \hline 
Mordecai~\cite{mordecai} (only country-level)&Textual & - & - & \textbf{74.1} & 82.9 & - & - & 72.3 & 84.6 & - & - & \textbf{72.7} & 81.8 \\ 
Cliff-clavin~\cite{clavin} 
& Textual & 36.9 & 53.1 & 71.2 & \textbf{86.5} & 38.5 & 56.9 & 66.2 & 87.7 & 33.1 & \textbf{48.7} & \textbf{72.7} & \textbf{85.1} \\  
B-Bd &Textual & 22.8 & 27.4  & 41.1  & 68.4 &33.8 & 35.4  & 49.2  & 70.8 &19.5 & 23.4  & 40.9  & 63.6   \\
B-Et  &Textual &  \textbf{48.1} & \textbf{53.5}  & 66.3  & 79.5 &58.5 & \textbf{64.6}  & \textbf{75.4}  & 81.5 & \textbf{42.9} & 46.8  & 61.0  & 77.9  \\
B-Bd + B-Et &Textual &  42.5 & 47.9  & 60.4  & 78.5 & \textbf{60.0} & \textbf{64.6}  & 73.8  & \textbf{89.2} &37.0 & 41.6  & 53.2  & 71.4  \\  
\hline 

ISNs~\cite{hierarchical}&Visual & 2.5 & 4.4 & 12.0 & 31.0 & \textbf{16.9} & \textbf{26.2} & \textbf{40.0} & \textbf{55.4} & 0.6 & 1.9 & 7.8 & 29.9 \\
CLIP$_i$  &Visual & \textbf{4.6} & \textbf{6.3}  & \textbf{15.4}  & \textbf{41.1} &4.6 & 4.6  & 13.8  & 41.5 &5.2 & \textbf{8.4}  & \textbf{19.5}  & 42.2   \\
Lo + Ob  &Visual & 3.2 & 3.7  & 8.5  & 27.7 &10.8 & 10.8  & 13.8  & 27.7 &3.9 & 4.5  & 9.7  & 27.3    \\
Sc + Ob  &Visual & 1.2 & 1.5  & 6.4  & 20.6 &3.1 & 4.6  & 9.2  & 21.5 &1.9 & 2.6  & 9.1  & 26.0   \\
Lo + Sc  &Visual & 2.4 & 3.0  & 9.0  & 27.1 &6.2 & 6.2  & 12.3  & 33.8 &1.9 & 3.2  & 9.1  & 26.0 \\ 
Lo + Sc + Ob  &Visual  & 2.5 & 3.4  & 9.1  & 31.0 &7.7 & 7.7  & 13.8  & 30.8 &3.2 & 5.2  & 11.7  & 33.8  \\ 
Lo + CLIP$_i$  &Visual &  3.7 & 5.6  & 12.9  & 36.9 &4.6 & 7.7  & 13.8  & 41.5 &5.2 & 7.1  & 16.2  & 37.7  \\
Sc + CLIP$_i$  &Visual & 3.9 & 5.6  & 12.7  & 36.4 &3.1 & 4.6  & 13.8  & 44.6 & \textbf{5.8} & \textbf{8.4}  & 16.9  & 40.3 \\
Lo + Sc + CLIP$_i$ &Visual  & 2.5 & 3.7  & 10.5  & 33.8 &4.6 & 4.6  & 10.8  & 33.8 &3.2 & 5.2  & 11.7  & \textbf{43.5} \\ 
\hline

CLIP$_i$ + B-Bd + B-Et & Textual+Visual & 63.6 & 68.9  & 78.5  & 86.6 & 69.2 & \textbf{76.9}  & \textbf{84.6}  & \textbf{90.8} &61.0 & 64.9  & 74.7  & 81.8 \\
CLIP$_i$ + Lo + B-Bd + B-Et & Textual+Visual & 61.4 & 66.0  & 76.8  & 86.3 &66.2 & 70.8  & 81.5  & \textbf{90.8} &61.0 & 64.9  & 74.0  & 81.8\\
CLIP$_i$ + Sc + B-Bd + B-Et & Textual+Visual & 63.1 & 68.0  & 78.0  & 86.0 &63.1 & 67.7  & 76.9  & 86.2 & \textbf{63.6} & 68.8  & 77.3  & 83.8   \\
Lo + Sc + B-Bd + B-Et & Textual+Visual & 65.1 & 69.5  & 78.7  & 84.8 &70.8 & 75.4  & 81.5  & 86.2 & \textbf{63.6} & 68.2  & 77.9  & 80.5 \\
CLIP$_i$ + Lo + Sc + B-Bd + B-Et & Textual+Visual & \textbf{65.5} & \textbf{70.6}  & \textbf{81.2}  & \textbf{88.7} & \textbf{72.3} & \textbf{76.9}  & 83.1  & \textbf{90.8} & \textbf{63.6} & \textbf{69.5}  & \textbf{81.2}  & \textbf{85.7}  \\
\hline
\end{tabular}
}\end{center}
% \vspace{-8mm}
\end{table}



\textbf{Textual Models}: For smaller GCD thresholds specifically city and region, in \textit{T2}, the combination \textit{B-Et + B-Bd} improves the performance, and in \textit{T1} and \textit{T3} the \textit{B-Et} model provides the best results.
%
When used separately, \textit{B-Et} has a more substantial impact than \textit{B-Bd}, indicating that named entities and their frequency play a vital role to predict the focus location in the news.
%
% Regarding larger distance thresholds in \textit{T1} and \textit{T3}, \textit{Mordecai} at the country level and \textit{Cliff-clavin} at the continent level achieve the best results.
While \textit{Mordecai} and \textit{Cliff-clavin} achieve the best results at country and continent level for \textit{T1} and \textit{T3}, respectively, these baselines are either not applicable~(\textit{Mordecai}) or achieve worse results~(\textit{Cliff-clavin}) compared to our models on more fine-grained levels. 

\textbf{Visual Models}: 
%
The results show that \textit{CLIP$_i$} performs well in all test variants providing the best results on T1 and T3, and that combinations with scene~(\textit{Sc + CLIP$_i$}) and location features~(\textit{Lo + Sc + CLIP$_i$}) can further improve the results. ISNs specifically trained for photo geolocalization achieve superior results on \textit{T2} where images depict the query location and provide enough geographical cues. Unlike \textit{CLIP$_i$}, ISNs do not generalize well on other test variants.



\textbf{Multimodal Models}: 
The combination of \textit{CLIP$_i$} with multimodal information drastically improves the results compared to unimodal models in all test data variants and distance thresholds. %  except for larger distance thresholds in \textit{T2} where \textit{CLIP$_i$ + B-Bd + B-Et} shows better or equal performance.
%
Even though our visual models do not outperform \textit{ISNs} in \textit{T2}, they considerably improve the results when combined with textual features~(\textit{Lo + Sc + B-Bd + B-Et}). 
These results suggest that a multimodal architecture is beneficial for focus location estimation in news.



\begin{figure}[t]
% \small
% \captionsetup{font=footnotesize}
  \includegraphics[width=\textwidth]{images/qualitative_examples.pdf}  \caption{Sample outputs of the MM-Locate-News dataset. In the left column the multimodal model predicts the correct location but in the right column it fails. Images are replaced with similar ones due to license restrictions.}
  \label{fig:qualitative_examples}
\end{figure}
%
\textbf{Qualitative Results}:
%
Figure~\ref{fig:qualitative_examples} presents the sample outputs for different models. 
As expected, it is easier for the textual model to predict the correct focus location when there are multiple mentions of the ground truth location in the text (Figure~\ref{fig:qualitative_examples}-a.1), or person names related to the focus location such as Figure~\ref{fig:qualitative_examples}-a.2, which mentions \textit{Masis Mayilian} the forign minister of \textit{Artsakh}. 
However, the textual model fails when there are multiple locations (Figure~\ref{fig:qualitative_examples}-b.2) or person names (Figure~\ref{fig:qualitative_examples}-b.1) which are irrelevant to the focus location.
It is very challenging for the visual model to predict the correct focus location due to lack of visual geo-representative features in news images (Figure~\ref{fig:qualitative_examples}-a.1, \ref{fig:qualitative_examples}-c.2) specifically when the image is indoor (Figure~\ref{fig:qualitative_examples}-a.2). 
In contrast, the image sometimes provides rich content as displayed in Figure~\ref{fig:qualitative_examples}-b.1, which shows the sport competition mentioned in the text, or Figure~\ref{fig:qualitative_examples}-b.2 which illustrates the \textit{Comfort Women statue}, referring to \textit{Japan}.
The multimodal model fails when there are multiple mentions of irrelevant entities and the image lacks geo-representative features such as illustrated in  Figure~\ref{fig:qualitative_examples}-a.2.
In Figure~\ref{fig:qualitative_examples}-c.1, both unimodal models fail but the combination of visual and textual information helps the multimodal model succeed since the text is about the event shown in the picture which is related to the focus location \textit{Kenya}.
Another example is Figure~\ref{fig:qualitative_examples}-c.2, where the image contains scene information (Cricket field) but it does not provide visual information about the event (Cricket sport competition). 
Therefore, the multimodal model fails to predict the city \textit{Adelaide}, but it predicts the correct focus country \textit{Australia}. 
Even though the image provides rich visual features when combined with irrelevant locations in the text (e.g., \textit{South Korea}) the model gets confused.
% and predicts the wrong location. 
This demonstrates how much entities in text are important for multimodal focus location estimation. 
To sum up, the qualitative examples confirm the need for both image and text to predict the focus location of news.

 

% In Figure~\ref{fig:qualitative_examples} (a) left, the visual model fails due to lack of visual features. However, the textual and multimodal models succeed since there are multiple mentions of \textit{Japan}. In Figure~\ref{fig:qualitative_examples} (a) right, the multimodal model fails even though there are mentions of \textit{Artsakh} and \textit{Masis Mayilian} in the text. The textual and multimodal models fail because various entities appear in the text that is irrelevant to the focus location, such as \textit{Azerbaijan}. In Figure~\ref{fig:qualitative_examples} (b) left, although the focus location (\textit{Sri Lanka}) is also mentioned in the text, the textual model fails since there are various mentions of other entities such as \textit{Pakistan} or person names relevant to \textit{Pakistan} such as \textit{Abid Ali}. In Figure~\ref{fig:qualitative_examples} (b) left, the visual model succeeds. However, the textual model fails because of many irrelevant entities such as \textit{Babar Azim} or, more importantly, \textit{Pakistan}, which is the top 1 prediction. In the right sample, the multimodal model fails together with the textual model because of multiple mentions of \textit{South Korea} and other relevant entities to it, such as \textit{Choo Mi-ae} in the text, which confuse the models. However, the visual model succeeds because of the \textit{Comfort Women statue}, which refers to a particular location: \textit{Japan}. In Figure~\ref{fig:qualitative_examples} (c) both unimodal models fail. Although on the left side, the combination of visual and textual information helps the multimodal model succeed since the text talks about the activity shown in the picture related to the focus location: \textit{Kenya}. On the right side, all the models fail to predict the exact location since the image does not provide rich visual features, and the text includes many other irrelevant locations such as \textit{Pakistan} and \textit{England}. Nevertheless, the textual and multimodal models can predict the country of \textit{Adelaide}, which is \textit{Australia}. In general, the qualitative examples confirm the need for both image and text to predict the focus location of a news document.
%


\subsection{Experimental Results on BreakingNews}
\label{sec:res_breakingnews}
%
We also evaluate our proposed focus location estimation architectures on Breaking\-News~\cite{breakingnews} for comparison. We divide the dataset into \num{33376}, \num{11210}, and \num{10581} samples for train, validation, and test splits. 
However, please note that the quality of ground truth labels in Breaking\-News is much lower compared to our proposed MM-Locate-News dataset as the test data are not annotated manually for focus locations. 
For a better comparison to the approaches presented by Ramisa et al.~\cite{breakingnews}, we train a regression model by minimizing the GCD between the ground truth (the first geo-coordinate as mentioned in the original paper~\cite{breakingnews}) and the predicted geographical coordinates based on the various types of state-of-the-art visual and textual features presented in Section~\ref{sec:baseline_models}.
 
% To be able to evaluate on BreakingNews, we map the location~(city, country) in MM-Locate-News that is closest to the ground-truth geo-coordinates provided by Breaking\-News. 
% Then we fine-tune our models on the BreakingNews train set for a maximum of ten epochs using the hyperparameters mentioned in Section~\ref{sec:eval_setup}.
% We evaluate our model based on two setups. The first one is a zero-shot setting where the models trained on MM-Locate-News are directly tested on the BreakingNews. In the second configuration we fine-tune our models on the BreakingNews train set for a maximum of ten epochs. 
% (3) We trained a model from scratch on BreakingNews with the same hyperparamters~(Section~\ref{sec:eval_setup}). 
% (4) finetune but have regression as loss as done by BreakingNews


% \begin{table}[t]
% \begin{center}
% % \small
% \caption{Mean and median GCD (km) using the best models using different training procedures (MuFL $\rightarrow $ BN means that a model was first trained with MM-Locate-News and then fine-tuned on BreakingNews) per modality on the BreakingNews test set (mean and median values are divided by 1000). All the
% evaluations are in the city-level. }
% \label{tab:eval_breakingnews}

% \begin{tabular}{  l | l | c c  } \hline 

%   \textbf{Approach}  & \textbf{Training} & \textbf{Mean} & \textbf{Median}  \\ \hline
% % 
% % Lo + Sc  (zero-shot)  & MuFL & 7.81 & 6.51  \\ 
% % Lo + Sc          &  BN      & - & - \\ 
% % Lo + Sc          & MuFL $\rightarrow $ BN      & 4.76 & 3.74 \\  % epoch 510
% % \hline
% % CLIP$_i$  (zero-shot)  & MuFL & 7.44 & 7.13 \\ 
% CLIP$_i$          &  BN (regression)      & 2.84 & 1.29 \\  % epoch 20
% % CLIP$_i$         & MuFL $\rightarrow $ BN      & 3.77 & 2.39 \\  % epoch 510
% %
% % \hline
% % B-Bd  +  B-Et (zero-shot)  & MuFL & 7.56 &  7.44  \\ 
% B-Bd $\oplus$  B-Et         & BN (regression)     & 1.78 & 0.73 \\  %epoch 22
% % B-Bd  +  B-Et         & MuFL $\rightarrow $ BN    & 2.55 & 1.21\\  % epoch 510
% %
% % \hline
% % Lo + Sc + B-Bd + B-Et (zero-shot)  & MuFL & - & -  \\ 
% % Lo + Sc + B-Bd + B-Et (zero-shot)  & MuFL & 7.62 & 7.49  \\ 
% Lo + Sc + B-Bd + B-Et & BN (regression)     & 2.61 & 1.48 \\   
% % Lo + Sc + B-Bd + B-Et & MuFL $\rightarrow $ BN     & \textbf{2.48} & \textbf{1.14} \\ % epoch 510
% % 
% \hline
% \hline
% Places~\cite{breakingnews}  & BN   &     3.40 & \textbf{0.68}\\ 
% W2V matrix~\cite{breakingnews} & BN  &    1.92 & 0.90 \\ 
% VGG19 + Places +
% W2V~\cite{breakingnews} & BN &\textbf{1.91} & 0.88 \\ \hline
% \end{tabular}
% \end{center}
% \end{table}


\begin{table}[t]
\begin{center}
% \small
\caption{Mean and median GCD (km) using the best models per modality on the BreakingNews test set (mean and median values are divided by 1000).} % All the evaluations are based on city-level accuracy.}
\label{tab:eval_breakingnews}

\begin{tabular}{  l |  c c  } \hline 

\textbf{Approach}   & \textbf{Mean} & \textbf{Median}  \\ \hline

CLIP$_i$               &  2.84 & 1.3 \\ 
% CLIP$_i$ + Lo + Sc               & - & - \\ 
B-Bd +  B-Et    & 1.93 & 0.88 \\ 

CLIP$_i$  + Lo + Sc + B-Bd + B-Et  & \textbf{1.88} & \textbf{0.83} \\   
% 
\hline
\hline
Places~\cite{breakingnews}    &     3.40 & \textbf{0.68}\\ 
W2V matrix~\cite{breakingnews} &    1.92 & 0.90 \\ 
VGG19 + Places +
W2V~\cite{breakingnews}&\textbf{1.91} & 0.88 \\ \hline
\end{tabular}
\end{center}
\end{table}


Table~\ref{tab:eval_breakingnews} shows the comparison of the regression models provided by Ramisa et al.~\cite{breakingnews} with our approaches using Mean and Median GCD values (divided by 1000). 
%
From our proposed models, as expected the multimodal model \textit{CLIP$_i$ + Lo + Sc + B-Bd + B-Et} achieves the best performance. In comparison with \textit{VGG19 + Places + W2V matrix} from Ramisa et al.~\cite{breakingnews}, our model achieves better results with a difference of 30\,km and 50\,km in terms of mean and median GCD, respectively. 
Regarding the proposed unimodal models \textit{B-Bd +  B-Et} outperforms \textit{CLIP$_i$} in terms of both mean and median. 
The proposed textual model \textit{B-Bd + B-Et} achieves slightly better results in comparison with \textit{W2V matrix~\cite{breakingnews}} regarding the median value (with difference of 20\,km). 
Regarding the visual models, CLIP$_i$ outperforms Places~\cite{breakingnews} in terms of mean value by 560\,km. 
However, in terms of median value it is worse with a margin of 620\,km. 
This may be explained by more (bad) outlier predictions of the Places model. % the fact that some news articles provided by BreakingNews were not available anymore and therefore our models were trained with fewer samples compared to Ramisa et al.~\cite{breakingnews}. 
Overall, the results suggest that a multimodal architecture is beneficial for the task of location estimation in news.

% This can be explained by limited number of locations in MM-Locate-News and mapping the BreakingNews locations to them which adds noise to the results.


\section{Conclusion}
\label{sec:conc}
In this paper, we have introduced a novel dataset called \textit{MM-Locate-News}, which is a multimodal collection of image-text pairs for focus location estimation of news articles. 
A weakly-supervised method has been suggested to collect news with focus locations. 
We manually annotated the test data to acquire three different test data variants.
%
We have proposed various baselines and multimodal approaches using state-of-the-art transformer-based architectures for the task of focus location estimation.
The experimental results have shown that the combination of textual and visual features for geolocation estimation outperforms the compared approaches that rely on features from a single modality. 

In future work, we will extend the dataset by considering additional languages and locations. We will also investigate multimodal geolocation estimation on different news domains and apply further noise removal to the images.
\\
\\
\textbf{Acknowledgements.} This work was partially funded by the EU Horizon 2020 research and innovation program under the Marie Skłodowska-Curie grant agreement no.~812997 (CLEOPATRA ITN), and by the Ministry of Lower Saxony for Science and Culture (Responsible AI in digital society, project no.~51171145).

%
% ---- Bibliography ----

\bibliographystyle{splncs04}
\bibliography{references}

\end{document}
