%\vspace{-0.3cm}
\section{Discussion}
\label{sec:discussion}




\subsection{Ablation Study}
The proposed knowledge distillation methods mainly have three modules, including spatial-temporal distillation, the BEV embedding distillation, and the weight-inheriting scheme. Table~\ref{tab:nuscene} gives the ablation study of the three modules. It is observed that: (i) By simply using the weight-inheriting scheme without applying any knowledge distillation loss, 0.96 mAP and 1.99 NDS improvements can be obtained, indicating that the student detector can benefit from using the pre-trained weights from teachers on the BEV queries and positional encoding.
(ii) By applying BEV response distillation and weight-inheriting, 1.43 mAP and 2.56 NDS improvements can be observed, which are 0.47 and 0.57 higher than only using weight-inheriting, indicating BEV response distillation can successfully transfer teacher knowledge to the student.
(iii) 1.35 mAP and 2.41 NDS improvements can be obtained by using spatial-temporal distillation and weight-inheriting, which are 0.39 and 0.42 higher than only using weight-inheriting, indicating spatial-temporal distillation allows the student to learn how to fuse information from different timestamps and views from its teacher.
(iv) By combining the three modules together, 1.67 mAP and 2.58 NDS improvements can be obtained, which demonstrates that the benefits of spatial-temporal distillation and BEV response distillation are orthogonal. (v) By only using the two knowledge distillation while disabling the weight-inheriting scheme, 1.44 mAP and 2.07 NDS improvements can be observed, which are 0.58 and 0.71 lower than performing knowledge distillation with weight-inheriting, indicating weight-inheriting is also indispensable even if knowledge distillation losses are applied.
In summary, these experimental results demonstrate that the three modules in our method have their own effectiveness and their merits are orthogonal.
%(v) It is observed that our method can be utilized with the previous knowledge distillation methods to achieve further performance boosts. For instance, x mAP and x NDS improvements can be observed by combing our method with non-local distillation proposed by Zhang~\emph{et al.}. We argue that is because our method focuses on knowledge distillation on the fusion of information from different timesteps and views while previous methods mainly focus the knowledge distillation on the feature extract of single images. Hence, their performance improvements can be combined.
\vspace{-0.40cm}
\paragraph{Ablation on Weight-Inheriting}
To facilitate the training of the student model, some previous knowledge distillation methods propose initializing the parameters of the student with the parameters of the teacher (\emph{i.e.,}  initialization scheme), which sometimes leads to slight performance improvements. In contrast, the proposed weight-inheriting scheme in this paper not only initializes the parameters of BEV queries and positional encoding with their value from the teacher but also freezes them during the whole training period (\emph{i.e.,} weight-inheriting scheme). To study their difference, we have conducted several experiments and found that (i) By using the initialization scheme, after the training of the student, the parameters of BEV queries and positional encoding in the student are totally different from them in the teacher, indicating the inconsistency problem between the students and the teachers in knowledge distillation still exist. (ii) Experimental results show that by only using the traditional initialization scheme, the student detector (student-1 in Table~\ref{tab:stu_tea}) achieves 33.63 mAP and 44.70 NDS, which are 0.7 and 0.9 higher than the baseline, but still 0.89 and 1.90 lower than the weight-inheriting scheme. These observations indicate that using such a weight-inheriting scheme which exactly guarantees the consistency between the inputs of the students and teachers is indispensable.  

% \vspace{-0.40cm}
%\paragraph{Combining Our Method with Previous KD} As discussed in Section~\ref{sec:method}, since knowledge distillation on single images feature extraction has been well-studied, the proposed methods mainly focus on the information fusion stage in multi-view 3D detection. To further study the effectiveness of our method, we have combined our method with the previous distillation method from Zhang~\emph{et al,}. Experimental results show that the trained student (student-3 in Table~\ref{tab:stu_tea}) achieves x mAP and x NDS, which is x and x higher than only using the method from Zhang~\emph{et al,}, indicating that our method are orthogonal to previous methods.


%In this paragraph, we further study the effectiveness of the following several schemes: (a) \emph{teacher initialization}: using weights of teacher models for initialization. \emph{loss regularization}: using the $L_2$ loss between the weights from the student and the teacher as the regularization. The effectiveness of these schemes are shown in Table~\ref{}. It is observed that: ()




\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{detection_vis_camera-eps-converted-to.pdf}
    \vspace{-0.3cm}
    \caption{Visualization of detection results of images in different views. The color of boxes indicates the corresponding categories.}
    \vspace{-0.2cm}
    \label{fig:detection_vis_camera}
\end{figure}
\subsection{Visualization}
\paragraph{Detection Results}
Figure~\ref{fig:detection_vis_camera} and Figure~\ref{fig:bev_vis} 
visualize the detection results of the student detector trained without and with our method from the perspective of different camera views and bird-eye-view, respectively. Note that the used student detector has 6.4 FPS and 40.45M parameters.
It is observed that the student trained by our method produces impressive results which are similar to the ground truth. In contrast, the student trained without knowledge distillation generates incorrect predictions in the cameras of the front-left view, the front-view, and the front-right view. As shown in their BEV visualization, the mistakes made by the student trained without knowledge distillation have a relatively long distance from the car, indicating the student trained without knowledge distillation is unable to detect the faraway objects while our method can address this problem.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{bev_vis-eps-converted-to.pdf}
    %\vspace{-0.2cm}
    \caption{Visualization of detection results in BEV. Boxes in green and blue indicate the ground truth and the prediction results.}
    \vspace{-1em}
    \label{fig:bev_vis}
\end{figure}

\vspace{-0.30cm}
\paragraph{Attention Weights}
The proposed spatial-temporal distillation enables the student to learn teacher knowledge on information fusion by training it to mimic the attention weights in temporal self-attention and spatial cross-attention.
Figure~\ref{fig:bev_atten} gives the visualization results of attention weights from the teacher, the student trained with knowledge distillation and the student trained without knowledge distillation. It is observed that: (i) Compared with the student detectors, the attention weights from the teacher tend to concentrate more on several sampled points, indicating the teacher detector is able to leverage the information from certain images. (ii) Compared with the student trained without knowledge distillation, the attention weights from the student trained with knowledge distillation are more similar to the attention weights of the teacher, indicating that the spatial-temporal distillation successfully enables the student to approach the teacher detector.

\begin{figure}
    \centering
    \includegraphics[width=8cm]{attention_weight-eps-converted-to.pdf}
    \vspace{-0.3cm}
    \caption{Visualization of attention weights in temporal cross-attention from the teacher, the student trained with and without KD. A lighter pixel indicates a higher value.}
    \vspace{-0.2cm}
    \label{fig:bev_atten}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{response.png}
    \vspace{-0.6cm}
    \caption{Visualization of model response to different positions from Birds'-Eye-View and the corresponding detection results.}
    \vspace{-0.2cm}
    \label{fig:response}
\end{figure}

% \begin{figure}[htbp]	
% 	\subfigure[DogLeg Method] 
% 	{
% 		\begin{minipage}{6cm}
% 			\centering  V       
% 			\includegraphics[scale=0.4]{cvpr2023-author_kit-v1_1-1/latex/test_distill.jpg}   
% 		\end{minipage}
% 	}
% 	\subfigure[Steepest Descent Method] 
% 	{
% 		\begin{minipage}{7cm}
% 			\centering      
% 			\includegraphics[scale=0.4]{cvpr2023-author_kit-v1_1-1/latex/test_distill.jpg}   
% 		\end{minipage}
% 	}
% 	%\caption{name of the figure} 
% 	%\label{fig:1}
% \end{figure}


\vspace{-0.30cm}
\paragraph{BEV Response}
Figure~\ref{fig:response} shows the BEV response and the corresponding detection results from the student detector. Note that a lighter pixel in BEV response map indicates the detector has a higher response.
It is observed that the detector tends to show a higher response in the position where objects exist, indicating that BEV response contains valuable semantic information about the localization of objects. Hence, the proposed BEV response distillation can improve the ability of localization of the student detector by training it to imitate the BEV response from its teacher. 
