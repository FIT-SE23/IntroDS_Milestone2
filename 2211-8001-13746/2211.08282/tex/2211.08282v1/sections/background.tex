\section{Background}
\vspace{-1mm}
\label{sec:background}

\paragraph{Equivariance} 
The map $f: \gX  \rightarrow \gZ$ is said to be equivariant with respect to the group $\gG = (G, \cdot)$ if
\begin{equation}
\label{eqn:equivariance}
  \exists \Gamma_g \ \ \ \text{such that} \ \ \ \  f(T_g [\vx]) = \Gamma_g [f(\vx)] \ \ \ \ \forall g \in G\ ,
\end{equation}
where $G$ is the set of all group elements, $\cdot$ is the group operation, $T_g$ is the representation of the transformation $g \in G$ in input space $\gX$, and $\Gamma_g$ is the representation of the same transformation in output space $\gZ$. If $T_g$ and $\Gamma_g$ are formal group representations \cite{serre} such maps $f$ are termed group-homomorphisms since they can be seen to preserve the structure of the group in the output space.
There are many different methods for constructing group equivariant neural networks, resulting in different representations of the transformation in feature space $\Gamma_g$. In this work, we consider only discrete groups $\gG$ and networks which admit regular representations for $\Gamma$ (see Appendix \ref{appendix:C} for an example). Specifically, we denote the output of our network $f(\vx) = \vz \in \sR^{C \times |G|}$, where $C$ is the number of output channels. As a simple example, a standard convolutional layer would have all height ($H$) and width ($W$) spatial coordinates as the set $G$, giving $\vz \in \sR^{C \times HW}$. A group-equivariant neural network \cite{gcnn} which is equivariant with respect to the the group of all integer translations and 90-degree rotations ($p4$) would thus have a feature multiplicity four times larger ($\vz \in \sR^{C \times 4HW}$), since each spatial element is associated with the four distinct rotation elements $(0^o, 90^o, 180^o, 270^o)$. Such a rotation equivariant network is depicted in Figure \ref{fig:equiv} with the `lifted' rotation dimension extended along the vertical axis ($\theta$). In both the translation and rotation cases, the regular representation $\Gamma_g$ acts by permuting the representation along the group dimension, leaving the feature channels unchanged.

% \vspace{-1mm}
\paragraph{Notation} The vector of features (channels) at a specific group element $g$ is sometimes called a `fiber' \cite{cohen2016steerable}. In this work we use the following shorthand for indexing fibers according to their group element $g$: $\vz(g) \equiv \vz_{:,g} \in \sR^{C}$. Similarly, the set of fibers corresponding to an ordered set of group elements $\vg$ can be called a `fiber bundle' which we denote: $\vz(\vg) = [\vz(g)\  |\  g \in \vg] \in \sR^{|\vg|C}$. Fiber bundles can be seen in Figure \ref{fig:equiv} as the small cubes being compared (with the fibers themselves extending into the undepicted fourth dimension). Using this notation, we can define the action of $\Gamma_g$ as: $\Gamma_g [\vz(\vg_0)] = \vz(g^{-1} \cdot \vg_0)$. Thus $\Gamma_g$ can be seen to move the fibers from `base' locations $\vg_0$ to a new ordered set of locations $g^{-1} \cdot\vg_0$. We highlight that order is critical for our definition since a transformation such as rotation may simply permute $\vg_0$ while leaving the unordered set intact.

\paragraph{Augmentation-based SSL (A-SSL)} 