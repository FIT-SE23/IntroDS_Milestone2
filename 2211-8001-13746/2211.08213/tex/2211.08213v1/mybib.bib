@article{aldeneh2021you,
  title={You're Not You When You're Angry: Robust Emotion Features Emerge by Recognizing Speakers},
  author={Aldeneh, Zakaria and Provost, Emily Mower},
  journal={IEEE Transactions on Affective Computing},
  year={2021},
  publisher={IEEE}
}

@inproceedings{old_emo_st,
  title={Study on speaker verification on emotional speech},
  author={Wu, Wei and Zheng, Thomas Fang and Xu, Ming-Xing and others},
  booktitle={Ninth International Conference on Spoken Language Processing},
  year={2006}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and others},
  booktitle={Proc. of CVPR},
  pages={770--778},
  year={2016}
}

@inproceedings{opensmile,
author = {Eyben, Florian and Wöllmer, Martin and Schuller, Björn},
year = {2010},
month = {01},
pages = {1459-1462},
title = {openSMILE -- The Munich Versatile and Fast Open-Source Audio Feature Extractor},
journal = {MM'10 - Proceedings of the ACM Multimedia 2010 International Conference},
doi = {10.1145/1873951.1874246}
}

@article{msp,
	author = {R. Lotfian and C. Busso},
	title = {Building Naturalistic Emotionally Balanced Speech Corpus by Retrieving Emotional Speech From Existing Podcast Recordings},
	journal = {IEEE Transactions on Affective Computing},
	volume = {10},
	number = {4},
	year = {2019},
	pages = {471-483},
	month = {October-December},
	doi={10.1109/TAFFC.2017.2736999},
}
@article{iemocap,
  title={IEMOCAP: Interactive emotional dyadic motion capture database},
  author={Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun, and others},
  journal={Language resources and evaluation},
  volume={42},
  number={4},
  pages={335--359},
  year={2008},
  publisher={Springer}
}
@INPROCEEDINGS{conformer,
  author={Shor, Joel and Jansen, Aren and Han, Wei, and others},
  booktitle={ICASSP}, 
  title={Universal Paralinguistic Speech Representations Using self-Supervised Conformers}, 
  year={2022},
  volume={},
  number={},
  pages={3169-3173},
  doi={10.1109/ICASSP43922.2022.9747197}}

@inproceedings{pappagari2020x,
  title={x-vectors meet emotions: A study on dependencies between emotion and speaker recognition},
  author={Pappagari, Raghavendra and Wang, Tianzi and Villalba, Jesus,  and others},
  booktitle={ICASSP},
  pages={7169--7173},
  year={2020},
}

@inproceedings{bancroft2019exploring,
  title={Exploring the intersection between speaker verification and emotion recognition},
  author={Bancroft, Michelle and Lotfian, Reza and Hansen, John and Busso, Carlos},
  booktitle={ACIIW},
  pages={337--342},
  year={2019},
}

@inproceedings{parthasarathy2017study,
  title={A study of speaker verification performance with expressive speech},
  author={Parthasarathy, Srinivas and Zhang, Chunlei and Hansen, John HL and Busso, Carlos},
  booktitle={ICASSP},
  pages={5540--5544},
  year={2017},
}

@inproceedings{parthasarathy2017predicting,
  title={Predicting speaker recognition reliability by considering emotional content},
  author={Parthasarathy, Srinivas and Busso, Carlos},
  booktitle={ACII},
  pages={434--439},
  year={2017},
}

@InProceedings{chowdhDeepTalk21,
  author       = "Chowdhury, A. and Ross, A. and David, P.",
  title        = "DeepTalk: Vocal Style Encoding for Speaker Recognition and Speech Synthesis",
  booktitle    = "ICASSP",
  year         = "2021",
}
@article{Lotfian_2019_3,
	author = {R. Lotfian and C. Busso},
	title = {Building Naturalistic Emotionally Balanced Speech Corpus by Retrieving Emotional Speech From Existing Podcast Recordings},
	journal = {IEEE Transactions on Affective Computing},
	volume = {10},
	number = {4},
	year = {2019},
	pages = {471-483},
	month = {October-December},
	doi={10.1109/TAFFC.2017.2736999},
}

@ARTICLE{crema,  author={Cao, Houwei and Cooper, David G. and Keutmann, Michael K. and others},  journal={IEEE Transactions on Affective Computing},   title={{CREMA-D}: Crowd-Sourced Emotional Multimodal Actors Dataset},   year={2014},  volume={5},  number={4},  pages={377-390},  doi={10.1109/TAFFC.2014.2336244}}

@ARTICLE{ehealthcare,  author={Koelstra, Sander and Muhl, Christian and Soleymani, Mohammad and others},  journal={IEEE Transactions on Affective Computing},   title={DEAP: A Database for Emotion Analysis ;Using Physiological Signals},   year={2012},  volume={3},  number={1},  pages={18-31},  doi={10.1109/T-AFFC.2011.15}}


@ARTICLE{EEG,  author={Song, Tengfei and Zheng, Wenming and Song, Peng and Cui, Zhen},  journal={IEEE Transactions on Affective Computing},   title={EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks},   year={2020},  volume={11},  number={3},  pages={532-541},  doi={10.1109/TAFFC.2018.2817622}}

@article{Harms2010,
  doi = {10.1007/s11065-010-9138-6},
  url = {https://doi.org/10.1007/s11065-010-9138-6},
  year = {2010},
  month = sep,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {20},
  number = {3},
  pages = {290--322},
  author = {Madeline B. Harms and Alex Martin and Gregory L. Wallace},
  title = {Facial Emotion Recognition in Autism Spectrum Disorders: A Review of Behavioral and Neuroimaging Studies},
  journal = {Neuropsychology Review}
}

@ARTICLE{convo1,  author={Poria, Soujanya and Majumder, Navonil and Mihalcea, Rada and others},  journal={IEEE Access},   title={Emotion Recognition in Conversation: Research Challenges, Datasets, and Recent Advances},   year={2019},  volume={7},  number={},  pages={100943-100953},  doi={10.1109/ACCESS.2019.2929050}}

@misc{convo2,
  doi = {10.48550/ARXIV.1908.11540},
  url = {https://arxiv.org/abs/1908.11540},
  author = {Ghosal,  Deepanway and Majumder,  Navonil and Poria,  Soujanya and others},
  keywords = {Computation and Language (cs.CL),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation},
  publisher = {arXiv},
  year = {2019},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@misc{convo3,
  doi = {10.48550/ARXIV.1810.02508},
  url = {https://arxiv.org/abs/1810.02508},
  author = {Poria,  Soujanya and Hazarika,  Devamanyu and Majumder,  Navonil and others},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations},
  publisher = {arXiv},
  year = {2018},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@article{eyben2015geneva,
  title={The Geneva minimalistic acoustic parameter set (GeMAPS) for voice research and affective computing},
  author={Eyben, Florian and Scherer, Klaus R and Schuller, Bj{\"o}rn W and others},
  journal={IEEE transactions on affective computing},
  volume={7},
  number={2},
  pages={190--202},
  year={2015},
  publisher={IEEE}
}

@article{Abbaschian2021,
  doi = {10.3390/s21041249},
  year = {2021},
  month = feb,
  publisher = {{MDPI} {AG}},
  volume = {21},
  number = {4},
  pages = {1249},
  author = {Babak Joze Abbaschian and Daniel Sierra-Sosa and Adel Elmaghraby},
  title = {Deep Learning Techniques for Speech Emotion Recognition,  from Databases to Models},
  journal = {Sensors}
}

@misc{gst,
  doi = {10.48550/ARXIV.1803.09017},
  url = {https://arxiv.org/abs/1803.09017},
  author = {Wang,  Yuxuan and Stanton,  Daisy and Zhang,  Yu and others},
  keywords = {Computation and Language (cs.CL),  Machine Learning (cs.LG),  Sound (cs.SD),  Audio and Speech Processing (eess.AS),  FOS: Computer and information sciences,  FOS: Computer and information sciences,  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Electrical engineering,  electronic engineering,  information engineering},
  title = {Style Tokens: Unsupervised Style Modeling,  Control and Transfer in End-to-End Speech Synthesis},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}


@misc{speechbrain,
  title={{SpeechBrain}: A General-Purpose Speech Toolkit},
  author={Mirco Ravanelli and Titouan Parcollet and Peter Plantinga and others},
  year={2021},
  eprint={2106.04624},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  note={arXiv:2106.04624}
}

@article{jhu,
  title={CopyPaste: An Augmentation Method for Speech Emotion Recognition},
  author={R. Pappagari and Jes{\'u}s Villalba and Piotr Żelasko and Laureano Moro-Vel{\'a}zquez and Najim Dehak},
  journal={ICASSP},
  year={2021},
  pages={6324-6328}
}

@inproceedings{jhumit,
author = {Villalba, Jesús and Chen, Nanxin and Snyder, David and others},
year = {2019},
pages = {1488-1492},
title = {State-of-the-Art Speaker Recognition for Telephone and Video Speech: The {JHU-MIT} Submission for {NIST SRE}18},
doi = {10.21437/Interspeech.2019-2713}
}

@inproceedings{jenniferwilliam,
  title={Disentangling Style Factors from Speaker Representations.},
  author={Williams, Jennifer and King, Simon},
  booktitle={Interspeech},
  pages={3945--3949},
  year={2019}
}

@book{darwin,
  title={The expression of the emotions in man and animals},
  author={Darwin, Charles},
  year={1872}
}
@article{basicemotion,
  title={Basic emotions},
  author={Ekman, Paul},
  journal={Handbook of cognition and emotion},
  volume={98},
  number={45-60},
  pages={16},
  year={1999}
}

@INPROCEEDINGS{dimensions,  author={Giannakopoulos, Theodoros and Pikrakis, Aggelos and Theodoridis, Sergios},  booktitle={ICASSP},   title={A dimensional approach to emotion recognition of speech from movies},   year={2009},  volume={},  number={},  pages={65-68},  doi={10.1109/ICASSP.2009.4959521}}

@ARTICLE{gemaps_aff,  author={Eyben, Florian and Scherer, Klaus R. and Schuller, Björn W. and others},  journal={IEEE Transactions on Affective Computing},   title={The Geneva Minimalistic Acoustic Parameter Set (GeMAPS) for Voice Research and Affective Computing},   year={2016},  volume={7},  number={2},  pages={190-202},  doi={10.1109/TAFFC.2015.2457417}}

@inproceedings{dl1,
author = {Xu, Mingke and Zhang, Fan and Cui, Xiaodong and Zhang, Wei},
year = {2021},
pages = {6319-6323},
booktitle={ICASSP},
title = {Speech Emotion Recognition with Multiscale Area Attention and Data Augmentation},
doi = {10.1109/ICASSP39728.2021.9414635}
}

@ARTICLE{dl2,  author={Parthasarathy, Srinivas and Busso, Carlos},  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},   title={Semi-Supervised Speech Emotion Recognition With Ladder Networks},   year={2020},  volume={28},  number={},  pages={2697-2709},  doi={10.1109/TASLP.2020.3023632}}

@inproceedings{dl3,
  title = {Speech Emotion Recognition Using Capsule Networks},
  author = {Xixin Wu and Songxiang Liu and Yuewen Cao and others},
  year = {2019},
  doi = {10.1109/ICASSP.2019.8683163},
  url = {https://doi.org/10.1109/ICASSP.2019.8683163},
  researchr = {https://researchr.org/publication/WuLCLYDMHWLM19},
  cites = {0},
  citedby = {0},
  pages = {6695-6699},
  booktitle = {ICASSP},
  isbn = {978-1-4799-8131-1},
}
@inproceedings{dl4,
author = {Xu, Yunfeng and Xu, Hua and Zou, Jiyun},
year = {2020},
pages = {6499-6503},
title = {{HGFM} : A Hierarchical Grained and Feature Model for Acoustic Emotion Recognition},
booktitle={ICASSP},
doi = {10.1109/ICASSP40776.2020.9053039}
}

@inproceedings{ecapa,
  author    = {Brecht Desplanques and
               Jenthe Thienpondt and
               Kris Demuynck},
  editor    = {Helen Meng and
               Bo Xu and
               Thomas Fang Zheng},
  title     = {{ECAPA-TDNN:} Emphasized Channel Attention, Propagation and Aggregation
               in {TDNN} Based Speaker Verification},
  booktitle = {Interspeech},
  pages     = {3830--3834},
  publisher = {{ISCA}},
  year      = {2020},
}

 @inbook{prosody, place={Cambridge, UK}, title={A survey of intonation systems}, booktitle={Intonation systems: A survey of twenty languages}, publisher={Cambridge University Press}, author={Hirst, Daniel and Cristo, Albert Di and Hirst, Daniel and Cristo, Albert Di}, year={1998}, pages={4–7}} 
 
 @inproceedings{psych_contours,
  title={F0-CONTOURS IN EMOTIONAL SPEECH},
  author={Astrid Paeschke and Miriam Kienast and Walter F. Sendlmeier},
  year={1999}
}

@inproceedings{ATM,
  author    = {Thomas Swearingen and
               Will Drevo and
               Bennett Cyphers and
               others},
  title     = {{ATM:} {A} distributed, collaborative, scalable system for automated
               machine learning},
  booktitle = {{IEEE} International Conference on Big Data, Boston,
               MA, USA},
  pages     = {151--162},
  year      = {2017},
  crossref  = {DBLP:conf/bigdataconf/2017},
  doi       = {10.1109/BigData.2017.8257923},
  timestamp = {Tue, 23 Jan 2018 12:40:42 +0100}
}

@misc{deepvox,
  doi = {10.48550/ARXIV.2008.11668},
  
  url = {https://arxiv.org/abs/2008.11668},
  
  author = {Chowdhury, Anurag and Ross, Arun},
  
  keywords = {Audio and Speech Processing (eess.AS), Machine Learning (cs.LG), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {DeepVOX: Discovering Features from Raw Audio for Speaker Recognition in Degraded Audio Signals},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
