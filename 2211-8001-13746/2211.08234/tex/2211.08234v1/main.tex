
\documentclass{article} % For LaTeX2e
\usepackage[final]{iclr2023_conference}
\usepackage{times}
% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

\usepackage{mathtools} % amsmath with fixes and additions
% \usepackage{siunitx} % for proper typesetting of numbers and units
\usepackage{booktabs} % commands to create good-looking tables
\usepackage{tikz} % nice language for creating drawings and diagrams

\usepackage{hyperref}
\usepackage{url}

\hypersetup{
    colorlinks=true,
    % citecolor=cyan,
    % linkcolor=blue,
    % filecolor=magenta,      
    % urlcolor=cyan
    }
    
\usepackage{subfigure}      % for subfigures
% for wrap figures
\usepackage{wrapfig}

%% custom packages
\usepackage{amsmath}        % for eqref
%\usepackage{amsfonts}      % for indicator function
\usepackage{amssymb}   
\usepackage{bbm}            % for indicator function
% \usepackage{xspace}         % margin note
% \usepackage{todonotes}      % margin note
\usepackage{graphicx}       % for pdf image
\usepackage{xcolor}         % colors
\usepackage{subfigure}      % for subfigures
\usepackage{overpic}
% \usepackage{booktabs}       % professional-quality tables
% \usepackage{mathtools}      % for define as symbol

% for tables
\usepackage{multirow}
\usepackage{array}

\usepackage{pgfplots}
\usepackage{mathtools,amssymb}
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{assumption}{Assumption}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\usepackage{thmtools, thm-restate}
\usepackage{vcell}
\usepackage{tabularx}
\usepackage[ruled]{algorithm2e}
\makeatletter
% \newcommand{\algorithmstyle}[1]{\renewcommand{\algocf@style}{#1}}
\newcommand{\removelatexerror}{\let\@latex@error\@gobble}
\makeatother
% \newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\newcommand\mycommfont[1]{\footnotesize\textcolor{blue}{#1}}
\newcommand\myfont[1]{\footnotesize\ttfamily{#1}}
\SetCommentSty{mycommfont}
\SetAlFnt{\footnotesize}
\SetAlCapFnt{\footnotesize}
\SetAlCapNameFnt{\footnotesize}


\title{Build generally reusable agent-environment interaction models}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{%
  Jun Jin$^{1,}$\thanks{Correspondence to jun.jin1@huawei.com}
  \hspace{1mm}
   Hongming Zhang$^{1,2}$
  \hspace{1mm}
  Jun Luo$^{1}$
\\
\hspace{-5mm}
$^{1}${Huawei Noah's Ark Lab}
  \hspace{1mm}
$^{2}$University of Alberta
  \hspace{1mm}
% \hspace{-2mm}\texttt{ \{jun.jin1,hongming.zhang1,jun.luo1\}@huawei.com}
}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}


\begin{document}


\maketitle

\begin{abstract}
This paper tackles the problem of how to pre-train a model and make it generally reusable backbones for downstream task learning. In pre-training, we propose a method that builds an agent-environment interaction model by learning domain invariant successor features from the agent's vast experiences covering various tasks, then discretize them into behavior prototypes which result in an embodied set structure. To make the model generally reusable for downstream task learning, we propose (1) embodied feature projection that retains previous knowledge by projecting the new task's observation-action pair to the embodied set structure and (2) projected Bellman updates which add learning plasticity for the new task setting. We provide preliminary results that show downstream task learning based on a pre-trained embodied set structure can handle unseen changes in task objectives, environmental dynamics and sensor modalities.
% We also show this learning architecture exhibits vanilla learning stability-plasticity without adding additional loss terms or regularizers. 
% Codes will be available in the camera-ready version at: https://gitee.com/mindspore/models/tree/master/research/rl/general-embodied-set.
\end{abstract}

\section{Introduction}
\input{sections/1_introduction.tex}

\section{Related work}
\label{sec:survey}
\input{sections/2_related_works.tex}

\section{Methodology}
\input{sections/3_method.tex}

\section{Experimental setup}
\input{sections/4_experiments.tex}

\section{Preliminary results}
\input{sections/5_performance.tex}

% \section{Model analysis}
% \input{sections/6_model_analysis.tex}

\section{Conclusion}
This paper tackles the problem of pre-training a generally reusable model for downstream tasks with unseen task objectives, environments, and even with unseen sensor modalities. Our approach is inspired by the \textit{embedded agency} perspective that the agent's past experience shapes its future decision-making behaviors. We propose to learn an agent-environment interaction model by extracting cross-domain transferable successor features using the agent's various task experiences. To make the model generally reusable, we propose to discrete it into behavior prototypes, resulting in an embodied set structure that further supports \textit{embodied feature projection} and \textit{projected Bellman updates} to enable downstream task learning with heterogeneous settings. Preliminary results show that downstream task learning by projecting on our proposed embodied set structure can handle unseen changes in task objectives, environmental dynamics and sensor modalities.

For future works, more comprehensive experiments are needed to understand why and how the pre-trained embodied set structure can be generally reused in downstream task learning. It's also worth working on methods that can continually update the constructed \textit{embodied set structure} given that more task experience is gained, thus forming an \textit{embedded agency} version of continual reinforcement learning~\citep{Khetarpal2020TowardsCR} solution. 


\bibliography{iclr2023_conference}
\bibliographystyle{iclr2023_conference}

\appendix
\section{Appendix}
\input{sections/appendix.tex}
\end{document}
