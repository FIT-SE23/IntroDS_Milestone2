\begin{wrapfigure}{r}{0.35\textwidth}
    \centering
    \includegraphics[width=0.35\textwidth]{figs/Fig1.pdf}
    \caption{\footnotesize What models are generally shared between heterogeneous tasks that can be reused to accelerate new task learning in unseen settings? \normalsize}
    %\label{fig:decentcem-a-architecture}
    \vspace{-3mm}
\end{wrapfigure}

Can we pre-train a generally reusable backbone to accelerate downstream task reinforcement learning (RL)? While such backbones are popular in computer vision and natural language processing (e.g., pre-trained ResNet \citep{he2016deep} and pre-trained GPT3 \citep{brown2020language}, pre-trained decision-making backbones that support general downstream task learning are a few. The challenges largely attribute to the vast complexity and variety of decision-making tasks, that the pre-trained model will suffer from the out-of-distribution nightmare when reused to learn a new task. For example, a downstream task's environment dynamics or task objectives may be unseen during pre-training. Or we may need to add an extra sensor modality (e.g., language) to the agent to best fit the task requirement (e.g., understanding human commands). How can we pre-train a backbone that handles the above-unseen changes in downstream task learning, without making any assumptions on the task similarity \citep{duan2016rl,gupta2018meta} of environment similarity \citep{packer2018assessing,rajeswaran2016epopt}? 

Empirically, humans are capable of reusing experience from one task to another, and the tasks we can handle are surprisingly heterogeneous (Fig. 1), from playing blocks, hockey and karate, to learning a carpenter or cooking job. It's natural to ask, (1) what model is generally shared between heterogeneous tasks? And (2) how can it fit in any downstream task learning with unseen settings? 
% This paper aims to tackle the two questions.

%过去decade，RL task backbones并不稀奇。例如VAE，pre-trained ResNet，successor features，laplacian representation, 但是我们缺乏系统地思考pre-train与reuse的问题。而这里的关键是回答，在unseen change发生时，什么是没有变的。若将pre-train，reuse考虑的task都一起考虑，就是这些heterogeneous task中哪些是generally reusable model？
% Backbones for RL tasks are not new. During the past decade, we have seen task-agnostic backbones like VAE for state dimension reduction, pre-trained ResNet for pixel-control tasks, task-specific ones like successor features for fast value evaluation, and environment-specific ones like Laplacian representation for better exploration strategies, and many others (check our survey in Sec. \ref{sec:survey}). But a systematical thinking on the pre-train / reuse paradigm is lacking. If we consider all tasks during pre-training and reuse, one key problem is to find a generally reusable model in heterogeneous tasks. Without assuming any environmental or task distribution priors, we need to seek other perspectives.

Systematically, thinking on the above questions results in two perspectives of viewing what component is shared across tasks---the world and the agent \citep{agent}. The first one seeks to build a \textit{Bayesian world model} \citep{ha2018world}, with which, the agent stores prior knowledge about the physical world. For example, ``balls will roll'' and ``walking on ice is slippery''. Then the Bayesian agent selects a proper world configuration for downstream task learning. However, since downstream tasks can be complex and diverse, then how large and how accurate the world model should be is not clear. The second perspective seeks to build an \textit{embedded agency} \citep{orseau2012space}, that the agent gradually constructs knowledge learned from its past experience, respecting the fact that the world is far more complex than the agent. The constructed knowledge can be representations or models and will accelerate downstream task learning. The \textit{embedded agency} perspective can also gradually build a world model for the agent, but unlike the \textit{Bayesian world model}, the agent's past experience shapes what the world model is, how large it is, and how accurate it is. This paper relates to the second viewpoint. % there is no clear boundary between the agent and the world.

Though the \textit{embedded agency} view is conceptually appealing, 
% and it best aligns with the prevalent theory of \textit{``mind embodied, embedded, and enacted''} from cognitive science, 
technically how to build it and the promising benefits w.r.t. sample efficiency or continual learning capability are not clear. Without being too ambitious to build a complete embedded agency, in this paper, we focus on a more practical starter: \textit{how the agent constructs a model from its embodied experience, and how it accelerates new task learning when environments, task objectives, and even sensor modalities are unseen}. 

Specifically, we format the problem of building a generally reusable model as an embodied set construction approach that constructs a domain invariant set structure using a large dataset covering the agent's vast task experiences. We call it an agent-environment interaction model since the set elements are discretized successor features \citep{barreto2017successor} which represent how a decision-making agent interacts with the world. We call our approach embodied set construction since the set structure is constructed so that it is a shared component across tasks and environments, which can be viewed as an embodiment of the agent. We call it generally reusable since learning by projecting onto the embodied set structure enables learning stability-plasticity. Our contributions are as follows:
%不存在generally reusable
\begin{itemize}
    \item We propose an \textit{embodied set construction} approach to pre-train a reusable agent-environment interaction model by firstly learning domain invariant successor features from the agent's past experience, then discretizing them to behaviour prototypes which result in an embodied set structure. Note that the constructed embodied set structure, though optimized to be domain-invariant, still suffers the out-of-distribution (O.O.D.) problem when reused in downstream tasks under unseen settings.
    \item To make the pre-trained model generally reusable, we propose two projection-based techniques that enable learning stability-plasticity: (1) \textit{embodied feature projection} which retains previous knowledge by projecting the new task's observation-action pairs onto the embodied set structure, and (2) \textit{projected Bellman update} which adds plasticity for the new task learning.
    \item Combined together, we propose a complete solution of pre-training a generally reusable model and plugging it as a backbone to accelerate downstream task learning.
\end{itemize}
\begin{figure}[h]
 	\setlength{\belowcaptionskip}{-10pt}
	\centering
	\includegraphics[width=0.8\textwidth]{figs/fig0.pdf}
	\caption{\footnotesize Diagram of our proposed method. \normalsize}
     % \vspace{-2.5mm}
	\label{fig:intro}
\end{figure} 

Our experiments show that downstream task learning based on a pre-trained embodied set structure can handle unseen changes of task objectives, environmental dynamics and sensor modalities, without assuming any environmental or task distribution priors.
% We also show this learning architecture exhibits vanilla learning stability-plasticity without adding additional loss terms or regularizers. 