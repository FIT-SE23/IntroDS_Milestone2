\input{tables/overview}

\section{Approach}

Previous works \citep{T0-paper,FLAN} have shown that prompted multi-task training can greatly improve zero-shot performance on unseen tasks. One intuitive reason behind the validity of this improvement is that all the NLP tasks share a common ability that allows LMs to solve unseen tasks based on the data from other training tasks. To test this idea and even enhance zero-shot generalization, a direct way is explicitly defining what this "common ability" is. Here, we define this "common ability" by designing a new general task of ``discriminating whether a text sample comes from the true data distribution of natural language''. 

We will first formulate the learning problem (\S~\ref{sec:formualtion}), and then define the concept \textit{discriminative tasks} (\S~\ref{sec:disc}), followed by describing how we transform discriminative tasks into our shared formulation.
In \S~\ref{sec:ud} and \S~\ref{sec:generalizedud}, we will study our UD, respectively on discriminative tasks and on a generalized scope of both discriminative and generative tasks.


\subsection{Multi-Task Training for Zero-Shot Generalization} \label{sec:formualtion}


Now we describe the learning problem we aim to solve in this work.
We adopt the same setting as in \citet{T0-paper}. The input to our problem is a set of training tasks with labeled data, and the goal is to train a model that generalizes to unseen test tasks. The training and test tasks are constrained to have distinct task types for the evaluation of cross-task-type generalization. A pre-trained model is jointly trained on the set of training tasks and directly evaluated on the set of test tasks in a zero-shot manner.






\subsection{Discriminative Tasks} \label{sec:disc}


We use the term ``discriminative tasks'' to refer to tasks that can be framed as selecting from a few options. 

More concretely, there are two types of discriminative tasks. The first type is tasks with multiple options, such as multi-choice question answering and news classification. The problem can be framed as selecting the right option from multiple ones, where the options are either customized for each sample (e.g., multi-choice question answering) or shared within the task (e.g., news classification). The second type is tasks with yes/no options, such as paraphrase identification and natural language inference. Given a sample of these tasks, a model is asked to predict a yes/no (or true/false) answer. 

It is important to notice that discriminative tasks constitute a significantly large portion of modern NLP research tasks. For example, all of the test tasks of the T0 benchmark~\cite{T0-paper}, SuperGLUE~\cite{wang2019superglue}, GLUE~\cite{wang2019glue}, and 85+\% tasks in BBH benchmark~\cite{bbh} are discriminative tasks.


Also note that our definition of discriminative tasks has a larger scope compared to the conventional notion of ``classification'' which usually refers to tasks with a non-customized, fixed set of labels. In contrast, discriminative tasks might have sample-customized options, e.g., multi-choice question answering and coreference resolution.



\subsection{A Universal Discriminator}
\label{sec:ud}


Given a text sample $x$, let $P(\text{true} | x)$ be the probability that $x$ is sampled from the true data distribution of natural language. We train a universal discriminator (UD), denoted as $D(x)$, to estimate the probability $P(\text{true} | x)$ for each text sample $x$. From another perspective of contrastive learning \cite{oord2018representation}, this problem can also be viewed as learning a partial order of the probability distribution. Specifically, for two text samples $x_1$ and $x_2$, if $P(\text{true} | x_1) > P(\text{true} | x_2)$, the UD is expected to predict $D(x_1) > D(x_2)$. This contrastive view is essential for tasks with multiple options, i.e., learning to select from a few options based on the partial order given by UD.



Figure~\ref{fig:overview} compares the multi-task prompted formulation of T0 and the formulation of our UD.
In the following, we will show how we use this formulation of UD to unify and solve discriminative tasks.

\subsubsection{Unifying Discriminative Tasks}
\label{sec:unifydiscriminativetasks}

We assume that for any task, the concatenation of input and the correct option follows the true data distribution of natural languages, while the concatenation of input and the other wrong options deviates much from the true data distribution. 




Given this assumption, we claim that almost all discriminative tasks are equivalent to our defined task (i.e., estimating $P(\text{true} | x)$) above. Here, ``equivalent'' has bi-directional meanings: on one hand, there exists a reduction\footnote{In complexity theory, a reduction is an algorithm transforming one problem A into another problem B such that a solution for problem B could also be used to solve problem A.} from UD's task (say, task U) to any discriminative task (say, task A): given a piece of labeled training data for task A, we can generate several pieces of labeled training data for task U.


On the other hand, there exists another reduction from any discriminative task A to UD's task U: given a piece of testing data for task A, we can generate several pieces of testing data for task U such that by first predicting $D(\cdot)$ on them and then using a mapping from task U's outputs to task A's outputs, we can generate the answer for task A.






Based on the definition of discriminative tasks in \S~\ref{sec:disc}, there are two main categories, multi-choice tasks and yes/no tasks. We will discuss each category in detail as follows (also see Table \ref{tab:task_formulate_example} in appendix for specifics).


\paragraph{Multi-Choice Tasks}
For multi-choice tasks, we concatenate the text input $x_{in}$ with each choice $\{c_i\}_{i=1}^{N_c}$ to form samples. For example, for multi-choice question answering, we concatenate the given paragraph and question with each answer candidate. See Table \ref{tab:task_formulate_example} for more task formulations. During training, the concatenated samples with the correct choice are given label $1$ (true) for UD and the other incorrect ones are given label $0$ (false). During testing, similarly, we concatenate the text input 
$x_{in}$ with each choice $\{c_i\}_{i=1}^{N_c}$ 
to form several samples 
$\{(x_{in},c_i)\}_{i=1}^{N_c}$ 
and ask UD for their $D(\cdot)$ scores. We then select the sample with the maximal $D(\cdot)$ score and output its corresponding choice.






\paragraph{Tasks with Yes/No Choices}
For yes/no tasks, we directly treat the text input $x_{in}$ as a sample and assign its 0/1 label based on its yes/no label. During training, we use $x_{in}$ with its assigned 0/1 label as UD's training data. During testing, we first get the output of UD on $x_{in}$, $D(x_{in})$, and then output answer yes/no based on whether $D(x_{in})>0.5$\footnote{We note that more delicate threshold search might be possible, but we find it performs well using a constant 0.5.}. 

Empirical experiments suggest that unifying tasks with Yes/No choices in such a new way can produce better zero-shot performance than using the same method for Multi-Choice Tasks. We provide two justifications here: First, the Yes/No answer tokens here don't contain specific information and thus the model cannot benefit from concatenation. Second, the two tokens Yes/No are asymmetric in the training dataset which may result in the model uniformly assigning higher scores for one of them no matter what the task input is. 





\paragraph{Minimal Prompting} A key principle we follow for task formulation is minimal prompting. From Table \ref{tab:task_formulate_example}, one can see that our prompts are minimal in the sense that they are mostly just concatenations of different elements from the raw input, discarding most of the previously instructive prompting words. This is very different from T0 \cite{T0-paper} and other generative approaches \cite{gpt3-paper,PET-paper} that add lengthy task descriptions with different wordings into the prompts.

We argue that there are two major benefits of minimal prompting. First,  previous work \cite{liu2021gpt} has shown that zero-shot and few-shot performances are very sensitive to the prompts used for inference. Minimal prompting is more robust and requires less prompt engineering efforts at test time. This is especially important for true zero-shot real-world applications as there is no data available for choosing the right prompt. Second, as we will show in our experiments, UD performs much better with minimal prompts than lengthy descriptive prompts, while generative approaches do not work well with minimal prompts. This is also consistent with our motivation that all the NLP tasks share a common ability: ``discriminating whether a text sample comes from the true data distribution'' and UD is attempting to learn ``what kind of concatenation between input and option makes it look like the true language?'', which does not rely much on the descriptions for each task. On the other hand, T0 attempts to generate the answer directly basing on all the information it gets, so prompts provide an extra source of information and are helpful. See \S~\ref{sec:minimal_prompts} for our ablation study on minimal prompts.

Note that it is also important to use minimal prompts to resolve ambiguity in some cases. For example, consider the natural language inference (NLI) task that predicts whether a premise $A$ entails a hypothesis $B$. Simply concatenating $A$ and $B$ is ambiguous, because the model cannot tell which is the premise. The model also is not aware that this is an NLI task. To resolve this kind of ambiguity, we use a minimal prompt ``Premise: A. Hypothesis: B.'' instead, as shown in Table \ref{tab:task_formulate_example}.





\subsubsection{Architecture}

UD can use any pre-trained encoder model as the backbone. In this work, we experiment with the T5 encoder and DeBERTa \cite{debertav3}. Since T5 is an encoder-decoder model, we only use the encoder part. For the T5 backbone, we perform mean pooling over the last-layer encoder features, followed by a dropout layer and a linear layer to predict a scalar logit. For the DeBERTa backbone, we use the last-layer feature of the first token, followed by a two-layer perceptron with dropout to also output a scalar logit. We train UD with the binary cross entropy loss.



\subsection{A Generalized Universal Discriminator}
\label{sec:generalizedud}

To further study how the discriminative approaches work in combination with generative tasks, we also propose to experiment with a generalized version of UD (denoted as generalized UD).



Different from the previous UD that only uses an encoder as the backbone model, the generalized UD employs an encoder-decoder architecture. In the following, we experiment with the T5 model.
Generalized UD takes both discriminative and generative tasks into consideration, and is jointly trained over both types of tasks at the same time.



For discriminative tasks, they are reformulated into binary classification tasks through minimal prompting, as is described in  \S~\ref{sec:unifydiscriminativetasks}. Specifically, it takes the minimal prompted texts into the encoder and uses the decoder to predict over \{``Yes'', ``No''\}.
In such cases, generalized UD is optimized with the binary cross-entropy loss.
For generative tasks, they take the form of ``input-and-target'' pairs. Generalized UD is fed with the textual inputs, and generates the targets through decoding.
For generative tasks, generalized UD is trained to optimize the cross-entropy loss.
















