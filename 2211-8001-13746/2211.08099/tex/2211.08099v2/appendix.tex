\newpage
\onecolumn
\appendix
\section{Examples of Minimal Prompt}
Here we provide Table~\ref{tab:task_formulate_example} for some examples of how to construct minimal prompted data according to \S~\ref{sec:unifydiscriminativetasks}.

\input{tables/task_formulate_ud}

\section{Full Experiment Results}




\subsection{Evaluation on Big-Bench}\label{sec:bigbench}
Here we report the full results for 13 tasks in the Big-Bench \citet{bigbench}, which is also utilized in original T0 paper~\cite{T0-paper}. All the tasks from BIG-Bench are ensured unseen in our training set for the zero-shot setting. The results are displayed in Table ~\ref{tab:bigbench}, where UD outperforms T0 by 4-8 points on different scales.




\begin{table*}
\resizebox{\textwidth}{!}{%
    \begin{tabular}{l|ccccccccccccc|c}
    \toprule[1pt]
    \multirow{2}{*}{Model} 
        & \multirow{2}{*}{\shortstack{code \\ desc.}}
        & \multirow{2}{*}{\shortstack{conce\\-ptual}}
        & \multirow{2}{*}{\shortstack{known\\unknowns}}
        & \multirow{2}{*}{\shortstack{logic \\ grid}}
        & \multirow{2}{*}{\shortstack{logic \\ deduction}}
        & \multirow{2}{*}{\shortstack{miscon\\-ceptions}}
        & \multirow{2}{*}{\shortstack{novel\\concepts}}
        & \multirow{2}{*}{\shortstack{strate\\-gyqa}}
        & \multirow{2}{*}{\shortstack{wino\\-why}}
        & \multirow{2}{*}{\shortstack{syllo\\-gisms}}
        & \multirow{2}{*}{\shortstack{movie\\dialog}}
        & \multirow{2}{*}{\shortstack{lang\\-uage\_id}}
        & \multirow{2}{*}{\shortstack{vita\\-minc}} 
        & \multirow{2}{*}{Avg.}\\
    &&&&&&&&&&&&&&\\
    \midrule[1pt]
    UD-DeBERTaV3 & 76.7 & 64.1 & 76.1 & 39.9 & 54.9 & 50.2 & 50.0 & 59.9 & 45.8 & 50.4 & 57.7 & 13.3 & 61.5 & 53.9 \\
    \midrule[1pt]
    T0-Large$\star$ & 14.1 & 40.4 & \textbf{60.4} & \textbf{38.0} & \textbf{41.2} & 50.0 & 10.0 & \textbf{52.3} & \textbf{49.7} & 50.3 & 46.8 & 16.0 & 46.2 & 39.6 \\
    UD-Large & \textbf{51.7} & \textbf{54.4} & 47.8 & 33.4 & 34.6 & \textbf{50.2} & \textbf{26.5} & 47.0 & 45.7 & \textbf{50.6} & \textbf{51.7} & \textbf{16.3} & \textbf{55.8} & \textbf{43.5} \\
    
    \midrule[1pt]
    T0-XL$\star$ & 23.4 & 48.1 & 64.6 & \textbf{42.5} & \textbf{50.1} & \textbf{52.7} & 25.0 & 53.1 & \textbf{45.4} & 50.2 & 47.7 & 19.0 & 60.0 & 44.8 \\
    UD-XL & \textbf{53.3} & \textbf{73.8} & \textbf{65.2} & 37.2 & 37.8 & 48.0 & \textbf{35.3} & \textbf{53.1} & 45.3 & \textbf{50.4} & \textbf{50.1} & \textbf{22.9} & \textbf{63.7} & \textbf{48.9} \\
    \midrule[1pt]
    T0-XXL$\dagger$ & 36.7 & 62.5 & 63.0 & 39.6 & 55.4 & \textbf{52.5} & 15.6 & 52.7 & 47.4 & \textbf{51.8} & 53.8 & 20.7 & 64.7 & 47.4\\
    UD-XXL & 61.7 & 71.8 & 76.1 & 38.0 & 59.1 & 49.3 & \textbf{61.8} & 61.3 & 45.9 & 50.1 & 57.3 & 21.6 & 67.2 & 55.5 \\
    UD+-XXL & \textbf{63.3} & \textbf{82.5} & \textbf{84.8} & \textbf{39.2} & \textbf{67.5} & 49.3 & 58.8 & \textbf{64.2} & \textbf{47.5} & 50.4 & \textbf{57.9} & \textbf{27.3} & \textbf{70.2} & \textbf{58.7} \\
    \bottomrule[1pt]
    
    \end{tabular}%
    }
\caption{Zero-shot performance of Universal Discriminator and T0 on Big-Bench test tasks used in T0 paper. Results with $\dagger$ are reported by~\citeauthor{T0-paper}, and results with $\star$ are reproduced in our framework.}
\label{tab:bigbench}
\end{table*}

\subsection{Evaluation on BBH}\label{sec:bbh}
Here we report the full results for 22 discriminative tasks from BBH \citep{bbh}. For reference, we reproduce Flan-T5\citep{flant5}'s zero-shot performance on BBH tasks by evaluating their public checkpoints. All the tasks from BBH are ensured unseen in our training set for the zero-shot setting. The results are displayed in Table~\ref{tab:bbh_full}, where UD constantly performs better than T0 and Flan-T5 on all the scales even though Flan-T5 is trained on a much broader scope of tasks than UD is.

\begin{table*}
\resizebox{\textwidth}{!}{%

    \begin{tabular}{l|ccc|ccc|cccc}
    \toprule[1pt]
    Dataset & T0-Large & Flan-T5-Large & UD-Large & T0-XL & Flan-T5-XL & UD-XL & T0-XXL & Flan-T5-XXL & UD-XXL & UD+-XXL \\
    \midrule[1pt]
    boolean\_expression  & 48.4 & 49.6 & \textbf{64.0} & 47.6 & 54.8 & \textbf{68.4} & 46.4 & 56.8 & \textbf{68.4} & 66.0 \\
    causal\_judgement & 56.2 & 59.4 & \textbf{61.5} & 58.8 & 59.9 & \textbf{63.6} & 62.0 & 60.9 & \textbf{65.2} & 63.6 \\
    data\_understanding & 30.4 & 18.8 & \textbf{30.4} & 38.8 & 34.8 & \textbf{41.2} & \textbf{63.2} & 56.8 & 51.6 & 53.2  \\
    disambiguation\_qa & 54.4 & 34.8 & \textbf{68.4} & 61.2 & \textbf{66.8} & 65.2 & 64.4 & 66.8 & \textbf{67.2} & 66.8 \\
    formal\_fallacies & 54.4 & \textbf{55.6} & 50.4 & 52.4 & \textbf{54.0} & 46.4 & 52.0 & 55.2 & 54.0 & \textbf{58.8} \\
    geometric\_shapes & 0.0 & \textbf{21.6} & 9.6 & 0.0 & \textbf{20.0} & 9.6 & 11.2 & \textbf{31.2} & 9.6 & 9.6 \\
    hyperbaton & \textbf{72.0} & 59.6 & 71.2 & 52.4 & 58.8 & \textbf{66.8} & 63.2 & 70.8 & 68.0 & \textbf{82.0}\\
    logical\_deduction\_five\_objects & 34.8 & \textbf{40.0} & 32.8 & 38.8 & \textbf{48.0} & 39.2 & 46.4 & 53.6 & 58.4 & \textbf{65.2} \\
    logical\_deduction\_seven\_objects & 27.6 & \textbf{40.4} & 25.2 & 37.6 & \textbf{52.4} & 32.0 & 50.4 & 60.0 & 56.4 & \textbf{67.2}  \\
    logical\_deduction\_three\_objects & 49.2 & 37.6 & \textbf{60.4} & 62.8 & 64.8 & \textbf{69.2} & 65.6 & 74.4 & 80.8 & \textbf{83.2} \\
    movie\_recommendation & 51.4 & 55.0 & \textbf{60.4} & 55.0 & 47.4 & \textbf{69.6} & 61.0 & 38.5 & 73.2 & \textbf{78.8} \\
    navigate & 58.8 & 56.4 & \textbf{63.6} & 60.4 & 59.2 & 58.4 & 65.6 & 60.8 & 63.2 & 64.8 \\
    penguins\_in\_a\_table & 36.3 & 32.9 & \textbf{36.3} & 34.3 & \textbf{42.5} & 41.1 & 40.4 & 41.1 & 39.7 & \textbf{46.6} \\
    reasoning\_about\_colored\_objects & 39.2 & \textbf{40.4} & 36.4 & 41.6 & 47.2 & \textbf{54.4} & 56.8 & 61.6 & 57.2 & \textbf{63.2}\\
    ruin\_names & 23.0 & 22.6 & \textbf{44.4} & 21.8 & \textbf{33.5} & 24.4 & 17.8 & 34.7 & 35.6 & \textbf{68.8} \\
    snarks & 48.3 & 56.1 & \textbf{74.7} & 45.5 & 55.6 & \textbf{73.0} & 55.1 & 72.5 & 75.3 & \textbf{82.0} \\
    sports\_understanding & 53.2 & \textbf{55.6} & 54.8 & 47.6 & \textbf{52.4} & 51.6 & 52.8 & \textbf{60.0} & 57.6 & 56.0 \\
    temporal\_sequences & 13.2 & \textbf{25.2} & 23.6 & 24.8 & 22.4 & \textbf{63.2} & 14.8 & 28.8 & 43.2 & \textbf{60.8} \\
    tracking\_shuffled\_objects\_five\_objects & \textbf{12.8} & 12.4 & 12.0 & 12.8 & 12.0 & \textbf{13.2} & 12.0 & 15.2 & 12.4 & \textbf{20.0}  \\
    tracking\_shuffled\_objects\_seven\_objects & 7.6 & 8.4 & \textbf{9.6} & 8.8 & \textbf{9.2} & 8.4 & 8.0 & 13.2 & 8.4 & \textbf{14.0} \\
    tracking\_shuffled\_objects\_three\_objects & 33.2 & \textbf{33.6} & 31.2 & 33.6 & 32.8 & \textbf{34.8} & 29.6 & 24.4 & \textbf{33.6} & 20.8  \\
    web\_of\_lies & 51.2 & \textbf{52.4} & 51.2 & 51.2 & \textbf{52.4} & 47.6 & 50.8 & 50.0 & 50.4 & \textbf{56.8} \\
    \midrule[1pt]
    Avg.  & 38.9 & 39.5 & \textbf{44.2} & 40.4 & 44.6 & \textbf{47.3} & 45.0 & 49.4 & 51.3 & \textbf{56.7} \\
    \bottomrule[1pt]
    \end{tabular}%
}
  \caption{Zero-shot performance of Universal Discriminator, T0, and Flan-T5 on BBH test tasks \citep{bbh}.}
  \label{tab:bbh_full}%
\end{table*}%



\section{More Ablation Studies}

\subsection{Ablation on Base Models}\label{sec:base_models}
\input{tables/ablation_base_model}

We also study the effects of using different backbone pretrained models. We experiment with three backbone models of different types, respectively the encoder part of an encoder-decoder model, an encoder model, and a decoder model. Specifically, we use the T5 encoder, DeBERTa \cite{debertav3}, and GPT \cite{radford2018gpt} respectively for these three types. It is noteworthy that though similar in architecture for both T5 encoder and DeBERTa, they are pretrained with different self-supervised language modeling tasks, which in fact leads to huge differences in zero-shot generalization, as we will show in Table~\ref{tab:ablationbasemodel}.











Results of different backbone models are presented in Table \ref{tab:ablationbasemodel}. 
Among all three types of backbone models, the encoder backbone models appear to be the most suitable type of backbone, where both encoder models of two scales respectively achieve the best and the second best results, outperforming all the others by more than 5 points.

Using the same number of parameters (i.e., 1.5B), both DeBERTa-V2 and T5-Encoder significantly outperform GPT-XL, which demonstrates that a bidirectional architecture works better than the unidirectional architecture for the discriminator formulation.
In addition, DeBERTa-V2 outperforms T5-Encoder by 7 points, implying that not only model architecture but also the self-supervised pretraining task determines the ability of UD discrimination. Models pretrained with masked language modeling tasks are more suitable for UD.

The impacts of the architecture and pretraining tasks of backbone models are even larger than the influence of scale, as we also observe that an encoder model with 300M parameters (i.e., DeBERTaV3) achieves much better performance than the T5 encoder and GPT-XL with 1.5B parameters.
















