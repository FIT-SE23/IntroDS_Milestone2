\begin{table*}[t]
\setlength{\tabcolsep}{1.5mm}
\centering

\subtable[On 11 discriminative test tasks following the T0 benchmark.]{
\resizebox{\textwidth}{!}{%
    \begin{tabular}{l|l|c|ccccc|ccc|cc|c|c}
    \toprule[1pt]
    \multirow{2}{*}{Base Model} &
    \multirow{2}{*}{Method} &
    \multirow{2}{*}{\#Params} & 
    \multicolumn{5}{|c|}{\textbf{Natural Language Inference}} & \multicolumn{3}{|c|}{\textbf{Sentence Completion}} & \multicolumn{2}{c|}{\textbf{Coreference}} & \multicolumn{1}{c|}{\textbf{WSD}} 
    & \multirow{2}{*}{Avg.}\\
    & & & RTE & CB & ANLI1 & ANLI2 & ANLI3 & COPA & Hella. & Story. & WSC & Wino. & WiC &  \\
    \midrule[1pt]
    Decoder-only & GPT-3 & 175B 
        &63.5 &46.4
        &34.6 &	35.4&	34.5&	91.0&	78.9&	83.2&	65.4&	70.2&	- & -\\
    Decoder-only & GLaM & 137B 
        & 56.3	& 39.3	& 39.7	& 35.5	& 34.1	& 90.0	& 76.7	& 81.1	& 82.1	& 71.3	& 50.6 & 59.7\\
    MoE Decoder-only & GLaM & 64B 
        & 66.8	& 33.9	& 40.9	& 38.2	& 40.9	& 90.0	& 77.1	& 82.5	& 83.5	& 73.4	& 50.5 & 61.6\\
    Decoder-only & PaLM & 540B 
        & 72.9	& 51.8	& 48.0	& 44.2	& 45.7	& 93.0	& 83.4	& 84.6	& 89.1	& 81.1	& 59.1 & 68.5\\
    Decoder-only & FLAN & 137B 
        & 78.3	& 64.1	& 47.7	& 43.9	& 47.0	& 90.6	& 56.4	& 92.2	& 80.8	& 67.3 & - & -\\
    \midrule[1pt]
    \multirow{3}*{\shortstack{ELECTRA}}
    & PE-CLS & 335M
        & 60.2	& 57.4	& 34.1	& 34.4	& 36.4	& 92.7	& 44.1	& 96.0	& 62.8	& 56.3	& 50.7	& 56.8
        \\
    & PE-PROB & 335M
        & 54.0	& 49.2	& 32.3	& 33.3	& 33.5	& 81.9	& 36.7	& 89.5	& 64.3	& 50.7	& 50.9	& 52.4 \\
    & PE-REP & 335M
        & 69.0	& 61.3	& 36.1	& 35.0	& 39.4	& 91.2	& 47.0	& 96.8	& 70.0	& 56.2	& 51.1	& 58.5
        \\
    \midrule
    \multirow{1}*{\shortstack{DeBERTaV3}}
    & \multirow{1}*{{UD (ours)}} & 304M
        & \multirow{1}*{71.1}
        & \multirow{1}*{76.8}
        & \multirow{1}*{43.8}
        & \multirow{1}*{41.3}
        & \multirow{1}*{45.7}
        & \multirow{1}*{96.0}
        & \multirow{1}*{60.7}
        & \multirow{1}*{97.4}
        & \multirow{1}*{66.4}
        & \multirow{1}*{83.6}
        & \multirow{1}*{53.3}
        & \multirow{1}*{66.9}
    \\
    \midrule[1pt]
    \multirow{2}*{\shortstack{T5-Large}}
    & \multirow{1}*{T0 $\star$} & 800M
        & 75.1	& 55.5	& 32.9	& 32.3	& 33.7	& 84.6	& 28.2	& 94.0	& 63.0	& 54.6	& 51.2	& 55.0 \\


    & {UD (ours)} & 400M
        & \textbf{83.8}
        & \textbf{80.4}
        & \textbf{36.8}
        & \textbf{34.2}
        & \textbf{42.2}
        & \textbf{90.0}
        & \textbf{56.1}
        & \textbf{96.4}
        & \textbf{68.3}
        & \textbf{62.9}
        & \textbf{54.6}	
        & \textbf{64.1} \\
    \midrule[1pt]
    \multirow{3}*{\shortstack{T5-XL}}
    & \multirow{1}*{T0 $\dagger$} & 3B
        & 64.6 
        & 45.4
        & 33.8
        & 33.1
        & 33.3
        & 72.4
        & 27.3
        & 84.0
        & 65.1
        & 51.0
        & 50.7
        & 51.0 \\

    & \multirow{1}*{T0 $\star$} & 3B
    & \textbf{79.7}	& 68.9	& \textbf{43.1}	& \textbf{38.5}	& 42.3	& \textbf{94.1}	& 31.5	& 97.5	& 68.8	& 61.3	& \textbf{54.1}	& 61.8\\

 
    & {UD (ours)} & 1.5B
        & 78.7
        & \textbf{73.2}
        & 41.2
        & 36.3
        & \textbf{45.4}
        & 94.0
        & \textbf{70.1}
        & \textbf{97.9}
        & \textbf{72.1}
        & \textbf{70.6}
        & 53.0	
        & \textbf{66.6} \\
    \midrule[1pt]
    \multirow{4}*{\shortstack{T5-XXL}}
    & \multirow{1}*{T0 $\dagger$} & 11B
        & 80.8
        & 70.1
        & 43.6
        & 38.7
        & 41.3
        & 90.0
        & 33.6
        & 92.4
        & 61.5
        & 59.9
        & 56.6
        & 60.8 \\

    & \multirow{1}*{T0 $\star$} & 11B
    & \textbf{85.8}	& 73.3	& 47.3	& 42.0	& 46.1	& 94.4	& 31.5	& 98.4	& 62.8	& 72.8	& 56.0	& 64.6 \\

    & {UD (ours)} & 5.5B
    & 80.5	& 87.5	& 49.0	& 42.9 & 	48.8	& 95.0	& 77.4	& \textbf{98.6}	& 73.1	& 82.2	& 57.1	& 72.0 \\

    & {UD+ (ours)} & 5.5B
    & 82.0	& \textbf{89.3}	& \textbf{53.4} & \textbf{48.1} & \textbf{51.0} & \textbf{96.0} & \textbf{78.9} & 96.7	& \textbf{75.0}	& \textbf{86.4}	& \textbf{58.5}	& \textbf{74.1} \\
    \bottomrule[1pt]
\end{tabular}
}
\label{tab:maintable:top}
}


\subtable[On 13 discriminative BigBench tasks following the T0 benchmark]{
\resizebox{0.7\textwidth}{!}{%
    \begin{tabular}{l|cc|cc|ccc|}
    \toprule[1pt]
    \multirow{1}{*}{Model} 
        & \multirow{1}{*}{\shortstack{T0-Large}}
        & \multirow{1}{*}{\shortstack{UD-large}}
        & \multirow{1}{*}{\shortstack{T0-XL}}
        & \multirow{1}{*}{\shortstack{UD-XL}}
        & \multirow{1}{*}{\shortstack{T0-XXL}}
        & \multirow{1}{*}{\shortstack{UD-XXL}}
        & \multirow{1}{*}{\shortstack{UD+-XXL}}\\
    \midrule[1pt]
    BigBench (Avg.) & 39.6 & \textbf{43.5} & 44.8 & \textbf{48.9} & 47.4 & 55.5 & \textbf{58.7} \\
    \bottomrule[1pt]
    \end{tabular}%
    }
\label{tab:maintable:middle}
}

\subtable[On 22 discriminative BBH tasks]{
\resizebox{\textwidth}{!}{%
    \begin{tabular}{l|ccc|ccc|cccc|}
    \toprule[1pt]
    \multirow{1}{*}{Model} 
        & \multirow{1}{*}{\shortstack{T0-Large}}
        & \multirow{1}{*}{\shortstack{Flan-T5-Large}}
        & \multirow{1}{*}{\shortstack{UD-Large}}
        & \multirow{1}{*}{\shortstack{T0-XL}}
        & \multirow{1}{*}{\shortstack{Flan-T5-XL}}
        & \multirow{1}{*}{\shortstack{UD-XL}}
        & \multirow{1}{*}{\shortstack{T0-XXL}}
        & \multirow{1}{*}{\shortstack{Flan-T5-XXL}}
        & \multirow{1}{*}{\shortstack{UD-XXL}}
        & \multirow{1}{*}{\shortstack{UD+-XXL}}\\
    \midrule[1pt]
    BBH (Avg.) & 38.9 & 39.5 & \textbf{44.2} & 40.4 & 44.6 & \textbf{47.3} & 45.0 & 49.4 & 51.3 & \textbf{56.7} \\
    \bottomrule[1pt]
    \end{tabular}%
    }
\label{tab:maintable:bottom}
}
\caption{
Zero-shot performance of our UD and baselines.
Results in the first block are reported by previous work, respectively from GPT-3~\cite{gpt3-paper}, GLaM~\cite{glam}, PaLM~\cite{palm}, and FLAN~\cite{FLAN}.
Note that we provide these reported results for reference, and do not compare directly. Some of the reported tasks are evaluated on the test split, while we follow the better baseline method T0 to report on validation splits.
Results with $\dagger$ are reported by~\citeauthor{T0-paper}, and results with $\star$ are reproduced in our framework. We reproduced the three variants of prompting ELECTRA~\cite{xia2022prompting} under our setting, denoted as ``PE-CLS'', ``PE-PROB'', ``PE-REP''.
Results for Flan-T5-Large/Xl/XXL~\citep{flant5} are reproduced by testing zero-shot performance on their released checkpoints.
In the same group, T0 and Flan-T5 has 2x model parameters compared to UD. For abbreviation, we denote UD based on T5-XX as ``UD-XX'', e.g., UD-XL refers to UD based on the T5-XL model.
}
\label{tab:maintable}
\vspace{-0.7cm}
\end{table*}