\input{tables/discri_task_count}
\input{tables/overview}
\input{tables/task_formulate_ud}


\section{Approach}

Previous works \citep{T0-paper,FLAN} have shown that prompted multi-task training can greatly improve zero-shot performance on unseen tasks. One intuitive reason behind the validity of this improvement is that all the NLP tasks share a common ability that allows LMs to solve unseen tasks based on the data from other training tasks. To test this idea and even enhance zero-shot generalization, a direct way is explicitly defining what this "common ability" is. Here, we define this "common ability" by designing a new general task of ``discriminating whether a text sample comes from the true data distribution of natural language''. 

We will first formulate the learning problem (\S~\ref{sec:formualtion}), and then define the concept \textit{discriminative tasks} (\S~\ref{sec:disc}), followed by describing how we transform discriminative tasks into our shared formulation.
In \S~\ref{sec:ud} and \S~\ref{sec:generalizedud}, we will study our UD, respectively on discriminative tasks and on a generalized scope of both discriminative and generative tasks.


\subsection{Multi-Task Training for Zero-Shot Generalization} \label{sec:formualtion}


Now we describe the learning problem we aim to solve in this work.
We adopt the same setting as in \citet{T0-paper}. The input to our problem is a set of training tasks with labeled data, and the goal is to train a model that generalizes to unseen test tasks. The training and test tasks are constrained to have distinct task types for the evaluation of cross-task-type generalization. A pretrained model is jointly trained on the set of training tasks and directly evaluated on the set of test tasks in a zero-shot manner.


% The difference between our multi-task training and theirs is that our training and evaluation processes are all in the UD format (which be described in section~\ref{sec:ud}) and then transform the result to each individual task. We believe that training and evaluating in this shared format can better induce zero-shot generalization performance across different tasks.

% \paragraph{Finetuning}
% We also study the finetuning paradigm. Specifically, after we train the model using multiple tasks, we follow previous work \cite{T5-paper} to further finetune the model on each individual task to obtain the best performance on these tasks. We use this setting to test the performance of our approach with abundant labels.


% whether our UD format training has advantage in the standard finetuning paradigm. In specific, we first perform a multi-tasking training on a pretrained T5 model, and then finetune each individual task, where all the training and evaluating processes are in UD format. We hypothesis that the shared UD format makes it possible for LM to learn from other tasks and thus improve the accuracy after finetuning.

\subsection{Discriminative Tasks} \label{sec:disc}

% \zy{given the definition of discriminative tasks, and then prove that a significant portion of NLP tasks are discriminative tasks.}

We use the term ``discriminative tasks'' to refer to tasks that can be framed as selecting from a few options. 
%\xhk{instead of generating an answer verbalizer by the model itself}

More concretely, there are two types of discriminative tasks. The first type is tasks with multiple options, such as multi-choice question answering and news classification. The problem can be framed as selecting the right option from multiple ones, where the options are either customized for each sample (e.g., multi-choice question answering) or shared within the task (e.g., news classification). The second type is tasks with yes/no options, such as paraphrase identification and natural language inference. Given a sample of these tasks, a model is asked to predict a yes/no (or true/false) answer. 
%\xhk{We separately create the second type of tasks because the yes/no token itself doesn't contain much information compared with customized choices. Empirical experiments suggest that there is a need to unify them in a different way.} 
% \sout{In this work, we will mainly study how to use discriminative approaches to optimize the performance of discriminative tasks.}

It is important to notice that discriminative tasks constitute a significantly large portion of modern NLP research tasks. For example, all of the test tasks of the T0 benchmark~\cite{T0-paper}, SuperGLUE~\cite{wang2019superglue}, GLUE~\cite{wang2019glue} are discriminative tasks. 
As shown in Figure \ref{fig:discrim}, discriminative tasks constitute up to 60+\% in the T0 multi-task benchmark.
Also note that our definition of discriminative tasks has a larger scope compared to the conventional notion of ``classification'' which usually refers to tasks with a non-customized, fixed set of labels. In contrast, discriminative tasks might have sample-customized options, e.g., multi-choice question answering and coreference resolution.

% For ``discriminative tasks", we mean those tasks with limited answer choices provided to LMs during the test phase. We use two observations of discriminative tasks compared with generative tasks in developing our method: First, rather than considering which is the answer for a task from scratch, discriminative tasks only require LMs to judge whether each choice is acceptable and then select the most acceptable one. Second, if a choice is not the correct answer for a given task, we can usually find some violation of real language usage in certain concatenation of the input and the wrong choice. The first observation makes it reasonable to train a specialized discriminator to do the ``true distribution" judgment for each choice separately, and the second observation implies the existence of universal rules behind such judgements across different tasks, motivating us to train a universal discriminator.


% \subsection{Unifying training data from most NLP classification tasks to \solution task}
\subsection{A Universal Discriminator}
\label{sec:ud}

% \zy{Moved from other places, need to rewrite and fit in} 

Given a text sample $x$, let $P(\text{true} | x)$ be the probability that $x$ is sampled from the true data distribution of natural language. We train a universal discriminator (UD), denoted as $D(x)$, to estimate the probability $P(\text{true} | x)$ for each text sample $x$. From another perspective of contrastive learning \cite{oord2018representation}, this problem can also be viewed as learning a partial order of the probability distribution. Specifically, for two text samples $x_1$ and $x_2$, if $P(\text{true} | x_1) > P(\text{true} | x_2)$, the UD is expected to predict $D(x_1) > D(x_2)$. This contrastive view is essential for tasks with multiple options, i.e., learning to select from a few options based on the partial order given by UD.


% Given a labeled dataset $\mc{D}=\{x_i,y_i\}$ where $x_i$ is text and $y_i\in[0,1]$ is the probability that $x_i$ comes from the true data distribution of natural language. Our goal is to train a universal discriminator (UD) which can provide a mapping $f(x)$ from a text to a probability that $x$ comes from the true data distribution of natural language. This tasks measure the ability to discriminate whether a text sample comes from the true data distribution of natural language or not.

Figure~\ref{fig:overview} compares the multi-task prompted formulation of T0 and the formulation of our UD.
In the following, we will show how we use this formulation of UD to unify and solve discriminative tasks.
% In the following, we will show how we do this and once we get such a discriminator, how it can solve all the discriminative tasks.

\subsubsection{Unifying Discriminative Tasks}
\label{sec:unifydiscriminativetasks}

We assume that a data example is considered ``correct'' if it follows the true data distribution of natural languages, while ``wrong" if it deviates much from the true data distribution. 
% \xhk{We assume that given a discriminative task example, a "correct" transformation \zy{not clear based on context, what is a transformation?} (see the following paragraphs for different transformation methods) of this example can be considered as coming from the true data distribution of natural language, while some other "wrong" transformation can't, where our proposed UD is aimed at predicting this.} \zy{language not formal enough}
Given this assumption, we claim that almost all discriminative tasks are equivalent to our defined task (i.e., estimating $P(\text{true} | x)$) above. Here, ``equivalent" has bi-directional meanings: on one hand, there exists a data transformation method such that one piece of training data from a discriminative task can be transformed into several pieces of UD's training data. 
On the other hand, there exists a data transformation method such that UD can solve a discriminative task by first predicting $D(\cdot)$ for a set of transformed samples and then using a mapping from UD's outputs to the original task's outputs.
% On the other hand, there exists a data transformation method such that UD can solve a discriminative task by first predicting $P(\text{true} | x)$ for a transformed input $x$ and then using a mapping from UD's outputs to the original task's outputs.
% On the other hand, there exists a data transformation method such that UD answers \zy{answers?} a piece of test data from a discriminative task by first predicting scores $D(\cdot)$ for a set of its transformed samples and then using a mapping from UD's outputs to the original task's outputs. \zy{simplify this sentence}


%\xhk{Given this assumption, we claim that almost all discriminative tasks are equivalent to our defined task (i.e., estimating $P(\text{true} | x)$) above. Here, ``equivalent" has bi-directional meanings: on one hand, for a piece of training data from any discriminative task, we can combine its input $x_{in}$ with each of its options from $\{c_i\}_{i=1}^{N_c}$ to get several pieces of UD's training data ($\{x_i=(x_{in},c_i)\}_{i=1}^{N_c}$). On the other hand, given a piece of test data $x_{in},\{c_i\}_{i=1}^{N_c}$ from any discriminative task, UD can answer it by first predicting scores $\{D((x_{in},c_i))\}_{i=1}^{N_c}$ for the set of combined samples between input and each option and use a mapping from the UD's outputs to the original task's outputs}


%Given this assumption, we claim that almost all discriminative tasks are equivalent to our defined task (i.e., estimating $P(\text{true} | x)$) above. Here, ``equivalent" has bi-directional meanings: on one hand, there exists a data transformation method such that a discriminative task's training data can be transformed into UD's training data. On the other hand, there exists a data transformation method such that UD can solve a discriminative task by first predicting $P(\text{true} | x)$ for a transformed input $x$ and then using a mapping from UD's outputs to the original task's outputs.

Based on the definition of discriminative tasks in \ref{sec:disc}, there are two main categories, multi-choice tasks and yes/no tasks. We will discuss each category in detail as follows (also see Table \ref{tab:task_formulate_example} for specifics).

% For all the discriminative tasks we have met, we design 3 unifying methods to transform each tasks's data to UD's iuput data, basing on the relationship of the given answer choices: parallel, opposite, or extent. Please refer to Table~\ref{tab:task_formulate_example} to see examples for each unifying method.

\paragraph{Multi-Choice Tasks}
For multi-choice tasks, we concatenate the text input $x_{in}$ with each choice $\{c_i\}_{i=1}^{N_c}$ to form samples. For example, for multi-choice question answering, we concatenate the given paragraph and question with each answer candidate. See Table \ref{tab:task_formulate_example} for more task formulation. During training, the concatenated samples with the correct choice are given label $1$ ("correct" transformation) for UD and the other incorrect ones are given label $0$ ("wrong" transformation). During testing, similarly, we concatenate the text input 
$x_{in}$ with each choice $\{c_i\}_{i=1}^{N_c}$ 
to form several samples 
$\{(x_{in},c_i)\}_{i=1}^{N_c}$ 
and ask UD for their $D(\cdot)$ scores. We then select the sample with the maximal $D(\cdot)$ score and output its corresponding choice.

%For multi-choice tasks, we concatenate each choice with the text inputs to form a sample. For example, for multi-choice question answering, we concatenate each candidate answer with the given paragraph and question. See Table \ref{tab:task_formulate_example} for more task formulation. During training, the concatenated samples with the correct choices are given label 1 for UD and the incorrect ones are given label 0. During test, for each sample, we select the concatenated sentence with the maximal UD probability and output its corresponding choice.

% \xhk{move to multi-choice paragraph}
% Some of the multi-choice tasks might be related to regression; i.e., a restaurant review classification task assigns 1 to 5 stars to an input text. In this case, we can set the groundtruth label as a probability (e.g., 0.25, 0.5, 0.75, 1.0, etc), which is compatible with the cross entropy loss. We note that other formulations are also possible.

% For tasks like Question Answering, Sentence Completion, the answer choices are several unrelated words or phrases. Our unifying method is to use minimal prompt to concatenate all the raw input keywords and each answer choice. In training phase, the concatenated sentence with correct answer is given label 1, and the other sentences are given label 0. In testing phase, we select the concatenated sentence with the maximal probability of true, and output its corresponding answer choice.

% Some of the multi-choice tasks might be related to regression; e.g., a restaurant review classification task assigns 1 to 5 stars to an input text. We design a slightly more accurate formulation for these tasks (see Appendix \ref{sec:extent}).

% \xhk{A special case of multi-choice tasks is extent measurement, e.g. the degree of sentiment, or the attitude of a given paragraph. We design a slightly more accurate unifying method in appendix~\ref{sec:extent}}

\paragraph{Tasks with Yes/No Choices}
% \xhk{One reviewer suggested how to use UD in test phase is unclear, so I rewrite this paragraph.}
For yes/no tasks, we directly treat the text input $x_{in}$ as a sample and assign its 0/1 label based on its yes/no label. During training, we use $x_{in}$ with its assigned 0/1 label as UD's training data. During testing, we first get the output of UD on $x_{in}$, $D(x_{in})$, and then output answer yes/no based on whether $D(x_{in})>0.5$\footnote{We note that more delicate threshold search might be possible, but we find it performs well using a constant 0.5.}. 

%We separately create a new method for tasks with Yes/No choices because here the answer tokens Yes/No themselves don't contain much information compared with customized choices. 
Empirical experiments suggest that unifying tasks with Yes/No choices in such a new way can produce better zero-shot performance than using the same method for Multi-Choice Tasks because the answer tokens here don't contain much information and thus the model cannot benefit from concatenation.

%For yes/no tasks, we use a more direct connection to UD. During training, we use the yes/no label as the UD label for each sample. During test, we perform binary classification using a threshold of 0.5\footnote{We note that more delicate threshold search might be possible, but we find it perform well using a constant 0.5.} based on the UD predictions.


% Some tasks are essentially binary interrogating questions, e.g. judging whether a hypothesis is implied by the premise, judging whether two sentences has the same meaning. Their answer choices are usually Yes/No, True/False. For these tasks, we assume that the answer for this tasks is an intrinsic nature of the given raw input, even without choice attached. Through minimal prompting, we get a concatenation of the raw input's keywords as the input for UD. In training phase, we assign it a label basing on its answer. In test phase, we do the binary selection by checking whether the probability of true outputed by UD is larger than 0.5. 

% \paragraph{Extent Answer Choices}
% Some tasks are asking for the location of the given input in an extent measurement, e.g. the degree of sentiment, or the attitude of a given paragraph. Usually, "positive" and "negative" are the two ends in the measurement. For these tasks, we use minimal prompt to concatenate the input with each of the two extreme extent verbalizers, e.g. "positive" and "negativeâ€œ, and we assign it the label basing on the true location of the sentence in the extent measurement.

\paragraph{Minimal Prompting} A key principle we follow for task formulation is minimal prompting. From Table \ref{tab:task_formulate_example}, one can see that our prompts are minimal in the sense that they are mostly just concatenations. This is very different from T0 \cite{T0-paper} and other generative approaches \cite{gpt3-paper,PET-paper} that add lengthy task descriptions with different wordings into the prompts.

We argue that there are two major benefits of minimal prompting. First,  previous work \cite{liu2021gpt} has shown that zero-shot and few-shot performances are very sensitive to the prompts used for inference. Minimal prompting is more robust and requires less prompt engineering efforts at test time. This is especially important for true zero-shot real-world applications as there is no data available for choosing the right prompt. Second, as we will show in our experiments, UD performs much better with minimal prompts than lengthy descriptive prompts, while generative approaches do not work well with minimal prompts. This is also consistent with our motivation that UD unifies discriminative tasks so it does not rely much on descriptions for each task.

Note that it is also important to use minimal prompts to resolve ambiguity for yes/no tasks. For example, consider the natural language inference (NLI) task that predicts whether a premise $A$ entails a hypothesis $B$. Simply concatenating $A$ and $B$ is ambiguous, because the model cannot tell which is the premise. The model also is not aware that this is an NLI task. To resolve this kind of ambiguity, we use a minimal prompt ``Premise: A. Hypothesis: B.'' instead, as shown in Table \ref{tab:task_formulate_example}.

% \subsubsection{Minimal Prompting}

% \zy{Describe the idea of minimal prompting here}

% In the three unifying methods described above, we need a minimal prompting to concatenate different keywords of a task's raw input and each of its choices. The goal of our minimal prompting is to make the prompted sentence looks more like sampled from the true language distribution for correct answer and less like sampled from the true distribution for other wrong choices, but not to instructing what the task is, which is the key difference between our minimal prompt and the task descriptive prompts used in \citet{T0-paper}. We call it ``minimal'' because for many cases, only trivial concatenation with choice attached at the end is enough for out goal, and it is much simpler than the prompts used in \citet{T0-paper}. However, in some cases, such ``minimal" prompts are necessary because trivial concatenation may result some ambiguity for certain different tasks. For example, in NLI tasks, if we want to judge whether a hypothesis ``B`` is implied by a premise ``A", simple concatenation like ``A B" is ambiguous, because attaching a reason instead of a hypothesis also looks like a sentence sampled from true language distribution, but it should be given False for the NLI task. In this case, our minimal prompt should give ``premise: A Hypothesis: B" to clarify the meaning of each sentence component. Similar necessary case for minimal prompting usually happens for those tasks with opposite choices.

% \subsection{Using a \solution oracle to solve most NLP classification tasks}
% \subsection{Training and Evaluating Universal Discriminator}

% \subsection{Architecture}
\subsubsection{Architecture}

UD can use any pretrained encoder model as the backbone. In this work, we experiment with the T5 encoder and DeBERTa \cite{debertav3}. Since T5 is an encoder-decoder model, we only use the encoder part. For the T5 backbone, we perform mean pooling over the last-layer encoder features, followed by a dropout layer and a linear layer to predict a scalar logit. For the DeBERTa backbone, we use the last-layer feature of the first token, followed by a two-layer perceptron with dropout to also output a scalar logit. We train UD with the binary cross entropy loss.



\subsection{A Generalized Universal Discriminator}
\label{sec:generalizedud}

To further study how the discriminative approaches work in combination with generative tasks, we also propose to experiment with a generalized version of UD (denoted as generalized UD).



Different from the previous UD that only uses an encoder as the backbone model, the generalized UD employs an encoder-decoder architecture. In the following, we experiment with the T5 model.
Generalized UD takes both discriminative and generative tasks into consideration, and is jointly trained over both types of tasks at the same time.



For discriminative tasks, they are reformulated into binary classification tasks through minimal prompting, as is described in  \S~\ref{sec:unifydiscriminativetasks}. Specifically, it takes the minimal prompted texts into the encoder and uses the decoder to predict over \{``Yes'', ``No''\}.
In such cases, generalized UD is optimized with the binary cross-entropy loss.
For generative tasks, they take the form of ``input-and-target'' pairs. Generalized UD is fed with the textual inputs, and generates the targets through decoding.
For generative tasks, generalized UD is trained to optimize the cross-entropy loss.






% \zy{describe the architecture}

% \zy{Moved from other places, need to rewrite and fit in} 

% We inherit the multi-task training phase by \citep{T0-paper,FLAN}. During the training phase, we transform all training tasks' data into data for UD, and train a LM to solve the this task, i.e. we train a universal discriminator. Then, in the zero-shot testing phase, we transform each testing task's data into UD format and use UD's prediction to deduce the answer for the original testing task. Therefore, once we train a UD, we can use it to solve almost all the NLP tasks. 

\begin{comment}
Here we only give an example from COPA in table~\ref{tab:copa_raw_input}

The raw input is
\begin{table}[htbp]
    \centering
    \begin{tabularx}{0.5\textwidth}{ l|X }
        \toprule
        Input & The hamburger meat browned.  \\
        \midrule 
        Ask for & cause  \\
        \midrule
        Choices & The cook froze it., The cook grilled it.\\
        \midrule 
        Target & The cook grilled it.  \\
        \bottomrule 
    \end{tabularx}
    \caption{an example from COPA's raw data}
    \label{tab:copa_raw_input}%
\end{table}%

The way we test this task is that we first similarly unifying the data to the \solution data format, by concatenating its input, "ask for", and choice. Then we use our \solution model to predict the probability of True for each sentence. Finally, we select the choice with whose concatenated sentence has the highest probability of True.

Our input for \solution is

\begin{table}[htbp]
    \centering
    \begin{tabularx}{0.5\textwidth}{ X }
        \toprule
        Input \\
        \midrule
        The hamburger meat browned. cause The cook froze it. \\
        \midrule 
        The hamburger meat browned. cause The cook grilled it. \\
        \bottomrule 
    \end{tabularx}
    \caption{a unified COPA example}
    \label{tab:quarel_consistency}%
\end{table}%
\end{comment}


% \subsection{Discussion}

% % \zy{This section mainly discusses our advantages to generative modeling.}

% % \zy{Moved from other places, need to rewrite and fit in} 

% Similar to prompting, which makes all NLP tasks to "text generation task", here we make all NLP tasks to the UD format, which is a discriminative task. One key difference between our unifying method and prompting is that, prompting uses human task descriptive language to unify all tasks to "text generation task", but there is no evidence that the LM can truly understand the prompt's instruction \citep{()} and the choice of different prompts can significantly disturb the performance \citep{}. Therefore, prompts are just unifying the input and output format of all tasks rather than unifying their task nature. However, after our unifying method, we hypothesis that all tasks now share the same ability, more suitable for multi-task training, and can induce better zero-shot performance to unseen tasks. Besides, our unifying methods need minimal prompting, no task descriptive language is used, which significantly reduces performance's sensitivity on handcrafted prompts and save human efforts on designing such prompts.

% \xhk{move to here: why we want to train a universal discriminator for discriminative tasks? We use two observations of discriminative tasks compared with generative tasks in developing our method: First, rather than considering which is the answer for a task from scratch, discriminative tasks only require LMs to judge whether each choice is acceptable and then select the most acceptable one. Second, if a choice is not the correct answer for a given task, we can usually find some violation of real language usage in certain concatenation of the input and the wrong choice. The first observation makes it reasonable to train a specialized discriminator to do the ``true distribution" judgment for each choice separately, and the second observation implies the existence of universal rules behind such judgements across different tasks, motivating us to train a universal discriminator.}