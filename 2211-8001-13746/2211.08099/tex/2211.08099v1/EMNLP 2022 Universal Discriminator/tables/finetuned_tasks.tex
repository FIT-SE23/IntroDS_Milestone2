\begin{table}[t]
\setlength{\tabcolsep}{4.5mm}
\centering
    \resizebox{0.5\textwidth}{!}{%
    \begin{tabular}{lcccc}
        \toprule[1pt]
        % \textbf{Finetuned Task} & \textbf{Task Type} & \textbf{Metric} & \textbf{Eval Set} & \textbf{SOTA Reference} & \textbf{SOTA} & \textbf{Ours}  \\
        \textbf{Finetuned Task} & \textbf{T0} & \textbf{UD}  \\
        \midrule[1pt]
        MRPC & 90.5 & 89.7 (to be improve) \\
        QQP & 85.9 (to improve) & \textbf{91.6} \\
        PAWS & 95.1 & \textbf{97.2} \\
        WikiQA  & 96.1 & \textbf{96.5}\\
        CosmosQA & 88.4 & \textbf{90.7}\\
        DREAM & 90.5 & \textbf{91.6} \\
        QuAIL & 65.6 & \textbf{80.2} \\
        QuaRel & 88.2 & \textbf{95.3}\\
        QuaRTz & 94.1 & \textbf{94.5} \\
        SciQ & 97.6& \textbf{98.1}\\
        SocialIQA &  \textbf{82.2} & 81.7 \\
        WikiHop & & 58.6\\
        Amazon & \textbf{97.6}(to improve) & 97.3 \\
        IMDB & \textbf{96.9} & 96.7\\
        Rotten & 93.4 & \textbf{93.6} \\
        Yelp & 72.28 (first two prompts) & 68.1 (hard to improve)\\
        AGNews & 95.1 & \textbf{95.3} \\
        DBPedia & & \\
        TREC & 96.7 & \textbf{97.8}\\
        \bottomrule[1pt]
    \end{tabular}
    }
    \caption{Results on finetuned tasks for UD and the baseline T0. Both methods use T5-XXL as a base model. T0 has 2x model parameters compared to UD.}

    % compared with state-of-the-art results.}
    \label{tab:finetunedtasks}
\end{table}