\begin{figure}[t]
    \centering%
    % TODO nominal & ours with the same iterations
    \subplot{scatter/gal}{GAL}
    \subplot{scatter/dverge}{Dverge}
    % \subplot{trs}{TRS~\cite{yang2021trs}}
    % \subplot{dverge}{Dverge with logits~\cite{yang2020dverge}}
    \subplot{num_models/logits}{Robust sub-models \vs{} attacks}
    % \begin{subfigure}[b]{0.3\textwidth}
    %     \centering\includegraphics[
    %         scale=0.8, trim=0 10pt 0 0
    %     ]{loss_surface/softmax_adv_sub}%
    %     \caption{\attack{} loss.}\label{fig:loss:ours}
    % \end{subfigure}
    % \includegraphics[width=\linewidth]{figures/scatter_compare_with_other_method/softmax_gal_ensemble_8_0.03.pdf}%
    \caption{%
        (\subref{fig:scatter/gal},\subref{fig:scatter/dverge})
        Existing attacks~\cite{
            madry18,carlini17,croce20aa,mao2021caa,ye2022aaa}
        with strong baselines
        are neither efficient
        in the number of model forward/backward passes,
        nor reliable in the estimation of ensemble robustness
        when compared with \attack.
        GAL~\cite{kariyappa2019gal}
        and Dverge~\cite{yang2020dverge}
        defenses are trained on \cifarx{}
        with 8 sub-models.
        We used \( \linf \) attacks
        within \( \epsilon = 0.01 \),
        ``Nominal'' is self-reported.
        (\subref{fig:num_models/logits})
        \attack{} can successfully fool
        logit-based ensembles
        (ADP~\cite{pang2019adp}, GAL and Dverge)
        even with the majority of their sub-models
        giving correct outputs
        (``\( A \rightarrow B \)''
         means using \( A \) to attack \( B \)
         for up to 100 iterations).
    }\label{fig:intro:motivation}
\end{figure}%
