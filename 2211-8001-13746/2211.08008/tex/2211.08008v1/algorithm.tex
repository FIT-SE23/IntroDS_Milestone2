% chk-tex
\begin{algorithm}[t]
\caption{%
    The \attack{} white-box robust evaluation for ensemble defenses.
}\label{alg:overview}
\algnewcommand{\IfThen}[2]{% \IfThenElse{<if>}{<then>}
    \State{\algorithmicif\ {#1}\ \algorithmicthen\ {#2}}}
\algnewcommand{\IfThenElse}[3]{% \IfThenElse{<if>}{<then>}{<else>}
    \State{\algorithmicif\ {#1}\ %
    \algorithmicthen\ {#2}\ \algorithmicelse\ {#3}}}
\newcommand{\algcmt}{\algorithmiccomment}
\newcommand{\submodelset}{\f{\bracks{1:M}}}
\begin{algorithmic}[1]
    \Function{\tt\attack\_\,Attack}{$
        \submodelset,
        \x, \y, \beta, \tau, \momentum, \epsilon, I
    $}
        \State{\(
            \xadv_0 \gets \project\left(
                \x + \mathbf{u}
            \right),\,\text{where}\,
            \mathbf{u} \sim \uniform{-\epsilon, \epsilon}
         \)}
        \algcmt{Random init}
        \State{\( \m_0 \gets 0 \)}
        \For{\( i \in \bracks{0:I-1} \)}
            \State{\(
                \logit{m} \gets \f{m}\parens{\xadv_i}
             \) for all \(  {m} \in [1:M]  \)}
            \algcmt{Sub-model predictions}
            \State{\(
                \logit{\E} \gets
                    \frac1M \ssum_{m \in [1:M]}
                    \ensop\parens{\logit{m}}
             \)}
            \algcmt{Ensemble prediction}
            \State{\( \dl\E \gets \logit\E_\y - \logit\E_\hy \)}
            \IfThen{\( \dl\E \leq 0 \)}{\Return{\( \xadv_i \)}}
            \algcmt{Successful attack}
            \State{\(
                \bm{g}_{i + 1} \gets
                    \sign\parens{\nabla_{\xadv_i}
                        \attackloss\parens{
                        \logit{1:M}, \logit\E, y
                    }
                }
             \)}
            \algcmt{Sign-gradient with the \attack{} loss}
            \State{\(
                \stepsize \gets \epsilon \parens*{
                    1+\cos \parens*{ \nicefrac{i\pi}{I} }
                }
             \)}
            \algcmt{Cosine step-size schedule}
            \State{\(
                \m_{i + 1} \gets \project\left(
                    \m_i + \stepsize \bm{g}_{i + 1}
                \right)
             \)}
            \algcmt{Iterative update}
            \State{\(
                \xadv_{i + 1} \gets \project\left(
                    \xadv_i + {}
                    \momentum \left( \m_{i+1} - \xadv_i \right) +
                    (1 - \momentum) \left( \xadv_i - \xadv_{i - 1} \right)
                \right)
             \)}
            \algcmt{\ldots with momentum}
        \EndFor{}
        \State{\Return{\( \xadv_I \)}}
        \algcmt{Give up after \( I \) iterations}
    \EndFunction%
\end{algorithmic}
\end{algorithm}%
