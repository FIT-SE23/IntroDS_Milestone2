{
    "2203.05154": {
        "title": "Practical Evaluation of Adversarial Robustness via Adaptive Auto Attack",
        "authors": [
            "Ye Liu",
            "Yaya Cheng",
            "Lianli Gao",
            "Xianglong Liu",
            "Qilong Zhang",
            "Jingkuan Song"
        ],
        "submission_date": "2022",
        "SemanticScholarId": "8d21ff9eb99fb2482461ef6269f89d4350cb9450"
    },
    "2111.05328": {
        "title": "Data Augmentation Can Improve Robustness",
        "authors": [
            "Sylvestre-Alvise Rebuffi",
            "Sven Gowal",
            "D. A. Calian",
            "Florian Stimberg",
            "Olivia Wiles",
            "Timothy Mann"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "e4f7fb7a00fdc6dbc7de1deb4cf2d558a3f4d443"
    },
    "2110.09468": {
        "title": "Improving Robustness using Generated Data",
        "authors": [
            "Sven Gowal",
            "Sylvestre-Alvise Rebuffi",
            "Olivia Wiles",
            "Florian Stimberg",
            "D. A. Calian",
            "Timothy Mann"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "9c8d46b59e871e18d8d2e1ec1aa9b96d2f3d7342"
    },
    "2106.10189": {
        "title": "Adversarial Training Helps Transfer Learning via Better Representations",
        "authors": [
            "Zhun Deng",
            "Linjun Zhang",
            "Kailas Vodrahalli",
            "Kenji Kawaguchi",
            "James Y. Zou"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "ef5ae093db63435b51681704de64fad4e95a01c4"
    },
    "2104.09284": {
        "title": "LAFEAT: Piercing Through Adversarial Defenses with Latent Features",
        "authors": [
            "yunrui yu",
            "Xitong Gao",
            "Chengzhong Xu"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "e94d4b4c7b16cd9713aaf6d9dc31dea0f484abfb"
    },
    "2104.00671": {
        "title": "TRS: Transferability Reduced Ensemble via Promoting Gradient Diversity and Model Smoothness",
        "authors": [
            "Zhuolin Yang",
            "Linyi Li",
            "Xiaojun Xu",
            "Shiliang Zuo",
            "Qiang Chen",
            "Benjamin I. P. Rubinstein",
            "Pan Zhou",
            "Ce Zhang",
            "Bo Li"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "c526dcd91152cc4b155e4e76c6ee3ec931b321df"
    },
    "2012.05434": {
        "title": "Composite Adversarial Attacks",
        "authors": [
            "Xiaofeng Mao",
            "Yuefeng Chen",
            "Shuhui Wang",
            "Hang Su",
            "Yuan He",
            "Hui Xue"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "2afc07df53deb068d5daf538e84d447224e37a7d"
    },
    "2009.14720": {
        "title": "DVERGE: Diversifying Vulnerabilities for Enhanced Robust Generation of Ensembles",
        "authors": [
            "Huanrui Yang",
            "Jingyang Zhang",
            "Hongliang Dong",
            "Nathan Inkawhich",
            "Andrew B. Gardner",
            "Andrew Touchet",
            "Wesley Wilkes",
            "Heath Berry",
            "H. Li"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "b3b88cb29938a5445edd543b0498a51c4931f840"
    },
    "2003.01690": {
        "title": "Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks",
        "authors": [
            "Francesco Croce",
            "Matthias Hein"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "18939eadc9c4460c8385e0591cde214a1ead067b"
    },
    "2002.08347": {
        "title": "On Adaptive Attacks to Adversarial Example Defenses",
        "authors": [
            "Florian Tramèr",
            "Nicholas Carlini",
            "Wieland Brendel",
            "A. Ma̧dry"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "58c143069444c7dff4be53531a47efefc40be497"
    },
    "1910.09338": {
        "title": "An Alternative Surrogate Loss for PGD-based Adversarial Testing",
        "authors": [
            "Sven Gowal",
            "Jonathan Uesato",
            "Chongli Qin",
            "Po-Sen Huang",
            "Timothy A. Mann",
            "Pushmeet Kohli"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "1c004973fff36cbec999ada6f033873f888cbbac"
    },
    "1908.09163": {
        "title": "Targeted Mismatch Adversarial Attack: Query With a Flower to Retrieve the Tower",
        "authors": [
            "Giorgos Tolias",
            "Filip Radenovic",
            "Ondřej Chum"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "12d795865741f04b020f66fa9dc50a551c39d171"
    },
    "1908.01517": {
        "title": "Adversarial Self-Defense for Cycle-Consistent GANs",
        "authors": [
            "D. Bashkirova",
            "Ben Usman",
            "Kate Saenko"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "c2d6cf8933e6c034bf2a81b0a061115bcb1d9b9a"
    },
    "1905.13736": {
        "title": "Unlabeled Data Improves Adversarial Robustness",
        "authors": [
            "Y. Carmon",
            "Aditi Raghunathan",
            "Ludwig Schmidt",
            "Percy Liang",
            "John C. Duchi"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "b3f1aa12dde233aaf543bb9ccb27213c494e0fd5"
    },
    "1901.09981": {
        "title": "Improving Adversarial Robustness of Ensembles with Diversity Training",
        "authors": [
            "S. Kariyappa",
            "Moinuddin K. Qureshi"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "d4473a41c9f7b4095599bec14ea0a88e7041e737"
    },
    "1901.08846": {
        "title": "Improving Adversarial Robustness via Promoting Ensemble Diversity",
        "authors": [
            "Tianyu Pang",
            "Kun Xu",
            "Chao Du",
            "Ning Chen",
            "Jun Zhu"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "676e40050453ddeb1387f8314478c0ac3681a8c6"
    },
    "1901.08573": {
        "title": "Theoretically Principled Trade-off between Robustness and Accuracy",
        "authors": [
            "Hongyang Zhang",
            "Yaodong Yu",
            "Jiantao Jiao",
            "E. Xing",
            "L. Ghaoui",
            "Michael I. Jordan"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "6c405d4b5dc41a86be05acd59c06ed19daf01d14"
    },
    "1811.03194": {
        "title": "AdVersarial: Perceptual Ad Blocking meets Adversarial Machine Learning",
        "authors": [
            "Florian Tramèr",
            "Pascal Dupré",
            "Gili Rusak",
            "Giancarlo Pellegrino",
            "D. Boneh"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "b053e3b7e50a02d8c170285a9afcac3653a5c784"
    },
    "1805.12152": {
        "title": "Robustness May Be at Odds with Accuracy",
        "authors": [
            "Dimitris Tsipras",
            "Shibani Santurkar",
            "Logan Engstrom",
            "Alexander Turner",
            "A. Ma̧dry"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "1b9c6022598085dd892f360122c0fa4c630b3f18"
    },
    "1802.00420": {
        "title": "Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples",
        "authors": [
            "Anish Athalye",
            "Nicholas Carlini",
            "D. Wagner"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "651adaa058f821a890f2c5d1053d69eb481a8352"
    },
    "1711.09404": {
        "title": "Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients",
        "authors": [
            "A. Ross",
            "F. Doshi-Velez"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "ac8e45a0451ac578f17f631fc2663ee4b98b83a9"
    },
    "1706.06083": {
        "title": "Towards Deep Learning Models Resistant to Adversarial Attacks",
        "authors": [
            "A. Ma̧dry",
            "Aleksandar Makelov",
            "Ludwig Schmidt",
            "Dimitris Tsipras",
            "Adrian Vladu"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "7aa38b85fa8cba64d6a4010543f6695dbf5f1386"
    },
    "1608.04644": {
        "title": "Towards Evaluating the Robustness of Neural Networks",
        "authors": [
            "Nicholas Carlini",
            "D. Wagner"
        ],
        "submission_date": "2016",
        "SemanticScholarId": "df40ce107a71b770c9d0354b78fdd8989da80d2f"
    },
    "1512.03385": {
        "title": "Deep Residual Learning for Image Recognition",
        "authors": [
            "Kaiming He",
            "X. Zhang",
            "Shaoqing Ren",
            "Jian Sun"
        ],
        "submission_date": "2015",
        "SemanticScholarId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d"
    },
    "1412.6572": {
        "title": "Explaining and Harnessing Adversarial Examples",
        "authors": [
            "I. Goodfellow",
            "Jonathon Shlens",
            "Christian Szegedy"
        ],
        "submission_date": "2014",
        "SemanticScholarId": "bee044c8e8903fb67523c1f8c105ab4718600cdb"
    },
    "1312.6199": {
        "title": "Intriguing properties of neural networks",
        "authors": [
            "Christian Szegedy",
            "Wojciech Zaremba",
            "I. Sutskever",
            "Joan Bruna",
            "D. Erhan",
            "I. Goodfellow",
            "R. Fergus"
        ],
        "submission_date": "2013",
        "SemanticScholarId": "d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad"
    }
}