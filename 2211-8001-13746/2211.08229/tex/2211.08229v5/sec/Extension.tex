\vspace{-1mm}
\section{Extension to Multi-modal CL}
\label{extension}
We also extend {\name} to attack image encoders in multi-modal CL~\cite{radford2021learning,jia2021scaling}, which uses image-text pairs to pre-train an image encoder and a text encoder. Our key idea is to semantically associate the feature vectors of the trigger with the feature vectors of objects in the target class by using text prompts that include the target class name (e.g., “a photo of dog”) as the medium. Appendix~\ref{multiCL} shows how we create poisoned image-text pairs and describes the experimental details. Our results show that {\name} outperforms the existing backdoor attack to multi-modal CL~\cite{carlini2022poisoning}, especially when the pre-training dataset only includes a few image-text pairs related to the target class. 
