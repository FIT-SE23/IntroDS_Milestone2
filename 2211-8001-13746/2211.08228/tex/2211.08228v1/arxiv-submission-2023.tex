%File: anonymous-submission-latex-2023.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage[submission]{aaai23}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS

% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\usepackage[graphicx]{realboxes}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{adjustbox}
\usepackage{bigstrut}
\usepackage{booktabs}
\usepackage{comment}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2023.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{1} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai23.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{When to Use What: An In-Depth Comparative Empirical Analysis of OpenIE Systems for Downstream Applications}
\author{
    %Authors
    % All authors must be in the same font size and format.
    Kevin Pei\textsuperscript{\rm 1}, Ishan Jindal\textsuperscript{\rm 2}, Kevin Chen-Chuan Chang\textsuperscript{\rm 1}, Chengxiang Zhai\textsuperscript{\rm 1}, Yunyao Li\textsuperscript{\rm 3}\\
    {\normalfont \textsuperscript{\rm 1} Grainger College of Engineering, University of Illinois at Urbana-Champaign}\\
    {\normalfont \textsuperscript{\rm 2} IBM Research}
    {\normalfont \textsuperscript{\rm 3} Apple Knowledge Platform}\\
    {\normalfont\{kspei2,kcchang,czhai\}@illinois.edu, Ishan.Jindal@ibm.com, yunyaoli@apple.com}
}
\affiliations{
    %Afiliations
    \textsuperscript{\rm 1}Association for the Advancement of Artificial Intelligence\\
    % If you have multiple authors and multiple affiliations
    % use superscripts in text and roman font to identify them.
    % For example,

    % Sunil Issar, \textsuperscript{\rm 2}
    % J. Scott Penberthy, \textsuperscript{\rm 3}
    % George Ferguson,\textsuperscript{\rm 4}
    % Hans Guesgen, \textsuperscript{\rm 5}.
    % Note that the comma should be placed BEFORE the superscript for optimum readability

    1900 Embarcadero Road, Suite 101\\
    Palo Alto, California 94303-3310 USA\\
    % email address must be in roman text type, not monospace or sans serif
    publications23@aaai.org
%
% See more examples next
}


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract}
Open Information Extraction (OpenIE) has been used in the pipelines of various NLP tasks.
Unfortunately, there is no clear consensus on which models to use in which tasks.
Muddying things further is the lack of comparisons that take differing training sets into account.
In this paper, we present an application-focused empirical survey of neural OpenIE models, training sets, and benchmarks in an effort to help users choose the most suitable OpenIE systems for their applications.
We find that the different assumptions made by different models and datasets have a statistically significant effect on performance, making it important to choose the most appropriate model for one's applications.
We demonstrate the applicability of our recommendations on a downstream Complex QA application.
\end{abstract}
\section{Introduction}

Open Information Extraction (OpenIE) is the task of extracting relation tuples from plain text \cite{angeli2015leveraging}. 
In its simplest form, OpenIE extracts information in the form of tuples consisting of \textit{subject\emph{(S)}}, \textit{predicate\emph{(P)}}, \textit{object\emph{(O)}}, and any \textit{additional arguments\emph{(A)}}. 
OpenIE is open domain, intended to be easy to deploy in different domains without fine-tuning. 
The tuples extracted by OpenIE consist of tokens from the original text, allowing for the extraction of all relations regardless of type. 
Models largely fall into two categories: models with hand-crafted extraction patterns and models with automatically learned extraction patterns \cite{niklaus2018survey}. 
The increasing availability of semi-automatically generated training datasets using previous OpenIE methods \cite{cui2018neural}, as well as significant advances in deep learning modeling techniques such as LSTM have led to the development of state-of-the-art neural models that automatically learn extraction patterns \cite{cui2018neural, garg2018supervising}. 



Since its introduction in \citet{etzioni2008open}, OpenIE has attracted a large amount of attention by the research community for use as a tool for a wide range of downstream NLP tasks such as Slot Filling \cite{soderland2013open, angeli2015leveraging}, Question Answering (QA) \cite{fader2013paraphrase, khot2017answering}, Summarization \cite{cao2018faithful, ponza2018facts}, and Event Schema Induction \cite{balasubramanian2013generating, romadhony2019utilizing}.
However, there is no real consensus on which OpenIE model is best for which application.
We can observe this lack of consensus in summarization, where different papers use OLLIE \cite{christensen2014hierarchical}, MinIE \cite{ponza2018facts}, and Stanford CoreNLP \cite{cao2018faithful, zhang2021far} as their OpenIE models.
Different applications may also have different best OpenIE models.
As an example, choosing a model that assumes all relations only have a subject and object may not be suitable for event schema induction since that excludes any event schemas with more than two entities.
The papers that introduce new OpenIE models and datasets do not specify how downstream applications would be impacted by the different assumptions those papers make about which relations to extract.

We find that prior OpenIE surveys are also insufficient to find the best OpenIE model for a given application.
The only previous application-focused OpenIE survey we found was \citet{mausam2016open}.
However, this survey does not identify the desired properties of OpenIE for those applications or provide an empirical comparison of OpenIE systems.
\citet{niklaus2018survey} provide a taxonomy of OpenIE models, but does not include any comparison of datasets or an empirical study.
\citet{glauber2018systematic} and \citet{claro2019multilingual} also do not provide an empirical application-focused survey.



Another problem is the lack of apples-to-apples comparisons between OpenIE models.
Comparisons should keep the training set, benchmark, and evaluation metric constant when comparing models to eliminate confounders.
Unfortunately, the papers that introduce new OpenIE models and datasets often do not provide this apples-to-apples comparison.
For example, CopyAttention \cite{cui2018neural}, SpanOIE \cite{zhan2020span}, IMoJIE \cite{kolluru2020imojie}, and OpenIE6 \cite{kolluru2020openie6} all compare their model to models trained on different training sets.
OpenIE6 reports performance on WiRE57 which Multi$^2$OIE \cite{ro2020multi} does not, but Multi$^2$OIE reports performance on ReOIE2016 which OpenIE6 does not.
Because the training set can greatly affect the performance of a neural model, we focus on selecting both the appropriate OpenIE model and training set, which we refer to as an \textit{OpenIE System}. 

To resolve our lack of understanding, we focus on the particular question: \textit{How do I choose a particular OpenIE system for a given application?}
Different implicit assumptions about OpenIE may have a significant impact on the performance of downstream applications such as the assumptions that all relations are verb-based \cite{zhan2020span} or that all relations have only a subject and object \cite{kolluru2020imojie}. %, that the predicates and arguments of all relations are contiguous in the text \cite{stanovsky2018supervised}, or that each predicate only forms a relation with one set of arguments \cite{ro2020multi}.
%The papers that introduce new OpenIE models and datasets do not specify how downstream applications would benefit from the novelties they introduce, making it difficult to answer this question. 
To answer this question an apples-to-apples comparison must be conducted for different application settings, keeping the training data, benchmark, and evaluation criteria constant while comparing models.



Because it is impractical to find the best model for every application given the many possible applications of OpenIE, we instead characterize applications based on what properties they desire from OpenIE.
For example, the desire for N-ary relation extraction by event schema induction.
We use these properties to characterize OpenIE models and datasets and then evaluate whether those properties result in meaningful differences in performance.
In the process of answering these questions we provide an extensive apples-to-apples comparison of existing neural OpenIE models such that a practitioner can utilize our practical observations to effectively select a neural OpenIE model and training set for their downstream application. 
Finally, we apply our recommendations to a downstream Complex QA task.
We hope our survey provides insight into how to select OpenIE models and datasets for future practitioners' applications. 
In summary, our contributions are as follows:
\begin{itemize}
    \item We propose a comprehensive taxonomy that covers OpenIE training sets, benchmarks, evaluation metrics, and neural models.
    \item We present an extensive empirical comparison of different models on different datasets with recommendations based on the results.
    \item We perform a case study on Complex QA to show the efficacy of our recommendations.
\end{itemize}

To the best of our knowledge, our survey is the only application-focused empirical survey on OpenIE datasets and recent neural OpenIE methods.
%The paper is organized as follows: Section 2 introduces applications which have used OpenIE and what properties they have explicitly desired.
%Sections 3-5 introduce OpenIE datasets, models, and evaluation metrics and characterizes them by those desired properties.
%Sections 3-4 provide a taxonomy of OpenIE training sets, benchmarks, evaluation metrics, and neural models.
%Section 5 presents the experiments we have performed to answer \textit{Q1} and \textit{Q2} and an analysis of the results.
%Section 5 presents the experiments we have performed to obtain a fair comparison of OpenIE systems and an analysis of the results for recommendation.
%Section 6 presents our conclusions.

\begin{table*}[]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lccccc}
\toprule
\multicolumn{1}{l}{}                                       & \begin{tabular}[c]{@{}c@{}}Question \\ Answering\end{tabular} & Slot Filling          & \begin{tabular}[c]{@{}c@{}}Event Schema \\ Induction\end{tabular} & Summarization         & \begin{tabular}[c]{@{}c@{}}Knowledge Base \\ Population\end{tabular} \\ \midrule
\textbf{\textsl{HR}}: Higher Recall                & \cmark                                         & \cmark & \cmark                                             & \cmark & \cmark                                                                                               \\
\textbf{\textsl{HP}}: Higher Precision             &                                          & \cmark &                                              & \cmark &                                                                                                 \\
\textbf{\textsl{N-ary}}: N-ary Relation Extraction              & \cmark                                         & \cmark & \cmark                                             &  &                                                                                                 \\
\textbf{\textsl{IN}}: Inferred Relation Extraction     & \cmark                                         & \cmark & \cmark                                             & \cmark &                                                                                                 \\
%\textbf{\textsl{CE}}: Canonicalized Extractions    & \cmark                                         &  &                                              &  &                                                                                                 \\
%\textbf{\textsl{IRE}}: Imperative Relation Extraction & \cmark                                         &  &                                              & \cmark &                                                                                                 \\
\textbf{\textsl{FE}}: Fast Extraction &                                          &  &                                              & &  \cmark                                                                                               \\ \bottomrule
\end{tabular}%
}
\caption{Properties explicitly mentioned in application papers as motivation for choosing a particular OpenIE model or as a way to improve performance within a case study. There are additional desired properties we omit that no existing models or datasets have, such as the canonicalization of extracted relations and extracting relations from imperative sentences \cite{fader2013paraphrase, khot2017answering, zhang2021far}.}
\label{table:applications}
\end{table*}




\section{Motivating Applications}
% \section{Motivation}

In this section, we identify the properties of OpenIE systems desired by 5 downstream applications: \textit{Slot Filling}, \textit{Question Answering (QA)}, \textit{Summarization}, \textit{Event Schema Induction}, and \textit{Knowledge Base Population}.
%We omit other applications that utilize OpenIE for the sake of brevity.
We survey how OpenIE is used in each of the applications and the properties explicitly desired based on the corresponding papers, either as motivation for choosing a given OpenIE model or within a case study as a property that would improve performance.
%We then formulate research questions to measure whether these properties actually have a noticeable effect on performance.

The desired properties we observe are Higher Recall, Higher Precision, N-ary Relation Extraction, Inferred Relation Extraction, and Fast Extraction.
We define an "Inferred Relation" (IN) to be a relation where the predicate contains words that are not in the original sentence.
For example, given the sentence "Bill Gates, former CEO of Microsoft, is a Harvard dropout", the relation (Bill Gates, was, former CEO of Microsoft) can be inferred even though "was" is not in the original sentence.
We define an "N-ary Relation" (N-ary) to be a relation with more arguments than just (subject, predicate, object).
For instance, the relation (Alice, baked, Bob, a pie) has an additional argument.



\noindent\textbf{Slot Filling}
Slot filling is a task where an incomplete tuple must be completed using information from a given corpus \cite{chen2019bert}.
For example, given the incomplete tuple (Obama, born in, ?), extract (Obama, was born in, Honolulu) using information from the corpus.
%OpenIE can be used to extract tuples from the corpus, which can be linked to the incomplete tuple using entity linking methods.
In this task, OpenIE is used to extract complete tuples which are used to fill slots by linking those tuples to tuples missing slots using entity linking methods.
OpenIE can be used by extracting complete tuples which are linked to the incomplete tuple using entity linking methods.
The incomplete tuple can then be completed by using the complete tuple extracted using OpenIE.
Because OpenIE is not constrained to a predefined schema, it is useful for extracting different surface forms of relations.
\citet{soderland2013open}, \citet{angeli2015leveraging}, \citet{soderland2015university}, and \citet{soderland2015combining} take advantage of how correct relations often appear multiple times in text to match empty slots to the highest precision OpenIE tuple.
\citet{soderland2013open}, \citet{angeli2015leveraging}, \citet{soderland2015university}, and \citet{soderland2015combining} all state in their case studies they would benefit from the ability to extract inferred relations (\textsl{IN}), and \citet{soderland2015university} and \citet{soderland2015combining} state they would benefit from the ability to extract n-ary relations (\textsl{N-ary}).
These two properties allow more surface forms of relations to be extracted, which allows for more slots to be filled.



\noindent\textbf{Question Answering}
We focus on 2 subtasks of QA that utilize OpenIE: Open-domain Question Answering (OpenQA) and Complex QA.
\citet{fader2013paraphrase,fader2014open,yin2015answering}, and \citet{clark2018think} are OpenQA methods that use retrieval-based methods to match OpenIE extractions to questions.
OpenQA involves answering questions given a large database \cite{fader2014openqa}.
By rewriting queries into incomplete tuples, it is possible to use relations extracted from the database to answer queries by filling in the missing slots in the query.
For example, rewriting the query "Where was Obama born?" into slot filling the tuple (Obama, born in, ?) and answering using the relation (Obama, was born in, Honolulu).
%\citet{fader2014open} and \citet{yin2015answering} utilize a knowledge base (KB) generated from Open IE relation tuples by retrieving tuples matching the query from the KB.
\citet{fader2014open} and \citet{yin2015answering} obtain those relations from a knowledge base of OpenIE extractions.

Complex questions must use information from multiple sentences to find answers and require inferring relationships between multiple entities\cite{chali2009complex}.
\citet{khot2017answering} and \citet{lu2019answering} generate graphs from extracted relation tuples, then reason over these graphs to answer the questions.

In all QA applications surveyed, high recall (\textsl{HR}) is desired, with \citet{lu2019answering} using a custom OpenIE method specifically to obtain a higher recall.
\citet{yin2015answering}'s case studies state that \textsl{N-ary} in particular would benefit performance while \citet{lu2019answering} uses a custom OpenIE method that supports \textsl{IN}.
Several methods already paraphrase questions so that the surface forms of extracted relations match at least one of the question paraphrases, indicating that extracting more surface forms of a relation would answer more questions \cite{fader2013paraphrase, fader2014open, yin2015answering}.



\noindent\textbf{Summarization} 
OpenIE addresses the problems of redundancy and fact fabrication in summarization.
%The summarization methods surveyed use the heuristic that two pieces of text that contain the same relations most likely contain the same information.
%This heuristic is used both to reduce redundancy of summaries and to ensure that the summary only generates facts that are present in the original text.
% \cite{christensen2014hierarchical} use OpenIE for hierarchical summarization.
%Hierarchical summarization is a task where the goal is to generate a hierarchy of summaries, with summaries higher in the hierarchy providing a general overview and those lower in the hierarchy providing more detailed summaries of an aspect of the high-level summary.
% In this task, OpenIE is used to identify redundancy by seeing if there are matching extracted relation tuples in different levels of the hierarchy.
% \cite{cao2018faithful} and \cite{zhang2021far} utilize OpenIE for abstractive summarization, using OpenIE to ensure that the generated summary only contains relations from the original text.
% \cite{zhang2021far} also prevents redundancy by ensuring there are not extra relations in the generated summary compared to relations in the gold standard summary.
% \cite{ponza2018facts} use graphs constructed from OpenIE relations to extract the most salient facts from a given document, which forms a summary of the document.
%In this task, OpenIE is used to identify redundancy by seeing if there are matching extracted relation tuples in different levels of the hierarchy. 
To combat redundancy in hierarchical and abstractive summarization, OpenIE is used to ensure that the generated summary does not have repeated relations or more relations than the gold standard summary \cite{christensen2014hierarchical, zhang2021far}.
To combat fact fabrication in abstractive summarization, OpenIE is used to ensure that the generated summary only contains relations from the original text \cite{cao2018faithful,zhang2021far}.
% and to ensure that there are not extra relations in the generated summary compared to relations in the gold standard summary \cite{zhang2021far}  .
%Further, \cite{ponza2018facts} use graphs constructed from OpenIE relations to extract the most salient facts from a given document, which forms a summary of the document.
In summarization tasks, \textsl{HR} is useful to ensure summaries contain all information, with \citet{ponza2018facts} citing greater diversity of extractions as a way to improve performance.
The exception is \citet{zhang2021far}, where high precision (\textsl{HP}) is desired in order to reduce redundant extractions.





\noindent\textbf{Event Schema Induction} 
Event Schema Induction is the automatic discovery of patterns that indicate events and the agents and their roles within that event.
Extracted relation tuples can be used to find surface forms of events, with repeated extracted tuples being used to induce event schemas.
The open nature of OpenIE allows for events to be found regardless of the domain or surface form of the event.
% \cite{balasubramanian2013generating}, \cite{romadhony2019utilizing}, and \cite{sahnoun2020event} utilize OpenIE in Event Schema Induction, mapping predicates to events and arguments to agents of the event.
Predicates of extracted tuples are generally mapped to events and arguments to agents of the event \cite{balasubramanian2013generating,romadhony2019utilizing,sahnoun2020event}.
\textsl{HR} is useful for Event Schema Induction for the same reason it is useful for Slot Filling: finding more surface forms of an event allows for more event schemas to be induced.
\citet{sahnoun2020event} also specifically desire \textsl{IN} so that more event schemas can be learned, while \citet{balasubramanian2013generating} state that \textsl{N-ary} would improve performance.





\noindent\textbf{Knowledge Base Population} 
OpenIE's open-domain nature has led to its use in automatically populating knowledge bases (KBs).
The relations extracted by OpenIE can be used to create new nodes and edges in KBs.
\citet{muhammad2020open} and \citet{kroll2021toolbox} use learning-based OpenIE models because of their ability to generalize to unseen relations and achieve \textsl{HR}.
\citet{kroll2021toolbox} also explicitly chooses Stanford CoreNLP and OpenIE6 because of their fast extraction times (\textsl{FE}).

%Therefore, depending on the desired property of the downstream application the choice of the OpenIE system could be different. 
%Depending on the desired property of the downstream application the choice of the OpenIE system could be different. 
% \Ishan{Summarize and merge different properties.}
We use these desired properties to formulate research questions in Section \ref{sub:rq}.
Table \ref{table:applications} provides a summary of applications and their explicitly desired properties.




\begin{table*}[]
\centering
%\begin{adjustbox}{width=0.8\linewidth}
\resizebox{\textwidth}{!}{%
\begin{tabular}{clccrrrrc}
\toprule
& \multicolumn{1}{l}{\textbf{Dataset}}             & \textbf{\begin{tabular}[c]{@{}c@{}}Creation Method\end{tabular}} & \textbf{Source}                                                          & \multicolumn{1}{c}{\textbf{\#Extractions}} & \multicolumn{1}{c}{\textbf{\#IN}} & \multicolumn{1}{c}{\textbf{\#N-ary}} \\ \midrule
% \multicolumn{1}{c}{{\underline{\textbf{Training Sets}} }} & \textbf{}                                                           & \textbf{}                                                                & \multicolumn{1}{c}{\textbf{}}              & \multicolumn{1}{c}{\textbf{}}           & \multicolumn{1}{c}{\textbf{}}        & \multicolumn{1}{c}{\textbf{}}                    & \textbf{}             \\
\multirow{5}{*}{\begin{tabular}[c]{@{}c@{}}Training\\ Sets\end{tabular}} &SpanOIE                                          & \begin{tabular}[c]{@{}c@{}}Weak Labeling\end{tabular}            & Wikipedia                                                                & 2,175K                                     & 2K                                                                       & 231K                                 \\
& OIE4                                             & \begin{tabular}[c]{@{}c@{}}Weak Labeling\end{tabular}            & Wikipedia                                                                & 181K                                       & 3K                                                                        & 34K                                  \\
& IMoJIE                                           & \begin{tabular}[c]{@{}c@{}}Weak Labeling\end{tabular}            & Wikipedia                                                                & 215K                                       & 3K                                                                        & 0                                    \\
& LSOIE                                            & \begin{tabular}[c]{@{}c@{}}Weak Labeling\end{tabular}  & \begin{tabular}[c]{@{}c@{}}QA-SRL 2.0 Wikipedia, Science\end{tabular} & 101K                                       & 0                                                                          & 32K                                  \\ \midrule
% {\underline{ \textbf{Test Sets}}}                         &                                                                     &                                                                          &                                            &                                         &                                      &                                      &                                              \\
\multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}Test\\ Sets\end{tabular}}  & OIE2016                                          & \begin{tabular}[c]{@{}c@{}}Weak Labeling\end{tabular}            & QA-SRL                                                                   & 1,730                                      & 359                                                                       & 708                                  \\
& WiRe57                                           & \begin{tabular}[c]{@{}c@{}}Manual Annotation\end{tabular}        & \begin{tabular}[c]{@{}c@{}}Wikipedia and Newswire\end{tabular}        & 343                                        & 173                                                                       & 79                                   \\
& ReOIE2016                                        & \begin{tabular}[c]{@{}c@{}}Manual Annotation\end{tabular}        & OIE2016                                                                  & 1,508                                      & 155                                                                      & 611                                  \\
& CaRB                                             & \begin{tabular}[c]{@{}c@{}}Crowdsourced Annotation\end{tabular}  & OIE2016                                                                  & 5,263                                      & 736                                                                       & 683                                  \\
& LSOIE                                            & \begin{tabular}[c]{@{}c@{}}Weak Labeling\end{tabular}            & \begin{tabular}[c]{@{}c@{}}QA-SRL 2.0 Wikipedia, Science\end{tabular} & 22,376                                     & 0                                                                      & 4,920                               \\ \bottomrule
%& BenchIE                                          & \begin{tabular}[c]{@{}c@{}}Manual Annotation\end{tabular}        & OIE2016                                                                  & 1,350                                      & N/A                                                                      & N/A                                  \\ \bottomrule
\end{tabular}%
%\end{adjustbox}
}
\caption{Comparison of the attributes of different datasets. $\#$Extractions: Number of Extractions, $\#$IN  : Number of inferred relations, $\#$N-ary: Number of N-ary Relations.}
\label{table:datasets}
\end{table*}


\section{Datasets}


In this section, we discuss the differences between different OpenIE training sets and benchmarks and what properties they possess.
We also briefly touch on different evaluation metrics.
The common principles that guide the creation of OpenIE training sets and benchmarks are \textit{Assertedness}, \textit{Minimal Propositions/Atomicity}, and \textit{Completeness and Open Lexicon} \cite{stanovsky2016creating, lechelle2018wire57, bhardwaj2019carb}.
\textit{Assertedness} means the relation must be implied by the original sentence alone.
\textit{Minimal Propositions} means each relation should include as few words as possible while retaining meaning.
\textit{Completeness and Open Lexicon} means all relations should be extracted, without a predefined domain or scope.
%\begin{itemize}
%    \item \textbf{Assertedness} A relation must be asserted in the original sentence instead of extracting implied relations.
%            For instance, given the sentence \textit{“Sam succeeded in convincing John”} the extractions should be (Sam, succeeded in convincing, John) and not (Sam, convinced, John).
%    \item \textbf{Minimal Propositions/Atomicity} A extracted relation should be as short as possible without losing any information from         the relation.
%            This may lead to relations with conjunctions with conjunctions being split into two relations.
%            An example would be the sentence \textit{"Sam talked to John and Lisa"} where (Sam, talked to, John) and (Sam, talked to, Lisa) are extracted instead of (Sam, talked to, John and Lisa).
%    \item \textbf{Completeness and Open Lexicon} All extractions are considered without being restricted to a particular domain.
%            However, in practice some OpenIE datasets make certain assumptions such as the absence of inferred relations that affect their completeness compared to other OpenIE datasets.
%\end{itemize}

Despite these common guiding principles, OpenIE datasets still differ in their creation method and subsequently have differing properties.
We provide statistics about different datasets in table \ref{table:datasets}.




\subsection{Training Datasets}

Given how data-hungry deep learning models are and how costly it is to manually label OpenIE datasets, most OpenIE training sets are weakly labeled using high confidence extractions from prior OpenIE models to get "silver-standard" labels.
\textbf{CopyAttention} \cite{cui2018neural}, \textbf{SpanOIE} \cite{zhan2020span}, and \textbf{OIE4} \cite{kolluru2020imojie} are training sets consisting of high confidence OpenIE4 extractions from Wikipedia.
Unlike CopyAttention and OIE4, SpanOIE includes low-quality extractions with pronoun arguments.
%However, instead of setting a hard confidence threshold, \citet{zhan2020span} consider extractions of all confidences so that low-quality extractions with pronoun arguments are considered.
%Although OpenIE4 supports \textsl{P4}, these datasets do not support \textsl{P4}.
%The \textbf{OIE4} dataset introduced by \citet{kolluru2020imojie} uses OpenIE4 to extract 180,517 extractions from Wikipedia and has properties \textsl{P3} and \textsl{P4}.
%The \textbf{OIE4} dataset introduced by \citet{kolluru2020imojie} uses OpenIE4 to extract from Wikipedia and has properties \textsl{P3} and \textsl{P4}.
%The \textbf{IMoJIE} dataset \cite{kolluru2020imojie} attempts to get higher quality labels by combining Wikipedia extractions from OpenIE4, ClausIE \cite{del2013clausie}, and RNNOIE, using a common scoring metric to combine extractions and filtering out repeated extractions.
The~\textbf{IMoJIE}~dataset \cite{kolluru2020imojie} attempts to get higher quality labels by combining Wikipedia extractions from OpenIE4, ClausIE, and RNNOIE, using a common scoring metric to combine extractions and filtering out repeated extractions.
%Rather than simply taking all high confidence extractions from each method and pooling them together, \citet{kolluru2020imojie} address the issues of incomparable confidence scores, repeated extraction, and potential extraction errors with a score-and-filter approach.
%Score-and-filter scores extractions using the generation score of IMoJIE and filters the highest scoring extractions to remove repeated extractions.
%\citet{kolluru2020imojie} address the issues of incomparable confidence scores, repeated extraction, and potential extraction errors with a score-and-filter approach, using a common scoring metric and filtering the highest scoring extractions to remove repeated extractions.
%In contrast to prior weakly labeled training sets, \citet{solawetz2021lsoie} introduce a dataset automatically converted from the crowdsourced QA-SRL Bank 2.0 dataset, which consists of both a Wikipedia and a Science domain.
The \textbf{LSOIE} training set \cite{solawetz2021lsoie} is composed of automatically converted Semantic Role Labeling (SRL) extractions with high inter-annotator agreement from the Wikipedia and Science domain of the crowdsourced QA-SRL Bank 2.0 dataset.
Because this dataset is derived from SRL, all relations are assumed to be verb-based and only contain words in the original sentence.



\subsection{Benchmarks}

\textbf{OIE2016} \cite{stanovsky2016creating} is a benchmark for OpenIE automatically derived from the crowdsourced QA-SRL dataset annotated on PropBank and Wikipedia sentences.
%To convert the SRL extractions to OpenIE extractions, there are two steps.
%First, all questions where pronouns are the only answer arguments are removed.
%Then, all combinations of answer arguments combined with the predicate are extracted.
\textbf{WiRe57} \cite{lechelle2018wire57} consists of expert annotations for 57 sentences.
\textbf{CaRB} \cite{bhardwaj2019carb} uses crowdsourcing to re-annotate the sentences in the OIE2016 benchmark.
In contrast to other OpenIE datasets, each extraction contains as much information as possible in the arguments, meaning prepositions are part of the arguments and not the predicate.
\textbf{ReOIE2016} \cite{zhan2020span} uses manual annotation to re-annotate OIE2016 to attempt to resolve problems arising from incorrect extraction.
The \textbf{LSOIE} \cite{solawetz2021lsoie} training set has a corresponding benchmark derived using the same source and rules.
\textbf{BenchIE} \cite{gashteovski2021benchie} is derived from CaRB and is based on the idea that extracted relations need to exactly match at least one gold standard out of a set of equivalent manually annotated relations to be useful for downstream applications.

%Ultimately, the decision of what benchmark to use will affect the decision of which model and training set to choose.
%If the chosen benchmark matches the user's application setting, then high scoring models on the chosen benchmark will be the most useful for that user's application.
%As a result, it's important to choose the benchmark that has properties that match the application setting.
%Users should choose a benchmark with properties that match their application setting.
%The resulting benchmark will affect which model and training set are most appropriate.

Some of these benchmarks introduce new evaluation metrics.
%There are three major classes of evaluation metric: lexical matching, sentence-level matching, and word-level matching.
\textbf{OIE2016} introduces \textit{lexical matching}, which treats extraction as a binary classification task.
A predicted relation is matched to a gold standard relation if the heads of the predicate and all arguments are the same.
%\textbf{BenchIE} uses sentence-level matching, only matching predicted relations to gold standard relations if they match exactly.
\textbf{WiRe57} and \textbf{CaRB} use \textit{word-level matching}, which calculate recall and precision based on the proportion of matching tokens in the predicted and gold standard relations.
The difference between the two is that there is a greater penalty to recall for \textbf{WiRe57} if there are fewer predicted relations than relations in the gold standard.
%They calculate precision the same way and differ in how they calculate recall, with the recall of \textbf{WiRe57} being higher than the recall of \textbf{WiRe57}.


%\textbf{OIE2016} \cite{stanovsky2016creating} uses lexical matching, treating OpenIE as a binary classification task.
%A predicted relation is matched to a gold standard relation if the heads of the predicate and all arguments are the same.
%Precision and recall are calculated based on whether the extractions are true positives, false positives, true negatives, or false negatives.
%ReOIE2016 \cite{zhan2020span} and LSOIE \cite{solawetz2021lsoie} share this evaluation metric.

\textbf{BenchIE} uses sentence-level matching.
Sentence-level matching requires an exact match of the predicate and arguments instead of just the heads like lexical matching.
Instead of a set of gold tuples to represent the gold standard relations, fact sets represent the gold standard relations.
Each fact set consists of a set of equivalent relations and a predicted relation is considered a true positive for a given relation if it matches a relation within the fact set exactly.

Because of BenchIE's reliance on fact sets which other benchmarks lack, the BenchIE metric is only compatible with BenchIE and no other metrics can be used with the BenchIE dataset.
As a result, an apples-to-apples comparison of the BenchIE dataset and metric are not possible like with other datasets and metrics, so we do not report performance on BenchIE.

%\textbf{WiRe57} \cite{lechelle2018wire57} uses word-level matching, with precision as the proportion of tokens in the predicted relation that are in the gold standard relation and recall as the proportion of tokens in the gold standard relation that are in the prediction relation.
%Predicted relations are matched to the gold standard relations that maximizes the F1-score.
%Predicted relations can only be matched to gold standard relations that share at least one token in the predicate and all arguments.
%\textbf{CaRB} \cite{bhardwaj2019carb} also uses word-level matching, but the matching of predicted to gold standard relations differs.
%When computing recall, a predicted relation can be matched to any number of gold standard relations.
%This is intended to not penalize systems that combine multiple relations into one, such as those that contain %conjunctions.
%When computing precision, a predicted relation can only be matched to one gold standard relation.
%The final matching is the one that maximizes the F-score.
%Additionally, the predicted and gold standard relations only need to share a word in the predicate to be matched.

%\textbf{WiRe57} \cite{lechelle2018wire57} uses word-level matching, with precision as the proportion of tokens %in the predicted relation that are in the gold standard relation and recall as the proportion of tokens in the %gold standard relation that are in the prediction relation.
%\textbf{CaRB} \cite{bhardwaj2019carb} also uses word-level matching, but with an alternate way of computing %recall that allows multiple predicted relations to be matched to the same gold standard relation.



\begin{table}[]
\centering
\begin{adjustbox}{width=0.9\linewidth}
\begin{tabular}{lccc}
\toprule
\multicolumn{1}{l}{\textbf{Model}} & \textbf{\begin{tabular}[c]{@{}c@{}}Problem Formulation\end{tabular}} & \textbf{N-ary}    & \textbf{IN} \\ \midrule
%SpanOIE                            & \begin{tabular}[c]{@{}c@{}}Span Classification\end{tabular}          & \cmark &  \\
SpanOIE                            & \begin{tabular}[c]{@{}c@{}}Labeling\end{tabular}          & \cmark &  \\
IMoJIE                             & Generation                                                              &  &  \\
Multi$^2$OIE                          & Labeling                                                                & \cmark &  \\
IGL-OIE                            & Labeling                                                                &  & \cmark \\
CIGL-OIE                           & Labeling                                                                &  & \cmark \\
OpenIE6                            & Labeling                                                                &  & \cmark \\ \bottomrule
\end{tabular}%
\end{adjustbox}
\caption{Comparison of neural OpenIE models.}
\label{table:models}
\end{table}



\section{Models}

In this section, we present recent neural OpenIE models and the properties that set them apart.
OpenIE models can be categorized based on how they formulate the OpenIE problem: as a text generation or labeling problem.
Different models also possess different properties depending on what assumptions they make about relations.
We provide overviews of the models in table \ref{table:models}.


\subsection{Generative Problem Formulation}

Generative OpenIE models cast OpenIE as a sequence-to-sequence problem, taking the sentence as input and attempting to generate all relations in the sentence as output.
%Generative OpenIE models take a sentence as input and attempt to generate all relations in the sentence as output.
\textbf{CopyAttention} \cite{cui2018neural} generates extractions using GloVe embeddings and a 3-layer stacked Long Short-Term Memory (LSTM) as the encoder and decoder.
%The vocabulary is limited to tokens in the original sentence and special tokens to indicate the predicate and arguments of each relation.
%As a result, emphasis is placed on the copy mechanism, which uses attention to copy tokens from the input to the output.
\textbf{IMoJIE} \cite{kolluru2020imojie} builds upon CopyAttention by using BERT embeddings and introducing \textit{iterative extraction} to combat repeated extractions.
\textit{Iterative extraction} is the appending of extractions to the end of the sentence before being used as input so the model can identify what relations have previously been extracted at the cost of significantly reduced extraction speed.
%Kolluru et al. observed that previous OpenIE methods sometimes extracted the same relation multiple times %but with different levels of detail, such as omitting a temporal or location argument.
%To combat this, IMoJIE appends extractions to the input after each extraction.
%However, this significantly reduces the speed of IMoJIE.
\textbf{Adversarial-OIE} \cite{han2021generative} uses a Generative Adversarial Network (GAN) to generate extractions.
The model consists of a sequence generator model that takes BERT and position embeddings as input and generates extractions, and an adversary model that tries to distinguish between relations in the gold standard and relations extracted by the sequence generator model.

Generative models rely on a copy mechanism to copy vocabulary from the original sentence, meaning they can not generate tokens that are not in the original sentence and subsequently can not extract \textsl{IN} relations.


\subsection{Labeling Problem Formulation}

Labeling OpenIE models cast OpenIE as a sequence labeling problem, taking the sentence as input and labeling each token in the sentence with its role in each relation, usually using a BIO tagging scheme.
%Labeling OpenIE models take a sentence as input and label each token in the sentence with its role in each relation, usually using a BIO tagging scheme.
Labeling models can be further subdivided into Piecewise and Holistic Labeling.

%\subsubsection{Piecewise Labeling}
\textbf{Piecewise Labeling} models label predicates and arguments in different stages.
\textbf{RnnOIE} \cite{stanovsky2018supervised} is a bi-directional LSTM (BiLSTM) transducer inspired by SRL that firsts labels predicates and then labels arguments with BIO tags for each extracted predicate.
%Predicates are obtained from the gold standard during training and identified with verb POS tags at test time.
\textbf{SpanOIE} \cite{zhan2020span} is also based on SRL, using a BiLSTM to perform span classification instead of BIO tagging.
Span classification enables the use of span features, which can be richer than word-level features.
%First, candidate spans for the predicate are generated and evaluated, and then candidate spans for the arguments are generated based on the predicates.
%The final relations extracted are the relation spans with the highest scores.
\textbf{Multi$^2$OIE}'s \cite{ro2020multi} novelty is multi-head attention and BERT embeddings.
After labeling the predicates, multi-head attention is used between the predicate and the rest of the sentence to label the arguments.
%BIO tags are used for labeling, and BERT is used for word embeddings.
\textbf{MILIE} \cite{kotnis2021integrating} introduces its own \textit{iterative prediction}, the process of extracting one component of the relation tuple at a time, for multilingual OpenIE.
Extraction can be performed predicate first, subject first, or object first, followed by any of the remaining components.
The intention was to make multilingual extraction easier, in case other languages benefited from different extraction orders.
%Depending on the language, extraction can be performed predicate first, subject first, or object first, followed by any of the remaining components.
\textbf{DetIE} \cite{vasilkovsky2022detie} uses ideas from single-shot object detection to make predictions more quickly than previous methods.

Uniquely, piecewise labeling models label all predicates in a sentence simultaneously and assume that for each predicate, there is only one set of arguments.
This means that they can not extract multiple relations that share the same predicate, unlike generative and holistic labeling models.
%Generative models can generate multiple relations with the same predicate and holistic labeling models extract multiple relations from a sentence independently, making this limitation unique to piecewise labeling models.
%This is a problem unique to piecewise labeling methods, since generative models can generate multiple relations with the same predicate and holistic labeling models perform the entire extraction process multiple times for each sentence, allowing multiple relations with the same predicates and arguments to be extracted.



\textbf{Holistic Labeling} models label predicates and arguments simultaneously
%\textbf{SenseOIE} \cite{garg2018supervising} is an ensemble model that takes the predictions of multiple models as input along with several types of embeddings.
\textbf{OpenIE6} \cite{kolluru2020openie6} introduces grid labeling, constraint rules, and conjunction rules to improve the labeling process.
Grid labeling is simultaneous extraction of multiple relations from a sentence.
Constraint rules are used to penalize certain things like repeated extractions or not extracting a relation for a head verb.
Conjunction rules are used to split relations containing conjunctions into two separate relations.
%These novelties reduce redundancy and satisfy the Minimal Propositions/Atomicity requirement of OpenIE.
IGL-OIE is the first stage, using only grid labeling; CIGL-OIE is the second stage, adding in constraint rules; OpenIE6 is the final stage, using conjunction rules to handle relations that contain conjunctions.

Labeling models generally can not label tokens that are not in the original sentence, meaning they can not extract \textsl{IN} relations.
The exceptions are IGL-OIE, CIGL-OIE, and OpenIE6, which explicitly allows for the extraction of "be" relations even if they are not in the original sentence.



\section{Experiments}

In this section, we describe how we compare OpenIE models and datasets for the sake of recommendation.
In our experiments, we focus on the reported state-of-the art models for English OpenIE, the most widely-used English benchmarks with associated papers, and the 4 training sets used by those models.
We then use OpenIE in a downstream Complex QA task to demonstrate the applicability of our recommendations.

When comparing OpenIE systems, we place a greater emphasis on F1 score than AUC.
%One further note should be made about how AUC is calculated.
The original implementations of CaRB, OIE2016, and WiRe57 use the trapezoidal rule to calculate the area under the PR curve.
It is assumed that all PR curves have data points at recall 0, precision 1.
This means that methods without low recall points on the PR curve will have inflated AUC values.
For example, for the CaRB test set using the CaRB metric, CIGL-OIE trained on OIE4 has a minimum recall of 0.214 with precision 0.678 at confidence 1.0, while Multi$^2$OIE trained on SpanOIE has a minimum recall of 0.0003 with precision 0.5 at confidence 1.0.
Considering just these lowest recall data points, CIGL-OIE has an AUC of 0.180, while Multi$^2$OIE has an AUC of 0.0002, meaning CIGL-OIE already has a large inherent advantage in AUC without considering the higher confidence data points.
As a result, we consider the highest F1 score on the PR curve to be a better metric than AUC when evaluating overall model performance.


\subsection{Research Questions}
\label{sub:rq}

To find the best system for different applications, we test whether the properties of OpenIE models and datasets have a statistically significant effect on accuracy in benchmarks with properties that correspond to the desires of downstream applications.
If there is no significant difference between the performance of OpenIE systems with different properties, then the chosen system should be the system with the best overall empirical performance.
In addition to how model and dataset properties affect accuracy, we are also interested in how the choice of model affects efficiency in order to satisfy the fast extraction property (\textsl{FE}).
Generally, generative models are much slower than labeling models \cite{kolluru2020openie6}.
Subsequently, we investigate whether the efficiency difference between model types is significant.

\begin{enumerate}
        \item \textbf{R1:} How does whether a model supports N-ary relation (\textsl{N-ary}) extraction and whether the training set contains \textsl{N-ary} affect the F1 score of a model on test sets with \textsl{N-ary}?
    
        \item \textbf{R2:} How does whether a model supports inferred relation  (\textsl{IN}) extraction and whether the training set contains \textsl{IN} affect the F1 score of a model on test sets with or without \textsl{IN}?
    
        \item \textbf{R3:} How does the model type affect efficiency as measured by the number of sentences relations are extracted from per second (Sen./Sec)?
    
\end{enumerate}



% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[]
\centering
\begin{adjustbox}{width=\linewidth}
\begin{tabular}{lrrrrrrr}
\toprule
\multirow{2}{*}{Model} & \multirow{2}{*}{Sen./Sec.}      & \multicolumn{3}{c}{CaRB}                                               & \multicolumn{3}{c}{WiRE 57}                                            \\ \cmidrule(lr){3-5} \cmidrule(lr){6-8}
                                &                                 & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} \\ \midrule
SpanOIE                         & 13.40                           & 0.474                 & 0.464                 & 0.433                  & 0.474                 & 0.374                 & 0.375                  \\
IMoJIE                          & 2.07                            & 0.598                 & 0.431                 & 0.488                  & 0.598                 & 0.355                 & 0.428                  \\
Multi$^2$OIE                    & 29.22                           & \textbf{0.626}        & 0.501                 & \textbf{0.552}         & \textbf{0.624}        & 0.419                 & \textbf{0.488}         \\
IGL-OIE                         & \textbf{84.07} & 0.574                 & 0.442                 & 0.497                  & 0.574                 & 0.365                 & 0.434                  \\
CIGL-OIE                        & 68.80                           & 0.490                 & \textbf{0.531}        & 0.503                  & 0.489                 & 0.429                 & 0.442                  \\
OpenIE6                         & 28.36                           & 0.394                 & 0.518                 & 0.438                  & 0.394                 & \textbf{0.463}        & 0.413                  \\ \hline
\end{tabular}%
\end{adjustbox}
\caption{Performances of different models with different evaluation metrics averaged across training and test data.}
\label{table:avg_model_performance}
\end{table}



% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[]
\centering
\begin{adjustbox}{width=\linewidth}
\begin{tabular}{llrrrrrr}
\toprule
\multirow{2}{*}{Training Set} & \multirow{2}{*}{Test Set} & \multicolumn{3}{c}{CaRB}                                               & \multicolumn{3}{c}{WiRE 57}                                            \\  \cmidrule(lr){3-5} \cmidrule(lr){6-8}
                                       &                           & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} \\ \midrule
SpanOIE                                & OIE2016                   & 0.485          & 0.502                 & 0.478          & 0.484          & 0.420                 & 0.434          \\
OIE4                                   & OIE2016                   & 0.537          & 0.493                 & 0.511          & 0.536          & 0.410                 & 0.461          \\
LSOIE                                  & OIE2016                   & \textbf{0.620} & \textbf{0.538}        & \textbf{0.564} & \textbf{0.620} & \textbf{0.447}        & \textbf{0.508} \\
IMoJIE                                 & OIE2016                   & 0.446          & 0.449                 & 0.423          & 0.445          & 0.378                 & 0.382          \\ \midrule
SpanOIE                                & WiRe57                    & 0.411          & 0.371                 & 0.381          & 0.415          & 0.199                 & 0.261          \\
OIE4                                   & WiRe57                    & \textbf{0.470} & \textbf{0.374}        & \textbf{0.416} & \textbf{0.469} & 0.211                 & \textbf{0.289} \\
LSOIE                                  & WiRe57                    & 0.347          & 0.208                 & 0.257          & 0.347          & 0.127                 & 0.183          \\
IMoJIE                                 & WiRe57                    & 0.421          & 0.370                 & 0.373          & 0.419          & \textbf{0.223}        & 0.266          \\ \midrule
SpanOIE                                & ReOIE2016                 & 0.636          & \textbf{0.635}        & \textbf{0.615} & 0.636          & \textbf{0.622}        & \textbf{0.610} \\
OIE4                                   & ReOIE2016                 & \textbf{0.720} & 0.565                 & 0.597          & \textbf{0.720} & 0.553                 & 0.590          \\
LSOIE                                  & ReOIE2016                 & 0.622          & 0.527                 & 0.558          & 0.622          & 0.516                 & 0.552          \\
IMoJIE                                 & ReOIE2016                 & 0.586          & 0.588                 & 0.554          & 0.584          & 0.569                 & 0.544          \\ \midrule
SpanOIE                                & CaRB                      & 0.529          & 0.446                 & 0.471          & 0.526          & 0.313                 & 0.378          \\
OIE4                                   & CaRB                      & \textbf{0.604} & \textbf{0.449}        & \textbf{0.513} & \textbf{0.604} & \textbf{0.317}        & \textbf{0.412} \\
LSOIE                                  & CaRB                      & 0.532          & 0.344                 & 0.412          & 0.532          & 0.255                 & 0.337          \\
IMoJIE                                 & CaRB                      & 0.517          & 0.429                 & 0.447          & 0.514          & 0.315                 & 0.360          \\ \midrule
SpanOIE                                & LSOIE                     & 0.461          & 0.573                 & 0.501          & 0.461          & 0.525                 & 0.477          \\
OIE4                                   & LSOIE                     & 0.505          & 0.566                 & 0.532          & 0.505          & 0.517                 & 0.506          \\
LSOIE                                  & LSOIE                     & \textbf{0.653} & \textbf{0.686}        & \textbf{0.660} & \textbf{0.653} & \textbf{0.629}        & \textbf{0.629} \\
IMoJIE                                 & LSOIE                     & 0.419          & 0.508                 & 0.440          & 0.419          & 0.473                 & 0.427          \\ \hline
\end{tabular}%
\end{adjustbox}
\caption{Performances of different training and test sets averaged across models.}
\label{table:avg_dataset_performance}
\end{table}



\subsection{Experimental Setup}

\noindent\textbf{Models:} We compare \textit{SpanOIE}, \textit{IMoJIE}, \textit{Multi$^2$OIE}, and the 3 stages of OpenIE6: \textit{IGL-OIE}, \textit{CIGL-OIE}, and \textit{OpenIE6}. 
These models are publicly available, with Multi$^2$OIE and OpenIE6 being state-of-the-art for labeling models and IMoJIE being state-of-the-art for generative models. 
For each model, we train them with their original dev set and their original hyperparameters.
We run all experiments using a Quadro RTX 5000 GPU.


\noindent\textbf{Training Datasets:} We train the models on the \textit{SpanOIE}, \textit{OIE4}, \textit{IMoJIE}, and \textit{LSOIE} training sets. 
%\footnote{The SpanOIE dataset we use for experiments is a subset of the dataset used to train CopyAttention in \citet{cui2018neural}}
The LSOIE training set contains both the Science and Wikipedia domain sentences to increase the amount of training data. 
Due to the input structure of SpanOIE and Multi$^2$OIE models, they can not be trained on training datasets with inferred relations. 
We remove any inferred relations from the training sets of those models.
Similarly, as IMoJIE and OpenIE6 can not extract N-ary relations, we convert all N-ary relations in the training set into binary relations by moving arguments beyond the subject and object into the object. 
For instance, the relation (Alice, baked, Bob, a pie) was converted into (Alice, baked, Bob a pie). 
None of these limitations apply to the test sets.


\noindent\textbf{Benchmarks:} We evaluate all the models on the publicly available English benchmarks \textit{OIE2016}, \textit{WiRE57}, \textit{ReOIE2016}, \textit{CaRB}, and \textit{LSOIE}. 

\noindent\textbf{Evaluation Metrics:} We use \textit{OIE2016}'s, \textit{WiRE57}'s, and \textit{CaRB}'s metrics for evaluation.
%The BenchIE metric is only applicable to the BenchIE benchmark and the BenchIE benchmark can only be evaluated using the BenchIE metric.
We compare performance using primarily F1 score to address \textsl{HR} and \textsl{HP} and sentences extracted per second to address \textsl{FE}.
%We measure performance using F1 score to address \textsl{HR} and \textsl{HP} and sentences extracted per second to address \textsl{FE}.
We perform student's t-test between OpenIE system, test set, and evaluation metric configurations to answer \textbf{R1}, \textbf{R2}, and \textbf{R3}. 
For \textbf{R1} and \textbf{R2} the t-scores are computed using the per-sentence F1 scores of each method.
For \textbf{R3} the t-scores are computed using the mean sentences per second for each training set and test set combination for a given model, resulting in 24 data points per model.
We do not measure the time required to extract from each individual sentence because it can be difficult to measure given the parallel execution of each mode.



\section{Results}

\subsection{Overall Evaluation}
In this section, we perform an apples-to-apples comparison among different OpenIE systems to first determine the SoTA OpenIE model and then to determine the best general-purpose OpenIE training dataset. 

\noindent\textbf{Best OpenIE Model} We compare the different models on different evaluation metrics averaged across different training and test sets in Table \ref{table:avg_model_performance}. 
We observe that across all evaluation metrics  Multi$^2$OIE and  the CIGL-OIE have the highest or second highest F1 score.
This means that independent of training and test sets the \textit{Labeling} OpenIE models are better than the \textit{Span Classification} and \textit{Generative} models. 
We also observe that \textit{Labeling} OpenIE models are more efficient than the \textit{Span Classification} and \textit{Generative} models, extracting from more sentences per second.

\noindent\textbf{Best OpenIE Training Set} Because performance on a test set is also greatly dependent on the training set depending on the domain and generation method of the training and test sets, we determine the best training set for each test set.
In Table \ref{table:avg_dataset_performance}, we compare different training and test set combinations with different evaluation metrics averaged across models.
We observe that the models trained on LSOIE training set perform best on the OIE2016 and LSOIE test sets. 
%It is because that LSOIE training set and both OIE2016 and LSOIE test sets are derived from different versions of QA-SRL and generated using the same rules.  
This is because the LSOIE training set and the OIE2016 and LSOIE test sets are derived from different versions of QA-SRL and generated using the same rules.  
On the WiRe57, ReOIE2016, and CaRB test sets, we observe that the models trained on the OIE4 and SpanOIE training sets generally perform the best. 
It is likely because the OIE4 and SpanOIE training sets contain \textsl{N-ary} and \textsl{IN} relations like the WiRe57, ReOIE2016, and CaRB test sets.
Other training sets lack one or both of these properties.



\begin{table}[]
\centering
\begin{adjustbox}{width=\linewidth}
\begin{tabular}{l|l}
\toprule
\textbf{Sentence}  & \begin{tabular}[c]{@{}l@{}}A short distance to the east, NC 111 diverges \\ on Greenwood Boulevard.\end{tabular}   \\ \hline
\textbf{Multi2OIE} & (NC 111, diverges, on Greenwood Boulevard)                                                                         \\ \hline
\textbf{CIGL-OIE}  & \begin{tabular}[c]{@{}l@{}}(NC 111, diverges, A short distance to the east \\ on Greenwood Boulevard)\end{tabular} \\ \midrule
\end{tabular}%
\end{adjustbox}
\caption{A demonstration that CIGL-OIE tends to extract longer arguments than Multi$^2$OIE. Multi$^2$OIE is trained on SpanOIE and CIGL-OIE is trained on OIE4. The sentence is from the CaRB test set.}
\label{table:extraction_comparison}
\end{table}


Of the two models with the highest average CaRB F1 scores, Multi$^2$OIE and CIGL-OIE, Multi$^2$OIE has higher average precision while CIGL-OIE has higher average recall.
CIGL-OIE tends to extract longer objects than Multi$^2$OIE as seen in table \ref{table:extraction_comparison}, which may explain this difference.



\subsection{Research Questions}

To answer our research questions, we perform student's t-test using the CaRB F1 scores of the highest scoring model, training set, and test set combinations for each setting.
%To answer \textbf{R1} and \textbf{R2}, we have 2 independent variables: whether the model supports \textsl{N-ary} or textsl{IN} extraction, and whether the training data has \textsl{N-ary} or\textsl{IN} relations.
%\noindent \textbf{Research Question 1}
We perform comparisons of OpenIE systems, where one aspect (model or training set) is changed and the other aspects are kept constant.
%We perform 4 comparisons of 2 methods, where the independent variable and constants change for each comparison.
%For each combination of test set and evaluation metric, we choose whatever model and training set combination has the highest F1 score and matches the chosen aspects and calculate the t-score.
Then, we choose the test set and evaluation metric for the two settings that results in the highest t-score between methods, which is used to answer \textbf{R1} and \textbf{R2}. %hypotheses H1$_0$ and H2$_0$.

For \textbf{R1}, we conclude (1) regardless of training set, the best \textsl{N-ary} models perform better than the best non-\textsl{N-ary} models; (2) regardless of the model, training on the best \textsl{N-ary} training sets results in higher performance than training on the best non-\textsl{N-ary} training sets. 
Therefore \textbf{if an application benefits from \textsl{N-ary}, then the best OpenIE system should include either a \textsl{N-ary} model, \textsl{N-ary} training set, or both}, with both being preferred if both are available.
%Generally speaking, the recommendation would be to use a \textsl{N-ary} model and \textsl{N-ary} training set if both are available.


For \textbf{R2}, we infer that \textsl{IN} models are better than non-\textsl{IN} models when there is either a \textsl{IN} training and \textsl{IN} test set, or when there is a non-\textsl{IN} training and non-\textsl{IN} test set.
\textsl{IN} training sets are better than non-\textsl{IN} training sets when there is an \textsl{IN} model and \textsl{IN} test set.
In the case of non-\textsl{IN} and \textsl{IN} test set, it is unclear whether \textsl{IN} or non-\textsl{IN} training sets are superior.
Therefore \textbf{if an application benefits from \textsl{IN}, then the chosen training set and model should either both be \textsl{IN} or both be non-\textsl{IN}. 
If an application benefits from non-\textsl{IN}, then the chosen training set should be non-\textsl{IN}, and subsequently the chosen model should be \textsl{IN}.}
%Generally speaking, the recommendation would be to use a \textsl{IN} model and non-\textsl{IN} training set if both are available.
%That way, the properties of the training and test set would be the same.


For \textbf{R3}, we compare the efficiency of the sole generative model, IMoJIE, to the efficiency of every other model.
From our results, we observe that every other model is faster than IMoJIE and the difference is statistically significant. %which matches with our expectations.
This makes intuitive sense, since generative models tend to have longer execution times than labeling models and it has been previously shown that IMoJIE is exceptionally slow compared to other OpenIE methods \cite{kolluru2020openie6}.
Therefore \textbf{if an application is concerned about efficiency, then the chosen OpenIE model should not be a generative model.}


\section{A Case Study: Complex QA}

To verify our recommendations, we perform a case study using QUEST \cite{lu2019answering}, a Complex QA method that uses OpenIE to extract entities and predicates from the question and from answer documents to generate knowledge graphs.
The nodes are entities derived from the subjects and objects, while the edges are predicates.
The knowledge graph is matched to the entities in the question and traversed to find potential answers.
Because more extractions result in a larger knowledge graph, QUEST benefits from \textsl{HR} which the authors use their own rule-based OpenIE method to achieve.


\subsection{Experimental Setup}

To test our recommendations, we replace the OpenIE method used by the authors with Multi$^2$OIE trained on SpanOIE, CIGL-OIE trained on OIE4, and OpenIE6 trained on OIE4.
We chose these models and training sets because they are the ones with the overall highest CaRB recall and F1 scores that match the properties desired by complex QA, namely \textsl{N-ary} and \textsl{IN}.


One caveat is that in order for QUEST to connect entities from multiple sentences, they must have the same surface form.
%QUEST resolves this by using a rule-based OpenIE method that extracts specific noun phrases.
Because OpenIE methods often extract long subjects and objects that include adjectives and modifiers, if the subject or object of an extraction contains entities extracted by QUEST, we add additional relations using those entities.
%we add the extractions of all OpenIE methods we use so that if their subject or object contains entities extracted by QUEST, we add additional relations using those entities.
For example, in the sentence "Hector Elizondo was nominated for a Golden Globe for his role in Pretty Woman," QUEST may extract the entities "Hector Elizondo," "Golden Globe," and "Pretty Woman."
If an OpenIE method were to extract the triple \textit{("Hector Elizondo", "was nominated", "for a Golden Globe for his role in Pretty Woman")}, we would add the additional extractions \textit{("Hector Elizondo", "was nominated", "Golden Globe")} and \textit{("Hector Elizondo", "was nominated", "Pretty Woman")}.
QUEST also performs preprocessing before running its rule-based OpenIE method, most prominently replacing pronouns with the entities they refer to.
This is because nodes in the knowledge graph can not be made using pronouns.
We replace pronouns using the same method QUEST does before running any OpenIE method.

We run QUEST using the CQ-W question set and search for answers in the Top-10 Google document set used in their paper. 
Because CIGL-OIE has the highest CaRB recall and OpenIE6 has the highest WiRe57 recall, we expect that using either of them will result in higher downstream performance than using Multi$^2$OIE.






% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[]
\centering
\begin{adjustbox}{width=\linewidth}
\begin{tabular}{lllrrr}
\toprule
\multicolumn{1}{l}{OpenIE} & \multicolumn{1}{c}{Questions} & \multicolumn{1}{c}{Documents} & \multicolumn{1}{c}{MRR} & \multicolumn{1}{c}{P@1} & \multicolumn{1}{c}{Hit@5} \\ \midrule
QUEST                                      & CQ-W                                   & Top 10                                 & 0.132                            & 0.080                            & 0.167                              \\ \midrule
CIGL-OIE                                   & CQ-W                                   & Top 10                                 & \textbf{0.111}                           & \textbf{0.060}                            & \textbf{0.167}                              \\
OpenIE6                                    & CQ-W                                   & Top 10                                 & 0.104                            & 0.060                            & 0.147                              \\
Multi2OIE                                  & CQ-W                                   & Top 10                                 & 0.094                            & 0.053                            & 0.140                              \\ \bottomrule
\end{tabular}%
\end{adjustbox}
\caption{Performance of QUEST using different OpenIE methods on the CQ-W dataset using the Top 10 Google documents. }
\label{table:QUEST}
\end{table}


\subsection{Evaluation}


We compare the Mean Reciprocal Rank (MRR), Precision@1 (P@1), and Hit@5 for each OpenIE model.
The results of our case study are summarized in table \ref{table:QUEST}.
We observe higher performance of CIGL-OIE and OpenIE6 than Multi$^2$OIE on QUEST, which matches our expectations based on the higher recall of CIGL-OIE and OpenIE6.
Our case study demonstrates the applicability of our empirical study to the use of OpenIE methods in downstream applications.

An important note is that oftentimes a great deal of pre- and post-processing is necessary to adapt OpenIE for different downstream applications.
Removing pronouns and adding additional entity-based extractions was necessary to achieve reasonable performance with different OpenIE methods in QUEST.
Even after modifying Multi$^2$OIE, CIGL-OIE, and OpenIE6 in this way, their performance is less than the original performance of QUEST.
%Although QUEST states that a high-recall OpenIE method is important, the exact metric is undefined.
%QUEST also states that overly long arguments are a poor fit for their method.
As a result, it is important for practitioners to not just consider the performance of OpenIE models on test sets matching their application, but to also consider how to adapt OpenIE to the specific needs of their application.




\section{Conclusion}

In this paper, we presented an application-focused empirical comparison of recent neural OpenIE models, training sets, and benchmarks.
%We first identified the two major motivations for this survey: a general comparison of OpenIE systems and a recommendation of specific OpenIE systems for downstream applications.
%We surveyed OpenIE applications, datasets, evaluation metrics, and neural models.
%We then discussed different downstream NLP applications that use OpenIE or OpenIE-derived knowledge graphs and the OpenIE properties each one desires, with a focus on 4 applications.
%We organize OpenIE models by generative and labeling, and identify the different properties each model possesses.
%We organize OpenIE training and test sets by their method of creation, either weakly labeled, crowdsourced, or manually annotated, and similarly identify the properties of each dataset.
%We then presented the different evaluation metrics associated with the OpenIE test sets, organized into lexical and word-level matching.
%We then survey OpenIE datasets, evaluation metrics, and neural models.
%After the survey, we perform a variety of experiments to perform an in-depth comparison of state-of-the-art OpenIE models with different properties, trained on a variety of training sets and evaluated on a variety of test sets with different evaluation metrics.
%After the survey, we perform experiments to compare state-of-the-art OpenIE models trained on a variety of training sets and evaluated on a variety of test sets with different evaluation metrics.
%We then performed apples-to-apples comparisons of neural OpenIE models trained on a variety of training sets and evaluated on a variety of test sets with different evaluation metrics.
Our experiments showed that the different properties of OpenIE models and datasets affect the performance, meaning it is important to choose the appropriate system for a given application and not just choose whatever model is state-of-the-art.
%We perform these experiments because although each OpenIE paper contains comparisons with previous OpenIE methods on different benchmarks, these comparisons are not comprehensive and do not take the training set into account.
%We find that the best overall OpenIE models are Multi$^2$OIE and CIGL-OIE.
%The best training sets are the ones that best match the test sets the trained models are evaluated on.
%We discovered that when evaulating on test sets with n-ary relations, models that can extract n-ary relations tend to be better than models that can't, and training sets containing n-ary relations tend to be better for training than training sets that don't.
%For test sets with inferred relations, models that can extract inferred relations are better than models that can't, and training sets containing inferred relations are better for training than training sets that don't.
%This trend does not hold for test sets that don't contain inferred relations.
%We also found that labeling OpenIE models outperform generative OpenIE models in both accuracy and efficiency.
%We hope that this survey can help users identify the best OpenIE system for their downstream applications and inspire new OpenIE research to create new models and datasets that can better address the properties desired by downstream applications.
We hope that this survey helps users identify the best OpenIE system for their downstream applications and inspires new OpenIE research into addressing the properties desired by downstream applications.


% Use \bibliography{yourbibfile} instead or the References section will not appear in your paper
\bibliography{aaai23}

\appendix

\label{sec:appendix}

\section{Appendix A: Empirical Results}
\label{sec:AppendixB}

In this section, we show the empirical results of training each model on a variety of training sets and evaluating them on a variety of test sets with different evaluation metrics. 
We also show the empirical results of our student's t-tests comparing different OpenIE systems.





\begin{table*}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lllrrrrrrrrrrrrr}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Model}} & \multicolumn{1}{c}{\multirow{2}{*}{Training set}} & \multicolumn{1}{c}{\multirow{2}{*}{Test set}} & \multicolumn{1}{c}{\multirow{2}{*}{Sen./Sec}} & \multicolumn{4}{c}{OIE2016}                                                                      & \multicolumn{4}{c}{WiRe57}                                                                       & \multicolumn{4}{c}{CaRB}                                                                         \\ \cmidrule(lr){5-8}  \cmidrule(lr){9-12}  \cmidrule(lr){13-16} 
\multicolumn{1}{c}{}                       & \multicolumn{1}{c}{}                              & \multicolumn{1}{c}{}                          & \multicolumn{1}{c}{}                          & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} \\ \midrule
SpanOIE                                    & SpanOIE                                           & OIE2016                                       & 16.65                                         & 0.704                 & 0.792                 & 0.745                  & 0.675                   & 0.576        & 0.376                 & 0.455                  & 0.296          & 0.576        & 0.459                 & 0.511                  & 0.362          \\
IMoJIE                                     & SpanOIE                                           & OIE2016                                       & 2.61                                          & 0.755        & 0.851                 & 0.8                    & 0.614                   & 0.575                 & 0.389                 & 0.464                  & 0.212                   & 0.575                 & 0.466                 & 0.515                  & 0.253                   \\
Multi$^2$OIE                                  & SpanOIE                                           & OIE2016                                       & 28.21                                         & 0.724                 & 0.915                 & 0.809                  & 0.719                   & 0.558                 & 0.439                 & 0.491         & 0.29                    & 0.566                 & 0.521                 & 0.542         & 0.348                   \\
IGL-OIE                                    & SpanOIE                                           & OIE2016                                       & 67.55                                & 0.733                 & 0.768                 & 0.75                   & 0.585                   & 0.551                 & 0.347                 & 0.426                  & 0.211                   & 0.551                 & 0.419                 & 0.476                  & 0.253                   \\
CIGL-OIE                                   & SpanOIE                                           & OIE2016                                       & 50.61                                         & 0.711                 & 0.981        & 0.824         & 0.737          & 0.375                 & 0.474                 & 0.419                  & 0.212                   & 0.375                 & 0.592        & 0.459                  & 0.263                   \\
OpenIE6                                    & SpanOIE                                           & OIE2016                                       & 23.32                                         & 0.519                 & 0.975                 & 0.678                  & 0.532                   & 0.269                 & 0.492        & 0.348                  & 0.177                   & 0.269                 & 0.556                 & 0.362                  & 0.2                     \\ \midrule
SpanOIE                                    & OIE4                                              & OIE2016                                       & 16.19                                         & 0.584                 & 0.454                 & 0.511                  & 0.36           & 0.584                 & 0.37                  & 0.453                  & 0.293          & 0.703                 & 0.813                 & 0.754                  & 0.692                   \\
IMoJIE                                     & OIE4                                              & OIE2016                                       & 3.44                                          & 0.553                 & 0.474                 & 0.51                   & 0.231                   & 0.553                 & 0.399                 & 0.464                  & 0.196                   & 0.695                 & 0.824                 & 0.754                  & 0.495                   \\
Multi$^2$OIE                                  & OIE4                                              & OIE2016                                       & 31.14                                         & 0.597        & 0.491                 & 0.539         & 0.32                    & 0.595        & 0.4                   & 0.478         & 0.261                   & 0.747        & 0.864                 & 0.801                  & 0.72                    \\
IGL-OIE                                    & OIE4                                              & OIE2016                                       & 70.02                                & 0.544                 & 0.48                  & 0.51                   & 0.313                   & 0.544                 & 0.39                  & 0.455                  & 0.257                   & 0.718                 & 0.84                  & 0.774                  & 0.661                   \\
CIGL-OIE                                   & OIE4                                              & OIE2016                                       & 49.26                                         & 0.529                 & 0.537        & 0.533                  & 0.356                   & 0.529                 & 0.436                 & 0.478         & 0.289                   & 0.718                 & 0.92                  & 0.806         & 0.726          \\
OpenIE6                                    & OIE4                                              & OIE2016                                       & 24.20                                         & 0.415                 & 0.523                 & 0.463                  & 0.314                   & 0.413                 & 0.467        & 0.438                  & 0.278                   & 0.557                 & 0.922        & 0.694                  & 0.615                   \\ \midrule
SpanOIE                                    & LSOIE                                             & OIE2016                                       & 15.36                                         & 0.657                 & 0.521                 & 0.581                  & 0.432                   & 0.657                 & 0.432                 & 0.521                  & 0.358                   & 0.657                 & 0.804                 & 0.723                  & 0.666                   \\
IMoJIE                                     & LSOIE                                             & OIE2016                                       & 1.00                                          & 0.719                 & 0.411                 & 0.523                  & 0.261                   & 0.719                 & 0.339                 & 0.461                  & 0.216                   & 0.852        & 0.766                 & 0.807                  & 0.577                   \\
Multi$^2$OIE                                  & LSOIE                                             & OIE2016                                       & 31.00                                         & 0.728        & 0.585                 & 0.649         & 0.483          & 0.728        & 0.484                 & 0.582         & 0.401          & 0.758                 & 0.894                 & 0.821                  & 0.767          \\
IGL-OIE                                    & LSOIE                                             & OIE2016                                       & 68.27                                & 0.636                 & 0.485                 & 0.551                  & 0.331                   & 0.636                 & 0.394                 & 0.487                  & 0.27                    & 0.762                 & 0.823                 & 0.791                  & 0.634                   \\
CIGL-OIE                                   & LSOIE                                             & OIE2016                                       & 52.40                                         & 0.568                 & 0.618        & 0.592                  & 0.391                   & 0.568                 & 0.494                 & 0.528                  & 0.314                   & 0.74                  & 0.947        & 0.831         & 0.738                   \\
OpenIE6                                    & LSOIE                                             & OIE2016                                       & 24.56                                         & 0.41                  & 0.609                 & 0.49                   & 0.315                   & 0.41                  & 0.541        & 0.466                  & 0.279                   & 0.542                 & 0.924                 & 0.683                  & 0.563                   \\ \midrule
SpanOIE                                    & IMoJIE                                            & OIE2016                                       & 7.16                                          & 0.084                 & 0.428                 & 0.14                   & 0.232                   & 0.084                 & 0.394                 & 0.138                  & 0.213                   & 0.188                 & 0.975                 & 0.316                  & 0.579                   \\
IMoJIE                                     & IMoJIE                                            & OIE2016                                       & 1.68                                          & 0.551                 & 0.451                 & 0.496         & 0.225                   & 0.551                 & 0.381                 & 0.451                  & 0.191                   & 0.779                 & 0.905                 & 0.837                  & 0.607                   \\
Multi$^2$OIE                                  & IMoJIE                                            & OIE2016                                       & 31.58                                         & 0.599        & 0.453                 & 0.516                  & 0.302                   & 0.596                 & 0.378                 & 0.463                  & 0.252                   & 0.764                 & 0.842                 & 0.801                  & 0.739                   \\
IGL-OIE                                    & IMoJIE                                            & OIE2016                                       & 63.00                                & 0.545                 & 0.396                 & 0.459                  & 0.238                   & 0.545                 & 0.323                 & 0.406                  & 0.194                   & 0.775                 & 0.797                 & 0.786                  & 0.592                   \\
CIGL-OIE                                   & IMoJIE                                            & OIE2016                                       & 49.62                                         & 0.509                 & 0.482                 & 0.495                  & 0.269                   & 0.509                 & 0.375                 & 0.432                  & 0.21                    & 0.775                 & 0.928                 & 0.845                  & 0.69                    \\
OpenIE6                                    & IMoJIE                                            & OIE2016                                       & 23.59                                         & 0.386                 & 0.484        & 0.43                   & 0.215                   & 0.386                 & 0.416                 & 0.4                    & 0.184                   & 0.582                 & 0.91                  & 0.71                   & 0.511                   \\ \bottomrule
\end{tabular}%
}
\caption{A table that lists performances of different OpenIE systems on the OIE2016 benchmark.}
\end{table*}




\begin{table*}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lllrrrrrrrrrrrrr}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Model}} & \multicolumn{1}{c}{\multirow{2}{*}{Training set}} & \multicolumn{1}{c}{\multirow{2}{*}{Test set}} & \multicolumn{1}{c}{\multirow{2}{*}{Sen./Sec}} & \multicolumn{4}{c}{OIE2016}                                                                      & \multicolumn{4}{c}{WiRe57}                                                                       & \multicolumn{4}{c}{CaRB}                                                                         \\ \cmidrule(lr){5-8}  \cmidrule(lr){9-12}  \cmidrule(lr){13-16} 
\multicolumn{1}{c}{}                       & \multicolumn{1}{c}{}                              & \multicolumn{1}{c}{}                          & \multicolumn{1}{c}{}                          & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} \\ \midrule
SpanOIE                                    & SpanOIE                                           & WiRe57                                        & 9.10                                          & 0.87                  & 0.72                  & 0.788                  & 0.673                   & 0.464                 & 0.194                 & 0.274                  & 0.142                   & 0.464                 & 0.372                 & 0.413                  & 0.272                   \\
IMoJIE                                     & SpanOIE                                           & WiRe57                                        & 0.91                                          & 0.863                 & 0.644                 & 0.738                  & 0.465                   & 0.461                 & 0.154                 & 0.231                  & 0.061                   & 0.461                 & 0.313                 & 0.373                  & 0.123                   \\
Multi$^2$OIE                                  & SpanOIE                                           & WiRe57                                        & 23.17                                         & 0.9                   & 0.758                 & 0.823                  & 0.698                   & 0.498                 & 0.203                 & 0.288                  & 0.097                   & 0.498                 & 0.391                 & 0.438                  & 0.186                   \\
IGL-OIE                                    & SpanOIE                                           & WiRe57                                        & 9.34                                          & 0.916                 & 0.638                 & 0.753                  & 0.604                   & 0.482                 & 0.167                 & 0.248                  & 0.097                   & 0.482                 & 0.333                 & 0.394                  & 0.189                   \\
CIGL-OIE                                   & SpanOIE                                           & WiRe57                                        & 7.75                                          & 0.889                 & 0.84                  & 0.864                  & 0.77                    & 0.281                 & 0.195                 & 0.231                  & 0.069                   & 0.283                 & 0.406                 & 0.333                  & 0.145                   \\
OpenIE6                                    & SpanOIE                                           & WiRe57                                        & 3.50                                          & 0.74                  & 0.831                 & 0.783                  & 0.641                   & 0.304                 & 0.28                  & 0.291                  & 0.127                   & 0.28                  & 0.408                 & 0.332                  & 0.167                   \\ \midrule
SpanOIE                                    & OIE4                                              & WiRe57                                        & 9.07                                          & 0.526                 & 0.397                 & 0.453                  & 0.303                   & 0.526                 & 0.217                 & 0.307                  & 0.166                   & 0.895                 & 0.743                 & 0.812                  & 0.704                   \\
IMoJIE                                     & OIE4                                              & WiRe57                                        & 1.19                                          & 0.414                 & 0.35                  & 0.379                  & 0.109                   & 0.414                 & 0.189                 & 0.26                   & 0.059                   & 0.823                 & 0.665                 & 0.735                  & 0.433                   \\
Multi$^2$OIE                                  & OIE4                                              & WiRe57                                        & 19.65                                         & 0.537                 & 0.37                  & 0.439                  & 0.194                   & 0.537                 & 0.197                 & 0.289                  & 0.104                   & 0.921                 & 0.717                 & 0.807                  & 0.67                    \\
IGL-OIE                                    & OIE4                                              & WiRe57                                        & 8.19                                          & 0.457                 & 0.337                 & 0.388                  & 0.22                    & 0.452                 & 0.174                 & 0.251                  & 0.111                   & 0.931                 & 0.673                 & 0.782                  & 0.653                   \\
CIGL-OIE                                   & OIE4                                              & WiRe57                                        & 6.82                                          & 0.436                 & 0.391                 & 0.413                  & 0.247                   & 0.436                 & 0.196                 & 0.27                   & 0.123                   & 0.9                   & 0.787                 & 0.84                   & 0.742                   \\
OpenIE6                                    & OIE4                                              & WiRe57                                        & 3.47                                          & 0.451                 & 0.397                 & 0.423                  & 0.261                   & 0.451                 & 0.295                 & 0.357                  & 0.192                   & 0.799                 & 0.755                 & 0.777                  & 0.662                   \\ \midrule
SpanOIE                                    & LSOIE                                             & WiRe57                                        & 8.52                                          & 0.357                 & 0.209                 & 0.263                  & 0.142                   & 0.357                 & 0.135                 & 0.196                  & 0.092                   & 0.759                 & 0.534                 & 0.627                  & 0.469                   \\
IMoJIE                                     & LSOIE                                             & WiRe57                                        & 0.46                                          & 0.351                 & 0.182                 & 0.24                   & 0.052                   & 0.351                 & 0.094                 & 0.148                  & 0.026                   & 0.961                 & 0.574                 & 0.719                  & 0.534                   \\
Multi$^2$OIE                                  & LSOIE                                             & WiRe57                                        & 18.31                                         & 0.44                  & 0.202                 & 0.276                  & 0.106                   & 0.44                  & 0.128                 & 0.198                  & 0.067                   & 0.851                 & 0.534                 & 0.656                  & 0.485                   \\
IGL-OIE                                    & LSOIE                                             & WiRe57                                        & 9.54                                          & 0.32                  & 0.183                 & 0.233                  & 0.063                   & 0.32                  & 0.099                 & 0.151                  & 0.034                   & 0.92                  & 0.571                 & 0.705                  & 0.549                   \\
CIGL-OIE                                   & LSOIE                                             & WiRe57                                        & 7.65                                          & 0.301                 & 0.223                 & 0.256                  & 0.082                   & 0.301                 & 0.114                 & 0.165                  & 0.044                   & 0.933                 & 0.694                 & 0.796                  & 0.671                   \\
OpenIE6                                    & LSOIE                                             & WiRe57                                        & 3.81                                          & 0.311                 & 0.247                 & 0.275                  & 0.114                   & 0.311                 & 0.194                 & 0.239                  & 0.086                   & 0.766                 & 0.688                 & 0.725                  & 0.554                   \\ \midrule
SpanOIE                                    & IMoJIE                                            & WiRe57                                        & 7.33                                          & 0.087                 & 0.364                 & 0.141                  & 0.198                   & 0.087                 & 0.274                 & 0.133                  & 0.149                   & 0.303                 & 0.898                 & 0.454                  & 0.585                   \\
IMoJIE                                     & IMoJIE                                            & WiRe57                                        & 1.17                                          & 0.517                 & 0.404                 & 0.454                  & 0.207                   & 0.517                 & 0.224                 & 0.313                  & 0.116                   & 0.911                 & 0.778                 & 0.84                   & 0.622                   \\
Multi$^2$OIE                                  & IMoJIE                                            & WiRe57                                        & 24.83                                         & 0.539                 & 0.373                 & 0.44                   & 0.228                   & 0.539                 & 0.195                 & 0.287                  & 0.12                    & 0.9                   & 0.706                 & 0.791                  & 0.692                   \\
IGL-OIE                                    & IMoJIE                                            & WiRe57                                        & 10.36                                         & 0.485                 & 0.291                 & 0.364                  & 0.144                   & 0.48                  & 0.157                 & 0.236                  & 0.08                    & 0.934                 & 0.7                   & 0.8                    & 0.65                    \\
CIGL-OIE                                   & IMoJIE                                            & WiRe57                                        & 7.83                                          & 0.44                  & 0.395                 & 0.417                  & 0.197                   & 0.44                  & 0.196                 & 0.271                  & 0.099                   & 0.926                 & 0.799                 & 0.858                  & 0.744                   \\
OpenIE6                                    & IMoJIE                                            & WiRe57                                        & 4.24                                          & 0.459                 & 0.393                 & 0.424                  & 0.2                     & 0.452                 & 0.292                 & 0.355                  & 0.144                   & 0.802                 & 0.781                 & 0.792                  & 0.648                   \\ \bottomrule
\end{tabular}%
}
\caption{A table that lists performances of different OpenIE systems on the WiRe57 benchmark.}
\end{table*}




% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table*}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lllrrrrrrrrrrrrr}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Model}} & \multicolumn{1}{c}{\multirow{2}{*}{Training set}} & \multicolumn{1}{c}{\multirow{2}{*}{Test set}} & \multicolumn{1}{c}{\multirow{2}{*}{Sen./Sec}} & \multicolumn{4}{c}{OIE2016}                                                                      & \multicolumn{4}{c}{WiRe57}                                                                       & \multicolumn{4}{c}{CaRB}                                                                         \\ \cmidrule(lr){5-8}  \cmidrule(lr){9-12}  \cmidrule(lr){13-16} 
\multicolumn{1}{c}{}                       & \multicolumn{1}{c}{}                              & \multicolumn{1}{c}{}                          & \multicolumn{1}{c}{}                          & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} \\ \midrule
SpanOIE                                    & SpanOIE                                           & ReOIE2016                                     & 16.87                                         & 0.741                 & 0.842                 & 0.788                  & 0.733                   & 0.772                 & 0.595                 & 0.672                  & 0.527                   & 0.772                 & 0.61                  & 0.681                  & 0.54                    \\
IMoJIE                                     & SpanOIE                                           & ReOIE2016                                     & 2.71                                          & 0.773                 & 0.84                  & 0.805                  & 0.627                   & 0.785                 & 0.601                 & 0.681                  & 0.456                   & 0.785                 & 0.607                 & 0.684                  & 0.46                    \\
Multi$^2$OIE                                  & SpanOIE                                           & ReOIE2016                                     & 27.70                                         & 0.737                 & 0.932                 & 0.823                  & 0.753                   & 0.749                 & 0.688                 & 0.717                  & 0.586                   & 0.749                 & 0.698                 & 0.723                  & 0.596                   \\
IGL-OIE                                    & SpanOIE                                           & ReOIE2016                                     & 67.16                                         & 0.762                 & 0.784                 & 0.773                  & 0.653                   & 0.756                 & 0.557                 & 0.641                  & 0.455                   & 0.756                 & 0.569                 & 0.649                  & 0.465                   \\
CIGL-OIE                                   & SpanOIE                                           & ReOIE2016                                     & 49.33                                         & 0.688                 & 0.991                 & 0.812                  & 0.733                   & 0.437                 & 0.663                 & 0.527                  & 0.35                    & 0.437                 & 0.69                  & 0.535                  & 0.365                   \\
OpenIE6                                    & SpanOIE                                           & ReOIE2016                                     & 22.84                                         & 0.498                 & 0.988                 & 0.662                  & 0.532                   & 0.314                 & 0.628                 & 0.419                  & 0.268                   & 0.314                 & 0.636                 & 0.42                   & 0.272                   \\ \midrule
SpanOIE                                    & OIE4                                              & ReOIE2016                                     & 16.72                                         & 0.815                 & 0.617                 & 0.702                  & 0.56                    & 0.815                 & 0.604                 & 0.694                  & 0.548                   & 0.729                 & 0.839                 & 0.78                   & 0.726                   \\
IMoJIE                                     & OIE4                                              & ReOIE2016                                     & 3.00                                          & 0.756                 & 0.119                 & 0.206                  & 0.075                   & 0.756                 & 0.119                 & 0.205                  & 0.075                   & 0.75                  & 0.155                 & 0.257                  & 0.095                   \\
Multi$^2$OIE                                  & OIE4                                              & ReOIE2016                                     & 27.74                                         & 0.813                 & 0.647                 & 0.72                   & 0.561                   & 0.813                 & 0.635                 & 0.713                  & 0.55                    & 0.773                 & 0.869                 & 0.818                  & 0.746                   \\
IGL-OIE                                    & OIE4                                              & ReOIE2016                                     & 64.23                                         & 0.732                 & 0.629                 & 0.677                  & 0.531                   & 0.732                 & 0.615                 & 0.668                  & 0.52                    & 0.751                 & 0.877                 & 0.809                  & 0.72                    \\
CIGL-OIE                                   & OIE4                                              & ReOIE2016                                     & 51.78                                         & 0.698                 & 0.697                 & 0.698                  & 0.582                   & 0.698                 & 0.675                 & 0.686                  & 0.564                   & 0.74                  & 0.948                 & 0.831                  & 0.776                   \\
OpenIE6                                    & OIE4                                              & ReOIE2016                                     & 23.30                                         & 0.506                 & 0.679                 & 0.58                   & 0.472                   & 0.506                 & 0.671                 & 0.577                  & 0.467                   & 0.559                 & 0.938                 & 0.701                  & 0.642                   \\ \midrule
SpanOIE                                    & LSOIE                                             & ReOIE2016                                     & 16.33                                         & 0.69                  & 0.536                 & 0.603                  & 0.453                   & 0.69                  & 0.53                  & 0.6                    & 0.448                   & 0.65                  & 0.814                 & 0.723                  & 0.672                   \\
IMoJIE                                     & LSOIE                                             & ReOIE2016                                     & 1.03                                          & 0.747                 & 0.414                 & 0.533                  & 0.283                   & 0.747                 & 0.409                 & 0.529                  & 0.279                   & 0.836                 & 0.726                 & 0.778                  & 0.525                   \\
Multi$^2$OIE                                  & LSOIE                                             & ReOIE2016                                     & 31.24                                         & 0.746                 & 0.586                 & 0.657                  & 0.495                   & 0.746                 & 0.582                 & 0.654                  & 0.49                    & 0.759                 & 0.845                 & 0.8                    & 0.736                   \\
IGL-OIE                                    & LSOIE                                             & ReOIE2016                                     & 69.48                                         & 0.626                 & 0.472                 & 0.538                  & 0.325                   & 0.626                 & 0.453                 & 0.525                  & 0.312                   & 0.742                 & 0.786                 & 0.763                  & 0.602                   \\
CIGL-OIE                                   & LSOIE                                             & ReOIE2016                                     & 53.49                                         & 0.548                 & 0.582                 & 0.564                  & 0.365                   & 0.548                 & 0.559                 & 0.553                  & 0.351                   & 0.715                 & 0.93                  & 0.808                  & 0.716                   \\
OpenIE6                                    & LSOIE                                             & ReOIE2016                                     & 24.94                                         & 0.374                 & 0.574                 & 0.453                  & 0.281                   & 0.374                 & 0.562                 & 0.45                   & 0.275                   & 0.518                 & 0.924                 & 0.664                  & 0.53                    \\ \midrule
SpanOIE                                    & IMoJIE                                            & ReOIE2016                                     & 7.36                                          & 0.099                 & 0.535                 & 0.167                  & 0.294                   & 0.099                 & 0.527                 & 0.166                  & 0.289                   & 0.175                 & 0.993                 & 0.298                  & 0.584                   \\
IMoJIE                                     & IMoJIE                                            & ReOIE2016                                     & 1.84                                          & 0.713                 & 0.603                 & 0.653                  & 0.395                   & 0.713                 & 0.592                 & 0.647                  & 0.388                   & 0.802                 & 0.947                 & 0.868                  & 0.65                    \\
Multi$^2$OIE                                  & IMoJIE                                            & ReOIE2016                                     & 30.72                                         & 0.817                 & 0.614                 & 0.701                  & 0.542                   & 0.812                 & 0.606                 & 0.694                  & 0.534                   & 0.794                 & 0.863                 & 0.827                  & 0.793                   \\
IGL-OIE                                    & IMoJIE                                            & ReOIE2016                                     & 68.80                                         & 0.728                 & 0.53                  & 0.614                  & 0.42                    & 0.728                 & 0.508                 & 0.599                  & 0.403                   & 0.799                 & 0.817                 & 0.808                  & 0.644                   \\
CIGL-OIE                                   & IMoJIE                                            & ReOIE2016                                     & 49.48                                         & 0.674                 & 0.622                 & 0.647                  & 0.464                   & 0.671                 & 0.579                 & 0.621                  & 0.431                   & 0.796                 & 0.919                 & 0.853                  & 0.723                   \\
OpenIE6                                    & IMoJIE                                            & ReOIE2016                                     & 26.42                                         & 0.483                 & 0.623                 & 0.544                  & 0.342                   & 0.483                 & 0.601                 & 0.535                  & 0.33                    & 0.584                 & 0.925                 & 0.716                  & 0.514                   \\ \bottomrule
\end{tabular}%
}
\caption{A table that lists performances of different OpenIE systems on the ReOIE2016 benchmark.}
\end{table*}




% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table*}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lllrrrrrrrrrrrrr}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Model}} & \multicolumn{1}{c}{\multirow{2}{*}{Training set}} & \multicolumn{1}{c}{\multirow{2}{*}{Test set}} & \multicolumn{1}{c}{\multirow{2}{*}{Sen./Sec}} & \multicolumn{4}{c}{OIE2016}                                                                      & \multicolumn{4}{c}{WiRe57}                                                                       & \multicolumn{4}{c}{CaRB}                                                                         \\ \cmidrule(lr){5-8}  \cmidrule(lr){9-12}  \cmidrule(lr){13-16} 
\multicolumn{1}{c}{}                       & \multicolumn{1}{c}{}                              & \multicolumn{1}{c}{}                          & \multicolumn{1}{c}{}                          & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} \\ \midrule
SpanOIE                                    & SpanOIE                                           & CaRB                                          & 17.14                                         & 0.81                  & 0.778                 & 0.794                  & 0.704                   & 0.609                 & 0.273                 & 0.377                  & 0.219                   & 0.609                 & 0.403                 & 0.485                  & 0.324                   \\
IMoJIE                                     & SpanOIE                                           & CaRB                                          & 3.12                                          & 0.836                 & 0.794                 & 0.814                  & 0.639                   & 0.629                 & 0.283                 & 0.39                   & 0.17                    & 0.629                 & 0.416                 & 0.5                    & 0.25                    \\
Multi$^2$OIE                                  & SpanOIE                                           & CaRB                                          & 22.39                                         & 0.826                 & 0.878                 & 0.851                  & 0.793                   & 0.59                  & 0.315                 & 0.411                  & 0.22                    & 0.609                 & 0.458                 & 0.523                  & 0.326                   \\
IGL-OIE                                    & SpanOIE                                           & CaRB                                          & 69.67                                         & 0.831                 & 0.771                 & 0.8                    & 0.672                   & 0.611                 & 0.267                 & 0.371                  & 0.184                   & 0.611                 & 0.399                 & 0.483                  & 0.275                   \\
CIGL-OIE                                   & SpanOIE                                           & CaRB                                          & 52.62                                         & 0.789                 & 0.986                 & 0.876                  & 0.818                   & 0.379                 & 0.331                 & 0.354                  & 0.148                   & 0.379                 & 0.508                 & 0.434                  & 0.228                   \\
OpenIE6                                    & SpanOIE                                           & CaRB                                          & 24.17                                         & 0.643                 & 0.981                 & 0.777                  & 0.671                   & 0.335                 & 0.406                 & 0.367                  & 0.181                   & 0.338                 & 0.489                 & 0.399                  & 0.223                   \\ \midrule
SpanOIE                                    & OIE4                                              & CaRB                                          & 16.92                                         & 0.646                 & 0.413                 & 0.503                  & 0.339                   & 0.646                 & 0.28                  & 0.39                   & 0.23                    & 0.804                 & 0.777                 & 0.79                   & 0.701                   \\
IMoJIE                                     & OIE4                                              & CaRB                                          & 3.83                                          & 0.624                 & 0.442                 & 0.517                  & 0.247                   & 0.624                 & 0.304                 & 0.408                  & 0.17                    & 0.804                 & 0.816                 & 0.81                   & 0.572                   \\
Multi$^2$OIE                                  & OIE4                                              & CaRB                                          & 33.37                                         & 0.647                 & 0.442                 & 0.525                  & 0.317                   & 0.647                 & 0.298                 & 0.408                  & 0.213                   & 0.838                 & 0.831                 & 0.835                  & 0.761                   \\
IGL-OIE                                    & OIE4                                              & CaRB                                          & 72.82                                         & 0.607                 & 0.438                 & 0.509                  & 0.323                   & 0.607                 & 0.298                 & 0.399                  & 0.219                   & 0.82                  & 0.834                 & 0.827                  & 0.734                   \\
CIGL-OIE                                   & OIE4                                              & CaRB                                          & 58.49                                         & 0.584                 & 0.479                 & 0.526                  & 0.35                    & 0.584                 & 0.326                 & 0.418                  & 0.237                   & 0.814                 & 0.908                 & 0.858                  & 0.796                   \\
OpenIE6                                    & OIE4                                              & CaRB                                          & 24.93                                         & 0.518                 & 0.482                 & 0.499                  & 0.346                   & 0.518                 & 0.395                 & 0.448                  & 0.281                   & 0.685                 & 0.903                 & 0.779                  & 0.716                   \\ \midrule
SpanOIE                                    & LSOIE                                             & CaRB                                          & 16.59                                         & 0.561                 & 0.334                 & 0.418                  & 0.26                    & 0.561                 & 0.244                 & 0.34                   & 0.191                   & 0.741                 & 0.731                 & 0.736                  & 0.636                   \\
IMoJIE                                     & LSOIE                                             & CaRB                                          & 1.05                                          & 0.615                 & 0.281                 & 0.386                  & 0.157                   & 0.615                 & 0.195                 & 0.296                  & 0.109                   & 0.896                 & 0.702                 & 0.788                  & 0.569                   \\
Multi$^2$OIE                                  & LSOIE                                             & CaRB                                          & 33.89                                         & 0.611                 & 0.369                 & 0.461                  & 0.262                   & 0.611                 & 0.267                 & 0.372                  & 0.189                   & 0.818                 & 0.81                  & 0.814                  & 0.738                   \\
IGL-OIE                                    & LSOIE                                             & CaRB                                          & 67.65                                         & 0.529                 & 0.304                 & 0.386                  & 0.178                   & 0.529                 & 0.215                 & 0.305                  & 0.127                   & 0.825                 & 0.743                 & 0.782                  & 0.616                   \\
CIGL-OIE                                   & LSOIE                                             & CaRB                                          & 49.70                                         & 0.475                 & 0.386                 & 0.426                  & 0.21                    & 0.475                 & 0.273                 & 0.346                  & 0.149                   & 0.814                 & 0.897                 & 0.853                  & 0.753                   \\
OpenIE6                                    & LSOIE                                             & CaRB                                          & 28.14                                         & 0.403                 & 0.389                 & 0.396                  & 0.198                   & 0.403                 & 0.333                 & 0.365                  & 0.168                   & 0.667                 & 0.898                 & 0.766                  & 0.627                   \\ \midrule
SpanOIE                                    & IMoJIE                                            & CaRB                                          & 7.41                                          & 0.131                 & 0.438                 & 0.202                  & 0.248                   & 0.131                 & 0.4                   & 0.198                  & 0.226                   & 0.265                 & 0.979                 & 0.417                  & 0.619                   \\
IMoJIE                                     & IMoJIE                                            & CaRB                                          & 1.77                                          & 0.633                 & 0.457                 & 0.531                  & 0.266                   & 0.633                 & 0.306                 & 0.413                  & 0.179                   & 0.863                 & 0.914                 & 0.888                  & 0.696                   \\
Multi$^2$OIE                                  & IMoJIE                                            & CaRB                                          & 31.22                                         & 0.648                 & 0.418                 & 0.508                  & 0.301                   & 0.645                 & 0.28                  & 0.39                   & 0.201                   & 0.848                 & 0.813                 & 0.83                   & 0.771                   \\
IGL-OIE                                    & IMoJIE                                            & CaRB                                          & 73.88                                         & 0.615                 & 0.384                 & 0.473                  & 0.252                   & 0.615                 & 0.252                 & 0.357                  & 0.165                   & 0.865                 & 0.803                 & 0.833                  & 0.681                   \\
CIGL-OIE                                   & IMoJIE                                            & CaRB                                          & 55.01                                         & 0.574                 & 0.437                 & 0.496                  & 0.274                   & 0.563                 & 0.286                 & 0.379                  & 0.178                   & 0.855                 & 0.909                 & 0.881                  & 0.768                   \\
OpenIE6                                    & IMoJIE                                            & CaRB                                          & 25.35                                         & 0.503                 & 0.44                  & 0.47                   & 0.252                   & 0.498                 & 0.365                 & 0.421                  & 0.204                   & 0.715                 & 0.898                 & 0.796                  & 0.633                   \\ \bottomrule
\end{tabular}%
}
\caption{A table that lists performances of different OpenIE systems on the CaRB benchmark.}
\end{table*}





% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table*}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lllrrrrrrrrrrrrr}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Model}} & \multicolumn{1}{c}{\multirow{2}{*}{Training set}} & \multicolumn{1}{c}{\multirow{2}{*}{Test set}} & \multicolumn{1}{c}{\multirow{2}{*}{Sen./Sec}} & \multicolumn{4}{c}{OIE2016}                                                                      & \multicolumn{4}{c}{WiRe57}                                                                       & \multicolumn{4}{c}{CaRB}                                                                         \\ \cmidrule(lr){5-8}  \cmidrule(lr){9-12}  \cmidrule(lr){13-16} 
\multicolumn{1}{c}{}                       & \multicolumn{1}{c}{}                              & \multicolumn{1}{c}{}                          & \multicolumn{1}{c}{}                          & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} & \multicolumn{1}{c}{P} & \multicolumn{1}{c}{R} & \multicolumn{1}{c}{F1} & \multicolumn{1}{c}{AUC} \\ \midrule
SpanOIE                                    & SpanOIE                                           & LSOIE                                         & 18.56                                         & 0.745                 & 0.851                 & 0.794                  & 0.742                   & 0.537                 & 0.388                 & 0.451                  & 0.298                   & 0.537                 & 0.551                 & 0.544                  & 0.423                   \\
IMoJIE                                     & SpanOIE                                           & LSOIE                                         & 2.92                                          & 0.631                 & 0.866                 & 0.73                   & 0.499                   & 0.53                  & 0.516                 & 0.523                  & 0.244                   & 0.53                  & 0.537                 & 0.534                  & 0.253                   \\
Multi$^2$OIE                                  & SpanOIE                                           & LSOIE                                         & 27.55                                         & 0.618                 & 0.909                 & 0.736                  & 0.646                   & 0.525                 & 0.596                 & 0.558                  & 0.364                   & 0.525                 & 0.628                 & 0.571                  & 0.383                   \\
IGL-OIE                                    & SpanOIE                                           & LSOIE                                         & 205.07                                        & 0.636                 & 0.815                 & 0.714                  & 0.582                   & 0.529                 & 0.484                 & 0.505                  & 0.295                   & 0.529                 & 0.506                 & 0.517                  & 0.308                   \\
CIGL-OIE                                   & SpanOIE                                           & LSOIE                                         & 159.43                                        & 0.634                 & 0.975                 & 0.769                  & 0.653                   & 0.379                 & 0.601                 & 0.464                  & 0.284                   & 0.379                 & 0.633                 & 0.474                  & 0.3                     \\
OpenIE6                                    & SpanOIE                                           & LSOIE                                         & 59.69                                         & 0.458                 & 0.965                 & 0.622                  & 0.468                   & 0.268                 & 0.562                 & 0.363                  & 0.215                   & 0.268                 & 0.58                  & 0.366                  & 0.222                   \\ \midrule
SpanOIE                                    & OIE4                                              & LSOIE                                         & 19.48                                         & 0.541                 & 0.541                 & 0.541                  & 0.416                   & 0.541                 & 0.382                 & 0.447                  & 0.294                   & 0.737                 & 0.848                 & 0.788                  & 0.736                   \\
IMoJIE                                     & OIE4                                              & LSOIE                                         & 3.62                                          & 0.52                  & 0.564                 & 0.541                  & 0.248                   & 0.52                  & 0.541                 & 0.53                   & 0.239                   & 0.61                  & 0.89                  & 0.724                  & 0.442                   \\
Multi$^2$OIE                                  & OIE4                                              & LSOIE                                         & 39.12                                         & 0.547                 & 0.547                 & 0.547                  & 0.327                   & 0.547                 & 0.517                 & 0.532                  & 0.309                   & 0.642                 & 0.877                 & 0.742                  & 0.637                   \\
IGL-OIE                                    & OIE4                                              & LSOIE                                         & 196.72                                        & 0.521                 & 0.566                 & 0.543                  & 0.378                   & 0.521                 & 0.54                  & 0.53                   & 0.361                   & 0.628                 & 0.896                 & 0.738                  & 0.659                   \\
CIGL-OIE                                   & OIE4                                              & LSOIE                                         & 191.90                                        & 0.505                 & 0.621                 & 0.557                  & 0.414                   & 0.505                 & 0.587                 & 0.543                  & 0.392                   & 0.617                 & 0.945                 & 0.747                  & 0.692                   \\
OpenIE6                                    & OIE4                                              & LSOIE                                         & 64.24                                         & 0.394                 & 0.557                 & 0.462                  & 0.354                   & 0.394                 & 0.537                 & 0.455                  & 0.342                   & 0.47                  & 0.924                 & 0.623                  & 0.587                   \\ \midrule
SpanOIE                                    & LSOIE                                             & LSOIE                                         & 18.09                                         & 0.666                 & 0.65                  & 0.658                  & 0.541                   & 0.666                 & 0.474                 & 0.554                  & 0.394                   & 0.715                 & 0.888                 & 0.792                  & 0.762                   \\
IMoJIE                                     & LSOIE                                             & LSOIE                                         & 1.09                                          & 0.748                 & 0.597                 & 0.664                  & 0.395                   & 0.748                 & 0.571                 & 0.648                  & 0.379                   & 0.741                 & 0.891                 & 0.809                  & 0.563                   \\
Multi$^2$OIE                                  & LSOIE                                             & LSOIE                                         & 37.98                                         & 0.745                 & 0.703                 & 0.723                  & 0.579                   & 0.745                 & 0.676                 & 0.709                  & 0.557                   & 0.662                 & 0.935                 & 0.775                  & 0.707                   \\
IGL-OIE                                    & LSOIE                                             & LSOIE                                         & 201.64                                        & 0.697                 & 0.65                  & 0.673                  & 0.515                   & 0.697                 & 0.611                 & 0.652                  & 0.485                   & 0.679                 & 0.891                 & 0.771                  & 0.651                   \\
CIGL-OIE                                   & LSOIE                                             & LSOIE                                         & 183.46                                        & 0.621                 & 0.767                 & 0.686                  & 0.566                   & 0.621                 & 0.717                 & 0.666                  & 0.529                   & 0.643                 & 0.978                 & 0.776                  & 0.705                   \\
OpenIE6                                    & LSOIE                                             & LSOIE                                         & 65.63                                         & 0.438                 & 0.75                  & 0.553                  & 0.447                   & 0.438                 & 0.723                 & 0.546                  & 0.428                   & 0.473                 & 0.954                 & 0.633                  & 0.529                   \\ \midrule
SpanOIE                                    & IMoJIE                                            & LSOIE                                         & 7.19                                          & 0.085                 & 0.439                 & 0.142                  & 0.238                   & 0.085                 & 0.389                 & 0.139                  & 0.211                   & 0.226                 & 0.996                 & 0.368                  & 0.61                    \\
IMoJIE                                     & IMoJIE                                            & LSOIE                                         & 2.98                                          & 0.517                 & 0.523                 & 0.52                   & 0.236                   & 0.517                 & 0.497                 & 0.507                  & 0.225                   & 0.681                 & 0.945                 & 0.792                  & 0.532                   \\
Multi$^2$OIE                                  & IMoJIE                                            & LSOIE                                         & 33.67                                         & 0.554                 & 0.527                 & 0.54                   & 0.348                   & 0.554                 & 0.502                 & 0.527                  & 0.333                   & 0.651                 & 0.882                 & 0.749                  & 0.703                   \\
IGL-OIE                                    & IMoJIE                                            & LSOIE                                         & 218.05                                        & 0.517                 & 0.472                 & 0.493                  & 0.256                   & 0.517                 & 0.443                 & 0.477                  & 0.241                   & 0.691                 & 0.863                 & 0.767                  & 0.567                   \\
CIGL-OIE                                   & IMoJIE                                            & LSOIE                                         & 189.39                                        & 0.489                 & 0.551                 & 0.518                  & 0.286                   & 0.489                 & 0.503                 & 0.496                  & 0.262                   & 0.678                 & 0.934                 & 0.785                  & 0.6                     \\
OpenIE6                                    & IMoJIE                                            & LSOIE                                         & 66.80                                         & 0.353                 & 0.534                 & 0.425                  & 0.219                   & 0.353                 & 0.506                 & 0.416                  & 0.207                   & 0.502                 & 0.924                 & 0.651                  & 0.452                   \\ \bottomrule
\end{tabular}%
}
\caption{A table that lists performances of different OpenIE systems on the LSOIE benchmark.}
\vspace{-0.1in}
\end{table*}




% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table*}[]
\centering
\resizebox{0.8\textwidth}{!}{%
\begin{tabular}{cccccc}
\toprule
\multirow{2}{*}{Independent Var.} & \multirow{2}{*}{Constants} & \multicolumn{2}{c}{p-value $\leq 0.05$}     & \multicolumn{2}{c}{p-value $> 0.05$}     \\ \cmidrule(lr){3-4} \cmidrule(lr){5-6} 
                                  &                            & t-score $> 0$ & t-score $< 0$ & t-score $> 0$ & t-score $< 0$ \\ \midrule
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}non-N-ary model vs.\\ N-ary model\end{tabular}} & non-N-ary train, N-ary test & 2         & 5         & 3             & 5            \\ \cmidrule{2-6} 
                                                                                     & N-ary train, N-ary test     & 3         & 5         & 1             & 6            \\ \midrule
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}non-N-ary train vs.\\ N-ary train\end{tabular}} & non-N-ary model, N-ary test & 0         & 11        & 0    & 4         \\ \cmidrule{2-6} 
                                                                                     & N-ary model, N-ary test     & 4         & 9         & 0             & 2            \\ \bottomrule
\end{tabular}%
}
\caption{Statistical significance tests to answer R1. Each number represents the number of test set and evaluation metric combinations with the corresponding t-score and p-value. When t-score is greater than 0, non-N-ary outperforms N-ary, and when t-score is less than 0, N-ary outperforms non-N-ary.}
\label{table:R1}
\vspace{-0.1in}
\end{table*}



% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table*}[]
\centering
\resizebox{0.8\textwidth}{!}{%
\begin{tabular}{cccccc}
\toprule
\multirow{2}{*}{Independent Var.} & \multirow{2}{*}{Constants} & \multicolumn{2}{c}{p-value $\leq 0.05$}     & \multicolumn{2}{c}{p-value $> 0.05$}     \\ \cmidrule(lr){3-4} \cmidrule(lr){5-6} 
                                  &                            & t-score $> 0$ & t-score $< 0$ & t-score $> 0$ & t-score $< 0$ \\ \midrule
                                  \multirow{5}{*}{\begin{tabular}[c]{@{}c@{}}non-IN model \\ vs.\\ IN model\end{tabular}} & non-IN train, IN test         & 9                             & 0                             & 2                                 & 1                                \\ \cmidrule{2-6} 
                                                                                        & IN train, IN test             & 0                             & 4                             & 7                                 & 1                                \\ \cmidrule{2-6} 
                                                                                        & non-IN train, non-IN test     & 0                             & 1                             & 2                                 & 0                                \\ \cmidrule{2-6} 
                                                                                        & IN train, non-IN test         & 3                             & 0                             & 0                                 & 0                                \\ \midrule
\multirow{5}{*}{\begin{tabular}[c]{@{}c@{}}non-IN train \\ vs.\\ IN train\end{tabular}} & non-IN model, IN test         & 6                             & 6                             & 0                                 & 0                                \\ \cmidrule{2-6} 
                                                                                        & IN model, IN test             & 2                             & 7                             & 0                                 & 3                                \\ \cmidrule{2-6} 
                                                                                        & non-IN model, non-IN test     & 2                             & 1                             & 0                                 & 0                                \\ \cmidrule{2-6} 
                                                                                        & IN model, non-IN test         & 2                             & 0                             & 1                                 & 0                                \\ \bottomrule
\end{tabular}
}
\caption{Statistical significance tests to answer R2. Each number represents the number of test set and evaluation metric combinations with the corresponding t-score and p-value. When t-score is greater than 0, non-IN outperforms IN, and when t-score is less than 0, IN outperforms non-IN.}
\label{table:R2}
\vspace{-0.1in}
\end{table*}




\begin{table}[]
\centering
\begin{adjustbox}{width=\linewidth}
\begin{tabular}{lrlrrr}
\toprule
                                                \multicolumn{2}{c}{Configuration 1}                      & \multicolumn{2}{c}{Configuration 2}                      & \multicolumn{1}{c}{\multirow{2}{*}{t-Score}} & \multicolumn{1}{c}{\multirow{2}{*}{p-value}} \\ \cmidrule(lr){1-2} \cmidrule(lr){3-4} 
                                                                                        \multicolumn{1}{c}{Model} & \multicolumn{1}{c}{Sen./Sec} & \multicolumn{1}{c}{Model} & \multicolumn{1}{c}{Sen./Sec} & \multicolumn{1}{c}{}                         & \multicolumn{1}{c}{}                         \\ \midrule
 IMoJIE                    & 2.070                        & Multi$^2$OIE                 & 29.225                       & -21.621                                      & 1.50E-15                                     \\
                                                                                                    IMoJIE                    & 2.070                        & IGL-OIE                   & 84.072                       & -5.501                                       & 2.63E-05                                     \\
                                                                                                    IMoJIE                    & 2.070                        & CIGL-OIE                  & 68.800                       & -4.929                                       & 9.31E-05                                     \\
                                                                            IMoJIE                    & 2.070                        & OpenIE6                   & 28.357                       & -5.813                                       & 1.31E-05                                     \\ \bottomrule
\end{tabular}%
\end{adjustbox}
\caption{Statistical significance tests to answer R3 with \textit{Generative Model vs. Non-generative Model} independent variable . Sentences per second is averaged over all training and test sets.}
\label{table:R3}
\vspace{-0.1in}
\end{table}




\end{document}
