%----------------------------------------------------------------------
%%% INTRODUCTION
%----------------------------------------------------------------------
% !TEX root = ./Main.tex


This paper focuses on solving \ac{VI} problems of the form
\begin{equation}
\label{eq:VI}
\tag{VI}
\text{Find $\sol\in\points$ such that}
	\;\;
	\braket{\vecfield(\sol)}{\point - \sol}
	\geq 0
	\;\;
	\text{for all $\point\in\points$},
\end{equation}
where $\points$ is a closed convex subset of a finite-dimensional normed space $\pspace$, and $\vecfield \from \points \to \dspace$ is a single-valued operator on $\points$ with values in $\dspace$, the dual of $\pspace$.
The study of such problems dates back to \citet{Sta64} and \citet{Min67}, and it has recently attracted considerable interest in many areas of mathematical programming, game theory and data science as a template for ``optimization beyond minimization'' \textendash\ \ie for problems where finding an optimal state does not necessarily involve minimizing a loss function.
%As a special case, if $\vecfield = \nabla\obj$ for some smooth function $\obj\from\points\to\R$, solving \eqref{eq:VI} is equivalent to finding the first-order stationary points of $\obj$.
In particular, in addition to standard minimization problems \textendash\ which are recovered when $\vecfield = \nabla\obj$ for some smooth function $\obj$ \textendash\ the general formulation \eqref{eq:VI} includes saddle-point problems, games, complementarity problems, systems of nonlinear equations, and many other types of equilibrium problems;
for a comprehensive introduction to the topic and its applications, see \citet{FP03} and references therein.


Algorithms for solving \eqref{eq:VI} likewise have a %very 
rich history in optimization.
%which is impossible to adequately survey here.
To provide a short overview, the original proximal point methods %of \citet{Mar70} and \citet{Roc76} 
\cite{Mar70, Roc76}
were shown to converge when $\vecfield$ is monotone;
however, these methods involve a backward step on $\vecfield$, so they are difficult to implement in practice.
In this regard, forward methods that only require oracle access to $\vecfield$ are more practical, but they fail to converge if $\vecfield$ is merely monotone. %(for example, in bilinear min-max problems).
Nonetheless, if coupled with an iterate averaging scheme, forward methods \emph{do} converge, and they achieve an $\bigoh(1/\sqrt{\run})$ convergence certificate after $\run$ iterations \citep{Bru77,Pas79}.

Bridging the gap between forward and backward methods, the \acf{EG} algorithm \cite{Kor76} provided an extrapolation mechanism that
%effectively 
emulated a backward step with two interleaved forward steps, achieving in this way 
trajectory convergence when $\vecfield$ is pseudomonotone and Lipschitz continuous.
Subsequently, combining extrapolation with iterate averaging, the \acf{MP} algorithm of \citet{Nem04} \textendash\ which has the same update structure as \cite{AT05} \textendash\ was shown to converge at a rate of $\bigoh(1/\run)$ in monotone \acp{VI}, a rate which is order-optimal for first-order methods \citep{Nem92,OX21}.

A salient feature of the \acl{MP} algorithm is that it foregoes Euclidean projections in favor of a more sophisticated Bregman proximal step in the spirit of \acf{MD} \citep{NY83,BecTeb03,AT05}.
Owing to this feature, \acl{MP} achieves an almost dimension-free convergence speed in problems with a favorable geometry,
%The oracle complexity of \acl{MP} thus becomes almost dimension-free in problems with a favorable geometry, 
%(like the simplex, linearly constrained semidefinite programs, second-order cones, etc.), 
all the while retaining an order-optimal dependence on $\run$.
Because of this ``best-of-both-worlds'' guarantee, the \acl{MP} algorithm and its variants \textendash\ dualized \citep{Nes07}, optimistic \citep{Pop80,RS13-NIPS,HIMM19}, stochastic \citep{JNT11,GBVV+19}, adaptive \citep{ABM19,ABM21}, etc. \textendash\ have become the method of choice for large-scale \acl{VI} problems where higher-order methods cannot be efficiently implemented.


%----------------------------------------------------------------------
%%% CONTRIBS
%----------------------------------------------------------------------
\para{Our contributions}

In this broad context, our paper seeks to quantify the finer trajectory convergence properties of Bregman proximal methods as a function of the geometry of the problem and the Bregman regularizer underlying the method. 
For generality, we focus on non-monotone \acp{VI}, and we examine the rate of convergence of a wide class of \acdef{AMP} algorithms to local solutions that satisfy a \acl{SOS} condition.
Specifically, the \ac{AMP} template includes as special cases the \acl{MP}, \acl{MD} and \acl{OMD} algorithms, so it provides a unified view of some of the most widely used Bregman methods in the literature.

Our first finding is that the algorithm's rate of convergence depends sharply on the chosen Bregman regularizer (Euclidean, entropic, or other).
We formalize this via the notion of the \emph{Legendre exponent},
%$\legexp\in[0,1]$,
which can roughly be described as the logarithmic ratio of the volume of a %regular 
ball centered at the solution under study 
to that of a Bregman ball of the same radius.%
\footnote{This notion was first introduced in the conference paper \cite{AIMM21}, which can be seen as a precursor of our work.
The paper \cite{AIMM21} deals with \emph{stochastic} \aclp{VI} (so there is no overlap with the results presented herein and the derived rates are naturally different), but the notion of the Legendre exponent plays a similar role in both works.}
For example, Euclidean methods have a Legendre exponent of $\legexp = 0$ and they converge at a linear rate;
%on the other hand,
entropic methods have a Legendre exponent of $\legexp = 1/2$ at boundary points, and they converge at a rate of $\bigoh(\run^{-1})$;
and more generally, as we show in \cref{thm:general}, methods with a Legendre exponent $\legexp>0$ converge at a rate of $\bigoh(\run^{1-1/\legexp})$.
%Then, as we show in \cref{thm:general}, Bregman methods converge at a geometric rate if $\legexp=0$, and at a rate of $\bigoh(\run^{1-1/\legexp})$ otherwise.
The Euclidean regime ($\legexp = 0$) is perfectly aligned with existing results for the geometric last-iterate convergence rate of the \ac{EG} algorithm and its variants in strongly monotone \acp{VI} \citep{GBVV+19,Mal15,HIMM19,MOP19a}.
By contrast, the Legendre regime ($\legexp > 0$) indicates a significant drop in the algorithm's last-iterate convergence speed,
even though ergodic convergence results might suggest otherwise.
%average analysis of \cite{Nem04} might suggest otherwise. % (at least on the surface).

Subsequently, %motivated by applications to game theory and linear programming, 
we take a closer look at the convergence rate of \ac{AMP} methods as a function of the constraints that are active at a solution $\sol$ of \eqref{eq:VI} and the position of $\vecfield(\sol)$ relative to said constraints.
This analysis reveals that Bregman proximal methods have a particularly fine structure:
%even though the rates mentioned above are, in general, tight,
along \emph{sharp directions} (\ie constraints along which $\vecfield(\sol)$ is strictly inward-pointing), \ac{AMP} algorithms converge
in a finite number of iterations if $\legexp=0$,
at a geometric rate if $0 < \legexp \leq 1/2$,
and
at a rate of $\bigoh(1/\run^{1/(2\legexp-1)})$ if $1/2 < \legexp < 1$ (\cf \cref{thm:sharp} for a precise statement).
Thus, even though the rate estimates of \cref{thm:general} are in general tight, the actual rate of convergence of a Bregman method along different coordinates\,/\,constraints could be considerably different \textendash\ and, in fact, dramatically faster if the solution under study is itself sharp.
We find this separation property particularly appealing, as it highlights the interplay between sharp and non-sharp directions:
\cref{thm:general} describes the rate of convergence along the latter, while \cref{thm:sharp} estimates the speed along the former.