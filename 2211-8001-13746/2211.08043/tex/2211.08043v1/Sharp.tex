%----------------------------------------------------------------------
%%% SHARP
%----------------------------------------------------------------------
% !TEX root = ./Main.tex


Motivated by applications to game theory and linear programming, our goal in this section will be to take a closer look at the convergence rate of \eqref{eq:AMP} for different solution configurations that may arise in practice \textendash\ and, in particular, in linearly constrained problems.
To that end, we begin by revisiting the examples of \cref{sec:examples}.


%----------------------------------------------------------------------
%%% EXAMPLES REDUX
%----------------------------------------------------------------------
\subsection{Motivating examples, redux}
\label{sec:examples-sharp}

A common feature of \crefrange{ex:Eucl}{ex:Hell} is that the problem's defining vector field vanishes at the solution point under scrutiny.
In the series of examples below, we examine the rate of convergence achieved when this is not the case.


%----------------------------------------------------------------------
%% Euclidean begins here

\begin{example}[Euclidean regularization]
\label{ex:Eucl-sharp}
Consider again the quadratic regularizer of \cref{ex:Eucl} over $\points = [0,\infty)$, but with $\vecfield(\point) = \point + 1$.
The solution of \eqref{eq:VI} is still $\sol = 0$ but the update \eqref{eq:MD-generic} now becomes
\begin{equation}
\label{eq:MD-Eucl-sharp}
\fixmap(\point)
	= \pospart{\point - \step(\point + 1)}
	= \pospart{(1-\step) \point -\step}\,.
\end{equation}
Since $\fixmap(\point) = 0$ for all sufficiently small $\point>0$, we readily conclude that $\curr$ converges to $\sol$ in a \emph{finite} number of iterations.
\endenv
\end{example}

%% Euclidean ends here
%----------------------------------------------------------------------


%----------------------------------------------------------------------
%% Entropy begins here

\begin{example}[Entropic regularization]
\label{ex:ent-sharp}
Under the entropic regularizer of \cref{ex:ent}, and taking again $\vecfield(\point) = \point+1$, the update rule \eqref{eq:MD-generic} becomes
\begin{equation}
\label{eq:MD-ent-sharp}
\fixmap(\point)
	= \point \exp(-\step(\point + 1))
	= \point e^{- \step} + o(\point)
	\sim \point e^{-\step}
%	\quad
%	\text{for small $\point > 0$}.
%	\text{as $\point\to0$}
\end{equation}
\ie $\fixmap$ is a contraction for small $\point > 0$.
Hence, in contrast to \cref{ex:ent}, $\curr$ converges to $0$ at a geometric rate, even though the problem's solution lies on the boundary of $\points$.
\endenv
\end{example}

%% Entropy ends here
%----------------------------------------------------------------------


%----------------------------------------------------------------------
%% Fractional begins here

\begin{example}[Fractional power]
\label{ex:frac-sharp}
Finally, consider the fractional power regularizer of \cref{ex:frac}, again with $\vecfield(\point) = \point + 1$.
Then, for $\qexp \in (0,1)$, the update rule \eqref{eq:MD-generic} gives
\begin{align}
\fixmap(\point)
	&= \bracks{\point^{\qexp -1} + \step(1-\qexp)(\point + 1)}^{1/(\qexp-1)}
	% &= \point \bracks{1 + \step(1-\qexp)\point^{1-\qexp} + o(\point^{1-\qexp})}^{1/(\qexp-1)} \\
% 	&= \point \bracks{1 - \step\point^{1-\qexp} + o(\point^{1-\qexp})}
% 	\sim \point - \step\point^{2-\qexp}
%	\notag\\
	= \point - \step\point^{2-\qexp} + o(\point^{2-\qexp})
%	\quad
%	\text{as $\point\to0$}.
%	\text{for small $\point$}.
\end{align}
for small $\point>0$.
Thus, by \cref{lem:basicnum}, we conclude that $\curr$ converges to $0$ as $\abs{\curr - \sol} = \Theta\parens[\big]{\run^{-1/(1-\qexp)}}$ and hence $\breg(\sol,\curr) = \Theta\parens[\big]{\run^{-\qexp/(1-\qexp)}}$, which is again faster than the rate predicted by \cref{thm:general}.
\endenv
\end{example}

%% Fractional ends here
%----------------------------------------------------------------------


\Crefrange{ex:Eucl-sharp}{ex:frac-sharp} already show that the convergence rate of \eqref{eq:AMP} can change drastically depending on whether $\vecfield(\sol)$ is zero or not.
In the example below, we examine in more detail the behavior of the individual coordinates of $\curr$ as a function of the position of $\vecfield(\sol)$ relative to $\points$.


%----------------------------------------------------------------------
%% Simplex begins here

\begin{example}[Higher-dimensional simplices]
\label{ex:simplex-2d}
Consider the canonical two-di\-men\-sional simplex $\points = \setdef{(\point_{1}, \point_{2}, \point_3)\in \R_{+}^{3}}{\point_{1} + \point_{2} + \point_{3} = 1}$ of $\R^{3}$
%\PM{It's a 2d-simplex embedded in 3d-space, not a 3d-simplex, so I changed things a bit here ;-)}
equipped with the entropic regularizer
$\hreg(\point) = \sum_{\coord=1}^{3} \point_{\coord} \log\point_{\coord}$.
%with induced divergence function
%$\breg(\base,\point) = \sum_{\coord=1}^{3} \base_{\coord} \log(\base_{\coord}/\point_{\coord})$.
Consider also the vector field $\vecfield(\point) = \point - \base$ with $\base=(-\slack_{1}, -\slack_{2},1)$ for some $\slack_{1}, \slack_{2} \geq 0$, so the solution of \eqref{eq:VI} is $\sol = (0,0,1)$, an extreme point of $\points$.
%(see also \cref{fig:simplex} for a range of possible configurations).

Since the Legendre exponent of $\hreg$ at $\sol$ is easily seen to be $\legof{\sol} = 1/2$, \cref{thm:general} would indicate a rate of convergence of $\breg(\sol,\curr) = \bigoh(1/\run)$ or, in terms of norms, $\norm{\curr - \sol} = \bigoh(1/\run)$.
However, this rate can be very pessimistic if, for example, $\slack_{1} > 0$.
Indeed, in this case, since $\curr$ converges to $\sol = (0,0,1)$, the relevant coordinates of $\vecfield(\curr)$ will evolve as $\vecfield_{1}(\curr) = \state_{1,\run} + \slack_{1} = \slack_{1} + o(1)$ and $\vecfield_{3}(\curr) = \state_{3,\run} - 1 = o(1)$.
Accordingly, since entropic regularization on the simplex leads to the exponential weights update \cite{BecTeb03}
\begin{equation}
\label{eq:EW}
\state_{\coord,\run+1}
	\propto \state_{\coord,\run} \exp\parens*{-\step \vecfield_{\coord}(\curr)}
	\quad
	\text{for all $\run \geq \start$, $\coord = 1,2,3$},
\end{equation}
the fact that $\lim_{\run\to\infty}\state_{3,\run} = 1$ readily yields
\begin{align}
\state_{1,\run+1}
	\sim \frac{\state_{1,\run+1}}{\state_{3,\run+1}}
	&= \frac{\state_{1,\run}}{\state_{3,\run}}
		\exp\parens*{-\step \vecfield_{1}(\curr) + \step \vecfield_{3}(\curr)}
%	\\
	= \frac{\state_{1,\run}}{\state_{3,\run}}
		\exp\parens*{-\step \slack_{1} + o(1)}
%& & \text{ for } \run = \running
\end{align}
\ie $\state_{1,\run}$ converges to $0$ at a \emph{geometric} rate whenever $\slack_{1} > 0$.

By symmetry, the argument above yields the same rate for $\state_{2,\run}$ if $\slack_{2} > 0$.
However, as we show in \cref{app:ex}, if $\slack_{2} = 0$, we would have $\state_{2,\run} = \Theta(1/\run)$ no matter the value of $\slack_{1}$ (and likewise for the rate of $\state_{1,\run}$ if $\slack_{1}=0$).
In other words, the rate provided by \cref{thm:general} is tight for the coordinate $\coord \in \{1,2\}$ with a vanishing drift coefficient $\slack_{\coord}$, but not otherwise;
we will devote the rest of this section to deriving a formal statement (and proof) of the general principle underlying this observation.
%If $\slack_{2}$ was positive, we would have the same result for the second coordinate, but if it null, one can check that the convergence speed of $\state_{2,\run}$ does not improve.
%Indeed, with $\slack_{2} = 0$, one can show that
%\begin{align}
%\state_{2,\run+1}
%	\sim	\frac{\state_{2,\run+1}}{(\next)_3} =\Omega\parens*{\frac{1}{\run}}\,,
%\end{align}
%see \cref{app:ex} for details.
\endenv
\end{example}

%% Simplex begins here
%----------------------------------------------------------------------


%----------------------------------------------------------------------
%%% LINEAR SETUP
%----------------------------------------------------------------------
\subsection{Linearly constrained problems}

For concreteness, we will focus in what follows on linearly constrained problems, which is where the structural configurations outlined in the previous examples are more prominent.
To simplify the presentation and the analysis, we will identify $\pspace$ with $\R^{\nCoords}$ endowed with the Euclidean scalar product $\inner{\cdot}{\cdot}$, and we will not distinguish between primal and dual vectors (meaning in particular that the distinction between normal and polar cones will be likewise blurred).
%\FI{From now on, only normal cones, no dual/polar !}

Formally, we will consider polyhedral domains written in normal form as
\begin{equation}
\label{eq:polyhedron}
\points
	= \setdef{\point \in \R_{+}^{\nCoords}}{\mat \point = \cvec}
\end{equation}
for some matrix $\mat\in\R^{\nConstr\times\nCoords}$ and $\cvec\in\R^{\nCoords}$.%
\footnote{Inequality constraints of the form $\mat\point\leq\cvec$ can also be accommodated in \eqref{eq:polyhedron} by introducing the associated slack variables $s = \cvec - \mat\point \geq 0$.
Even though this leads to a more verbose presentation of $\points$, the form \eqref{eq:polyhedron} is much more convenient in terms of notational overhead, so we will stick with the equality formulation throughout.}
Moreover, %to avoid trivialities, 
we will further assume that $\points$ admits a \emph{Slater point}, \ie there exists some $\point\in\points$
such that $\point_{\coord} > 0$ for all $\coord=1,\dotsc,\nCoords$.
This setup is particularly flexible, as it allows us to identify the \emph{active} constraints at $\point\in\points$ with the zero components of $\point$.

Elaborating further on this, since $\inner{\vecfield(\sol)}{\point-\sol} \geq 0$ for all $\point\in\points$ and any solution $\sol$ of \eqref{eq:VI}, we directly infer that $-\solvec$ is an element of the normal cone $\ncone(\sol)$ to $\points$ at $\sol$.
In our polyhedral setting, $\ncone(\sol)$ admits an especially simple representation as
\begin{equation}
\label{eq:ncone-sharp}
\ncone(\sol)
	= \row(\mat)
		- \setdef{(\slack_{1},\dotsc,\slack_{\nCoords})\in\R_{+}^{\nCoords}}{\slack_{\coord}=0 \text{ whenever } \sol_{\coord} = 0}
%	= \setdef[\bigg]{-\sum_{\coord\in\actcoords} \slack_{\coord} \bvec_{\coord}}{\slack_{\coord}\geq0, \coord\in\actcoords}
%		+ \row(\mat)
%	= \left\{-\sum_{\coord \in \actcoords} \slack_{\coord} \bvec_{\coord} : (\slack_{\coord})_{\coord \in \actcoords} \in \R_+^{\actcoords}\right\} + \row(\mat) %\\
		%\relint \ncone(\sol) &= \left\{-\sum_{\coord \in \actcoords} \slack_{\coord} \bvec_{\coord} : (\slack_{\coord})_{\coord \in \actcoords} \in (\R_+^*)^{\actcoords}\right\} + \row(\mat)\,,
\end{equation}
%or, more compactly, as $\ncone(\sol) = \row(\mat) - \R_{+}^{\actcoords}$,
where $\row(\mat) = (\ker\mat)^{\perp} \subseteq \R^{\nCoords}$ denotes the row space of $\mat$ \cite[Ex.~5.2.6]{HUL01}.
%the normal cone to $\points$ at $\sol$ can be expressed more compactly as $\ncone(\sol) = \row(\mat) - \R_{+}^{\actcoords}$, with $\R^{\actcoords}$ treated here as a subspace of $\R^{\nCoords}$.
As a result, we see that $\sol$ is a solution of \eqref{eq:VI} if and only if $\vecfield(\sol)$ can be written in the form
\begin{equation}
\label{eq:slacks}
\solvec - \sum_{\coord\in\actcoords} \slack_{\coord}\bvec_{\coord}
	\in \row(\mat)
\end{equation}
for an ensemble of non-negative \emph{slackness coefficients} $\slack_{\coord} \geq 0$, $\coord\in\actcoords$, where
\begin{equation}
\label{eq:actcoords}
\actcoords
	\equiv \actcoords(\sol)
	= \setdef{\coord}{\sol_{\coord} = 0}
\end{equation}
denotes the set of inequality constraints of \eqref{eq:polyhedron} that are active at $\sol$.
In view of all this, we will distinguish the following solution configurations:

\begin{definition}[Sharpness]
\label{def:sharp}
Let $\sol\in\points$ be a solution of \eqref{eq:VI} with associated slackness coefficients $\slack_{\coord}$, $\coord\in\actcoords$, as per \eqref{eq:slacks}.
The set of \emph{sharp} \textpar{$\sharp$} and \emph{flat} \textpar{$\flat$} directions at $\sol$ are respectively defined as
\begin{equation}
\label{eq:sharp}
\sharps
	= \setdef{\coord\in\actcoords}{\slack_{\coord} > 0}
	\qquad
	\text{and}
	\qquad
\flats
%	= \actcoords\setminus\sharps
	= \setdef{\coord\in\actcoords}{\slack_{\coord} = 0},
\end{equation}
and we say that $\vecfield$ is \emph{sharp} at $\sol$ if $\sharps = \actcoords$ (or, equivalently, if $\flats = \varnothing$).
The \emph{sharpness} of $\vecfield$ at $\sol$ is then defined as
\begin{equation}
\label{eq:drift}
\drift
	= \min\nolimits_{\coord\in\sharps} \slack_{\coord}.
\end{equation}
%and we will say that $\sol$ is itself \emph{sharp} if
%$\lspan(\sharps) + \row(\mat) = \points$.
%$\sharps = \{1,\dotsc,\nCoords\}$ (\ie $\sol=0$ and $\sharps = \actcoords$).\FI{Added this, delete if too redundent}
\end{definition}

The terminology ``sharp'' and ``flat'' alludes to the case where $\vecfield$ is a gradient field, and is best illustrated by an example.
To wit, let $\obj(\point_{1},\point_{2}) = \point_{1} + \tfrac{1}{2}(\point_{2}-1)^{2}$ for $\point_{1},\point_{2}\geq0$, so $\obj$ admits a (unique) global minimizer at $\sol = (0,1)$.
Applying \cref{def:sharp} to $\vecfield = \nabla\obj$, we readily get $\sharps = \{1\}$ and $\flats=\{2\}$, reflecting the fact that $\obj(\point_{1},1)$ exhibits a sharp minimum at $0$ along $\point_{1}$ whereas the landscape of $\obj(0,\point_{2})$ is flat to first-order around $1$ along $\point_{2}$.


%----------------------------------------------------------------------
%%% RATES
%----------------------------------------------------------------------
\subsection{Convergence rate analysis}
\label{sec:rate-sharp}

We are now in a position to state and prove our refinement of \cref{thm:general} for linearly constrained problems.
To that end, following \citet{ABB04}, we will assume in the rest of this section that \eqref{eq:AMP} is run with a Bregman regularizer $\hreg$ that is adapted to the polyhedral structure of $\points$ as per the definition below:

\begin{definition}
\label{def:decomposable}
Let $\points$ be a polyhedral domain of the general form \eqref{eq:polyhedron}, and let $\hker\from\R_{+}\to\R$ be a continuous function such that
\begin{enumerate*}
[\itshape a\upshape)]
\item
$\hker''(\point)$ exists and is positive for all $\point>0$;
and
\item
$\hker''$ is locally Lipschitz on $(0,\infty)$.
\end{enumerate*}
Then, a Bregman regularizer $\hreg$ on $\points$ is said to be \emph{decomposable with kernel $\hker$} if
\begin{equation}
\label{eq:decomposable}
\hreg(\point)
	= \sum_{\coord=1}^{\nCoords} \hker(\point_{\coord})
	\quad
	\text{for all $\point\in\points$}.
\end{equation}
\end{definition}

%\begin{assumption}[Polyhedral Bregman regularizers]\label{asm:decomposable}
%	Let $\hker$ be a proper, \ac{lsc}, convex $\R\to\R\cup\{\infty\}$ function with domain $\dom \hker = [0, +\infty)$ and $\hker'$ be a continuous selection of subgradients. We define
%\begin{equation}
%\hreg(\point)
%	\defeq \sum_{\coord=1}^{\nCoords} \hker(\point_{\coord}) \text{ if } \mat \point = \cvec \text{ and } + \infty \text{ elsewhere}\,
%	\end{equation}
%	so that $\points = \dom \hreg$.
%	Moreover, we assume that $\hreg$ is 1 strongly convex w.r.t.~some norm $\|.\|$.
%\end{assumption}

In addition to facilitating calculations, the notion of decomposability will further allow us to describe the convergence rate of the iterates of \eqref{eq:AMP} near the boundary of $\points$ in finer detail.
%and ultimately explain the differences observed in \crefrange{ex:Eucl-sharp}{ex:simplex-2d}.
In fact, as it turns out, the speed of convergence along a given direction will actually be determined by the behavior of the derivative of the Bregman kernel $\hker$ near $0$.

%\PMedit
{
In this regard, there are two distinct regimes to consider.
First, if $\lim_{\point\to0^{+}}\hker'(\point) = -\infty$, it is straightforward to see that $\dom\subd\hreg = \relint\points$ so, by \cref{lem:mirror}, the iterates $\curr$ of \eqref{eq:AMP} will remain in $\relint\points$ for all $\run$;
in this case $\hreg$ is essentially smooth \textendash\ or \emph{Legendre} \textendash\ in the sense of \citet[Chap.~26]{Roc70}, and we will refer to it as \emph{steep}.
Otherwise, if $\hker'(0)$ exists and is finite, $\curr$ may reach the boundary of $\points$ in a finite number of iterations;
we will refer to this case as \emph{non-steep}.
The key difference between these two regimes is that, in the non-steep case, the algorithm may achieve convergence in a finite number of steps (at least along certain directions).
On the other hand, even though finite-time convergence is not possible in the steep regime, the algorithm's rate of convergence may still depend on the boundary behavior of $\hker$.
To illustrate this, we will consider the following concrete cases:
}

\begin{assumption}
\label{asm:ker}
Let $\hker\from\R_{+}\to\R$ be a kernel function as per \cref{def:decomposable}.
%Then, as $\point\to0^{+}$, one of the following holds:
Then $\hker'$ exhibits one of the following behaviors as $\point\to0^{+}$:
\begin{enumerate}
[(\itshape a\upshape)]
\item
\label[case]{asm:ker-Eucl}
\emph{Euclidean-like:}
	\tabto{7em}
	$\liminf_{\point\to0^{+}} \hker'(\point) > -\infty$.
% \PM{An internal remark for posterity:
% since $\hker'$ is increasing (by \cref{def:decomposable}), the above implies that $\lim_{\point\to0^{+}}\hker'(\point)$ also exists, and is hence equal to $\hker'(0)$.}
% \WA{Curiosity question on the internal remark: why couldn't this limit be > $\hker'(0)$?}
% \PM{I was thinking because $\hker$ is differentiable in the interior $+$ mean value theorem.}
% \WA{Indeed}

\item
\label[case]{asm:ker-log}
\emph{Entropy-like:}
	\tabto{7em}
	$\liminf_{\point\to0^{+}} \bracks{\hker'(\point) + \log\point} > -\infty$.
\item
\label[case]{asm:ker-power}
\emph{Power-like:}
	\tabto{7em}
	$\liminf_{\point\to0^{+}} \point^{\kernelexp} \hker'(\point) > -\infty$ for some $\kernelexp\in(0,1)$.
\end{enumerate}
\end{assumption}

%----------------------------------------------------------------------
\begin{remark*}
\Crefrange{asm:ker-Eucl}{asm:ker-power} above respectively mean that $\abs{\hker'(\point)}$ grows as $\bigoh(1)$, $\bigoh(\abs{\log\point})$ or $\bigoh(1/\point^{\kernelexp})$ as $\point\to0^{+}$.
Clearly, we have \ref{asm:ker-Eucl}$\implies$\ref{asm:ker-log}$\implies$\ref{asm:ker-power} so these cases are not exclusive;
nonetheless, to avoid overloading the presentation, when we say that \ref{asm:ker-log} holds, we will tacitly imply that \labelcref{asm:ker-Eucl} does not also hold at the same time \textendash\ and likewise for \ref{asm:ker-power}.
%Under this convention, \cref{asm:ker}\ref{asm:ker-Eucl} corresponds to non-steep regularizers, whereas \cref{asm:ker-log,asm:ker-power} are both steep.
\endenv
\end{remark*}
%----------------------------------------------------------------------


%\begin{assumption}\label{asm:ker}
% The behavior of $\hker$ near $0$ either satisfies:
%	\begin{enumerate}[(a)]
%			\item There exists $\kernelcst \in \R$, $\kernelexp > 0$, $\thres > 0$ such that, for $ \point \in \dom \partial \hker \cap [0, \thres)$,
%\begin{equation}
%	\log \point - \kernelcst \le \hker'(\point)\,.
%\end{equation}\label{asm:ker grad log}
%		\item There exists $\kernelcst > 0$, $\kernelexp > 0$, $\thres > 0$ such that, for $ \point \in \dom \partial \hker \cap [0, \thres)$,
%\begin{equation}
%	-\kernelcst\point^{-\kernelexp} \le \hker'(\point)
%\end{equation} \label{asm:ker grad sublinear}
%	\item $\hker'$ is defined at 0 and it is continuous on its whole domain $\proxdom = [0, +\infty)$.
%\label{asm:ker grad continuous}
%\WA{If we wanted to be able to say that this case implies that $\legexp = 0$, we would need to replace "continuous" by "locally Lipschitz".}
%	\end{enumerate}
%\end{assumption}
%
%With this notion at hand, we can now state our main result of this section: the coordinates of Mirror-prox type methods converge linearly, sublinearly, or even in finite time depending on the steepness of the Bregman regularizer as characterized by the above assumption.

With all this in hand, we proceed to show that, in linearly constrained problems, \eqref{eq:AMP} converges along sharp directions at $\sol$ at an accelerated rate relative to \cref{thm:general}:
sublinear rates may become linear, and linear rates transform to convergence in finite time.

\begin{theorem}
\label{thm:sharp}
%Let $\points$ be a polyhedral domain of the general form \eqref{eq:polyhedron}, and assume that \eqref{eq:AMP} is run with a decomposable regularizer as per \cref{def:decomposable}.
Suppose that \eqref{eq:AMP} is run in a polyhedral domain with a decomposable regularizer as per \cref{def:decomposable}.
Suppose further that \cref{asm:Lipschitz,asm:strong,asm:signal-base,asm:ker} hold, and that the method's step-size and initialization satisfy the requirements of \cref{thm:general}.
Then, for all $\coord\in\sharps$, we have:
\smallskip
\begin{subequations}
\label{eq:rate-sharp}
\begin{enumerate}
%[left=1em,label={\bfseries Case (\alph*):}]
[(\itshape a\upshape)]
\item
Under \cref{asm:ker}\ref{asm:ker-Eucl}, there exists some $\nRuns \geq \start$ such that:
\begin{align}
\label{eq:rate-sharp-Eucl}
\state_{\coord,\run}
	&= 0
	\quad
	\text{for all $\run\geq\nRuns$}
\shortintertext{%
\item
Under \cref{asm:ker}\ref{asm:ker-log}:}
\label{eq:rate-sharp-log}
\state_{\coord,\run}
	&= \bigoh\parens[\big]{\exp(-\step\drifteff\run/2)}
\shortintertext{%
\item
Under \cref{asm:ker}\ref{asm:ker-power}:}
\label{eq:rate-sharp-power}
\state_{\coord,\run}
	&= \bigoh\parens[\big]{(\step\drifteff\run/2)^{-1/\kernelexp}}
\end{align}
\end{enumerate}
\end{subequations}
where
\begin{equation}
\label{eq:drift-eff}
\drifteff
	= \begin{cases}
		\drift
			&\quad
			\text{if $\vecfield$ is sharp at $\sol$ \textpar{\ie $\flats=\varnothing$}},
			\\
		\drift/\varrho
			&\quad
			\text{otherwise},
	\end{cases}
\end{equation}
and $\varrho \equiv \varrho(\mat,\cvec,\sol) \geq 1$ is a positive constant that depends only on $\points$ and $\sol$.
\end{theorem}

\cref{thm:sharp} is the main result of this section so, before proving it, some remarks are in order.
We begin with the observation that, if the sharp directions at $\sol$ suffice to characterize it, the coordinate-wise guarantees \eqref{eq:rate-sharp} must extend to the full space.
This is always so if $\sol$ is an extreme point of $\points$ and $\vecfield$ is sharp at $\sol$, in which case we will say that $\sol$ is itself \emph{sharp}.
We then have the following immediate corollary of \cref{thm:sharp}:
%\begin{equation}
%\label{eq:sol-sharp}
%\lspan(\sharps) + \row(\mat)
%	= \pspace
%\end{equation}
%\WAedit{To better understand \cref{thm:sharp}, one can look at the particular case of $\sol$ being an extremal point and $\vecfield$ sharp at $\sol$.}


%----------------------------------------------------------------------
%% Simplex figure begins here

\begin{figure}
\centering
\resizebox{!}{.27\textwidth}{\input{Figures/Sol-mixed.tex}}
\hfill
\resizebox{!}{.27\textwidth}{\input{Figures/Sol-pure.tex}}
\hfill
\resizebox{!}{.27\textwidth}{\input{Figures/Sol-strict.tex}}
\hspace{2em}
\caption{Different solution configurations:
a non-extreme solution where $\vecfield$ is sharp (left),
an extreme solution where $\vecfield$ is not sharp (center),
and
a sharp solution (\ie an extreme solution where $\vecfield$ is sharp; right).}
\label{fig:simplex}
\vspace{-2ex}
\end{figure}

%% Simplex figure ends here
%----------------------------------------------------------------------


\begin{corollary}
\label{cor:sharp}
%\WAedit{Under the condition that $\lspan \setdef{\bvec_\coord}{\coord \in \sharps} + \row(\mat) = \pspace$, we have $\norm{\curr - \sol} \to 0$ at a rate}
\PMedit{If $\sol$ is sharp, we have $\norm{\curr - \sol} \to 0$ at a rate given by}
\eqref{eq:rate-sharp-Eucl}, \eqref{eq:rate-sharp-log}, or \eqref{eq:rate-sharp-power},
%\cref{eq:rate-sharp-Eucl,eq:rate-sharp-log,eq:rate-sharp-power},
depending respectively on whether \cref{asm:ker-Eucl}, \labelcref{asm:ker-log}, or \labelcref{asm:ker-power} of \cref{asm:ker} holds.
\end{corollary}

\begin{proof}
First, note that $\sol$ is sharp if and only if $\lspan\setdef{\bvec_{\coord}}{\coord\in\sharps} + \row(\mat) = \R^{\nCoords}$:
indeed, since $\points$ is a polyhedron, $\sol$ is extreme if and only if $\ncone(\sol)$ has nonempty topological interior, and this, combined with \eqref{eq:ncone-sharp} and the fact that $\sharps = \actcoords$ (since $\vecfield$ is sharp at $\sol$), proves our assertion.
We thus conclude that, for all $\coord = 1,\dotsc,\nCoords$, there exist $\coef_{\coord\coordalt} \in \R$, $\coordalt\in\sharps$, such that $\bvec_{\coord} - \sum_{\coordalt\in\sharps} \coef_{\coord\coordalt} \bvec_{\coordalt} \in \row(\mat)$,
and hence, for all $\run = \running$, we have $\state_{\coord,\run} - \sol[\state_{\coord}] = \sum_{\coordalt \in \sharps} \coef_{\coord\coordalt} \state_{\coordalt,\run}$.
Our claim then follows from \cref{thm:sharp} and the fact that all norms are equivalent on $\R^{\nCoords}$.
\end{proof}

We continue with a series of observations elaborating further on \cref{thm:sharp}.

%----------------------------------------------------------------------
\setcounter{remark}{0}
%----------------------------------------------------------------------
\begin{remark}
[Examples]
\label{rem:examples}
In our series of running examples, the guarantees of \cref{thm:sharp} are as follows:
\begin{enumerate}
\item
\emph{Euclidean regularization} (\cref{ex:Eucl}):
With $\hker(\point) = \point^{2}/2$, this regularizer satisfies \cref{asm:ker}\ref{asm:ker-Eucl} because $\hker'$ is defined and continuous on all of $\R_{+}$, so we get convergence along the sharp directions of $\sol$ in a finite number of steps.
\item
\emph{Negative entropy} (\cref{ex:ent}):
The corresponding kernel is $\hker(\point) = \point \log \point$ for $\point \geq 0$.
Since $\hker'(\point) = \log \point + 1$ on $(0,\infty)$, $\hker$ satifies \cref{asm:ker}\ref{asm:ker-log}, so the algorithm's rate of convergence along sharp directions is geometric.
\item
\emph{Tsallis entropy} (\cref{ex:frac}):
For $\qexp < 1$, the kernel $\hker(\point) =
[\qexp(1-\qexp)]^{-1} (\point - \point^{\qexp})$ is differentiable on $(0, \infty)$.
Since $\hker'(\point) = [\qexp(1-\qexp)]^{-1} (1 - \qexp \point^{\qexp-1})$, this kernel satisfies \cref{asm:ker}\ref{asm:ker-power} with $\kernelexp = 1-\qexp$, leading to an $\bigoh(1/\run^{1/(1-\qexp)})$ rate of convergence along sharp directions.
It is also worth noting here that the Legendre exponent at $\sol$ is upper bounded by $\kernelexp$ as $\legsol \leq (1 + \kernelexp)/2$;
we defer the details of this calculation to \cref{app:ex}.
\item
\emph{Hellinger regularizer} (\cref{ex:Hell}):
The Hellinger kernel is given by $\hker(\point) = -\sqrt{1-\point^{2}}$, so $\hker'(\point) = \point/(1-\point^{2})$ for all $\point\in(-1,1)$.
The behavior of this kernel would then correspond to \cref{asm:ker}\ref{asm:ker-power} with $\kernelexp = 1/2$.
\end{enumerate}
To facilitate comparisons with \cref{thm:general}, we juxtapose the corresponding rates in \cref{tab:rates-sharp}.
% Indeed, let $\nhd$ be the neighborhood of $\base$ given by \cref{asm:ker} \ref{asm:ker grad sublinear}.
% At the cost of reducing $\nhd$, we can assume that $\nhd \cap \bd \dom \hker \subseteq \{\base\}$.
% Now, we can safely take some $\point \in \nhd \cap \dom \partial \hker$, with $\point \neq \base$ and it is guaranteed that $[\point, \base) \in \intr\dom \hker $.
\endenv
\end{remark}
%----------------------------------------------------------------------


%----------------------------------------------------------------------
%% Table of rates begins here

\begin{table}[tbp]
\footnotesize
\renewcommand{\arraystretch}{1.25}
%\setlength{\tabcolsep}{1em}
\input{Tables/Rates-Sharp}
\smallskip
\caption{Summary of the accelerated rates of convergence observed along sharp directions as a function of the underlying Bregman kernel (\cf \cref{def:decomposable}).
The Euclidean, entropic and Tsallis kernels are the prototypical examples of \cref{asm:ker-Eucl,asm:ker-log,asm:ker-power} of \cref{asm:ker};
%(\cf \crefrange{ex:Eucl-sharp}{ex:frac-sharp});
to avoid trivialities, we only consider the behavior of $\hker$ at the boundary of its domain.}
\label{tab:rates-sharp}
\vspace{-2ex}
\end{table}

%% Table of rates ends here
%----------------------------------------------------------------------


%----------------------------------------------------------------------
\begin{remark}
[Solution configurations]
By construction (and the fact that $\points$ admits a Slater point), it is straightforward to verify that $\vecfield$ is sharp at $\sol$ if and only if $\vecfield(\sol) \in -\relint(\ncone(\sol))$;
likewise, $\sol$ is itself sharp if and only if $\vecfield(\sol) \in -\intr(\ncone(\sol))$.
%\PMedit
{
As we noted in the proof of \cref{cor:sharp}, the latter condition is equivalent to asking that $\lspan\setdef{\bvec_{\coord}}{\coord\in\sharps} + \row(\mat) = \R^{\nCoords}$, a condition which describes precisely the informal requirement that the sharp directions at $\sol$ suffice to characterize it.
By contrast, if $\vecfield$ is sharp at some non-extreme point $\sol$, there exists some (nonzero) $\tvec\in\tcone(\sol)$ such that $\braket{\vecfield(\sol)}{\tvec} = 0$, indicating that the accelerated rates of \cref{thm:sharp} cannot be active along the residual direction $\pvec$.
}
We illustrate these distinct solution configurations in \cref{fig:simplex}.

\endenv
\end{remark}
%----------------------------------------------------------------------


%----------------------------------------------------------------------
\begin{remark}[Alternative polyhedral representations]
Even though every polyhedral domain can be represented in normal form by means of \eqref{eq:polyhedron} \textendash\ possibly up to introducing a set of slack variables to account for constraints of the form $\mat\point \leq \cvec$ \textendash\ some polyhedra can be represented more succinctly as
%This theorem could be generalized, mainly at the cost of more intricate settings and notations, to the following class of polyhedra
\begin{equation}
\label{eq:polyhedron-alt}
\points
	= \setdef{\point\in\R^{\nCoords}}{\text{$\mat\point = \cvec$ and $\inner{\matalt_{\constr}}{\point} \in \region_{\constr}, \constr=1,\dotsc,\nConstr$}}
\end{equation}
for an ensemble of vectors $\matalt_{\constr} \in \R^{\nCoords}$ and intervals $\region_{\constr} \subseteq \R$ for each of the problem's inequality constraints $\constr=1,\dotsc,\nConstr$.
At the cost of heavier notation, \cref{thm:sharp} can be extended to this setting by considering decomposable Bregman regularizers of the form $\hreg(\point) = \sum_{\constr=1}^{\nConstr} \hker_{\constr}(\inner{\matalt_{\constr}}{\point})$, $\point\in\points$, where each $\hker_{\constr}$ is a suitable Bregman kernel on $\region_{\constr}$.
Mutatis mutandis, the sets of active, sharp and flat constraints can then be defined as in \cref{def:sharp}, and the guarantees of \cref{thm:sharp} would apply to the constraint excess variables $\chi_{\constr,\run} = \inner{\matalt_{\constr}}{\curr}$, $\constr=1,\dotsc,\nConstr$.
%	\begin{align}
%		\points = \{\point \in \pspace: \inner{\matalt_{\coord}}{\point} \in \dom \hker_{\coord}, \coord=1,\dots,\nConstr, \mat \point = \cvec\}\,,
%	\end{align}
%	with
%	\begin{align}
%		\hreg(\point) \defeq \sum_{\coord = 1}^{\nCoords} \hker_{\coord}\parens*{\inner{\matalt_{\coord}}{\point}} + \delta_{\mat \point = \cvec}\,.
%	\end{align}
%	However, the guarantees of the \cref{thm:sharp} would be on the quantities,
%	\begin{align}
%		|\inner{\matalt_{\coord}}{\point - \sol}| \text{ for } \coord \in \sharps\,.
%	\end{align}
\endenv
\end{remark}
%----------------------------------------------------------------------


%----------------------------------------------------------------------
\begin{remark}[Tightness and the structure of $\points$]
It is also important to note that the dependence of $\drifteff$ on the structure of $\points$ in the second branch of \eqref{eq:drift-eff} cannot be lifted.
To see this, let
\begin{equation}
\points
	= \setdef{\point\in\R_{+}^{2}}{\point_{1} = \eps\point_{2}}
\end{equation}
\ie $\mat = \bracks{1 \; -\eps}$ and $\ker\mat$ is spanned by the vector $\pvec = (\eps,1)$.
Then, if we take $\vecfield(\point) = \point - \base$ with $\base_{1} \leq 0$ and $\base_{2} \geq 0$ (so that the origin is a solution), and we equip $\points$ with the Bregman regularizer induced by the entropic kernel $\hker(\point) = \point\log\point$, a straightforward calculation shows that the iterates of \eqref{eq:MD} satisfy the recursion
\begin{equation}
\eps \hker'(\state_{1,\run+1}) + \hker'(\state_{2,\run+1})
	= \bracks[\big]{\eps \hker'(\state_{1,\run}) + \hker'(\state_{2,\run})}
		+ \step \parens[\big]{\eps\state_{1,\run} + \state_{2,\run}}
		- \step \inner{\base}{\pvec}.
\end{equation}
Thus, letting $\curr[\chi] = \state_{2,\run} = \state_{1,\run} / \eps$, the above can be rewritten as
\begin{equation}
\eps \hker'(\eps\next[\chi]) + \hker'(\next[\chi])
	= \bracks[\big]{\eps \hker'(\eps\curr[\chi]) + \hker'(\curr[\chi])}
		+ \step (\eps^{2} + 1) \curr[\chi]
		- \step \inner{\base}{\pvec}
\end{equation}
and hence, with $\hker'(\point) = 1 + \log\point$, we finally get
\begin{equation}
\next[\chi]
	= \curr[\chi] \exp\parens*{
			- \step \frac{\eps^{2} + 1}{\eps + 1} \curr[\chi]
			+ \step \frac{\inner{\base}{\pvec}}{\eps + 1}
		}.
\end{equation}
Now, if $\inner{\base}{\pvec} < 0$,
we readily infer that $\curr[\chi] = \state_{2,\run}$ converges linearly to $0$
%as predicted by \cref{thm:sharp}. More exactly, we have that, up to a constant
at a rate of
\begin{equation}
\curr[\chi]
	\sim \exp\parens*{- \frac{\abs{\inner{\base}{\pvec}}}{\eps + 1} \step\run}
\end{equation}
as predicted by \cref{thm:sharp}.
In particular, if $\vecfield(0) = - \base = (\drift, \drift)$
with $\drift > 0$, the iterates of \eqref{eq:MD} converge geometrically to zero with exponent $\step \drift$, which matches the estimate of \cref{thm:sharp} up to a factor of $1/2$ in the exponent.
On the contrary, if $\vecfield(0) = -\base = (\drift, 0)$, the term $\abs{\inner{-\base}{\pvec}} = \eps\drift$ depends on the linear structure of $\points$ and can be arbitrarily bad as $\eps$ goes to zero.
This illustrates why one cannot do away with the dependence on the linear structure of $\points$ when $\vecfield$ is not sharp at $\sol$.
\endenv
\end{remark}
%----------------------------------------------------------------------


%----------------------------------------------------------------------
%%% TECHNICAL PROOFS
%----------------------------------------------------------------------
\subsection{Proof of \cref{thm:sharp}}
\label{sec:proof-sharp}

We now proceed to the proof of \cref{thm:sharp}, beginning with two helper lemmas tailored to the polyhedral structure of $\points$.
%Before starting the proof of the result, we introduce two helpful lemmas linking the steepness of $\hreg$ to the one of $\hker$, and comparing active constraints.
The first is a book-keeping result regarding the subdifferentiability of $\hreg$.

\begin{lemma}
\label{lem:dh}
Let $\hreg$ be a decomposable regularizer on $\points$ with kernel $\hker$ as per \cref{def:decomposable}.
Then the domain of subdifferentiability of $\hreg$ is $\proxdom = \setdef{\point \in \points}{\point_{\coord} \in \dom \subd \hker \text{ for all } \coord = 1,\dots,\nCoords}$ and a continuous selection of $\subd\hreg$ is given by the expression
\begin{equation}
\label{eq:dh}
\nabla \hreg(\point)
	= \sum_{\coord = 1}^{\nCoords} \hker'(\point_{\coord})\bvec_{\coord}
	\quad
	\text{for all $\point\in\proxdom$}.
\end{equation}
%defines a continuous selection of subgradients of $\hreg$ on $\proxdom = \{\point \in \points: \point_{\coord} \in \dom \subd \hker \text{ for } \coord = 1,\dots,\nCoords\}$.
\end{lemma}

\begin{proof}
%This is a consequence of the fact that the subdifferential of a sum of functions is the sum of their subdifferentials if the the relative interiors of their domains intersect
See \citet[Thm~23.8]{Roc70}, whose qualification condition is satisfied thanks to the fact that $\points$ is polyhedral.
\end{proof}

%As a consequence, $\hreg$ is steep if and only if $\hker$ is steep:
%	\begin{equation}
%		\dom \partial \hreg = \relint \points \iff \dom \partial \hker = \intr \dom \hker = (0,+\infty)\,.
%	\end{equation}

The second ingredient we will need is a separation result in the spirit of Farkas' lemma.

\begin{restatable}{lemma}{separation}
\label{lem:separation}
%Suppose that $\points$ is of the general polyhedral form \eqref{eq:polyhedron}.
Let $\points$ be a polyhedral domain of the general form \eqref{eq:polyhedron}.
Then, for all $\sol\in\points$, there exists $\polycst = \polycst(\mat, \cvec, \sol) \geq 1$ such that, for all $\coords \subseteq \actcoords \equiv \actcoords(\sol)$, at least one of the following holds:
\begin{enumerate}
[(\itshape a\upshape)]
\item
\label[case]{itm:inactive}
$\coords \neq \varnothing$ and there exists $\coord \in \actcoords\setminus\coords$ such that
%\begin{align}
%\forall \point \in \points,\,
\(
\point_{\coord}
	\leq \polycst \max\setdef{\point_{\coordalt}}{\coordalt \in \coords}
%	\quad
%	\text{for all $\point\in\points$}.
%\end{align}
\)
for all $\point\in\points$.
\item
\label[case]{itm:active}
There exists $\pvec \in \ker\mat$ such that $\norm{\pvec} \leq \polycst$, $\pvec_{\coord} = 0$ if $\coord \in \coords$ and $\polycst \geq \pvec_{\coord} \geq 1$ if $\coord \in \actcoords \setminus \coords$.
\end{enumerate}
\end{restatable}

The proof of \cref{lem:separation} is based on Farkas' lemma so we relegate it to \cref{app:aux} and instead proceed to use it to prove our main result for linearly constrained problems.

\begin{proof}[Proof of \cref{thm:sharp}]
We will consider two main cases, depending on whether $\lim_{\point\to0^{+}}\hreg'(\point) = -\infty$ (the steep case) or $\lim_{\point\to0^{+}}\hreg'(\point) > -\infty$ (the non-steep case).
The steep regime will cover \cref{asm:ker-log,asm:ker-power} of \cref{asm:ker}, whereas the non-steep regime will account for \cref{asm:ker-Eucl}.

\para{Case 1: the steep regime}
We begin by noting that, without loss of generality, \cref{asm:ker-log,asm:ker-power} respectively imply that there exist $\kernelcst\in\R$ and $\thres>0$ such that, for all $\point\in(0,\thres)$, we have:
\begin{subequations}
\label{eq:ker-growth}
\begin{flalign}
\qquad
\text{Under \cref{asm:ker}\ref{asm:ker-log}:}
	&\;\;\;
	\text{$\hker'(\point) \geq \log\point - \kernelcst$}
	&&
	\\
\text{Under \cref{asm:ker}\ref{asm:ker-power}:}
	&\;\;\;
	\text{$\hker'(\point) \geq -\kernelcst\point^{-\kernelexp}$}
	&&
\end{flalign}
\end{subequations}
With this in mind, let $\radius > 0$ be sufficiently small so that the relative neighborhood $\ball_{\radius} \defeq \setdef{\point\in\points}{\norm{\point - \sol} \leq \radius}$ of $\sol$ in $\points$ satisfies:
\begin{itemize}
\item
$\ball_{\radius} \subseteq \nhd \cap \basin$ with $\basin$ and $\nhd$ defined by \eqref{eq:strong} and \eqref{eq:Breg-nhd} respectively.
\item
If $\point \in \ball_{\radius}$ then $\point_{\coord} < \thres$ for all $\coord \in \actcoords$.
%where $\thres$ is given by \cref{asm:ker grad sublinear} or \cref{asm:ker grad log} of \cref{asm:ker},
\item
If $\point \in \ball_{\radius}$, then $\dnorm{\vecfield(\point) - \vecfield(\sol)} \leq \drift/(2\polycst)$ with $\drift$ given by \eqref{eq:drift} and $\polycst$ given by \cref{lem:separation}.

%\PM{We have not defined $\bregbdedcst$, so maybe it would be better to define $\bregbdedcst$ as the supremum of (\dots) over $\ball_{\radius}$ when we actually need it?}
%\WA{Indeed, implemented}
\end{itemize}

%To proceed, 
Recall that Step 1 of the proof of \cref{thm:general} implies that the iterates $\curr$ and half-iterates $\lead$ of \eqref{eq:AMP} will remain in $\ball_{\radius}$ for all $\run$ %=\running$ 
if $\init$ is initialized sufficiently close to~$\sol$.
Accordingly, with this stability guarantee in hand, we will construct sets $\coords_{\sharp} \subseteq \sharps$, $\coords_{\flat} \subseteq \flats$ such that, for all $\coord \in \coords \defeq \coords_{\sharp} \cup \coords_{\flat}$,% we have
\begin{align}
\label{eq:propCoord}
\state_{\coord,\run}
	\leq \polycst^{\abs{\coords}}
		\cdot \begin{cases}
		\exp\parens*{\kernelcst + \polycst \dnorm{\grad \hreg(\init)} + \polycst \bregbdedcst - \step \drifteff(\run - 1)/2}
			&\quad
			\text{under \cref{asm:ker}\ref{asm:ker-log},}
			\\
		\kernelcst \pospart*{\step\drifteff(\run - 1)/2 - \polycst \dnorm{\grad \hreg(\init)} - \polycst \bregbdedcst}^{-\frac{1}{\kernelexp}}
			&\quad
			\text{under \cref{asm:ker}\ref{asm:ker-power}},
		\end{cases}
\end{align}
where
{$\bregbdedcst \defeq \sup_{\point \in \ball_{\radius}} \dnorm*{ \sum_{\coord \notin \actcoords} \hker'(\point_{\coord}) \bvec_\coord}$, $\polycst \geq 1$ is the constant given by \cref{lem:separation} and
$\drifteff$ is defined as in \eqref{eq:drift-eff} with $\varrho = \polycst\abs{\actcoords}$.
%	\begin{align}
%		\drifteff \defeq
%		\begin{cases}
%			\drift & \text{if the sharpness assumption \cref{assumption:sharpness} holds,} \\
%			\frac{\drift}{\polycst \abs{\actcoords}} & \text{otherwise.}
%		\end{cases}
%	\end{align}
}
%\WA{For reference: this is $< + \infty$ because this concerns only inactive coordinates and because $\hker$ is continuous on the interior of its domain}
%\PM{Eh, whatevs\dots I say, forget about it, if they ask, we'll answer\dots}
%\PM{There was a definition here for $\drift$ which clashed with the original definition in the theorem (basically whether we use $\polycst$ or $\polycst\abs{\actcoords}$ in the denominator;
%can you please check the commented source file?}
%\WA{This was because my constant $\polycst$ differed in the proof and in the theorem, this is explicit now, \ie we take $\varrho \defeq \polycst \abs{\actcoords}$, but this can be removed at the expense of an addtionnal term in the statement of the theorem.}
%\PM{Does the current sentence suit you? If yes, we can view the issue as resolved?}
%\WA{Yep!}
%\PM{This would also be a better place to define $\bregbdedcst$ I think\dots}
%\WA{Done}
%where $\kernelcst$ is as in \cref{asm:ker} and
%	\begin{align}
%		\drifteff \defeq
%		\begin{cases}
%			\drift & \text{if the sharpness assumption \cref{assumption:sharpness} holds,} \\
%			\frac{\drift}{\polycst \abs{\actcoords}} & \text{otherwise.}
%		\end{cases}
%	\end{align}


We will proceed inductively, starting with $\coords_{\sharp} = \coords_{\flat} = \varnothing$, in which case the stated property holds trivially.
For the inductive step, if \eqref{eq:propCoord} holds for $\coords_{\sharp} \subsetneq \sharps$ and $\coords_{\flat} \subseteq \flats$, we will show that there is some index $\coordalt \in \actcoords \setminus \coords$ such that \eqref{eq:propCoord} still holds for $\coords \cup \{\coordalt\}$.
By iterating this procedure, since the number of active constraints is finite, we will reach %a point where
$\coords_{\sharp} = \sharps$ and the result of the theorem will follow.

To carry all this out, assume that $\coords_{\sharp} \subsetneq \sharps$, $\coords_{\flat} \subseteq \flats$, and apply \cref{lem:separation} to $\coords = \coords_{\sharp} \cup \coords_{\flat}$.
If the first case of \cref{lem:separation} holds, then $\coords \neq \varnothing$ and there exists $\coord \in \actcoords$ such that
\begin{equation}
\state_{\coord,\run}
	\leq \polycst \max\nolimits_{\coordalt\in\coords} \state_{\coordalt,\run}
\end{equation}
so \eqref{eq:propCoord} still holds when $\coord$ is appended to $\coords_{\sharp}$ or $\coords_{\flat}$ (depending on whether it belongs to $\sharps$ or $\flats$).
Otherwise, the second case of \cref{lem:separation} holds and there exists some $\pvec \in \ker\mat$ with $\norm{\pvec} \leq \polycst$,
$\pvec_{\coord} = 0$ if $\coord \in \coords$,
and
$\polycst \geq \pvec_{\coord} \geq 1$ if $\coord \in \actcoords \setminus \coords$.
Since $\hreg$ is steep, this means that $\next = \proxof{\curr}{-\step \lead[\signal]}$ belongs to $\proxdom = \relint \points$ for all $\run=\running$, so the normal cone $\ncone(\next)$ to $\points$ at $\next$ will be the affine hull of $\points$, \ie $\ncone(\next) = \row(\mat)$.
Hence, \cref{lem:mirror} guarantees that
\begin{equation}
\label{eq:proof-sharp-mirror-step}
\subsel\hreg(\next)
	- \subsel\hreg(\curr)
	+ \step \lead[\signal]
	\in \row(\mat)
\end{equation}
so, telescoping over $\runalt = \start$ to $\run-1$, we get
\begin{equation}
\subsel\hreg(\curr)
	- \subsel\hreg(\init)
	+ \step \sum_{\runalt = \start}^{\run-1} \iterlead[\signal]
	\in \row(\mat).
\end{equation}
Taking the scalar product with $\pvec \in \ker\mat$ then yields
\begin{equation}
\sum_{\coord=1}^{\nCoords} \hker'(\state_{\coord,\run}) \pvec_{\coord}
	= \inner{\subsel\hreg(\init)}{\pvec}
		- \step \sum_{\runalt=\start}^{\run - 1} \inner{\iterlead[\signal]}{\pvec}
\end{equation}
so, after rearranging and invoking \eqref{eq:slacks} to write $\inner{\vecfield(\sol)}{\pvec} = \sum_{\coord \in \actcoords} \slack_{\coord} \pvec_{\coord}$, we get
\begin{align}
\sum_{\coord \in \actcoords \setminus \coords} \hker'(\state_{\coord,\run}) \pvec_{\coord}
	+ \sum_{\coord \in \coords} \hker'(\state_{\coord,\run}) \pvec_{\coord}
	&= \inner{\subsel\hreg(\init)}{\pvec}
		- \step \sum_{\runalt=\start}^{\run - 1} \sum_{\coord \in \actcoords} \slack_{\coord} \pvec_{\coord}
	\notag\\
	&+\step \sum_{\runalt = \start}^{\run - 1} \inner{\vecfield(\sol) - \iterlead[\signal]}{\pvec}
		- \sum_{\coord \notin \actcoords} \hker'(\state_{\coord,\run}) \pvec_{\coord}.
\end{align}
Now, by the properties we used to construct $\pvec$,
%($\norm{\pvec} \leq \polycst$, $\pvec_{\coord} = 0$ if $\coord \in \coords$ and $\polycst \geq \pvec_{\coord} \geq 1$ if $\coord \in \actcoords \setminus \coords$ as stated above),
we further have
%\PM{Gents, if I'm not mistaken $\sum_{\coord \notin \actcoords} \hker'(\state_{\coord,\run})$ is not a vector ;-)
%But anyway, to avoid lugging it around, maybe we give it a name and stop writing the sum everywhere?}
%\WA{Fixed. As for giving it a name, for me we introduc enough notations already, but as you prefer.}
\begin{align}
\label{eq:proof-sharp-template-ineq}
\sum_{\mathclap{\coord\in\actcoords \setminus \coords}} \hker'(\state_{\coord,\run}) \pvec_{\coord}
	& \leq \polycst \dnorm{\subsel\hreg(\init)}
		- \step\parens{\run-1} \sum_{\mathclap{\coord \in \actcoords \setminus \coords}} \slack_{\coord} \pvec_{\coord}
	\notag\\
	&\qquad
		+ \step\sum_{\runalt=\start}^{\run - 1} \polycst \dnorm{\vecfield(\sol) - \iterlead[\signal]}
		+ \polycst \dnorm*{\sum_{\coord \notin \actcoords} \hker'(\state_{\coord,\run}) \bvec_\coord}
	\notag\\
	& \leq \polycst \dnorm{\subsel\hreg(\init)}
		- \step (\run - 1) \sum_{\mathclap{\coord \in \actcoords \setminus \coords}} \slack_{\coord} \pvec_{\coord}
		+ \tfrac{1}{2} \step \drift (\run - 1)
		+ \polycst \bregbdedcst.
\end{align}
where the second inequality follows from how we chose $\ball_{\radius}$ at the beginning of the proof.

We conclude our analysis by distinguishing whether $\vecfield$ is sharp at $\sol$ (\ie if $\flats = \varnothing$ or not).
\begin{enumerate}
[left=0em,label={\bfseries Case \arabic*:}]
\item
If $\flats=\varnothing$, we have $\actcoords \setminus \coords = \sharps \setminus \coords_{\sharp}$ and $\slack_{\coord} \geq \drift$ for all $\coord \in \actcoords \setminus \coords$, so \eqref{eq:proof-sharp-template-ineq} gives
\begin{equation}
\sum_{\coord \in \actcoords \setminus \coords} \hker'(\state_{\coord,\run}) \pvec_{\coord} + \step (\run - 1) \drift \pvec_{\coord}
	\leq \polycst \dnorm{\subsel\hreg(\init)}
		+ \tfrac{1}{2} \step\drift(\run-1)
		+ \polycst \bregbdedcst.
\end{equation}
Choosing the coordinate $\coordalt \in \actcoords \setminus \coords$ which corresponds to the smallest term in the sum on the \ac{LHS}, we obtain that
\begin{align}
	\parens*{\hker'(\state_{\coordalt,\run}) + \step (\run - 1) \drift} (\abs{\actcoords} \setminus \coords) \pvec_{\coordalt}
	\leq
	\polycst \dnorm{\subsel\hreg(\init)}
	+ \tfrac{1}{2} \step\drift(\run - 1)
	+ \polycst \bregbdedcst
\end{align}
and noting that $\abs{\actcoords\setminus \coords} \pvec_{\coordalt} \geq 1$ yields
%\PM{Could you check this line to verify everything is aok? [I did a stupid change at some point and I'm not sure if I reverted things properly]}
%\WA{Checked}
%\WA{There is a very small case that we are brushing under the carpet here. This reasoning is valid only if $\hker'(\state_{\coordalt,\run}) + \step (\run - 1) \drift$ is non-negative. If it's negative, \cref{eq:proof-sharp-final-ineq1} still holds (trivially) though.}
\begin{align}
 \label{eq:proof-sharp-final-ineq1}
	\hker'(\state_{\coordalt,\run})
	\leq
	\polycst \dnorm{\subsel\hreg(\init)}
	-\tfrac{1}{2} \step\drift(\run - 1)
	+ \polycst \bregbdedcst\,.
\end{align}

\item
If $\flats \neq \varnothing$, then, since $\coords_{\sharp} \subsetneq \sharps$, the intersection of $\actcoords \setminus \coords$ and $\sharps$ is not empty so that, $\sum_{\coord \in \actcoords \setminus \coords} \slack_{\coord} \pvec_{\coord} \geq \sum_{\coord \in \actcoords \setminus \coords} \slack_{\coord} \geq \drift$ and the inequality \eqref{eq:proof-sharp-template-ineq} above becomes,
\begin{align}
	\sum_{\coord \in \actcoords \setminus \coords} \hker'(\state_{\coord,\run}) \pvec_{\coord}
	\leq
	\polycst \dnorm{\subsel\hreg(\init)}
	- \tfrac{1}{2} \step\drift(\run - 1)
	+ \polycst \bregbdedcst\,.
\end{align}

Now, choosing $\coordalt$ to be the coordinate in $\actcoords \setminus \coords$ which minimizes the \ac{LHS} and bounding $\abs{\actcoords \setminus \coords}$ by $1$ and $\abs{\actcoords}$, we get that
\begin{align}
\hker'(\state_{\coordalt,\run}) \pvec_{\coordalt}
	\leq
	\polycst \dnorm{\subsel\hreg(\init)}
	-\frac{\step \drift}{2\abs{\actcoords}} (\run - 1)
	+ \polycst \bregbdedcst\,.
\end{align}
Dividing both sides by $\pvec_{\coordalt}$ and using that it lies between $1$ and $\polycst$ gives
\begin{align}
 \label{eq:proof-sharp-final-ineq2}
	\hker'(\state_{\coordalt,\run})
	\leq
	\polycst \dnorm{\subsel\hreg(\init)}
	-\frac{\step \drift}{2 \polycst \abs{\actcoords}} (\run - 1)
	+ \polycst \bregbdedcst\,
\end{align}
\end{enumerate}
Therefore, we have shown that, in both cases, there exists $\coordalt \in \actcoords \setminus \coords$ such that \eqref{eq:proof-sharp-final-ineq2} holds, since $\polycst \abs{\actcoords} \geq 1$.
%\PM{Don't understand this sentence \textendash\ or, rather, I think I understand what you mean, but some polishing is in order.}
Therefore, combining this inequality with \eqref{eq:ker-growth} we conclude that \eqref{eq:propCoord} holds for $\coordalt$,
and 
%\PM{The bound was restated here (commented in the source), not sure why\dots was this intentional?}
%\WA{It's because it was the bound of \eqref{eq:propCoord} \emph{without} the term $\polycst^{\abs{\coords}}$, and it implies \eqref{eq:propCoord} since $\polycst \geq 1$.}
%\begin{align}
%\state_{\coordalt,\run}
%	\leq \begin{cases}
%		\exp\parens*{\kernelcst + \polycst \dnorm{\grad \hreg(\init)} + \polycst \bregbdedcst - \frac{\step \drifteff}{2}(\run - 1)}
%			&\quad
%			\text{ if \cref{asm:ker grad log} of \cref{asm:ker} holds,} \\
%		\kernelcst \pospart*{
%			\frac{\step \drifteff }{2}(\run - 1)
%			- \polycst \dnorm{\grad \hreg(\init)} - \polycst \bregbdedcst
%		}^{-\frac{1}{\kernelexp}}
%		& \text{ if \cref{asm:ker grad sublinear} of \cref{asm:ker} holds.}
%	\end{cases}
%\end{align}
since $\polycst \geq 1$,
%\PM{There's an issue here with what we've actually defined the constant to be.}
we conclude that we can augment $\coords_{\sharp}$ or $\coords_{\flat}$ by $\coordalt$, depending on whether it belongs to $\sharps$ or $\flats$.%respectively.
%\WA{Implicitely, I mean that ``the bound \eqref{eq:propCoord} still holds for the other coordinates that we had already put in $\coords$'', is it clear?}
%\PM{Yep.}
%\WA{Thx}

\para{Case 2: the non-steep regime}
The proof borrows the structure of the first case, though it is more straightforward.

	Take $\radius > 0$ small enough such that $\ball_{\radius} \defeq \{ \point\in\points : \norm{\point - \sol} \leq \radius \}$ satisfies
	\begin{itemize}
		\item $\ball_{\radius}$ is included in $\nhd \cap \basin$,
		\item if $\point, \pointalt \in \ball_{\radius}$ then, $\dnorm{\subsel\hreg (\point) - \subsel\hreg(\pointalt)} \leq \frac{\step \drift}{3 \polycst}$ where $\polycst$ is given by \cref{lem:separation}. This is possible since $\subsel\hreg$ is continuous at $\sol$.
%\WA{The radius $r$ depends on $\step$, this is not very nice but it is the simplest way. The precise way would be to use the uniform continuity of $\subsel\hreg$ near $\sol$...}
		\item if $\point \in \ball_{\radius}$, then $\dnorm{\vecfield(\point) - \vecfield(\sol)} \leq \frac{\drift}{3 \polycst}$.
 \item No other constraint $\point_{\coord} = 0$ with $\coord \notin \actcoords$ becomes active in $\ball_{\radius}$.
	\end{itemize}
	As we have seen in the stability part of the proof of \cref{thm:general}, if \eqref{eq:AMP} is started close enough to~$\sol$, then all the iterates $\curr$ and the half-iterates $\lead$ for $\runalt=\running$ are contained in $\ball_{\radius}$.


 %In this case, we will show that taking $\nRuns = \afterstart$ is enough to get the guarantee of the theorem.
 %\FI{??}\WA{Yep, I don't know either}
 As above, fix some $\run \geq \nRuns$.
 We will build sets $\coords_{\sharp} \subseteq \sharps$, $\coords_{\flat} \subseteq \flats$ with the property that that
 \begin{align}
 \label{eq:propertynonsteep}
 \text{ for all } \coord \in \coords_{\sharp} \cup \coords_{\flat}, \state_{\coord,\run} = 0 \,.
 \end{align}

	Starting with $\coords_{\sharp} = \coords_{\flat} = \varnothing$, \cref{eq:propertynonsteep} is trivially verified.
	Now, take $\coords_{\sharp} \subsetneq \sharps$, $\coords_{\flat} \subseteq \flats$ which satisfy the desired property and, as before, apply \cref{lem:separation} with $\coords \defeq \coords_{\sharp} \cup \coords_{\flat}$.
If the first case of \cref{lem:separation} holds, then $\coords \neq \varnothing$ and there exists $\coordalt \in \actcoords$ such that,
\begin{align}
	\state_{\coordalt,\run} & \leq \polycst \max\parens*{\state_{\coord,\run} : \coord \in \coords}\,,
\end{align}
which yields the result by adding $\coord$ to $\coords_{\sharp}$ or $\coords_{\flat}$ depending whether it belongs to $\sharps$ or $\flats$ .
Otherwise, if the second case holds, there is some $\pvec \in \ker\mat$ such that $\norm{\pvec} \leq \polycst$, $\pvec_{\coord} = 0$ if $\coord \in \coords$ and $\polycst \geq \pvec_{\coord} \geq 1$ if $\coord \in \actcoords \setminus \coords$.
For the sake of contradiction, assume that for all $\coord \in \actcoords \setminus \coords$, $\state_{\coord,\run} > 0$. Showing that this results in a contradiction will give us an additional coordinate $\coordalt \in \actcoords \setminus \coords$ for which $\state_{\coordalt,\run} = 0$ that we will then add to $\coords_{\sharp}$ or $\coords_{\flat}$ as in the first case.

 Now, let us determine the normal cone at $\curr$. %Thanks to this hypothesis and 
 Since $\curr$ belongs to $\ball_\radius^{\points}(\sol)$, no other constraint other than the ones corresponding to $\coords$ can become active, and these constraints are actually active by the definition of $\coords$ and \cref{eq:propertynonsteep}. Hence, the normal cone at $\curr$ (see \cref{eq:ncone-sharp}) becomes%\FI{W: Say why we have $ \coords$ and not $\actcoords$}\WA{Too much now or is it ok?}
\begin{align}
	\ncone(\curr) &= \left\{-\sum_{\coord \in \coords} \slack_{\coord} \bvec_{\coord} : (\slack_{\coord})_{\coord \in \coords} \in (\R_+)^{\coords}\right\} + \row(\mat)\,,
\end{align}
and taking a scalar product between the last inclusion of \cref{lem:mirror} and $\pvec$, we get that,
\begin{align}
	\inner*{ \subsel\hreg(\curr) - \subsel\hreg(\prev) - \step \beforelead[\signal]}{\pvec} = 0\,.
\end{align}
This means that,
\begin{align}
	\step\inner{\vecfield(\sol)}{\pvec} &=
	\inner*{ \subsel\hreg(\curr) - \subsel\hreg(\prev)}{\pvec} + \step\inner{\vecfield(\sol) - \step \beforelead[\signal]}{\pvec}
	\leq
	\frac{2\step \drift}{3}\label{eq:proof-sharp-eucl-final-ineq}\,
\end{align}
 where the last inequality comes from our definition of $\ball_\radius^{\points}(\sol)$.
However, by \eqref{eq:slacks} and the properties of $\pvec$, we also have %\FI{W: Say why we have $\actcoords \setminus \coords$ and not $\actcoords$}\WA{Is it enough?}
\begin{align}
	\inner{\vecfield(\sol)}{\pvec} &=
	\sum_{\coord \in \actcoords \setminus \coords} \slack_{\coord} \pvec_{\coord} \geq \drift\,
\end{align}
%since $\coords_{\sharp} \subsetneq \sharps$.
which is in contradiction with \eqref{eq:proof-sharp-eucl-final-ineq}.
We may therefore iteratively add coordinates of $\actcoords$ for which $ \state_{\coord,\run} = 0$, which completes the induction and our proof.
\end{proof}
