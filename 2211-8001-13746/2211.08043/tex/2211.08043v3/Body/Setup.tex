%----------------------------------------------------------------------
%% SETUP
%----------------------------------------------------------------------
% !TEX root = ../Main.tex


In the rest of our paper
$\pspace$ will denote an $\nCoords$-dimensional real space with norm $\norm{\cdot}$
and
$\points$ will be a closed convex subset thereof.
We will also write
$\dpoints \defeq \dspace$ for the dual of $\pspace$,
$\braket{\dpoint}{\point}$ for the canonical pairing between $\dpoint\in\dpoints$ and $\point\in\pspace$,
and
$\dnorm{\dpoint} \defeq \max \setdef{\braket{\dpoint}{\point}}{\norm{\point}\leq 1}$ for the induced dual norm on $\dpoints$.


%----------------------------------------------------------------------
%% ASSUMPTIONS
%----------------------------------------------------------------------
\subsection{Blanket assumptions}

Throughout the sequel, we will make the following assumptions for the defining vector field $\vecfield\from\points\to\dpoints$ of \eqref{eq:VI} and the solution $\sol\in\points$ under study:

\begin{assumption}
[Lipschitz continuity]
\label{asm:Lipschitz}
The vector field $\vecfield$ is \emph{$\lips$-Lipschitz continuous}, \ie
\begin{equation}
\label{eq:Lipschitz}
\tag{LC}
\dnorm{\vecfield(\pointalt) - \vecfield(\point)}
	\leq \lips \norm{\pointalt - \point}
	\quad
	\text{for all $\point,\pointalt\in\points$}.
\end{equation}
\end{assumption}

\begin{assumption}
[Second-order sufficiency]
\label{asm:strong}
There exists
a convex neighborhood $\basin$ of $\sol$ in $\points$
and
a positive constant $\strong > 0$
such that
\begin{equation}
\label{eq:strong}
\tag{SOS}
\braket{\vecfield(\point) - \vecfield(\sol)}{\point - \sol}
	\geq \strong \norm{\point - \sol}^{2}
	\quad
	\text{for all $\point\in\basin$}.
\end{equation}
\end{assumption}

In general, \Cref{asm:strong} guarantees that $\sol$ is the unique solution of \eqref{eq:VI} in $\basin$;
we illustrate this in two special cases of interest:
\begin{enumerate}
\item
\emph{Minimization problems:}
suppose that $\vecfield = \nabla\obj$ for some Lipschitz smooth objective function $\obj$ on $\points$.
Then, \cref{asm:strong} implies that $\obj$ grows (at least) quadratically along every ray emanating from $\sol$, \ie $\obj(\point) - \obj(\sol) \geq \braket{\subsel\obj(\sol)}{\point - \sol} + (\strong/2) \norm{\point - \sol}^{2} = \Omega(\norm{\point-\sol}^{2})$ for all $\point\in\basin$, implying in particular that $\sol$ is an isolated minimizer of $\obj$.
\item
\emph{Min-max problems:}
suppose that $\points$ factorizes as $\points = \minvars\times\maxvars$ for suitable factor sets $\minvars$, and $\maxvars$,
let $\minmax\from\points\to\R$ be a smooth function on $\points$,
and
write $\vecfield = (\nabla_{\minvar}\minmax,-\nabla_{\maxvar}\minmax)$ for the min-max gradient of $\minmax$ (with respect to $\minvar\in\minvars$ and $\maxvar\in\maxvars$ respectively).
Then, any solution $\sol = (\minsol,\maxsol)$ of \eqref{eq:VI} that satisfies \cref{asm:strong} enjoys the local growth bounds $\minmax(\minvar,\maxsol) - \minmax(\minsol,\maxsol) = \Omega(\norm{\minvar - \minsol}^{2})$ and $\minmax(\minsol,\maxsol) - \minmax(\minsol,\maxvar) = \Omega(\norm{\maxvar - \maxsol}^{2})$, implying in turn that $\sol$ is an isolated, hyperbolic saddle-point of $\minmax$.
\end{enumerate}
More examples satisfying \eqref{eq:strong} include strict \aclp{NE} in finite games \cite{FT91}, deterministic Nash policies in (generic) stochastic games \cite{SV15}, etc.
Overall, \cref{asm:Lipschitz,asm:strong} apply to a very wide range of problems, so we will treat them as blanket assumptions throughout.


%----------------------------------------------------------------------
%% METHOD
%----------------------------------------------------------------------
\subsection{\acl{BP} methods}
\label{subsec:BP_methods}

As we discussed in the introduction, the main algorithmic template that we will examine for solving \eqref{eq:VI} is a general class of first-order algorithms known as \acdefp{BPM}.
The defining ingredient of this class is the notion of \emph{Bregman regularizer}, which we define below as follows:

\begin{definition}
[Bregman regularizers and related notions]
\label{def:Bregman}
A proper, \acl{lsc}, strictly convex function $\hreg\from\pspace\to\R\cup\{\infty\}$ is a \emph{Bregman regularizer} on $\points$ if
the following are true
\begin{enumerate}
\item
$\hreg$ is supported on $\points$, \ie $\dom\hreg = \points$.
\item
The subdifferential of $\hreg$ admits a \emph{continuous selection}, \ie there exists a continuous mapping $\subsel\hreg\from\dom\subd\hreg\to\dpoints$ such that $\subsel\hreg(\point) \in \subd\hreg(\point)$ for all $\point\in\dom\subd\hreg$.
\item
$\hreg$ is \emph{locally strongly convex} relative to $\norm{\cdot}$, \ie for any compact set $\cpt \subseteq \dom \hreg$, we have
%there is some $\hstr > 0$ such that
%for all $\point\in \cpt \cap \dom\subd\hreg, \pointalt\in \cpt$, we have
\begin{equation}
\label{eq:hstr}
\hreg(\pointalt)
	\geq \hreg(\point)
		+ \braket{\subsel\hreg(\point)}{\pointalt - \point}
		+ \tfrac{\hstr}{2} \norm{\pointalt - \point}^{2}
%	\quad
%	\text{for all $\point\in \cpt \cap \dom\subd\hreg, \pointalt\in \cpt$}.
\end{equation}
for some $\hstr>0$ and for all $\point\in \cpt \cap \dom\subd\hreg$, $\pointalt\in \cpt$. 
\end{enumerate}
\noindent
%\WA{I don't know why there is so much space here now...}
%\PM{Welcome to the intricacies of \TeX :-)}
%\PM{The problem is that the item above was wrapped in a ``revise'' macro, which interferes with the equation wrapper (it adds a stop, and hence a linebreak).
%This is one of the reasons that I had introduced the beginrev and endedit commands (which don't have this problem and also don't interfere with Sync\TeX\ on longer tracts of text).
%I should have explained this, sorry\dots}
The set $\proxdom \defeq \dom\subd\hreg$ will be referred to as the \emph{prox-domain} of $\hreg$.
In addition, we also define the \emph{Bregman divergence} of $\hreg$ as
\begin{alignat}{2}
\label{eq:Breg}
\breg(\base,\point)
	&= \hreg(\base)
		- \hreg(\point)
		- \braket{\subsel\hreg(\point)}{\base - \point}
	&\qquad
	&\text{for all $\point\in\proxdom$, $\base\in\points$}
\intertext{and the induced \emph{prox-mapping} as}
\label{eq:prox}
\proxof{\point}{\dvec}
	&= \argmin\nolimits_{\pointalt\in\points} \{ \braket{\dvec}{\point - \pointalt} + \breg(\pointalt,\point) \}
	&\qquad
	&\text{for all $\point\in\proxdom$, $\dvec\in\dpoints$}.
\end{alignat}
\end{definition}

\begin{remark}
\label{rem:Bregman}
Examples of Bregman regularizers are given in \cref{sec:examples}, where we also take an in-depth look at their properties.
For our analysis and results, we will assume for convenience that $\hreg$ is $1$-strongly convex in a suitable neighborhood $\zone$ of $\sol$ which will be understood from the context;
this can always be achieved by rescaling $\hreg$, so there is no loss of generality.
To avoid technicalities, we will also tacitly assume that $\proxof{\point}{\dpoint}$ is well-defined whenever it is invoked (this is always the case if, for example, $\hreg$ is coercive or $\nabla\hreg$ is invertible).
\end{remark}

Given a Bregman regularizer on $\points$, the general class of \acdefp{BPM} that we will consider is defined via the generic recursion
\begin{equation}
\label{eq:BPM}
\tag{BPM}
\begin{aligned}
\lead
	= \proxof{\curr}{-\curr[\step]\curr[\signal]}
%	\\
	\qquad
\next
	= \proxof{\curr}{-\curr[\step]\lead[\signal]}
\end{aligned}
\end{equation}
where
\begin{enumerate*}
[(\itshape i\hspace*{1pt}\upshape)]
\item
$\run=\running$ denotes the method's iteration counter;
\item
$\curr[\step] > 0$ is a (non-increasing) step-size sequence;
\item
$\curr[\signal]$ and $\lead[\signal]$ are sequences of ``oracle signals'' that we discuss in detail below.
\end{enumerate*}
In terms of vocabulary, the iterates $\curr$, $\run=\running$, will be referred to as the ``\emph{base states}'' of the method, while the ``half-iterates'' $\lead$, $\run=\running$, will be referred to as the method's ``\emph{leading states}''.
Finally, in terms of initialization, we will take for convenience $\init = \state_{1/2}$.

Now, regarding the sequence of oracle signals $\curr[\signal]$ and $\lead[\signal]$ defining \eqref{eq:BPM}, we will assume throughout that
\begin{equation}
\label{eq:signal-lead}
\lead[\signal]
	= \vecfield(\lead)
	\qquad
	\text{for all $\run=\running$}
\end{equation}
\ie \eqref{eq:BPM} generates a new base state $\next$ by taking a Bregman proximal step from $\curr$ with oracle input from the leading state $\lead$.
By contrast, the leading state itself can be generated in a number of different ways from $\curr$, depending on the definition of $\curr[\signal]$:

\begin{assumption}
\label{asm:signal-base}
For all $\run=\running$, the oracle signal $\curr[\signal]$ is of the form:
\begin{equation}
\label{eq:signal-base}
\curr[\signal]
	= \coef[a] \vecfield(\curr)
		+ \coef[b] \vecfield(\beforelead)
\end{equation}
for some $\coef[a],\coef[b] \in [0,1]$ with
$\coef[a] + \coef[b] \leq 1$
and
$\coef[a] + \coef[b] = 1$ if $\coef[b]>0$.\footnote{Note that the requirement ``$\coef[a] + \coef[b] = 1$ if $\coef[b] > 0$'' is only intended to ease notation and does not lead to a loss in generality:
if $\coef[b] > 0$, we can always rescale $\curr[\step]$ by $\coef[a] + \coef[b]$ so the condition $\coef[a] + \coef[b] = 1$ is satisfied automatically.}
\end{assumption}

For concreteness, we illustrate below three archetypal Bregman methods that serve as the backbone of the above framework:

\begin{enumerate}
\setlength{\itemsep}{0pt}
\item
\Acli{MD}:
following \cite{NY83,BecTeb03,NJLS09}, the \acli{MD} algorithm proceeds recursively as $\new = \proxof{\point}{-\step\vecfield(\point)}$, so it can be recovered from \eqref{eq:BPM} by taking
\begin{alignat}{3}
\label{eq:MD}
\tag{MD}
\coef[a] = 0, \coef[b] = 0
	&\qquad
	\text{or, equivalently}
	&\qquad
\curr[\signal]
	&= 0
	&\quad
	\text{for all $\run=\running$}
\intertext{%
\item
\Acli{MP}:
following \cite{Nem04,JNT11}, the \acli{MP} algorithm corresponds to the choice}
\label{eq:MP}
\tag{MP}
\coef[a] = 1, \coef[b] = 0
	&\qquad
	\text{or, equivalently}
	&\qquad
\curr[\signal]
	&= \vecfield(\curr)
	&\quad
	\text{for all $\run=\running$}
\intertext{%
\item
\Acli{OMD}:
originally due to \cite{Pop80} (in the Euclidean case) and \cite{CYLM+12,RS13-NIPS} (for the general case), the \acli{OMD} algorithm is obtained by setting}
\label{eq:OMD}
\tag{OMD}
\coef[a] = 0, \coef[b] = 1
	&\qquad
	\text{or, equivalently}
	&\qquad
\curr[\signal]
	&= \vecfield(\beforelead)
	&\quad
	\text{for all $\run=\running$}
\end{alignat}
\end{enumerate}
These three algorithms are the most widely studied Bregman methods in the literature, so we will use them as running examples throughout.