%----------------------------------------------------------------------
%%% INTRODUCTION
%----------------------------------------------------------------------
% !TEX root = ../Main.tex


\Acp{BPM} have a long and rich history in optimization, going back at least to the introduction of \acl{MD} by Nemirovski \& Yudin \citep{NY83}.
In plain terms, \acp{BPM} are first-order (constrained) optimization algorithms that forego Euclidean projections in favor of a more sophisticated ``prox-mapping'' that minimizes a certain distance-like functional known as the Bregman divergence \citep{NY83,CT93,Bre67,Kiw97}.
When this Bregman divergence is the Euclidean distance squared, one recovers the standard projection-based methods;
other than that, depending on the problem's feasible region, different Bregman setups lead to a diverse collection of algorithms,
from exponentiated gradient descent on the simplex \citep{NY83,BecTeb03,ACBFS02},
to matrix multiplicative weights on the positive-semidefinite cone \cite{TRW05,KSST12},
variants of Karmarkar's affine scaling algorithm for linear programs \cite{VMF86},
etc.

One of the most appealing features of \acp{BPM} is that they achieve almost dimension-free convergence rates in problems with a convex structure and a favorable geometry \textendash\ such as the $L^{1}$ ball, the spectraplex, second-order cones, etc. \cite{Bub15,Nes09,BecTeb03}.
This is owed to a delicate interplay between the algorithms' non-Euclidean update scheme and the global geometry of the problem's domain.
However, these (almost) dimension-free guarantees also come with some strings attached:
they do not concern the sequence of iterates generated by the method, but only its time average
\revise{(or, through the same, ``regret-based'' analysis, the method's ``best iterate'')};
in this way, the best guarantee that can be achieved after $\run$ iterations is $\bigoh(1/\run)$.

In terms of oracle complexity, this is sufficient for problems that are not strongly convex\,/\,strongly monotone, but if one targets finer, geometric convergence rates,
\revise{the inherent averaging involved in regret-based guarantees is hard to compensate.}
And, on the other extreme, if the problem is not convex\,/\,monotone to begin with, iterate averaging does not provide any quantifiable benefits whatsoever, so it becomes crucial to study the actual trajectory of the method.


%----------------------------------------------------------------------
%%% CONTRIBS
%----------------------------------------------------------------------
\para{Our contributions}

Our paper seeks to quantify the last-iterate convergence rate of \aclp{BPM} as a function of the Bregman divergence defining the method and the local geometry that it induces.
To treat this question in as general a manner as possible, we focus on \ac{VI} problems of the form
\begin{equation}
\label{eq:VI}
\tag{VI}
\text{Find $\sol\in\points$ such that}
	\;\;
	\braket{\vecfield(\sol)}{\point - \sol}
	\geq 0
	\;\;
	\text{for all $\point\in\points$},
\end{equation}
where $\points$ is a closed convex subset of a finite-dimensional normed space $\pspace$, and $\vecfield \from \points \to \dspace$ is a (possibly non-monotone) single-valued operator on $\points$ with values in $\dspace$, the dual of $\pspace$.
This problem is a staple of many areas of mathematical programming, game theory and data science, as it provides a template for ``optimization beyond minimization'' \textendash\ \ie for problems where finding an optimal solution does not necessarily involve minimizing a loss function.
In particular, in addition to standard minimization problems \textendash\ which are recovered when $\vecfield = \nabla\obj$ for some smooth function $\obj$ \textendash\ the general formulation \eqref{eq:VI} includes saddle-point problems, games, complementarity problems, etc.;
for an introduction, see \cite{FP03} and references therein.

In this broad context, we examine the rate of convergence of a wide class of \aclp{BPM} to local solutions of \eqref{eq:VI} that satisfy a \acl{SOS} condition.
Specifically, the class of algorithms we consider includes as special cases
\begin{enumerate*}
[(\itshape i\hspace*{1pt}\upshape)]
\item
the original \acf{MD} algorithm of \cite{NY83};
\item
the \acf{MP} method of Nemirovski \cite{Nem04} \textendash\ which has the same update structure as the Bregman-based algorithm of \cite{AT05} and contains as a special case the \acf{EG} algorithm of \cite{Kor76};
\item
the so-called \acf{OMD} method of \cite{RS13-NIPS} \textendash\ itself a Bregman analogue of the modified Arrow-Hurwicz algorithm of \cite{Pop80};
\end{enumerate*}
etc.

Our first finding is a crisp characterization of last-iterate convergence rate of \acp{BPM} in terms of the local geometry induced by the underlying Bregman function near a given solution of \eqref{eq:VI}.
We make this dependence precise via the notion of the \emph{Legendre exponent}, a regularity measure for Bregman methods due to \cite{AIMM21}, which can roughly be described as the logarithmic ratio of the volume of a Euclidean ball to that of a Bregman ball of the same radius.
For example, Euclidean methods have a Legendre exponent of $\legexp = 0$ and they converge at a linear rate;
entropic methods have a Legendre exponent of $\legexp = 1/2$ at boundary points, and they converge at a rate of $\bigoh(\run^{-1})$;
more generally,
as we show in \cref{thm:general}, methods with a Legendre exponent $\legexp>0$ converge at a rate of $\bigoh(\run^{1-1/\legexp})$.
\PM{We need to fix this: the $1-1/\legexp$ exponent is not consistent with the $\bigoh(1/\run)$ expression.}
\WA{I don't see the issues, yes this expression is not well-defined for $\legexp = 0$ but this is normal, the two situations differ radically.}
The Euclidean regime ($\legexp = 0$) is perfectly aligned with existing results for the geometric last-iterate convergence rate of the \ac{EG} algorithm and its variants \citep{GBVV+19,Mal15,HIMM19,MOP20}.
By contrast, the Legendre regime ($\legexp > 0$) indicates a significant drop in the algorithm's last-iterate convergence speed, even though ergodic convergence rates \cite{Nes04} and results for bilinear games \cite{WLZL21} might suggest otherwise.

Subsequently, motivated by applications to game theory and linear programming, we take a closer look at the convergence rate of \acp{BPM} across the constraints that are active at a solution $\sol$ of \eqref{eq:VI} depending on the position of $\vecfield(\sol)$ relative to said constraints. 
This analysis reveals that Bregman proximal methods have a particularly fine structure:
along \emph{sharp directions} (\ie constraints along which $\vecfield(\sol)$ is strictly inward-pointing), \acp{BPM} converge
\begin{enumerate*}
[(\itshape i\hspace*{1pt}\upshape)]
\item
at a rate of $\bigoh(1/\run^{1/(2\legexp-1)})$ if $1/2 < \legexp < 1$;
\item
at a \emph{geometric rate} if $0 < \legexp \leq 1/2$ (\eg for entropic methods);
and
\item
in a \emph{finite} number of iterations if $\legexp=0$
\end{enumerate*}
(\cf \cref{thm:sharp}).
Thus, even though the estimates of \cref{thm:general} are, in general tight, the actual convergence rate of a Bregman method along different coordinates\,/\,constraints could be starkly different \textendash\ and, in fact, dramatically faster if the solution under study is itself sharp.

The closest antecedent of our work is the conference paper \cite{AIMM21} where the Legendre exponent was introduced to analyze the convergence of \ac{OMD} in \emph{stochastic} \ac{VI} problems (without considering sharp directions and/or faster identification rates).
The stochastic and deterministic settings are obviously very different, both in the challenges involved as well as the rates obtained, so there is no overlap in our analysis and results.
Other than that, we are not aware of any comparable results in the literature concerning the radically different convergence landscape of \acp{BPM} along active and inactive constraints.