%----------------------------------------------------------------------
%%% INTRODUCTION
%----------------------------------------------------------------------
% !TEX root = ../Main.tex


\Acp{BPM} have a long and rich history in optimization, going back at least to the introduction of the influential \acl{MD} algorithm by Nemirovski \& Yudin \citep{NY83}.
In plain terms, \acp{BPM} are first-order (constrained) optimization algorithms that forego Euclidean projections in favor of a more sophisticated ``prox-mapping'' that minimizes a certain distance-like functional known as the Bregman divergence \citep{NY83,CT93,Bre67,Kiw97}.
When this Bregman divergence is the Euclidean distance squared, one recovers the standard projection-based methods;
other than that, depending on the problem's feasible region, different Bregman setups lead to a diverse collection of algorithms,
from exponentially weighted gradient descent in the simplex \citep{NY83,BecTeb03,ACBFS02},
to matrix multiplicative weights on the positive-semidefinite cone \cite{TRW05,KSST12},
variants of Karmarkar's affine scaling algorithm for linear programs \cite{VMF86}, etc.

From an operational standpoint, one of the most appealing features of \acp{BPM} is that they achieve almost dimension-free convergence rates in problems with a convex structure and a favorable geometry \textendash\ such as the $L^{1}$ ball, the spectraplex, second-order cones, etc. \cite{Bub15,Nes09,BecTeb03}.
This is owed to a delicate interplay between the algorithms' non-Euclidean update scheme and the global geometry of the problem's domain. % \textendash\ more specifically, its ``Bregman radius'' \cite{Bub15}.
However, these (almost) dimension-free guarantees also come with some strings attached:
they do not concern the sequence of iterates generated by the method, but only its time average;
as a result, the best guarantee that can be achieved after $\run$ iterations is $\bigoh(1/\run)$.
In terms of oracle complexity, this is sufficient for problems that are not strongly convex\,/\,strongly monotone, but if one targets finer, geometric convergence rates, the lag induced by averaging cannot be compensated.
And, on the other extreme, if the problem is not convex\,/\,monotone to begin with, iterate averaging does not provide any quantifiable benefits whatsoever;
in this case, only the \emph{actual} iterates generated by the method can be used as candidate solutions.


%----------------------------------------------------------------------
%%% CONTRIBS
%----------------------------------------------------------------------
\para{Our contributions}

%In view of all this, 
In this context, our paper seeks to provide a precise characterization of the last-iterate convergence rate of \aclp{BPM}, as a function of the Bregman divergence defining the method and the local geometry that it induces.
To treat this question in as general a setting as possible, we focus throughout on \ac{VI} problems of the form
\begin{equation}
\label{eq:VI}
\tag{VI}
\text{Find $\sol\in\points$ such that}
	\;\;
	\braket{\vecfield(\sol)}{\point - \sol}
	\geq 0
	\;\;
	\text{for all $\point\in\points$},
\end{equation}
where $\points$ is a closed convex subset of a finite-dimensional normed space $\pspace$, and $\vecfield \from \points \to \dspace$ is a (possibly non-monotone) single-valued operator on $\points$ with values in $\dspace$, the dual of $\pspace$.
This problem is a staple of many areas of mathematical programming, game theory and data science, as it provides a template for ``optimization beyond minimization'' \textendash\ \ie for problems where finding an optimal solution does not necessarily involve minimizing a loss function.
%As a special case, if $\vecfield = \nabla\obj$ for some smooth function $\obj\from\points\to\R$, solving \eqref{eq:VI} is equivalent to finding the first-order stationary points of $\obj$.
In particular, in addition to standard minimization problems \textendash\ which are recovered when $\vecfield = \nabla\obj$ for some smooth function $\obj$ \textendash\ the general formulation \eqref{eq:VI} includes saddle-point problems, games, complementarity problems, etc.;
for an introduction, see \cite{FP03} and references therein.

In this broad context, we examine the rate of convergence of a wide class of \aclp{BPM} to local solutions of \eqref{eq:VI} that satisfy a \acl{SOS} condition.
%Specifically, the \ac{AMP} template includes as special cases the \acl{MP}, \acl{MD} and \acl{OMD} algorithms, so it provides a unified view of some of the most widely used \acp{BPM} in the literature.
Specifically, the class of algorithms we consider includes as special cases
\begin{enumerate*}
[(\itshape i\hspace*{1pt}\upshape)]
\item
the original \acf{MD} algorithm of \cite{NY83};
\item
the \acf{MP} method of Nemirovski \cite{Nes04} \textendash\ which has the same update structure as the Bregman-based algorithm of \cite{AT05} and contains as a special case the \acf{EG} algorithm of \cite{Kor76};
\item
the so-called \acf{OMD} method of \cite{RS13-NIPS} \textendash\ itself a Bregman analogue of the modified Arrow-Hurwicz algorithm of \cite{Pop80};
\end{enumerate*}
etc.

Our first finding is a crisp characterization of last-iterate convergence rate of \acp{BPM} in terms of the local geometry induced by the underlying Bregman function near a given solution of \eqref{eq:VI}.
We make this dependence precise via the notion of the \emph{Legendre exponent}, a regularity measure for Bregman methods due to \cite{AIMM21}, which can roughly be described as the logarithmic ratio of the volume of a Euclidean ball to that of a Bregman ball of the same radius. % and reference point (the solution in question).
%Our first finding is that the algorithm's rate of convergence depends sharply on the chosen Bregman regularizer (Euclidean, entropic, or other).
%We explicit this dependence using the notion of the \emph{Legendre exponent}, introduced in \cite{AIMM21},
%$\legexp\in[0,1]$,
%which can roughly be described as the logarithmic ratio of the volume of a %regular 
%ball centered at the solution %under study 
%to that of a Bregman ball of the same radius. %
%\footnote{This notion was first introduced in the conference paper \cite{AIMM21}, which can be seen as a precursor of our work.
% The paper \cite{AIMM21} deals with \emph{stochastic} \aclp{VI} (so there is no overlap with the results presented herein and the derived rates are naturally different), but the notion of the Legendre exponent plays a similar role in both works.}
For example, Euclidean methods have a Legendre exponent of $\legexp = 0$ and they converge at a linear rate;
%on the other hand,
entropic methods have a Legendre exponent of $\legexp = 1/2$ at boundary points, and they converge at a rate of $\bigoh(\run^{-1})$;
more generally,
as we show in \cref{thm:general}, methods with a Legendre exponent $\legexp>0$ converge at a rate of $\bigoh(\run^{1-1/\legexp})$.
%Then, as we show in \cref{thm:general}, Bregman methods converge at a geometric rate if $\legexp=0$, and at a rate of $\bigoh(\run^{1-1/\legexp})$ otherwise.
The Euclidean regime ($\legexp = 0$) is perfectly aligned with existing results for the geometric last-iterate convergence rate of the \ac{EG} algorithm and its variants \citep{GBVV+19,Mal15,HIMM19,MOP20}.
By contrast, the Legendre regime ($\legexp > 0$) indicates a significant drop in the algorithm's last-iterate convergence speed, even though ergodic convergence rates \cite{Nes04} and results for bilinear games \cite{WLZL21} might suggest otherwise.
\PM{Do we want to talk about error bound conditions at all? [I guess not, just checking\dots]}\FI{Would say no}
%For \emph{stochastic} \aclp{VI}, we used the Legendre exponent in \cite{AIMM21} 
%uses  notion of the Legendre exponent plays a similar role in both works.
%(so there is no overlap with the results presented herein and the derived rates are naturally different), but the notion of the Legendre exponent plays a similar role in both works.}
%average analysis of \cite{Nem04} might suggest otherwise. % (at least on the surface).
% The paper \cite{AIMM21} deals with \emph{stochastic} \aclp{VI} (so there is no overlap with the results presented herein and the derived rates are naturally different), but the notion of the Legendre exponent plays a similar role in both works.}


Subsequently, motivated by applications to game theory and linear programming, we take a closer look at the convergence rate of \acp{BPM} across the constraints that are active at a solution $\sol$ of \eqref{eq:VI} depending on the position of $\vecfield(\sol)$ relative to said constraints. 
% as a function of the constraints that are active at a solution $\sol$ of \eqref{eq:VI} and the position of $\vecfield(\sol)$ relative to said constraints.
This analysis reveals that Bregman proximal methods have a particularly fine structure:
%even though the rates mentioned above are, in general, tight,
along \emph{sharp directions} (\ie constraints along which $\vecfield(\sol)$ is strictly inward-pointing), \acp{BPM} converge
\begin{enumerate*}
[(\itshape i\hspace*{1pt}\upshape)]
\item
at a rate of $\bigoh(1/\run^{1/(2\legexp-1)})$ if $1/2 < \legexp < 1$;
\item
at a \emph{geometric rate} if $0 < \legexp \leq 1/2$ (\eg for entropic methods);
and
\item
in a \emph{finite} number of iterations if $\legexp=0$
\end{enumerate*}
(\cf \cref{thm:sharp}). % for a precise statement).
Thus, even though the estimates of \cref{thm:general} are in general tight, the actual rate of convergence of a Bregman method along different coordinates\,/\,constraints could be starkly different \textendash\ and, in fact, dramatically faster if the solution under study is itself sharp.
%We find this separation property particularly appealing, as it highlights the interplay between sharp and non-sharp directions:
%\cref{thm:general} describes the rate of convergence along the latter, while \cref{thm:sharp} estimates the speed along the former.\FI{I'm not so sure about this sentence, I guess it could be removed to be more direct but no strong opinion here}

%As far as we are aware, 
The closest antecedent of our work is the conference paper \cite{AIMM21} where the Legendre exponent was introduced to analyze the convergence of \ac{OMD} in \emph{stochastic} \ac{VI} problems (without considering sharp directions and/or faster identification rates).
The stochastic and deterministic settings are obviously very different, both in the challenges involved as well as the rates obtained, so there is no overlap in our analysis and results.
%(in particular, the rates obtained in the deterministic case are much faster than their stochastic counterpart).
Other than that, we are not aware of any comparable results in the literature concerning the radically different convergence landscape of \acp{BPM} along active and inactive constraints.