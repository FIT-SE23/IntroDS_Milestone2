\documentclass[11pt,reqno]{amsart}

\usepackage[utf8]{inputenc}
\usepackage[margin=1.25in]{geometry}
\parindent=.25in
\usepackage{hyperref}
\usepackage{appendix}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{stmaryrd} 
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathrsfs}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{Definition}[theorem]{Definition}
\newtheorem{Assumption}[theorem]{Assumption}
\newtheorem{remark}[theorem]{Remark}


\usepackage{biblatex} %Imports biblatex package
\addbibresource{sample.bib} %Import the bibliography file

\numberwithin{equation}{section}

\title[Ergodicity stochastic heat equation Hölder coefficient]{Exponential ergodicity of stochastic heat equations with Hölder coefficients}
\author{Yi HAN}
\address{Department of Pure Mathematics and Mathematical Statistics, University of Cambridge.
}
\email{yh482@cam.ac.uk}
\thanks{Supported by EPSRC grant EP/W524141/1.}


\begin{document}
\maketitle
\begin{abstract}
    We consider ergodicity of stochastic heat equations driven by space-time white noise in dimension one, whose drift and diffusion coefficients are merely Hölder continuous. We give a short proof that there exists a unique in law mild solution when the diffusion coefficient is $\beta$ - Hölder continuous for $\beta>\frac{3}{4}$ and uniformly nondegenerate, and that the drift is locally Hölder continuous. Due to non-smoothness of the  coefficients, it is hard to obtain Bismut-Elworthy-Li type estimates that are central to the strong Feller property and unique ergodicity in the Lipschitz case, and transforming the coordinates via solving a Kolmogorov equation also seems intractable. Instead, we construct a distance function $d$ which is locally contracting and that bounded subsets of the state space are small in the sense of Harris' ergodic theorem. The construction utilizes a generalized coupling technique introduced by Kulik and Scheutzow in Ann.Probab vol.48 No.6: 3041-3076, 2020 in the setting of stochastic delay equations. Assuming the existence of a suitable Lyapunov function, we prove existence of a spectral gap and that transition probabilities converge exponentially fast to the unique invariant measure. The same method can be applied when the SPDE has a Burgers type nonlinearity $(-A)^{1/2}F(X_t)$ or $\partial_x F(X_t)$, where $F$ is continuous and has linear growth. We prove existence of a unique in law mild solution when $F$ is locally $\zeta$-Höloder continuous for $\zeta>\frac{1}{2}$, and the other assumptions are the same as before. We then extend spectral gap and exponential ergodicity results to this case once we have a suitable Lyapunov function.
\end{abstract}


\section{Introduction}
We are interested in ergodicity of the stochastic heat equation
\begin{equation}\label{heatequation}
    dX_t=\Delta X_t dt+b(X_t)dt+\sigma(X_t)dW_t
\end{equation}
defined on the Hilbert space $L^2((0,1))$ with Dirichlet or Neumann boundary condition, and $W$ a cylindrical Wiener process on $L^2((0,1))$. A wide variety of more general SPDEs will also be considered in this paper, with the common feature that they have Hölder, but not Lipschitz, drift and diffusion coefficients. 

Let $H$ be a Hilbert space, which will be the state space of our stochastic evolution equation. Recall that a Markov semigroup $(\mathcal{P}_t)_{t\geq 0}$ on $H$ is said to satisfy  the strong Feller property if for any bounded measurable function $f$ on $H$, $\mathcal{P}_tf$ is a continuous function for any $t>0$. For the stochastic heat equation \eqref{heatequation}, when the coefficients $b$ and $\sigma$ are Lipschitz continuous and $\sigma$ is uniformly non-degenerate, \eqref{heatequation} is known  to satisfy the strong Feller property, see \cite{peszat1995strong}. We can further derive a Bismut-Elworthy-Li type estimate (see \cite{elworthy1994formulae}): for any bounded measurable function $f$ on $H$, we have
\begin{equation}
    \label{bismut-li}
|\mathcal{P}_tf(x)-\mathcal{P}_tf(y)|\leq C (t)\|f\|_\infty |x-y\|_H,\quad \text{for each }t>0,x,y\in H.\end{equation}
 Combined with a global boundedness condition, we can show that \eqref{heatequation} has a unique invariant measure (see for example \cite{da2014stochastic} ,Section 11.7.) Uniqueness of the invariant measure can also be verified via a coupling approach, see \cite{mueller1993coupling}, also under the Lipschitz assumptions on $b$ and $\sigma$.

With more refined estimates, we can often show that transition probabilities of the SPDE \eqref{heatequation} converge exponentially fast to its unique invariant measure. In such an argument, the strong Feller property in its \textit{qualitative} form is usually not enough, and \textit{quantitative} estimates involving the Bismut-Elworthy-Li formula \eqref{bismut-li} is necessary. Even for simgular stochastic PDEs like the dynamical $\phi_2^4$ model, establishing a quantitative estimate like \eqref{bismut-li} is still a critical step towards proving its exponential convergence to equilibrium, see \cite{tsatsoulis2018spectral}.

In this paper we are interested in stochastic heat equations \eqref{heatequation} with non-Lipschitz coefficients. Establishing the strong Feller property and Bismut-Elworthy-Li estimates become highly nontrivial for lack of smoothness. When $\sigma$ is the identity and $b$ is bounded continuous, the strong Feller property of \eqref{heatequation} was established in \cite{maslowski2000probabilistic} via a probabilistic method. However, the proof is only qualitative, and useful quantitative estimates like  \eqref{bismut-li} are not obtained.
When $\sigma$ is only Hölder continuous, even the well-posedness of  \eqref{heatequation} is a demanding question to be answered first, and the strong Feller property of \eqref{heatequation} (even with the drift $b=0$) does not seem to be well studied before.

To better explain the scope, we first discuss ergodicity of finite dimensional diffusion with irregular coefficients. Consider for example the SDE 
\begin{equation}dX_t=b(X_t)dt+\sigma(X_t)dW_t\label{sde1.3},\end{equation}
where $W$ is a $n$-dimensional Brownian motion, $b$ and $\sigma$ are $\mathbb{R}^n$-valued. We assume $b$ is bounded measurable (or satisfy some integrability conditions) and $\sigma$ is uniformly non-degenerate and Hölder continuous in the operator norm. In this finite dimensional setting, Zvonkin's transform \cite{zvonkin1974transformation} can be used to remove the singular drift and we can consider an equation with more regular coefficients. The strong Feller property and exponential ergodicity of \eqref{sde1.3} can be deduced if the transformed equation has these properties. It has been employed to derive exponential ergodicity results for a wide class of SDEs with irregular coefficients, see \cite{xie2020ergodicity}. The technique also extends to Lévy noise

For stochastic PDEs, however, Zvonkin's transform is not available anymore. In recent years there has been a few works on regularization by noise for the stochastic heat equation with additive noise, including \cite{butkovsky2019regularization} and \cite{athreya2020well}, but the arguments involved in these works are quite involved, and it seems rather difficult to be adapted to our setting to derive the strong Feller property. Moreover, they are hard to be adapted to the multiplicative noise case.

Our strategy is instead motivated by recent progress in ergodicity of the stochastic delay differential equation (SDDE) with finite memory. These equations have infinite dimensional state space, yet the Brownian motion only acts on a finite dimensional subspace, so that the strong Feller property fails in general. A major breakthrough in ergodicity of SDDEs is obtained by Hairer, Mattingly and Scheutzow in \cite{hairer2011asymptotic}, where they invented an asymptotic coupling strategy and developed a generalized form of Harris's theorem to establish exponential ergodicity of SDDEs with (one sided) Lipschitz coefficients and non-degenerate noise. Although the Lipschitz assumption is not necessary for the SDDE to be well-posed, it is still assumed in \cite{hairer2011asymptotic} to obtain unique ergodicity and exponential convergence. The Lipschitz assumption is finally removed in Kulik and Scheutzow \cite{kulik2020well} via a generalized coupling approach, only assuming that the diffusion coefficient satisfies a Hölder assumption and the drift satisfies a one-sided Hölder assumption. We will use this generalized coupling approach for a wide variety of stochastic PDES with space-time white noise.

Compared to the setting of stochastic delay equations, we do not have to work with a memory process $(X_t)_{-t_0\leq t\leq 0}$, which simplifies some of the presentations. However, we have to be careful when working with space-time white noise, and in particular we use the mild formulation of SPDEs instead of  Itô's formula in this paper.  Smoothing assumptions on the operator $A$ need to be specified, and the $\frac{3}{4}$-Hölder continuity of the diffusion coefficient $\sigma$ we obtain in the SPDE case (see Theorem \ref{theorem1.1}) is different from the $\frac{1}{2}$-Hölder results \cite{kulik2020well} for the delay equations. Moreover, we can consider a first order term $(-A)^{1/2}F(X_t)$ in the drift, thanks to the smoothing properties of the semigroup $S(t)$ generated by $A$. This is a purely SPDE phenomenon that has no SDE or SDDE analogue.



In this paper we exclusively work with \textbf{weak mild} solutions to  stochastic evolution equations on \textbf{a general Hilbert space $H$} driven by a cylindrical wiener process $W$,
\begin{equation}\label{conceptual}dX_t=A X_t dt+b(X_t)dt+\sigma(X_t)dW_t,\quad X_0=x\in H.\end{equation} In a word, this means the solution is probabilistically weak, and is given in the form of a mild solution in the PDE sense. More precisely, a \textit{weak mild} solution consists of a sequence $(\Omega,\mathcal{F},(\mathcal{F}_t),\mathbb{P},W,X)$, where $(\Omega,\mathcal{F},(\mathcal{F}_t),\mathbb{P})$ is a filtered probability space defining both a cylindrical wiener process $W$ and an $\mathcal{F}_t$-adapted, $H$-valued continuous process $(X_t)_{t\geq 0}$ such that they satisfy, $\mathbb{P}$-almost surely,
\begin{equation}\label{concepmild}X_t=S(t)x+\int_0^t S(t-s)b(X_s)ds+\int_0^t S(t-s)\sigma(X_s)dW_s,\end{equation} where $S(t)=e^{tA}$ is the semigroup generated by $A$ on $H$.
If we have a term $(-A)^{1/2}F(X_t)$ instead of the drift $b(X_t)$ in \eqref{conceptual}, then we have the corresponding term $$\int_0^t (-A)^{1/2}S(t-s)F(X_s)ds$$ in the mild formulation \eqref{concepmild}.


\subsection{Well-posedness of stochastic heat equation with Hölder coefficients}

Our well-posedness result is given as follows:

\begin{theorem}\label{theorem1.1}
Consider the evolution equation 
\begin{equation}\label{evolutionequation}
    dX_t=A X_t dt+b(X_t)dt+\sigma(X_t)dW_t,\quad X_0=x\in H
\end{equation}
on a Hilbert space $H$, where $W$ is a cylindrical Wiener process on $H$. Assume that

$\mathbf{H_1}$ The densely defined operator $A:\mathcal{D}(A)\subset H\to H$
is diagonalizable on $H$, with eigenfunctions $\{e_n\}_{n\geq 1}$ forming an orthonormal basis in $H$, such that the eigenvalues $$Ae_n=-\lambda_n e_n,\quad \lambda_n>0,$$ satisfy the summability condition: for each $\eta\in(0,\frac{1}{2}),$
$$\sum_{n\geq 1}\frac{1}{{{\lambda_n}^{1-\eta}}}<\infty.$$

Assume we are given some $M>0$ so that the coefficients $b$ and $\sigma$ satisfy

$\mathbf{H_2}$ For some $\alpha\in(0,1]$, 
$$\|b(x)-b(y)\|\leq M\|x-y\|^\alpha,\quad \|x-y\|\leq 1,$$



$\mathbf{H_3}$ For some $\beta\in(\frac{3}{4},1],$
$$\|\sigma(x)-\sigma(y)\|\leq M\|x-y\|^\beta,\quad \|x-y\|\leq 1,$$
where $\|\cdot\|$ also denotes the operator norm on $H$.

$\mathbf{H_4}$ for each $x\in H$, $\sigma(x)$ has a right inverse $\sigma(x)^{-1}$ that moreover satisfies: for some $C>0$,
$$\sup_{x\in H}\|\sigma(x)^{-1}\|\leq C<\infty.$$ 

$\mathbf{H_5}$ $b$ and $\sigma$ satisfy the linear growth assumption: for some $M>0$, 
$$\|b(x)\|\leq M(1+\|x\|), \quad \|\sigma(x)\|\leq M( 1+\|x\|).$$

Then there exists a unique weak mild solution to \eqref{evolutionequation}. The process $(X_t)_{t\geq 0}$ defines a time-homogeneous Markov process on $H$.
\end{theorem}

\begin{remark}
The assumption $\mathbf{H_1}$ is satisfied by the Laplacian on $L^2((0,\pi))$ with Dirichlet boundary condition, whose eigenvalues are $\lambda_n=n^2$. An extension to more general operators will be given in Theorem \ref{theorem1.4}. In standard SPDE literature, it is usually assumed that $A$ is symmetric and $A^{-1}$ is compact and trace-class, which implies that $Ae_n=\lambda_n e_n$ for an orthonormal basis $\{e_n\}_n$ of $H$ and that $\sum_n \frac{1}{\lambda_n}<\infty.$ We impose a stronger summability condiiton on $\frac{1}{\lambda_n}.$
\end{remark}


\subsection{Generalized coupling and exponential ergodicity}
We will establish exponential ergodicity via the generalized Harris theorem introduced in \cite{hairer2011asymptotic}, which consists of both local and global controls. On a global scale, we assume the existence of a Lyapunov function $V$ for the SHE \eqref{heatequation} that confines its dynamics from escaping too far from bounded components of $H$. On a local scale, we assume we can find a \textit{distance-like} function $d$ such that the dynamics of \eqref{heatequation} is contracting with respect to $d$ for sufficiently close initial values and that bounded sets are $d$-small.
Then exponential ergodicity is a direct corollary of the generalized Harris' theorem \cite{hairer2011asymptotic}.

We say a function $d:H\times H\to [0,1]$ is distance-like if it is symmetric, lower-semicontinuous and such that $d(x,y)=0$ implies $x=y$. We extend $d$ to a positive function $\mathcal{M}_1(H)\times\mathcal{M}_1(H)\to\mathbb{R}_+$, with $\mathcal{M}_1(H)$ the set of all Borel probability measures on $H$, by 
$$d(\mu,\nu)=\inf_{\pi\in\mathcal{C}(\mu,\nu)}\int_{H^2}d(x,y)\pi(dx,dy),$$
where $\mathcal{C}(\mu,\nu)$ consists of all the couplings of $\mu$ and $\nu$. This is nothing but the 1-Wasserstein distance when $d$ is a metric on $H$.

For a Markov operator $\mathcal{P}$ on $H$, we say a set $A\subset H$ is $d$-small if for some some $\epsilon>0,$
$$d(\mathcal{P}(x,\cdot),\mathcal{P}(y,\cdot))\leq 1-\epsilon$$
for any $x,y\in A$.


In this paper it is not hard to construct, for any $R>0$, a distance-like function $d$ on $H$ so that the unit ball $B(0,R)$ in $H$ is $d$-small. The difficult part is to find a $d$ that is contracting for the dynamics \eqref{heatequation} for sufficiently close initial values $x,y$. Inspired by \cite{kulik2020well}, we consider the distance function $$d_{N,\gamma}(x,y):=(N\|x-y\|^\gamma)\wedge 1,\quad N\geq 1,\gamma\in[0,1],$$
where $\|\cdot\|$ is the distance on the Hilbert space $H$. The constant $\gamma>0$ is chosen depending on the Hölder exponents of $b$ and $\sigma$, and the constant $N$ will be chosen sufficiently large.

Our main result is as follows:


\begin{theorem}\label{contractionmain}
 Assume all the assumptions of Theorem \ref{theorem1.1} are satisfied. For each $x\in H$ denote by $(X_t^x)_{t\geq 0}$ the solution to \eqref{evolutionequation} with initial value $x$. Then for any $D>0$ and $t>0$ we may find some $\gamma\in(0,1)$, some positive integer $N$, and some $\theta\in(0,1)$ such that 
\begin{equation}\label{22111}d_{N,\gamma}(\operatorname{Law}(X_t^x),\operatorname{Law}(X_t^y))\leq \theta  d_{N,\gamma}(x,y),\quad \text{ given }\|x\|\leq D,\|y|\leq D.\end{equation}
and 
\begin{equation}\label{22112}d_{N,\gamma}(\operatorname{Law}(X_t^x),\operatorname{Law}(X_t^y))\leq \theta  d_{N,\gamma}(x,y),\quad  \text{ given } d_{N,\gamma}(x,y)<1.\end{equation}

\end{theorem}

Assume further the existence of a Lyapunov function, we can show existence and uniqueness of the invariant measure and the existence of a spectral gap.


\begin{theorem}\label{harristheorem}
Assume the assumptions of Theorem \ref{theorem1.1} are satisfied. Denote by $\mathbb{E}_x$ the law of the solution $(X_t)_{t\geq 0}$ to \eqref{evolutionequation} with $X_0=x$, and denote by $(\mathcal{P}_t)_{t\geq 0}$ the Markov semigroup defined by $X$ on the Hilbert space $H$.

Assume that the following Lyapunov condition holds: for some $t_0>0$, 
\begin{equation}\label{lyapunov1}\mathbb{E}_x V(X_{t_0})-V(x)\leq -cV(x)+C_V,\quad x\in H,\end{equation}
here $V:H\to[1,+\infty)$ is a continuous Lyapunov function, the constants $c\in(0,1)$ and $C_V\in\mathbb{R}$ are fixed and independent of $x$. Assume further that $V(x)\to\infty$ as $\|x\|\to\infty$.


Then there exists a unique invariant measure $\pi$ for the Markov process $(X_t)_{\geq 0}$. Moreover, we have the following \textbf{spectral gap} result: we may find a function $\widetilde{d}:H\times H\to\mathbb{R}_+$, given by $$\widetilde{d}(x,y)=\sqrt{(1\wedge \|x-y\|^\gamma)(1+V(x)+V(y))},$$ where $\gamma\in(0,\alpha\wedge (4\beta -3)),$ and we may find some $t_*>0$, such that 
\begin{equation}\label{spectralgapfinal}\widetilde{d}(\mathcal{P}_{nt_*}\mu,\mathcal{P}_{nt_*}\nu)\leq 2^{-n}\widetilde{d}(\mu,\nu),\quad n\in\mathbb{N}_+\end{equation}
for any probability measures $\mu,\nu$ on $H$.
\end{theorem}


One can further prove that the transition probabilities converge exponentially fast to the invariant measure for any time $t\geq 0$. When we have a Lyapunov function of a weaker form, we can obtain subexponential or polynomial convergence rates. We outline these results in the following theorem, which is the SPDE analogue of Theorem 2.3 of \cite{kulik2020well}.



For any positive $\gamma\in(0,1]$ we set $$d_\gamma(x,y):=\|x-y\|^\gamma\wedge 1.$$ Given a measurable function $\phi:\mathbb{R}^+\to\mathbb{R}^+$, define as in \cite{kulik2020well} the functions 
$$\Phi(v)=\int_1^v \frac{dw}{\phi(w)},\quad r(t)=\phi(\Phi^{-1}(t)).$$


\begin{theorem}\label{theorem1.55}
    In the setting of Theorem \ref{harristheorem}, assume instead that we have the following Lyapunov condition: for some $t_0>0$,
    \begin{equation}\label{lyapunov2}
        \mathbb{E}_x V(X_{t_0})-V(x)\leq -\phi(V(x))+C_V,\quad x\in H,
    \end{equation}
    where $V:H\to [1,\infty)$ is a measurable Lyapunov function, the scalar function $\phi:\mathbb{R}^+\to\mathbb{R}^+$ is strictly increasing and concave, satisfying $\phi(\infty)=\infty.$ Assume moreover that $V(x)\to\infty$ as $\|x\|\to\infty$. 
    
    Then there exists a unique invariant measure $\pi$ for $(X_t)_{t\geq 0}$.
    For any $\gamma\in(0,1]$ and $\epsilon>0$ there exists $\xi>0,C>0$,$\epsilon\in(0,1)$ such that 
    \begin{equation}\label{ratefinal}
d_\gamma(\operatorname{Law}(X_t^x),\pi)\leq\frac{C}{r(\xi t)^{1-\epsilon}}\phi(V(x))^{1-\epsilon}.
    \end{equation}
    \end{theorem}

\begin{remark}
    Depending on the choice of $\phi$, various convergence rates can be obtained from Theorem \ref{theorem1.55}. We obtain exponential convergence rates if $\phi(v)=cv$, and in such cases $r(t)=ce^{ct}$. We obtain subexponential convergence rate if $\phi(v)=c(v+b)\log^{-\eta}(v+b)$ for $c>0,\eta>0$ and $b$ large enough, in which case $r(t)\geq c_0e^{c_1 t^{1/(1+\eta)}}$. We obtain polynomial convergence rates if $\phi(v)=cv^{-\epsilon}$, $c>0,\epsilon\in(0,1)$, in such cases $r(t)$ is a polynomial in $t$. See also \cite{douc2004practical}, Section 2, or \cite{butkovsky2014subgeometric} Theorem 3.3, or \cite{kulik2020well}, Remark 2.2 for more examples.
\end{remark}



\begin{remark}
There are not many works on  Lyapunov functionals for SPDEs driven by space-time white noise, despite their prevalence in finite dimensional setting. Nonetheless, in many simple yet important cases like
$$dX_t=(\Delta_\sigma-\lambda)X_t dt+b_1(X_t)dt+\sigma(X_t)dW_t,$$ where $\Delta_\sigma$ is the Laplacian, $\lambda>0$, $b_1$ is bounded and Hölder continuous, and $\sigma$ is bounded Hölder and nondegenerate, existence of a Lyapunov functional can easily be verified by hand, for example one can take $V(x)=\|x\|+1,x\in H$. Even existence and uniqueness of invariant measures for these simple examples appear to be new in the literature.
\end{remark}



\subsection{More general operators}
The assumption $\mathbf{H}_1$ on the operator $A$ covers the Laplacian operator on compact domains of $\mathbb{R}$ with prescribed boundary conditions, but excludes some more general operators on $H$. In this section we explore these general cases and prove well-posedness and ergodicity results in exactly the same manner.


The main result is as follows:

\begin{theorem}\label{theorem1.4}
Consider the  evolution equation \eqref{evolutionequation} on $H$. Assume that


    $\mathbf{H}_1'$: the densely defined operator $A:\mathcal{D}(A)\subset H\to H$ is diagonalizable on $H$, whose eigenfunctions $\{e_n\}_{n\geq 1}$ form an orthonormal basis of $H$, and $Ae_n=-\lambda_n e_n$, $\lambda_n>0$ for each $n$.
    
    
    There exists some $\eta_0\in(0,1)$ such that the eigenvalues $\lambda_n$ of $A$ satisfy the summability condition: for each $\eta\in(0,\eta_0)$,
    $$\sum_{n\geq 1}\frac{1}{\lambda_n^{1-\eta}}<\infty,$$ 
    and
    $\mathbf{H}_3'$: For some $M>0$ and $\beta\in(1-\frac{\eta_0}{2},1],$  where $\eta_0$ is defined in  $\mathbf{H}_1'$, we have
   $$\|\sigma(x)-\sigma(y)\|\leq M\|x-y\|^\beta,\quad \|x-y\|\leq 1,\quad x,y\in H.$$

    Assume also that $\mathbf{H}_2$,  $\mathbf{H}_4$ and $\mathbf{H_5}$ hold. Then the conclusion of Theorem \ref{theorem1.1}, Theorem \ref{contractionmain}, Theorem \ref{harristheorem} and Theorem \ref{theorem1.55} also hold.

\end{theorem}
The assumption $\mathbf{H}_1'$ covers for example the bilaplacian operator $$A=-\Delta_\sigma^2,$$ where $\Delta_\sigma$ is the Laplacian operator with Neumann boundary condition on a bounded open set $G\subset\mathbb{R}^d$, $d=1,2,3.$ Well-posedness results for SPDEs with the bilaplacian operator $\Delta_\sigma^2$ and  Hölder diffusion coefficients seem to be new in the literature


\subsection{Buregers type nonlinearity}
Now we show that the results we obtain basically carry over when we have a drift of Burgers type $(-A)^{1/2}F(X_t)$.

\begin{theorem}\label{burgerstheorem1}
    Consider the evolution equation
\begin{equation}\label{burgersequation}
dX_t=AX_t dt+b(X_t)dt+(-A)^{1/2}F(X_t)dt+\sigma(X_t)dW_t,\quad X_0=x\in H\end{equation}
    on a Hilbert space $H$, where $W$ is a space-time white noise on $H$. 
    
    Assume that the operator $A$ satisfies $\mathbf{H}_1'$, the drift $b$ satisfies $\mathbf{H}_2$, the diffucion coefficient $\sigma$ satisfies $\mathbf{H}_3'$, and that assumptions $\mathbf{H}_4$ and $\mathbf{H}_5$ are satisfied as well. Assume moreover that

    $\mathbf{H}_6$. For some $\zeta\in(\frac{1}{2},1]$ and $M>0$, 
    $$\|F(x)-F(y)\|\leq M\|x-y\|^\zeta,\quad \|x-y\|\leq 1,$$ and that $$\|F(x)\|\leq M(1+\|x\|),\quad x\in H.$$

    Then there exists a unique weak mild solution to \eqref{burgersequation}. The process $(X_t)_{t\geq 0}$ defines a time-homogeneous Markov process on $H$.
\end{theorem}

\begin{remark}
    In the additive noise case $\sigma=I_d$ and $b=0$, existence of a weak mild solution was proven in \cite{priola2021optimal} for all $\zeta\in(0,1]$ via an optimal regularity result for the Kolmogorov equation. However that argunent does not carry over to multiplicative noise. Our method can deal with diffusion coefficients that are merely Hölder continuous, and we can study ergodicity of \eqref{burgersequation}, at the loss of restricting ourselves to the more regular regime $\zeta\in(\frac{1}{2},1].$

    In equation \ref{burgersequation} we may as well consider a drift of the form $(-A)^\omega F(X_t)$ for any $\omega\in(0,1)$. The proof is completely analogous, yet the assumption $\mathbf{H}_6$ will slightly change depending on the value of $\omega$.
\end{remark}

Typical examples of SPDEs that fall within \eqref{burgersequation} are Burgers type equations \footnote{Let $A$ be the Laplacian on $(0,2\pi).$ Setting $F=\frac{\partial}{\partial\xi}(-A)^{-1/2}h$ in \eqref{burgersequation} transforms \eqref{burgersequation} to this equation, and a direct computation shows that $\frac{\partial}{\partial\xi}(-A)^{-1/2}$ is a bounded operator on $L^2((0,2\pi))$. See \cite{prato2003new}, Remark 4.3 and Example 4.4 for related computations.}
\begin{equation}\label{exbur}du(t,\xi)=\frac{\partial^2}{\partial\xi^2}u(t,\xi)dt+\frac{\partial}{\partial \xi} h(u(t,\xi))dt+\sigma(u(t,\xi))dW_t(\xi),u(0,\xi)=u_0(\xi),\quad \xi\in(0,2\pi),\end{equation}
and the Cahn-Hilliard equations with stochastic forcing
\begin{equation}\label{exlug}du(t,\xi)=-\Delta_\xi^2 u(t,\xi)dt+\Delta_\xi h(u(t,\xi))dt+\sigma(u(t,\xi))dW_t(\xi),u(0,\xi)=u_0(\xi) \text{ on } G,\end{equation}
given some open, regular bounded set $G\subset\mathbb{R}^3$.

For spectral gap and exponential ergodicity, we have:

\begin{theorem}\label{burgerstheorem2}
    Assume that all the assumptions of Theorem \ref{burgerstheorem1} are satisfied. Then the conclusions of Theorem \ref{contractionmain}, \ref{harristheorem} and \ref{theorem1.55} are true as well. That is, for any $t>0$ and $D>0$ we can find a distance $d_{N,\gamma}$ such that \eqref{22111} and \eqref{22112} are satisfied, and given a suitable Lyapunov function satisfying \eqref{lyapunov1} or \eqref{lyapunov2}, we can deduce the spectral gap result \eqref{spectralgapfinal} or the convergence rate \eqref{ratefinal} respectively.
\end{theorem}
A simple example where all these assumptions are satisfied is 
$$dX_t=A X_t dt -\lambda X_t dt+(-A)^{1/2}F(X_t)dt+\sigma(X_t)dW_t,$$ where $\lambda>0$, $F$ is bounded and satisfies $\mathbf{H}_6$, $\sigma$ is bounded, uniformly non-degenerate and satisfies $\mathbf{H}_3'$. The Lyapunov function can be chosen as $V(x):=\|x\|+1.$


\subsection{Discussion and a review of related literature}


\subsubsection{Stochastic heat equation with Hölder coefficients}

The existence of a martingale solution to a general stochastic evolution equation 
$$
    dX_t=A X_t dt+b(X_t)dt+\sigma(X_t)dW_t,\quad X_0=x\in H
$$
is classical. Assuming the linear growth assumption $\mathbf{H_5}$, and that $b$ and $\sigma$ are continuous, and that for some $\eta>0,$
\begin{equation}\label{usual1}\int_0^1 t^{-2\eta}\|S(t)\|_2^2 dt<\infty,\end{equation}
a proof of existence can be found for example in \cite{gkatarek1994weak}.

The uniqueness part is much harder, and a Lipschitz assumption on $\sigma$ is usually imposed, see for example the  strong well-posedness result \cite{bally1994white} for stochastic heat equation with measurable drift of linear growth, and a Lipschitz diffusion coefficient. Another stream of research concerns the one dimensional super-Brownian motion
\begin{equation}
    \label{superspde}
dX_t=\frac{1}{2}\Delta X_t dt+\sqrt{X_t}dW_t,\end{equation} see \cite{konno1988stochastic} and \cite{reimers1989one},
whose weak uniqueness are established by different methods and cannot be carried over to general Hölder continuous diffusion coefficients. This SPDE \eqref{superspde} does not satisfy our non-degeneracy assumption $\mathbf{H_4}$, whereas the well-posedness and ergodicity results of this paper rely heavily on $\mathbf{H_4}$. For SPDE literature working under the non-degeneracy assumption $\mathbf{H_4}$ and Hölder diffusion coefficients, we mention an analytic approach introduced in \cite{zambotti2000analytic}, where the diffusion coefficient should be some bounded Hölder-continuous trace class perturbation of the identity operator, and \cite{athreya2006infinite} who worked instead with a fixed basis and assumed extra off-diagonal summability conditions. In the additive noise case, \cite{priola2021optimal} also considered a drift of the form $(-A)^{1/2}F$ with $F$ locally Hölder continuous.


The well-posedness results in the literature closest to our Theorem \ref{theorem1.1} is Mytnik and Perkins \cite{mytnik2011pathwise}. The authors obtained pathwise uniqueness for stochastic heat equation on the real line, with diffusion coefficient $\sigma$ to be $\beta$-Hölder continuous for $\beta>\frac{3}{4}$, and the drift $b$ to be Lipschitz. The non-degeneracy assumption $\mathbf{H_4}$ is not assumed in \cite{mytnik2011pathwise}. Then in \cite{mueller2014nonuniqueness} the $\frac{3}{4}$ threshold is shown to be sharp by providing non-uniqueness examples where the diffusion coefficient $\sigma$ is $\beta<\frac{3}{4}$-Hölder. Even uniqueness in law is violated. In this paper, we obtain weak uniqueness in the same range $\beta\in (\frac{3}{4},1]$ and the drift Hölder continuous as well, under the non-degeneracy assumption $\mathbf{H_4}$.


Although we do not establish strong uniqueness, and we are essentially working on a bounded domain in $\mathbb{R}^1$ (by the assumption $\mathbf{H}_1$) rather than the real line, our proof has the benefit of being much shorter than that in \cite{mytnik2011pathwise}, and we do not use the explicit form of Gaussian densities and heat kernel estimates. As a result, our proof can be easily generalized (see Theorem \ref{theorem1.4}) to other operators $A$ including the bilaplacian $A=\Delta_\sigma^2$, and we can further consider stochastic PDEs defined on domains of $\mathbb{R}^n$, $n\geq 2$ if the operator $A$ has rich smoothing properties.


From a regularization by noise perspective, the assumption $\mathbf{H_4}$ we assume is necessary if we wish to have a non-Lipschitz drift $b$. It is also necessary for us to obtain unique ergodicity of the stochastic evolution equation. Whilst $\beta=\frac{3}{4}$ is shown to be a threshold for (weak and strong) uniqueness in \cite{mueller2014nonuniqueness}, it is not clear if $\beta=\frac{3}{4}$ is also a threshold for weak uniqueness under the non-degeneracy assumption $\mathbf{H}_4$, or if less regular diffusion coefficients in a general form can guarantee uniqueness if they are uniformly non-degenerate.



\subsubsection{ Ergodicity of stochastic PDEs}

Ergodicity in infinite dimensions has received a lot of attention in the past three decades (see for example the monograph \cite{da1996ergodicity}). The case of stochastic PDEs with degenerate noise has received a lot of attention, see for example the work on 2D Navier Stokes equations \cite{hairer2006ergodicity} and a general framework \cite{hairer2011theory}. These works used Malliavin calculus to compute the first and second variations of the process. From these calculations we can obtain detailed information of the stochastic system on fairly small scales, so that we can obtain unique ergodicity even when the noise is highly degenerate \cite{hairer2006ergodicity}.  The asymptotic coupling approach \cite{hairer2002exponential} is also used these works as a toolbox to obtain unique ergodicity as the strong Feller property is absent. 


In the case of stochastic delay equations, the asymptotic coupling approach and a generalized version of Harris theorem (see \cite{hairer2011asymptotic}) provided a satisfying answer to the problem of characterizing unique ergodicity for stochastic delay equations, even if Malliavin calculus is not available anymore. In all these papers the coefficients of the SPDE are locally Lipschitz continuous (in some cases we may consider one-side Lipschitz, or monotone, or dissipative coefficients). We mention also some recent works with  Lévy driving noise \cite{wang2022irreducibility}.

For SDEs and SPDEs with irregular coefficients, the finite dimensional case can be dealt with via Zvonkin's transform \cite{xie2020ergodicity}. For stochastic delay equations with Hölder coefficients, we mention the work of Kulik and Scheutzow \cite{kulik2020well} who introduced a generalized coupling approach. Not much is known about unique ergodicity and weak ergodic rates for stochastic PDEs with non-Lipschitz coefficients and driven by cylindrical noise, in particular if the diffusion coefficient $\sigma$ is merely Hölder continuous. We aim to fill this gap in this paper.


\subsubsection{SPDEs with Burgers type nonlinearity}
The classical Burgers equation (\eqref{exbur} with $F(u)=u^2$) is not covered by Theorem \ref{burgerstheorem1}. See \cite{gyongy1998existence}, \cite{rockner2006kolmogorov} and \cite{prato2003new} for more well-posedness results. However, it is pointed out in \cite{priola2021optimal} that Hölder perturbations of the stochastic Burgers equation can be considered, once existence of a solution is known. This also applies to techniques in our paper, as we only need the coefficients to be locally Hölder continuous for our estimates to work. For irregular coefficients $F$, weak well-posedness was established in \cite{prato2003new} under a smallness condition on $H$, and in \cite{priola2022correction} this smallness assumption is removed. We restrict ourselves to regularity $\zeta\in(\frac{1}{2},1]$ but allow for multiplicative noise with merely Hölder diffusion coefficients. If we choose $F$ to be the identity on $H$, we recover the transport type SPDE with drift term $\frac{\partial}{\partial\xi}u(t,\xi).$
For the Cahn-Hilliard equation \eqref{exlug}, likewise we rule out the classical case $F(u)=u^3-u$. We mention \cite{da1996stochastic}, \cite{elezovic1991stochastic} and \cite{es2009maximal} for more on the Cahn-Hilliard equation. 


\subsubsection{Assumptions on the semigroup}

The assumption $\mathbf{H}_1$ is used in the proof of Proposition \ref{stochasticinte}, and can be replaced by other assumptions that lead to the same conclusion. A possible replacement is \begin{equation}\label{special}\int_0^t \|S(s)\|^{\eta}_2ds<\infty,\quad \text{for all }0<\eta<4,\end{equation} then we can apply Hölder's inequality in the estimate \eqref{summabilityfinal} to derive the same upper bound. However, this assumption \eqref{special} seems difficult to verify in practice.

The assumption $\mathbf{H}_1$ implies \eqref{usual1}, which is a commonly made assumption in the SPDE literature that guarantees well-posedness and sample path continuity of the solution (see \cite{da2014stochastic},Theorem 7.5). It further implies the (very weak) assumption \begin{equation}
    \label{weakest}
\int_0^1 \|S(s)\|_2^2ds<\infty.\end{equation} This last assumption is enough to guarantee well-posedness of mild solutions when coefficients are Lipschitz (see also \cite{da2014stochastic}, Theorem 7.5), but is otherwise so weak that we cannot apply our  method to deduce any well-posedness or ergodicity results in the Hölder case. 

In Theorem \ref{theorem1.4} we interpolate between the strong assumption $\mathbf{H}_1$ and the weak assumption \eqref{weakest} by introducing the new assumption $\mathbf{H}_1'$. We can obtain well-posedness and exponential ergodicity in all these intermediate cases, as well as cases where a stronger assumption than $\mathbf{H}_1$ is imposed.

From the results of Theorem \ref{burgerstheorem1}, we can see that the summability index $\eta_0$ in $\mathbf{H}_1'$ only affects the diffusion coefficient $\sigma$ but otherwise has no impact on the regularity of the two drifts $b$ and $F$. We conclude that irregularity of the diffusion coefficient $\sigma$ is much more dangerous to handle, compared to the irregularity of the drifts $b$ and $F$.


\section{Well-posedness of weak mild solutions}

\subsection{Preliminaries}

We begin with a deviation estimate for stochastic integrals in the white noise case. This result is fundamental  for all the other proofs of this paper.

\begin{proposition}\label{stochasticinte}
Consider the stochastic integral $$Z(t)=e^{-\lambda t}\int_0^t S(t-s)e^{\lambda s}\phi(s)dW_s,$$
where the semigroup $S(t)$ is generated by an operator $A$ satisfying $\mathbf{H}_1$ and $\lambda>0$ is some fixed constant. Assume that for some constant $\phi_\infty>0$ we have $$\sup_{t\in[0,T]}\|\phi(t)\|<\phi_\infty$$ almost surely. Then for each positive integer $m\in\mathbb{N}_+$ and each $\eta\in(0,\frac{1}{2})$ we may find a constant $C_{m,\eta}>0$ such that 
\begin{equation}\label{1/4conclude}\mathbb{P}(\sup_{t\in[0,T]}\|Z(t)\|\geq C_{m,\eta}\lambda^{-\frac{1}{2}\eta}\|\phi\|_\infty R)\leq \frac{C_{m,\eta}}{R^m},\quad R>0.\end{equation}

\end{proposition}


\begin{proof}
We use the following infinite dimensional BDG inequality (see for example Theorem 4.37 of \cite{da2014stochastic}): for any $p\geq 2$ there exists $C_p>0$ such that for every $t\geq 0$,
\begin{equation}\label{BDG}\mathbb{E}\sup_{s\in[0,t]}\left|\int_0^s \Phi(r)dW(r)\right|^p\leq C_p\left[\int_0^t (\mathbb{E}[\|\Phi(s)\|_2]^p)^{2/p}ds\right]^{p/2},\end{equation}  where $\|\cdot\|_2$ denotes the Hilbert-Schmide norm on $H$.

With the choice $\Phi(s)=S(t-s)e^{\lambda s}\phi(s)$, $\|\Phi(s)\|_2$ is bounded almost surely by $$\|S(t-s)\|_2e^{\lambda s}\|\phi\|_\infty.$$ 


Therefore we must compute
\begin{equation}\label{summabilityfinal}
\begin{aligned}&\int_0^t \|S(t-s)\|_2^2 e^{2\lambda s}\|ds\\=&\int_0^t\sum_{n\geq 1}e^{-2\lambda_n(t-s)+2\lambda s}ds\leq e^{2\lambda t}\sum_{n\geq 1}\frac{1}{2(\lambda_n+\lambda)}. 
\end{aligned}\end{equation}

Now we use Young's product inequality\footnote{which says for $a,b\geq 0$, and $p,q>1$ such that $\frac{1}{p}+\frac{1}{q}=1$, we have $$ab\leq \frac{a^p}{p}+\frac{b^q}{q}$$} for the sum $\lambda_n+\lambda$. For any $\eta\in(0,\frac{1}{2})$ we may find some universal constant $C_\eta>0$ depending only on $\eta$, such that 
$$\lambda_n+\lambda\geq C_\eta {(\lambda_n})^{1-\eta}\lambda^{\eta},$$ so that the right hand side of \eqref{summabilityfinal}can be bounded by, modulo some universal constant,
$$e^{2\lambda t}\lambda^{-\eta}\sum_{n\geq 1}\frac{1}{(\lambda_n)^{1-\eta}}.$$

The sum is finite by the summability assumption in $\mathbf{H_1}$. We
deduce that the right hand side of \eqref{BDG} is bounded by, modulo some universal constant $C_{p,\eta}$, $$e^{\lambda p t}\|\phi\|_\infty^p\lambda^{-\frac{p\eta}{2}}.$$


The proof of Proposition \ref{stochasticinte} finishes by applying Chebyshev's inequality.
\end{proof}


We will also use the following proposition, whose proof is deferred to Appendix \ref{appendixA}.
\begin{proposition}\label{proposition1.2} Fix $T>0$ and consider the stochastic evolution equation \eqref{evolutionequation} satisfying the assumptions of Theorem \ref{theorem1.1}.
For any $\epsilon>0$, we can find a compact subset $K\subset H$ such that 
$\mathbb{P}(\theta_K\leq T)<\epsilon,$ where $\theta_K:=\inf\{t\geq 0:X_t\notin K\}.$
\end{proposition}

Finally we provide an estimate 
that follows from Girsanov transform, which is an analogue of Proposition 3.2 of \cite{kulik2020well} in the SPDE setting. 

\begin{proposition}\label{proposition2.3}
Consider $X_t$ that solves the SPDE \eqref{evolutionequation} under the assumption of Theorem \ref{theorem1.1}, and consider another SPDE 
\begin{equation}\label{girsanov!}dY_t=AY_t dt+b(Y_t)dt+\lambda \phi_t 1_{t\leq\tau} dt+\sigma(Y_t)dW_t,\quad Y_0=x\in H,\end{equation}
where $\tau$ is a stopping time and $(\phi_t)_{t\geq 0}$ is an adapted process such that \eqref{girsanov!} has a unique weak mild solution. Assume that $\sup_{0\leq t\leq\tau}\|\phi_t\|\leq \|\phi\|_\infty<\infty$ almost surely for some constant $\|\phi\|_\infty.$ Then for any $T>0$ we may find a constant $C$ such that 
$$d_{TV}(\operatorname{Law}(X|_{[0,T]},Y_{[0,T]}))\leq CT^{1/2}\lambda \|\phi\|_\infty.$$
\end{proposition}


\begin{remark}When we use Proposition \ref{proposition1.2} in the proof of Theorem \ref{theorem1.1}, we will work with a mollified version of the SPDE with Lipschitz coefficients, so that well-posedness of the SPDEs are guaranteed. When we later use Proposition \ref{proposition1.2} to derive contraction estimates in Chapter \ref{section3}, we have already established well-posedness, so we will not worry about the well-posedness issues and apply this Proposition directly.\end{remark}

\begin{proof}
By Pinsker's inequality, we have
$$d_{TV}(\operatorname{Law}(X|_{[0,T]},Y_{[0,T]}))\leq\sqrt{2 H_{\text{rel}}(\operatorname{Law}(X|_{[0,T]}\mid Y_{[0,T]}))},$$
where $H_{\text{rel}}(\cdot\mid\cdot)$ denotes the relative entropy on path space $\mathcal{C}([0,T];H).$

Since $\sigma$ is non-degenerate, the law of $X|_{[0,T]}$ can be obtained from $Y|_{[0,T]}$ via Girsanov transform (a version of Girsanov transform for cylindrical processes can be bound in \cite{da2014stochastic}, Chapter 10):
$$(W_t)_{0\leq t\leq T}\mapsto (W_t-\sigma(Y_t)^{-1}\lambda \phi_t 1_{t\leq \tau})_{0\leq t\leq T}.$$

Since $\sigma^{-1}\lambda\phi_t1_{t\leq\tau}$ is bounded almost surely by $C\lambda\|\phi\|_\infty$, where $C$ is the upper bound in Hypothesis $\mathbf{H}_4$, the Proposition follows from a direct computation of relative entropy.
\end{proof}




\subsection{Proof of Theorem \ref{theorem1.1}}


\begin{proof} Existence of a weak mild solution is well-known, see for example \cite{gkatarek1994weak}, Theorem 2, and a generalized version of the existence result will be proved in Appendix \ref{appendixB}. We now prove uniqueness of weak mild solution.


We fix an orthonormal basis of the Hilbert space $H$. For each positive integer $n\in\mathbb{N}_+$ denote by $P_n$ the projection of $H$ onto the subspace spanned by the first $n$ basis vectors. Consider the coefficients $P_n b(P_n x)$ and $P_n \sigma(P_n x)$. Upon convolution with a finite-dimensional smooth mollifying function, we can assume that these functions are Lipschitz continuous for each $n$. Moreover, these approximating sequences converge to $b$ and $\sigma$ uniformly on every compact subset of $H$. To conclude, we may find a sequence of vectors $b^n(x)$ and operators $\sigma^n(x)$, converging to $b$ and $\sigma$ uniformly on each compact subspace of $H$, such that they satisfy $\mathbf{H_2}$, $\mathbf{H_3}$ and $\mathbf{H_5}$ with constants that are uniform in $n$.

For any initial value $x\in H$, consider the following three SPDEs
$$dX_t=A X_t dt+b(X_t)dt+\sigma(X_t)dW_t,\quad X_0=x,$$
$$dX^n_t=A X^n_t dt+b^n(X^n_t)dt+\sigma^n(X^n_t)dW_t,\quad X^n_0=x,$$
and 
$$d\widetilde{X}^n_t=A\widetilde{X}^n_t dt+b^n(\widetilde{X}^n_t)dt+\lambda (X_t-\widetilde{X}_t^n)dt 1_{t\leq\tau}+\sigma^n(\widetilde{X}^n_t)dW_t,\quad \widetilde{X}_0^n=x,$$
where $\tau$ is a stopping time to be determined.

Before going into details we briefly outline the two-step proof strategy. To show $X_t^n$ converges to $X_t$ in distribution, we first establish a contracting estimate of $X_t$ towards $\widetilde{X}_t^n$ via choosing $\lambda$ sufficiently large. Then we show that $X_t^n$ is sufficiently close to $\widetilde{X}_t^n$ in total variation distance, using an appropriate definition of the stopping time $\tau$ and non-degeneracy of $\sigma^n$. The proof completes as a combination of these two bounds.




Given a compact subset $K\subset H$ with $x\in K$, denote by $$\Delta_K^n:=\sup_{y\in K}\|b^n(y)-b(y)\|+\|\sigma^n(y)-\sigma(y)\|$$
and set $\tau_K^n:=\inf\{t\geq 0:\|X_t-\widetilde{X}_t^n\|\geq 2\Delta_K^n\}.$ Also denote by $\theta_K:=\inf\{t\geq 0: X_t\notin K\}.$ We set $$\tau=\tau_K^n\wedge\theta_K$$ and $$\lambda=({\Delta_K^n})^{\gamma -1}$$ 
for some value of $\gamma>0$ to be fixed later.


As we form the approximation sequence $\sigma^n$ via mollifying finite dimensional projections $P_n\sigma(P_nx)$, it might be the case that $\sigma^n$ may not have a right inverse, so the assumption $\mathbf{H_4}$ is not true for the sequence $\sigma^n$. Fortunately, when restricted to the subspace $p_n H$ we can find a right inverse $(\sigma^n)^{-1}$ for $\sigma^n$ such that $P_n\sigma^n (\sigma^n)^{-1}=P_n$ and that 
$\sup_{x\in H}\|(\sigma^n(x))^{-1}\|\leq C<\infty$ uniformly in $n$. 


Now we apply Proposition \ref{proposition2.3} for the projected process $P_n(X_t^n-\widetilde{X}_t^n)$ and deduce that, 
for any $T>0$ we can find a constant $C$ (uniform in $n$) such that
\begin{equation}\label{variationineq}
d_{TV}(\operatorname{Law}(P_nX^n|_{[0,T]}),\operatorname{Law}(P_n\widetilde{X}^n|_{[0,T]}))\leq C T^{1/2}(\Delta_K^n)^\gamma.\end{equation}

For $0\leq t\leq \tau$, assume for simplicity that $\Delta_K^n\in[0,1)$, we may compute via triangle inequality that for some universal constant $C>0$,
$$
    \|b(X_t)-b^n(\widetilde{X}_t^n)\|\leq M(2\Delta_K^n)^{\alpha}+\Delta_K^n\leq C (\Delta_K^n)^\alpha,\quad t\leq \tau
$$ and 
$$\|\sigma(X_t)-\sigma^n(\widetilde{X}_t^n)\|\leq M(2\Delta_K^n)^\beta+\Delta_K^n\leq C (\Delta_K^n)^\beta,\quad t\leq\tau,$$
where $M$ is the constant appearing in Assumptions $\mathbf{H}_2$ and $\mathbf{H}_3$.


A direct computation yields
$$\begin{aligned}
\|X_t-\widetilde{X}_t^n\|&\leq e^{-\lambda t}\left\|\int_0^t S(t-s)e^{\lambda s }[b(X_s)-b^n(\widetilde{X}_s^n)]ds\right\|\\&+\left\|e^{-\lambda t}\int_0^t S(t-s)e^{\lambda s }[\sigma(X_s)-\sigma^n(\widetilde{X}_s^n)]dW_s\right\|.\end{aligned}.$$


 Applying Proposition \ref{stochasticinte}, note that we choose $\lambda=(\Delta_K^n)^{\gamma -1}$, we obtain that for each $\eta\in(0,\frac{1}{2})$ and $m\in\mathbb{N}_+$, we may find a constant $C=C_{\eta,m}$ satisfying
\begin{equation}\label{complementary}\mathbb{P}(\sup_{t\in[0,\tau]}\|X_t-\widetilde{X}_t^n\|>C (\Delta_K^n)^{1+\alpha-\gamma}+C(\Delta_K^n)^{\frac{1-\gamma}{2}\eta+\beta}R)\leq \frac{C}{R^m},\quad R>0.\end{equation}


By our assumption $\alpha\in(0,1]$ and $\beta\in(\frac{3}{4},1]$, we can find $\eta\in(0,\frac{1}{2})$ sufficiently close to $\frac{1}{2}$ and $\gamma\in(0,1)$ sufficiently close to $0$, such that the following holds at the same time:
\begin{equation}
    \label{condition2}
\begin{cases}
\gamma\in(0,\alpha)\\
\frac{1-\gamma}{2}\eta+\beta>1.\\
\end{cases}\end{equation}
Consequently, the powers of $\Delta_K^n$ in the bracket of \eqref{complementary} are all larger than one.
We fix from now on the choice of $\gamma$ and $\eta$, as well as the constant $C_m=C_{\eta,m}$.

Now we choose $\chi\in(0,\frac{1-\gamma}{2}\eta+\beta-1]$ and set $R:=(\Delta_K^n)^{-\chi}$ in the estimate \eqref{complementary}. Denote by $$\Omega_\nu:=\{\sup_{t\in[0,\tau]}\|X_t-\widetilde{X}_t^n\|>C (\Delta_K^n)^{1+\alpha-\gamma}+C(\Delta_K^n)^{\frac{1-\gamma}{2}\eta+\beta-\chi}\}.$$
Upon choosing $\Delta_K^n$ sufficiently small, we deduce that $\|X_t-\widetilde{X}_t^n\|\leq\Delta_K^n$ for all $t\leq\tau$ on $\Omega\setminus\Omega_\nu$. Since the processes have continuous trajectories, we deduce that we indeed have $$\theta_K\wedge T\leq \tau_K^n$$ on $\Omega\setminus\Omega_\nu$. From this we conclude that, for any $\kappa>0$,
\begin{equation}
   \label{convergeinprob} 
\mathbb{P}(\sup_{t\in[0,T\wedge \theta_K]} \|X_t-\widetilde{X}_t^n\|>\kappa)\to 0,\quad n\to\infty.\end{equation}


For every $m\in\mathbb{N}_+$ let $F_m$ be a bounded continuous function on $\mathcal{C}([0,T];P_m H).$ To prove uniqueness it suffices to show that, for each $m\in\mathbb{N}_+,$
\begin{equation}\label{condition}
\mathbb{E}[F_m(P_mX|_{[0,T]})]-\mathbb{E}[F_m(P_mX^n|_{[0,T]})]\to 0,\quad n\to\infty,\end{equation} where we denote also by $P_m$ the natural projection of $\mathcal{C}([0,T]; H)$  onto $\mathcal{C}([0,T];P_m H).$
Indeed, since $b^n$ and $\sigma^n$ are Lipschitz for each $n$, the SPDE solved by $X^n$ has a unique strong solution, and $\operatorname{Law}(X^n|_{[0,T]})$ is uniquely determined. The limit \eqref{condition} then implies the law of $X|_{[0,T]},$ projected onto $C([0,T];P_m H)$, is uniquely determined. Since $m\in\mathbb{N}_+$ is arbitrary, the law of $X|_{[0,T]}$ is then  uniquely defined.



To prove \eqref{condition}, first note that \eqref{variationineq} implies, \footnote{Using the elementary fact that 
for $m<n$, 
$$d_{TV}(\operatorname{Law}(P_mX^n|_{[0,T]}),\operatorname{Law}(P_m\widetilde{X}^n|_{[0,T]}))\leq d_{TV}(\operatorname{Law}(P_nX^n|_{[0,T]}),\operatorname{Law}(P_n\widetilde{X}^n|_{[0,T]}).$$
} in the limit $\Delta_K^n\to 0,$

$$\mathbb{E}[F_m(P_m\widetilde{X}^n|_{[0,T]})]-\mathbb{E}[F_m(P_mX^n|_{[0,T]})]\to 0,\quad n\to\infty,$$


Note also that \eqref{convergeinprob} implies $\widetilde{X}^n|_{[0,T]}$ converges to $X|_{[0,T]}$ in probability, on $\{\theta_K\geq T\}$. Therefore 
$$\lim\sup_{n\to\infty}\left|\mathbb{E}[F_m(P_m\widetilde{X}^n|_{[0,T]})]-\mathbb{E}[F_m(P_mX|_{[0,T]})]\right|\leq  2\sup_x\|F_m(x)\|\mathbb{P}(\theta_K\leq T).$$
The right hand side can be set arbitrarily small thanks to Proposition \ref{proposition1.2}. This completes the proof of \eqref{condition}, and weak uniqueness follows.

The Markov property of $(X_t)_{t\geq 0}$ follows from the Markov property of the approximating sequence $(X_t^n)_{t\geq 0}$ via a usual approximation argument. 
\end{proof}


\subsection{Proof of Theorem \ref{theorem1.4}: the well-posedness part}

\begin{proof}
We first show that under the assumptions $\mathbf{H}_1'$ the conclusions of Proposition \ref{stochasticinte} can be modified accordingly.


Under $\mathbf{H}_1'$, we replace the choice $\eta\in(0,\frac{1}{2})$ by $\eta\in(0,\eta_0)$ everywhere in the proof of Proposition \ref{stochasticinte}, and conclude with: for each $\eta\in(0,\eta_0)$ and $m\in\mathbb{N}_+$, we find $C_{m,\eta}>0$ such that
\begin{equation}\label{modifications}\mathbb{P}(\sup_{t\in[0,T]}\|Z(t)\|\geq C_m \lambda^{-\frac{1}{2}\eta} \|\phi\|_\infty R)\leq \frac{C_{m,\eta}}{R^m},\quad R>0,\end{equation}
in place of \eqref{1/4conclude}.

Assume $\mathbf{H}_2$. Then the proof of Theorem \ref{theorem1.1} carries over almost identically, and we only need to make the following change:

 Under $\mathbf{H}_1'$ we have $\alpha\in(0,1]$ and $\beta\in(1-\frac{\eta_0}{2},1)$, so we can find $\eta\in(0,\eta_0)$ sufficiently close to $\eta_0$ and $\gamma>0$ sufficiently small such that 
$$\begin{cases}
\gamma\in(0,\alpha)\\
\frac{1-\gamma}{2}\eta+\beta>1.\\
\end{cases}$$
holds. Then the exponents of $\Delta_K^n$ in \eqref{complementary} are strictly greater than one. The rest of the proof is identical to that of Theorem \ref{theorem1.1}.


 The Markov property of $(X_t)_{t\geq 0}$ also follows from that of the approximating sequence via a usual approximating argument. 
\end{proof}





\section{Choice of a metric and contracting properties}\label{section3}

\subsection{The generalized coupling approach}
As discussed in the introduction, we will show that by a suitable choice of $N$ and $\gamma$, the distance function $$d_{N,\gamma}(x,y):=N\|x-y\|^\gamma\wedge 1$$ is contracting for the dynamics $X_t$ for suitably close initial values $x,y\in H$. Since the coefficients are not Lipschitz, we cannot use a direct coupling mechanism to show the dynamics is contracting. Instead, we follow a generalized coupling approach, introduced in kulik and Scheutzow\cite{kulik2020well}. The generalized coupling approach involves both pathwise contraction estimates and probabilistic estimates via Girsanov transform.

Fix two initial values $x,y\in H$. To couple the two processes
\begin{equation}\label{eqx}dX_t=AX_t dt+b(X_t)dt+\sigma(X_t)dW_t,\quad X_0=x\end{equation}
and 
\begin{equation}\label{eqy}dY_t=AY_t dt+b(Y_t)dt+\sigma(Y_t)dW_t,\quad Y_0=y,\end{equation}
we introduce a constant $\lambda>0$ and a stopping time $\tau$ whose value will be determined later, and we consider an auxiliary control process
\begin{equation}\label{controlprocess}
d\widetilde{Y}_t=A\widetilde{Y}_t dt+b(\widetilde{Y}_t)dt+\lambda(X_t-\widetilde{Y}_t)dt1_{t\leq\tau}+\sigma(\widetilde{Y}_t)dW_t,\quad \widetilde{Y}_0=y.\end{equation}

The distance between $X_t$ and $\widetilde{Y}_t$ will be bounded via a pathwise argument, while the distance between $\widetilde{Y}_t$ and $Y_t$ can be bounded via Girsanov transform.  

We set $$\tau=\tau_{x,y}:=\inf\{t\geq 0:|X_t-\widetilde{Y}_t|\geq 2\|x-y\|\},$$
and set $\lambda:=\|x-y\|^{\gamma -1}$ for some $\gamma\in(0,1)$ to be determined later. 

It follows from Proposition \ref{proposition2.3} that for any $T>0$ we can find $C$ such that 
\begin{equation}
    \label{controlgirsanov}
d_{TV}(\operatorname{Law}(Y|_{[0,T]}),\operatorname{Law}(\widetilde{Y}|_{[0,T]}))\leq CT^{1/2} \|x-y\|^\gamma.\end{equation}


Writing \eqref{eqx} and \eqref{eqy} in mild formulations, and consider $Z_t:=e^{\lambda t}(X_t-\widetilde{Y}_t),$ we have 
$$dZ_t=\Delta Z_t dt+e^{\lambda t}(b(X_t)-b(Y_t))dt+e^{\lambda t}(\sigma(X_t)-\sigma(Y_t))dW_t$$

That is, 
\begin{equation}\label{difference}
\begin{aligned}
\|X_t-\widetilde{Y}_t\|\leq e^{-\lambda t}|x-y|&+e^{-\lambda t}\left\|\int_0^t S(t-s)e^{\lambda s}(b(X_s)-b(\widetilde{Y}_s))ds\right\|\\&+e^{-\lambda t}\left\|\int_0^t S(t-s)e^{\lambda s}(\sigma(X_s)-\sigma(\widetilde{Y}_s))dW_s\right\|.
\end{aligned}\end{equation}
Using the Hölder continuity $\mathbf{H}_2$ and $\mathbf{H}_3$ of $b$ and $\sigma$, definition of the stopping time $\tau$ and Proposition \ref{stochasticinte}, we obtain the following deviation estimate: for each $m\in\mathbb{N}_+$ and $\eta\in(0,\frac{1}{2})$, we may find some fixed constant $M=M_{m,\eta}>0$ such that 
\begin{equation}\label{fififi}
    \mathbb{P}(\sup_{0\leq t\leq \tau\wedge T}(\|X_t-\widetilde{Y}_t\|- e^{-\lambda t}\|x-y\|)\geq  M\lambda^{-1}\|x-y\|^{\alpha}+M\lambda^{-\frac{1}{2}\eta}\|x-y\|^{\beta} R)\leq \frac{M}{R^m},\quad R>0.
\end{equation}


Recall we made the choice $\lambda=\|x-y\|^{\gamma -1}$. We may find  $\gamma>0$ sufficiently small and $\eta\in(0,\frac{1}{2})$ sufficiently close to $\frac{1}{2}$ such that
$$
\begin{cases}
\gamma\in(0,\alpha)\\
\frac{1-\gamma}{2}\eta+\beta>1.\\
\end{cases}$$ holds, as it did in
\eqref{condition2}.

Then we find some  $0<\chi<\min(\alpha-\gamma,\beta+\frac{1-\gamma}{2}\eta-1)$ and choose furthermore $$R=\|x-y\|^{-\chi}$$  to obtain
\begin{equation}
    \mathbb{P}(\sup_{0\leq t\leq\tau\wedge T} (\|X_t-\widetilde{Y_t}\|-e^{-\|x-y\|^{\gamma -1}t}\|x-y\|)\geq M_m\|x-y\|^{1+\chi})\leq M_m \|x-y\|^{2m\chi}.
\end{equation}


Denote by $\Omega_\nu:=\{\sup_{0\leq t\leq \tau\wedge T}\|X_t-\widetilde{Y}_t\|-e^{-\|x-y\|^{\gamma -1}t}\|x-y\|\geq M_n\|x-y\|^{1+\chi}\},$ then by choosing $\|x-y\|$ small enough, on the complementary set $\Omega\setminus\Omega_\nu$ one must have $\sup_{0\leq t\leq\tau_\wedge T} \|X_t-Y_t\|\leq 2\|x-y\|$. Thus by continuity of the trajectories we must have \begin{equation}\label{stoppingtimestimate}\tau=\tau_{x,y}\geq T\end{equation}on $\Omega\setminus\Omega_\nu$, so we can deduce that
\begin{equation}\label{1.111}
    \mathbb{P}(\sup_{0\leq t\leq T} (\|X_t-\widetilde{Y_t}\|-e^{-\|x-y\|^{\gamma -1}t}\|x-y\|)\geq M_m\|x-y\|^{1+\chi})\leq M_m \|x-y\|^{2m\chi}.
\end{equation}

Now we make a choice of $m\in\mathbb{N}_+$ such that \begin{equation}\label{limitofm}m\chi \geq \gamma,\end{equation}
and fix the choice of the constant $M:=M_m$ in the rest of the argument.

Since $$e^{-\nu^{\gamma -1}T}+M\nu^\chi\to 0\quad \text{ as   }\nu\to 0,$$ 
we will choose some sufficiently small  $\nu_0>0$ and assume that $\|x-y\|\leq \nu_0$ to obtain, as a consequence of \eqref{1.111}, \eqref{stoppingtimestimate} and \eqref{limitofm}: 
\begin{equation} \label{deviationestimate11}
    \mathbb{P}(\|X_T-\widetilde{Y}_T\|\geq \frac{1}{2}\|x-y\|)\leq M \|x-y\|^{2\gamma}.
\end{equation}

Since probability is upper bounded by 1, we restate the above estimate as
\begin{equation} \label{deviationestimate}
    \mathbb{P}(\|X_T-\widetilde{Y}_T\|\geq \frac{1}{2}\|x-y\|)\leq M \|x-y\|^{2\gamma}\wedge 1.
\end{equation}

We can also derive the following estimate which will be useful later:
\begin{equation} \label{longtime}
    \mathbb{P}(\sup_{0\leq t\leq T}\|X_t-\widetilde{Y}_t\|\geq 2\|x-y\|)\leq M \|x-y\|^{2\gamma}\wedge 1.
\end{equation}

\subsection{The case of close enough initial values}\label{Section3.2}
In this section we consider initial values $x,y\in H$ that are close in the sense that $$d_{N,\gamma}(x,y)<1.$$
We combine \eqref{deviationestimate} with the control \eqref{controlgirsanov}to deduce a contraction estimate for $\|X_t-Y_t\|$ under the distance $d_{N,r}.$ The proof is very similar to Proposition 5.1 of \cite{kulik2020well}. 


Recall that we have derived \eqref{deviationestimate} assuming $x$ and $y$ are close enough: for some $\nu_0>0$ sufficiently small, $\|x-y\|\leq\nu_0$. Thus we choose $N$ large enough \footnote{once we have fixed a value of $\gamma>0$} such that $d_{N,\gamma}(x,y)=1$ for any pair $(x,y)$ with $\|x-y\|\geq\nu_0.$ We will work under this assumption throughout the proof without further mentioning.

For any two initial values $x,y\in H$, consider the SPDEs $X_t$ \eqref{eqx}, $Y_t$ \eqref{eqy}, as well as the control process $\widetilde{Y}_t$ \eqref{controlprocess}.


Consider a coupling $(\xi_1,\xi_2)$ where $\xi_1$ has law $X_t$, $\xi_2$ has law $\widetilde{Y}_t$ and that $(X_t,\widetilde{Y}_t)$ satisfy the contraction estimate \eqref{deviationestimate} with $t=T$. 


Consider another coupling $(\xi_2,\xi_3)$ where $\xi_2$ has law $\widetilde{Y}_t$ and $\xi_3$ has law $Y_t$, and such that by \eqref{controlgirsanov}, $$\mathbb{P}(\xi_2\neq \xi_3)\leq d_{TV}(\operatorname{Law}(Y_{[0,T]))};\operatorname{Law}(\widetilde{Y}|_{[0,T]}))\leq CT^{1/2}\|x-y\|^\gamma.$$
We may now form a coupling $(\xi_1,\xi_3)$ of $(X_t,Y_t),$ possibly on a different probability space, via the coupling $(\xi_1,\xi_2)$ and $(\xi_2,\xi_3)$ and obtain the following estimate:
$$\begin{aligned}
\mathbb{E}d_{N,\gamma}(\xi_1,\xi_3)&\leq \mathbb{E} d_{N,\gamma}(\xi_1,\xi_2)+\mathbb{P}(\xi_2\neq\xi_3)\\&\leq \mathbb{E}d_{N,\gamma}(\xi_1,\xi_2)1_{\{\|\xi_1-\xi_2\|\leq\frac{1}{2} \|x-y\|\}}+\mathbb{P}(\|\xi_1-\xi_2\|\geq \frac{1}{2}\|x-y\|)+\mathbb{P}(\xi_2\neq\xi_3).\end{aligned}
$$

Since we assume that $$d_{N,\gamma}(x,y)=N\|x-y\|^\gamma<1,$$ and therefore $N2^{-\gamma} \|x-y\|^\gamma<1,$ we combine the various estimates to deduce that 
\begin{equation}\label{goodgifts}\begin{aligned}\mathbb{E}d_{N,\gamma}(\xi_1,\xi_3)&\leq N2^{-\gamma} \|x-y\|^\gamma +M\|x-y\|^{2\gamma}+C\|x-y\|^\gamma\\ \leq& d_{N,\gamma}(x,y)\left(2^{-\gamma}+\frac{M\|x-y\|^{2\gamma}\wedge 1}{N\|x-y\|^\gamma}+\frac{C}{N}\right).\end{aligned}\end{equation}
Note that $\sup_{s\geq 0}\frac{M s^{2\gamma}\wedge 1}{s^\gamma}<\infty.$
Therefore, upon choosing $N$ large enough, we may find some $\theta_1\in(2^{-\gamma},1)$ such that, for some given $N_0$ depending on $\gamma$ and $\theta_1$, we have
\begin{equation}\mathbb{E}d_{N,\gamma}(\xi_1,\xi_3)\leq \theta_1 d_{N,\gamma}(x,y),\quad \text{ for all } N\geq N_0,\quad \text{all } d_{N,\gamma}(x,y)<1.\end{equation}

By definition of the Wasserstein distance,  $$
d_{N,\gamma}\left(\operatorname{Law}(X_t),\operatorname{Law}(Y_t)\right)\leq \mathbb{E}d_{N,\gamma}(\xi_1,\xi_2),$$
so we conclude that \begin{equation}d_{N,\gamma}\left(\operatorname{Law}(X_t),\operatorname{Law}(Y_t)\right)
\leq \theta_1 d_{N,\gamma}(x,y),\quad N\geq N_0,\quad d_{N,\gamma}(x,y)<1.\end{equation}

Note that the choice of $N$ and $\gamma$ depend on the final time $t>0$. 

To unify notations in this paper, we write $X_t^x$ the law of $X_t$ with initial value $x\in H$, and rewrite this estimate as
\begin{equation}\label{localcontraction}d_{N,\gamma}\left(\operatorname{Law}(X_t^x),\operatorname{Law}(X_t^y)\right)
\leq \theta_1 d_{N,\gamma}(x,y),\quad N\geq N_0,\quad d_{N,\gamma}(x,y)<1.\end{equation}


One could also derive in the same way from \eqref{longtime} the following estimate
\begin{equation}\label{longtimespider}
    \sup_{0\leq s\leq t} d_{N,\gamma}\left(\operatorname{Law}(X_s^x),\operatorname{Law}(X_s^y)\right)
\leq 3 d_{N,\gamma}(x,y),\quad N\geq N_0,\quad d_{N,\gamma}(x,y)<1.
\end{equation}

\subsection{The case of distant initial values}

We finally derive a contraction estimate for initial values $x,y$ such that $d_{N,\gamma}(x,y)=1,$ but that for some fixed $R>0$, $\|x\|\leq R$ and $\|y\|\leq R$.


We begin with a lemma that describes the possibility of visiting bounded subsets of $H$, which is similar to Proposition 5.2 of \cite{kulik2020well} and to the proof of various estimates we have done. 

\begin{lemma}\label{lemma3.1}
For each $x\in H$ and $\lambda>0$, denote by $X_t^{\lambda,x}$ the solution to the SPDE 
$$dX_t=A X_t dt-\lambda X_t dt+b(X_t)dt+\sigma(X_t)dW_t,\quad X_0=x,$$ where $b$ and $\sigma$ satisfy the assumptions $\mathbf{H}_1$ to $\mathbf{H}_5$.


Then for any $D>0$ and $\delta>0$, there exists $\lambda$ sufficiently large (depending only on $D$, $\delta$, $t$ and the constants in assumption $\mathbf{H}_1$ to $\mathbf{H}_5$) such that  
$$\inf_{\|x\|\leq D} \mathbb{P}(\|X_t^{\lambda,x}\|\leq\delta)\geq\frac{1}{2}.$$
\end{lemma}

\begin{proof}
Consider the stopping time $\tau_D:=\inf\{t\geq 0: \|X_t^{\lambda,x}\|\geq 2D\}.$ By the linear growht property $\mathbf{H}_5$, we may find some $M>0$ such that $\|b(X_t^{\lambda,x})\|\leq M(1+D)$ and $\|\sigma(X_t^{\lambda,x})\|\leq M(1+D)$ whenever $t\leq\tau_D$. Arguing with the mild formulation and estimating each term explicitly, using also Proposition \ref{stochasticinte} with $\eta=\frac{1}{4}$, we claim that
$$\mathbb{P}\left(\sup_{s\in[0,t\wedge\tau_D]} \|X_s^{\lambda,x}\|- e^{-\lambda s}\|x\|\geq \lambda^{-1}M(1+D)+\lambda^{-\frac{1}{8}}M(1+D)R\right)\leq \frac{C}{R^2},\quad R\geq 2.$$
Choosing $R=\lambda^{\frac{1}{16}}$ for $\lambda$ large, we see that 
\begin{equation}\label{event}\mathbb{P}\left(\sup_{s\in[0,t\wedge\tau_D]} \|X_s^{\lambda,x}\|- e^{-\lambda s}\|x\|\geq \lambda^{-1}M(1+D)+ \lambda^{-\frac{1}{16}}M(1+D)\right)\leq C \lambda^{-\frac{1}{8}}.\end{equation}
Arguing as in the previous proofs, we see that when $\lambda$ is sufficiently large, in the complement of the event in \eqref{event} one must have $\tau_D\geq t$. Now if we choose $\lambda$ sufficiently large, we can ensure that 
$\mathbb{P}(\|X_t^{\lambda,x}\|\leq \delta)\geq \frac{1}{2},$ uniformly over the initial value $\|x\|\leq D$. This completes the proof.
\end{proof}

In the following we fix this choice of $\lambda>0$. Via direct moment estimates, we may find 
$$C_1(\lambda):=\sup_{\|x\|\leq D}\mathbb{E}[\sup_{s\in[0,t]}\|X^{\lambda,x}_s\|^2]<\infty.$$ By arguing via Girsanov transform, we compute the relative entropy between solutions $X^x$ and $X^{\lambda,x}$ as follows:
\begin{equation}
    \label{relativedifference}\sup_{\|x\|\leq D} H_{\text{rel}}(\operatorname{Law}(X^{\lambda,x}|_{[0,t]})\mid\operatorname{Law}(X^{x}|_{[0,t]}))\leq \frac{\lambda t}{2}C_1(\lambda)\sup_{x\in H}\|\sigma(x)^{-1}\|:=C_2<\infty,\end{equation} where $H_{\text{rel}}$ denotes the relative entropy on path space $C([0,T];H).$

 We will use a powerful formula on relative entropy (see \cite{kulik2020well}, Appendix A or \cite{butkovsky2020generalized}, Appendix A): for two measures $\mu$ and $\nu$ on a common measure space $(X,\chi)$, and for any set $A\in\chi$, we have for each $N\in\mathbb{N}_+$
$$\nu(A)\geq\frac{1}{N}\mu(A)-\frac{H_{\text{rel}}(\mu\mid\nu)+\log 2}{N\log N}.$$


In our case we consider $A:=\{\omega\in \mathcal{C}([0,t];H): \|\omega_t\|\leq\delta\},$ $\nu=\operatorname{Law}(X^x|_{[0,t]})$ and $\mu=\operatorname{Law}(X^{\lambda,x}|_{[0,t]}).$ Combining Lemma \ref{lemma3.1} and estimate \eqref{relativedifference}, we deduce that 
$$\inf_{\|x\|\leq D}\mathbb{P}(\|X_t^x\|\leq\delta)\geq\frac{1}{2N}-\frac{C_2+\log 2}{N\log N}.$$ 
Now we choose $N=\exp(4C_2+4\log 2)$ and deduce that 
\begin{equation}\label{finalconclusion}\inf_{\|x\|\leq D}\mathbb{P}(\|X_t^x\|\leq\delta)\geq\frac{1}{L(D,\delta)},\end{equation} where $L(D,\delta):=4\exp(4C_2+4\log 2)$ is a constant that only depends on $D$, $\delta$, $t$ and the constants in hypothesis $\mathbf{H}_1-\mathbf{H}_5.$

\subsection{Concluding the proof of contraction property}
We are now ready to prove Theorem \ref{contractionmain}.
\begin{proof}
Consider two initial values $x,y\in H$ such that $\|x\|\leq D$, $\|y\|\leq D$ and $d_{N,\gamma}(x,y)=1$, where the values of $N$ and $\gamma$ have been fixed in Section \ref{Section3.2}.

Consider the solutions $X_t^x$ and $X_t^y$. If $$\|X_t^x\|\leq\frac{1}{2^{1+1/\gamma}N^{1/\gamma}}\quad\text{ and }\quad \|X_t^y\|\leq \frac{1}{2^{1+1/\gamma}N^{1/\gamma}},$$ then $d_{N,\gamma}(X_t^x,X_t^y)\leq\frac{1}{2}.$ Otherwise we upper bound $d_{N,\gamma}(X_t^x,X_t^y)$ by 1. Using an independent coupling of $X_t^x$ and $X_t^y$, we compute that
\begin{equation}\label{largecontraction}
\begin{aligned}
    d_{N,\gamma}(\operatorname{Law}(X_t^x),\operatorname{Law}(X_t^y))&\leq d_{N,\gamma}(X_t^x,X_t^y)\\&\leq 1-\frac{1}{2}\left(\inf_{\|z\|\leq D}\mathbb{P}(\|X_t^z\|\leq\frac{1}{2^{1+1/\gamma}N^{1/\gamma}})\right)^2<1.\end{aligned}
\end{equation}
 Take $\theta$ to be the maximum of the constant $\theta_1$ in \eqref{localcontraction} and the constant in the right hand side of \eqref{largecontraction}, we conclude that 
 \begin{equation}d_{N,\gamma}\left(\operatorname{Law}(X_t),\operatorname{Law}(Y_t)\right)
\leq \theta d_{N,\gamma}(x,y),\quad \|x\|\leq D,\|y\|\leq D.\end{equation}
This finishes the proof.
\end{proof}

The same conclusion holds under the hypothesis $\mathbf{H}_1'$ and $\mathbf{H}_3'$, as stated in Theorem \ref{theorem1.4}. We give a sketch of proof of this fact:
\begin{proof}
Under the assumptions $\mathbf{H}_1'$ and $\mathbf{H}_3'$, using \eqref{modifications}, we still have the estimate \eqref{fififi} but for all $\eta\in(0,\eta_0)$. Now as $\beta>1-\frac{\eta_0}{2},$ we may take $\gamma>0$ sufficiently small and $\eta\in(0,\eta_0)$ sufficiently close to $\frac{1}{2}$ such that 
$$
\begin{cases}
\gamma\in(0,\alpha)\\
\frac{1-\gamma}{2}\eta+\beta>1.\\
\end{cases}$$ holds as well. Then with the same choice of $\chi$ we obtain \eqref{1.111}. All the remaining steps are identical, leading us to 
\eqref{deviationestimate} and then \eqref{localcontraction}.

Meanwhile, lemma \ref{lemma3.1}, as well as the estimate \eqref{finalconclusion}, are true in this case with the same proof. Thus we have proved Theorem \ref{contractionmain} under the assumptions $\mathbf{H}_1'$, $\mathbf{H}_3'$, $\mathbf{H}_2$, $\mathbf{H}_4$ and $\mathbf{H}_5.$
\end{proof}


\section{Lyapunov function and exponential ergodicity}
\subsection{spectral gap and existence of invariant measure}

Now we are in the position to prove the spectral gap result, Theorem \ref{harristheorem}.
\begin{proof}
We check all the assumptions in Theorem 4.8 of \cite{hairer2011asymptotic} are satisfied. Fix some $t>0$ and set $D:=\sup\{\|x\|:x\in H, V(x)\leq 4K_V\}$ \footnote{The supremum $D$ is finite thanks to the assumption $V(x)\to\infty$ as $\|x\|\to\infty$.} in the setting of Theorem \ref{contractionmain}, then we may find a choice of $d$ and $\gamma$ such that the distance function $d_{N,\gamma}$ satisfies
\begin{itemize}
    \item $\mathcal{P}_{t}$ is contracting for initial values $x,y\in H$ with $d_{N,\gamma}(x,y)<1$. 
    \item The sublevel set $\{x\in H:V(x)\leq 4K_V\}$ is $d$-small for $\mathcal{P}_{t}$.
\end{itemize}

Then by Theorem 4.8 of \cite{hairer2011asymptotic}, $\mathcal{P}_t$ can have at most one invariant measure, and if we define $\widetilde{d}(x,y)=\sqrt{d_{N,\gamma}(x,y)(1+V(x)+V(y))}$, there exists $t_*>0$ such that 
$$\widetilde{d}(\mathcal{P}_{t_*}\mu,\mathcal{P}_{t_*}\nu)\leq \frac{1}{2}\widetilde{d}(\mu,\nu)$$
for any probability measures $\mu,\nu\in\mathcal{M}_1(H)$. 


By the elementary inequality 
$$1\wedge \|x-y\|^\gamma\leq 1\wedge N\|x-y\|^\gamma\leq N(1\wedge \|x-y\|^\gamma),$$
we may choose a larger $t_*$ and redefine $\widetilde{d}(x,y)=\sqrt{(1\wedge \|x-y\|^\gamma)(1+V(x)+V(y))}$ so that we still have
\begin{equation}\label{iterativeexist}\widetilde{d}(\mathcal{P}_{t_*}\mu,\mathcal{P}_{t_*}\nu)\leq \frac{1}{2}\widetilde{d}(\mu,\nu).\end{equation}

The last step is to prove there exists an invariant measure $\pi$ for $\mathcal{P}$.
 Although we have not yet established the Feller property of the process $X_t$, \footnote{In the proof of Theorem \ref{theorem1.1} we encountered a technical difficulty of finding Lipschitz approximations of the infinite-dimensional operator $\sigma$ that remains uniformly non-degenerate. We circumvent this issue and proved uniqueness via an ad-hoc strategy, and we do not establish Feller property of the process for similar reasons.} an argument similar to Corollary 4.11 of \cite{hairer2011asymptotic} allows us to prove existence without knowing the Feller property in advance. 
 
 Fix a probability measure $\mu\in\mathcal{M}_1(H)$ such that $\int Vd\mu<\infty$. Applying \eqref{iterativeexist} iteratively, we get
 $$\widetilde{d}(\mathcal{P}_{(n+1)t_*}\mu,\mathcal{P}_{nt_*}\mu)\leq\frac{1}{2^n} \widetilde{d}(\mathcal{P}_{t_*}\mu,\mu).$$
 Since $\widetilde{d}$ dominates $d_0:=1\wedge \|x-y\|$, and the latter is a complete metric on $H$, we deduce that the Wasserstein distance associated with $\widetilde{d}$ defines a complete metric for probability measures on $H$ that integrates $V.$\footnote{A Cauchy sequence $(\mu_n)$ with respect to the Wasserstein $\widetilde{d}$ is also a Cauchy sequence with respect to the 1-Wasserstein distance defined by $d_0$, so that $(\mu_n)$ is uniformly tight (see for example \cite{bolley2008separability}, Section 2, step 1). Then proceed with tightness and weak convergence arguments. The strategy is identical to proving the standard Wasserstein distance $W_p$ on a metric space is complete. See \cite{bolley2008separability} for an outline.} Thus there exists a probability measure $\mu_\infty$ such that $\widetilde{d}(\mathcal{P}_{nt_*}\mu,\mu_\infty)$ converges to $0$ as $n\to\infty$. One readily checks that $\widetilde{d}(\mathcal{P}_{t_*}\mu_\infty,\mu_\infty)=0$, so that $\mu_\infty$ is invariant for $\mathcal{P}_{t_*}$.
 
 Finally, define 
 $$\mu_*(A)=\frac{1}{t_*}\int_0^{t_*}(\mathcal{P}_s\mu_\infty)(A)ds$$ for each measurable $A\subset H$. One sees that $\mathcal{P}_t\mu_*=\mu_*$ for any $t>0$.
\end{proof}

\begin{remark}
Theorem \ref{harristheorem} provides exponential convergence and spectral gap results for the Markov semigroup $(\mathcal{P}_t)_{t\geq 0}$ at discrete times $t=t_*k,k\in\mathbb{N}_+$. In general we cannot deduce a contraction bound of the form 
$$\widetilde{d}(\mathcal{P}_t\mu,\mathcal{P}_t\nu)\leq c_1e^{-c_2t}\widetilde{d}(\mu,\nu),$$ that holds for all $t\geq 0$ via Harris theorem, unless $C_V\leq 0$ or $C_V>0$ is sufficiently small. This is because in the application of Harris theorem (see \cite{hairer2011yet} or \cite{hairer2011asymptotic}, Theorem 4.8) we should check the level set $\{x\in H:V(x)\leq 4C_V\}$ is $d$-small. In our setting this is achieved via the estimate \eqref{largecontraction}. Regarding that estimate, unless we already have $4C_V\leq \frac{1}{2^{1+1/\gamma}N^{1/\gamma}},$ for $\gamma$ and $N$ some parameters determined by the coefficients of the SPDE,  the probability estimate in \eqref{largecontraction} cannot be made uniform over all $t\geq 0$.
\end{remark}


\subsection{Convergence rates in various regimes}

Now we prove Theorem \ref{theorem1.55} that gives geometric, subgeometric and polynomial convergence rates in various regimes. As the idea of proof is similar to Theorem 2.4 of \cite{butkovsky2014subgeometric} and Theorem 2.3 of\cite{kulik2020well}, we only give a sketch of its main ideas.

\begin{proof}
First consider the discrete-time Markov chain $(X_{t_0n})_{n\in\mathbb{N}_+}$. Set $t=t_0$ in Theorem \ref{contractionmain}, we can fix a choice of the distance $d=d_{N,\gamma}$, $N\in\mathbb{N}_+$, $\gamma\in(0,1)$ such that the sub-level set $V^{-1}([0,4C_V])$ is $d$-small. 
We take $p=\epsilon^{-1}$ and $q=(1-\epsilon)^{-1}$, and define $d_{M,\gamma,p}(x,y)=d_{N,\gamma}(x,y)^{1/p}.$
Now applying Theorem 2.1 of \cite{butkovsky2014subgeometric} or Theorem 4.5.2 of \cite{kulik2017ergodic}, we deduce the existence of an invariant measure $\pi$ and that, for some $c,C>0$,
\begin{equation}\label{geometricmain}d_{N,\gamma,p}(\operatorname{Law}(X^x_{nt_0}),\pi)\leq \frac{C}{r(cnt_0)^{1-\epsilon}}\phi(V(x))^{1-\epsilon},\quad n\in\mathbb{N}_+.\end{equation}


Moreover, using \eqref{longtimespider} and that the distance $d_{N,\gamma}$ is upper bounded by 1, we further conclude that for all $x,y\in H$, 
\begin{equation}\label{contractsmall}
d_{N,\gamma}(\operatorname{Law}(X_t^x,X_t^y))\leq  4 d_{N,\gamma}(x,y),\quad 0\leq t\leq t_0.\end{equation}

Combining the Markov property, \eqref{geometricmain} and \eqref{contractsmall}, using also
$$d_{N,\gamma}(x,y)\leq d_{N,\gamma,p}(x,y),$$
we deduce that for some $\xi>0$,
$$d_{N,\gamma}(\operatorname{Law}(X_t^x),\pi)\leq \frac{C}{r(\xi t)^{1-\epsilon}}\phi (V(x))^{1-\epsilon},\quad \text{for all }x\in H,t\geq 0.$$

We complete the proof noting that $$d_{\gamma'}(x,y)\leq d_{\gamma}(x,y)\leq d_{N,\gamma}(x,y)$$
for any $0<\gamma\leq\gamma'\leq 1$ and $N\in\mathbb{N}_+.$
\end{proof}

As we have shown that the analogue of Theorem \ref{contractionmain} holds under the more general assumptions $\mathbf{H}_1'$, $\mathbf{H}_3'$, and the proof of Theorems \ref{harristheorem} and \ref{theorem1.55} only depend on the result of Theorem \ref{contractionmain}, we immediately deduce that Theorems \ref{harristheorem} and \ref{theorem1.55} also hold under assumption $\mathbf{H}_1'$, $\mathbf{H}_3'$. This finishes the proof of Theorem \ref{theorem1.4}.


\section{Burgers type nonlinearities}

We finally deal with the nonlinearity $(-A)^{1/2}F(X_t)$ in the drift. We start with some elementary yet crucial estimates:
Recall that $(-\lambda_k)_{k\geq 1}$ are the eigenvalues of $A$ with each $\lambda_k>0$, and $S(t)$ is the semigroup generated by $A$. Then we have
\begin{equation} \|S(t)A^{1/2}\|=\sup_{k\geq 1}e^{-\lambda_k t} \lambda_k^{1/2}\leq \frac{d}{t^{1/2}},\end{equation}
where $$d:=\sup_{r> o}e^{-r}r^{1/2}<\infty.$$
Moreover, for any $\lambda>0$ we have
\begin{equation}\label{burgersusefulestimate}
\begin{aligned}
    \int_0^t e^{-\lambda(t-s)}\|S(t-s)(-A)^{1/2}\|ds&\leq d\int_0^t e^{-\lambda t}\frac{1}{\sqrt{t}}dt
    \\&\leq \frac{1}{\sqrt{\lambda}}d\int_0^\infty e^{-t}\frac{dt}{\sqrt{t}}\leq \frac{C}{\sqrt{\lambda}}
    \end{aligned}
\end{equation}
for some universal constant $C>0$ that does not depend on $t$ and $\lambda$.

Finally, note that $t^{-1/2}$ is integrable on $[0,T]$ for any $T>0$. We now begin to prove the well-posedness result:

\subsection{Well-posedness with Burgers nonlinearities}

Now we prove Theorem \ref{burgerstheorem1}.
\begin{proof}
For existence of a weak mild solution, we generalize the existence part of Theorem 1 of \cite{priola2022correction} to cover multiplicative noise. The existence result is given in the following theorem, whose proof is deferred to Appendix \ref{appendixB}.
\begin{theorem}\label{theoreminappendixB} Assume the operator $A$ satisfies $\mathbf{H}_1'$, the coefficients $b$, $F$ and $\sigma$ are continuous and have linear growth: for some $M>0$, 
$$\|F(x)\|\leq M(1+\|x\|),\quad \|b(x)\|\leq M(1+\|x\|),\quad \|\sigma(x)\|\leq M(1+\|x\|).$$
Then there exists a weak mild solution to the evolution equation \eqref{burgerstheorem1}.
\end{theorem}


We now focus on showing the weak solution is unique in law. We follow closely the proof of Theorem \ref{theorem1.1}. Consider approximations $b^n$, $\sigma^n$ and $F^n$ that are Lipschitz continuous and satisfy $\mathbf{H}_2$, $\mathbf{H}_3'$, $\mathbf{H}_5$ and $\mathbf{H}_6$ with constants that are uniform in $n$, and such that $b^n,\sigma^n$ and $F^n$ converges uniformly to $b,\sigma$ and $F$ on any compact subset of $H$. Consider the following three stochastic evolution equations 
$$dX_t=A X_t dt+b(X_t)dt+(-A)^{1/2}F(X_t)dt+\sigma(X_t)dW_t,\quad X_0=x,$$
$$dX^n_t=A X^n_t dt+b^n(X^n_t)dt+(-A)^{1/2}F^n(X^n_t)dt+\sigma^n(X^n_t)dW_t,\quad X^n_0=x,$$
and 
$$d\widetilde{X}^n_t=A \widetilde{X}^n_t dt+b^n(\widetilde{X}^n_t)dt+(-A)^{1/2}F^n(\widetilde{X}^n_t)dt+\lambda (X_t-\widetilde{X}_t^n)dt 1_{t\leq\tau}+\sigma^n(\widetilde{X}^n_t)dW_t,\quad \widetilde{X}_0^n=x,$$
where $\tau$ is a stopping time to be determined.


Given a compact subset $K\subset H$ with $x\in K$, denote by $$\Delta_K^n:=\sup_{y\in K}\|b^n(y)-b(y)\|+\|\sigma^n(y)-\sigma(y)\|+\|F^n(y)-F(y)\|,$$
and set $\tau_K^n:=\inf\{t\geq 0:\|X_t-\widetilde{X}_t^n\|\geq 2\Delta_K^n\}.$ Also denote by $\theta_K:=\inf\{t\geq 0: X_t\notin K\}.$ We set $$\tau=\tau_K^n\wedge\theta_K$$ and $$\lambda=({\Delta_K^n})^{\gamma -1}$$ 
for some value of $\gamma>0$ to be fixed later.

Arguing as in \eqref{variationineq}, we deduce that for any $T>0$ we can find a constant $C$ (uniform in $n$) such that
\begin{equation}\label{burgersvariationineq}
d_{TV}(\operatorname{Law}(P_nX^n|_{[0,T]}),\operatorname{Law}(P_n\widetilde{X}^n|_{[0,T]}))\leq C T^{1/2}(\Delta_K^n)^\gamma.\end{equation}

For $0\leq t\leq \tau$, assume for simplicity that $\Delta_K^n\in[0,1)$, we may compute via triangle inequality that for some universal constant $C>0$,
$$
    \|b(X_t)-b^n(\widetilde{X}_t^n)\|\leq M(2\Delta_K^n)^{\alpha}+\Delta_K^n\leq C (\Delta_K^n)^\alpha,\quad t\leq \tau
$$ 
$$\|\sigma(X_t)-\sigma^n(\widetilde{X}_t^n)\|\leq M(2\Delta_K^n)^\beta+\Delta_K^n\leq C (\Delta_K^n)^\beta,\quad t\leq\tau,$$
and 
 $$\|F(X_t)-F^n(\widetilde{X}_t^n)\|\leq M(2\Delta_K^n)^{\zeta}+\Delta_K^n\leq C (\Delta_K^n)^\zeta,\quad t\leq \tau,$$
where $M$ is the constant appearing in Assumptions $\mathbf{H}_2$, $\mathbf{H}_3'$ and $\mathbf{H}_6$.


A direct computation yields
$$\begin{aligned}
\|X_t-\widetilde{X}_t^n\|&\leq e^{-\lambda t}\left\|\int_0^t S(t-s)e^{\lambda s }[b(X_s)-b^n(\widetilde{X}_s^n)]ds\right\|\\&+\left\|e^{-\lambda t}\int_0^t S(t-s)e^{\lambda s }[\sigma(X_s)-\sigma^n(\widetilde{X}_s^n)]dW_s\right\|\\&+\left\|\int_0^t e^{-\lambda(t-s)}S(t-s)(-A)^{1/2}[F(X_s)-F^n(\widetilde{X}_s^n)]ds\right\|
.\end{aligned}$$

Now arguing as in \eqref{complementary}, using the auxiliary estimate \eqref{burgersusefulestimate}, note that we choose $\lambda:=(\Delta_K^n)^{\gamma -1}$, we deduce that 
 for each $\eta\in(0,\eta_0)$ and $m\in\mathbb{N}_+$, we may find a constant $C=C_{\eta,m}$ satisfying
\begin{equation}\label{burgerscomplementary}\mathbb{P}(\sup_{t\in[0,\tau]}\|X_t-\widetilde{X}_t^n\|>C (\Delta_K^n)^{1+\alpha-\gamma}+C (\Delta_K^n)^{\frac{1-\gamma}{2}+\zeta}+C(\Delta_K^n)^{\frac{1-\gamma}{2}\eta+\beta}R)\leq \frac{C}{R^m},\quad R\geq 2.\end{equation}

By our assumption $\alpha\in(0,1]$, $\beta\in(1-\frac{\eta_0}{2},1]$ and $\zeta\in(\frac{1}{2},1]$, we can find $\eta\in(0,\eta_0)$ sufficiently close to $\eta_0$ and $\gamma\in(0,1)$ sufficiently close to $0$, such that the following holds at the same time:
\begin{equation}
    \label{burgerscondition2}
\begin{cases}
\gamma\in(0,\alpha)\\
\frac{1-\gamma}{2}+\zeta>1,\\
\frac{1-\gamma}{2}\eta+\beta>1.\\
\end{cases}\end{equation}
Consequently, the powers of $\Delta_K^n$ in the bracket of \eqref{burgerscomplementary} are all larger than one.

Arguing as in \eqref{convergeinprob}, we deduce that for any $\kappa>0$,
\begin{equation}
   \label{burgersconvergeinprob} 
\mathbb{P}(\sup_{t\in[0,T\wedge \theta_K]} \|X_t-\widetilde{X}_t^n\|>\kappa)\to 0,\quad n\to\infty.\end{equation}


The remaining proof of weak uniqueness follows from the same argument as those in Theorem \ref{theorem1.1}. We remark that the result of Proposition \ref{proposition1.2} carries over to the more general case with Burgers type drift \eqref{burgersequation}, that is, fix $T>0$, for any $\epsilon>0$ we can find a compact set $K\subset H$ containing the initial value $x\in H$ such that $\mathbb{P}(\theta_K\leq T)<\epsilon.$ It suffices to go through the estimates in Appendix \ref{appendixB} and notice that the arguments in Appendix \ref{appendixA} can carry over identically.
\end{proof}


\subsection{Contracting distance and exponential ergodicity}
We now prove Theorem \ref{burgerstheorem2}. It is clear that we only need to construct a distance $d_{N,\gamma}$ such that the consequences of Theorem \ref{contractionmain}, which are
\begin{equation}\label{burgersest1}d_{N,\gamma}(\operatorname{Law}(X_t^x),\operatorname{Law}(X_t^y))\leq \theta  d_{N,\gamma}(x,y),\quad \text{ given }\|x\|\leq D,\|y|\leq D,\end{equation}
and 
\begin{equation}\label{burgersest2}d_{N,\gamma}(\operatorname{Law}(X_t^x),\operatorname{Law}(X_t^y))\leq \theta  d_{N,\gamma}(x,y),\quad  \text{ given } d_{N,\gamma}(x,y)<1,\end{equation}
hold true for some $\theta\in(0,1)$ depending on $D$ and $t$. The spectral gap and exponential ergodicity results then follow at once. 

The estimate \eqref{burgersest1} is easy to establish. Arguing as in \eqref{finalconclusion}, we deduce similarly that
\begin{equation}\label{burgersfinalconclusion}\inf_{\|x\|\leq D}\mathbb{P}(\|X_t^x\|\leq\delta)\geq\frac{1}{L(D,\delta)}.\end{equation}
Then use an independent coupling, we deduce as in \eqref{largecontraction} that 
\begin{equation}\label{burgerslargecontraction}
\begin{aligned}
    d_{N,\gamma}(\operatorname{Law}(X_t^x),\operatorname{Law}(X_t^y))&\leq d_{N,\gamma}(X_t^x,X_t^y)\\&\leq 1-\frac{1}{2}\left(\inf_{\|z\|\leq D}\mathbb{P}(\|X_t^z\|\leq\frac{1}{2^{1+1/\gamma}N^{1/\gamma}})\right)^2<1.\end{aligned}
\end{equation}
for any $(x,y)\in H\times H$ with $\|x\|\leq D$ and $\|y\|\leq D$.
This completes the proof of \eqref{burgersest1}, and all that remains is to establish \eqref{burgersest2}.

We start to establish \eqref{burgersest2}. Fix two initial values $x,y\in H$. Consider the processes
\begin{equation}\label{burgerseqx}dX_t=AX_t dt+b(X_t)dt+(-A)^{1/2}F(X_t)dt+\sigma(X_t)dW_t,\quad X_0=x,\end{equation}
\begin{equation}\label{burgerseqy}dY_t=AY_t dt+b(Y_t)dt+(-A)^{1/2}F(Y_t)dt+\sigma(Y_t)dW_t,\quad Y_0=y,\end{equation}
where we set $$\tau=\tau_{x,y}:=\inf\{t\geq 0:|X_t-\widetilde{Y}_t|\geq 2\|x-y\|\},$$
and set $\lambda:=\|x-y\|^{\gamma -1}$ for some $\gamma\in(0,1)$ to be determined later. 
Consider also
\begin{equation}\label{burgerscontrolprocess}
d\widetilde{Y}_t=A\widetilde{Y}_t dt+b(\widetilde{Y}_t)dt+(-A)^{1/2}F(\widetilde{Y}_t)dt+\lambda(X_t-\widetilde{Y}_t)dt1_{t\leq\tau}+\sigma(\widetilde{Y}_t)dW_t,\quad \widetilde{Y}_0=y.\end{equation}

Then arguing as in \eqref{controlgirsanov}, we deduce that for any $T>0$ we can find $C$ such that 
\begin{equation}
    \label{burgerscontrolgirsanov}
d_{TV}(\operatorname{Law}(Y|_{[0,T]}),\operatorname{Law}(\widetilde{Y}|_{[0,T]}))\leq CT^{1/2} \|x-y\|^\gamma.\end{equation}

Then arguing through the mild formulation of $X_t$ and $\widetilde{Y}_t$ as in \eqref{difference}, we get that
\begin{equation}\label{burgersdifference}
\begin{aligned}
\|X_t-\widetilde{Y}_t\|\leq e^{-\lambda t}|x-y|&+e^{-\lambda t}\left\|\int_0^t S(t-s)e^{\lambda s}(b(X_s)-b(\widetilde{Y}_s))ds\right\|\\&+e^{-\lambda t}\left\|\int_0^t S(t-s)e^{\lambda s}(\sigma(X_s)-\sigma(\widetilde{Y}_s))dW_s\right\|\\&+\left\|\int_0^t e^{-\lambda(t-s)}S(t-s)(F(X_s)-F(\widetilde{Y}_s))ds\right\|.
\end{aligned}\end{equation}


Using the Hölder continuity $\mathbf{H}_2$, $\mathbf{H}_3'$ and $\mathbf{H}_6$ of $b$, $\sigma$ and $F$, the definition of the stopping time $\tau$ and Proposition \ref{stochasticinte}, we obtain as in \eqref{fififi} the following deviation estimate: for each $m\in\mathbb{N}_+$ and $\eta\in(0,\frac{1}{2})$, we may find some fixed constant $M=M_{m,\eta}>0$ such that for $R>0$,
\begin{equation}\label{burgersfififi}
    \mathbb{P}(\sup_{0\leq t\leq \tau\wedge T}(\|X_t-\widetilde{Y}_t\|- e^{-\lambda t}\|x-y\|)\geq  M(\lambda^{-1}\|x-y\|^{\alpha}+\lambda^{-\frac{1}{2}}\|x-y\|^\zeta+\lambda^{-\frac{1}{2}\eta}\|x-y\|^{\beta} R))\leq \frac{M}{R^m},
\end{equation}
where we also used the auxiliary estimate \eqref{burgersusefulestimate}. Recall our choice $\lambda=\|x-y\|^{\gamma -1}$. We now choose $\gamma>0$ sufficiently small such that \eqref{burgerscondition2} is satisfied. 

Then we find some  $0<\chi<\min(\alpha-\gamma,\beta+\frac{1-\gamma}{2}\eta-1,\zeta+\frac{1-\gamma}{2}-1)$ and set furthermore $$R=\|x-y\|^{-\chi}.$$ 
Arguing as in \eqref{1.111} and \eqref{deviationestimate}, we conclude that 
\begin{equation} \label{burgersdeviationestimate}
    \mathbb{P}(\|X_T-\widetilde{Y}_T\|\geq \frac{1}{2}\|x-y\|)\leq M \|x-y\|^{2\gamma}\wedge 1.
\end{equation}
Having worked out this short-time estimate, we can construct the distance $d_{N,\gamma}$ as desired. Arguing as in \eqref{goodgifts}, we obtain as in \eqref{localcontraction} that for a choice of $N_0$ and $\gamma$ depending on $t$,
\begin{equation}\label{burgerslocalcontraction}d_{N,\gamma}\left(\operatorname{Law}(X_t^x),\operatorname{Law}(X_t^y)\right)
\leq \theta_1 d_{N,\gamma}(x,y),\quad N\geq N_0,\quad d_{N,\gamma}(x,y)<1.\end{equation}
This completes the proof of \eqref{burgersest2}, and the whole proof of Theorem \ref{burgerstheorem2} now finishes.



\appendix
\section{Compactness of stochastic PDEs}\label{appendixA}
In this section we only need to assume the operator $A$ satisfies assumption \eqref{usual1}, instead of the much stronger assumption $\mathbf{H}_1$.
The following proposition will be quite useful (see for example Proposition 8.4 of \cite{da2014stochastic}):

\begin{proposition}\label{prop1.3}
If $S(t),t>0$, are compact operators and $0<\frac{1}{p}<\eta\leq 1$, then the operator $G_\eta$
\begin{equation}\label{factorization}G_\eta f(t)=\int_0^t (t-s)^{\eta -1}S(t-s)f(s)ds,\quad f\in L^p(0,T;H),t\in[0,T]\end{equation}
is compact from $L^p((0,T);H)$ into $C([0,T];H).$
\end{proposition}
The proof consists in verifying that for each $t\in[0,T]$, the set $\{G_\eta f(t):|f|_p\leq 1\}$ is relatively compact in $H$, and that $G_\eta f(t),t\in[0,T]$ is uniformly continuous in $t$ with respect to the operator norm, i.e. $|G_\eta f(t)-G_\eta f(s)|\leq \epsilon$ if $\|f\|_p\leq 1$, $|t-s|\leq\delta$. As the concept of a set being relatively compact is equivalent to it being totally bounded, we may first find a finite subset  $\mathfrak{A}\subset[0,T]$ and a relatively compact subset $K_\mathfrak{A}$ of $H$ such that the unit ball of $L^p$ maps to $K_\mathfrak{A}$ under $G_\eta f(t)$ for each $t\in\mathfrak{A}$. Then we use the continuity of $G_\eta f(t)$ in operator norm to find a relatively compact subset $K\subset H$ such that $G_\eta f(t)$ maps the unit ball of $L^p$ into $K$, for all $t\in[0,T]$. 

The operator $G_\eta$ is quite useful because of the following factorization formula:
for any adapted process $\phi\in L^p(\Omega\times[0,T];L(H,H)),$
\begin{equation}
    \int_0^t S(t-s)\phi(s)dW_s=\frac{\sin\pi\eta}{\pi} G_\eta Y(t),
\end{equation}
where 
\begin{equation}
    Y(t)=\int_0^t (t-s)^{-\eta} S(t-s)\phi(s)dW_s.
\end{equation}
This expansion $Y(t)$ allows us to make use of the semigroup assumption $\eqref{usual1}$. 


Before we proceed, we note that the solution to the SPDE \eqref{evolutionequation} can be represented as
\begin{equation}\label{expansionrepresent}X_t=S(t)x+G_1 b(t)+\frac{\sin\pi\eta}{\pi}G_\eta \sigma(t),\end{equation}
with $b(t)=b(X_t)$
and $\sigma(t)=\int_0^t (t-s)^{-\eta} S(t-s)\sigma(X_s)dW_s.$


Under the linear growth assumption $\mathbf{H_5}$ and the semigroup assumption \eqref{usual1}, one can find a constant $C_T>0$ such that 
\begin{equation}\label{momentestimate}
\sup_{t\in[0,T]}\mathbb{E}[\|X_t\|^p]\leq C_T(1+\|x\|^p),\end{equation} where $X$ is a solution to \eqref{evolutionequation} and $p\geq 2$. The proof can be found for example in Theorem 7.5 of \cite{da2014stochastic}. More precisely, we need to find Lipschitz approximations of the coefficients $b$ and $\sigma$, but as the resulting estimate is independent of the Lipschitz constant, we simily drop that approximation.

Now we can use \eqref{momentestimate} to estimate $b(t)$ and $\sigma(t)$. Via Young's inequality and BDG inequality,
\begin{equation}\label{youngbdg}\int_0^T \mathbb{E}[ \|\sigma(s)\|^p] ds\leq C_p\int_0^T\left(\int_0^s (s-r)^{-2\eta}\|S(s-r)\sigma(X_r)\|_2^2\right)^{p/2} ds,\end{equation}
which is further bounded, using assumption \eqref{usual1}, estimate \eqref{momentestimate} and the linear growth assumption $\mathbf{H}_5$, by $C(1|\|x\|^p)$ where $C$ is some universal constant. The estimate for $\int_0^T \mathbb{E}[\|b(s)\|^p]ds$ is similar. 

For any $0<p^{-1}<\delta\leq 1$ define 
\begin{equation}\label{blackboxs}\Lambda(R,\delta):=\{\omega\in C([0,T];H):\omega=G_\delta u,\int_0^T \|u(s)\|^p ds<R.\}\end{equation}
Denote also by $$\Xi(R):=\{\omega\in C([0,T];H):\omega(t)=S(t)x+w_1(t)+w_2(t),w_1\in \Lambda(R,1), w_2\in \Lambda(R,\eta)\},$$
then $\Xi(R)$ is relatively compact in $C([0,T];H)$ for any $R>0$, thanks to Proposition \ref{prop1.3}.

Moreover,  $\mathbb{P}(X|_{[0,T]}\notin \Xi(R))$ converges to $0$ as $R\to\infty$, thanks to the boundedness of  $\mathbb{E}[\|\sigma(\cdot)\|_{L^p([0,T];H}]$ and $\mathbb{E}[\|b(\cdot)\|_{L^p([0,T];H}]$, see \eqref{youngbdg}. 



Now we can prove Proposition \ref{proposition1.2}.
\begin{proof}
For each $t\in[0,T]$ denote by $\Xi(R)_t$ the projection of $\Xi(R)$ onto the subspace $\{t\}\times H$, and identify $\{t\}\times H$ with $H$. Set $K:=\cup_{t\in[0,T]}\Xi(R)_t$. By the argument after the statement of Proposition \ref{prop1.3}, the set $K$ is relatively compact in $H$ for any $R>0$. It suffices to take $R$ sufficiently large to guarantee $\mathbb{P}(\theta_K\leq T)<\epsilon.$
\end{proof}


\section{Existence of weak mild solutions}\label{appendixB}
In this section we assume the densely defined operator $A$ has eigenfunctions $e_k$ forming an orthonormal basis of $H$, with eigenvalues $Ae_k=-\lambda_k e_k$. Assume that $\sum_k\frac{1}{\lambda_k}<\infty.$ Finally assume that \eqref{usual1} is satisfied by the semigroup $S(t)$.

We first quote the following compactness result (see \cite{priola2022correction}, Proposition 11).

\begin{proposition}\label{propb1}
    Given $p>2$. The operator $Q:L^p([0,T];H)\to C([0,T];H)$
    $$Qf(t):=\int_0^t (-A)^{1/2}S(t-s)f(s)ds,\quad f\in L^p([0,T];H),t\in[0,T]$$
    is compact. 
\end{proposition}
Now we prove Theorem \ref{theoreminappendixB}, the existence of weak mild solutions. The proof is a generalization of the argument in \cite{priola2022correction}, Section 4, so we only give a sketch.

\begin{proof}
Denote by $\pi_m$ the orthogonal projection of $H$ onto the subspace spanned by the first $m$ eigenvalues $e_1,\cdots,e_m$. We write $A_m=A\circ \pi_m$. Using the weak existence result in \cite{gkatarek1994weak}, for each $m$ we can construct weak mild solutions to the SPDE 
\begin{equation}\label{approxSPDE}dX^m_t=A X^m_t dt+ b(X^m_t)dt+(-A_m)^{1/2}F(X^m_t)dt+\sigma(X^m_t)dW_t.\end{equation}
We can prove that for some $p>2$,
\begin{equation}\label{momentunis}\sup_{m\geq 1}\sup_{t\in[0,T]}\mathbb{E}\|X^m_t\|^p= C_p<\infty.\end{equation}
To obtain \eqref{momentunis} we need to control 
$$\left\|\int_0^t S(t-s)(-A_m)^{1/2}F(X_s^m)ds\right\|^p_H$$ via a Gronwall argument, which is done in Section 4 of \cite{priola2022correction}. We also need to control $$\left\|\int_0^t S(t-s)
\sigma(X_s^m)dW_s\right\|^p_H$$ via a Gronwall argument, which can be found in chapter 8 of \cite{da2014stochastic} (utilizing the mapping $G_\eta$ defined in \eqref{factorization}, Young's inequality and the assumption \ref{usual1} on the semigroup $S(t)$.)

Now denote by $F_m:=\pi_m\circ F$, we learn from \eqref{momentunis}  and the linear growth property of $F$ that for any $T>0$, 
\begin{equation}
    \label{uniest12}
\sup_{m\geq 1}\mathbb{E}\int_0^T \|F_m(X^m_t)\|_H^pdt<\infty.\end{equation}

In the spirit of the decomposition \eqref{expansionrepresent}, we observe that the solution $X_t^m$ to \eqref{approxSPDE} can be reformulated as
$$X_t^m= S(t)x+G_1 b(X^m_\cdot)(t)+\frac{\sin\pi\eta}{\pi}G_\eta \sigma(X^m_\cdot)(t)+QF^n(X^m_\cdot)(t),$$
where $G_1$ and $G_\eta$ are defined in Appendix \ref{appendixA}. By $G_1b(X_\cdot^m)(t)$ we mean that we consider the function $f:s\mapsto b(X_s^m)$, then compute $G_1(f)$, and evaluate the resulting function at time $t$. The same interpretation applies to $QF^m(X_\cdot^m)$(t). The case of $G_\eta\sigma(X_\cdot^m)(t)$  is slightly different, where we consider the function $f:s\mapsto (t-s)^{-\eta}S(t-s)\sigma(X_s^m)dW_s$.


Now for any $R>0$ define 
$$Q(R):=\{\omega\in C([0,T];H):\omega=Q u,\int_0^T \|u(s)\|^p ds<R,\}$$
and define 
$$\begin{aligned}
\Xi(R):=\{&\omega\in C([0,T];H):\omega(t)=S(t)x+w_1(t)+w_2(t)+w_3(t),\\&w_1\in \Lambda(R,1), w_2\in \Lambda(R,\eta),w_3\in Q(R)\},\end{aligned}$$
where $\Lambda(R,1)$ and $\Lambda(R,\eta)$ are defined in \eqref{blackboxs}.
\end{proof}
By Proposition \ref{prop1.3} and \ref{propb1}, $\Xi(R)$ is compact in $C([0,T];H)$ for any $R>0$. By the uniform moment estimate \eqref{uniest12} and the corresponding one for $b(X_t^m)$ and $\sigma(X_t^m)$\footnote{For $\sigma(X_t^m)$ we need (uniform in $m$) $L^p$- estimates for the function $f^m:s\mapsto (t-s)^{-\eta}S(t-s)\sigma(X_s^m)dW_s$, which can be obtained via the infinite dimensional Burkholder inequality, the semigroup assumption \eqref{usual1} and the linear growth property of $\sigma$.}, we deduce that $$P((X_t^m)_{0\leq t\leq T}\notin \Xi(R))\to 0 \text{ as } R\to\infty,$$ uniformly over $m\geq 1$. By the Prokhorov theorem the laws of $(X_t^m)_{0\leq t\leq T}$ are tight in $C([0,T];H)$.

The next step is to use Skorokhod representation theorem to enlarge the probability space and take the limit of the tight sequence, using continuity of the coefficients. The argument can be found in Section 4 of \cite{priola2022correction} or Section 2 of \cite{gkatarek1994weak}
, so we omit the details.



\section*{Acknowledgements}
The author thanks Professor James Norris for helpful suggestions on this paper.


\printbibliography

\end{document}



For finite dimensional diffusion $dX_t=b(X_t)dt+\sigma(X_t)dW_t,$ it is well-known that the assumptions $\mathbf{H_3}$, $\mathbf{H_4}$ and $\mathbf{H_5}$ on $\sigma$ are sufficient to guarantee well-posedness of the martingale problem, while the assumption on $b$ can be more general, including bounded measurable  or singular integrable functions, see for example \cite{xia2020lq}. A Sobolev type bound on $\|\nabla \sigma\|$ is required to guarantee the weak solution is a strong one. Therefore, in our Theorem \ref{theorem1.1}, we only prove uniqueness in probability. We believe that the assumption $\mathbf{H_3}$ is close to optimal, while $\mathbf{H_2}$ can clearly be weakened, say allowing a bounded continuous drift. To be consistent with our exponential ergodiity results, we only work with the Hölder assumption $\mathbf{H_2}$ for the drift $b$.



\begin{remark}
While applying \eqref{BDG}, the exponent of $\lambda$ on the right hand side is $\lambda^{-\frac{p}{2}}$ instead of $\lambda^{-p}$. This is the only place that forces us to assume the diffusion coefficient $\sigma$ is $\beta$-Hölder for $\beta\in(\frac{1}{2},1]$. If an alternative estimate can be derived that gives $\lambda^{-p}$, we can prove well-posedness of the stochastic heat equation \eqref{evolutionequation} in the full Hölder regime $\beta\in(0,1]$.
\end{remark}




{Lipschitz case.} Assume that
    
    $\mathbf{H}_1'$: The semigroup $(S(t))_{t\geq 0}$ satisfies $\int_0^1 \|S(t)\|_2^2<\infty$,  and 
    
    $\mathbf{H_2'}$: For some $\alpha\in[0,1]$ and $M>0,$
$$\|b(x)-b(y)\|\leq M\|x-y\|^\alpha,\quad \|x-y\|\leq 1.$$ If $\alpha=0$, we require that $b$ is continuous. Moreover, assume that

    $\mathbf{H}_3'$: For some $M>0$, $$\|\sigma(x)-\sigma(y)\|\leq M\|x-y\|,\quad x,y\in H.$$
    Assume also that $\mathbf{H}_4$ and $\mathbf{H_5}$ holds. Then the conclusion of Theorem \ref{theorem1.1} holds.
    {General case.}
    
    
    
    Under $\mathbf{H}_1'$, we may use the crude estimate 
$$\int_0^t \|S(t-s)\|_2^2 e^{2\lambda s}ds\leq M e^{2\lambda t}$$
in place of \eqref{summabilityfinal}, and obtain for each $m\geq 2,$
\begin{equation}\mathbb{P}(\sup_{t\in[0,T]}\|Z(t)\|\geq C_m \|\phi\|_\infty R)\leq \frac{C_{m,\eta}}{R^m},\quad \text{for each }R\geq 2,\end{equation}
in place of \eqref{1/4conclude}.



\begin{remark}
When $\mathbf{H_2'}$ holds but $\mathbf{H_2}$ fails, that is when $b$ is continuous and locally bounded, Theorem \ref{theorem1.4} shows the solution has Feller property in addition to weak uniqueness. While it is possible to show uniqueness of martingale solution via Girsanov transform, one cannot in general prove the Feller property via Girsanov transform. Thus Theorem \ref{theorem1.4} also brings something new in this case.
\end{remark}






It implies the weaker condition:  for some $\eta>0$, 
\begin{equation}\label{weakassumption}\int_0^1 t^{-2\eta}\|S(t)\|_2^2<\infty,\end{equation}
where $\|\cdot\|_2$ denotes the Hilbert-Schmidt norm on $H$. Under this weaker condition we are only able to prove weak uniqueness when the diffusion coefficient is Lipschitz continuous. We can sort of interpolate between the strong assumption $\mathbf{H_1}$ and the weak assumption \eqref{weakassumption}, which is the content of Theorem \ref{theorem1.4



We briefly compare SDDEs and the stochastic heat equation (SHE) with non-Lipschitz coefficients. As already discussed, although in some cases one can prove the strong Feller property for SHEs, we can hardly obtain the Bismut-Li type estimate \eqref{bismut-li} if coefficients are non-Lipschitz, and this is very similar to the problem that arises in the SDDE setting with Lipschitz coefficients. The primary difficulty for SHEs is that it is driven by an infinite dimensional space-time white noise, which requires much more careful technical treatments than SDDEs driven by a finite-dimensional Brownian motion. The key is to utilize the smoothing properties of the Laplacian $\Delta$. On the other hand, we do not have to keep track of the memory process for SHEs, so that the analysis can be done on a state-dependent scale. This simplifies some arguments that are involved in the SDDE setting.
