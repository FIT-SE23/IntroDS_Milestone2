\documentclass[conference,single]{IEEEtran}
% \documentclass[12pt, draftclsnofoot, onecolumn]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{bm}
\usepackage{algorithmic}
% \usepackage{subcaption}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{capt-of}  % <---
\usepackage{cuted}    % <===
\usepackage{multirow}
\usepackage{lipsum}
\usepackage{hyperref}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}


\title{Multi-Task Learning for massive MIMO CSI Feedback\\}

\author{\IEEEauthorblockN{Sharan Mourya,}
% \IEEEauthorblockA{\textit{IIT, Hyderabad} \\
% Hyderabad, India \\
% sharan.mourya@5g.iith.ac.in}\\
\and
\IEEEauthorblockN{SaiDhiraj Amuru,}
% \IEEEauthorblockA{\textit{IIT, Hyderabad} \\
% Hyderabad, India \\
% asaidhiraj@ee.iith.ac.in}
\and
\IEEEauthorblockN{Kiran Kumar Kuchi}
% \IEEEauthorblockA{\textit{IIT, Hyderabad} \\
% Hyderabad, India \\
% kkuchi@ee.iith.ac.in}
}
% \author{Sharan Mourya, SaiDhiraj Amuru, Kiran Kuchi
% \thanks{Sharan Mourya is with the Department of Electrical Engineering, Indian Institute of Technology, Hyderabad, India}
% \thanks{A. SaiDhiraj is with the Faculty of
% Department of Electrical Engineering, Indian Institute of Technology, Hyderabad, India}
% \thanks{K. Kuchi is with the Faculty of
% Department of Electrical Engineering, Indian Institute of Technology, Hyderabad, India}
% }

% \author{\IEEEauthorblockN{ Sharan Mourya}
% \IEEEauthorblockA{\textit{IIT, Hyderabad} \\
% % Hyderabad, India \\
% sharan.mourya@5g.iith.ac.in}\\
% \and
% \IEEEauthorblockN{SaiDhiraj Amuru}
% \IEEEauthorblockA{\textit{IIT, Hyderabad} \\
% % Hyderabad, India \\
% asaidhiraj@ee.iith.ac.in}
% \and
% \IEEEauthorblockN{Kiran Kumar Kuchi}
% \IEEEauthorblockA{\textit{IIT, Hyderabad} \\
% % Hyderabad, India \\
% kkuchi@ee.iith.ac.in}}


\maketitle

\begin{abstract}
Deep learning-based massive MIMO CSI feedback has received a lot of attention in recent years. Now, there exists a plethora of CSI feedback models that exploit a wide variety of deep learning models and techniques ranging from convolutional neural networks (CNNs) to the recent attention-based transformer networks. Most of the models are based on auto-encoders (AE) architecture with an encoder network at the user equipment (UE) and a decoder network at the gNB (base station). However, these models are trained for a single user in a single channel scenario, making them ineffective in scenarios where a gNB is addressing various users while each user has different abilities and may employ a different CSI feedback encoder network and also in scenarios where the users are employing the same encoder network but are experiencing different channel conditions. In this work, we address these specific issues by exploiting the techniques of multi-task learning (MTL) in the context of massive MIMO CSI feedback.
\end{abstract}

\begin{IEEEkeywords}
CSI Feedback, Multi-Task Learning, CSINet, CLNet, STNet.
\end{IEEEkeywords}

\section{Introduction}
With the introduction of Deep Learning techniques \cite{csinet}, channel state information (CSI) feedback for frequency division duplex (FDD) systems has seen an incredible increase in performance and a sizeable reduction in complexity and power consumption. CSINet \cite{csinet} was the first to introduce an  auto-encoder (AE) \cite{vae} based on Convolutional Neural Networks (CNNs) to the compression problem. CSINet employed a fixed receptor size for the CNN to capture the spatial correlation in the angular-delay domain. In \cite{crnet}, a similar approach with multiple receptor sizes was proposed. CLNet\cite{clnet} introduced a simple technique to combine the real and imaginary values of a channel matrix, unlike other models that treated them separately. STNet \cite{stnet} proposed a transformer \cite{transformer} network that has state-of-the-art performance with $1/10^{th}$ resource utilization of other transformer models.\par
All these neural networks are auto-encoder models with an encoder network at the user equipment (UE) and a decoder network at the gNB (base station). The encoder compresses the channel matrix by a factor, which is called the\textit{ compression ratio} and transmits it to the decoder to reconstruct the channel matrix. This encoder-decoder model is then trained in a single-user scenario with either indoor or outdoor channel conditions. This trained model only works in that specific scenario, which is often not useful in reality as the gNB addresses many users with different channel conditions at once. Thus, a model trained for only a specific scenario cannot be employed as a general solution. In addition, there exist numerous CSI feedback models with varying complexities and processing capabilities. Thus, in a multi-user scenario, every user could use a different CSI feedback model whichever meets their requirements. Consequently, the decoder network at gNB has to support a variety of encoder networks to perform well. This is where multi-task learning (MTL) is essential wherein a single model can be trained with multiple datasets i.e, multiple channel scenarios or multiple auto-encoder models.
\par
In \cite{past}, Li et al. proposed multi-task learning techniques for a multi-scenario use case where users are experiencing different channel conditions. However, they restricted the users to having the same encoder architecture to transmit CSI feedback. This limitation is not practical as different users employ different architectures depending on their power and memory requirements. In this letter, we address this issue by allowing users to have different encoder architectures as well as different channel conditions. They also designed a new neural network to address the multi-scenario case whereas we propose to use MTL techniques with existing high-performance models, making our approach generalizable to any model. Zhang et al. \cite{diff} worked on reducing the memory and training time requirements of the existing CSI feedback models by using multi-task learning. Nevertheless, their approach was applicable only to a single-user and single-channel scenario. In contrast, we propose a methodology to use the existing CSI feedback models for multi-user and multi-scenario conditions while reducing resource utilization.   \par This paper is organized as follows: In Section II we motivate the problem, in Section III we describe the system model, in Section IV we summarize MTL and its techniques applicable to massive MIMO CSI feedback and in Section V we present numerical results performed on COST2100 \cite{cost} dataset and finally conclude in section VI.



\section{Motivation}
In the context of CSI feedback, user distributions in a cell can be broadly classified into (also shown in Fig.{~\ref{cases}})
\begin{enumerate}
    \item \textit{Single-Scenario Single-Model (SSSM)}: Each user is experiencing the same channel conditions and all are using the same encoder model.
    \item \textit{Single-Scenario Multi-Model (SSMM)}: All users are experiencing the same channel conditions but each user is using a different encoder model.
    \item \textit{Multi-Scenario Single-Model (MSSM)}: Each user is experiencing different channel conditions but all are using the same encoder model.
    \item \textit{Multi-Scenario Multi-Model (MSMM)}: Each user is experiencing different channel conditions and is using a different encoder model.
\end{enumerate}
\begin{figure}[h]
\centering
\includegraphics[width=0.6\linewidth]{cases.png}
\captionof{figure}{Classification of user distributions. Background color represents channel conditions, i.e., a single color indicates that the channel is the same throughout the users and a color gradient indicates that the channel varies across users. User color indicates the encoder model employed by the user, i.e., same-colored users use the same encoder models and different-colored users use different encoder models.}
\label{cases}
\end{figure}
Users in a cell can be grouped according to these distributions and in reality, gNB might be dealing with more than one user distribution at once. In all these cases, gNB has to decode the CSI feedback from varied user distributions but the decoder is only trained for the SSSM case. The usage of this decoder in the other three cases results in a significant drop in performance. For example, consider three CSI feedback models CSINet\cite{csinet}, CLNet\cite{clnet}, and STNet\cite{stnet} trained for indoor channel scenarios at a $1/4$ compression ratio. We then paired CSINet's encoder with the decoders of CLNet and STNet and vice versa. Table I shows the normalized mean-squared error (NMSE) \cite{csinet} performance of each encoder model paired with every other decoder model on a COST 2100 dataset \cite{cost}.



\begin{table}[h!]
\caption{NMSE at 1/4 compression ratio and indoor channel conditions}
\centering
\begin{tabular}{|c|c|c|c|} 
\hline
 Model & CSINet Decoder& CLNet Decoder & STNet Decoder\\
 \hline
 CSINet Encoder & -17.36 & 14.53 & 15.56 \\ 
 \hline
 CLNet Encoder& 13.52 & -29.16 & 16.31 \\
 \hline
 STNet Encoder & 10.46 & 15.13 & -31.81 \\
 \hline
\end{tabular}\\
\end{table}
From Table I, we see that the performance degrades when not using the right encoder-decoder pair. Although all three models are trained for exactly the same scenario, they seem to have no correspondence between them. This is more profound if we use the model trained for one channel condition to evaluate a different channel condition. Table II lists the NMSE values of CSINet trained in one scenario and evaluated in another scenario. Performance degradation is evident where ever the right scenario is not evaluated.
\begin{table}[h!]
\centering
\caption{NMSE at 1/4 compression ratio for CSINet}
\begin{tabular}{|c|c|c|} 
\hline
 Model & CSINet (Indoor) & CSINet (Outdoor)\\
 \hline
 CSINet (Indoor) & -17.36 & 13.29\\ 
 \hline
 CSINet (Outdoor)& 11.74 & -8.75\\
 \hline
\end{tabular}\\
\end{table}
Tables I and II indicate that a single model cannot be employed to decode CSI feedback in multi-user and multi-scenario conditions. One way to mitigate this is shown in Fig.{~\ref{switch}} where we use multiple decoders at gNB each corresponding to a different auto-encoder model and switch between these depending on the channel condition and the encoder that the user has employed, which can be identified by a specifier sent along with CSI feedback. This not only increases the feedback overhead but also makes the gNB's design more complicated. This approach is also not scalable as the number of decoders at gNB grows proportionally with the number of different encoders used by users in the cell. 
\begin{figure}[h]
\centering
\includegraphics[width=3in]{switch.png}
\captionof{figure}{gNB with multiple decoders. Here, four users have four different encoders whose corresponding decoders are available at the gNB. So, whenever the gNB serves a user, it automatically switches to the corresponding decoder.}
\label{switch}
\end{figure}\\
So the need for generalizing the CSI feedback model arises where ideally the gNB uses a single decoder model to decode CSI feedback from varied user distributions as shown in Fig.{~\ref{one}}. One way to solve this problem is by using multi-task learning (MTL)\cite{mtl} where we define each scenario and encoder model as a task and train the gNB's decoder with all the tasks together to decrease the complexity of the gNB.
\begin{figure}[h]
\centering
\includegraphics[width=3in]{one.png}
\captionof{figure}{gNB with a single decoder. Here, four users have four different encoders and a single decoder has to be trained to decode the CSI feedback from all the encoders.}
\label{one}
\end{figure}
For the purpose of this study, we consider two channel scenarios: indoor and outdoor, and two different auto-encoder models: CSINet, and STNet. However, the concepts in this paper can be generalized to any number of models and scenarios. Now, each user has two attributes: \{\textit{Scenario, Encoder Model}\}, and those users with the same attributes fall under the same task.

\section{System Model}

Let's consider an orthogonal frequency division multiplexing (OFDM) system with $\Tilde{N}_{c}$ sub-carriers, and $N_{t}\times1$ antennas i.e., $N_{t}$ antennas at the base station (gNB) and 1 antenna at the user equipment (UE). The received signal at UE on the $n^{th}$ sub-carrier can be expressed as
\begin{equation}
    y_{n} = \textbf{$\bm{\Tilde{h}_{n}}^{H}$}\bm{v_{n}}x_{n} + \textbf{$w_{n}$},
\end{equation}
where, $\bm{\Tilde{h}_{n}} \in \mathbb{C}^{N_{t}\times 1}$, $\bm{\Tilde{v}_{n}} \in \mathbb{C}^{N_{t}\times 1}$, $x_{n} \in \mathbb{C}$ and $w_{n} \in \mathbb{C}$ represent channel vector, precoding vector, symbol transmitted and additive noise on the $n^{th}$ sub-carrier.
The overall channel matrix is of the dimension $\Tilde{N}_{c} \times N_{t}$ and is expressed as
\begin{equation}
    \bm{\Tilde{H}} = \big[\bm{\Tilde{h}_{1},\Tilde{h}_{2},\cdots,\Tilde{h}_{\Tilde{N_{c}}}} \big]^{H}.
\end{equation}
The total number of feedback elements is $2N_{t}\Tilde{N}_{C}$ (for both real and imaginary parts of the channel) which is huge and impractical in real scenarios considering $N_{t}=32,64,\hdots$ and $\Tilde{N}_{C} = 1024,2048,\hdots$ for a massive MIMO system. So, we reduce the overhead by making the channel matrix sparser by transforming it into the angular-delay domain \cite{csinet}. This is accomplished by the following transformation
\begin{equation}
    \bm{\bar{H}} = \bm{F_{d}\Tilde{H}F_{a}^{H}},
\end{equation}

where, $\bm{F_{d}}$ and $\bm{F_{a}}$ are 2-D DFT matrices of dimensions $\Tilde{N}_{c}\times \Tilde{N}_{c}$ and $N_{t} \times N_{t}$ respectively. In the delay domain, the time delay between multipath arrivals lies within a limited period. Using this, we can truncate the matrix $\bm{\bar{H}}$ by only keeping the first $N_{c}$ rows where $N_{c}$ is chosen such that the remaining entries of $\bm{\bar{H}}$ are close to zero. We define this truncated matrix as $\bm{H}$ that has dimensions $N_{c}\times N_{t}$. Also, we split this matrix into real and imaginary parts and combine them as a third dimension similar to the RGB channels of an image. With this, the overall feedback overhead becomes $2N_{c}N_{t}$ which is significantly smaller than earlier as $N_{c}$ will only be a fraction of $\Tilde{N}_{c}$ (total number of sub-carriers). 
\par
Now that we have the sparsified channel matrix, $\bm{H}$, it is sent into the encoder-decoder architecture as shown in Fig.{~\ref{net}} where $\bm{H}$ is compressed into a 1-D vector of dimension $M \times 1$. Here, we define compression ratio as $\gamma = \frac{M}{2N_{c}N_{t}}$. This compressed channel matrix is sent back to gNB from UE on the uplink. gNB then decodes this feedback signal as $\bm{\hat{H}}$. This encoding and decoding process is defined as follows
\[s = f_{e}(\bm{H}),\] \[\bm{\hat{H}} = f_{d}(s),\]
where $f_{e}$, and $f_{d}$ denote the functions of the encoder and decoder, respectively. $s$ is the compressed code word and $\bm{\hat{H}}$ is the estimated channel matrix by the model.

\begin{figure}[h]
\centering
\includegraphics[width=3in]{ae.png}
\captionof{figure}{Auto-encoder model of CSI feedback.}
\label{net}
\end{figure}

\section{Multi-Task learning}
Multi-task learning is defined as the training of a model with a certain number of tasks where all the tasks or a subset of them are related but not identical. The relatedness between the tasks might have a constructive effect on the model improving each others' performance. This relatedness is a key factor in understanding the benefits of MTL. Users distributed according to SSSM or SSMM are highly correlated as opposed to the users corresponding to MSSM or MSMM because users experiencing similar channel conditions have similar encoder outputs. This also makes them easier to learn jointly by gNB's decoder. Task relatedness gives rise to two types of MTL models that we investigate in this study: architecture-based MTL model and training-based MTL model. Architecture-based MTL models accommodate special structures in the model itself to learn the task relatedness. This can be mainly divided into two types: hard parameter sharing and soft parameter sharing \cite{overview}. On the other hand, Training based MTL models don't have any special structures to learn the task relatedness but they aim to encode it into the learning model itself via regularization \cite{types}. This can be achieved by joint training as described in the next subsection.

\subsection{Training-based MTL}
\begin{figure}[h]
\centering
\includegraphics[width=0.85\linewidth]{prev.png}
\captionof{figure}{Joint training with the linear autoregressive loss for N tasks where each task is trained separately on the decoder by choosing a small batch size. Autoregression is achieved by adding the previous loss to the current loss.}
\label{prev}
\end{figure}

\subsubsection{Joint Training}
In every epoch, a small batch from the dataset of each task is trained on the model sequentially with all the tasks while calculating the loss for each task separately. After calculating the loss, we also add the loss from the previous training instance to the current training instance as shown in Fig.{~\ref{prev}}. So for dataset $i$, the loss function is defined as,
\begin{equation}
    loss\{i\} = loss\{i\} + \alpha \times loss\{i-1\}.
\end{equation}
Note that $i$ here means $i\pmod{N}$ as the training is cyclic but it's omitted in the equations hereafter for simplicity. This is a linear autoregressive model for the loss function where $\alpha$ is a regularization coefficient. With this, the model not only tries to learn the features of the current instance but also tries to keep its knowledge of the features from the previous instance. This facilitates the model to learn task relatedness making it effective in SSSM or SSMM user distributions as they have higher similarity between them. As the decoder in Fig.~\ref{prev} should learn the task relatedness from many encoder models, we propose to use a high-performance model like STNet\cite{stnet} as the decoder.

\subsection{Architecture-based MTL}

\subsubsection{Hard Parameter Sharing}
Task relatedness is captured by sharing a few layers across tasks while keeping several task-specific output layers as shown in Fig.{~\ref{hard}}.
\begin{figure}[h]
\centering
\includegraphics[width=2in]{hard.png}
\captionof{figure}{Decoder architecture with hard parameter sharing method to capture task relatedness.}
\label{hard}
\end{figure}
This method also greatly reduces the risk of overfitting as it adds inductive bias by providing an alternate hypothesis for the model to learn \cite{overview} which generalizes the solutions better.
\subsubsection{Soft Parameter Sharing}
In this method, each task has its own model and parameters but few layers are regularized to reduce the distance between the parameters as shown by constrained layers in Fig.{~\ref{soft}}. This encourages the parameters to be similar.
\begin{figure}[h]
\centering
\includegraphics[width=2in]{soft.png}
\captionof{figure}{Decoder architecture with soft parameter sharing method to capture task relatedness in gNB's Decoder.}
\label{soft}
\end{figure}
In the context of CSI feedback, hard parameter sharing is preferred as conditioning parameters across users in soft parameter sharing is computationally more complex and also consumes more power. In particular, for MSSM and MSMM distributions, the hard-sharing of parameters is effective as each task-specific layer can be assigned to a different channel scenario. Also, multi-scenario distributions don't share similarities between the tasks which makes it difficult to learn the tasks simultaneously using joint training.\par
We propose an approach for the hard sharing of parameters exploiting the decoder architecture of STNet \cite{stnet}. Fig.~\ref{stnet_decoder} depicts the decoder of STNet consisting of two parallel stems; CNN stem and transformer stem each designed for a specific task. The transformer stem captures the long-range correlation of the antennas to better reconstruct the channel matrix whereas the CNN stem supplements it by capturing the short-range details of the channel.

\begin{figure}[h]
\centering
   \includegraphics[width=0.7\linewidth]{stnet_decoder.png}
   \caption{Structure of STNet's decoder. It consists of two stems in parallel: CNN and transformer. The output of the CNN stem is used by the transformer stem to better reconstruct the channel.}
   \label{stnet_decoder} 
\end{figure}
\begin{figure}[h]
\centering
   \includegraphics[width=0.75\linewidth]{mssm.png}
   \caption{Proposed changes to the STNet decoder to allow the hard-sharing of parameters for two tasks. CNN stem is shared across the two tasks while the transformer stem is task specific. }
   \label{mssm} 
\end{figure}



As the transformer stem is the main contributor to the performance of the STNet, we make it task-specific while sharing the CNN stem across all tasks as shown in Fig.~\ref{mssm}. A task specifier should also be sent alongside CSI feedback to indicate which transformer stem to use. Obtaining this task specifier is outside the scope of this work, but a simple approach can be found in \cite{past}. We evaluate this modified STNet decoder in the next section.
\section{Results}
For simulation purposes, we consider a system with $32\times1$ antennas (i.e., 32 antennas at BS and 1 antenna at UE). We choose the COST2100 dataset with two scenarios: the indoor pico cellular scenario at 5.3GHz and the outdoor rural scenario at 300MHz. The training, validation, and test datasets consist of 100,000, 30,000, and 20,000 matrices, respectively. Mean Squared Error (MSE) with an Adam optimizer is the loss function.
\begin{equation}
    MSE = \frac{1}{B}\sum_{i=1}^{B} ||\bm{H}-\bm{\hat{H}}||^2,
\end{equation}
where $\bm{H}$ is the input channel matrix, $\bm{\hat{H}}$ is the reconstructed channel matrix as shown in Fig.~\ref{net}, and $B$ is the batch size. We use Normalised Mean Square Error (NMSE) as the performance metric which is defined as follows
\begin{equation}
    NMSE = \mathbb{E} \bigg\{\frac{||\bm{H}-\bm{\hat{H}}||^2}{||\bm{H}||^2}\bigg\}.
\end{equation}

We consider two auto-encoder models for our evaluation; CSINet\cite{csinet}, and STNet\cite{stnet}. The original NMSE values of these models when trained without any multi-task learning techniques are given in Table III. We will use these values to benchmark the MTL methods namely joint training and hard parameter sharing.
\begin{table}[h!]
\caption{Original NMSE values of CSINet and STNet}
\centering
\begin{tabular}{|c|c|c|c|c|c|} 
 \hline
Model \& Scenario & \multicolumn{1}{c|}{1/4} & \multicolumn{1}{c|}{1/16} & \multicolumn{1}{c|}{1/32} & \multicolumn{1}{c|}{1/64}\\
 \hline
 CSINet Indoor & -17.36 & -8.65& -6.24 &-5.84 \\ 
 \hline
  CSINet Outdoor & -8.75 & -4.51&  -2.81 &-1.93  \\
 \hline
 STNet Indoor & -31.81& -15.43&  -9.42 &-7.81  \\
 \hline
 STNet Outdoor & -12.91& -5.72&  -3.51 &-2.46  \\
 \hline
\end{tabular}\\
\end{table}

\subsection{Joint Learning}
Joint learning is advantageous in SSSM and SSMM scenarios due to the higher similarity between the tasks, so for this evaluation, we chose an indoor scenario with two encoder models: CSINet and STNet. We then trained these models on the STNet's decoder as per Fig.~\ref{prev}. The batch size was set to 50 and the regularization coefficient to 0.3 with a learning rate of 0.001. The obtained NMSE results are presented in Table IV.
\begin{table}[h!]
\caption{CSINet + STNet joint training}
\centering
\begin{tabular}{|c|c c|c c|} 
%  \hline
%   \multicolumn{5}{|c|}{NMSE}\\
 \hline
  Scenario & \multicolumn{2}{c|}{Indoor}\\
 \hline
Model& CSINet & STNet\\
 \hline
 1/4 & -19.10 & -25.32\\ 
 \hline
 1/16 & -10.92 & -14.63\\
 \hline
 1/32 & -8.68 & -9.24\\
 \hline
 1/64 & -6.22 & -6.90\\
 \hline
\end{tabular}\\
\end{table}

Comparing the NMSE values of CSINet between Tables III and IV, we notice that the performance of CSINet has improved when trained along with STNet. This is presented in Fig.~\ref{csinet} for various compression ratios. However, unlike CSINet the performance of STNet decreased when trained jointly. To understand this result better, we used the linear Zero-Forcing (ZF) transmit precoding\cite{stnet} to evaluate the overall spectral efficiency improvement of the communication system due to joint training. Although STNet's performance has reduced, it is evident from Fig.~\ref{csinet+stnet} that the combined spectral efficiency of CSINet and STNet when trained jointly is significantly higher than the combined spectral efficiency when trained independently.

\begin{figure}[h]
\centering
   \includegraphics[width=0.7\linewidth]{csinet.png}
   \caption{NMSE values of CSINet for various compression ratios in indoor channel scenarios when trained independently vs when trained jointly with STNet.}
   \label{csinet}
\end{figure}
\begin{figure}[h]
\centering
   \includegraphics[width=0.65\linewidth]{csinet+stnet.jpg}
   \caption{Combined spectral efficiency plots of CSINet and STNet when trained independently vs when trained jointly for an indoor scenario at 1/4 compression ratio. Spectral efficiency values at SNR=10dB
 are zoomed in and labeled for clarity. CR = compression ratio.}
   \label{csinet+stnet} 
\end{figure}

% \subsubsection{CLNet+STNet}
% \begin{figure}[h]
% \centering
%   \includegraphics[width=0.87\linewidth]{clnet.png}
%   \caption{NMSE values of CLNet for various compression ratios in indoor channel scenario when trained independently vs when trained jointly with STNet.}
%   \label{clnet}
% \end{figure}
% \begin{figure}[h]
% \centering
%   \includegraphics[width=0.75\linewidth]{clnet+stnet.jpg}
%   \caption{Combined spectral efficiency plots of CLNet and STNet when trained independently vs when trained jointly for an indoor scenario at 1/16 compression ratio. Spectral efficiency values at SNR=10dB
%  are zoomed in and labeled for clarity. CR = compression ratio}
%   \label{clnet+stnet} 
% \end{figure}
% Similarly, we also jointly trained the STNet decoder with the encoders of CLNet and STNet and presented the NMSE results in Table V. Except for the compression ratio of 1/4, CLNet's performance has also increased when trained jointly with STNet as shown in Fig.\ref{clnet}. However, the performance did not increase as much as it did for CSINet because CLNet performs extremely well even when trained independently due to which there isn't much room for improvement. 



% \begin{table}[h!]
% \caption{CLNet encoder+STNet encoder on STNet decoder}
% \centering
% \begin{tabular}{|c|c c|c c|} 
% %  \hline
% %   \multicolumn{5}{|c|}{NMSE}\\
%  \hline
%   Scenario & \multicolumn{2}{c}{Indoor} & \multicolumn{2}{c|}{Outdoor}\\
%  \hline
% Model& CLNet & STNet & CLNet & STNet \\
%  \hline
%  1/4 & -26.15 & -27.13 & -8.03 & -8.66 \\ 
%  \hline
%  1/16 & -11.77 & -14.83 & -4.44 & -4.63 \\
%  \hline
%  1/32 & -8.99 & -9.25 & -2.66 & -3.38\\
%  \hline
%  1/64 & -6.63 & -6.96 & -1.44 & -2.03\\
%  \hline
% \end{tabular}\\
% \end{table}


% We also performed spectral efficiency evaluation for this system using ZF precoding. As seen from Fig.\ref{clnet+stnet}, the combined spectral efficiency of CLNet and STNet trained jointly is higher than the combined spectral efficiency of CLNet and STNet when trained independently as shown in Fig.\ref{switch}. \par






\subsection{Hard Parameter Sharing}
\begin{figure}[h]
\centering
   \includegraphics[width=0.7\linewidth]{csinet_mssm.png}
   \caption{NMSE values of CSINet for various compression ratios in indoor channel scenario when trained with STNet in outdoor channel scenario using hard parameter sharing}
   \label{csinet_mssm} 
\end{figure}


\begin{figure}[h]
\centering
   \includegraphics[width=0.65\linewidth]{csinet+stnet_hard.jpg}
   \caption{Combined spectral efficiency plots of CSINet and STNet when trained independently vs when trained by hard sharing of parameters at 1/4 compression ratio. Spectral efficiency values at SNR=10dB are zoomed in and labeled for clarity. CR = compression ratio.}
   \label{csinet+stnet_hard} 
\end{figure}
As mentioned earlier, hard parameter sharing is efficient in MSSM and MSMM scenarios, so we chose two encoders in different scenarios: the CSINet encoder in the indoor scenario and the STNet encoder in the outdoor scenario. We then trained these models on the decoder shown in Fig.~\ref{mssm} while assigning each encoder to a different transformer stem. The batch size and learning rate are the same as earlier. The NMSE results of this configuration are given in Table V.
\begin{table}[h!]
\caption{CSINet+STNet hard parameter sharing}
\centering
\begin{tabular}{|c|c c|} 
%  \hline
%   \multicolumn{5}{|c|}{NMSE}\\
 \hline
Model& CSINet Indoor & STNet Outdoor\\
 \hline
 1/4 & -18.08 & -10.06\\ 
 \hline
 1/16 & -11.22 & -4.92 \\
 \hline
 1/32 & -8.64 & -3.13\\
 \hline
 1/64 & -6.26 & -2.10\\
 \hline
\end{tabular}\\
\end{table}



Similar to joint training, the performance of CSINet has also improved when trained with hard parameter sharing on a modified STNet decoder. The NMSE gains of this approach over regular training are presented in Fig.~\ref{csinet_mssm}. We also used the linear Zero-Forcing (ZF) transmit precoding to gauge the spectral efficiency improvement as shown in Fig.~\ref{csinet+stnet_hard}. 
\subsection{Complexity}
The original purpose of joint training or hard parameter sharing is to reduce the resource utilization of the system which can be quantified by the number of parameters of the neural network. We presented the number of parameters of CSINet combined with STNet for various training methodologies in Table VI.

% \begin{table}[h!]
% \caption{Number of parameters}
% \centering
% \begin{tabular}{|c|c c|} 
% %  \hline
% %   \multicolumn{5}{|c|}{NMSE}\\
%  \hline
%   Configuration & \multicolumn{2}{c|}{CSINet+STNet } \\
%  \hline
% Training Type & Independent & Joint\\
%  \hline
%  1/4 & 4.216M & 3.164M\\ 
%  \hline
%  1/16 & 1.070M & 0.804M\\
%  \hline
%  1/32 & 0.546M & 0.410M\\
%  \hline
%  1/64 & 0.283M & 0.213M\\
%  \hline
% \end{tabular}\\
% \end{table}

\begin{table}[h!]
\caption{Number of parameters}
\centering
\begin{tabular}{|c|c c c|} 
%  \hline
%   \multicolumn{5}{|c|}{NMSE}\\
 \hline
  Configuration & \multicolumn{3}{c|}{CSINet+STNet}\\
 \hline
Training Type & Independent & Joint Learning & Hard Sharing \\
 \hline
 1/4 & 4.216M & 3.164M & 3.954M \\ 
 \hline
 1/16 & 1.070M & 0.804M & 0.912M \\
 \hline
 1/32 & 0.546M & 0.410M & 0.496M\\
 \hline
 1/64 & 0.283M & 0.213M & 0.252M\\
 \hline
\end{tabular}\\
\end{table}

It is evident from Table VI that the proposed methods consume significantly fewer hardware resources while achieving better spectral efficiencies. For example, CSINet in an SSMM scenario when trained jointly with STNet consumed $25\%$ fewer resources while increasing the combined spectral efficiency by $0.07bps/Hz$. Similarly, CSINet in an MSMM scenario when trained with hard parameter sharing consumed $7\%$ fewer resources while increasing its combined spectral efficiency by $0.02bps/Hz$. In addition, our approach also increased the performance of CSINet individually. For example, when trained jointly with STNet the performance of CSINet, for a compression ratio of $1/32$,  increased by $39\%$, and when trained by hard parameter sharing, it increased by $38\%$.
\section{Conclusion}
In this letter, we divided the users in a multi-user scenario into four categories within the context of channel state information (CSI) feedback using deep learning and presented the inadequacies of the existing CSI feedback models in generalizing their results to all the categories. We then proposed multi-task learning techniques to address the shortcomings of these existing models to improve their performance and resource utilization in a multi-user scenario. We evaluated these methods on the COST2100 dataset for two existing models namely CSINet, and STNet to present our findings. 





















% \begin{figure*}[h]
% \centering
% \includegraphics[width=\linewidth]{output.png}
% \captionof{figure}{Joint training with linear autoregressive loss for N tasks where each task is trained separately on the decoder by choosing a very small batch size. Autoregression is achieved by adding the previous loss to the current loss. Also notice that this goes around in a cyclic fashion.}
% \label{cross}
% \end{figure*}





















% \subsection{Joint Training with cross output loss}
% In this, we define a new loss function termed \textit{Cross Loss} that calculates the loss between the output of the current instance to the output of the previous instant i.e.,
% \begin{equation}
%     loss\{i\} = loss\{i\} + \alpha \times CrossLoss\{i-1\},
% \end{equation}
% where, 
% \begin{equation}
%     CrossLoss\{i\} = loss(output\{i\}, output\{i-1\}),
% \end{equation}
% and $\alpha$ is the regularization coefficient. For user distributions like SSSM and SSMM where the outputs are supposed to be same, calculating the distance between two successive outputs acts as regularization on the parameters to retain the knowledge of features from previous training instance.
% \begin{figure}[h]
% \centering
% \includegraphics[width=3.5in]{cross.png}
% \captionof{figure}{Joint training with cross output loss for N tasks where each task is trained separately on the decoder by choosing a very small batch size. Cross loss is the loss between two successive outputs of the decoder which is then added to the instantaneous loss with a regularization coefficient.}
% \label{cross}
% \end{figure}




















\bibliography{reference}
\bibliographystyle{ieeetr}
\end{document}
