\setcounter{page}{1}

\appendix
\onecolumn
\begin{center}
	\Large{\textbf{HMOE: Hypernetwork-based Mixture of Experts for Domain Generalization}} \\
	\vspace{1.0em} \Large{Supplementary Material}\\
	\vspace{2.0em}
\end{center}

\section{Toy Regression Problem}
In the paper, we employ HMOE to address the domain generalization problem in image classification. In fact, HMOE is equally applicable to other problems troubled by heterogeneous patterns. To demonstrate the versatility of HMOE, we apply it to a toy regression task, aiming to learn a one-dimensional function defined over three intervals. Through this toy problem, we can also more intuitively understand the learning dynamics of HMOE, including the evolution of the gating mechanism and how experts become specialized gradually.

We use the function $y = \sin (4 \pi x)$ to generate 10, 20, and 30 data points uniformly in three intervals: $(0, 0.5)$, $(1, 1.5)$, and $(2, 2.5)$, respectively, as shown in \cref{fig:toy_experts}. Unequal data points are used to simulate a naturally unbalanced expert load. These three intervals represent three source domains, and we see if HMOE can generalize well in the regions between intervals.

HMOE uses three embedding vectors of dimension $D=8$, which are initialized using the standard normal distribution. All networks of HMOE are MLPs with 32 hidden units. The featurizer is a three-layer MLP whose input size is 1 and output size is 32. The encoder is a three-layer whose input size is 1 and output size is $D$. The classifier is a two-layer MLP whose input size is 32 and output size is 1. The hypernetwork is a four-layer MLP whose input size is $D$ and output size is the total number of learnable parameters (\ie, weights and biases) of the classifier. All MLPs use the SiLU activation function \cite{hendrycksGaussianErrorLinear2016} except the output layers. In addition, $\mathcal{L}_{y}$ (use MSE as the loss function), $\mathcal{L}_{en}$, and $\mathcal{L}_{kl}$ are used with $\lambda_{y} = \lambda_{en} = \lambda_{kl} = 1$, and HMOE is trained using Adam \cite{kingmaAdamMethodStochastic2014} with learning rate $0.001$ over $20,000$ epochs.

The evolution of the experts' outputs and gate values with respect to training epochs is depicted in \cref{fig:toy_experts}. From this, we can observe that three experts compete with each other and progressively delineate their respective positions. Notably, HMOE manages to identify three intervals even in the face of imbalanced data. After training, we compare two different inference modes, as shown in \cref{fig:toy_inference}. They all coincide well with the training points. MIX seems to perform better in the regions between intervals, while OOD presents an unexpected peak. Overall, HMOE demonstrates an ability to detect heterogeneous patterns within data.

\begin{figure}[htbp]
	\centering
	\begin{subfigure}{0.6\linewidth}
		\includegraphics[width=\textwidth]{Toy_Experts_Gates}
		\caption{Experts' outputs and gate values during training}
		\label{fig:toy_experts}
	\end{subfigure}
	%
	\begin{subfigure}{0.3\linewidth}
		\includegraphics[width=\textwidth]{Toy_Preds}
		\caption{Two inference modes after training}
		\label{fig:toy_inference}
	\end{subfigure}
	\caption{A toy regression problem. We generate some data points using the function $y=\sin (4 \pi x)$ in three intervals and fit HMOE with three embedding vectors to these points. HMOE well identifies three intervals and experts also become specialized.}
	\label{fig:toy_regression}
\end{figure}

\clearpage
\section{Description and visualization of datasets of DomainBed}

\begin{table}[htbp]
	\centering
	\small
	\setlength\tabcolsep{3pt}
	\begin{tabular}{cccccccccc}
		\toprule
		\textbf{Dataset} & \multicolumn{6}{c}{\textbf{Domains}}  & \textbf{\# of classes} & \textbf{\# of samples}   & \textbf{Image size}\\
		\toprule
		& \footnotesize{+90\%} & \footnotesize{+80\%} & \footnotesize{-90\%} & & & & & & \\
		Colored MNIST \cite{arjovskyInvariantRiskMinimization2019} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/ColorMNIST_env00.1_30_idx13207_class1.png}}   &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/ColorMNIST_env10.2_27_idx2676_class0.png}}    &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/ColorMNIST_env20.9_25_idx16596_class1.png}}   & & & & 2 & 70,000 & (2, 28, 28) \\
		& \multicolumn{6}{l}{\footnotesize{\emph{(degree of correlation between color and label)}}} & & & \\
		& \footnotesize{0$^{\circ}$} & \footnotesize{15$^{\circ}$} & \footnotesize{30$^{\circ}$} & \footnotesize{45$^{\circ}$} & \footnotesize{60$^{\circ}$} & \footnotesize{75$^{\circ}$} & & & \\
		Rotated MNIST \cite{ghifaryDomainGeneralizationObject2015} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/RotatedMNIST_env00_15_idx1402_class9.png}}   &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/RotatedMNIST_env115_6_idx1082_class9.png}}   &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/RotatedMNIST_env230_16_idx9314_class9.png}}  &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/RotatedMNIST_env345_5_idx4978_class9.png}}   &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/RotatedMNIST_env460_2_idx1096_class9.png}}   &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/RotatedMNIST_env575_41_idx6482_class9.png}}  & 10 & 70,000 & (1, 28, 28) \\
		& \footnotesize{Caltech101} & \footnotesize{LabelMe} & \footnotesize{SUN09} & \footnotesize{VOC2007} & & & & & \\
		VLCS \cite{fangUnbiasedMetricLearning2013} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/VLCS_env0Caltech101_17_idx34_class0}} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/VLCS_env1LabelMe_30_idx59_class0}} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/VLCS_env2SUN09_11_idx16_class0}} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/VLCS_env3VOC2007_6_idx219_class0}} & & & 5 & 10,729 & (3, 224, 224) \\
		& \footnotesize{Art} & \footnotesize{Cartoon} & \footnotesize{Photo} & \footnotesize{Sketch} & & & & & \\
		PACS \cite{liDeeperBroaderArtier2017} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/PACS_env0art_painting_3_idx170_class0}} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/PACS_env1cartoon_2_idx81_class0}} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/PACS_env2photo_7_idx165_class0}} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/PACS_env3sketch_7_idx516_class0}} & & & 7 & 9,991 & (3, 224, 224) \\
		& \footnotesize{Art} & \footnotesize{Clipart} & \footnotesize{Product} & \footnotesize{Photo} & & & & & \\
		OfficeHome \cite{venkateswaraDeepHashingNetwork2017} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/OfficeHome_env0Art_4_idx585_class10}} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/OfficeHome_env1Clipart_18_idx772_class10}} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/OfficeHome_env2Product_18_idx748_class10}} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/OfficeHome_env3Real_World_26_idx852_class10}} & & & 65 & 15,588 & (3, 224, 224) \\
		& \footnotesize{L100} & \footnotesize{L38} & \footnotesize{L43} & \footnotesize{L46} & & & & & \\
		TerraIncognita \cite{beeryRecognitionTerraIncognita2018} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/TerraIncognita_env0location_100_1_idx1967_class7}} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/TerraIncognita_env1location_38_11_idx7940_class7}} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/TerraIncognita_env2location_43_10_idx3571_class7}} &
		\raisebox{-.5\height}{\includegraphics[width=25pt, height=25pt]{dataset_images/TerraIncognita_env3location_46_23_idx4220_class7}} & & & 10 & 24,788 & (3, 224, 224) \\
		& \multicolumn{6}{l}{\footnotesize{\emph{(camera trap location)}}} & & & \\
	\end{tabular}
	\label{table:datasets}
	\caption{Description and visualization of datasets used in our experiments (Adapted from \cite{gulrajaniSearchLostDomain2020})}
\end{table}

\section{Detailed domain generalization results}

We detail the domain generalization results for each dataset, and we format \textcolor{cyan}{first}, \underline{second} and \textcolor{gray}{worse than DeepAll} results.

\vspace{1em}
%%%%%%%%%%%%%%%%%%%
% ColoredMNIST
%%%%%%%%%%%%%%%%%%%
\begin{table}[htbp]
	\centering
	\small
	\setlength\tabcolsep{6pt}
	\begin{tabular}{lcccc|c}
		\hline
		\textbf{Algorithm} & \textbf{+90\%} & \textbf{+80\%} & \textbf{-90\%} & \textbf{Avg} & \textbf{Ranking} \\
		\hline
		\multicolumn{6}{c}{\emph{w/ Domain Labels}} \\
		\hline
		Mixup \cite{yanImproveUnsupervisedDomain2020} & 72.3 {\scriptsize$\pm$ 0.1} & 73.1 {\scriptsize$\pm$ 0.0} & 10.4 {\scriptsize$\pm$ 0.1} & 51.9 & 4 \\
		CORAL \cite{sunDeepCoralCorrelation2016} & \textcolor{gray}{71.3} {\scriptsize$\pm$ 0.3} & 73.0 {\scriptsize$\pm$ 0.2} & \textcolor{gray}{9.9} {\scriptsize$\pm$ 0.0} & 51.4 & 13 \\
		VREx \cite{kruegerOutofdistributionGeneralizationRisk2021} & \underline{73.1} {\scriptsize$\pm$ 0.3} & \underline{73.7} {\scriptsize$\pm$ 0.3} & 10.0 {\scriptsize$\pm$ 0.1} & \underline{52.2} & \underline{2} \\
		Fish \cite{shiGradientMatchingDomain2021a} & \textcolor{gray}{71.3} {\scriptsize$\pm$ 0.1} & 73.1 {\scriptsize$\pm$ 0.2} & 10.2 {\scriptsize$\pm$ 0.1} & 51.5 & 9 \\
		ARM \cite{zhangAdaptiveRiskMinimization2021} & \textcolor{cyan}{81.7} {\scriptsize$\pm$ 0.5} & \textcolor{cyan}{74.8} {\scriptsize$\pm$ 1.1} & 10.3 {\scriptsize$\pm$ 0.2} & \textcolor{cyan}{55.6} & \textcolor{cyan}{1} \\
		MTL \cite{blanchardDomainGeneralizationMarginal2021} & 71.6 {\scriptsize$\pm$ 0.3} & 72.9 {\scriptsize$\pm$ 0.3} & 10.2 {\scriptsize$\pm$ 0.0} & 51.5 & 10 \\
		GroupDRO \cite{sagawaDistributionallyRobustNeural2020} & 73.0 {\scriptsize$\pm$ 0.1} & 73.0 {\scriptsize$\pm$ 0.4} & 10.2 {\scriptsize$\pm$ 0.3} & 52.1 & 3 \\
		MLDG \cite{liLearningGeneralizeMetalearning2018} & \textcolor{gray}{37.5} {\scriptsize$\pm$ 9.9} & \textcolor{gray}{56.4} {\scriptsize$\pm$ 5.2} & \textcolor{cyan}{38.8} {\scriptsize$\pm$ 8.1} & \textcolor{gray}{44.2} & \textcolor{gray}{16} \\
		MMD \cite{liDomainGeneralizationAdversarial2018} & \textcolor{gray}{53.9} {\scriptsize$\pm$ 2.7} & \textcolor{gray}{51.6} {\scriptsize$\pm$ 0.8} & 10.1 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{38.5} & \textcolor{gray}{18} \\
		DANN \cite{ganinDomainadversarialTrainingNeural2016} & 72.5 {\scriptsize$\pm$ 0.1} & 72.7 {\scriptsize$\pm$ 0.2} & 10.1 {\scriptsize$\pm$ 0.1} & 51.8 & 5 \\
		IRM \cite{arjovskyInvariantRiskMinimization2019} & \textcolor{gray}{57.0} {\scriptsize$\pm$ 2.7} & \textcolor{gray}{57.2} {\scriptsize$\pm$ 4.9} & \textcolor{gray}{9.7} {\scriptsize$\pm$ 0.0} & \textcolor{gray}{41.3} & \textcolor{gray}{17} \\
		\cdashline{1-5}
		HMOE-DL  & \textcolor{gray}{71.5} {\scriptsize$\pm$ 0.4} & 72.9 {\scriptsize$\pm$ 0.1} & 10.2 {\scriptsize$\pm$ 0.0} & 51.5 & 11 \\
		\hline
		\multicolumn{6}{c}{\emph{w/o Domain Labels}} \\
		\hline
		SelfReg \cite{kimSelfregSelfsupervisedContrastive2021} & \textcolor{gray}{71.1} {\scriptsize$\pm$ 0.3} & 73.0 {\scriptsize$\pm$ 0.0} & 10.1 {\scriptsize$\pm$ 0.2} & 51.4 & 14 \\
		SagNet \cite{namReducingDomainGap2021} & 72.2 {\scriptsize$\pm$ 0.0} & 73.3 {\scriptsize$\pm$ 0.3} & 10.0 {\scriptsize$\pm$ 0.1} & 51.8 & 6 \\
		RSC \cite{huangSelfchallengingImprovesCrossdomain2020} & 72.1 {\scriptsize$\pm$ 0.3} & \textcolor{gray}{72.3} {\scriptsize$\pm$ 0.8} & 10.1 {\scriptsize$\pm$ 0.1} & 51.5 & 12 \\
		DeepAll \cite{vapnikNatureStatisticalLearning1999} & 71.6 {\scriptsize$\pm$ 0.1} & 72.7 {\scriptsize$\pm$ 0.2} & 10.0 {\scriptsize$\pm$ 0.1} & 51.4 & 15 \\
		\cdashline{1-5}
		HMOE-ND  & 71.8 {\scriptsize$\pm$ 0.1} & 73.0 {\scriptsize$\pm$ 0.1} & \underline{10.5} {\scriptsize$\pm$ 0.2} & 51.8 & 7 \\
		HMOE-MU  & 71.7 {\scriptsize$\pm$ 0.4} & 73.0 {\scriptsize$\pm$ 0.3} & 10.3 {\scriptsize$\pm$ 0.1} & 51.7 & 8 \\
		\hline
	\end{tabular}
	\caption{Domain generalization results on Colored MNIST}
\end{table}


%%%%%%%%%%%%%%%%%%%
% RotatedMNIST
%%%%%%%%%%%%%%%%%%%
\begin{table}[htbp]
	\centering
	\small
	\setlength\tabcolsep{6pt}
	\begin{tabular}{lccccccc|c}
		\hline
		\textbf{Algorithm} & \textbf{0} & \textbf{15} & \textbf{30} & \textbf{45} & \textbf{60} & \textbf{75} & \textbf{Avg} & \textbf{Ranking} \\
		\hline
		\multicolumn{9}{c}{\emph{w/ Domain Labels}} \\
		\hline
		Mixup \cite{yanImproveUnsupervisedDomain2020} & \textcolor{gray}{93.8} {\scriptsize$\pm$ 0.1} & 98.8 {\scriptsize$\pm$ 0.1} & 99.0 {\scriptsize$\pm$ 0.0} & 99.1 {\scriptsize$\pm$ 0.1} & 98.9 {\scriptsize$\pm$ 0.0} & \textcolor{gray}{95.9} {\scriptsize$\pm$ 0.2} & \textcolor{gray}{97.6} & \textcolor{gray}{13} \\
		CORAL \cite{sunDeepCoralCorrelation2016} & 95.8 {\scriptsize$\pm$ 0.2} & 98.5 {\scriptsize$\pm$ 0.1} & 99.1 {\scriptsize$\pm$ 0.0} & \textcolor{gray}{99.0} {\scriptsize$\pm$ 0.1} & \underline{99.1} {\scriptsize$\pm$ 0.0} & \underline{96.6} {\scriptsize$\pm$ 0.1} & 98.0 & 2 \\
		VREx \cite{kruegerOutofdistributionGeneralizationRisk2021} & 95.5 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{98.3} {\scriptsize$\pm$ 0.2} & \textcolor{gray}{98.9} {\scriptsize$\pm$ 0.1} & \textcolor{gray}{98.9} {\scriptsize$\pm$ 0.0} & 98.9 {\scriptsize$\pm$ 0.0} & 96.4 {\scriptsize$\pm$ 0.1} & 97.8 & 7 \\
		Fish \cite{shiGradientMatchingDomain2021a} & 95.5 {\scriptsize$\pm$ 0.4} & 98.7 {\scriptsize$\pm$ 0.0} & 99.0 {\scriptsize$\pm$ 0.0} & 99.1 {\scriptsize$\pm$ 0.1} & 98.9 {\scriptsize$\pm$ 0.0} & 96.3 {\scriptsize$\pm$ 0.3} & 97.9 & 6 \\
		ARM \cite{zhangAdaptiveRiskMinimization2021} & \underline{95.9} {\scriptsize$\pm$ 0.1} & 98.8 {\scriptsize$\pm$ 0.0} & \textcolor{gray}{98.9} {\scriptsize$\pm$ 0.1} & 99.1 {\scriptsize$\pm$ 0.0} & 98.9 {\scriptsize$\pm$ 0.0} & 96.2 {\scriptsize$\pm$ 0.1} & \textcolor{cyan}{98.1} & \textcolor{cyan}{1} \\
		MTL \cite{blanchardDomainGeneralizationMarginal2021} & 95.2 {\scriptsize$\pm$ 0.2} & 98.6 {\scriptsize$\pm$ 0.1} & \underline{99.1} {\scriptsize$\pm$ 0.0} & \textcolor{gray}{98.9} {\scriptsize$\pm$ 0.1} & \textcolor{gray}{98.8} {\scriptsize$\pm$ 0.1} & \textcolor{gray}{96.1} {\scriptsize$\pm$ 0.1} & 97.8 & 8 \\
		GroupDRO \cite{sagawaDistributionallyRobustNeural2020} & \textcolor{gray}{94.9} {\scriptsize$\pm$ 0.2} & 98.6 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{98.9} {\scriptsize$\pm$ 0.0} & \textcolor{gray}{99.0} {\scriptsize$\pm$ 0.1} & 99.0 {\scriptsize$\pm$ 0.0} & 96.3 {\scriptsize$\pm$ 0.1} & 97.8 & 9 \\
		MLDG \cite{liLearningGeneralizeMetalearning2018} & 95.3 {\scriptsize$\pm$ 0.1} & 98.5 {\scriptsize$\pm$ 0.1} & 99.0 {\scriptsize$\pm$ 0.0} & \textcolor{gray}{99.0} {\scriptsize$\pm$ 0.0} & 98.9 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{96.1} {\scriptsize$\pm$ 0.1} & 97.8 & 10 \\
		MMD \cite{liDomainGeneralizationAdversarial2018} & 95.8 {\scriptsize$\pm$ 0.3} & 98.8 {\scriptsize$\pm$ 0.0} & 99.0 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{98.9} {\scriptsize$\pm$ 0.0} & 99.0 {\scriptsize$\pm$ 0.0} & 96.2 {\scriptsize$\pm$ 0.1} & 98.0 & 3 \\
		DANN \cite{ganinDomainadversarialTrainingNeural2016} & \textcolor{cyan}{95.9} {\scriptsize$\pm$ 0.1} & 98.5 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{98.6} {\scriptsize$\pm$ 0.0} & \textcolor{gray}{98.8} {\scriptsize$\pm$ 0.0} & \textcolor{gray}{98.7} {\scriptsize$\pm$ 0.0} & \textcolor{gray}{95.6} {\scriptsize$\pm$ 0.1} & \textcolor{gray}{97.7} & \textcolor{gray}{12} \\
		IRM \cite{arjovskyInvariantRiskMinimization2019} & \textcolor{gray}{81.9} {\scriptsize$\pm$ 2.4} & \textcolor{gray}{88.1} {\scriptsize$\pm$ 4.2} & \textcolor{gray}{93.2} {\scriptsize$\pm$ 0.6} & \textcolor{gray}{91.3} {\scriptsize$\pm$ 2.8} & \textcolor{gray}{93.1} {\scriptsize$\pm$ 0.7} & \textcolor{gray}{76.0} {\scriptsize$\pm$ 0.7} & \textcolor{gray}{87.3} & \textcolor{gray}{18} \\
		\cdashline{1-8}
		HMOE-DL  & \textcolor{gray}{87.7} {\scriptsize$\pm$ 1.3} & \textcolor{gray}{93.3} {\scriptsize$\pm$ 2.2} & \textcolor{gray}{98.2} {\scriptsize$\pm$ 0.3} & \textcolor{gray}{98.6} {\scriptsize$\pm$ 0.0} & \textcolor{gray}{98.2} {\scriptsize$\pm$ 0.2} & \textcolor{gray}{88.8} {\scriptsize$\pm$ 1.5} & \textcolor{gray}{94.1} & \textcolor{gray}{17} \\
		\hline
		\multicolumn{9}{c}{\emph{w/o Domain Labels}} \\
		\hline
		SelfReg \cite{kimSelfregSelfsupervisedContrastive2021} & 95.7 {\scriptsize$\pm$ 0.1} & 98.7 {\scriptsize$\pm$ 0.0} & 99.0 {\scriptsize$\pm$ 0.0} & \textcolor{cyan}{99.2} {\scriptsize$\pm$ 0.0} & \textcolor{cyan}{99.1} {\scriptsize$\pm$ 0.0} & 96.5 {\scriptsize$\pm$ 0.1} & 98.0 & 4 \\
		SagNet \cite{namReducingDomainGap2021} & 95.1 {\scriptsize$\pm$ 0.3} & \underline{98.8} {\scriptsize$\pm$ 0.0} & \textcolor{cyan}{99.1} {\scriptsize$\pm$ 0.0} & 99.1 {\scriptsize$\pm$ 0.1} & 99.0 {\scriptsize$\pm$ 0.0} & \textcolor{cyan}{96.7} {\scriptsize$\pm$ 0.1} & 98.0   & 5 \\
		RSC \cite{huangSelfchallengingImprovesCrossdomain2020} & \textcolor{gray}{94.0} {\scriptsize$\pm$ 0.3} & \textcolor{gray}{98.3} {\scriptsize$\pm$ 0.1} & 99.0 {\scriptsize$\pm$ 0.0} & \textcolor{gray}{98.9} {\scriptsize$\pm$ 0.0} & 98.9 {\scriptsize$\pm$ 0.0} & \textcolor{gray}{95.9} {\scriptsize$\pm$ 0.1} & \textcolor{gray}{97.5} & \textcolor{gray}{15} \\
		DeepAll \cite{vapnikNatureStatisticalLearning1999} & 95.0 {\scriptsize$\pm$ 0.4} & 98.5 {\scriptsize$\pm$ 0.2} & 99.0 {\scriptsize$\pm$ 0.0} & \underline{99.1} {\scriptsize$\pm$ 0.0} & 98.9 {\scriptsize$\pm$ 0.0} & 96.2 {\scriptsize$\pm$ 0.1} & 97.8 & 11 \\
		\cdashline{1-8}
		HMOE-ND  & \textcolor{gray}{94.5} {\scriptsize$\pm$ 0.1} & 98.5 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{98.8} {\scriptsize$\pm$ 0.0} & \textcolor{gray}{98.7} {\scriptsize$\pm$ 0.0} & \textcolor{gray}{98.7} {\scriptsize$\pm$ 0.1} & \textcolor{gray}{95.7} {\scriptsize$\pm$ 0.3} & \textcolor{gray}{97.5} & \textcolor{gray}{16} \\
		HMOE-MU  & \textcolor{gray}{94.6} {\scriptsize$\pm$ 0.3} & \textcolor{cyan}{98.8} {\scriptsize$\pm$ 0.0} & \textcolor{gray}{98.9} {\scriptsize$\pm$ 0.1} & \textcolor{gray}{98.8} {\scriptsize$\pm$ 0.0} & \textcolor{gray}{98.8} {\scriptsize$\pm$ 0.1} & \textcolor{gray}{95.6} {\scriptsize$\pm$ 0.2} & \textcolor{gray}{97.6} & \textcolor{gray}{14} \\
		\hline
	\end{tabular}
	\caption{Domain generalization results on Rotated MNIST}
\end{table}


%%%%%%%%%%%%%%%%%%%
% VLCS
%%%%%%%%%%%%%%%%%%%
\begin{table}[htbp]
	\centering
	\small
	\setlength\tabcolsep{6pt}
	\begin{tabular}{lccccc|c}
		\hline
		\textbf{Algorithm}  &  \textbf{Caltech101}    & \textbf{LabelMe}     & \textbf{SUN09}     & \textbf{VOC2007}  & \textbf{Avg} & \textbf{Ranking} \\
		\hline
		\multicolumn{7}{c}{\emph{w/ Domain Labels}} \\
		\hline
		Mixup \cite{yanImproveUnsupervisedDomain2020} & \textcolor{cyan}{98.2} {\scriptsize$\pm$ 0.3} & \textcolor{gray}{64.8} {\scriptsize$\pm$ 0.3} & 74.9 {\scriptsize$\pm$ 0.2} & \textcolor{gray}{76.9} {\scriptsize$\pm$ 1.0} & 78.7 & 3 \\
		CORAL \cite{sunDeepCoralCorrelation2016} & 97.2 {\scriptsize$\pm$ 0.4} & 65.8 {\scriptsize$\pm$ 0.4} & 74.0 {\scriptsize$\pm$ 0.3} & \textcolor{gray}{75.4} {\scriptsize$\pm$ 0.8} & 78.1 & 6 \\
		VREx \cite{kruegerOutofdistributionGeneralizationRisk2021} & 96.1 {\scriptsize$\pm$ 0.5} & \textcolor{gray}{64.8} {\scriptsize$\pm$ 1.2} & 72.6 {\scriptsize$\pm$ 0.5} & \textcolor{gray}{75.5} {\scriptsize$\pm$ 1.0} & \textcolor{gray}{77.3} & \textcolor{gray}{14} \\
		Fish \cite{shiGradientMatchingDomain2021a} & 96.8 {\scriptsize$\pm$ 0.5} & \textcolor{gray}{64.5} {\scriptsize$\pm$ 0.3} & 74.9 {\scriptsize$\pm$ 0.3} & \textcolor{gray}{76.1} {\scriptsize$\pm$ 1.0} & 78.1 & 7 \\
		ARM \cite{zhangAdaptiveRiskMinimization2021} & 97.0 {\scriptsize$\pm$ 0.2} & \underline{65.9} {\scriptsize$\pm$ 1.4} & 73.0 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{76.2} {\scriptsize$\pm$ 1.4} & 78.0 & 9 \\
		MTL \cite{blanchardDomainGeneralizationMarginal2021} & 96.3 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{64.5} {\scriptsize$\pm$ 0.3} & 72.6 {\scriptsize$\pm$ 0.5} & \textcolor{gray}{75.6} {\scriptsize$\pm$ 0.9} & \textcolor{gray}{77.3} & \textcolor{gray}{15} \\
		GroupDRO \cite{sagawaDistributionallyRobustNeural2020} & 97.1 {\scriptsize$\pm$ 0.3} & \textcolor{cyan}{65.9} {\scriptsize$\pm$ 0.7} & 72.4 {\scriptsize$\pm$ 1.7} & \textcolor{gray}{75.8} {\scriptsize$\pm$ 0.4} & 77.8 & 10 \\
		MLDG \cite{liLearningGeneralizeMetalearning2018} & 96.9 {\scriptsize$\pm$ 0.6} & \textcolor{gray}{61.5} {\scriptsize$\pm$ 0.8} & \textcolor{gray}{71.7} {\scriptsize$\pm$ 0.7} & \textcolor{gray}{76.5} {\scriptsize$\pm$ 0.2} & \textcolor{gray}{76.6} & \textcolor{gray}{17} \\
		MMD \cite{liDomainGeneralizationAdversarial2018} & 96.9 {\scriptsize$\pm$ 0.5} & \textcolor{gray}{64.2} {\scriptsize$\pm$ 1.9} & \textcolor{gray}{71.7} {\scriptsize$\pm$ 0.9} & \textcolor{gray}{76.6} {\scriptsize$\pm$ 1.8} & \textcolor{gray}{77.4} & \textcolor{gray}{13} \\
		DANN \cite{ganinDomainadversarialTrainingNeural2016} & 95.8 {\scriptsize$\pm$ 1.0} & \textcolor{gray}{65.1} {\scriptsize$\pm$ 0.7} & \textcolor{gray}{68.1} {\scriptsize$\pm$ 2.4} & \textcolor{gray}{73.5} {\scriptsize$\pm$ 0.7} & \textcolor{gray}{75.6} & \textcolor{gray}{18} \\
		IRM \cite{arjovskyInvariantRiskMinimization2019} & 96.8 {\scriptsize$\pm$ 0.3} & \textcolor{gray}{64.6} {\scriptsize$\pm$ 1.2} & 75.2 {\scriptsize$\pm$ 0.8} & \textcolor{gray}{76.6} {\scriptsize$\pm$ 3.4} & 78.3 & 5 \\
		\cdashline{1-6}
		HMOE-DL  & 95.5 {\scriptsize$\pm$ 1.4} & \textcolor{gray}{63.5} {\scriptsize$\pm$ 0.5} & 73.8 {\scriptsize$\pm$ 1.0} & \textcolor{gray}{75.0} {\scriptsize$\pm$ 1.5} & \textcolor{gray}{77.0} & \textcolor{gray}{16} \\
		\hline
		\multicolumn{7}{c}{\emph{w/o Domain Labels}} \\
		\hline
		SelfReg \cite{kimSelfregSelfsupervisedContrastive2021} & \underline{97.6} {\scriptsize$\pm$ 0.4} & \textcolor{gray}{65.2} {\scriptsize$\pm$ 0.2} & \underline{75.5} {\scriptsize$\pm$ 0.2} & \textcolor{gray}{77.1} {\scriptsize$\pm$ 0.7} & \textcolor{cyan}{78.9} & \textcolor{cyan}{1} \\
		SagNet \cite{namReducingDomainGap2021} & 96.8 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{63.0} {\scriptsize$\pm$ 1.0} & 72.3 {\scriptsize$\pm$ 0.2} & \textcolor{cyan}{78.7} {\scriptsize$\pm$ 1.1} & 77.7 & 11 \\
		RSC \cite{huangSelfchallengingImprovesCrossdomain2020} & 96.7 {\scriptsize$\pm$ 0.9} & \textcolor{gray}{64.7} {\scriptsize$\pm$ 0.7} & \textcolor{cyan}{76.4} {\scriptsize$\pm$ 0.6} & \textcolor{gray}{77.4} {\scriptsize$\pm$ 0.8} & \underline{78.8} & \underline{2} \\
		DeepAll \cite{vapnikNatureStatisticalLearning1999} & 95.0 {\scriptsize$\pm$ 0.5} & 65.4 {\scriptsize$\pm$ 1.0} & 72.0 {\scriptsize$\pm$ 1.2} & 77.7 {\scriptsize$\pm$ 0.3} & 77.5 & 12 \\
		\cdashline{1-6}
		HMOE-ND  & 96.8 {\scriptsize$\pm$ 0.5} & \textcolor{gray}{64.7} {\scriptsize$\pm$ 0.5} & 75.0 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{76.1} {\scriptsize$\pm$ 1.5} & 78.1 & 8 \\
		HMOE-MU  & 97.1 {\scriptsize$\pm$ 0.2} & \textcolor{gray}{64.6} {\scriptsize$\pm$ 0.7} & 74.9 {\scriptsize$\pm$ 0.4} & \underline{77.9} {\scriptsize$\pm$ 0.3} & 78.6 & 4 \\
		\hline
	\end{tabular}
	\caption{Domain generalization results on VLCS}
\end{table}


%%%%%%%%%%%%%%%%%%%
% PACS
%%%%%%%%%%%%%%%%%%%
\begin{table}[htbp]
	\centering
	\small
	\setlength\tabcolsep{6pt}
	\begin{tabular}{lccccc|c}
		\hline
		\textbf{Algorithm}  &  \textbf{Art}    & \textbf{Cartoon}    & \textbf{Photo}    & \textbf{Sketch} & \textbf{Avg} & \textbf{Ranking} \\
		\hline
		\multicolumn{7}{c}{\emph{w/ Domain Labels}} \\
		\hline
		Mixup \cite{yanImproveUnsupervisedDomain2020} & 88.1 {\scriptsize$\pm$ 0.3} & 81.7 {\scriptsize$\pm$ 1.0} & 98.1 {\scriptsize$\pm$ 0.1} & 78.6 {\scriptsize$\pm$ 1.6} & 86.6 & 6 \\
		CORAL \cite{sunDeepCoralCorrelation2016} & 87.8 {\scriptsize$\pm$ 0.9} & \underline{82.7} {\scriptsize$\pm$ 0.9} & 98.0 {\scriptsize$\pm$ 0.1} & 78.4 {\scriptsize$\pm$ 1.8} & 86.7 & 5 \\
		VREx \cite{kruegerOutofdistributionGeneralizationRisk2021} & 86.5 {\scriptsize$\pm$ 2.0} & \textcolor{gray}{79.2} {\scriptsize$\pm$ 0.9} & 97.7 {\scriptsize$\pm$ 0.3} & 80.6 {\scriptsize$\pm$ 1.2} & 86.0 & 10 \\
		Fish \cite{shiGradientMatchingDomain2021a} & \textcolor{gray}{86.0} {\scriptsize$\pm$ 1.8} & \textcolor{cyan}{83.1} {\scriptsize$\pm$ 0.3} & 98.1 {\scriptsize$\pm$ 0.3} & 80.5 {\scriptsize$\pm$ 2.3} & 86.9 & 4 \\
		ARM \cite{zhangAdaptiveRiskMinimization2021} & \textcolor{gray}{86.2} {\scriptsize$\pm$ 1.2} & \textcolor{gray}{81.5} {\scriptsize$\pm$ 0.7} & \textcolor{gray}{97.2} {\scriptsize$\pm$ 0.3} & 77.9 {\scriptsize$\pm$ 1.1} & \textcolor{gray}{85.7} & \textcolor{gray}{12} \\
		MTL \cite{blanchardDomainGeneralizationMarginal2021} & 88.4 {\scriptsize$\pm$ 0.8} & \textcolor{gray}{80.7} {\scriptsize$\pm$ 1.2} & 97.8 {\scriptsize$\pm$ 0.2} & \textcolor{gray}{75.2} {\scriptsize$\pm$ 1.8} & \textcolor{gray}{85.5} & \textcolor{gray}{13} \\
		GroupDRO \cite{sagawaDistributionallyRobustNeural2020} & \textcolor{gray}{86.3} {\scriptsize$\pm$ 1.9} & \textcolor{gray}{81.0} {\scriptsize$\pm$ 0.6} & 97.8 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{74.9} {\scriptsize$\pm$ 2.0} & \textcolor{gray}{85.0} & \textcolor{gray}{15} \\
		MLDG \cite{liLearningGeneralizeMetalearning2018} & \textcolor{cyan}{90.7} {\scriptsize$\pm$ 0.3} & \textcolor{gray}{80.4} {\scriptsize$\pm$ 0.4} & 97.9 {\scriptsize$\pm$ 0.1} & 79.5 {\scriptsize$\pm$ 0.8} & \underline{87.1} & \underline{2} \\
		MMD \cite{liDomainGeneralizationAdversarial2018} & 87.0 {\scriptsize$\pm$ 0.4} & \textcolor{gray}{79.6} {\scriptsize$\pm$ 0.9} & \textcolor{gray}{97.4} {\scriptsize$\pm$ 0.3} & \textcolor{gray}{72.6} {\scriptsize$\pm$ 1.8} & \textcolor{gray}{84.2} & \textcolor{gray}{16} \\
		DANN \cite{ganinDomainadversarialTrainingNeural2016} & \textcolor{gray}{79.4} {\scriptsize$\pm$ 1.9} & \textcolor{gray}{74.7} {\scriptsize$\pm$ 0.9} & \textcolor{gray}{97.0} {\scriptsize$\pm$ 1.1} & \textcolor{gray}{57.1} {\scriptsize$\pm$ 7.0} & \textcolor{gray}{77.0} & \textcolor{gray}{18} \\
		IRM \cite{arjovskyInvariantRiskMinimization2019} & \textcolor{gray}{84.8} {\scriptsize$\pm$ 1.8} & \textcolor{gray}{73.9} {\scriptsize$\pm$ 1.9} & \textcolor{cyan}{98.6} {\scriptsize$\pm$ 0.1} & \textcolor{gray}{71.3} {\scriptsize$\pm$ 1.0} & \textcolor{gray}{82.1} & \textcolor{gray}{17} \\
		\cdashline{1-6}
		HMOE-DL  & 87.5 {\scriptsize$\pm$ 1.4} & \textcolor{gray}{78.9} {\scriptsize$\pm$ 1.3} & 97.6 {\scriptsize$\pm$ 0.1} & 77.9 {\scriptsize$\pm$ 1.3} & \textcolor{gray}{85.5} & \textcolor{gray}{14} \\
		\hline
		\multicolumn{7}{c}{\emph{w/o Domain Labels}} \\
		\hline
		SelfReg \cite{kimSelfregSelfsupervisedContrastive2021} & 86.8 {\scriptsize$\pm$ 2.0} & 82.3 {\scriptsize$\pm$ 0.8} & 97.6 {\scriptsize$\pm$ 0.2} & 77.8 {\scriptsize$\pm$ 0.8} & 86.1 & 9 \\
		SagNet \cite{namReducingDomainGap2021} & \textcolor{gray}{85.3} {\scriptsize$\pm$ 2.0} & 81.8 {\scriptsize$\pm$ 1.6} & 97.7 {\scriptsize$\pm$ 0.3} & 79.8 {\scriptsize$\pm$ 0.8} & 86.2 & 8 \\
		RSC \cite{huangSelfchallengingImprovesCrossdomain2020} & 86.6 {\scriptsize$\pm$ 1.2} & 82.4 {\scriptsize$\pm$ 0.4} & \textcolor{gray}{97.4} {\scriptsize$\pm$ 0.3} & \underline{81.6} {\scriptsize$\pm$ 0.7} & 87.0 & 3 \\
		DeepAll \cite{vapnikNatureStatisticalLearning1999} & 86.4 {\scriptsize$\pm$ 1.2} & 81.7 {\scriptsize$\pm$ 0.6} & 97.5 {\scriptsize$\pm$ 0.3} & 77.7 {\scriptsize$\pm$ 1.8} & 85.8 & 11 \\
		\cdashline{1-6}
		HMOE-ND  & 87.1 {\scriptsize$\pm$ 0.7} & 81.7 {\scriptsize$\pm$ 0.9} & 97.7 {\scriptsize$\pm$ 0.1} & 79.9 {\scriptsize$\pm$ 1.1} & 86.6 & 7 \\
		HMOE-MU  & \underline{89.6} {\scriptsize$\pm$ 0.5} & \textcolor{gray}{81.2} {\scriptsize$\pm$ 1.0} & \underline{98.3} {\scriptsize$\pm$ 0.2} & \textcolor{cyan}{82.9} {\scriptsize$\pm$ 1.6} & \textcolor{cyan}{88.0} & \textcolor{cyan}{1} \\
		\hline
	\end{tabular}
	\caption{Domain generalization results on PACS}
\end{table}


%%%%%%%%%%%%%%%%%%%
% OfficeHome
%%%%%%%%%%%%%%%%%%%
\begin{table}[htbp]
\centering
\small
\setlength\tabcolsep{6pt}
\begin{tabular}{lccccc|c}
\hline
\textbf{Algorithm}  & \textbf{Art}     & \textbf{Clipart}     & \textbf{Product}       & \textbf{Real}     & \textbf{Avg} & \textbf{Ranking} \\
\hline
\multicolumn{7}{c}{\emph{w/ Domain Labels}} \\
\hline
Mixup \cite{yanImproveUnsupervisedDomain2020} & 68.1 {\scriptsize$\pm$ 0.8} & 55.9 {\scriptsize$\pm$ 0.8} & 80.3 {\scriptsize$\pm$ 0.1} & \underline{82.0} {\scriptsize$\pm$ 0.3} & 71.6 & 3 \\
CORAL \cite{sunDeepCoralCorrelation2016} & \textcolor{cyan}{69.9} {\scriptsize$\pm$ 0.7} & \underline{56.8} {\scriptsize$\pm$ 0.1} & \underline{80.5} {\scriptsize$\pm$ 0.4} & 81.7 {\scriptsize$\pm$ 0.2} & \underline{72.2} & \underline{2} \\
VREx \cite{kruegerOutofdistributionGeneralizationRisk2021} & 66.4 {\scriptsize$\pm$ 0.8} & 54.0 {\scriptsize$\pm$ 0.4} & 78.2 {\scriptsize$\pm$ 0.2} & 80.6 {\scriptsize$\pm$ 0.2} & 69.8 & 5 \\
Fish \cite{shiGradientMatchingDomain2021a} & \textcolor{gray}{64.3} {\scriptsize$\pm$ 0.3} & 53.0 {\scriptsize$\pm$ 0.4} & 78.1 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{79.4} {\scriptsize$\pm$ 0.7} & 68.7 & 10 \\
ARM \cite{zhangAdaptiveRiskMinimization2021} & \textcolor{gray}{60.4} {\scriptsize$\pm$ 0.2} & 52.2 {\scriptsize$\pm$ 0.6} & \textcolor{gray}{75.6} {\scriptsize$\pm$ 0.6} & \textcolor{gray}{77.9} {\scriptsize$\pm$ 0.3} & \textcolor{gray}{66.5} & \textcolor{gray}{15} \\
MTL \cite{blanchardDomainGeneralizationMarginal2021} & \textcolor{gray}{64.3} {\scriptsize$\pm$ 0.7} & \textcolor{gray}{52.1} {\scriptsize$\pm$ 1.3} & 78.5 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{78.6} {\scriptsize$\pm$ 0.1} & \textcolor{gray}{68.4} & \textcolor{gray}{12} \\
GroupDRO \cite{sagawaDistributionallyRobustNeural2020} & \textcolor{gray}{63.7} {\scriptsize$\pm$ 0.8} & 52.9 {\scriptsize$\pm$ 0.8} & 77.6 {\scriptsize$\pm$ 0.2} & \textcolor{gray}{78.8} {\scriptsize$\pm$ 0.3} & \textcolor{gray}{68.3} & \textcolor{gray}{13} \\
MLDG \cite{liLearningGeneralizeMetalearning2018} & \textcolor{gray}{64.2} {\scriptsize$\pm$ 0.8} & 52.7 {\scriptsize$\pm$ 0.9} & 78.4 {\scriptsize$\pm$ 0.8} & \textcolor{gray}{78.1} {\scriptsize$\pm$ 0.2} & \textcolor{gray}{68.3} & \textcolor{gray}{14} \\
MMD \cite{liDomainGeneralizationAdversarial2018} & 65.6 {\scriptsize$\pm$ 0.3} & 53.7 {\scriptsize$\pm$ 0.5} & 77.8 {\scriptsize$\pm$ 0.1} & \textcolor{gray}{79.4} {\scriptsize$\pm$ 0.1} & 69.1 & 8 \\
DANN \cite{ganinDomainadversarialTrainingNeural2016} & \textcolor{gray}{62.0} {\scriptsize$\pm$ 0.9} & \textcolor{gray}{49.7} {\scriptsize$\pm$ 1.8} & \textcolor{gray}{76.1} {\scriptsize$\pm$ 0.5} & \textcolor{gray}{78.2} {\scriptsize$\pm$ 0.4} & \textcolor{gray}{66.5} & \textcolor{gray}{16} \\
IRM \cite{arjovskyInvariantRiskMinimization2019} & \textcolor{gray}{60.4} {\scriptsize$\pm$ 0.4} & \textcolor{gray}{49.6} {\scriptsize$\pm$ 1.0} & \textcolor{gray}{73.2} {\scriptsize$\pm$ 0.8} & \textcolor{gray}{76.2} {\scriptsize$\pm$ 0.5} & \textcolor{gray}{64.9} & \textcolor{gray}{18} \\
\cdashline{1-6}
HMOE-DL  & 64.8 {\scriptsize$\pm$ 0.7} & 53.0 {\scriptsize$\pm$ 1.4} & 78.6 {\scriptsize$\pm$ 0.3} & \textcolor{gray}{79.0} {\scriptsize$\pm$ 0.3} & 68.9 & 9 \\
\hline
\multicolumn{7}{c}{\emph{w/o Domain Labels}} \\
\hline
SelfReg \cite{kimSelfregSelfsupervisedContrastive2021} & 68.0 {\scriptsize$\pm$ 0.4} & 55.7 {\scriptsize$\pm$ 0.4} & 79.7 {\scriptsize$\pm$ 0.2} & 81.9 {\scriptsize$\pm$ 0.6} & 71.3 & 4 \\
SagNet \cite{namReducingDomainGap2021} & \textcolor{gray}{63.7} {\scriptsize$\pm$ 0.9} & 54.6 {\scriptsize$\pm$ 0.2} & 78.2 {\scriptsize$\pm$ 0.2} & 80.7 {\scriptsize$\pm$ 0.4} & 69.3 & 7 \\
RSC \cite{huangSelfchallengingImprovesCrossdomain2020} & \textcolor{gray}{60.7} {\scriptsize$\pm$ 1.4} & \textcolor{gray}{51.4} {\scriptsize$\pm$ 0.3} & \textcolor{gray}{74.8} {\scriptsize$\pm$ 1.1} & \textcolor{gray}{75.1} {\scriptsize$\pm$ 1.3} & \textcolor{gray}{65.5} & \textcolor{gray}{17} \\
DeepAll \cite{vapnikNatureStatisticalLearning1999} & 64.7 {\scriptsize$\pm$ 0.6} & 52.2 {\scriptsize$\pm$ 1.0} & 77.4 {\scriptsize$\pm$ 0.2} & 79.8 {\scriptsize$\pm$ 0.2} & 68.5 & 11 \\
\cdashline{1-6}
HMOE-ND  & 65.6 {\scriptsize$\pm$ 0.1} & 54.7 {\scriptsize$\pm$ 0.6} & 78.8 {\scriptsize$\pm$ 0.2} & 79.9 {\scriptsize$\pm$ 0.3} & 69.7 & 6 \\
HMOE-MU  & \underline{68.7} {\scriptsize$\pm$ 0.6} & \textcolor{cyan}{57.7} {\scriptsize$\pm$ 0.4} & \textcolor{cyan}{81.0} {\scriptsize$\pm$ 0.2} & \textcolor{cyan}{82.6} {\scriptsize$\pm$ 0.4} & \textcolor{cyan}{72.5} & \textcolor{cyan}{1} \\
\hline
\end{tabular}
\caption{Domain generalization results on OfficeHome}
\end{table}



%%%%%%%%%%%%%%%%%%%
% TerraIncognita
%%%%%%%%%%%%%%%%%%%
\begin{table}[htbp]
	\centering
	\small
	\setlength\tabcolsep{6pt}
	\begin{tabular}{lccccc|c}
		\hline
		\textbf{Algorithm} & \textbf{L100} & \textbf{L38} & \textbf{L43} & \textbf{L46} & \textbf{Avg} & \textbf{Ranking} \\
		\hline
		\multicolumn{7}{c}{\emph{w/ Domain Labels}} \\
		\hline
		Mixup \cite{yanImproveUnsupervisedDomain2020} & \textcolor{cyan}{68.3} {\scriptsize$\pm$ 2.0} & 43.9 {\scriptsize$\pm$ 0.4} & \textcolor{gray}{56.9} {\scriptsize$\pm$ 1.5} & \textcolor{gray}{36.6} {\scriptsize$\pm$ 0.5} & 51.4 & 5 \\
		CORAL \cite{sunDeepCoralCorrelation2016} & 52.9 {\scriptsize$\pm$ 3.7} & 46.8 {\scriptsize$\pm$ 1.4} & 59.5 {\scriptsize$\pm$ 0.4} & \textcolor{gray}{36.3} {\scriptsize$\pm$ 0.9} & 48.9 & 15 \\
		VREx \cite{kruegerOutofdistributionGeneralizationRisk2021} & 60.7 {\scriptsize$\pm$ 1.7} & 44.8 {\scriptsize$\pm$ 1.2} & 58.9 {\scriptsize$\pm$ 1.4} & 42.6 {\scriptsize$\pm$ 1.3} & 51.8 & 3 \\
		Fish \cite{shiGradientMatchingDomain2021a} & 55.7 {\scriptsize$\pm$ 2.2} & 46.9 {\scriptsize$\pm$ 2.5} & \underline{59.9} {\scriptsize$\pm$ 0.4} & 41.3 {\scriptsize$\pm$ 2.1} & 51.0 & 7 \\
		ARM \cite{zhangAdaptiveRiskMinimization2021} & 56.0 {\scriptsize$\pm$ 3.1} & 44.3 {\scriptsize$\pm$ 1.4} & \textcolor{gray}{54.9} {\scriptsize$\pm$ 0.3} & \textcolor{gray}{38.6} {\scriptsize$\pm$ 0.6} & 48.5 & 16 \\
		MTL \cite{blanchardDomainGeneralizationMarginal2021} & 55.1 {\scriptsize$\pm$ 0.8} & \underline{51.3} {\scriptsize$\pm$ 2.3} & \textcolor{gray}{57.8} {\scriptsize$\pm$ 0.8} & 41.2 {\scriptsize$\pm$ 2.1} & 51.3 & 6 \\
		GroupDRO \cite{sagawaDistributionallyRobustNeural2020} & 51.9 {\scriptsize$\pm$ 2.9} & 45.4 {\scriptsize$\pm$ 1.8} & \textcolor{cyan}{60.8} {\scriptsize$\pm$ 0.7} & 40.2 {\scriptsize$\pm$ 0.3} & 49.6 & 12 \\
		MLDG \cite{liLearningGeneralizeMetalearning2018} & 57.6 {\scriptsize$\pm$ 3.3} & 46.2 {\scriptsize$\pm$ 1.2} & \textcolor{gray}{58.4} {\scriptsize$\pm$ 0.7} & \textcolor{gray}{37.5} {\scriptsize$\pm$ 0.8} & 49.9 & 11 \\
		MMD \cite{liDomainGeneralizationAdversarial2018} & 61.0 {\scriptsize$\pm$ 2.7} & 43.2 {\scriptsize$\pm$ 0.6} & \textcolor{gray}{57.5} {\scriptsize$\pm$ 1.5} & \textcolor{gray}{38.3} {\scriptsize$\pm$ 2.2} & 50.0 & 10 \\
		DANN \cite{ganinDomainadversarialTrainingNeural2016} & \textcolor{gray}{48.8} {\scriptsize$\pm$ 1.1} & \textcolor{gray}{38.1} {\scriptsize$\pm$ 3.9} & \textcolor{gray}{44.1} {\scriptsize$\pm$ 4.4} & \textcolor{gray}{38.9} {\scriptsize$\pm$ 2.4} & \textcolor{gray}{42.5} & \textcolor{gray}{18} \\
		IRM \cite{arjovskyInvariantRiskMinimization2019} & \textcolor{gray}{49.4} {\scriptsize$\pm$ 4.3} & 47.6 {\scriptsize$\pm$ 2.4} & \textcolor{gray}{58.4} {\scriptsize$\pm$ 1.6} & \textcolor{cyan}{47.8} {\scriptsize$\pm$ 1.5} & 50.8 & 8 \\
		\cdashline{1-6}
		HMOE-DL  & 56.1 {\scriptsize$\pm$ 1.9} & 48.1 {\scriptsize$\pm$ 1.2} & \textcolor{gray}{57.7} {\scriptsize$\pm$ 0.8} & \textcolor{gray}{36.5} {\scriptsize$\pm$ 1.3} & 49.6 & 13 \\
		\hline
		\multicolumn{7}{c}{\emph{w/o Domain Labels}} \\
		\hline
		SelfReg \cite{kimSelfregSelfsupervisedContrastive2021} & 59.0 {\scriptsize$\pm$ 2.4} & 46.0 {\scriptsize$\pm$ 1.1} & 59.6 {\scriptsize$\pm$ 1.7} & 41.5 {\scriptsize$\pm$ 1.1} & 51.5 & 4 \\
		SagNet \cite{namReducingDomainGap2021} & 59.6 {\scriptsize$\pm$ 1.3} & 46.3 {\scriptsize$\pm$ 1.1} & 59.8 {\scriptsize$\pm$ 0.7} & \textcolor{gray}{37.2} {\scriptsize$\pm$ 1.6} & 50.7 & 9 \\
		RSC \cite{huangSelfchallengingImprovesCrossdomain2020} & 51.7 {\scriptsize$\pm$ 6.4} & 46.4 {\scriptsize$\pm$ 0.7} & 59.1 {\scriptsize$\pm$ 0.9} & \textcolor{gray}{39.2} {\scriptsize$\pm$ 1.1} & 49.1 & 14 \\
		DeepAll \cite{vapnikNatureStatisticalLearning1999} & 50.0 {\scriptsize$\pm$ 3.4} & 42.3 {\scriptsize$\pm$ 1.6} & 58.5 {\scriptsize$\pm$ 1.0} & 39.9 {\scriptsize$\pm$ 2.3} & 47.7 & 17 \\
		\cdashline{1-6}
		HMOE-ND  & 60.7 {\scriptsize$\pm$ 3.6} & \textcolor{cyan}{53.2} {\scriptsize$\pm$ 1.5} & \textcolor{gray}{56.7} {\scriptsize$\pm$ 1.2} & \textcolor{gray}{39.6} {\scriptsize$\pm$ 0.3} & \underline{52.5} & \underline{2} \\
		HMOE-MU  & \underline{67.3} {\scriptsize$\pm$ 1.0} & 43.4 {\scriptsize$\pm$ 1.4} & \textcolor{gray}{57.4} {\scriptsize$\pm$ 0.7} & \underline{43.0} {\scriptsize$\pm$ 2.8} & \textcolor{cyan}{52.8} & \textcolor{cyan}{1} \\
		\hline
	\end{tabular}
	\caption{Domain generalization results on TerraInc}
\end{table}