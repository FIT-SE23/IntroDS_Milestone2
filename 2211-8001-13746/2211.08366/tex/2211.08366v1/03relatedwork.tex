\section{Related Work}
\label{relatedwork}

This section covers the most notorious contributions in the field of Collaborative Filtering incorporating subspace clustering techniques; from Predictive (section 3.1) to Recommendation (section 3.2) stances. %approaches; as well as their major advantages and limitations, are highlighted.

\subsection{Rating prediction approaches}

In 2005, George and Merugu first introduced co-clustering as a tool to improve Collaborative Filtering  \citep{BiclustCF-scalablecf-george-2005}. In this work, they used weight Bregman co-clustering \citep{BC-Bregmancoclust-2004} to group users and items along a checkboard subspace structure, as firstly introduced by \cite{BC-Hartigan-partitionbiclust-1972}. Their co-clustering CF approach is based on the idea that the input data's missing ratings can be predicted using a suitable low parameter approximation of the input rating matrix, similar to CF approaches that rely on dimensionality reduction procedures such as singular value decomposition (SVD). %Following this concept, they use co-clustering as a tool to find low parameter approximations. 
The Bregman co-clustering returns non-overlapping subspace clusters covering the whole rating data space, as well as summary statistics derived from the co-clustering solution, to construct a matrix approximation for the input data matrix. For this particular application, the summary statistics are the rating averages of the users, items, and co-clusters. According to the authors, this permits a more reasonable rating approximation than just considering the average value of the co-cluster corresponding to the value we want to predict, which is plausible since it takes into account the biases of individual users and items. After computing the reconstructed approximate matrix, its values are considered for the rating prediction task. The authors designed incremental and parallel versions of the original co-clustering algorithm to build an efficient real-time CF mechanism, capable of updating the co-clusters as new users and ratings enter the system. The results of the work show that their approach achieves satisfactory accuracy compared with baseline matrix factorization models but at a lower computational cost.
    

In 2007, \cite{BCF-applybiclustcf-Castro-2007} suggested a biclustering CF methodology, using a heuristic immune-inspired biclustering technique, denoted BIC-aiNet, that finds biclusters with coherent values. Their methodology is based on two main stages: the biclusters' generation, and the similarity computation between the users and the resulting biclusters. After their artificial immune-inspired network generates the biclusters, they are used to predict how the active user would rate a specific item. The rating prediction is performed by searching for the biclusters that include the active user and item, and then, calculating the residue of each bicluster through mean-squared residue (MSR) \citep{BC-ChengChurch-2000}, %The mean-squared residue of a bicluster $B$, $\mathrm{MSR(B)}$, is defined as:
    
\begin{equation}\label{eq:relatedwork-castro-residuemeasure}
    \mathrm{MSR(B)} = \frac{1}{|U||I|}\sum_{u\in U}\sum_{i\in I}(r_{ui}-r_{Ui}-r_{uI}-r_{UI})^2,
\end{equation}
\vskip 0.1cm
    
\noindent where $|U|$ is the number of users in the bicluster, $|I|$ is the number of items in the bicluster, $r_{ui}$ is the rating of user $u$ assigned to item $i$, $r_{Ui}$ and $r_{uI}$ represent the mean value of user $u$ and item $i$, respectively, and $r_{UI}$ is the mean value of the entire bicluster. Finally, the bicluster with the smaller residue value is selected, and the average of its movies' ratings is used as the prediction. This methodology was evaluated in both rating prediction and Top-\textit{N} recommendation scenarios, achieving better scores than the methods used for comparison, being the constant version of BCF \citep{BCF-nearestbicsconst-Symeonidis-2006}, one of those.

\cite{BCF-franca-2009} also used an immune inspired biclustering algorithm, MOM-aiNET \citep{BC-MOMainet-Coelho2008} to obtain biclusters used to predict missing ratings for recommendation purposes. Their algorithm generates biclusters with a controlled percentage of missing values. Then, they use a quadratic programming approach to predict those values by trying to minimize the mean-squared residue of the bicluster. This approach is viewed as an improvement of the one developed by \cite{BCF-applybiclustcf-Castro-2007} (described above), as the latter simply replaces the missing values in a bicluster by the average of the bicluster's values, not reflecting the trends obtained by coherent biclusters. Whereas, in this approach, the missing values are viewed as variables that should be obtained to minimize the residue.

A more recent work in the direction of biclustering CF was published in 2014 by \cite{BCF-LiangLeng-2014}, who proposed a CF algorithm utilizing information-theoretic co-clustering (ITCC) \citep{BC-ITCC-Dhillon-2003}. Their approach (ITCCCF) consists in performing two-way clustering to discover a set of user clusters and a set of item clusters. After that, they compute the preference of a user $u$ for the cocluster containing an item $i$, $B=(U,I)$, ($P_{u,J}$), for each pair user-item per cluster,  
    
    \begin{equation}\label{eq:userpref}
        P_{u,i} = \frac{|I_u \cap I_i|}{|I_u|},
    \end{equation}    
    
\noindent where $I_u$ are the items that the user $u$ rated and $I_i$ are the items from the cocluster containing item $i$. A matrix of user-cluster preferences is constructed and its values are used to obtain the cosine similarity between each pair of users, $sim_p(u_1,u_2)$. This approach then combines the previous clustering preference similarity with a rating similarity determined through Person's correlation coefficient to find the $k$ most similar users. The $k$-nearest users are selected and the User-based CF is used to generate the rating prediction. Moreover, the whole process is also repeated for the item clusters and the Item-based CF is used to generate a new rating prediction. The final rating prediction is a linear combination that fuses the ratings from the user-based and item-based approaches. In order to evaluate their approach, using real-world datasets, the authors compared it with 5 state-of-the-art methods, some already mentioned in this work (UBCF \citep{UserBasedCF-Resnick-1994}, IBCF \citep{ItemBasedCF-Sarwar-2001}, CBCF \citep{ClusteringCF-Sarwar-2002}, BCC \citep{BiclustCF-scalablecf-george-2005}), being able to surpass all of them regarding prediction accuracy. Figure \ref{fig:CFbasedITCC-Liang2014} provides an overview of how this fusion rating technique works.

      \begin{figure}
        \centering
        \includegraphics[width=\linewidth]{CFbasedITCC-Liang2012.pdf}
        \caption{Outline of ITCCCF rating prediction approach by \cite{BCF-LiangLeng-2014}}
        \label{fig:CFbasedITCC-Liang2014}
    \end{figure}

In 2017, \cite{BCF-biclustcffusion-kantmahara-2017} also proposed a fusion-based approach called Nearest Biclusters Collaborative Filtering with Fusion (NBCFu) to address rating prediction using biclustering. In this approach, the xMOTIFs algorithm \citep{BC-xMotifs-Murali-2003} is used to generate the biclusters that are viewed as quality neighbors of users and items. After the biclusters' generation, the authors use the CjacMD measure \citep{BCF-biclustcffusion-kantmahara-2017-CjacMD-SIMMEASURE} (\autoref{eq:simmeasure-biclustcffusion-kantmahara-2017-CjacMD})  to obtain the K-nearest biclusters of the users and items. Considering a subspace of users $U\subseteq \mathcal{U}$, this similarity measure combines Mean Measure of Divergence (MMD) \citep{BCF-biclustcffusion-kantmahara-2017-MMD-SIMMEASURE}, Jaccard similarity, and cosine similarity,

    \vskip -0.2cm
    \begin{equation}\label{eq:simmeasure-biclustcffusion-kantmahara-2017-CjacMD}
        sim(u,U)_{JacMD}=sim(u,U)_{cos} + sim(u,U)_{Jaccard} + sim(u,U)_{MMD}.
    \end{equation}
\vskip 0.1cm
    
After this step, User-based CF and Item-based CF using cosine similarity are applied to the users/items found in most similar biclusters. Finally, the rating prediction of both approaches is combined through a weighted sum, optimized using gradient descent, to generate a final and more accurate rating prediction. The authors claim that their approach has better accuracy results than some state-of-the-art CF methods, including SVD++ \citep{MatrixFactCF-svd++-koren2008}. \autoref{fig:NBCFu-Kant2017} shows an overview of NBCFu.
    

    \begin{figure}
        \centering
        \includegraphics[width=\linewidth]{NBCFu-Kant2017.pdf}
        \caption{Outline of NBCFu rating prediction approach by \cite{BCF-biclustcffusion-kantmahara-2017}.}
        \label{fig:NBCFu-Kant2017}
    \end{figure}

El-Nabarawy et al. \cite{BCF-artmap-elnabarawy-2016} examined the viability of biclustering ARTMAP (BARTMAP) \citep{BC-BARTMAP-XU-2011} for recommendation purposes. BARTMAP is a biclustering algorithm based on the Adaptive Resonance Theory neural network model \citep{BCF-art-elnabarawy-2016}. The ratings for an active user are predicted through a normalized weighted sum of the ratings that the remaining users gave to the item in the same bicluster, weighted by their correlation with the active user. The similarity score between an active user $u$ and another user $u'$, $sim(u,u')$, belonging to the same bicluster is given by the Pearson correlation coefficient of their ratings in the bicluster,

    \begin{equation}\label{eq:ratingpredartmapelnabarawy-2016}
        \hat{r}_{ui} = \bar{r}_{uI}+\frac{\sum\limits_{u' \in U }(r_{u'i}-\bar{r}_{u'I}) \cdot sim(u,u')}{\sum\limits_{u' \in U}|sim(u,u')|}.
    \end{equation}
\vskip 0.05cm
%\noindent where $\hat{r}_{ui}$ is the rating of an user $u$ to an item $i$ \myworries{verificar se Ã© r ou \hat{r} e colocar aqui}. 
This formula can be seen an adaptation of the rating estimates used in User-based CF but restricted to a subspace. %instead of relying on the entire dataset. 
Using this prediction approach, the users with the highest positive correlation with the active user, have the most impact on the prediction. The algorithm's performance was compared against other collaborating filtering techniques, and it performed similarly to the previously mentioned approach, BIC-aiNet \citep{BCF-applybiclustcf-Castro-2007}.

Recently, \cite{BCF-impactbiclusteringcf-Singh-2018} introduced a new biclustering-based CF technique, BBCF. In this work, the authors use biclustering as a preprocessing step to scale CF approaches. Once the biclustering algorithm is executed, the users are compared with the found biclusters based on the items they have in common, 
    \vskip -0.2cm

    \begin{equation}\label{eq:similarityuserbiclusteruser}
        sim(u,B_k) = \frac{|I_u \cap I_k|}{|I_k|}.
    \end{equation}
    \vskip 0.1cm

Then, similarities between users and biclusters are weighted with the number of users in the bicluster so that biclusters with more users are privileged,
    
    \begin{equation}\label{eq:WF}
        \mathrm{WF}(u,B_k) = sim(u,B_k) \times |U_k|.
    \end{equation}
\vskip 0.08cm

After this step, the K-nearest biclusters per user are merged, creating a larger subspace referred as Nearest Neighbor Setup (NSS). The NSS of each user is viewed as a denser subspace of the U-I matrix, including a subset of users similar to the respective user along a subset of overall items. Finally, a classic CF approach, such as the Item-based, is applied over the personalized NSS of each user to predict the missing ratings. According to the authors, this approach tackles the scalability and sparsity problems that deteriorate the performance of memory-based CF methods, through the usage of the personalized NSSs instead of the entire U-I matrix. The authors evaluated BBCF using QUBIC and Item-based CF as the underlying biclustering and CF approaches, respectively, %using both predictive and classification metrics against CF baseline approaches, 
yielding better scores in most scenarios. However, they also highlight a clear drawback of their methodology. They point out that their approach cannot generate a prediction/recommendation for as many users/items as traditional methods. This handicap occurs because the NSS subspaces used within the CF algorithm may not fully cover the original user-item rating data space. %use only a subset of the users-items as database, so it can not consider all the users/items when modelling. 
    
     \begin{figure}
        \centering
        \includegraphics[width=0.8\linewidth]{BBCF-SinghMehotra-2017.pdf}
        \caption{Outline of BBCF rating prediction approach proposed by \cite{BCF-impactbiclusteringcf-Singh-2018}.}
        \label{fig:BBCF-SinghMehotra-2017}
    \end{figure}
    
\subsection{Top-\textit{N} Recommendation Approaches}

\cite{BCF-nearestbicsconstcoherent-Symeonidis-2008} proposed a neighborhood-based CF algorithm (NBCF) that uses biclustering to improve scalability and accuracy of CF. They also created a similarity measure, defined in \autoref{eq:similarityuserbiclusteruser}, to identify biclusters that better reflect users' preferences. Their approach can be combined with biclustering algorithms that find subspaces with either constant or coherent values. The authors used Bimax and xMOTIFs, respectively.  Upon selecting biclusters with overall constant values, we can only discover sets of users and items with identical rating values. Whereas, a coherent pattern allows to find users and items correlated with more complex behaviors, such as users that, for a subset of items, exhibit coherent ratings. After the discovery of biclusters, they measure the similarity of the active user with each bicluster, finding the k-nearest-biclusters to the user. Then, to capture the influence that each item belonging to a bicluster has over the active user, they use Weighted Frequency (WF), as in \autoref{eq:WF}. Finally, Weighted Frequencies scores are summed per item. %they sum the \textit{WF} values per item. 
The final top-\textit{N} recommended items are the $N$ items with the highest sum of WF.  \autoref{fig:CFNearestBicstopnrecommendation-symeonidis-2007} summarizes the process of this top-\textit{N} recommendation approach. The authors reported that both proposed approaches -- constant and coherent biclustering assumptions -- achieved better results in terms of accuracy and efficiency than classic CF algorithms such as User-based CF \citep{UserBasedCF-Resnick-1994}, Item-based CF \citep{ItemBasedCF-Sarwar-2001}, and clustering-based CF (CBCF) \citep{ClustCF-xue-2005}. They also concluded that despite being slightly less efficient, the recommendation accuracy when considering coherent biclusters outperforms the baseline approach with constant biclusters.

    
    \begin{figure}
        \centering
        \includegraphics[width=0.73\linewidth]{CFNearestBicstopnrecommendation-symeonidis-2007.pdf}
        \caption{Outline of the NBCF top-\textit{N} recommendation approach by \cite{BCF-nearestbicsconstcoherent-Symeonidis-2008}.}
        \label{fig:CFNearestBicstopnrecommendation-symeonidis-2007}
    \end{figure}
    

Still in the context of top-\textit{N} recommendation tasks, \cite{BCF-biclustneighborhoodtopn-alqadah-2015} also  proposed a biclustering neighborhood-based CF method (BCN). In this work, the authors use properties from the field of Formal Concept Analysis (FCA) \citep{BC-biclustneighborhoodtopn-FCA-BOOK}. FCA is a specialized form biclustering aiming at discovering dense subspaces from rating data produced from unary or binary preferences \citep{BC-biclustneighborhoodtopn-FCA-PHDTHESIS-juniarta2019}. FCA algorithms can be adapted to enumerate and order subspaces, which can then be used to identify neighborhoods of closely related subspaces. Alqadah et al. took advantage of these FCA properties to build neighborhoods for active users. Their approach finds the \enquote{smallest} subspace containing the active user $u$, which is the subspace containing the fewest number of users and the greatest number of items.  Then, by exploring the subspace neighborhood through FCA properties, it finds similar users to $u$, and appends the items in the neighborhood to a candidate set of items. Finally, the candidate items are ranked by combining a global and a bicluster neighborhood similarity, and the top $N$ items are returned as recommendations. The global distance between a user $u$ and an item $i$, $g(u,i)$, measures the similarity between the user and the item in the entire matrix,
\vskip -0.05cm
\small
    \begin{equation}
        g(u,i)= \frac{\sum_{i_k \in \mathcal{L}}Jacc(U_i,U_k)}{|I'|},
    \end{equation}
    \normalsize
    \vskip 0.15cm

\noindent where $J(U_i,U_k)$ is the Jaccard index defined over the set of all users who interact with item $i$ and the set of those who interact with item $i_k$, and $\mathcal{I}'$ is the set of items belonging to all found subspaces. In contrast, the local/neighborhood similarity, $l(u,i)$, captures similarities between locally similar users and items, considering the bicluster similarity \citep{BC-biclustneighborhoodtopn-bicsimilarity} using subspaces in which $i$ occurs. The authors claim that their approach is superior to those computing the biclusters offline since, in BCN, they map a user to a bicluster on demand. However, the BCN framework was designed to work on implicit feedback recommendations, and thus it can only be applied to binary data. Nevertheless, to surpass this limitation, it could be an interesting research stream to study the potential of an FCA adaptation capable of dealing with numerical rating data. For instance, in a very recent thesis, \cite{BC-biclustneighborhoodtopn-FCA-PHDTHESIS-juniarta2019} proposed and FCA extension to deal with numerical matrices and discover more flexible types of biclusters which could be potentially relevant for recommendation purposes. 
    

%\subsection{Biclustering in Collaborative Filtering}
%\myworries{Meter aqui coisas do paper survey related work.}
