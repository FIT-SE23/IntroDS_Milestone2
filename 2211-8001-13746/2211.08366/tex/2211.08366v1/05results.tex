\section{Experiments and Results}

This section experimentally assesses the proposed %discusses the issues related to the evaluation of our 
approach against state-of-the-art peers. In particular, we aim to answer the following research questions:

\begin{itemize}

    \item \textbf{RQ1.} How does USBCF compare against baseline CF approaches in terms of quality of predictions and coverage capability?
    \item \textbf{RQ2.} How does the biclustering search and minimum user-bicluster similarity threshold impact USBCF performance?
    \item \textbf{RQ3.} Can USBCF surpass the main limitations presented by the state of the art Biclustering-based CF (BBCF) \citep{BCF-impactbiclusteringcf-Singh-2018}?
    
\end{itemize}

\subsection{Experimental Setting}

\subsubsection{Experimental Platform and Software}
The models were trained on a machine with Intel Xeon Silver 4216 CPU @ 2.40GHz having sixty-four cores and 64GBs of RAM. Regarding the implementation of the approaches, the USBCF and the BBCF were implemented in Python. The remaining approaches consider the available implementation in Surprise \citep{Surpriselib-Hug-2020}, %(version 1.1.1), 
a Python scikit library for building and analyzing Recommender Systems.

\subsubsection{Datasets}

%Experiments were run on two benchmark datasets belonging to different domains, volume, user to item ratio (MovieLens-100k and Jester).

Experiments were run on two benchmark datasets with different volumes (MovieLens-100k and MovieLens-1M).

The MovieLens-100k\footnote{\url{https://grouplens.org/datasets/movielens/100k/}} dataset \citep{Dataset-Movielens-2016}, one of the most popular publicly available benchmark datasets to serve as domain testing for new CF approaches. This version of the MovieLens' dataset contains 100,000 ordinal ratings (1-5 scale) from 943 users on 1,682 movies. The data is in the form of triplets \textit{\textless user, item, rating\textgreater}. Each user has a minimum of 20 ratings made and a maximum of 737, but the average is 106 ratings per user with a standard deviation of 100 ratings. The sparsity of the MovieLens-100k is 93.6\%, in other words, approximately 6.4\% of the entries are filled.

%The Jester\footnote{\url{https://goldberg.berkeley.edu/jester-data/}} dataset \citep{Dataset-Jester-2016}  is a collection of around 4.1 Million continuous ratings (-10.00 to +10.00) of 100 jokes from 73,421 users: collected between April 1999 - May 2003. The data is arranged with one row per user, where the first column gives the number of jokes rated by that user and the next 100 columns give the ratings for the 01 - 100 jokes. The sparsity of the Jester dataset is 43.7\%.

The MovieLens-1M\footnote{\url{https://grouplens.org/datasets/movielens/1m/}} dataset \citep{Dataset-Movielens-2016} is a bigger version of the MovieLens-100k dataset that contains 1,000,209 ratings of 3,707 movies made by 6,040 users. The sparsity of the MovieLens-1M is 95.54\%.





\subsubsection{Experimental Protocol}
We trained and evaluated all the approaches on the canonical u.base/u.test splits of the MovieLens-100k dataset, used to perform a 5-fold cross-validation with 80\% of the ratings as training data and the remaining 20\% for testing per fold. The same procedure was used for the Movielens-1M dataset.

To measure the rating prediction accuracy of the recommendation algorithms, we used two standard metrics, namely \textit{Mean Absolute Error (MAE)},

\begin{equation}
    MAE = \displaystyle\frac{1}{n}\sum_{j=1}^{n}|\hat{r}_{u_ji_j}-r_{u_ji_j}|,
\end{equation}

\noindent and \textit{Root Mean Squared Error (RMSE)},

\begin{equation}
    RMSE = \displaystyle\sqrt{\frac{1}{n}\sum_{j=1}^{n}\big(\hat{r}_{u_ji_j}-r_{u_ji_j}\big)^2}.
\end{equation}




In this work, beyond the accuracy dimension, we also consider coverage measures for our evaluation, as some approaches provide high quality predictions but for only a small part of the user-item pairs.

\begin{itemize}
    \item \textit{Prediction Coverage.} The percentage of user-item pairs for which a prediction can be made \citep{CF-RecommenderSystemshandbook-Ricci-2015}.
    \item \textit{Item Coverage.} The number of items for which predictions can be formed as a percentage of the total number of items \citep{CF-EvaluateCF-Herlocker-2004}.
\end{itemize}


The optimal hyper-parameters for each model have been estimated using cross-validation on the available training data. Details on the selected hyper-parameters and the experiments reproducibility are discussed in section \ref{subsec:reproducibilityofexperiments}.



\subsection{Performance comparison with popular CF approaches (RQ1)}

In this experiment, we compare the performance of the USBCF against baselines and state-of-the-art rating prediction methods on the two benchmark datasets. The results reported for the USBCF approach use a combination of QUBIC2 biclustering solutions with varying minimum of columns, \textit{minCols}~$\in [3, 5, 7, 10, 15, 20]$, a minimum user-bicluster similarity threshold of 0.25, and an Item-based CF with a neighborhood of 20 items as the CF algorithmic choice. We refer to this model as \textbf{USBCF-IB}.


\subsubsection{Methods}

\begin{itemize}
\item \textit{Baseline Rating Predictor} (\textbf{Bias}) \citep{BaselineCF-bias-Koren2010}: user-item bias rating prediction algorithm, denoted by : $\hat{r}_{i,j}= \mu +  b_i + b_j$, where $\mu$ is the global mean rating, $b_j$ is the item bias, and $b_i$ is the user bias. 
    
    \item \textit{User-based CF} (\textbf{USCF}) \citep{UserBasedCF-Resnick-1994}: user-based CF model with mean-centered cosine similarity as similarity function and weighted-average - taking into account the mean ratings of each user - as aggregation function.
    
    \item \textit{Item-based CF} (\textbf{IBCF}) \citep{ItemBasedCF-Sarwar-2001}: item-based CF model with mean-centered cosine similarity as similarity function and weighted-average - taking into account the mean ratings of each user - as aggregation function.
    
    \item \textit{SVD Model by Simon Funk} (\textbf{FunkSVD}) \citep{MatrixFactCF-funksvd-Simon-2006}: the famous SVD-inspired approach popularized by Simon Funk during the Netflix Prize contest. It uses regularized stochastic gradient descent to train the user-feature and the item-feature matrix.
    
    \item \textit{Singular Value Decomposition with Implicit Feedback} (\textbf{SVD++}) \citep{MatrixFactCF-svd++-koren2008}: 
    an extension of the classic SVD approach that incorporates implicit feedback into the SVD model. 
    
    \item \textit{Non-negative Matrix Factorization} (\textbf{NMF}) \citep{MatrixFactCF-NMF-Xin-2014}:
    non-negative matrix factorization model for rating prediction.
    
    \item \textit{Weighted Bregman Co-Clustering} (\textbf{CoCCF}) \citep{BiclustCF-scalablecf-george-2005}: scalable Collaborative Filtering framework that uses weighted Bregman co-clustering and averages to generate predictions.
    
    \item \textit{Biclustering-based CF} (\textbf{BBCF}) \citep{BCF-impactbiclusteringcf-Singh-2018}: state-of-the-art biclustering-based methodology that uses biclustering as a preprocessing step to scale CF approaches.
    
\end{itemize}

\subsubsection{Results}


\begin{table}[!b]
\centering
\small
%\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}l|llll@{}}
\toprule
\multicolumn{1}{c}{Model} &   \multicolumn{1}{c}{MAE} &
  \multicolumn{1}{c}{RMSE} &
  \multicolumn{1}{c}{Coverage (\%)}  &
  \multicolumn{1}{c}{Item Coverage (\%)}
  
  \\ \midrule
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Bias\end{tabular}}	& 0.750 $\pm$ 0.007 & 0.946 $\pm$ 0.009 & 100.00 & 100.00\\


\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}UBCF \end{tabular}} & 0.752 $\pm$ 0.005 & 0.959 $\pm$ 0.007 & 99.83  & 97.85\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}IBCF \end{tabular}}& 0.746 $\pm$ 0.004 & 0.952 $\pm$ 0.005 & 99.83  & 97.85\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}FunkSVD  \end{tabular}}	& 0.720 $\pm$ 0.006 & 0.912 $\pm$ 0.006 & 100.00  & 100.00\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}SVD++ \end{tabular}}	 & 0.719 $\pm$ 0.006 & 0.911 $\pm$ 0.007 & 100.00  & 100.00\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}NMF \end{tabular}}	& 0.719 $\pm$ 0.005 & 0.921 $\pm$ 0.006 & 99.83 & 97.85\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}CoCCF\end{tabular}}	 & 0.757 $\pm$ 0.008 & 0.967 $\pm$ 0.010 & 100.00  & 100.00\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}BBCF-IB \end{tabular}}	 & 0.690 $\pm$ 0.007 & 0.886 $\pm$ 0.006 & 42.52  & 42.65\\
\midrule
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB \\ (minSim=0.25) \end{tabular}}			 & 0.716 $\pm$ 0.003 & 0.913 $\pm$ 0.004 & 80.03 & 65.14\\ 
\bottomrule
\end{tabular}
%}
\caption{Average predictive results on the MovieLens-100k dataset.}
\label{tab:benchmark_results_mvlens}
\end{table}






Results in \autoref{tab:benchmark_results_mvlens} show that USBCF-IB outperforms the Bias, UBCF, IBCF, and CoCCF models in rating prediction accuracy with statistical significance (at $\alpha$=1E-3), falling behind the BBCF-IB model in terms of accuracy yet significantly surpassing this later model in user and item coverage. Generally, the USBCF-IB approach achieves a rating prediction performance comparable to the matrix factorization-based approaches on the targeted data domain. It is important to note that UBCF, IBCF, BBCF-IB, and USBCF-IB accuracy results could possibly be further improved using a different similarity or aggregation method. For instance, subtracting the item's mean rating instead of the user's mean rating tends to be more effective \citep{CF-rethinkRSresearch-cEkstrand-2011}.

In terms of predictive coverage capability, the compared approaches were able to output a prediction for nearly 100\% of the test pairs, while the USBCF-IB model returns predictions for 80.03\% of the pairs and considers 65.14\% of the overall items, in the absence of the principles introduced along section \ref{coclussec}, nearly doubling the predictive coverage of the BBCF model. Focusing on the USBCF-IB and IBCF models on the Movielens-100k dataset, the results suggest the USBCF-IB approach can improve the IBCF accuracy results with a slight decrease in the coverage capability.

To investigate if the USBCF-IB model produced better predictions for the test pairs it made a prediction, we complemented the USBCF-IB with predictions of alternative approaches for the test pairs the USBCF-IB could not output a prediction. The results in \autoref{tab:usbcf_complemented_coclust_ibmvlens} confirm the USBCF is improving the classic IBCF (k=20) model, and show how the performance of the hybrid approaches vary according to the minimum user-bicluster similarity (minSim) USBCF parameter. Combining USBCF-UB with a CoCCF model also improves the quality of the predictions considerably.





\begin{table}[!t]
%\resizebox{\textwidth}{!}{%
\centering
\small
\begin{tabular}{@{}l|ccccc@{}}
%\small
\toprule
\multicolumn{1}{c}{Model} &   \multicolumn{1}{c}{MAE} &
  \multicolumn{1}{c}{RMSE} &
  \multicolumn{1}{c}{Coverage (\%)}  &
  \multicolumn{1}{c}{Item Coverage (\%)}
  
  \\ \midrule
  
  
 \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB+IBCF (minSim=0.1)\end{tabular}}			 & 0.742 $\pm$ 0.005 & 0.947 $\pm$ 0.005 & 99.83 & 97.85\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB+IBCF (minSim=0.2)\end{tabular}}			  & 0.741 $\pm$ 0.004 & 0.946 $\pm$ 0.005 & 99.83 & 97.85\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB+IBCF (minSim=0.3)\end{tabular}}			& 0.740 $\pm$ 0.004 & 0.945 $\pm$ 0.004 & 99.83 & 97.85\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB+IBCF (minSim=0.4)\end{tabular}}			  & 0.739 $\pm$ 0.004 & 0.945 $\pm$ 0.005 & 99.83 & 97.85\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB+IBCF (minSim=0.5)\end{tabular}}			 & 0.740 $\pm$ 0.004 & 0.947 $\pm$ 0.005 & 99.83 & 97.85\\

\midrule

\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB+CoCCF (minSim=0.1)\end{tabular}}			 & 0.742 $\pm$ 0.004 & 0.947 $\pm$ 0.005 & 100.00 & 100.00\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB+CoCCF (minSim=0.2)\end{tabular}}			& 0.742 $\pm$ 0.004 & 0.947 $\pm$ 0.005 & 100.00 & 100.00\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB+CoCCF (minSim=0.3)\end{tabular}}			  & 0.743 $\pm$ 0.005 & 0.950 $\pm$ 0.006 & 100.00 & 100.00\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB+CoCCF (minSim=0.4)\end{tabular}}			 & 0.745 $\pm$ 0.005 & 0.954 $\pm$ 0.008 & 100.00 & 100.00\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB+CoCCF (minSim=0.5)\end{tabular}}			  & 0.750 $\pm$ 0.007 & 0.960 $\pm$ 0.010 & 100.00 & 100.00\\

\bottomrule
\end{tabular}
%}
\caption{Predictive accuracy and coverage of USBCF when complemented with other CF approaches on the MovieLens-100k dataset.}
\label{tab:usbcf_complemented_coclust_ibmvlens}
\end{table}


Results on the MovieLens-1M dataset also indicate a competitive predictive accuracy of the proposed approach against the benchmarks methods. \autoref{tab:benchmark_results_mvlens1m} shows that in this data, the USBCF-IB model, with a minimum similarity of 0.25, retrieves an average mean absolute error of 0.686, covering 90.45\% of the user-item pairs. Approaches based on matrix factorization strategies such as NMF were not included as they were not able to converge in due time for adequate parameterization settings considering the size of the dataset. When the complementing USBCF-IB model with the remaining 9.55\% of the predictions, the results in \autoref{tab:usbcf_complemented_coclust_ibmovilens-1m} support the hypothesis that the USBCF-IB model improves the classic IBCF.

\begin{table}[H]
\small
\centering
%\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}l|cccc@{}}
\toprule
\multicolumn{1}{c}{Model} &   \multicolumn{1}{c}{MAE} &
  \multicolumn{1}{c}{RMSE} &
  \multicolumn{1}{c}{Coverage (\%)}  &
  \multicolumn{1}{c}{Item Coverage (\%)}
  
  \\ \midrule
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Bias\end{tabular}}	 & 0.719 $\pm$ 0.001 & 0.909 $\pm$ 0.001 & 100.00 & 100.00\\

\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}UBCF \end{tabular}}  & 0.735 $\pm$ 0.001 & 0.932 $\pm$ 0.001 & 99.98  & 99.22\\


\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}IBCF\end{tabular}} & 0.704 $\pm$ 0.001 & 0.899 $\pm$ 0.001 & 99.98 & 99.22 \\


\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}CoCCF\end{tabular}}	 & 0.717 $\pm$ 0.001 & 0.915 $\pm$ 0.002 & 100.00  & 100.00\\
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}BBCF\end{tabular}} 	 & 0.676 $\pm$ 0.001 & 0.866 $\pm$ 0.001 & 71.08 & 61.30\\

\midrule
\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB (minSim=0.25)\end{tabular}}			 & 0.686 $\pm$ 0.001 & 0.876 $\pm$ 0.001 & 90.45 & 77.21\\
\bottomrule

\end{tabular}
%}
\caption{Average predictive results of baseline and subspace clustering-based approaches on the MovieLens-1M dataset.}
\label{tab:benchmark_results_mvlens1m}
\end{table}



\begin{table}[H]
\resizebox{\textwidth}{!}{%
\centering
%\small
\begin{tabular}{@{}l|llll@{}}
%\small
\toprule
\multicolumn{1}{c}{Model} &   \multicolumn{1}{c}{MAE} &
  \multicolumn{1}{c}{RMSE} &
  \multicolumn{1}{c}{Coverage (\%)}  &
  \multicolumn{1}{c}{Item Coverage (\%)}
  
  \\ \midrule
  
 \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB+IBCF (minSim=0.25)\end{tabular}}			 & 0.698 $\pm$ 0.001 & 0.892 $\pm$ 0.001 & 99.98 & 99.22\\

\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB+CoCCF (minSim=0.25)\end{tabular}} & 0.700 $\pm$ 0.001 & 0.894 $\pm$ 0.001 & 100.00 & 100.00\\



\bottomrule
\end{tabular}
}
\caption{Predictive accuracy and coverage of USBCF complemented with other CF approaches on the MovieLens-1M dataset.}
\label{tab:usbcf_complemented_coclust_ibmovilens-1m}
\end{table}

\begin{comment}

\begin{table}[H]
\resizebox{\textwidth}{!}{%
\centering
%\small
\begin{tabular}{@{}l|lllll@{}}
%\small
\toprule
\multicolumn{1}{c}{Model} &   \multicolumn{1}{c}{MAE} &
  \multicolumn{1}{c}{RMSE} &
  \multicolumn{1}{c}{Coverage (\%)}  &
  \multicolumn{1}{c}{Item Coverage (\%)}
  
  \\ \midrule
  
 \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB+IBCF (minSim=0.25)\end{tabular}}			 & a & a & a & a\\

\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB+CoCCF (minSim=0.25)\end{tabular}}			 & a & a & a & a\\






\bottomrule
\end{tabular}
}
\caption{Predictive accuracy and coverage of USBCF complemented with other CF approaches on the Jester dataset.}
\label{tab:usbcf_complemented_coclust_ibjester}
\end{table}
\end{comment}


The testing time of USBCF-IB is computationally efficient, bounded by the lightweighted computational complexity of the subsequent item-based CF step. USBCF-IB training time is also efficient under heuristic biclustering searches and the creation of the personalized dataset (linear on the number of biclusters and their pattern length). Finally, once biclusters are discovered on referenced rating data, USBCF-IB can be applied in an online manner to predict preferences for unseen users.


\subsection{Biclustering and user-bicluster similarity in USBCF (RQ2)}\label{subsec:rq2}

In the second experiment, we study the impact of biclustering search on the USBCF performance using different QUBIC2 parameterizations. We also assess how the user-bicluster similarity affects the size of the personalized datasets produced by the approach, directly impacting the accuracy and coverage results. Accordingly, we varied the parameter of QUBIC2 that controls the shape of biclusters and the USBCF user-bicluster similarity threshold, both % to 0.2 and  minimum amount of matrix columns per bicluster, 
affecting the number, size and format of the biclusters produced and therefore the properties of the personalized data spaces.

\autoref{fig:usbcfminsim02_rmse_cov} shows that, for the MovieLens-100k dataset, the average quality of the predictions tends to be worse for biclustering solutions with a larger minimum of columns per bicluster. The coverage capability peaks for biclustering solutions with a minimum of 10 columns per bicluster.

    \begin{figure}[H]
        \centering
            \begin{subfigure}{0.49\textwidth}
            \includegraphics[width=\textwidth]{usbcf_mincols_rmse_mvlens100k.pdf}
            \caption{RMSE} %with different minimum columns per bicluster.}
            \end{subfigure}
      %
           \begin{subfigure}{0.49\textwidth}
            \centering
            \includegraphics[width=\linewidth]{usbcf_mincols_cov_mvlens100k.pdf}
            \caption{Coverage} %with different minimum columns per bicluster.}
        \end{subfigure}
    \caption{Effect of the minimum columns per bicluster parameter in the performance.}
    \label{fig:usbcfminsim02_rmse_cov}
    \end{figure}



We also tested the behavior of the approach when using biclusters from multiple biclustering solutions. We ran the biclustering algorithm with the minimum columns parameter in \{3, 5, 7, 10, 15, 20\}, combining the solutions and filtering non-maximal biclusters. The gathered results in \autoref{fig:USBCFComb_results_varyingminsim} against \autoref{fig:usbcfminsim02_rmse_cov} show that the combination of biclustering solutions with distinct properties produces personalized CF models with higher coverage capability and lower RMSE. 

    \begin{figure}[H]
        \centering
            \begin{subfigure}{0.49\textwidth}
            \includegraphics[width=\textwidth]{usbcfcomb_minsim_rmse_mvlens100k.pdf}
            \caption{RMSE}% with different user-bicluster similarity threshold.}
            \label{fig:usbcfcomb_minsim_rmse}
            \end{subfigure}
      %
           \begin{subfigure}{0.49\textwidth}
            \centering
            \includegraphics[width=\linewidth]{usbcfcomb_minsim_cov_mvlens100k.pdf}
            \caption{Coverage} %with different user-bicluster similarity threshold.}
            \label{fig:usbcfcomb_minsim_cov.pdf}
        \end{subfigure}
    \caption{Sensitivity of USBCF-IB to the user-bicluster similarity threshold parameter. }
    \label{fig:USBCFComb_results_varyingminsim}
    \end{figure}
  

%\begin{table}[H]
%\centering
%\resizebox{\textwidth}{!}{%
%\begin{tabular}{@{}l|lllll@{}}
%\toprule
%\multicolumn{1}{c}{Model} &   \multicolumn{1}{c}{MAE} &
%  \multicolumn{1}{c}{RMSE} &
%  \multicolumn{1}{c}{Coverage (\%)} &
%  \multicolumn{1}{c}{Fit Time} &
%  \multicolumn{1}{c}{Test Time} 
%  \\ \midrule
%\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB\%\(minSim=0.1)\end{tabular}}			 & 0.734 $\pm$ %0.005 & 0.933 $\pm$ 0.008 & 92.53 & 00:17:14 & %00:00:08\\
%\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB\%\(minSim=0.2)\end{tabular}}			 & 0.725 $\pm$ %0.004 & 0.922 $\pm$ 0.008 & 86.02 & 00:14:29 & %00:00:08\\
%\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB\%\(minSim=0.3)\end{tabular}}			 & 0.711 $\pm$ %0.004 & 0.907 $\pm$ 0.005 & 73.55 & 00:12:45 & %00:00:06\\
%\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB\%\(minSim=0.4)\end{tabular}}			 & 0.692 $\pm$ %0.007 & 0.884 $\pm$ 0.006 & 53.82 & 00:11:39 & %00:00:04\\
%\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}USBCF-IB\%\(minSim=0.5)\end{tabular}}			 & 0.671 $\pm$ %0.008 & 0.860 $\pm$ 0.009 & 32.36 & 00:10:54 & %00:00:02\\
% \bottomrule
%\end{tabular}
%}
%\caption{Average performance of USBCF when combining %multiple biclustering solutions.}
%\label{tab:USBCFComb_results_varyingminsim}
%\end{table}

We finally examined the average size of the personalized datasets when varying the user-bicluster similarity threshold. \autoref{fig:usbcf_min_avgsizes} shows that the USBCF minimum similarity parameter affects the dimensions of the personalized datasets, with lower threshold values creating larger datasets.  


        \begin{figure}[H]
        \centering
            \begin{subfigure}{0.49\textwidth}
            \includegraphics[width=\textwidth]{usbcfcomb_minsim_avgrows_mvlens100k.pdf}
            \caption{Average number of users per neighborhood.}
            \label{fig:casestudy_bbcf_NNBics_avgrows}
            \end{subfigure}
      %
           \begin{subfigure}{0.49\textwidth}
            \centering
            \includegraphics[width=\linewidth]{usbcfcomb_minsim_avgcols_mvlens100k.pdf}
            \caption{Average number of items per neighborhood.}
            \label{fig:casestudy_bbcf_NNBics_avgcols}
        \end{subfigure}
    \caption{Effect of the minimum user-bicluster similarity threshold on the average size of the personalized data spaces in USBCF. }
    \label{fig:usbcf_min_avgsizes}
    \end{figure}


    
\subsection{Performance comparison with Biclustering-based CF (BBCF) (RQ3)}
    
The goal of this third experiment is to compare USBCF against the state-of-the-art biclustering-based methodology, BBCF, introduced by \cite{BCF-impactbiclusteringcf-Singh-2018}. The reported results for BBCF were gathered using an hyperparameterized QUBIC2 biclustering solution, which yielded optimal behavior with a minimum of 15 columns per bicluster. Likewise the BBCF original work, we vary the number of biclusters per neighborhood parameter (\textit{NNBics}).

Results in \autoref{fig:bbcf_nnbrs_rmse_cov} show that smaller sets of biclusters per neighborhood are more favorable for the quality of the rating predictions. However, there is a clear RMSE-coverage trade-off, as the model's predictive coverage capability tends to degrade as the number of bicluster per neighborhood decreases. \autoref{fig:bbcf_nnbrs_avgsizes} shows that the size of the personalized datasets increase with larger values for the \textit{NNBics} parameter. These results highlight that, as expected, larger values of \textit{NNBics} lead to more complex personalized models, impacting the scalability of the approach.

    \begin{figure}[H]
        \centering
            \begin{subfigure}{0.49\textwidth}
            \includegraphics[width=\textwidth]{bbcf_nnbics_rmse_mvlens100k.pdf}
            \caption{Average RMSE of different biclustering neighborhood sizes.}
            \label{cc}
            \end{subfigure}
      %
           \begin{subfigure}{0.49\textwidth}
            \centering
            \includegraphics[width=\linewidth]{bbcf_nnbics_cov_mvlens100k.pdf}
            \caption{Average coverage of different biclustering neighborhood sizes.}
            \label{aa}
        \end{subfigure}
    \caption{Sensitivity of BBCF to the size of the biclustering neighborhoods. }
    \label{fig:bbcf_nnbrs_rmse_cov}
    \end{figure}
    



    \begin{figure}[H]
        \centering
            \begin{subfigure}{0.49\textwidth}
            \includegraphics[width=\textwidth]{bbcf_nnbics_avgrows_mvlens100k.pdf}
            \caption{Average number of users per NNBics setup.}
            \end{subfigure}
      %
           \begin{subfigure}{0.49\textwidth}
            \centering
            \includegraphics[width=\linewidth]{bbcf_nnbics_avgcols_mvlens100k.pdf}
            \caption{Average number of items per NNBics setup.}
        \end{subfigure}
    \caption{Effect of the number of biclusters in the neighborhood parameter on the average size of the personalized datasets in BBCF.  }
    \label{fig:bbcf_nnbrs_avgsizes}
    \end{figure}

Comparing these results with the ones from the previous experiment (\autoref{subsec:rq2}), we conclude that for models with similar coverage, USBCF model surpasses BBCF in prediction error. Moreover, the USBCF approach obtains higher coverage results than BBCF while using smaller personalized datasets.

\subsection{Reproducibility of the Experiments}
\label{subsec:reproducibilityofexperiments}

The source code of USBCF is available at our GitHub repository \footnote{\url{https://git.lasige.di.fc.ul.pt/mmsilva/usbcf-paper}}. The code to reproduce the experiments is also available in the same repository, as well as the obtained results. Regarding the hyper-parameters, we used the following defaults during the experiments: 
\begin{itemize}
    \item UBCF and IBCF: varied maximum number of users/items in the neighborhood (k). We present results for k = 20 as the results show it is an adequate value for the neighborhood size regarding predictive accuracy on both datasets.
    
    \item FunkSVD, SVD++, and NMF: grid search over the three main hyper-parameters for the optimization algorithm: number of features (n\_factors), number of iterations (n\_epochs) and regularization term (reg). %of their respective optimization algorithm. 
    For the MovieLens-100k data, the best hyper-parameters were n\_factors = 100, n\_epochs = 100, reg = 0.1 for SVD;  n\_factors = 30, n\_epochs = 50, reg = 0.1 for SVD++; and  n\_factors = 200, n\_epochs = 100, reg = 0.05 for NMF. The reported results use these optimal hyper-parameters estimates. As for the MovieLens-1M dataset, the best hyper-parameters were not attained as the approaches did not converge in due time.
    
    \item BBCF-IB: Varied the hyper-parameter number of nearest biclusters (nnbrs) from 50 to 300 for the Movielens-100k dataset and from 50 to 1000 for the Movielens-1M dataset, both using an Item-Based approach (k = 20) as CF algorithm. We also tested the minimum number of columns per bicluster (minCols) QUBIC2 parameter from 3 to 20. The best hyper-parameters considering predictive and coverage results were nnbrs = 50 and minCols = 15 for the Movielens-100k dataset; and nnbrs = 500 and minCols = 15 for the Movielens-1M dataset.
    
    \item USBCF-IB: Varied the minimum user-bicluster similarity threshold (minSim) parameter from 0.1 to 0.5, and used an Item-Based approach (k = 20) as CF algorithm. The best minSim considering predictive and coverage results were minSim = 0.25 for both datasets.
    
\end{itemize}
