\documentclass{article}


\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{graphicx}

\usepackage{colortbl}

\newif\ifdraft
\drafttrue
 %FS: Toggles between draft mode (i.e. with \drafttrue uncommented) 
 %and finalcopy mode (i.e. with \drafttrue commented) 

\newcommand{\citedexcerpt}[2]{\ifdraft{\leavevmode\color{blue}{``{#1}''\cite{#2}}}\else{\vspace{0ex}}\fi}
 %FS: For inserting excerpts of text by other authors when in draft mode
 %(excerpts disappear when in finalcopy mode)
 
\newcommand{\blue}[1]{\ifdraft{\leavevmode\color{blue}{#1}}\else{\leavevmode\color{black}{#1}}\fi}
 %FS: For typesetting text in blue when in draft mode
 %(this text is typeset in black when in finalcopy mode)

\newcommand{\replace}[2]{\ifdraft{\leavevmode\strikeout{#1} \leavevmode\color{blue}{#2}}\else{\leavevmode\color{black}{#2}}\fi}
 %FS: For replacing text with other text when in draft mode
 %(the replacing text is typeset in black and the replaced text disappears when in finalcopy mode)


\newcommand{\fabsebcomment}[1]{\ifdraft{\leavevmode\color{cyan}{[FS]: 
 {#1}}}\else{\vspace{0ex}}\fi}
\newcommand{\manucomment}[1]{\ifdraft{\leavevmode\color{red}{[MF]: 
 {#1}}}\else{\vspace{0ex}}\fi}
\newcommand{\alexcomment}[1]{\ifdraft{\leavevmode\color{purple}{[AM]: 
 {#1}}}\else{\vspace{0ex}}\fi}
\newcommand{\afabscomment}[1]{\ifdraft{\leavevmode\color{violet}{[AF]: 
 {#1}}}\else{\vspace{0ex}}\fi}
\newcommand{\pedroscomment}[1]{\ifdraft{\leavevmode\color{magenta}{[AP]: 
 {#1}}}\else{\vspace{0ex}}\fi}
\newcommand{\silscomment}[1]{\ifdraft{\leavevmode\color{brown}{[SC]: 
 {#1}}}\else{\vspace{0ex}}\fi}
\newcommand{\barbscomment}[1]{\ifdraft{\leavevmode\color{red}{[BB]: 
 {#1}}}\else{\vspace{0ex}}\fi}
\newcommand{ \mirkoscomment}[1]{\ifdraft{\leavevmode\color{red}{[MB]: 
 {#1}}}\else{\vspace{0ex}}\fi}
 %FS: for typesetting comments by each individual author when in draft mode
 %(these comments disappear when in finalcopy mode)
 %Colours allowed are black, red, blue, cyan, brown, 
 %magenta, violet, green, yellow, pink

\newcommand{\strikeout}[1]{\ifdraft{\st{#1}}\else{\vspace{0ex}}\fi}
 %FS: For striking out text when in draft mode
 %(striked-out text disappear when in finalcopy mode)
 
\newcommand{\highlight}[1]{\ifdraft{\hl{#1}}\else{#1}\fi}
 %FS: For hjghlighting text when in draft mode 
 %(highlighted text is typeset without highlighting when in finalcopy mode)

% ---- Counters -------------------

\setcounter{secnumdepth}{3}
 %FS: defines the depth of section numbering
 
\setcounter{tocdepth}{3}
 %FS: defines which sections are listed in the table of contents

% ---- Packages --------------------


\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{subcaption}
\newcommand{\codecomment}[1]{\State {\leavevmode\color{gray}{// {#1}}}}
\newcommand{\aftercodecomment}[1]{{\leavevmode\color{gray}{\hspace{1ex} // {#1}}}}
\newcommand{\scikitml}{\textsc{scikit-multilearn}}
\usepackage{dcolumn,booktabs}
\newcolumntype{d}[1]{D{.}{.}{#1}}


%\usepackage{a4}
 %FS: Makes pages more compact

%\usepackage[lined,boxed,linesnumbered]{algorithm2e}
 %FS: Allows writing pseudocode

\usepackage{array}
 %FS: Allows the definition of \newcolumntype's

\usepackage{amsmath}
 %FS: Allows the use of many math symbols of practical use
 
%\usepackage{cite}
 %FS: Sorts in-line numerical citations
 
%\usepackage{endnotes}
 %FS: for generating endnotes instead of footnotes: also requires
 %command
% \let\footnote=\endnote
 %which should be commented if regular footnotes are instead required
 
\usepackage[english]{babel}
 %FS: Makes text processing (e.g., hyphenation) language-dependent
 
\usepackage[T1]{fontenc}
 %FS: required by the tipa package

\usepackage[right]{lineno}
 %FS: Allows the use of line numbers and \linelabel{} commands. Command 
 \linenumbers
 %always needs to be uncommented if there are \linelabel{} commands in the text.
 %In this case, leave
 \renewcommand\makeLineNumber{}
 %uncommented to set line numbering off without the need of removing 
 %\linelabel{} commands, and comment it to set line numbering on

\usepackage{multibib}
 %FS: Allows splitting the bibliography into primary and secondary 
 %sources. If this is desired, commands
 %\newcites{prim}{Primary sources}
 %\newcites{sec}{References}
 %need to be uncommented, and bibtex needs to be run from terminal

\usepackage{multicol} 
 %FS: For producing multicolumns in the tabular environment
 
\usepackage{multirow} 
 %FS: For producing multirows in the tabular environment
 
%\usepackage[]{natbib} 
 %FS: For named-style bibliographical citations
 %Often needs to precede other packages
 %Use bibstyle ``apalike`` for APA-like references
 %Comment when opting for numerical citations
 
\usepackage{pifont}
 %FS: for using symbols such as \cmark and \xmark
 
\usepackage{rotating} 
 %FS: For rotating text 90 degrees in the tabular environment
 
\usepackage{soul} 
 %FS: allows striking out (\st{}) and highlighting (\hl{}) text. Command
 \sethlcolor{pink}
 %defines the highlighting colour

%\usepackage[table]{xcolor}
 %FS: Allows the use of coloured text

\usepackage{tikz}
 %FS: for making drawings
 
\usepackage{tipa}
 %FS: fonts for the phonetic alphabet
 
\usepackage[utf8]{inputenc} 
 %FS: For encoding the text in utf8 
 
\usepackage{url} 
 %FS: For correctly typesetting URLs
 
\usepackage{capt-of}
 %AM: for indicating the caption of minipage's components

% ---- Commands --------------------

\DeclareMathOperator{\bias}{B}
\DeclareMathOperator{\aae}{AE}
\DeclareMathOperator{\nae}{NAE}
\DeclareMathOperator{\rae}{RAE}
\DeclareMathOperator{\nrae}{NRAE}
\DeclareMathOperator{\kld}{KLD}
\DeclareMathOperator{\nkld}{NKLD}
\DeclareMathOperator{\emd}{EMD}
\DeclareMathOperator{\jsd}{JSD}
\DeclareMathOperator{\hd}{HD}
\DeclareMathOperator{\nhd}{NHD}
\DeclareMathOperator{\pd}{PD}
\DeclareMathOperator{\rpd}{RPD}
\DeclareMathOperator{\se}{SE}
\DeclareMathOperator{\nse}{NSE}
\DeclareMathOperator{\cra}{CR}
\DeclareMathOperator{\dra}{DR}
\DeclareMathOperator{\dr}{DR}
\DeclareMathOperator{\bcd}{BCD}
\DeclareMathOperator{\nas}{NAS}
\DeclareMathOperator{\nss}{NSS}
\DeclareMathOperator{\md}{MD}
\DeclareMathOperator{\nmd}{NMD}
\DeclareMathOperator{\rnod}{RNOD}

\newcommand{\MLPE}{\mathrm{MLPE}}
\newcommand{\CC}{\mathrm{CC}}
\newcommand{\PCC}{\mathrm{PCC}}
\newcommand{\ACC}{\mathrm{ACC}}
\newcommand{\PACC}{\mathrm{PACC}}
\newcommand{\RE}{\mathrm{RE}}

\newcommand{\TP}{\mathrm{TP}}
\newcommand{\TN}{\mathrm{TN}}
\newcommand{\FP}{\mathrm{FP}}
\newcommand{\FN}{\mathrm{FN}}
\newcommand{\POS}{\mathrm{POS}}
\newcommand{\NEG}{\mathrm{NEG}}

\newcommand{\TPR}{\mathrm{TPR}}
\newcommand{\FPR}{\mathrm{FPR}}
\newcommand{\TNR}{\mathrm{TNR}}
\newcommand{\FNR}{\mathrm{FNR}}

\newcommand{\bqbc}{\textsc{BC+BA}}
\newcommand{\bqmc}{\textsc{MLC+BA}}
\newcommand{\mqbc}{\textsc{BC+MLA}}
\newcommand{\mqmc}{\textsc{MLC+MLA}}
\newcommand{\abse}{$\operatorname{AE}$}
\newcommand{\rabse}{$\operatorname{RAE}$}

\newcommand{\roberta}{RoBERTa}
\newcommand{\toefl}{\textsc{ToEFL11}}
\newcommand{\efcamdat}{\textsc{EFCamDat2}}
\newcommand{\reddit}{\textsc{REDDIT-L2}}
\newcommand{\reddituk}{\textsc{REDDIT-UK}}
\newcommand{\locness}{\textsc{LOCNESS}}
\newcommand{\toeflbin}{\toefl/\locness}
\newcommand{\efcamdatbin}{\efcamdat/\locness}
\newcommand{\redditbin}{\reddit/\reddituk}
\newcommand{\pdag}{\phantom{^{\dag}}}

\newcommand{\BC}{BC}
\newcommand{\BQ}{BQ}
\newcommand{\OQ}{OQ}
\newcommand{\MLC}{MLC}
\newcommand{\SLQ}{SLQ}
\newcommand{\MLQ}{MLQ}
\newcommand{\SEP}{ }

\newcommand{\indfn}[1]{\mathbf{1}\hspace{-3px}\left[#1\right]}

\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}

\newcommand{\dsum}{\displaystyle\sum}
 %FS: Allows the \sum environment to be typeset in displayed equation mode

\newcommand{\gr}{\cellcolor[gray]{.7}}
 %FS: Grays out a single cell in a tabular environment

\newcommand{\killpunct}[1]{} 
 %FS: Handles bib citations where title ends with a question mark or exclamation mark

\newcommand{\side}[1]{\begin{sideways}{#1}\end{sideways}}
 %FS: For typesetting text tilted 90 degrees in tabular environments
 
\newcommand{\PO}{\phantom{0}}
 %FS: Adds a phantom space (useful in tables of numbers)

% ---- Renewed commands ------------

% \renewcommand{\baselinestretch}{1.00}
 
% ---- Theorems --------------------

\newtheorem{revcomment}{Reviewer Comment \#}[section]
\newtheorem{edscomment}{Editor Comment}[section]
 %FS: Useful for writing the ``Letter to the reviewers''
 
\newtheorem{answer}{Answer}[section]
\newtheorem{axiom}{Axiom}[section]

% ---- Column types ----------------

\newcolumntype{.}{D{.}{.}{-1}}
 % ???

\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}
 % ???

\newcolumntype{N}{@{}m{0pt}@{}}
 % ???

\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
 % ???

\newcolumntype{Y}{>{\centering\arraybackslash}X}
 % ???
 
%-----------------------------------------
% ---- End of Fab's preamble -------------
%-----------------------------------------


\title{Multi-Label Quantification}

\author{
Alejandro Moreo \\
  Istituto di Scienza e Tecnologie dell'Informazione\\
Consiglio Nazionale delle Ricerche\\
Via Giuseppe Moruzzi 1\\
Pisa, Italy, 56124 \\
  \texttt{alejandro.moreo@isti.cnr.it} \\
  %% examples of more authors
   \And
Manuel Francisco \\
Department of Computer Science and Artificial
Intelligence\\ 
University of Granada\\
C Periodista Daniel Saucedo Aranda s/n\\
  Granada, Spain 18071 \\
  \texttt{francisco@decsai.ugr.es} \\
  \And
Fabrizio Sebastiani \\
  Istituto di Scienza e Tecnologie dell'Informazione\\
Consiglio Nazionale delle Ricerche\\
Via Giuseppe Moruzzi 1\\
Pisa, Italy, 56124 \\
  \texttt{fabrizio.sebastiani@isti.cnr.it} \\
}

%\author{
%Alejandro Moreo \\
%  Istituto di Scienza e Tecnologie dell'Informazione\\
%Consiglio Nazionale delle Ricerche\\
%Via Giuseppe Moruzzi 1\\
%Pisa, Italy, 56124 \\
%  \texttt{alejandro.moreo@isti.cnr.it} \\
%  %% examples of more authors
%   \And
%Manuel Francisco \\
%Department of Computer Science and Artificial
%Intelligence\\ 
%University of Granada\\
%C Periodista Daniel Saucedo Aranda s/n\\
%  Granada, Spain 18071 \\
%  \texttt{francisco@decsai.ugr.es} \\
%  \And
%Fabrizio Sebastiani \\
%  Istituto di Scienza e Tecnologie dell'Informazione\\
%Consiglio Nazionale delle Ricerche\\
%Via Giuseppe Moruzzi 1\\
%Pisa, Italy, 56124 \\
%  \texttt{fabrizio.sebastiani@isti.cnr.it} \\
%}


%.--------


\begin{document}

\maketitle

%\renewcommand{\shortauthors}{Moreo et al.}

\begin{abstract}
  Quantification, variously called \emph{supervised prevalence
  estimation} or \emph{learning to quantify}, is the supervised
  learning task of generating predictors of the relative frequencies
  (a.k.a.\ \emph{prevalence values}) of the classes of interest in
  unlabelled data samples. While many quantification methods have been
  proposed in the past for binary problems and, to a lesser extent,
  single-label multiclass problems, the multi-label setting (i.e., the
  scenario in which the classes of interest are not mutually
  exclusive) remains by and large unexplored. A straightforward
  solution to the multi-label quantification problem could simply
  consist of recasting the problem as a set of independent binary
  quantification problems. Such a solution is simple but naïve, since
  the independence assumption upon which it rests is, in most cases,
  not satisfied. In these cases, knowing the relative frequency of one
  class could be of help in determining the prevalence of other
  related classes.  We propose the first truly multi-label
  quantification methods, i.e., methods for inferring estimators of
  class prevalence values that strive to leverage the stochastic
  dependencies among the classes of interest in order to predict their
  relative frequencies more accurately. We show empirical evidence
  that natively multi-label solutions outperform the naïve approaches
  by a large margin. The code to reproduce all our experiments is
  available online.
\end{abstract}

\keywords{Quantification, Learning to Quantify, Supervised Prevalence
Estimation, Class Prior Estimation, Multi-Label Quantification,
Multi-Label Learning}

%\received{31 December 2022} \received[revised]{31 December 2022}
%\received[accepted]{31 December 2022}

%\maketitle

\newpage

% \tableofcontents

% ----------------------------------------------------------------------

\section{Introduction}
\label{sec:intro}

\noindent Many fields such as the social sciences, political science,
market research, or epidemiology (to name a few), are inherently
interested in \emph{aggregate} data, i.e., in how populations of
individuals are distributed according to one or more indicators of
interest. Researchers who operate in these specialty areas are instead
little interested in the individuals \textit{per se}, since in these
fields the individuals are relevant only inasmuch as they are members
of the population of interest; in other words, disciplines such as the
above are interested ``not in the needle, but in the
haystack''~\cite{Hopkins:2010fk}.

Sometimes, researchers active in these fields use supervised learning
to obtain the data they need. For instance, epidemiologists interested
in the distribution of the causes of death across different
geographical regions may sometimes need to \emph{infer} the cause of
death of each person by classifying, via a machine-learned text
classifier, a verbal description of the symptoms that affected a
deceased person~\cite{King:2008fk}. However, these researchers are not
specifically interested in the class (representing a given cause of
death) to which an individual belongs; rather, their final goal is
estimating the \emph{prevalence} (i.e., \emph{relative frequency}, or
\emph{prior probability}) of each class in the unlabelled data.

At a first glance, estimating these prevalence values via supervised
learning looks like a direct application of classification, since one
could simply (i) train a classifier on labelled data, (ii) use this
classifier to issue label predictions for each unlabelled datapoint
(i.e., individual) in the population of interest, (iii) count how many
datapoints have been attributed to each of the classes of interest,
and (iv) normalize the counts by the total number of labelled
datapoints, thus obtaining the estimated relative frequencies of the
classes. However, there is by now abundant evidence
\cite{Bunse:2022dz, Forman:2008kx, Gonzalez:2017it, Moreo:2022bf,
Schumacher:2021ty} that such an approach, known in the literature as
the ``Classify and Count'' (CC) method, yields poor class prevalence
estimates when the distribution of the unlabelled datapoints across
the classes differs substantially from the analogous distribution
observed during training. This latter condition is typically known as
\emph{prior probability
shift}~\cite{Moreno-Torres:2012ay,Storkey:2009lp}; in the
aforementioned disciplines this condition is ubiquitous since, quite
obviously, there is interest in inferring a distribution \emph{only}
when we assume this unknown distribution to be possibly different from
the known distribution that characterizes the training data. The main
reason why CC %doomed
tends to fail
% when facing changing conditions,
in the presence of prior probability shift is that, in this case, the
IID assumption
% \footnote{Most of the machine learning machinery builds on top of
% the assumption that the (unknown) random variables describing the
% training and the test data are Independent and Identically
% Distributed (IID).}
on which most classifiers based on supervised learning rest upon, does
not hold.
% rest upon holds no longer.

\emph{Quantification} (variously called \emph{learning to quantify},
\emph{supervised prevalence estimation}, or \emph{class prior
estimation}) is the research field concerned with obtaining accurate
estimators of class prevalence values via machine
learning~\cite{Gonzalez:2017it}.
% Given that quantification is inherently related to classification,
Given its obvious relationship with classification, quantification has
been extensively studied in the two main settings typical of
classification, i.e., the binary setting (\emph{binary quantification}
-- BQ), in which the \emph{codeframe} (i.e., the set of classes of
interest) contains only two classes~\cite{Card:2018pb, Forman:2008kx,
Bella:2010kx, Esuli:2015gh,
Hassan:2020kq}, %~\cite{Bella:2010kx, Card:2018pb, Esuli:2015gh, Esuli:2018rm, Forman:2008kx, Milli:2013fk, Saerens:2002uq}
and the single-label multiclass setting (\emph{single-label
quantification} -- \SLQ), which involves three or more mutually
exclusive classes~\cite{Bunse:2022qq, Firat:2016uq, Gao:2016uq,
Moreo:2022bf, Schumacher:2021ty}. Quantification has also been studied
in other (less popular) settings, such as the ordinal case
(\emph{ordinal quantification} -- \OQ), in which there is a total
ordering among the classes (see, e.g.,~\cite{DaSanMartino:2016jk,
Bunse:2022dz, Castano:2022nz}).
% , for which the prediction of 5-star ratings of Amazon reviews is an
% example.~\cite{Esuli:2010fk,Nakov:2016ty,DaSanMartino:2016jk,
% DaSanMartino:2016ty,SemEval:2016:task4:ISTI-CNR}.

One important setting which % is still
remains to a large extent unexplored in the quantification literature
is \emph{multi-label quantification} (\MLQ), the scenario in which
every datapoint may belong to zero, one, or several classes at the
same time. Multi-label data arise naturally in many applicative
contexts, including the medical
domain~\cite{Janjua:2022yi}, %(monitoring multiple symptoms at the same time),
the legal domain~\cite{Csanyi:2022my}, %fault detection in
industry~\cite{Taqvi:2022oh}, or
cybersecurity~\cite{Mukherjee:2022xw}, among many others, and has been
thoroughly studied under the lens of classification in past literature
\cite{Elisseeff:2001iz, Zhang:2007as, Montanes:2014fu}, especially in
the field of text classification~\cite{McCallum:1999zv, Gao:2004op,
Read:2011zc, Zhang:2021ma}; see~\cite{Tsoumakas:2007nl,
Herrera:2016xt} for an overview of this topic. Despite the ubiquity of
multi-label data,
we %are unaware of any attempt to devise \emph{multi-label quantifiers}.
are aware of only one previous attempt to cope with the \MLQ\ problem
\cite{Levin:2017dq}; in this paper we set out to analyze \MLQ\
systematically.
% This shortage of published studies is likely not due to a lack of
% interest in aggregate analysis for multi-label scenarios, but
%% rather due to the simple fact that the field of quantification is
%% still largely unknown in the machine learning community.
% may be simply due to the fact that quantification is still a
% relatively little-known task in the machine learning community.

We start by noting that, since quantification systems are expected to
be robust to prior probability shift, we need to test them against
datasets exhibiting substantial amounts of shift.
% This requirement is rarely met by any of the available
% classification datasets, since the split into training set and test
% set is usually consistent with the IID assumption. This is why
% experimental protocols %routinely adopted in the
% proposed for the evaluation of quantification systems consist of
% generating, out of an unlabelled test set, many test samples
% characterized by widely varying prevalence values. Despite the fact
% that there are by now well-established policies for generating
% samples at controlled prevalence values for the binary and
% single-label cases,
%% , and ordinal case [unfortunately this paper is not yet published],
% how to do so in the multi-label case is not trivial, for reasons
% that will be discussed in Section~\ref{sec:mlapp}.
%% the simple reason that not all legitimate distributions of classes
%% are always realisable via sampling.
Our first contribution is the first experimental protocol
specifically designed for multi-label quantification, a protocol that
guarantees that the data MLQ systems are tested against do comply with
the above desideratum.

We carry on by noting that a trivial solution for MLQ could simply
consist of training one independent binary quantifier for each of the
classes in the codeframe. However, such a solution is arguably a
``naïve'' one, as it assumes the classes to be independent of each
other, and thus does not attempt to leverage the \emph{class-class
correlations}, i.e., the stochastic dependencies that may exist among
different classes. We show empirical evidence that multi-label
quantifiers constructed according to this naïve intuition yield
suboptimal performance, and that this happens independently of the
method used for training the binary quantifiers.
% We will call this type of systems \bqbc.

% We then move on to studying different strategies for tackling MLQ,
% and subdivide these strategies in four groups, based on the phases
%% (classification and aggregation)
% in which the multi-label nature of the problem is (if at all)
% addressed.  These include the \emph{classification} phase, in which
% a classifier is asked to generate predictions for each individual
% datapoint, and the \emph{aggregation} phase, in which a quantifier
% uses the above predictions to generate class prevalence estimates.
% We note that the only work we are aware of that deals with
% \MLQ~\cite{Levin:2017dq} squarely falls within the most ``trivial''
% group, and we go on to propose the first ``genuine'' \MLQ\ systems,
% i.e., systems that take into account the stochastic dependencies
% between the classes in all stages of the quantification process. We
% devise different methods for each of the four groups, and we test
% them in our experiments.

We then move on to studying different possible strategies for tackling
MLQ, and subdivide these strategies in four groups, based on their way
of addressing (if at all)
% (classification and aggregation)
the multi-label nature of the problem. While the first two groups can
be instantiated by using already available techniques, the other two
cannot, since this would require ``aggregation'' techniques (see
Section~\ref{sec:quant}) that leverage the stochastic relations
between classes, and no such method has been proposed before. We
indeed propose two such methods, called RQ and LPQ. By means of
extensive experiments that we have carried out using 15 publicly
available datasets, we show that, when working in combination with a
classifier that itself leverages the above-mentioned stochastic
relations, LPQ and (especially) RQ outperform all other MLQ
techniques.
%
% \alexcomment{Alternatively, we could simply say: ``We then move on
% by studying different class of genuine multi-label quantification
% systems that take into account, one way or another, the stochastic
% relations between the classes.'' And remove the following three
% paragraphs dedicated to \bqmc, \mqbc, and \mqmc, that will be
% explained in Section~\ref{sec:quant:ml}. Also, remove the ``We will
% call this type of systems \bqbc.'' sentence before.} We then move on
% by studying a first class of truly multi-label quantification
% systems. In doing so, we will pay special attention to the class of
% \textit{aggregative} quantifiers (by far the most popular one in
% quantification literature), i.e., quantifiers that require a
% classifier to generate predictions for each unlabelled data
% item.\footnote{ The CC approach described above is a rudimentary
% example of aggregative quantification, and typically plays the role
% of a %lower bound
% weak baseline any genuine quantification system (aggregative or not)
% is expected to easily beat.} This class of systems include
% aggregative quantifiers equipped with any existing classifier
% designed to tackle the multi-label problem nativelly. This represent
% the most direct solution to the multi-label quantification problem,
% as it simply combines already existing technologies (off-the-shelf
% aggregative quantifiers and off-the-shelf multi-label
% classifiers). In such a setting, the classification stage is
% informed of the class-class correlations, but the quantifier in
% charge of producing the class prevalence estimates is unaware of any
% correlation. Since methods from this class will be constituted by
% combinations of binary quantifiers (BQ) and multi-label classifiers
% (MC), we will refer to this class as \bqmc.
%
% We then study a third class of multi-label quantification systems
% aiming at refining an estimate of class prevalence values by taking
% into account the correlations between classes. Methods like this
% constitute a non-trivial novel solution that has never been
% attempted, to the best of our knowledge, in the past. In order to
% clearly evaluate the relative merits of such a multi-label
% correction, for the choice of the underlying classifier we stick to
% binary classifiers only. For this reason, we will call this class
% \mqbc.
%
% The fourth and last class of methods we will consider amounts to
% combining any (already existing) multi-label classifier with any
% (newly proposed) multi-label quantifier, thus bringing to bear the
% class dependencies both at the classification level and at the
% quantification level, simultaneously. We call this class of methods
% \mqmc. \alexcomment{Cancel up to here?}
%
% generating data samples exhibiting different degrees of shift with
% respect to the training distribution in multi-label collections. We
% test all the \MLQ\ systems we consider in this paper using this
% protocol.
%
% The extensive experiments we have carried out use 15 publicly
% available datasets , and%for multi-label classification (\MLC)
% clearly show that the %systems of the type \bqbc\
% naïve solutions perform comparatively worse than %the rest.
% approaches that try to learn from the correlations between the
% classes.  The same experiments also demonstrate that the key for
% obtaining accurate class prevalence estimates in multi-label
% settings is tackling the multi-label nature of the problem
% \emph{both} at the classification level and at the aggregation
% level; we propose two new such methods that do this.  class-class
% correlations are exploited both at the classification level and at
% the quantification level. \alexcomment{Adapt, since I have moved the
% definitions outside.}

The rest of this article is structured as follows. After devoting
Section~\ref{sec:notation} to notation and preliminaries, in
Section~\ref{sec:relwork} we survey related work on quantification and
on coping with multi-label data. In Section~\ref{sec:mlapp} we move on
to propose an evaluation protocol specifically devised for \MLQ. In
Section~\ref{sec:quant} we characterize the four groups of MLQ systems
according to the stages in which the multi-label nature of the problem
is tackled, and propose the first methods (Section~\ref{sec:quant:ml})
that allow doing this also at the ``aggregation'' stage. In
Section~\ref{sec:experiments} we present the experiments we have
carried out and discuss the results, while
Section~\ref{sec:conclusions} wraps up. The code to reproduce all our
experiments is available at
\url{https://github.com/manuel-francisco/quapy-ml/} .

% \alexcomment{Here lacks a definition of multi-label }Multi-label
% classification (MLC) has been thoroughly studied in recent years,
% with many relevant applications in different fields such
% medicine~\cite{Janjua:2022yi}, law~\cite{Csanyi:2022my},
% industry~\cite{Taqvi:2022oh}, cybersecurity~\cite{Mukherjee:2022xw},
% and many others. It was originally intended to predict the topics of
% documents for natural language processing (NLP), in which each one
% of them may be related to a number of topics
% simultaneously~\cite{Tsoumakas:2007nl}\alexcomment{This reference is
% from 2007; is this really the first appearance of multi-label? In
% any case, that the first appearance was in the realm of text
% classification is by and large anecdotal, since multi-label is a
% problem setting, and has nothing to do, in principle, with text}.
% \alexcomment{This is not material for an introduction, but for a
% related work section:} Mainly, there are two approaches to solve
% related tasks.~\cite{Tsoumakas:2007nl} categorised them in problem
% transformation and algorithm adaptation methods. The former focuses
% in changing the problem domain to a single-label one, in order to
% apply single-label models; the latter propose augmentations on
% single-label methods to extend their capabilities to the multi-label
% domain.~\cite{Madjarov:2012yl} introduces a third dimension, that
% consist on ensembles of the other two. Arguably, the simple approach
% is to treat each label as an independent problem. Unfortunately,
% training separate models would lead to classifiers that are unaware
% of label dependencies and, hence, weak.

% Interés de la cuantificación On the other hand\alexcomment{there is
% no ``on the one hand'' (and some people is ridiculously strict with
% this)}, quantification tries to predict the frequencies of the
% classes (also known as class prevalences \alexcomment{"prevalences"
% does not exist... you should say ``prevalence values'' or
% ``prevalence estimates"} or prior probabilities) in a sample. In
% other words, each instance would be a sample (or dataset
% \alexcomment{mmm no, a dataset could also encopass a training and a
% test set}) and the target would be the prevalence of each
% class. While MLC models assume independent and identically
% distributed random samples (i.i.d principle
% \alexcomment{assumption}), quantification needs to deal with the
% bias of a sample \alexcomment{what do you mean by ``bias of a
% sample"? what could be biased is a predictor, not a sample} and
% apply the necessary corrections to yield unbiased prevalence
% estimations.

% Quantification has many applications in areas like social
% sciences~\cite{hopkins_method_{2}010},
% epidemiology~\cite{killworth_social_{1}998} and political
% science~\cite{ecker_estimating_{2}017}, along with many
% others. Quantifiers are usually classified \alexcomment{this is
% perfectly right, but one typically tries to avoid using words like
% ``classified'' in contexts in which it has a special role (like
% this)} as \textit{aggregative} and \textit{non-aggregative} CITA
% \alexcomment{actually there are also meta quantifiers}. Aggregative
% methods take advantage of an underlying trained machine learning
% model \alexcomment{classifier (a model is way too generic)},
% meanwhile \alexcomment{I am not sure this ``meanwhile'' is correct;
% while, whereas, could be better} non-aggregative ones use other
% techniques to estimate the prevalences \alexcomment{prevalence
% values}. The most straightforward quantification method would be
% \textit{Classify and Count (CC)}, that consists on \alexcomment{I
% think ``consists of'' is more formal} using a classifier to predict
% the classes of each instance \alexcomment{as you say it, it looks
% like the classifier is multi-label; ``a classifier to predict the
% class of each...'' would be better} in the sample in order to
% aggregate the results and estimate class frequencies from there
% \alexcomment{as you say it, this definition accommodates also other
% aggregative quantifiers (since you are not specifying that the
% ``aggregation'' amounts to simply counting in CC)}. However, this
% method is a naive approach and it is still constrained within the
% i.i.d. principle. \alexcomment{not clear what ``constrained within"
% means; maybe ``it still hinges upon the ... it still relies on the
% IID..'' something like that?} \manucomment{Check references}

% % Justificación del interés de esta investigación
% In the same way that single-label classification \alexcomment{not
% defined} was generalised to multi-label classification
% \alexcomment{how is not specified}, it is possible to define a \MLQ\
% (MLQ) task \alexcomment{the task is the problem, you probably mean
% ``method'' or ``approach"} in which the output would be the class
% prevalence for each label \alexcomment{this definition still holds
% for non-trivial solutions, if you read it with multi-label
% quantifiers on mind... there is nothing in this sentence clarifying
% that you mean a set of independent binary quantifiers}. MLQ may have
% many applications, such as estimating aspect-based sentiment
% evolution (e.g. evolution during a political debate).

% % Descripción de la hipótesis
% To the best of our knowledge, there are no previous work that
% addresses \alexcomment{"adress", I think, since ``previous work"
% behaves as a plural (despite not being ``works"), just like
% ``related work"} MLQ task. The most direct approach would be to
% solve each label independently \alexcomment{vague sentence; what
% does ``solving a label'' mean? (I understand, but the wording is not
% very accurate)}. However, analogously to the case of MLC, the
% quantifier would not be able to take advantage of class-class
% correlations leading to suboptimal predictions.\alexcomment{there is
% something missing here; why should a MLC be unable to exploit label
% correlations? you probably mean the naive MLC...}

% % Descripción del trabajo realizado
% In this work, we performed \alexcomment{you typically speak in
% present or future tense in the introduction, present in the
% experiments, and past in the conclusions (few people do actually
% adhere to this convention, but this is how you should do it); you
% could refer to the experiments in past tense only for supporting
% some conclusion (see my ``the extensive experiments we HAVE CARRIED
% OUT clearly show''...} an analysis of different techniques designed
% to tackle with \alexcomment{tackle with? deal with [sb] or tackle
% [sb]} MLQ problems. Our purpose is not only to explore \MLQ\ methods
% but also to establish worthly baselines and an evaluation
% methodology for MLQ tasks.\alexcomment{I wouldn't say this is our
% purpose, it is simply that we needed to establish them since there
% are no previously known such methods/protocols.}

% Literature points out that methods designed to deal with multi-label
% scenarios can be adapted both for classification and
% regression~\cite{Tsoumakas:2007nl, borchani_survey_{2}015}. It would
% thus make sense to explore, for aggregative quantifiers, the
% adequacy of (1) multi-label classifiers as predictors of labels or
% posterior probabilites \alexcomment{the distinction between
% ``predicting labels'' and ``predicting posterior probabilities'' is
% not obvious for people who is not into quantification} and (2)
% multi-label regressors to correct the estimates\alexcomment{ this is
% hard to follow for newcomers}. These are grounds to \alexcomment{?
% maybe ``this sets the basis for..."?} adopt them as a general
% framework and articulate the experimentation accordingly (i.e. as
% instantiations \alexcomment{instances (yep... weirdly enough,
% ``instantiation'' does not exist...)} of the above).

% Therefore, experiments were conducted \alexcomment{we have performed
% experiments... we run experiments (do never use the impersonal form
% for referring to YOUR experiments); in English, unlike in Spanish,
% repeating a word (like ``we") many times, is not considered a fault
% or a sign of poor style...} using 16 popular multi-label datasets
% \alexcomment{important: previously used in multi-label
% classification experiments} in which we tested the performance of
% different combinations of single and multi-label approaches
% \alexcomment{for a newcomer, the distinction between classification
% and quantification could not be clear; say ``multi-label quantifier"
% instead of ``multi-label method/approach'' when you mean ``a
% quantifier"}:
% \begin{itemize}
% \item Single-label Classifiers (SLC) paired with single-label
%   \alexcomment{Q}uantifiers (SLQ). In this approach, each labelled
%   \alexcomment{?} is treated as if they were different problems
%   \alexcomment{the grammar is not correct; each X (so IT) is treated
%   as if THEY...}. This combination would establish the baseline
%   performance. \alexcomment{no... actually this is a novel approach,
%   since nobody before has attempted the multi-label case; this is
%   something we call ``naive", for reasons discussed above, but is
%   not a real baseline (a baseline is something coming from prior
%   art)}
% \item Multi-label Classifiers (MLC) paired with single-label
%   quantifiers (SLQ). The classifier would exploit relations between
%   labels, however the quantifier that supersedes it will only
%   aggregate the outputs\alexcomment{any quantifier, even multi-label
%   aggregative quantifiers, will ``only aggregate'' the outputs;
%   again, in ``aggregate'' there is nothing explicitly implying
%   anything (nor good nor bad)}. This approach results from the
%   current techniques that we use for MLC but in the context of a
%   quantification task.
% \item SLC paired with \alexcomment{"paired with'' is not terribly
%   clear or precise} multi-label aware quantifiers (MLQ). In this
%   case, the quantifier would try to amend the estimations of the
%   classifiers with additional information that the classifiers were
%   unaware of (label dependencies).
% \item MLC paired with MLQ. Where both the classification models
%   \alexcomment{model; otherwise one could think that you have a
%   classifier for each label (which is exactly what we dont want to
%   do)} and the quantifiers \alexcomment{quantifier; otherwise one
%   could think that you have a quantifier for every label (which is
%   exactly what we dont want to do)} have information regarding label
%   correlations\alexcomment{more precise: have the opportunity to
%   model the stochastic... otherwise looks like you give, as an
%   additional input, some information to the model}.
% \end{itemize}

% \alexcomment{This is completely irrelevant at this point. At most,
% you say this in a subsection of the experimental section.} In order
% to conduct these experiments, we used several well-known python
% packages. \textit{scikit-learn}~\cite{scikit-learn} provides us with
% the implementation of single-label classifiers as some multi-label
% solutions, such as problem transformation utilities and ensemble
% methods that are capable of handling multi-label
% tasks. \textit{scikit-multilearn}~\cite{Szymanski:2017ru} was
% release in 2017 and it provides python implementations of
% multi-label tools, such as classifiers and transformation
% tools. \textit{QuaPy}\footnote{\url{https://github.com/HLT-ISTI/QuaPy}}~\cite{Moreo:2021bs}
% is a quantification framework that provides state-of-the-art
% solutions to the single-label quantification task.
% \alexcomment{Something that one can say here is ``the code for
% replicating all our experiments is made publicly available at
% URL''.}

% The experiments were conducted using 12 multi-label datasets
% \alexcomment{ok for the number (though I think its 15), but where
% they are made available is irrelevant (at most you could say ``12
% publicly available datasets"), and should be indicated in the
% experiment section only. Again, say ``the experiments WE have
% conducted'' or ``OUR experiments were conducted", etc.} that are
% available in
% \textit{scikit-multilearn}\footnote{\url{http://scikit.ml/datasets.html\#scikit-multilearn-repository}}
% plus 4 additional text classification datasets that have been
% traditionally used for multi-label classification tasks. Table~X
% describe the properties of each one of them.\alexcomment{not here}

% Outline The rest of this document \alexcomment{article} is organised
% as follows...

% ----------------------------------------------------------------------

\section{Notation and Definitions}
\label{sec:notation}

\noindent In this paper we use the following notation. By $\mathbf{x}$
we indicate a datapoint drawn from a domain $\mathcal{X}$ of
datapoints, while by $y$ we indicate a class drawn from a finite,
predefined set of classes (also known as a \emph{codeframe})
$\mathcal{Y}=\{y_{1}, ..., y_{n}\}$, with $n$ the number of classes of
interest. Symbol $\sigma$ denotes a \emph{sample}, i.e., a non-empty
set of (labelled or unlabelled) datapoints drawn from
$\mathcal{X}$. By $p_{\sigma}(y)$ we indicate the \emph{true}
prevalence of class $y$ in sample $\sigma$, by $\hat{p}_{\sigma}(y)$
we indicate an \emph{estimate} of this prevalence, and by
$\hat{p}_{\sigma}^{q}(y)$ we indicate the estimate of this prevalence
obtained by means of quantification method $q$. We will denote by
$\mathbf{p}=(p_{1}, \ldots, p_{n})$ a real-valued vector. When
$\mathbf{p}$ is a vector of class prevalence values, then $p_{i}$ is
short for $p_\sigma(y_{i})$.

We first formalize the \SLQ\ problem
(Section~\ref{sec:notation:singlelabel}) and then propose a definition
of the \MLQ\ problem (Section~\ref{sec:notation:multi-label}).

% ----------------------------------------------------------------------

\subsection{Single-Label Codeframes}
\label{sec:notation:singlelabel}

\noindent In single-label problems, each datapoint $\mathbf{x}$
belongs to one and only one class in $\mathcal{Y}$. We denote a
datapoint with its true class label as a pair $(\mathbf{x},y)$,
indicating that $y\in\mathcal{Y}$ is the true label of
$\mathbf{x}\in\mathcal{X}$. We represent a set of $k$ datapoints as
$\{(\mathbf{x}^{(i)},y^{(i)})_{i=1}^k: \mathbf{x}^{(i)}\in\mathcal{X},
y^{(i)}\in\mathcal{Y}\}$. By $L$ we denote a collection of
\underline{l}abelled datapoints, that we typically use as a training
set, while by $U$ we denote a collection of \underline{u}nlabelled
datapoints, that we typically use for testing purposes.

We define a \emph{single-label hard classifier} as a
function $$h:\mathcal{X}\rightarrow \mathcal{Y}$$
\noindent i.e., a predictor of the class attributed to a datapoint.
%
We will instead take a \emph{single-label soft classifier} to be a
function $$s:\mathcal{X}\rightarrow \Delta^{n-1}$$
\noindent with $\Delta^{n-1}$ the unit ($n$-1)-simplex %\footnote{ The
% \emph{probability simplex} $\Delta^n$ is equivalent to the unit
% ($n$-1)-simplex. }
(aka \emph{probability simplex} or \emph{standard simplex}) defined as
$$\Delta^{n-1}=\{(p_{1}, \ldots,p_{n}) \mid p_{i}\in[0,1], \sum_{i=1}^{n} p_{i}=1\}$$ 
\noindent i.e., as the domain of all vectors representing probability
distributions over $\mathcal{Y}$.
%
% , in which $v_{i}$ is the posterior probability, denoted
% $\Pr(y_{i} | \mathbf{x})$, that $\mathbf{x}$ belongs to the class
% $y_{i}$ as estimated by $s$.
%
We define a \emph{single-label quantifier} as a function
$$q : 2^\mathcal{X}\rightarrow \Delta^{n-1}$$ \noindent
i.e., a function mapping samples drawn from $\mathcal{X}$ into
probability distributions over $\mathcal{Y}$.

Note that, despite the fact that the codomains of soft classifiers and
quantifiers are the same, in the former case the $i$-th component of
$s(\mathbf{x})$ denotes the posterior probability
$\Pr(y_{i} | \mathbf{x})$, i.e., the probability that $\mathbf{x}$
belongs to class $y_{i}$ as estimated by $s$, while in the latter case
it denotes the class prevalence value $p_\sigma(y_{i})$ as estimated
by $q$.

By $d(\mathbf{p},\hat{\mathbf{p}})$ we denote an evaluation measure
for \SLQ; these measures are typically \emph{divergences}, i.e.,
functions that measure the amount of discrepancy between two
probability distributions. Everything we say for single-label problems
applies to the binary case as well, since the latter is the special
case of the former in which $n=2$, with one class typically acting as
the ``positive class'', and the other as the ``negative class''.

% ----------------------------------------------------------------------

\subsection{Multi-Label Codeframes}
\label{sec:notation:multi-label}

\noindent In multi-label problems each datapoint $\mathbf{x}$ can
belong to zero, one, or more than one class in $\mathcal{Y}$. We
denote a datapoint with its true labels as a pair $(\mathbf{x},Y)$, in
which $Y\subseteq\mathcal{Y}$ is the set of true labels assigned to
$\mathbf{x}\in\mathcal{X}$. A multi-label collection with $k$
datapoints is represented as
$\{(\mathbf{x}^{(i)},Y^{(i)})_{i=1}^k: \mathbf{x}^{(i)}\in\mathcal{X},
Y^{(i)}\subseteq\mathcal{Y}\}$.
% As for single-label problems, we use $L$ and $U$ to denote
% collections of labelled and unlabelled datapoints that we use for
% training and testing purposes, respectively. For the sake of
% simplicity, we override notation used for single-label
% problems. This causes no ambiguity since in this paper, unless
% otherwise stated explicitly, we will only deal with the multi-label
% setting.
We define a \emph{multi-label hard classifier} as a
function $$h:\mathcal{X}\rightarrow 2^\mathcal{Y}$$
\noindent while we define a \emph{multi-label soft classifier} as a
function
$$s:\mathcal{X}\rightarrow [0,1]^{n}$$ Note that, unlike
in the single-label case, the codomain of function $s$ is not a
probability simplex, but the set of all real-valued vectors
$(p_{1}, \ldots, p_{n})$ such that $p_{i}\in[0,1]$, since constraint
$\sum_{i=1}^{n} p_{i} = 1$ is not enforced.

We define a \emph{multi-label quantifier} as a function
$$q : 2^\mathcal{X}\rightarrow [0,1]^{n}$$
\noindent i.e., a function mapping samples from $\mathcal{X}$ into
vectors of $n$ class prevalence values, where the class prevalence
values in a vector do not need to sum up to 1.

% The multi-label quantification problem can equivalently be regarded
% as a set of $n$ binary quantification problems. For this reason, as
% an evaluation measure for \MLQ\
%% \footnote{The only evaluation measure proposed for \MLQ\ that we
%% are aware of is the so-called \emph{Concordance Ration} proposed by
%% ~\cite{Levin:2017dq}, and could anyway be reframed along the terms
%% we describe here (see Section~\ref{sec:exp:eval} for more
%% details).}
% we can take any divergence $d$ customarily used for the evaluation
% of binary quantifiers and compute the average across the $n$
% classes. That is, given such a divergence $d$, we can take
%%
% \begin{equation}
%  \label{eq:bin2ml}
%  D(\mathbf{p},\hat{\mathbf{p}}) = 
%  \frac{1}{n}\sum_{i=1}^{n} d \left((p_{i}, 1-p_{i}), 
%    (\hat{p}_{i}, 1-\hat{p}_{i})\right) 
%\end{equation}
%%
%\noindent as an evaluation measure for multi-label quantification
% problems.

% \manucomment{any particular reason to pass $(p_{i}, 1-p_{i})$ to $d$
% instead of just $p_{i}$? the other dimension is constrained
% anyways.}  \alexcomment{Yes, this is needed. What we are saying is
% that, for a MLQ measure, we take a SLQ measure a report the
% macro-average. This means that for every class you compute the SLQ
% measure, and thus you need a proper probability distribution (for
% the binary case, ok, but a probability distribution anyway), so you
% need to add the constrained part. So, is this not clear enough from
% the explanation?}

% ----------------------------------------------------------------------

\section{Related Work}
\label{sec:relwork}

% ----------------------------------------------------------------------

\subsection{Multi-Label Quantification}
\label{sec:multi-label}

\noindent The task of quantification was first proposed by Forman in
2005~\cite{Forman:2005fk}, and emerges from the observation that in
some applications of classification the real goal is the estimation of
class prevalence values, and the prediction of individual class labels
is nothing but an intermediate step to achieve it.
% This looked like a violation of the ``Vapnik principle'', according
% to which in order to solve a more specific problem (in this case,
% quantification) one should never resort to solving a more general
% one (in this case, classification) as an intermediate step.
Forman~\cite{Forman:2005fk} observed that the so-called ``classify and
count'' method (discussed in the introduction) tends to deliver biased
estimators of class prevalence when confronted with situations
characterized by prior probability shift. Since then, many
contributions to this field have been published, describing new
quantification methods (see~\cite{Gonzalez:2017it} for an overview),
measures for evaluating the accuracy of quantifiers
\cite{Sebastiani:2020qf, Sakai:2021lp}, and protocols for the
experimental evaluation of quantification systems~\cite{Esuli:2015gh,
Forman:2005fk, Esuli:2022hy}. However, most of this work has focused
on the binary~\cite{Esuli:2015gh, Esuli:2018rm, Forman:2005fk,
Forman:2008kx, Maletzke:2019qd}, single-label multiclass
\cite{Bunse:2022qq, Gao:2016uq, Firat:2016uq, Moreo:2022bf}, or
ordinal~\cite{Bunse:2022dz, DaSanMartino:2016jk, Sakai:2021lp,
Castano:2022nz} versions of the problem, with essentially no attention
devoted to the multi-label case.

% There is, to the best of our knowledge, no previous record of any
% quantification paper dealing with multi-label
% codeframes. \alexcomment{We will review some quantification
% techniques more in detail in Section~\ref{sec:quantification}.}

To the best of our knowledge, the only previously proposed method
dealing with multi-label (text) quantification is
\cite{Levin:2017dq}. The method, dubbed PCC-PAV, mainly consists of
performing a refined calibration of the posterior probabilities
returned by a set of binary classifiers, each trained to issue soft
predictions for a specific class in the codeframe, followed by the
application of the (binary version of the) ``probabilistic classify
and count'' (PCC) quantification method (explained in
Section~\ref{sec:quant:sl}). The refinement amounts to constraining
the calibration algorithm (\emph{Pair Adjacent Violators} --
PAV~\cite{Zadrozny:2002eu}) to generate posterior probabilities that
have an expected value equal to the class prevalence values observed
in the training set. This modification results in a complex quadratic
programming problem that the authors try to alleviate by imposing a
``document unification'' heuristics (thus giving rise to the variant
PCC-EPAV). However, aside from its substantial computational cost, the
method presents two important limitations. The first limitation is
that the calibration process encourages the quantifier to stick to the
class prevalence values encountered in the training set (hereafter:
the \emph{training prevalence}), and thus makes it inadequate to
tackle prior probability shift.  Indeed, in~\cite{Levin:2017dq} the
authors test this method by means of an experimental protocol that
offers no guarantee that the system is confronted with substantial
amounts of prior probability shift; this is witnessed by the fact that
the trivial baseline (one that simply returns the training prevalence
for every test sample) achieves reasonably high scores. A second
limitation is that the method uses \emph{independently trained} binary
classifiers; to put it another way, the method does not in any way
address the multi-label nature of the problem, and is billed
``multi-label'' only since it is tested on multi-label datasets. This
method thus squarely falls within the class of ``naïve methods'' that
we have discussed in the introduction, and that we will more formally
define as the simplest group of \MLQ\ methods in the scheme that we
propose in Section~\ref{sec:quant:ml}.

% ----------------------------------------------------------------------

\subsection{Multi-Label Classification}
\label{sec:multi}

\noindent \label{par:rw:mlclf}Apart from PCC-PAV and PCC-EPAV, no
other published method explicitly addresses \MLQ. However, the field
of quantification is closely related to the field of classification,
and many of the concepts and principles adopted in quantification have
been borrowed from the classification literature. We will thus devote
most of this section to review existing approaches for multi-label
\emph{classification}, since some among the methods we propose in
Section~\ref{sec:quant:ml} for \MLQ\ are inspired by them.

In their survey~\cite{Tsoumakas:2007nl}, Tsoumakas and Katakis group
the approaches to \MLC\ in two main families: ``problem
transformation'' approaches (Section~\ref{sec:relwork:probtrans}) and
``algorithm adaptation techniques''
(Section~\ref{sec:relwork:algadapt}). Later on, a third family of
\MLC\ approaches based on ``ensemble methods''
(Section~\ref{sec:relwork:ensembles}) was introduced by Madjarov et
al.~\cite{Madjarov:2012yl}.

% \alexcomment{References are quite old. We should at least cover some
% recent (2020 onwards) papers on multi-label.}

% \subsection{Multi-label Classification}
% Multi-label classification deals with the problem of matching
% instances with a set of labels. It is possible for any given
% instance to have one or more labels, or none at all. Labels may have
% dependencies between them therefore models should take these into
% account when making predictions.

% ~\cite{Tsoumakas:2007nl} distinguishes between (1) problem
% transformation approaches and (2) algorithm adaptation techniques in
% order to tackle with this problem.~\cite{Madjarov:2012yl} introduces
% a third category which is (3) ensemble of methods that may include
% the other two approaches.

% \alexcomment{Found in~\cite{Rastogi:2022ty} ``On the other hand,
% multi-label approaches based on their label correlation are divided
% into three categories, namely first order, second order, and
% higher-order methods. First order methods tackle the multi-label
% classification problem without using the correlation between class
% labels such as multi-label learning with label specific features
% (LIFT) [41], Binary Relevance (BR) [2]; second-order methods exploit
% the pairwise relationship between label-pairs such as JFSC [14],
% LLSF [13]; and higher-order approaches exploit the relationship
% among all the class labels or subset of class labels, such as
% classifier chains (CCs) [27,33] and CCPU [29].''}

% ----------------------------------------------------------------------

\subsubsection{Problem Transformation Approaches}
\label{sec:relwork:probtrans}
% \manucomment{It feels kind of weird that first subsection is called
% Problem Transformation without any further reference to multi-label
% classification. Although paragraph~\ref{par:rw:mlclf} explains it,
% someone that is just glancing over the manuscript may think that
% this section is related to multi-label quantification. maybe add
% some reference to classification in subsection's title? maybe add
% another title before the aforementioned paragraph?}

\noindent The ``problem transformation'' approach consists of
recasting the original multi-label classification problem as a
single-label one, so that existing techniques for the single-label
case can be applied directly.

The simplest approach relying on this principle is the so-called
``binary relevance'' (BR) approach~\cite{Luaces:2012qi,
Montanes:2014fu}. BR consists of treating each label independently,
thus tackling the multi-label problem as a set of $n$ binary
classification problems. BR is a simplistic approach, since the
stochastic dependencies among the classes are not taken into
account. Despite its simplicity, BR has proven to work well in
previous studies~\cite{Madjarov:2012yl}, and has always been, by far,
the most frequently adopted approach for tackling multi-label
classification problems.

The ``label powerset'' (LP) approach consists instead of transforming
each unique assignment of labels, as found in the training datapoints,
in a new label. For example, if a training datapoint $\mathbf{x}$ has
labels $Y=\{y_{1},y_{5},y_{6}\}$, with
$y_{1}, y_{5}, y_{6} \in \mathcal{Y}$, then the datapoint is
relabelled as $Y'=y_{1:5:6}$, with $y_{1:5:6}$ a new ``synthetic''
class belonging to a single-label codeframe
$\mathcal{Y}'\supseteq \mathcal{Y}$. Once this relabelling has been
performed for all unique label assignments, the problem is treated as
a single-label problem using $\mathcal{Y}'$ as the codeframe. Although
this approach models label dependencies~\cite{Spolaor:2013ir}, the
number of possible classes in the new codeframe $\mathcal{Y}'$ is
exponential in the number of classes in the original codeframe, since
there are actually $2^{n}$ possible assignments of a datapoint to
classes in $\mathcal{Y}$ (hence the name of the approach). Even if not
all label combinations occur in practice in a single dataset, the
total number of different assignments that could be found when large
multi-label codeframes are used could easily make the problem
intractable. Some heuristics based on ensembles (discussed in
Section~\ref{sec:relwork:ensembles}) have been proposed to make the
problem tractable.  A further limitation of this approach is its low
statistical robustness, since, once a training datapoint $\mathbf{x}$
with labels $Y=\{y_{1},y_{5},y_{6}\}$ is given the synthetic label
$y_{1:5:6} \in \mathcal{Y}'$, it ``loses'' the individual labels
$y_{1}$, $y_{5}$, $y_{6}$, which means that these latter classes end
up having fewer training examples than in the standard BR approach. In
other words, having more classes means having, on average, fewer
training examples per class, which may bring about lower accuracy for
the individual (non-synthetic) classes.
% clustering the labels either randomly (RAkEL)
% ~\cite{Tsoumakas:2011vp} or using k-means (HOMER)
% ~\cite{Tsoumakas:2008ek} have been proposed to render the problem
% tractable. \alexcomment{check consistency (RakEL and HOMER -- though
% I am not sure that our random clustering is equivalent to HOMER)
% with our names in tables}
Yet another problem of the LP approach is the fact that combinations
of labels never found in the training set cannot be predicted at all.

The ``classifier chains'' (\textsc{CChain}) approach
\cite{Read:2011zc, Dembczynski:2010ei} consists instead of training a
\emph{sequence} of $n$ binary classifiers, one for each class in $n$,
chained so that each classifier receives, as additional inputs, the
predictions made by the previous classifiers in the chain. That is,
the first classifier $h_{1}$ in the chain is trained to predict label
$y_{1}$ using the original vector $\mathbf{x}$ as input, while the
$i$-th classifier in the chain is trained to predict label $y_{i}$
using as inputs the original vector $\mathbf{x}$ concatenated with a
vector of predictions
$(h_{1}(\mathbf{x}), \ldots, h_{i-1}(\mathbf{x}))$ for labels
$y_{1}, \ldots,y_{i-1}$, respectively. While this has turned out to be
one of the best-performing MLC methods~\cite{Madjarov:2012yl},
\textsc{CChain} presents a number of limitations. The first has to do
with the fact that \textsc{CChain} is sensitive to the order of the
classes; in other words, $\mathcal{Y}$ is treated as an \emph{ordered
sequence} (rather than a set) of classes, and reshuffling the sequence
would bring about different results, which is undesirable. Some
approaches to counter this limitation consist of training an ensemble
of
\textsc{CChain}s %\alexcomment{maybe better in the Ensembles section?}
using different label orderings in each of them, and then implementing
some aggregation policy such as majority
voting~\cite{Read:2011zc}. Yet another limitation of \textsc{CChain}
is that the classification phase is (unlike for the simpler BR
strategy) not amenable to parallelization, since the application of
classifier $h_{i}$ to unlabelled data must occur strictly after the
application of classifiers $h_{1}$, ..., $h_{i-1}$.
% both training time and inference time grow linearly with the number
% of labels,


% \paragraph{Binary relevance} Each label can be treated as a separate
% problem in which the target is only one of the labels. This is
% arguably the most simple approach towards multi-labeled tasks, and
% it does not take into consideration label relations, therefore it
% usually leads to weak models.

% \paragraph{Label Powerset} Transform each unique subset of labels to
% a class in a single-label problem. The benefit of this method is
% that it is capable of dealing with label
% dependencies~\cite{Spolaor:2013ir}. On the other hand, when dealing
% with a large number of labels, the n umber of potential combinations
% grows exponentially. Therefore, it may lead to a huge number of
% classes with only a few examples.

% \paragraph{Classifier chains}~\cite{Read:2011zc} proposes to deal
% with a $L$-labelled dataset training $L$ chained classifiers in
% which each classifier receives the inputs as well as the outputs of
% all the previous models in the chain. This method is one of the top
% performing ones, however it is sensible to the order in which the
% labels are chosen.

% ----------------------------------------------------------------------

\subsubsection{Algorithm Adaptation Approaches}
\label{sec:relwork:algadapt}

\noindent ``Algorithm adaptation'' approaches consist of adapting
single-label classifiers to return multi-label predictions.
%
% This approach consists on extending well-known single-label
% algorithms to the multi-label domain.
%
% Well-known traditional algorithms like \textsc{AdaBoost}, KNN, or
% SVM have been adapted to work on multi-label problems.
Schapire and Singer proposed a multi-label adaptation of
\textsc{AdaBoost}, called \textsc{AdaBoost.MH}~\cite{Schapire:2000nl},
which is based on choosing, for a given iteration of the boosting
process, a unique ``pivot term'' around which all the binary
classifiers for the individual classes
hinge. \textsc{ML-knn}~\cite{Zhang:2007as} is an adaptation of the
well-known (lazy) KNN algorithm, which treats each class
independently, and relies on the maximum \emph{a posteriori} (MAP)
principle to return multi-label predictions, where the prior and
posterior probabilities needed to compute the MAP rule are estimated
on the training set.
% A different branch of methods concentrate on adapting SVMs (an
% originally binary classification algorithm) to work on multi-label
% problems.
Some attempts to adapt SVMs to the multi-label problem include
\textsc{RankSVM}~\cite{Elisseeff:2001iz, Xu:2013gy}, which solves an
empirical risk minimization problem framed as a task of ranking
involving $n$ hyperplanes, and \textsc{ML-TSVM}~\cite{Chen:2016bs,
Ai:2021yp}, based on Twin SVMs (TSVMs)~\cite{Kumar:2009tt}, i.e., SVMs
that, instead of looking for one separation hyperplane, look for a
pair %(hence the name)
of non-parallel separating hyperplanes.
% \textsc{ML-TSVM} has been criticized in
Rastogi et al.~\cite{Rastogi:2022ty} noted that \textsc{ML-TSVM} does
not actually take into account the class-class correlations, and
propose a method called \emph{Multi-Label Minimax Probability Machine}
(\textsc{ML-MPM}), inspired by the ``kernel trick'' used in
SVMs. \textsc{ML-MPM} deals with class-class correlations by imposing
a regularization term on the predicted sets of classes
(``labelsets''), where this term takes into account the label
co-occurrence matrix as found in the training set. Other classical
methods that have been used within algorithm adaptation approaches
include decision trees (DT -- see, e.g.,~\cite{Vens:2008yr}) and
random forests (RF -- see, e.g.,~\cite{Madjarov:2012yl}).

Benites et al.~\cite{Benites:2010ix} proposed ML-ARAM and ML-FAM, two
multi-label extensions of neural networks based on \emph{Adaptive
Resonance Theory} (ART). The methods work by inferring hierarchical
relationships between classes in the codeframe. Although these systems
outperformed \textsc{ML-knn} in the experimental evaluation, it was
later noted that they suffer when facing datasets characterized by
large codeframes and high-dimensional feature
spaces~\cite{Benites:2015nq}, a common setting in text classification
endeavours. A variant of ML-ARAM, called \emph{Hierarchical
ARAM}~\cite{Benites:2015nq} was then proposed to mitigate this
problem; hierarchical ARAM works by clustering the prototypes that
ML-ARAM learns for the input datapoints, generating larger clusters
that can be more efficiently accessed at inference time.

% \paragraph{ML-knn}~\cite{Zhang:2007as} proposed a multi-label
% extension of the popular $k$-nearest neighbours method. It selects
% the $k$ closets neighbours and then outputs those labels using the
% \textit{maximum a-posteriori} rule. This is a lazy approach that
% treats each label independently. However, it is capable of
% maintaining the correlation between labels up to a certain point
% since the outputs are based on actual examples.
%
% \paragraph{MLARAM}~\cite{Benites:2010ix} suggest that it is possible
% to extract the hierarchy between labels automatically from label
% co-occurrences. Although they showed that the method was superior in
% terms of performance, classification speed suffers for large dataset
% and high multi-label dimensionality~\cite{Benites:2015nq}. This
% happens frequently with text classification datasets where the
% features are \textit{bag-of-words} or \textit{TF-IDF}, since
% vocabularies tend to be large.
%
% \paragraph{MLTSVM}~\cite{Chen:2016bs} use the idea behind Twin
% Support Vector Machine to build a method that determine several
% hyperplanes which can deal with the multi-label classification
% task. However, it does not handle label
% dependencies~\cite{Rastogi:2022ty}.
%
% \paragraph{ADABOOST.MH}~\cite{Schapire:2000nl} present an extension
% of \textit{AdaBoost} for a multi-label domain. They train a weak
% classifier per label that is later used to predict if a new example
% may be tagged for that label. Although it is supposed to be an
% adapted algorithm, it transforms the problem into single-label
% ones~\cite{Tsoumakas:2007nl}.

% ----------------------------------------------------------------------

\subsubsection{Ensemble-Based Approaches}
\label{sec:relwork:ensembles}

\noindent Ensemble-based approaches to MLC aim at improving model
performance by combining different base classifiers.
%
Some ensembles have been proposed as a response to specific problems
encountered in other \MLC\ systems.

A first class of such ensembles are based on a
\emph{divide-and-conquer} approach, according to which the set of
classes is first partitioned (using any clustering method), and the
smaller, cluster-specific multi-label problems are then solved
independently of each other. Different instances implementing this
principle exist in the literature. For example, the authors
of~\cite{Tsoumakas:2008ek} create a tree in which the internal nodes
are associated with sets of classes (called \emph{meta-classes}) and
their children are associated with subsets of the classes of the
parent node. The root represents the set of all classes, while the
leaves represent single classes. For each node, a multi-label
classifier is trained to predict (zero, one, or more) meta-classes,
each associated with one of the children nodes. The final set of
labels returned is the union of all labels in the leaf nodes
reached. \textsc{HOMER} implements the partitioning as balanced
clustering, while \textsc{HOMER-R} relies instead on $k$-means; in
both cases the smaller multi-label problems are tackled via the binary
relevance approach discussed in Section~\ref{sec:relwork:probtrans}.
\textsc{RakEL}~\cite{Tsoumakas:2011vp} instead relies on random
clustering (with the number of clusters a hyperparameter of the model)
for partitioning the classes, and then runs an instance of the label
powerset technique (LP -- discussed in
Section~\ref{sec:relwork:probtrans}) for each cluster. Since the
number of classes in each cluster is smaller than the total number of
classes, the combinatorial problem affecting the LP approach is
mitigated.
% For example, \textsc{RakEL}~\cite{Tsoumakas:2011vp} was proposed as
% a solution to the combinatorial problem affecting the label powerset
% technique (LP -- discussed in
% Section~\ref{sec:relwork:probtrans}). \textsc{RakEL} works by
% generating $k$ random clusters of labels (with $k$ an hyperparameter
% of the model), and then running an instance of LP in each
% cluster. Other methods have followed this intuition, by also
% proposing to generate clusters of labels that are not random. For
% example, \textsc{HOMER}~\cite{Tsoumakas:2008ek} uses k-means in
% order to generate the clusters.
In a similar vein, \emph{Label Space Clustering} (LSC)
\cite{Szymanski:2016qj} uses $k$-means for clustering, followed by an
instance of \textsc{ML-knn} local to each cluster.

% HOMER -> cluster (bkmeans) + BR Tsoumakas:2008ek HOMER-R -> random
% clusters + BR Tsoumakas:2008ek LCluster -> cluster (kmeans) + MLC
% (mlknn) Szymanski:2016qj Rakel - > random cluster + Lpowerset
% Tsoumakas:2011vp kClust -> cluster (kmeans) + Lpowerset [ours]

Other methods rely instead on \emph{label embeddings}, i.e., on
representing each class by means of a low-dimensional dense vector in
a continuous space, so that similar classes (i.e., classes that tend
to co-occur with each other) tend to be close to each other in the
embedding space. The \emph{Cost-Sensitive Label Embedding with
Multidimensional Scaling} (\textsc{CLEMS}) method~\cite{Huang:2017hw}
is one such example, and one that has proven to be among the best
performers in the label embedding arena (see
e.g.,~\cite{Szymanski:2017ru}).

Stacked Generalization (SG)~\cite{Wolpert:1992rq} has often been
employed to carry out multi-label classification. The idea is to train
an ensemble of binary classifiers, each for a different class (somehow
similarly to the BR approach) and use the classification predictions
as additional features to train a \emph{meta}-classifier. Some
variants following this intuition include the \textsc{Fun-TAT} and
\textsc{Fun-KFCV}~\cite{Esuli:2019dp} approaches for cross-lingual
\MLC, in which a language-agnostic meta-classifier receives as input
the predictions returned by language-specific multi-label
classifiers. An advantage of SG with respect to \textsc{CChain} is
that the former can be easily parallelized, since it is not dependent
on the order of presentation of the classes.
% \paragraph{Stacked classifiers} They are based on single-label
% classifiers whose outputs are stacked and used as inputs for a final
% estimator~\cite{Wolpert:1992rq}. Although it is considered an
% ensemble, it also relies upon a domain transformation. The main
% strength is that the uppermost estimator is able to learn the bias
% of the weak classifiers and tailor the output to deal with label
% dependencies.

% These methods try to obtain better model performance by using
% combinations of several algorithms. The combination of models is
% expected to work better than any of them separately.

% \paragraph{RAkEL}~\cite{Tsoumakas:2011vp} tries to solve the
% problems of \textit{Label Powerset}, in which the number of classes
% grows exponentially, by generating $k$ random clusters of labels and
% then applying label powerset to solve each set. The algorithm has
% two variants, depending on the allowance of overlap between label
% clusters.

% \paragraph{Label Space Clustering} Applies a clustering algorithm to
% reduce the complexity of the multi-label problem and then applies a
% \MLC\ algorithm. It works under the premise that multi-label
% classifiers work better when applied to a set of labels that have
% dependencies between them, and therefore they should improve their
% performance when trained over computed clusters.

% \paragraph{Embedding-based classifiers} They work by computing
% \textit{embeddings} of the labels that inherently encode label
% structure. Their development was a result of the need to handle a
% large number of labels.~\cite{Huang:2017hw} proposed CLEMS, which is
% arguably one of the top performing
% \textit{embedders}~\cite{Szymanski:2017ru}.

% \paragraph{Stacked classifiers} They are based on single-label
% classifiers whose outputs are stacked and used as inputs for a final
% estimator~\cite{Wolpert:1992rq}. Although it is considered an
% ensemble, it also relies upon a domain transformation. The main
% strength is that the uppermost estimator is able to learn the bias
% of the weak classifiers and tailor the output to deal with label
% dependencies.

% alexcomment{check HOMER~\cite{Tsoumakas:2008ek}}

% ----------------------------------------------------------------------

\section{An Evaluation Protocol for Testing Multi-Label Quantifiers}
\label{sec:mlapp}

\noindent For the evaluation of quantifiers, researchers often use the
same datasets that are elsewhere used for testing classifiers. On one
hand this looks natural, because both classification and
quantification deal with datapoints that belong to classes in a given
codeframe. On the other hand this looks problematic, since
classification deals with estimating class labels for individual
datapoints while quantification deals with estimating class prevalence
values for \emph{samples} (sets) of such datapoints. Simply estimating
the accuracy of a quantifier on the entire test set of a dataset used
for classification purposes (hereafter: a ``classification dataset'')
would not be enough, since this would be a single prediction only,
which would be akin to testing a classifier on a single datapoint
only. As a result, it is customary to generate a dataset to be used
for quantification purposes (a ``quantification dataset'') from a
classification dataset by extracting from the test set of the latter a
number of samples than will form the test set of the quantification
dataset. Exactly how these samples are extracted is specified by an
\emph{evaluation protocol}. Different evaluation protocols for the
binary case~\cite{Esuli:2015gh, Forman:2005fk}, for the single-label
multiclass case~\cite{Esuli:2022hy}, and for the ordinal
case~\cite{Bunse:2022dz}, have been proposed in the quantification
literature.

% The need for suitable protocols for generating test samples emerges
% from the fact that, in quantification, a sample of datapoints counts
% actually as one single instance. This happens because quantification
% targets samples, %just like
% in the same way classification targets individual datapoints. Put it
% other way, relying on a single test collection for assessing the
% performance of a quantifier would be equivalent to relying on a
% single instance for testing a classifier.
%
% For this reason, different protocols for the evaluation of
% quantification systems have been proposed for the binary and
% single-label cases, among which, the so-called \textit{Natural
% Prevalence Protocol} (NPP) and the \textit{Artificial Prevalence
% Protocol} (APP) have become the two most popular ones.

% NPP consists of collecting many samples over time as they naturally
% occur in real cases. Although this protocol allows confronting the
% quantifier with real cases, it suffers from the fact that the number
% of test samples thus acquired is often small (for the simple fact
% that the process of data collection is costly) and from the fact
% that most of the samples exhibit low shift with respect to the
% training data. NPP has indeed been adopted in a handful of previous
% research only~\cite{Esuli:2015gh, Gao:2016uq, Nakov:2016ty,
% Gonzalez:2019bq}. %For example, one could consider
% Alternatively, NPP is sometimes defined as the process of generating
% samples via random uniform sampling (i.e., disregarding the
% labelling information). However, this protocol is, by and large,
% uninteresting for quantification purposes, since the samples
% generated are expected to preserve the original prevalence of the
% test set, that is likely to coincide with the prevalence of the
% training set.

For the binary case,
% and single-label multiclass cases (which are the closest to our
% concerns),
the most widely adopted protocol is the so-called \emph{artificial
prevalence protocol} (APP)~\cite{Forman:2005fk}.  The APP consists of
extracting many samples from a set of test datapoints at controlled
prevalence values. The APP takes four parameters as input: the
unlabelled collection $U$, the sample size $k$, the number of samples
$m$ to draw for each predefined vector of prevalence values, and a
grid of prevalence values $\mathbf{g}$ (e.g.,
$\mathbf{g}=(0.0, 0.1, \ldots, 0.9, 1.0)$). We then generate all the
vectors $\mathbf{p}=(p(\oplus),p(\ominus))$ of $n=2$ prevalence values
consisting of combinations of values from the grid $\mathbf{g}$ that
represent valid distributions (i.e., such that the elements in
$\mathbf{p}$ sum up to 1). For each such prevalence vector, we then
draw $m$ different samples of $k$ elements each. The APP thus
confronts the quantifier with scenarios characterized by class
prevalence values very different from the ones seen during training.
This protocol is, by far, the most popular one in the quantification
literature (see, e.g.,~\cite{Forman:2005fk, Esuli:2018rm,
Maletzke:2019qd, Perez-Gallego:2017wt, Card:2018pb, Reis:2018fk,
Perez-Gallego:2019vl, Moreo:2022bf, Schumacher:2021ty, Vaz:2019eu}).

For the single-label multiclass case (which is the closest to our
concerns) the APP needs to take a slightly different form, since the
number of vectors $\mathbf{p}=(p(y_{1}), ..., p(y_{n}))$ representing
valid distributions for arbitrary $n$ is combinatorially high, for any
reasonable grid of class prevalence values. As a solution, one can
generate a number of random points on the probability simplex, with
the individual class prevalence values not even being constrained to
lie on a predetermined grid; when this number is high enough, it
probabilistically covers the entire spectrum of valid combinations.

However, even this form of the APP is not directly applicable to the
multi-label scenario, because in this latter the class prevalence
values in a valid vector do not necessarily sum up to 1. One could
attempt to simply treat the multi-label problem as a set of
independent binary problems, and then apply the APP independently to
each of the classes. Unfortunately, such a solution is impractical,
for at least three reasons.
%
\begin{itemize}

\item The first reason is that the number of samples thus generated is
  exponential in $n$, since there are
  $m|\mathbf{g}|^n$ %\manucomment{of?} \alexcomment{I think it's ok without the ``of"}
  such combinations. Note that $n$ (the number of classes in the
  codeframe) cannot be set at will, and thus, in order to keep the
  number of combinations tractable in cases in which $n$ is large (in
  our experiments we use datasets with up to $n=983$ classes),
  % below reasonable bounds,
  one would be compelled to set $m=1$ and choose a very coarse grid
  $\mathbf{g}$ of values (this would anyway prove insufficient when
  dealing with large codeframes).

\item The second and perhaps most problematic reason is that, in any
  case, many of the combinations are not even realisable.
  % \footnote{Concretely, if we arrange a matrix $R$ with a number of
  % rows equal to the number of instances, and the number of columns
  % equal to the number of classes $n$, and we set $r_{ij}=1$ if the
  % $i$-th instance has label $y_{j}$ or 0 otherwise, then there are
  % combinations that are unrealisable whenever the rank of
  % $R<n$. \alexcomment{no...this is not correct...}}
  That is, there may be prevalence vectors for which no sample could
  be drawn at all. To see why, assume that, among others, we have
  classes $y_{1}$, $y_{2}$, $y_{3}$ in our codeframe, and assume that
  in our test set $U$, every time a datapoint is labelled with $y_{1}$
  it is also labelled with either $y_{2}$ or $y_{3}$ but not
  both. This means that all samples $\sigma$ for which prevalence
  values $p_\sigma(y_{1})\neq (p_\sigma(y_{2}) + p_\sigma(y_{3}))$ are
  requested, cannot be
  generated. %There is an obvious correlation between the two, with label \textsc{Tennis} implying the presence of \textsc{Sports}, but not viceversa.\footnote{This is indeed a frequent scenario, that will arise in any multi-label setting derived from a hierarchical codeframe. However, this problematic is not specific to hierarchical codeframes (in which there are clear label implications), but can indeed arise in any multi-label dataset.} It would thus be impossible to generate a sample with, for example, 40\% prevalence of \textsc{Tennis} \manucomment{US: soccer; UK: football. I really don't mind if we use US/UK English as long as we stick to one} \alexcomment{we could say Tennis, and solve the problem}
  % and 10\% prevalence of \textsc{Sports}, since the prevalence of
  % the class \textsc{Tennis} cannot be greater %(e.g., 40\%)
  % than the prevalence of \textsc{Sports}. \manucomment{this example
  % is very clarifying but it is also problematic. Wouldn't it make
  % sense to explore only those labels that are leaves in the
  % hierarchy and let the upper categories be as they may? Does it
  % make sense to draw samples with different prevalence values for a
  % label that \textit{depends} on (and it's 100\% correlated with)
  % others? In the case of \textit{sports}, it would make sense to me
  % to explore different prevalence values for \textit{football},
  % \textit{basketball}, \textit{curling} but not for \textit{sports}
  % itself}. \alexcomment{Your intuition is perfectly right, but I
  % think the idea behind a multi-label system is not that it should
  % realize that, any time a document is about basketball, then it is
  % \textit{also} about sports, but rather the other way around; i.e.,
  % that if the classifier (or quantifier) believes the document (or
  % the prevalence distribution) is about sports, then classes
  % football, basketball, etc., should become more likely than the
  % leaf-categories from, say, class Economics. Let's see what
  % Fabrizio thinks about this (I recall he exposed similar
  % perplexities once).} \alexcomment{Maybe it would be less
  % problematic to replace this example with the following: ``Imagine
  % we have three categories A, B, and C in our test set $U$. Each
  % time a document has label A, it is also labeled as belonging to B
  % or to C. This means all samples $\sigma$ for which a prevalence
  % $p_\sigma(A)\neq p_\sigma(B) + p_\sigma(C)$ is requested, cannot
  % be generated.''} (e.g, 10\%).

\item Yet another reason why applying the APP would be, in any case,
  undesirable, is that the classes in most multi-label datasets
  typically follow a power-law distribution, i.e., there are few very
  popular classes and a long tail of many rare, or extremely rare,
  classes. The APP will sometimes impose high prevalence values for
  what in reality are very rare labels, which means that the sampling
  must be carried out \emph{with replacement}, which generates samples
  consisting of many replicas of the same few datapoints, which is
  clearly
  undesirable. %\manucomment{I'd also say that this kind of sample would be too much unrealistic, which is also the main drawback of the APP} \alexcomment{That this is undesirable is already implied by the ``consisting of many replicas of few datapoints'' (but I have now stated it clearlier); saying this is ``unrealistic'' could be counterproductive, since generating high shifts (as we do) could also be branded as unrealistic.}
\end{itemize}
%
\noindent For all these reasons we have designed a brand new
protocol %\manucomment{\textit{design a new protocol} seems to me a little categorical because, in essence, it follows the same scheme than classic APP. Maybe \textit{redesign} or \textit{adapted}? I think this would also attract more critics from reviewers since they may say that (1) the protocol has not been validated before (which make sense since this is the first attempt at MLQ) and that (2) it is based in APP therefore not novel. However this is just my opinion I really don't have a clue} \alexcomment{I think ``designed a new protocol'' is ok, since a protocol for ML has to be new. That the protocol es based on an adaptation of the APP is explicitly stated in what follows.}
for \MLQ, that we call ML-APP, since it is an adaptation of the APP to
multi-label datasets. The protocol amounts to performing rounds of the
APP, each targeting a specific class, but with the range of prevalence
values explored for each class being limited by the amount of
available positive examples. This allows all samples to be drawn
\emph{without} replacement. In each round, a class $y_{i}$ is actively
sampled at controlled prevalence values while the prevalence values
for the remaining classes are not predetermined. Pseudocode describing
the ML-APP protocol is shown as Algorithm~\ref{alg:mlapp}.

\begin{algorithm}[ht]
  \caption{\label{alg:mlapp}ML-APP protocol for multi-label data.}
  \begin{algorithmic}
    \State \textbf{Input:} $U$, a test collection \State
    \textbf{Input:} $k$, the sample size \State \textbf{Input:} $m$,
    the number of samples to draw for each prevalence \State
    \textbf{Input:} $\mathbf{g}$, the grid of prevalence values \State
    $S = \{\}$ \For{$y_{i}\in\mathcal{Y}$} \codecomment{Split $U$ in
    two sets, with $U_{y_{i}}$ containing all datapoints with label
    $y_{i}$ and $U_{\overline{y}_{i}}$ \newline \mbox{} \hspace{1.0em}
    // containing the others} \State
    {$U_{y_{i}}\leftarrow\{(\mathbf{x},Y)\in U : y_{i}\in Y\}$} \State
    {$U_{\overline{y}_{i}}\leftarrow\{(\mathbf{x},Y)\in U :
    y_{i}\notin Y\}$} \For{$g_{j} \in \mathbf{g}$}
    \codecomment{Compute the number of positives and negatives to
    extract} \State \textsc{Pos}
    $\leftarrow \lceil k \cdot g_{j} \rceil$ \State \textsc{Neg}
    $\leftarrow k - $\textsc{Pos} \codecomment{Generate samples only
    if the number of datapoints in $U_{y_{i}}$ allows}
    \codecomment{the sampling to be performed without replacement}
    \If{ $|U_{y_{i}}| \geq $ \textsc{Pos} } \For{$m$ repetitions}
    \State draw $\sigma_{y_{i}}$ from $U_{y_{i}}$, with
    $|\sigma_{y_{i}}|=$\textsc{Pos}, uniformly at random w/o
    replacement \State draw $\sigma_{\overline{y}_{i}}$ from
    $U_{\overline{y}_{i}}$, with
    $|\sigma_{\overline{y}_{i}}|=$\textsc{Neg}, uniformly at random
    w/o replacement \codecomment{Members of $\sigma_{y_{i}}$ and
    $\sigma_{\overline{y}_{i}}$ are not removed from $U_{y_{i}}$ or
    $U_{\overline{y}_{i}}$} \State
    $\sigma \leftarrow \sigma_{y_{i}} \cup \sigma_{\overline{y}_{i}}$
    \aftercodecomment{Note that $p_{\sigma}(y_{i})=g_{j}$; the
    prevalence for the other \newline \mbox{} \hspace{12.2em} //
    classes is not predetermined} \State
    $S\leftarrow S \cup \{\sigma\}$ \EndFor \EndIf \EndFor \EndFor
    \State \textbf{Return:} $S$
  \end{algorithmic}
\end{algorithm}

% sigmas = {} for each class $y_{i}$ in \mathcal{Y} split U in
% U_{y_{i}}, U_{\overline{y_{i}}} for each prevalence value $g_{j}$ in
% $g$ if q*g_{j} <= |U_{y_{i}}| : for k in {1,...,m}: draw
% \sigma_{y_{i}} from U_{y_{i}} uniformly at random without
% replacement with |\sigma_{y_{i}}|=q*g_{j} draw
% \sigma_{\overline{y_{i}}} from U_{\overline{y_{i}}} uniformly at
% random without replacement with
% |\sigma_{\overline{y_{i}}}|=q*(1-g_{j} ) \sigma = \sigma_{y_{i}}
% \cup \sigma_{\overline{y_{i}}} sigmas = sigmas \cup { \sigma }

The ML-APP covers the entire spectrum of class prevalence values, by
drawing without replacement, for every single class. This means that,
for large enough classes, there will be samples for which the
prevalence of the class exhibits a large prior probability shift with
respect to the training prevalence, while for rare classes the amount
of shift will be limited by the availability of positive
examples. Note that, when actively sampling a class $y_{i}$, any other
class $y_{j}$ will co-occur with it with a probability that depends on
the correlation between $y_{i}$ and $y_{j}$. For cases in which the
class $y_{i}$ being sampled is completely independent of the class
$y_{j}$, the samples generated will display a class prevalence for
$y_{j}$ that is approximately similar to the prevalence of $y_{j}$ in
$U$. In other words, samples generated via the ML-APP preserve the
stochastic correlations between the classes while also exhibiting
widely varying degrees of prior probability shift. Finally, note that
the total number of samples that can be generated via the ML-APP can
vary from dataset to dataset (even if they have the same number of
classes), and depends on the actual number of positive instances for
each class that are contained in the dataset. In any case, the maximum
number of samples that can be generated via the ML-APP is bounded by
$m n |\mathbf{g}|$.
% \alexcomment{It might be interesting to show the number of samples
% we have generated for each dataset.} \manucomment{I agree, however
% do you remember that we limited the number of samples by tweaking
% $m$ and $g$ for every dataset? We should also explain that, right?}
% \alexcomment{Right, but anyway I meant in the experimental section,
% in the subsection dedicated to the datasets, and maybe along with
% the other attributes of table \ref{tab:datasets}. But we will do it
% later maybe.}

% \manucomment{One more thing, should we explain here the
% \textit{iterative stratification} that we use to generate train/test
% samples? It makes sense to me although they are kind of
% unrelated... maybe in another section?} \alexcomment{No, this is
% something that is unrelated to ML-APP. This is something that
% regards the experimental protocol (not the protocol for generating
% test samples), and therefore has to be explained in the Experiments
% section, maybe along with the ``implementation details'' or maybe
% within the ``dataset'' section. I would prefer in the
% ``implementation details'' since otherwise it could look like the
% train/test sets for the datasets have been generated by us.}

% ----------------------------------------------------------------------

\section{Performing Multi-Label Quantification}
\label{sec:quant}

\noindent In this section we present the multi-label quantification
methods that we will experimentally compare in
Section~\ref{sec:experiments}. Throughout this paper we will focus on
\emph{aggregative} quantification methods, i.e., methods that require
all unlabelled datapoints to be classified (by a hard or a soft
classifier, depending on the method) as an intermediate step, and that
aggregate the individual (hard or soft) predictions in some way to
generate the class prevalence estimates. The reason why we focus on
aggregative methods is that they are by far the most popular
quantification methods in the literature, and that this focus allows
us an easier exposition. We will later show how the most interesting
intuitions for performing MLQ that we discuss in this paper also apply
to the non-aggregative case.

Before presenting truly multi-label quantifiers, though, we will
introduce a number of single-label (aggregative) multiclass
quantification methods from the literature, that will form the basis
for our extensions to the MLQ case.

% ----------------------------------------------------------------------

\subsection{Single-Label Multiclass Quantification Methods}
\label{sec:quant:sl}

\noindent \emph{Classify and Count} (CC), already hinted at in the
introduction, is the na\"ive quantification method, and the one that
is used as a baseline that all genuine quantification methods are
supposed to beat. Given a hard classifier $h$ and a sample $\sigma$,
CC is formally defined as
%
\begin{equation}\label{eq:CC}
  \begin{aligned}
    \hat{p}_{\sigma}^{\mathrm{CC}}(y_{i}) & = \frac{|\{\mathbf{x}\in
    \sigma|h(\mathbf{x})=y_{i}\}|}{|\sigma|}
  \end{aligned}
\end{equation}
%
\noindent In other words, the prevalence of a class $y_{i}$ is
estimated by classifying all unlabelled datapoints, counting the
number of datapoints that have been assigned to $y_{i}$, and dividing
the result by the total number of datapoints.

The \emph{Adjusted Classify and Count} (ACC) method
(see~\cite{Forman:2008kx, Vaz:2019eu}) attempts to correct the
estimates returned by CC by relying on the law of total probability,
according to which
%
% \begin{align}
%  \label{eq:ACC} 
%  \Pr(h(\mathbf{x})=y_{i}) = \sum_{y_{j}\in
%  \mathcal{Y}}\Pr(h(\mathbf{x})=y_{i}|y_{j})\cdot \Pr(y_{j})
%\end{align}
\begin{align}
  \label{eq:ACC} 
  p(h(\mathbf{x})=y_{i}) = \sum_{y_{j}\in
  \mathcal{Y}}p(h(\mathbf{x})=y_{i}|y_{j})\cdot p(y_{j})
\end{align}
%
\noindent which can be more conveniently rewritten using matrix
notation as
%
\begin{align}
  \label{eq:ACC2} 
  \mathbf{p}^{\mathrm{CC}}_{\sigma} = \mathbf{M}_h
  \cdot \mathbf{p}^{\mathrm{ACC}}_{\sigma}
\end{align}
%
\noindent where $\mathbf{p}^{\mathrm{CC}}_{\sigma}$ is the vector
representing the distribution across $\mathcal{Y}$ of the datapoints
as estimated via CC, and matrix $\mathbf{M}_h$ contains the
misclassification rates of $h$, i.e., $m_{ij}$ is the probability that
$h$ will assign class $y_{i}$ to a datapoint whose true label is
$y_{j}$. Matrix $\mathbf{M}_h$ is unknown, but can be estimated via
$k$-fold cross-validation, or on a validation set. Vector
$\mathbf{p}^{\mathrm{ACC}}_\sigma$ is the true distribution; it is
unknown, and the ACC method consists of estimating it by solving the
system of linear equations of Equation \ref{eq:ACC2} (see
\cite{Bunse:2022oj} for more on the multiclass version of ACC).
% Note that $\mathbf{p}^{\mathrm{ACC}}_\sigma$ is actually an
% approximation of the true distribution, since $\mathbf{M}_h$ is
% estimated.

While CC and ACC rely on the crisp counts returned by a hard
classifier $h$, it is possible to define variants of them that use
instead the expected counts computed from the posterior probabilities
returned by a calibrated probabilistic classifier $s$
\cite{Bella:2010kx}. This is the core idea behind \emph{Probabilistic
Classify and Count} (PCC) and \emph{Probabilistic Adjusted Classify
and Count} (PACC).
%
PCC is defined as%\manucomment{where is $h$?}
%
\begin{align}
  \begin{split}\label{eq:PCC}
    \hat{p}_{\sigma}^{\mathrm{PCC}}(y_{i}) & = \frac{1}{|\sigma|}\sum_{\mathbf{x}\in \sigma}[s(\mathbf{x})]_{i} \\
    & = \frac{1}{|\sigma|}\sum_{\mathbf{x}\in
    \sigma}\Pr(y_{i}|\mathbf{x})
  \end{split}
\end{align}
%
\noindent while PACC is defined as
%
\begin{align}
  \label{eq:PACC2} 
  \mathbf{p}^{\mathrm{PCC}}_{\sigma} = \mathbf{M}_s
  \cdot \mathbf{p}^{\mathrm{PACC}}_{\sigma}
\end{align}
%
\noindent Equation~\ref{eq:PACC2} is identical to
Equation~\ref{eq:ACC2}, but for the fact that the leftmost part is
replaced with the prevalence values estimated via PCC, and for the
fact that the misclassification rates of the soft classifier $s$
(i.e., the rates computed as expectations using the posterior
probabilities) are used.

% en quantification la mayoría de metodos son binary [citas], o
% multiclass [citas]; también hay algo pero poco de ordinal [citas].
% Quantification is the task of predicting prior probabilities of an
% unlabelled sample. Most of quantification work is constrained to
% binary domains CITAS, or even multiclass CITAS. There is also some
% related work dedicated to ordinal classification CITAS. Yet, to the
% best of our knowledge, no one has dealt with quantification for
% multi-label tasks.

% Attending to the nature of the quantifiers, we can distinguish
% between\manucomment{CITA}:
% \begin{itemize}
% \item Aggregative quantifiers, that use an underlying classifier.
% \item Non-aggregative quantifiers, that use other techniques that do
%   not rely on classification models.
% \end{itemize}

% According to~\cite{gonzalez_review_{2}017}, and with respect to the
% mechanics of the quantifier, there are three groups in which we can
% classify current approaches for quantification. These are (1)
% \textit{classify, count and correct}, (2) algorithm adaptations and
% (3) distribution matching.

% \subsection{Classify, Count and Correct}
% Classify, count and correct methods rely on a classification task of
% the instances in the unlabelled sample. The predictions are used to
% estimate the prevalence of each class in the sample; after that, a
% correction is applied to deal with the bias of the classifier.

% \paragraph{Classify and Count (CC)} It trains a classifier in order
% to produce an estimation of the classes for the unlabelled
% sample~\cite{Forman:2008kx}. This estimation is later used to
% estimate class prevalences. No corrections are applied. This is the
% most straightforward method nevertheless it is not a good
% quantification method, since i.i.d. principle must prevail in order
% for it to work.

% \paragraph{Probabilistic Classify and Count (PCC)} It follows the
% same scheme than CC but using a probabilistic
% classifier~\cite{bella_quantification_{2}010}. The idea is to obtain
% classifier posteriors and estimate the prevalence for each class as
% the average of such posteriors.

% \paragraph{Adjusted Classify and Count (ACC)} It relies on a
% correction applied to the CC estimates. Such correction is computed
% using the confusion matrix, which requires validation sets that
% should be obtained from the training sample (e.g. using
% cross-validation). The idea is to apply a linear transformation to
% the class estimates using equation~\ref{eq:ac}.
% \begin{equation}
% \label{eq:ac}
% \hat{p} = \frac{\hat{p_0}- fpr}{tpr - fpr}
% \end{equation}
% where $\hat{p_0}$ are the outputs of the classifier, $tpr$ stands
% for \textit{true positive rate} and $fpr$ for \textit{false positive
% rate}.

% \paragraph{Probabilistic Adjusted Classify and Count (PACC)} Which
% is a straighforward evolution of PCC with the same corrections
% applied in ACC~\cite{bella_quantification_{2}010}.

% As a general rule, CC and PCC will perform reasonably well when the
% priors of the unlabelled sample are similar to the training
% sample. In the event that the prior probability shift is noticeable,
% their adjusted versions (ACC and PACC) will yield better results,
% since they are aware of the bias of the underlying classifier.

% Adjusted method present one additional drawback when the training
% sample is highly imbalanced~\cite{gonzalez_review_{2}017}. In this
% case, when there are few positives, the classifier will try to
% predict the majority class, hence reducing the $fpr$ at the expense
% of the $tpr$. This result in excessive
% corrections~\cite{forman_quantifying_{2}006}, which can be mitigated
% using threshold selection techniques for classification.

% \subsection{Algorithm Adaptation}
% Algorithm adaptation consists on modifying existing classification
% methods to the task of quantification, for example by employing loss
% functions related to quantification instead of
% classification. Despite this detail, the approach used to estimate
% the priors of the sample is still the same: classify, count and
% correct.

% \paragraph{Quantification Trees} Which are an adaptation of decision
% trees to deal directly with the quantification
% task~\cite{milli_quantification_{2}013}. They do so by choosing a
% measure that takes into account the false positives and false
% negatives to select the best splits for quantification.

% \paragraph{Instance-based Quantification}
% ~\cite{barranquero_study_{2}013} proposes a quantifier method based
% on a similarity neighbourhood in the same fashion than the
% well-known $k$-nearest neighbours (kNN) algorithm.

% \paragraph{Ensembles}~\cite{perez-gallego_using_{2}017} proposes an
% ensemble for binary quantification in which they generate samples
% with different prevalences that they will later use to train
% different classifiers. An aggregation of the estimates yields the
% final output of the ensemble.

% \subsection{Distribution Matching}
% Distribution matching approaches try to match the distribution
% between the train sample and the unlabelled one, in order to adjust
% the classifier to match the class prior probability shift.

% \paragraph{Expectation-maximization} Which is based on the idea that
% probabilistic classifier posteriors can be modified to obtain new
% priors that maximise the
% likelihood~\cite{saerens_adjusting_{2}002}. Thus, the classifier can
% learn on a biased sample and its outputs will later be corrected
% without requiring more training.

% \paragraph{Iterative Methods}~\cite{vucetic_classification_{2}001}
% propose a bootstrapping strategy to initially train a model on the
% training sample and obtaining posterior probabilities. After that,
% new samples are generated from the train and the process is repeated
% until stopping criteria are met (convergence).

% \paragraph{Mixture Models} That adapt the distribution of the
% unlabelled sample by matching the outputs of a probabilistic
% classifier with the mixture of the distributions obtained from the
% training sample~\cite{forman_counting_{2}005}.

Methods CC, ACC, PCC, PACC, are sometimes collectively referred to as
the ``CC variants'', and are all (as it is easy to verify) aggregative
quantification methods.
% Methods CC, ACC, PCC, PACC, are sometimes collectively referred to
% as the ``CC variants'', and are all \emph{aggregative}
% quantification methods, i.e., estimation methods that accomplish
% quantification in two steps, one in which a classifier generates
% (hard or soft) individual predictions for each unlabelled datapoint,
% and another in which these predictions are aggregated in some way.
%
Although more sophisticated quantification systems have been proposed
in the literature, the CC variants have recently been found to be
competitive contenders when properly
optimized~\cite{Moreo:2021sp}. This, along with their simplicity, has
motivated us to focus on the four CC variants as a first step towards
devising multi-label quantifiers.

A further, very popular (aggregative) quantification method is the one
proposed in~\cite{Saerens:2002uq}, which is often called SLD, from the
names of its proposers, and which was called EMQ
in~\cite{Gao:2016uq}. SLD was the best performer in a recent data
challenge centred on quantification~\cite{Esuli:2022hy}, and consists
of training a probabilistic classifier and then using the EM algorithm
(i) to update the posterior probabilities that the classifier returns,
and (ii) to re-estimate the class prevalence values of the test
set. Steps (i) and (ii) are carried out in an iterative, mutually
recursive way, until mutual consistency, defined as the situation in
which
%
\begin{align}
  \label{eq:calib} 
  \hat{p}_{\sigma}(y_{i}) & \approx \sum_{\mathbf{x}\in \sigma}\Pr(y_{i}|\mathbf{x})
\end{align}  
%
\noindent is achieved for all $y_{i}\in \mathcal{Y}$.



% ----------------------------------------------------------------------

\subsection{Multi-Label Quantification}
\label{sec:quant:ml}

\noindent In this paper we will describe and compare many different
(aggregative) MLQ methods.  In order to better assess their relative
merits, we subdivide them into four different groups, depending on
whether the correlations between different classes are brought to bear
in the classification phase (i.e., by the classifier on which an
aggregative quantifier rests), or in the aggregation phase (i.e., in
the phase in which the individual predictions are aggregated), or in
both phases, or in neither of the two phases.

% We will first define a grouping of multi-label quantifiers depending
% on the type of information that is available in the classification
% and aggregation stages (Section~\ref{sec:quant:ml:grouping}), to
% then describe specific ways for bringing to bear information about
% the class-class correlations at the aggregation level
% (Section~\ref{sec:quant:ml:reg}).
%
%% ----------------------------------------------------------------------
%
% \subsubsection{Classes of Multi-Label Quantifiers}
% \label{sec:quant:ml:grouping}

The first and simplest such group is that of \MLQ\ methods that treat
each class as completely independent, and thus solve $n$ independent
binary quantification problems. We call such an approach \bqbc\
(``binary classification followed by binary aggregation''), since in
both the classification phase and the aggregation phase it looks at
the multi-label task as $n$ independent binary tasks, thus
disregarding, in both phases, the correlations among classes when
predicting their relative frequencies. This is akin to the binary
relevance (BR) problem transformation described in
Section~\ref{sec:relwork:probtrans} for classification, and consists
of transforming the multi-label dataset $L$ into a set of binary
datasets $L_{1}, \ldots, L_{n}$ in which
$L_{i}=\{(\mathbf{x},\indfn{y_{i}\in Y}):(\mathbf{x},Y)\in L\}$ is
labelled according to $\mathcal{Y}_{i}=\{\mathbf{0},\mathbf{1}\}$,
since the datapoints are relabelled using the indicator function
$\indfn{z}$ that returns $\mathbf{1}$ (the ``positive class'') if $z$
is true or $\mathbf{0}$ (the ``negative class'') otherwise. \bqbc\
methods then train one quantifier $q_{i}$ for each training set
$L_{i}$. At inference time, the prevalence vector for a given sample
$\sigma$ is computed as
$\mathbf{p}_{\sigma}^{\bqbc}=(p_{\sigma}^{q_{1}}(\mathbf{1}),p_{\sigma}^{q_{2}}(\mathbf{1}),\ldots,p_{\sigma}^{q_{n}}(\mathbf{1}))$.
Although this is technically a multi-label quantification
method, %and something that has never been attempted before,
\bqbc\ is actually the trivial solution that we expect any truly
multi-label quantifier to improve
upon. %\manucomment{would it make sense to add a diagram (aka visual abstract) of the architecture of each MLQ approach?}

A second, less trivial group is that of \MLQ\ methods based on the use
of binary aggregative quantifiers working on top of (truly)
multi-label classifiers. Methods in this group consist of $n$
independent binary aggregative quantifiers (e.g., built via one of the
methods described in Section~\ref{sec:quant:sl}) that rely on the
(hard or soft) predictions returned by a classifier natively designed
to tackle the multi-label problem (e.g., built via one of the methods
described in Section~\ref{sec:relwork}). Each binary quantifier takes
into account only the predictions for its associated class,
disregarding the predictions for the other classes. This represents a
straightforward solution to the \MLQ\ problem, as it simply combines
already existing technologies (binary aggregative quantifiers built
via off-the-shelf methods and (truly) multi-label classifiers built
via off-the-shelf methods). In such a setting, the classification
stage is informed by the class-class correlations, but the
quantification methods in charge of producing the class prevalence
estimates for each class do not pay attention to any such correlation,
and are disconnected from each other. Since methods in this group will
consist of a (truly) multi-label classification phase followed by a
binary quantification phase, we will refer to this group of methods as
\bqmc.

We next propose a third group of \MLQ\ systems, i.e., ones consisting
of natively multi-label quantification methods relying on the outputs
of $n$ independent binary classifiers.
%
%% aiming at refining an estimate of class prevalence values by
% taking into account the correlations between classes in order to
% issue predictions of class prevalence.
Methods like these represent a non-trivial novel solution for the
field of quantification, because no natively multi-label
quantification method has been proposed so far in the literature; in
Section~\ref{sec:quant:ml:reg} we propose some such methods. In order
to clearly evaluate the merits of such a multi-label aggregation
phase, as the underlying classifiers we use independent binary
classifiers only. For this reason, we will call this group of methods
\mqbc.

The fourth and last group of methods we consider amounts to combining
any (truly) multi-label classification method with any (truly)
multi-label quantification method among our newly proposed ones, thus
bringing to bear the class dependencies both at the classification
stage and at the aggregation stage. We call this group of methods
\mqmc.

Figure~\ref{fig:schema} illustrates in diagrammatic form the four
types of multi-label quantification methods we study in this paper. In
order to generate members of these four classes, we already have
off-the-shelf components for implementing the binary classification,
multi-label classification, and binary aggregation phases, but we have
no known method from the literature to implement multi-label
aggregation; Sections~\ref{sec:quant:ml:reg} and \ref{sec:quant:ml:lp}
are devoted to proposing two novel such methods.
%
\begin{figure}
  \centering
  \caption{The four groups of multi-label quantification methods. Dotted lines
  connecting class labels with a model (classifier or quantifier)
  indicate that the model learns from (or has access to) the class
  labels of the training datapoints. Solid lines connecting
  classifiers with quantifiers indicate a transfer of outputs from the
  classifier to the quantifier. With a slight deviation from our
  notation, here $h$ denotes any classifier, hard or soft.}
  \label{fig:schema}
  \include{figures/diagram}
\end{figure}
%
%\begin{table}[ht]
%  \centering
%  \caption{Taxonomy of multi-label quantifiers}
%  \label{fig:schema}
%  \begin{tabular}{|c|c|c|c|}
% \cline{3-4}
% \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{\textbf{Classification}} \\\cline{3-4}
% \multicolumn{2}{c|}{} & Binary & Multi-label \\\hline
% \multirow{2}{*}{\textbf{Quantification}} & Binary & \bqbc & \bqmc \\\cline{2-4}
% & Multi-label & \mqbc & \mqmc \\\hline
% \end{tabular}
% \end{table}



% ----------------------------------------------------------------------

\subsubsection{Bringing to Bear Class-Class Correlations at the
Aggregation Stage via Regression}
\label{sec:quant:ml:reg}

\noindent Let us assume we have a multi-label quantifier $q$ of type
\bqbc\ or \bqmc. Our idea is to detect how quantifier $q$ fails in
capturing the correlations between classes,
% characterize the bias that quantifier $q$ exhibits for each class,
and correct $q$ accordingly.
% ; in other words, and learn how to correct this by leveraging the
% systematic errors that are detected (if any) by observing the
% distribution of the class prevalence estimates. \fabsebcomment{Yes,
% but what does this have to do with class-class correlations?}
This is somehow similar to the type of correction implemented in ACC
and PACC.  However, we will formalize this intuition as a general
regression problem, thus not necessarily assuming this correction to
be linear (as ACC and PACC instead do).

More concretely, we split our training set $L$ into two parts, $L_{Q}$
(that we use for training our quantifier $q$) and $L_{R}$ (that we use
for training a regressor $r$, i.e., a function
$r : \mathbb{R}^{n} \rightarrow
\mathbb{R}^{n}$).\footnote{\protect\label{foot:iterativestrat}Note
that, for reasons discussed in~\cite{Sechidis:2011tu,
Szymanski:2017yc}, multi-label datasets cannot be split in a
stratified way using standard algorithms for single-label
stratification. For splitting the training set $L$, we thus use the
\emph{iterative stratification} method implemented in
\scikitml\footnote{\url{http://scikit.ml/stratification.html}} and
described in~\cite{Szymanski:2017yc}.} We then use the ML-APP protocol
described in Section~\ref{sec:mlapp} to extract, from set $L_{R}$, a
set
$\mathcal{R}=\{\sigma_{i} \sim \operatorname{ML-APP}(L_{R}, k, m,
\mathbf{g})\}$ of $l$ samples, where $k$ (sample size), $m$ (number of
samples to draw for each prevalence value on the grid), and
$\mathbf{g}$ (grid of prevalence values) are the parameters of the
ML-APP protocol.
%
% (\hat{\mathbf{p}}^q_{\sigma_{i}}, \mathbf{p}_{\sigma_{i}})_{i=1}^l :
%
% \manucomment{This is really important, however it interrupts the
% reading flow. I'm trying to understand how do you use the regressor
% to model class-class correlations, and now that I've reached the
% formal description, my focus is interrupted since there is a
% clarification regarding the splitting mechanism. I think this can
% (and should be) moved to another place, or even pushed to the footer
% as a footnote.}
%
Having done this, we first train our quantifier $q$ on $L_{Q}$; since
$q$ is a multi-label quantifier, it is a function that, given a sample
$\sigma$, returns a vector $\hat{\mathbf{p}}^q_{\sigma}$ of $n$ class
prevalence values, not necessarily summing up to
1. %\alexcomment{Maybe the following can be safely removed...} Recall $q$ is already a multi-label quantifier, either of type \bqbc\ or \bqmc. This means that, when $q$ is of type \bqbc, it internally handles several classifiers, of type ``hard'' (for example if CC or ACC are used) or of type ``soft'' (if PCC or PACC are used). If $q$ is of type \bqmc\ instead, it internally handles only one multi-label classifier (again, ``hard'' or ``soft''). Additionally, if the base quantifier is either ACC or PACC, this also implies that the training set $L_Q$ has to be split anew into $L_Q^{\mathrm{tr}}$ for training the classifier(s), and $L_Q^{\mathrm{va}}$ for estimating the misclassification rates of the (binary) matrices $\mathbf{M}$.\manucomment{We said earlier that, in order to estimate $M_h$, we could use simple train/val splits or k-cfv. However, we did not specify until right now that we are using simple splits. Wouldn't it make sense to sweep along with both possibilities?} \alexcomment{Yes you are right. I am leaning towards removing this explanation.}
We then apply $q$ to all the samples in $\mathcal{R}$; as a result,
for each sample $\sigma_{i}\in\mathcal{R}$ we have a pair
$(\hat{\mathbf{p}}^q_{\sigma_{i}}, \mathbf{p}_{\sigma_{i}})$, where
$\hat{\mathbf{p}}^q_{\sigma_{i}}$ is the vector of the $n$ prevalence
values estimated by $q$, and $\mathbf{p}_{\sigma_{i}}$ is the vector
of the $n$ true prevalence values. We use this set of $l$ pairs as the
training set for training a multi-output regressor
$r : \mathbb{R}^{n} \rightarrow \mathbb{R}^{n}$ that takes as input a
vector of $n$ ``uncorrected'' prevalence values and returns a vector
of $n$ ``corrected'' prevalence values; for training the regressor we
use any off-the-shelf multi-output regression algorithm. Note that the
regressor indeed captures the correlations between classes, since it
receives as input, for each sample, the class prevalence estimates for
all the $n$ classes altogether.\footnote{The fact that the regressor
captures the correlations between classes does not depend on it being
a multi-output regressor; even a set of $n$ single-output regressors
would obtain the same effect, which is only due to the fact that the
regressor takes as input all the $n$ class prevalence estimates at the
same time.
%
% Notice that the regressor is already modelling the correlations
% among the classes notwithstanding the fact that the regressor of
% choice be not natively multi-target. i.e., even if the regressor is
% constructed as a set of independent univariate regressors. The
% reason why, is that the covariates (inputs) are already class
% prevalence estimations, and so each of the corrected prevalence
% estimations (outputs) is taking advantage of the correlations
% between classes already.
}

% Note that, for generating the samples $L_{R}$, it would make sense
% to We use the same $k$ and $\mathbf{g}$ values that we later use in
% the evaluation, but we reduce $m$ in order to reduce the
% computational burden required to train $r$.\manucomment{Same opinion
% here. Are we talking about the methods or the specifics of our
% experiments? For me, it would make sense to push these kind of
% clarifications to another section that covers the full experimental
% setup. Otherwise it seems easy that some details go unnoticed.}
% \alexcomment{In this case, I think this is part of the idea,
% though. Maybe we could abstract this and say ``any sampling
% procedure'' in place of the ML-APP, and then add that this can be
% done via $k$-fold cross validation. In any case, I think it makes
% sense to use the same sampling procedure later used to evaluate the
% system, and given that for multi-label there is no other sampling
% procedure (apart, maybe, from the uniform sampling), this could stay
% as it is. (I don't have a strong opinion about this.)}

At inference time, given an (unlabelled) sample $\sigma$, we first
obtain a preliminary estimate of the class prevalence values
$\hat{\mathbf{p}}^q_\sigma$ via $q$, and then apply the correction
learned by $r$, thus computing
$\hat{\mathbf{p}}^r_\sigma=r(\hat{\mathbf{p}}^q_\sigma)$. We then
normalize, via clipping,\footnote{Clipping a value $v$ to the interval
$[a,b]$ amounts to returning $v$ if $v\in[a,b]$, $a$ if $v<a$, or $b$
if $v>b$. This is needed since, in principle, the regressor might
sometimes return values that fall outside the [0,1] interval.} every
prevalence value in $\hat{\mathbf{p}}^r_\sigma$ so that it falls in
the $[0,1]$ interval, and return the estimate.

The method (which we here call RQ, for ``\underline{r}egression-based
\underline{q}uantification'') is described succinctly as
Algorithm~\ref{alg:reg:train} (training phase) and
Algorithm~\ref{alg:reg:test} (inference
phase). %\alexcomment{Not sure if this is needed}\manucomment{I don't think so, but it could be worth it to add a diagram :)}\manucomment{\textbf{nope, i've changed my mind, I like it}}

% \begin{algorithm}[ht]
%   \caption{\MLQ\ correction via regression,
%   Training}\label{alg:reg:train}
%   \begin{algorithmic}
%     \State \textbf{Input:} $L$, a training collection \State
%     \textbf{Input:} $q$, a multi-label quantifier \State
%     \textbf{Input:} $r$, a multi-output regressor \State
%     \textbf{Input:} $k$, $m$, $\mathbf{g}$, parameters of the ML-APP
%     \State $L_Q, L_{R} = \operatorname{iterative-stratification}(L)$
%     \State train $q$ on $L_Q$ \State
%     $\mathcal{R}=\{(\hat{\mathbf{p}}^q_{\sigma_{i}},
%     \mathbf{p}_{\sigma_{i}})_{i=1}^l : \sigma_{i} \sim
%     \operatorname{ML-APP}(L_{R}, k, m, \mathbf{g})\}$ \State train
%     $r$ on $\mathcal{R}$ \State \textbf{Return:} $q, r$
%   \end{algorithmic}
% \end{algorithm}

% \begin{algorithm}[ht]
%   \caption{\MLQ\ correction via regression,
%   Inference}\label{alg:reg:test}
%   \begin{algorithmic}
%     \State \textbf{Input:} $\sigma$, an unlabelled sample \State
%     \textbf{Input:} $q$, a trained multi-label quantifier \State
%     \textbf{Input:} $r$, a trained multi-output regressor

%     \State $\hat{\mathbf{p}}^q_\sigma \leftarrow q(\sigma)$ \State
%     $\hat{\mathbf{p}}^r_\sigma \leftarrow
%     r(\hat{\mathbf{p}}^q_\sigma)$ \State
%     $\hat{\mathbf{p}}'^r_\sigma \leftarrow
%     \operatorname{clip}(\hat{\mathbf{p}}^r_\sigma, [0,1])$

%     \State \textbf{Return:} $\hat{\mathbf{p}}'^r_\sigma$

%   \end{algorithmic}
% \end{algorithm}

% ============================================= START OF SIDE-BY-SIDE
% ALGORITHMS
% \manucomment{the following can be safely removed, choose your preferred version and remove the other (labels are the same so there are warnings)}\\

% \medskip

\begin{minipage}{\textwidth}
  \begin{minipage}{.48\textwidth}
    \vspace{-1ex} \footnotesize
    \begin{algorithm}[H]
      \caption{\MLQ\ correction via regression:
      Training}\label{alg:reg:train}
      \begin{algorithmic}
        \State \textbf{Input:} $L$, a training collection \State
        \textbf{Input:} $q$, a multi-label quantifier \State
        \textbf{Input:} $r$, a multi-output regressor \State
        \textbf{Input:} $k$, $m$, $\mathbf{g}$, parameters of the
        ML-APP \State
        $L_Q, L_{R} = \operatorname{iterative-stratification}(L)$
        \State train $q$ on $L_Q$ \State
        $\mathcal{R}=\{(\hat{\mathbf{p}}^q_{\sigma_{i}},
        \mathbf{p}_{\sigma_{i}})_{i=1}^l : \sigma_{i} \sim
        \operatorname{ML-APP}(L_{R}, k, m, \mathbf{g})\}$ \State train
        $r$ on $\mathcal{R}$ \State \textbf{Return:} $q, r$
      \end{algorithmic}
    \end{algorithm}
    \vspace{3ex}
  \end{minipage}
  \hfill
  \begin{minipage}{.48\textwidth}
    \vspace{-1ex} \footnotesize
    \begin{algorithm}[H]
      \caption{\MLQ\ correction via regression: Inference
      \vspace{.5ex} \mbox{}}\label{alg:reg:test}
      \begin{algorithmic}
        \vfill \State \textbf{Input:} $\sigma$, an unlabelled sample
        \State \textbf{Input:} $q$, a trained multi-label quantifier
        \State \textbf{Input:} $r$, a trained multi-output regressor
        \Statex \State
        $\hat{\mathbf{p}}^q_\sigma \leftarrow q(\sigma)$ \State
        % $\hat{\mathbf{p}}^r_\sigma \leftarrow
        % r(\hat{\mathbf{p}}^q_\sigma)$ \State
        % $\hat{\mathbf{p}}'^r_\sigma \leftarrow
        % \operatorname{clip}(\hat{\mathbf{p}}^r_\sigma, [0,1])$
        % \Statex
        % \State \textbf{Return:} $\hat{\mathbf{p}}'^r_\sigma$
        % $\hat{\mathbf{p}}^r_\sigma \leftarrow
        % r(\hat{\mathbf{p}}^q_\sigma)$ \State
        $\hat{\mathbf{p}}^r_\sigma \leftarrow
        \operatorname{clip}(r(\hat{\mathbf{p}}^q_\sigma), [0,1])$
        \Statex
        \State \textbf{Return:} $\hat{\mathbf{p}}^r_\sigma$ \\
        \mbox{}
      \end{algorithmic}
    \end{algorithm}
    \vspace{4ex}
  \end{minipage}
\end{minipage}

\medskip

% END OF SIDE-BY-SIDE ALGORITHMS
% ================================================

As noted above, the regressor exploits the class-class correlations
during the aggregation phase. This means that, according to the
subdivision of MLQ methods illustrated in Table~\ref{fig:schema}, the
addition of a regression layer on top of an existing quantifier $q$
has the effect of transforming a \bqbc\ method into a \mqbc\ method,
or of transforming a \bqmc\ method into a \mqmc\ method.

% \alexcomment{Give a name: maybe Reg-Q}

% There are not previous work in \MLQ\. Yet, it is a necessary
% evolution of single-label quantification methods, since there are
% many real-world problems that are natively multi-label.

% There are several handicaps that we need to consider in order to
% address quantification in multi-label problems~\cite{Zhang:2014zn}:
% \begin{itemize}
% \item High label dimensionality, which result in an exponential
%   number of potential label sets.
% \item Label dependencies, which are required to model since it would
%   facilitate dealing with the high output space.
% \item High label imbalance, which is a common problem in some tasks
%   such as text classification. It constitutes a drawback both for
%   classifiers but also for artificial sampling protocols used to
%   train and/or validate quantifiers.
% \end{itemize}

% In the following sections, we describe our proposals for \MLQ\ as
% well as the evaluation strategy.

% \subsection{Methods}
% In order to obtain a generalisation of single-label quantification
% methods to a multi-label domain, it is possible to apply similar
% strategies than the one used for \MLC\ (e.g. problem transformation,
% algorithm adaptation and so on). In this article, we would focus on
% transformation approaches, therefore leaving the rest to future
% work. We used the four techniques of classify and count as base
% quantifiers (CC, PCC, ACC and PACC).

% \subsection{Binary Relevance}
% These methods treat each label as a single task. There are two
% variants of this approach.
% \begin{itemize}
% \item Using single-label classifiers, which would be the naive
%   approach for multi-label quantification, where both the classifier
%   and the quantifier are not aware of the label dependencies. In
%   this case, we will train a binary quantifier (with an underlying
%   binary classifier) for each label.
% \item Using multi-label classifiers, in which the quantifiers are
%   not aware of label dependencies but they work over the
%   classification product of a model which is aware of such
%   dependencies. In this scenario, we will train a binary quantifier
%   per label, each of them using the same underlying multi-label
%   classifier.
% \end{itemize}

% Our hypothesis is that multi-label classifiers would output more
% coherent results than when using single-label classifiers, therefore
% quantification would base its estimates on better classified
% samples.

% ----------------------------------------------------------------------

\subsubsection{Bringing to Bear Class-Class Correlations at the
Aggregation Stage via Label Powersets}
\label{sec:quant:ml:lp}

\noindent We investigate an alternative way of modelling class-class
correlations at the quantification level, this time by gaining
inspiration from label powersets (LPs -- see
Section~\ref{sec:relwork:probtrans}) and the heuristics for making
their application tractable (Section~\ref{sec:relwork:ensembles}).

LP is a problem transformation technique devised for transforming any
multi-label classification problem into a single-label one by
replacing the original codeframe with another one that encodes subsets
of this codeframe into ``synthetic'' classes (see
Section~\ref{sec:relwork:probtrans} for details).
% \alexcomment{An alternative option is to move here the technical
% details and simplify the explanation in the related work section.}
This problem transformation is directly applicable to the case of
quantification as well. Of course, the combinatorial explosion of the
number of synthetic classes has to be controlled somehow but,
fortunately enough, the same heuristics investigated for \MLC\ can
come to the rescue here.

Our method (which we here call LPQ, for ``\underline{l}abel
\underline{p}owerset -based \underline{q}uantification'') consists of generating, by
means of any existing clustering algorithm, a set $\mathcal{C}$ of
(non-overlapping) clusters consisting of few classes each, before
applying the LP strategy, so that the number of possible synthetic
classes remains under reasonable bounds.
% \fabsebcomment{Maybe some sort of distributional clustering could
% have been ideal here.}
For example, if our codeframe has $n=100$ classes,
% instead of (frustratingly) attempting to generate a codeframe for
% all $2^{100}$ possible labelsets, we could try to
extracting 25 clusters of 4 classes each results in the maximum
possible number of synthetic classes being $25 \cdot 2^4=400$, which
is much smaller than the original $2^{100}$.
% \fabsebcomment{As a method to limit the number of possible label
% combinations, it would have made more sense to me (and it would have
% been simpler) to only consider as valid combinations the ones that
% have at least $k$ training datapoints.}
We perform this clustering by treating classes in $\mathcal{Y}$ as
instances and training datapoints as features, so that a class is
represented by a binary vector of datapoints, where 1 indicates that
the datapoint belongs to the class and 0 that it does not.  The
clustering algorithm is thus expected to put classes displaying
similar assignment patterns (i.e., that tend to label the same
documents) in the same cluster.

% since not all $2^4$ combinations usually occur in real cases (same
% for all $2^{100}$ combinations in the original problem).  , and
% since there is no need for modelling labels for which no positive
% example exist.  \manucomment{This last comment may turn out to be
% problematic. Every related paper claims that this is the main
% disadvantage of label powerset, therefore there is a need for
% modelling new label combinations that are not present in the
% training set but the method is unable to do it. Moreover, this is
% not only related to labels without positive cases. See the case of
% sports and tennis: both classes could be present in the dataset but
% there is an impossible combination (which would be sports0-tennis1)}
% \alexcomment{Right, I agree. I will modify this.}

% \alexcomment{Add somewhere that this method does not have access to
% all-to-all class-class correlations, but only among labels in the
% cluster. The expectation though, is that this is sufficient, since
% there are few or no correlations between many classes in the
% codeframe.}  \manucomment{also because the clustering is supposed to
% group together those that are truly (cor)related. In fact, it may
% improve performance since it removes clutter and divides the problem
% into several others that are supposed to be independent (and less
% complex).}

Once we have performed the clustering, given the set of classes
$\mathcal{Y}_c \subseteq \mathcal{Y}$ contained in each cluster
$c\in\mathcal{C}$, we need to take the single-label codeframe
$\mathcal{Y}'_c$ determined from the
$2^{\mathcal{Y}}\rightarrow \mathcal{Y}'$ multi-label-to-single-label
mapping (a mapping that, e.g., would attribute to the set of classes
$\{y_{1},y_{5},y_{6}\}\subseteq \mathcal{Y}_{c}$ the synthetic class
$y_{1:5:6} \in \mathcal{Y}'_{c}$) and train a single-label quantifier
on it; this needs to be repeated for each
cluster. %\alexcomment{I am not sure if we could specify that such a single-label quantifier works with only one single-classifier, or if this could lead to confusion.}\manucomment{I think it is ok like this. If the quantifier is aggregative, then it has an underlying classifier, therefore there is no need to clarify}
At inference time, in order to provide class prevalence estimates for
the classes in $\mathcal{Y}_{c}$ from the predictions made for the
classes in $\mathcal{Y}'_{c}$ by the above-mentioned quantifier, we
have to ``reverse'' the multi-label-to-single-label mapping, so that
the estimated prevalence value of $y_{i}\in\mathcal{Y}_{c}$ is the sum
of the estimated prevalence values of all labels
$y'\in\mathcal{Y}'_{c}$ that involve $y_{i}$; performing this for each
cluster $c\in\mathcal{C}$ returns prevalence estimates for all classes
$y_{i}\in\mathcal{Y}$.


More formally, let us define a matrix $\mathbf{A}$ that records the
label assignment in cluster $c$, so that $a_{ij}=1$ if the set of
classes represented by the synthetic class $y'_{i}\in\mathcal{Y}'_c$
contains class $y_{j}\in\mathcal{Y}_c$, and $a_{ij}=0$ if this is not
the case. Note that $\mathbf{A}$ has as many rows as there are classes
in $\mathcal{Y}'_c$ and as many columns as there are classes in
$\mathcal{Y}_c$. Once our single-label quantifier $q$ produces an
output $\hat{\mathbf{p}}^q_\sigma$, we only need to compute the
product $(\hat{\mathbf{p}}^q_\sigma)^\top \mathbf{A}$ to obtain the
vector of prevalence estimates for the classes in
$\mathcal{Y}_{c}$. Performing all this for each cluster
$c\in\mathcal{C}$ returns prevalence estimates for all classes
$y_{i}\in\mathcal{Y}$. The example shown in Figure~\ref{fig:example}
may clarify things.
%
\begin{figure}[ht]
  \caption{An example considering a cluster made of three classes only
  (left), and the computations carried out for reconstructing the
  prevalence values for the original multi-label codeframe
  (right).\newline\mbox{}}
  \label{fig:example}
  \begin{subfigure}{0.45\textwidth}
    \centering \resizebox{\textwidth}{!}{%
    \begin{tabular}{|c|c|c|c|c|l|r|}
      \cline{2-4} \cline{6-7}
      \multicolumn{1}{c|}{} & \multicolumn{3}{c|}{$\mathcal{Y}_c$} & & \multicolumn{1}{c|}{\multirow{2}{*}{$\mathcal{Y}'_c$}} & \multicolumn{1}{c|}{\multirow{2}{*}{$\mathbf{\hat{p}}^q_\sigma$}}\\\cline{2-4}
      \multicolumn{1}{c|}{} & $y_1$ & $y_{2}$ & $y_{3}$ & & & \\\cline{1-4} \cline{6-7}
      \multirow{8}{*}{$\mathbf{A}$:} 
                            & 0 & 0 & 0 & & $y'_\emptyset$ & $\hat{p}^q_\sigma(y'_\emptyset)=0.15$\\
                            & 1 & 0 & 0 & & $y'_{1}$ & $\hat{p}^q_\sigma(y'_{1})=0.10$ \\
                            & 0 & 1 & 0 & & $y'_{2}$ & $\hat{p}^q_\sigma(y'_{2})=0.26$ \\
                            & 1 & 1 & 0 & & $y'_{1:2}$ & $\hat{p}^q_\sigma(y'_{1:2})=0.19$ \\
                            & 0 & 0 & 1 & & $y'_3$ & $\hat{p}^q_\sigma(y'_3)=0.05$ \\
                            & 1 & 0 & 1 & & $y'_{1:3}$ & $\hat{p}^q_\sigma(y'_{1:3})=0.13$ \\
                            & 0 & 1 & 1 & & $y'_{2:3}$ & $\hat{p}^q_\sigma(y'_{2:3})=0.11$ \\
                            & 1 & 1 & 1 & & $y'_{1:2:3}$ & $\hat{p}^q_\sigma(y'_{1:2:3})=0.01$ \\
      \cline{1-4} \cline{6-7}
    \end{tabular}
    }%
  \end{subfigure}%
  \begin{subfigure}{0.5\textwidth}
    \centering
    % \footnotesize
    \begin{tabular}{ll}
    
      \multicolumn{2}{l}{$(\hat{p}^q_\sigma(y_{1}),\hat{p}^q_\sigma(y_{2}),\hat{p}^q_\sigma(y_3))=(\mathbf{\hat{p}}^q_\sigma)^\top \mathbf{A}$} \\ 
      \\
      $\hat{p}^q_\sigma(y_{1})$ & = $\hat{p}^q_\sigma(y'_{1})+\hat{p}^q_\sigma(y'_{1:2})+\hat{p}^q_\sigma(y'_{1:3})+\hat{p}^q_\sigma(y'_{1:2:3})$ \\ & = $0.30$ \\
      $\hat{p}^q_\sigma(y_{2})$ & = $\hat{p}^q_\sigma(y'_{2})+\hat{p}^q_\sigma(y'_{1:2})+\hat{p}^q_\sigma(y'_{2:3})+\hat{p}^q_\sigma(y'_{1:2:3})$ \\ &= $0.57$ \\
      $\hat{p}^q_\sigma(y_3)$ & = $\hat{p}^q_\sigma(y'_{3})+\hat{p}^q_\sigma(y'_{1:3})+\hat{p}^q_\sigma(y'_{2:3})+\hat{p}^q_\sigma(y'_{1:2:3})$ \\ &= $0.43$
    \end{tabular}
    % \begin{tabular}{l}
%    
    %   $(\hat{p}^q_\sigma(y_{1}),\hat{p}^q_\sigma(y_{2}),\hat{p}^q_\sigma(y_3))=(\mathbf{\hat{p}}^q_\sigma)^\top \mathbf{A}$ \\
    %   \\
    %   $\hat{p}^q_\sigma(y_{1}) = \hat{p}^q_\sigma(y'_{1})+\hat{p}^q_\sigma(y'_{1:2})+\hat{p}^q_\sigma(y'_{1:3})+\hat{p}^q_\sigma(y'_{1:2:3}) = 0.30$ \\
    %   \\
    %   $\hat{p}^q_\sigma(y_{2}) = \hat{p}^q_\sigma(y'_{2})+\hat{p}^q_\sigma(y'_{1:2})+\hat{p}^q_\sigma(y'_{2:3})+\hat{p}^q_\sigma(y'_{1:2:3}) = 0.57$ \\
    %   \\
    %   $\hat{p}^q_\sigma(y_3) =
%       \hat{p}^q_\sigma(y'_{3})+\hat{p}^q_\sigma(y'_{1:3})+\hat{p}^q_\sigma(y'_{2:3})+\hat{p}^q_\sigma(y'_{1:2:3}) = 0.43$
%    \end{tabular}
  \end{subfigure}%
\end{figure}

In principle, the disadvantage of this method is that it cannot learn
the correlations between classes that belong to different clusters.
However, the method is based on the intuition that classes that are
indeed correlated tend to end up in the same cluster, and that the
inability to model correlations between classes that belong to
different clusters will be more than compensated by the reduction in
the number of combinations that one needs to take into account.

In the experiments of Section~\ref{sec:exp:mlq} we explore different
configurations of this approach, in which we combine different
clustering strategies.

% Label Powerset consists on a translation of all label combinations
% that are present on the training sample to a multiclass
% problem. The main handicap is the large number of classes that may
% be generated (for $l$ binary labels, the upper bound would be
% $2^l$). In order to reduce its complexity, clustering may be used.
% \begin{itemize}
% \item RAkEL+Q generate $k$ disjoint random clusters of labels and
%   transform each grouping to a multiclass problem. Then, a
%   multiclass quantifier is trained over them to estimate the
%   prevalences of each class. The last step would translate from
%   multiclass to multi-label, using the same powersets.
% \item Clustering+Q, where clusters are learned rather than selected
%   at random. A multiclass quantifier is trained for each grouping
%   to estimate the prevalences for each class, that would later be
%   transformed to a multi-label representation.
% \end{itemize}

% ----------------------------------------------------------------------

\section{Experiments}
\label{sec:experiments}

\noindent In this section we turn to describing the experiments we
have carried out in order to evaluate the performance of the different
methods for \MLQ\ that we have presented in the previous sections.  In
Section~\ref{sec:exp:eval} we discuss the evaluation measure we adopt,
while in Section~\ref{sec:exp:datasets} we describe the datasets on
which we perform our experiments. In Section~\ref{sec:exp:main} we
report experiments aiming at comparing the four groups of methods
discussed in Section~\ref{sec:quant:ml} and illustrated in
Figure~\ref{fig:schema}. In
Section~\ref{sec:exp:mlc}~and~\ref{sec:exp:mlq} we then move on to
exploring further instances of methods belonging to those four groups.

% ----------------------------------------------------------------------

\subsection{Evaluation Measures}
\label{sec:exp:eval}

\noindent
% \fabsebcomment{Multi-label quantification can be viewed, without
% loss of generality, as the task of of filling a binary
% $|\mathrm{Te}|\times n$ matrix $\hat{C}$ where each of the
% $|\mathrm{Te}|$ rows represents a sample in the test set
% $\mathrm{Te}$, the $n$ columns represent the classes, and each entry
% $\hat{c}_{ij}\in [0,1]$ is the predicted prevalence of class $y_{j}$
% in sample $\sigma_{i}$, i.e., an estimation of the unknown true
% prevalence $c_{ij}\in [0,1]$.  Note that, unlike in single-label
% quantification, there is no mutual consistency constraint between
% the values of different cells (in SLQ there is instead the
% constraint that the values on a row must sum up to 1).
%  
% In MLQ, the accuracy of a prediction can thus be measured in terms
% of how closely the prediction $\hat{c}_{ij}$ mirrors the true value
% $c_{ij}$, for all $i=1, ..., |\mathrm{Te}|$ and $j=1, ..., n$. It is
% essential to note that, because of the above-mentioned lack of
% mutual consistency constraints between the values of different
% cells, i.e., because of the \emph{independence} of the values
% $c_{ij}$ of each individual cell, in MLQ (unlike in SLQ) we can
% evaluate the accuracy of a prediction in a cell-wise manner. It thus
% makes sense to choose a measure of accuracy
% $d(\mathbf{p}, \hat{\mathbf{p}})$ at the cell level, and stipulate
% that our final evaluation measure is
%  %
% \begin{equation}
%  \label{eq:d}
%  \operatorname{D}(\mathbf{p}, \hat{\mathbf{p}})=\frac{1}{n}\sum_{i=1}^{|\mathrm{Te}|}\sum_{i=1}^{n}d(p_{ij}, \hat{p}_{ij})
%\end{equation}
%%
%\noindent In order to choose our cell-level measure of accuracy
% $d(\mathbf{p}, \hat{\mathbf{p}})$, it is natural to look at measures
% that have gained standard status in binary quantification.}
Any evaluation measure for binary quantification can be easily turned
into an evaluation measure for multi-label quantification, since
evaluating a multi-label quantifier can be done by evaluating how well
the prevalence value $p(y_{i})$ of each class $y_{i}\in|\mathcal{Y}|$
is approximated by the prediction $\hat{p}(y_{i})$. As a result, it is
natural to take a standard measure $d(\mathbf{p}, \hat{\mathbf{p}})$
for the evaluation of binary quantification, and turn it into a
measure
%
\begin{align}
  \label{eq:d}
  \operatorname{D}(\mathbf{p}, \hat{\mathbf{p}})=\frac{1}{n}\sum_{i=1}^{n}d((p_{i},(1-p_{i})), (\hat{p}_{i},(1-\hat{p}_{i})))
\end{align}
%
\noindent for the evaluation of multi-label quantification. (This is
exactly what we do in multi-label \emph{classification}, in which we
take $F_{1}$, a standard measure for the evaluation of binary
classification, and turn it into macroaveraged $F_{1}$, which is the
standard measure for the evaluation of multi-label classification.)

The study of evaluation measures for binary (and single-label
multiclass) quantification performed in~\cite{Sebastiani:2020qf}
concludes that the most satisfactory such measures are \emph{absolute
error} and \emph{relative absolute error}; these are the two measures
that we are going to use in this paper.
%
In the binary case, absolute error is defined as
%
\begin{align}
  \begin{split}
    \label{eq:ae}
    \operatorname{ae}(\mathbf{p},\hat{\mathbf{p}}) & =  \frac{|p_{1}-\hat{p}_{1}| + |p_{2}-\hat{p}_{2}|}{2} \\
    & =  \frac{|p_{1}-\hat{p}_{1}| + |(1-p_{1})-(1-\hat{p}_{1})|}{2} \\
    & = |p_{1}-\hat{p}_{1}|
    % \\
    % \label{eq:rae}
    % \rae(p,\hat{p}) & =\frac{1}{n}\sum_{y\in
    % \mathcal{Y}}\displaystyle\frac{|\hat{p}(y)-p(y)|}{p(y)}
  \end{split}
\end{align}
%
\noindent which yields the multi-label version
%
\begin{equation}
  \label{eq:AE}
  \operatorname{AE}(\mathbf{p}, \hat{\mathbf{p}})=\frac{1}{n}\sum_{i=1}^{n}|p_{i}-\hat{p}_{i}|
\end{equation}
%
\noindent In the binary case, relative absolute error is instead
defined as
%
\begin{align}
  \begin{split}
    \label{eq:rae}
    \operatorname{rae}(\mathbf{p},\hat{\mathbf{p}})  & =  \frac{1}{2}\left(\frac{|p_{1}-\hat{p}_{1}|}{p_{1}} + \frac{|p_{2}-\hat{p}_{2}|}{p_{2}}\right)\\
    & = \frac{1}{2}\left(\frac{|p_{1}-\hat{p}_{1}|}{p_{1}} +
      \frac{|(1-p_{1})-(1-\hat{p}_{1})|}{(1-p_{1})}\right)
  \end{split}
\end{align}
%
\noindent which yields the multi-label version
%
\begin{equation}
  \label{eq:RAE}
  \operatorname{RAE}(\mathbf{p}, \hat{\mathbf{p}})=\frac{1}{2n}\sum_{i=1}^{n}\left(\frac{|p_{i}-\hat{p}_{i}|}{p_{i}} + \frac{|(1-p_{i})-(1-\hat{p}_{i})|}{(1-p_{i})}\right)
\end{equation}
%
\noindent Since \rabse\ is undefined when $p_{i}=0$ or $p_{i}=1$, we
smooth the probability distributions $\mathbf{p}$ and
$\hat{\mathbf{p}}$ via additive smoothing; in the binary case, this
maps a distribution $\mathbf{p}=(p_{i},(1-p_{i}))$ into
%
\begin{equation}
  \label{eq:smooth}
  \operatorname{s}(\mathbf{p}) =
  \left(\frac{\epsilon+p_{i}}{2\epsilon+1},\frac{\epsilon+(1-p_{i})}{2\epsilon+1}\right)
\end{equation}
%
\noindent with $\epsilon$ the smoothing factor, that we set, following
\cite{Forman:2008kx}, to $\epsilon=(2|\sigma|)^{-1}$.

Note that we do \emph{not} use, as a measure, \emph{concordance
ratio}, i.e.,
%
\begin{equation}
  \label{eq:cr}
  \operatorname{CR}(\mathbf{p}, \hat{\mathbf{p}})=\frac{1}{n}\sum_{y=1}^{n}\frac{\min\{p_{i}, \hat{p}_{i}\}}{\max \{ p_{i}, \hat{p}_{i}\}}
\end{equation}
%
\noindent despite the fact that it is the measure used in
\cite{Levin:2017dq}, the only paper in the literature that addresses
multi-label quantification. The reason why we do not use it is the
fact that, as later shown in~\cite{Sebastiani:2020qf}, the
mathematical properties of CR do not make it (similarly to other
measures used in the quantification literature in the past, such as
the Kullback-Leibler Divergence) a satisfactory measure for
quantification; see~\cite[pp.\ 272--273]{Sebastiani:2020qf} for
details.


% The only known proposal of any evaluation measure dealing with \MLQ\
% is the so-called \emph{Concordance Ratio} (CR), proposed by
% ~\cite{Levin:2017dq} and defined as
%%
% \begin{equation}
%  \label{eq:cr}
%  \operatorname{CR}(\mathbf{p}, \hat{\mathbf{p}})=\frac{1}{n}\sum_{y=1}^{n}\frac{\min\{p_{i}, \hat{p}_{i}\}}{\max \{ p_{i}, \hat{p}_{i}\}}
%\end{equation}
%%
%\noindent Notice that CR is actually computed by averaging, across
% all classes, the concordance ratio \fabsebcomment{???} between a
% prevalence value and its estimate, which is computed independently
% for each label. This means Equation~\ref{eq:cr} admits a
% reinterpretation along the terms we describe in
% Section~\ref{sec:notation}, i.e., that one could rewrite it as an
% average of binary divergences implemented in terms of the
% concordance ratio $\operatorname{cr}$, i.e., as
%%
% \begin{equation}
%  \label{eq:cr2}
%  \operatorname{CR}(\mathbf{p}, \hat{\mathbf{p}})=\frac{1}{n}\sum_{y=1}^{n} \operatorname{cr}((p_{i}, 1-p_{i}), (\hat{p}_{i}, 1-\hat{p}_{i}))
%\end{equation}
%%
%% $\operatorname{cd}(\mathbf{p}, \mathbf{p}')=\frac{\min\{p_{i},
%% p'_{i}\}}{\max\{p_{i}, p'_{i}\}}$.
% \noindent In which $\operatorname{cr}$ is the divergence defined for
% the binary case (i.e., the case in which
% $\mathcal{Y}=\{y_{1},y_{2}\}$, with binary prevalence vectors
% $\mathbf{p}=(p_{1},p_{2})$ and
% $\hat{\mathbf{p}}=(\hat{p}_{1},\hat{p_{2}})$) as
%%
% \begin{equation}
%  \operatorname{cr}(\mathbf{p},\hat{\mathbf{p}})=\frac{\min\{p_{1}, \hat{p}_{1}\}}{\max\{p_{1}, \hat{p}_{1}\}}
%\end{equation}
%%
%\noindent However, this would give rise to a divergence measure
% ($\operatorname{cr}$) that has never been used in past
% quantification literature and which, despite having nothing specific
% to do with the multi-label nature of the problem, does completely
% disregard the negative prevalence ($p_{2}$ and $\hat{p}_{2}$) in the
% computation.
%% \footnote{In the binary case, with $\mathcal{Y}=\{y_{1},y_{2}\}$,
%% the $\operatorname{cr}$ divergence would be defined as
%% $$\operatorname{cr}(\mathbf{p},\hat{\mathbf{p}})=\frac{\min\{p_{1},
%% \hat{p}_{1}\}}{\max\{p_{1}, \hat{p}_{1}\}}$$
%% \noindent for binary prevalence vectors $\mathbf{p}=(p_{1},p_{2})$
%% and $\hat{\mathbf{p}}=(\hat{p}_{1},\hat{p_{2}})$. Note
%% $\operatorname{cr}$ completely disregards the negative prevalence
%% ($p_{2}$ and $\hat{p}_{2}$) in the computation.}
% Moreover, the $\operatorname{cr}$ has been criticised in past
% studies for not complying with many desirable properties one would
% desire an evaluation measure for quantification to enjoy
% ~\cite{Sebastiani:2020qf}.
%
% Specific metrics for \MLC\ cannot be easily adapted to the
% quantification case since, quite obviously, in quantification we are
% not interested in individual decisions but on obtaining accurate
% predictions of relative class frequencies. Instead, some metrics
% could be borrowed from multi-output regression, although not all of
% them would fulfil the requirements of a good evaluation measure for
% quantification. Take as an example the \emph{adjusted correlation
% coefficient}, routinely used in multi-target regression evaluation,
% that measures the degree of correlation between two real-valued
% arrays. Notice such a measure is unsatisfactory in our case, since a
% method that systematically overestimates (or underestimates) the
% true prevalence
% values %$\mathbf{p}$ (i.e., that always returns $\hat{\mathbf{p}}_{i} = \max\{\min\{\mathbf{p}_{i} + b, 1\},0\}$, with $b$ any fixed positive (or negative) amount) This method
% will score very high results
% anyway, %no matter the deviation imposed by $b$, since $\mathbf{p}$ and $\hat{\mathbf{p}}$
% since such predictions %are almost \textit{perfectly} correlated.
% would be strongly correlated to the true prevalence values.
%
% All these reasons have prompted us for leaning towards more standard
% evaluation metrics which have been proven reliable in the assessment
% of quantification systems in previous studies
% ~\cite{Sebastiani:2020qf}. We simply adopt \emph{absolute error}
% (one of the by now best established evaluation measures for
% quantification) as the binary divergence metric.
%%
% In the binary case, absolute error is defined as \fabsebcomment{This
% formula has some redundancy in it.}
%%
% \begin{equation}
%  \label{eq:ae}
%  \operatorname{ae}(\mathbf{p},\hat{\mathbf{p}}) =\frac{|p_{1}-\hat{p}_{1}| + |p_{2}-\hat{p}_{2}|}{2}%\\
%  %  \label{eq:rae}
%  % \rae(p,\hat{p}) & =\frac{1}{n}\sum_{y\in
%  % \mathcal{Y}}\displaystyle\frac{|\hat{p}(y)-p(y)|}{p(y)}
%\end{equation}
%%
%\noindent The multi-label extension amounts to averaging
% $\operatorname{ae}$ across all labels, i.e.,
%%
% \begin{equation}
%  \operatorname{AE}(\mathbf{p},\hat{\mathbf{p}}) =\frac{1}{n}\sum_{y=1}^{n}\operatorname{ae}((p_{i}, 1-p_{i}),(\hat{p}_{i}, 1-\hat{p}_{i}))
%\end{equation}
%%
%% \begin{equation}
%% \label{eq:ae}
%% \aae(\mathbf{p},\hat{\mathbf{p}}) =\frac{1}{n}\sum_{y\in 
%% \mathcal{Y}}|\hat{p}(y)-p(y)| %\\
%% \label{eq:rae}
%% \rae(p,\hat{p}) &
%% =\frac{1}{n}\sum_{y\in
%% \mathcal{Y}}\displaystyle\frac{|\hat{p}(y)-p(y)|}{p(y)}
%% \end{equation}
%%
% \noindent Another evaluation measure which is extensively used in
% the quantification literature is \emph{relative absolute error}. The
% multi-label extension $\operatorname{RAE}$ would be similarly
% obtained by replacing, in Equation~\ref{eq:ae}, the function
% $\operatorname{ae}$ with $\operatorname{rae}$, which is defined as
%%
% \begin{equation}
%  \label{eq:rae}
%  \operatorname{rae}(\mathbf{p},\hat{\mathbf{p}}) =\frac{1}{2}\left(\frac{|p_{1}-\hat{p}_{1}|}{p_{1}} + \frac{|p_{2}-\hat{p}_{2}|}{p_{2}}\right)
%\end{equation}
%%
%\noindent Since \rabse\ is undefined when $p_{1}=0$ or $p_{2}=0$, the
% probability distributions $\mathbf{p}$ and $\hat{\mathbf{p}}$ are
% smoothed via additive smoothing. In the binary case, additive
% smoothing takes any distribution $\mathbf{p}=(p_{1},p_{2})$ and
% returns
%%
% \begin{equation}
%  \label{eq:smooth}
%  \operatorname{s}(\mathbf{p}) =
%  \left(\frac{\epsilon+p_{1}}{2\epsilon+1},\frac{\epsilon+p_{2}}{2\epsilon+1}\right)
%\end{equation}
%%
%\noindent with $\epsilon$ the smoothing factor, that we set,
% following~\cite{Forman:2008kx}, to $\epsilon=(2|\sigma|)^{-1}$.

In the experiments we describe in Section~\ref{sec:experiments}, the
trends we observe and the conclusions we draw for \abse\ hold for
\rabse\ as well. In Section~\ref{sec:experiments} we will thus report
our results in terms of \abse\ only, deferring the results in terms of
\rabse\ to Appendix \ref{sec:app:rae}.

% There are no known records of evaluation for multi-label
% quantification, since no-one has attempted multi-label
% quantification in the past.

% We would thus adopt and adapt the standard evaluation metrics
% typically used in quantification literature. An easy approach would
% thus consist of adopting any binary such measure to the multi-label
% case.

% Acknowledge the fact that evaluation measures for \MLC\ and
% multi-label regression exist, but they cannot be \textit{trivially}
% adapted. For example, the aCC metric (as for ``adjusted correlation
% coefficient) routinely used in multi-label regression evaluation
% (i.e., measuring the degree of correlation between two arrays of
% real-valued predictions) is unsatisfactory in our case. To see why,
% imagine a method that systematically overestimates (or
% underestimates) the true prevalence vector $\mathbf{p}$, i.e., that
% always returns
% $\hat{\mathbf{p}}_{i} = \max\{\min\{\mathbf{p}_{i} + b, 1\},0\}$,
% with $b$ any fixed positive (or negative) amount. This method will
% score very high, no matter the deviation imposed by $b$, since
% $\mathbf{p}$ and $\hat{\mathbf{p}}$ are almost \textit{perfectly}
% correlated.
%
% \begin{align}
% \label{eq:ae}
% \aae(p,\hat{p}) & =\frac{1}{n}\sum_{y\in 
% \mathcal{Y}}|\hat{p}(y)-p(y)| \\
% \label{eq:rae}
% \rae(p,\hat{p}) & =\frac{1}{n}\sum_{y\in 
% \mathcal{Y}}\displaystyle\frac{|\hat{p}(y)-p(y)|}{p(y)} 
% \end{align}

% \subsection{Setup}

% % Setup
% We structured the experiments in four blocks with the purpose of
% studying the performance of the different approaches to deal with
% multi-label quantification problems. These are:
% \begin{enumerate}
% \item Single-label classifiers with single-label quantifiers. This
%   would be the trivial approach to solve multi-label tasks, where
%   models are unaware of label dependencies. Intuitively, these
%   methods would serve us as baseline models but would have no use in
%   real-life problems.
% \item Multi-label classifiers with single-label quantifiers. In this
%   block, classifiers would be aware of label dependencies, but not
%   the quantifiers. These experiments would allow us to test
%   different multi-label classifiers and see which one is more
%   capable in the context of a naive quantifier.
% \item Single-label classifiers with multi-label
%   quantifiers. Quantifiers would be aware of label dependencies and
%   therefore capable of correcting the bias of underlying
%   single-label classifiers. This would allow us to check the
%   performance boost of multi-label quantifiers without the help of a
%   multi-label classifier.
% \item Multi-label classifiers with multi-label quantifiers. These
%   would include the top performing classifier along with the best
%   multi-label quantifiers. Experiments run in this block are
%   expected to have the best outcomes and therefore establish the
%   baseline methods for future multi-label quantification research.
% \end{enumerate}

% ----------------------------------------------------------------------

\subsection{Datasets}
\label{sec:exp:datasets}

\noindent For our experiments we use 15 popular \MLC\ datasets,
including 3 datasets specific to text classification
(Reuters-21578,\footnote{\url{http://www.daviddlewis.com/resources/testcollections/reuters21578/}}
Ohsumed~\cite{Hersh:1994qm}, and
RCV1-v2\footnote{\url{http://www.ai.mit.edu/projects/jmlr/papers/volume5/lewis04a/lyrl2004_rcv1v2_{R}EADME.htm}}),
plus all the datasets linked from the \textsc{scikit-multilearn}
package~\cite{Szymanski:2017ru} with the exception of the RCV1-v2
subsets (we omit them since we already include the much larger
collection from which they were extracted). We refer to the original
sources for detailed descriptions of these datasets.\footnote{See also
\url{http://mlkd.csd.auth.gr/multilabel.html\#Datasets} and
\url{http://mulan.sourceforge.net/datasets-mlc.html}}

For the three textual datasets, we pre-process the text by applying
lowercasing, stop word removal, and punctuation removal, as
implemented in
\textsc{scikit-learn},\footnote{\url{https://scikit-learn.org/stable/index.html}}
and by masking numbers with a special token. We retain all terms
appearing at least 5 times in the training set, and convert the
resulting set of words into (sparse) tfidf-weighted vectors using
\textsc{scikit-learn}'s default
vectorizer.\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html}}

% \alexcomment{Should we give a brief explanation of each of them?
% they are too many...}

For all datasets, we remove very rare classes (i.e., those with fewer
than 5 training examples) from consideration, since they pose a
problem when it comes to generating validation (i.e., held-out data)
sets. Indeed, since we optimize the hyperparameters for all the
methods we use (as explained below), we need validation sets, and it
is sometimes impossible to have positive examples for these classes in
both the training and validation sets (let us remember that pure
stratification in multi-label datasets is not always achievable, as
argued in~\cite{Sechidis:2011tu, Szymanski:2017yc}).
% While a trivial workaround consisting of treating extremely rare
% classes differently (e.g., by invoking a backup solution based on
% ``classify and count'' on these cases) is possible, this would only
% blur the averaged results. That is, we would anyway be forced to
% activate the same heuristic \emph{for all methods}, since this
% splitting is always required (i.e., none among the methods we
% consider could legitimately take advantage of avoiding the
% splitting).  We thus deem more reasonable to simply remove rare
% classes from the dataset.  \strikeout{, and avoid invoking trivial
% solutions in rare classes}.
Note that all this only concerns the training set,
% (that is, cases in which we could decide in advance whether to
% invoke a backup solution),
and has nothing to do with the test set, which can include (and indeed
includes, for most datasets) extremely rare classes, since removing
classes that are rare in the test set would lead to an unrealistic
experimentation.  Note also that removing classes that are rare in the
training set is ``fair'', i.e., equally affects all methods that we
experimentally compare, since all of them involve hyperparameter
optimization.
% this consideration is transversal (thus fair) to all methods.
Finally, note that, whenever a method requires generating
\emph{additional} (and maybe nested) validation sets, it is inevitably
exposed to the problems mentioned above, and can thus be at a
disadvantage with respect to other methods that do not require
additional validation data.
%
Table~\ref{tab:datasets} shows a complete description of the datasets
we use (after deleting rare classes), along with some useful
statistics proposed in~\cite{Read:2010rk, Zhang:2014zn}, while Figure~\ref{fig:prevhist} shows the distribution of prevalence values for each dataset. Note that, in most datasets, this distribution obeys a power law.

% \begin{table}[t]
%   \centering
%   \caption{Description of the datasets. Columns \#Classes, \#Train,
%   and \#Test indicate the number of classes, training datapoints, and
%   test datapoints, respectively. Label cardinality (Card) reports the
%   mean number of labels per datapoint. Label density (Dens) is the
%   result of dividing the label cardinality by the total number of
%   labels. Label diversity (Div) is the number of unique labelsets that
%   are present in the dataset. Normalised label diversity (NormDiv)
%   reports the ratio between label diversity and the total number of
%   labels. The proportion of unique label combinations (PUniq) is the
%   total number of labelsets that are unique in the dataset, divided by
%   the number of examples. PMax reports the ratio of datapoints with
%   the most frequent labelset divided by the total number of
%   datapoints.}
%   \label{tab:datasets}
%   \resizebox{\textwidth}{!}{%
%   \begin{tabular}{lrrrrrrrrrr}
%     \toprule
%     Dataset &  \#Classes &  \#Train &  \#Test &  \#Features &   Card &  Dens &   Div &  NormDiv &  PUniq &  PMax \\
%     \midrule
%     \texttt{Scene} &         6 &    1211 &   1196 &        294 &  1.074 & 0.179 &    15 &    2.500 &  0.002 & 0.334 \\
%     \texttt{Emotions} &         6 &     391 &    202 &         72 &  1.868 & 0.311 &    27 &    4.500 &  0.010 & 0.207 \\
%     \texttt{Yeast} &        14 &    1500 &    917 &        103 &  4.237 & 0.303 &   198 &   14.143 &  0.051 & 0.158 \\
%     \texttt{Birds} &        17 &     322 &    323 &        260 &  0.991 & 0.058 &   124 &    7.294 &  0.205 & 0.932 \\
%     \texttt{Genbase} &        18 &     463 &    199 &       1186 &  1.219 & 0.068 &    23 &    1.278 &  0.006 & 0.369 \\
%     \texttt{Medical} &        18 &     333 &    645 &       1449 &  1.135 & 0.063 &    50 &    2.778 &  0.033 & 0.495 \\
%     \texttt{Tmc2007\_{5}00} &        22 &   21519 &   7077 &        500 &  2.220 & 0.101 &  1172 &   53.273 &  0.019 & 0.115 \\
%     \texttt{Ohsumed} &        23 &   24061 &  10328 &      18238 &  1.657 & 0.072 &  1901 &   82.652 &  0.041 & 0.120 \\
%     \texttt{Enron} &        45 &    1123 &    579 &       1001 &  3.357 & 0.075 &   734 &   16.311 &  0.491 & 0.147 \\
%     \texttt{Reuters21578} &        72 &    9603 &   3299 &       8250 &  1.029 & 0.014 &   447 &    6.208 &  0.028 & 0.409 \\
%     \texttt{RCV1-v2} &        98 &   23149 & 781265 &      24816 &  3.199 & 0.033 & 14820 &  151.224 &  0.345 & 2.323 \\
%     \texttt{Mediamill} &       100 &   30993 &  12914 &        120 &  4.374 & 0.044 &  6548 &   65.480 &  0.132 & 0.076 \\
%     \texttt{Bibtex} &       159 &    4880 &   2515 &       1836 &  2.402 & 0.015 &  2856 &   17.962 &  0.451 & 0.097 \\
%     \texttt{Corel5k} &       292 &    4500 &    500 &        499 &  3.480 & 0.012 &  3113 &   10.661 &  0.543 & 0.012 \\
%     \texttt{Delicious} &       983 &   12920 &   3185 &        500 & 19.020 & 0.019 & 15806 &   16.079 &  1.211 & 0.001 \\
%     \bottomrule
%   \end{tabular}
%   }
% \end{table}
% %
% \begin{figure}[b]
%   \centering
%   \includegraphics[width=\textwidth]{figures/thumb_datasets.pdf}
%   \caption{Prevalence histograms sorted from highly to lowly
%   populated. %\fabsebcomment{Questa figura non è mai richiamata dal testo.} 
%   }
%   \label{fig:prevhist}
% \end{figure}

\begin{figure}
%\begin{table}[t]
  \centering
  \captionof{table}{Description of the datasets. Columns \#Classes, \#Train,
  and \#Test indicate the number of classes, training datapoints, and
  test datapoints, respectively. Label cardinality (Card) reports the
  mean number of labels per datapoint. Label density (Dens) is the
  result of dividing the label cardinality by the total number of
  labels. Label diversity (Div) is the number of unique labelsets that
  are present in the dataset. Normalised label diversity (NormDiv)
  reports the ratio between label diversity and the total number of
  labels. The proportion of unique label combinations (PUniq) is the
  total number of labelsets that are unique in the dataset, divided by
  the number of examples. PMax reports the ratio of datapoints with
  the most frequent labelset divided by the total number of
  datapoints.}
  \label{tab:datasets}
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{lrrrrrrrrrr}
    \toprule
    Dataset &  \#Classes &  \#Train &  \#Test &  \#Features &   Card &  Dens &   Div &  NormDiv &  PUniq &  PMax \\
    \midrule
    \texttt{Emotions} &         6 &     391 &    202 &         72 &  1.868 & 0.311 &    27 &    4.500 &  0.010 & 0.207 \\
    \texttt{Scene} &         6 &    1211 &   1196 &        294 &  1.074 & 0.179 &    15 &    2.500 &  0.002 & 0.334 \\
    \texttt{Yeast} &        14 &    1500 &    917 &        103 &  4.237 & 0.303 &   198 &   14.143 &  0.051 & 0.158 \\
    \texttt{Birds} &        17 &     322 &    323 &        260 &  0.991 & 0.058 &   124 &    7.294 &  0.205 & 0.932 \\
    \texttt{Genbase} &        18 &     463 &    199 &       1186 &  1.219 & 0.068 &    23 &    1.278 &  0.006 & 0.369 \\
    \texttt{Medical} &        18 &     333 &    645 &       1449 &  1.135 & 0.063 &    50 &    2.778 &  0.033 & 0.495 \\
    \texttt{Tmc2007\_{5}00} &        22 &   21519 &   7077 &        500 &  2.220 & 0.101 &  1172 &   53.273 &  0.019 & 0.115 \\
    \texttt{Ohsumed} &        23 &   24061 &  10328 &      18238 &  1.657 & 0.072 &  1901 &   82.652 &  0.041 & 0.120 \\
    \texttt{Enron} &        45 &    1123 &    579 &       1001 &  3.357 & 0.075 &   734 &   16.311 &  0.491 & 0.147 \\
    \texttt{Reuters21578} &        72 &    9603 &   3299 &       8250 &  1.029 & 0.014 &   447 &    6.208 &  0.028 & 0.409 \\
    \texttt{RCV1-v2} &        98 &   23149 & 781265 &      24816 &  3.199 & 0.033 & 14820 &  151.224 &  0.345 & 2.323 \\
    \texttt{Mediamill} &       100 &   30993 &  12914 &        120 &  4.374 & 0.044 &  6548 &   65.480 &  0.132 & 0.076 \\
    \texttt{Bibtex} &       159 &    4880 &   2515 &       1836 &  2.402 & 0.015 &  2856 &   17.962 &  0.451 & 0.097 \\
    \texttt{Corel5k} &       292 &    4500 &    500 &        499 &  3.480 & 0.012 &  3113 &   10.661 &  0.543 & 0.012 \\
    \texttt{Delicious} &       983 &   12920 &   3185 &        500 & 19.020 & 0.019 & 15806 &   16.079 &  1.211 & 0.001 \\
    \bottomrule
  \end{tabular}  
  }
%\end{table}

\vspace{5ex}

%\begin{figure}[b]
  \centering
  \includegraphics[width=\textwidth]{figures/thumb_datasets.pdf}
  \captionof{figure}{Histograms of class prevalence values, one per dataset, sorted from highly populated datasets to lowly populated ones; values on the $x$ axis indicate intervals $[\alpha_{k},\beta_{k}]$ of class prevalence values, while values on the $y$ axis indicate the fraction of classes in the dataset that have prevalence values in the $[\alpha_{k},\beta_{k}]$ interval.
  }
  \label{fig:prevhist}
%\end{figure}
\vspace{-3ex}
\end{figure}

We set the parameters of the ML-APP for generating test samples (see
Section~\ref{sec:mlapp}) as follows. We fix the sample size to $k=100$
in all cases. We set the grid of prevalence values to
$\mathbf{g}=\{0.00,0.01,\ldots,0.99,1.00\}$ in all cases but for
dataset \verb+Delicious+, since in this latter the number of
combinations thus generated would be intractable, given that this is
dataset with no fewer than 983 classes; for \verb+Delicious+ we use
the coarser-grained grid
$\mathbf{g}=\{0.00,0.05,\ldots,0.95,1.00\}$. We set $m$ (the number of
samples to be drawn for each prevalence value) independently for each
dataset, to the smallest number that yields more than 10,000 test
samples ($m$ ranges from 1 in \verb+Delicious+ to 40 in \verb+Birds+).

We break down the results into three groups, each corresponding to a
different amount of shift. The rationale behind this choice is to
allow for a more meaningful analysis of the quantifiers' performance,
since the APP (and, by extension, the ML-APP) has often been the
subject of criticism for generating samples exhibiting degrees of
shift that are judged unrealistic and unlikely to occur in real
cases~\cite{Esuli:2015gh,Hassan:2021af}.
% \alexcomment{cite the Brazilians' ``pitfalls in quantification''
% paper?}  \fabsebcomment{Fatto, ma in quel papero queste espressioni
% non occorrono ...}
We instead believe that general-purpose quantification methods should
be tested in widely varying situations, from low-shift to high-shift
ones, and we thus prefer to test all such scenarios, but split the
corresponding results into groups characterized by of more or less
homogeneous amounts of shift.

More specifically, for each test sample generated via the ML-APP, we
compute its prior probability shift with respect to the training set
in terms of $\operatorname{AE}$ between the vectors of training and
test class prevalence values. We then bring together all the resulting
shift values and split the range of such values in three equally-sized
intervals (that we dub \emph{low shift}, \emph{mid shift}, and
\emph{high shift}). The accuracy values we report are thus not
averages across the same number of experiments, since the ML-APP often
tends to generate more samples in the low-shift region than samples in
the mid-shift region and (above all) in the high-shift region. The
number of samples, as well as the distribution of shift values,
depends on each dataset. 

Figure~\ref{fig:drift:appvsnpp} shows the
distributions of shift values that the ML-APP generates (blue) along with the distributions of shift values that we would obtain via uniform sampling (red). Note that the ML-APP succeeds in generating larger amounts of shift, and that most of the samples generated via uniform sampling would fall within what we call the ``low shift'' region.

\begin{figure}[h!]
  \centering \includegraphics[trim={0 0 0
  1cm},clip,width=\textwidth]{figures/app_npp_overlayed.pdf}
  \caption{Shifts generated via the proposed
  ML-APP (blue) and via uniform sampling (blue), as computed in terms of $\operatorname{AE}$ between the training set and the test samples.}
  \label{fig:drift:appvsnpp}
\end{figure}

% \begin{table}[tb]
%   \centering
%   \caption{\abse\ for different MLQ methods evaluated with NPP instead
%   of with the ML-APP.}
%   \label{tab:npp}
%   \resizebox{\textwidth}{!}{%
%   \input{tables/simple.npp.ae} }%
% \end{table}

% \alexcomment{Say something regarding the expected maximum shift that
% APP would generate in contrast to the same value for the ML-APP.}
% \alexcomment{No, this is not trivial, and the SL case is by no means
% representative of the ML case (I think AE has a maximum in $2/n$).}

% \begin{figure}
%   \centering
%   \includegraphics[width=\textwidth]{figures/thumb_drift.pdf}
%   \caption{Distribution of the values of prior probability shift
%   (computed in terms of $\operatorname{AE}$) between training set and
%   test sample for test samples generated by the
%   ML-APP. 
%   Dotted lines delimit the three regions of low shift, mid shift, and
%   high shift.}
%   \label{fig:shift}
% \end{figure}

% Artificial sampling was performed from 0 to the maximum possible
% prevalence for each label using 1\% steps, except for
% \textit{delicious} and \textit{jrcall} datasets (where the number of
% labels is significantly higher, therefore the experiments were
% prohibitive) that were explored in 5\% steps. The number of samples
% per prevalence step was set up accordingly for each dataset so each
% one of them have, at least, 10000 experiments. When artificial
% sampling was carried out just in order to perform model selection,
% the number of samples per prevalence step was fixed to 5 for small
% datasets and 1 for the biggest ones.

% Validation sets were required for model selection and during the
% training phase of some quantifiers. These were computed using the
% iterative stratification method implemented in
% \textit{skmultilearn}\footnote{\url{http://scikit.ml/stratification.html}}. Stratification
% of multi-label datasets is not
% trivial~\cite{Szymanski:2017yc,Sechidis:2011tu}. Label distribution
% is constrained to the actual examples that are present in the
% samples, therefore it is not possible to evenly distribute them in
% all cases.






% ----------------------------------------------------------------------

\subsection{Testing Instances of the Four Types of Multi-Label
Quantification Methods}
\label{sec:exp:main}

\noindent The goal of this section is to provide an answer to the
question: ``Which among the four groups of multi-label quantification
methods tends to perform best?''

To this aim, we choose one representative instance from each group,
and carry out the experiments using all the datasets. We perform this
choice by combining the following components:
%
\begin{itemize}

\item As the \textbf{binary classification method}, we choose logistic
  regression (LR), and use the implementation of it available from
  \textsc{scikit-learn}.\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html}}
  We consider LR a good choice, given that it is a probabilistic
  classifier that already provides fairly well calibrated posterior
  probabilities (which is of fundamental importance in PCC, PACC, and
  SLD), and given that, as indicated by previously reported
  results~\cite{Moreo:2021bs}, it tends to perform well. A set of LR
  classifiers are used when testing the binary relevance (BR) method
  described in Section~\ref{sec:relwork:algadapt}.
 
\item As the \textbf{multi-label classification method}, we adopt
  \emph{stacked generalization}~\cite{Wolpert:1992rq} (SG -- see
  Section~\ref{sec:relwork:ensembles}). We use our own implementation
  (since the implementation of stacked generalization available from
  \textsc{scikit-learn} only caters for the single-label
  case)\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html}},
  that relies on 5-fold cross-validation to generate the intermediate
  representations (in the form of posterior probabilities) given as
  input to the meta-learner, concatenated with the original input
  features. The base members of the ensemble consist of binary
  logistic regression classifiers as implemented in
  \textsc{scikit-learn}.
  % available in
  % \textsc{scikit-learn}.\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html}}
  % that uses logistic regression as the base member.
 
\item As the \textbf{binary aggregation method} Q, we experiment with
  all the methods covered in Section~\ref{sec:quant:sl}, i.e., CC,
  PCC, ACC, PACC, SLD. For all these methods we use the
  implementations made available in the \textsc{QuaPy} open-source
  library~\cite{Moreo:2021bs}.\footnote{\url{https://github.com/HLT-ISTI/QuaPy}}
 
\item As the \textbf{multi-label aggregation method}, we use the
  regressor-based strategy for quantification (that we dub RQ)
  described in Section~\ref{sec:quant:ml:reg}. We implement this
  method as part of the \textsc{QuaPy} framework. For training the base quantifier $q$ we experiment again 
  with all the methods covered in Section~\ref{sec:quant:sl}, 
  i.e., CC, PCC, ACC, PACC, SLD, while as the internal 
  regressor which receives its input from the base quantifier $q$ we use linear
  support vector regression (SVR), for which
  we use the \textsc{scikit-learn}
  implementation.\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html}}
  As the held-out validation set $L_{R}$ needed for training the
  regressor we use a set consisting of 40\% of the training
  datapoints, %\footnote{Note that, during training, $L_{R}$ corresponds to 40\% of $L$. Instead, during model selection, $L_{R}$ corresponds to 40\% of $L_{\operatorname{tr}}$, which means $L_{R}$ is actually 24\% of $L$, since $L_{\operatorname{tr}}$ already corresponds to 60\% of the original $L$.}
  chosen via iterative stratification~\cite{Szymanski:2017yc,
  Sechidis:2011tu} as implemented in
  \textsc{scikit-multilearn}.\footnote{\url{http://scikit.ml/stratification.html}}
  We call this aggregation method SVR-RQ. 
  
\end{itemize}

\noindent The methods we use in this experiment thus amount to the
combinations illustrated in
Table~\ref{tab:representative}. %for the class \bqbc\ we use Q+LR, for the
\begin{table}[h!]
  \centering
  \caption{Methods we use as instances of the four types of methods
  illustrated in Figure~\ref{fig:schema}.}
  \label{tab:representative}
  \begin{tabular}{ccc}
    \toprule
    \textbf{Type} & \textbf{Classification} & \textbf{Aggregation} \\ \midrule
    \bqbc & LR & Q$\in$\{CC,PCC,ACC,PACC,SLD\} \\
    \bqmc & SG & Q$\in$\{CC,PCC,ACC,PACC,SLD\} \\
    \mqbc & LR & Q$\in$\{CC,PCC,ACC,PACC,SLD\} + \textsc{SVR-RQ} \\
    \mqmc & SG & Q$\in$\{CC,PCC,ACC,PACC,SLD\} + \textsc{SVR-RQ} \\\bottomrule
  \end{tabular}
\end{table}

Following~\cite{Moreo:2021sp}, we perform model selection by using, as
the loss function to minimize, a quantification-oriented error measure
(and not a classification-oriented one), and by adopting the same
protocol used for the evaluation of our quantifiers. That is, model
selection is carried out by first splitting the training set $L$ into
two disjoint sets, i.e., (a) a proper training set
$L_{\operatorname{tr}}$ and (b) a held-out validation set
$L_{\operatorname{va}}$ consisting of 40\% of the labelled
datapoints. For splitting the training set, we again rely on the
iterative stratification routine of \textsc{scikit-multilearn} (see
Footnote~\protect\ref{foot:iterativestrat}). We use
$L_{\operatorname{tr}}$ to train the quantifiers with different
combinations of hyperparameters, while from $L_{\operatorname{va}}$ we
extract, via the ML-APP, validation samples on which we assess, via
$\operatorname{AE}$ (the same measure we use in the evaluation phase),
the quality of the hyperparameter combinations.  We explore the
hyperparameters via grid-search optimization, and use the best
configuration to retrain the quantifier on the entire training set $L$
after model selection. During the model selection phase, for the
ML-APP we use the same parameters $k$ and $\mathbf{g}$ that we use in
the test phase, but we reduce the number of repetitions $m$ to 5 in
the datasets with fewer than 90 classes, and to 1 in the other
datasets, in order to keep the computational burden under reasonable
bounds. %\manucomment{Not exactly. $m=1$ for datasets over 98;
% $m=5$ for datasets under 98 categories. see
% \verb|main\_pruebas.py:529|}

The hyperparameters we explore for LR include $C$, the inverse of the
regularization strength, in the range
$\{10^{-1},10^{0},10^{1},10^{2},10^{3}\}$, and \emph{ClassWeight},
which takes values in Balanced (which reweights the importance
of the examples so as to equate the overall contribution of each
class) or None (which gives the same weight to all datapoints,
irrespectively of the prevalence of the class they belong to). In
cases in which the class-specific classifiers are independent of each
other (i.e., for methods belonging to the \bqbc\ and \mqbc\ types) we
optimize the hyperparameters independently for each class. For SG, we
only optimize the hyperparameters of the meta-classifier, leaving the
hyperparameters of the base members to their default values. In
particular, we explore the parameters $C$ and \emph{ClassWeight}
as before, plus the hyperparameter \emph{Normalize}, which takes
values in \emph{True} (which has the effect of standardizing the
inputs of the meta-classifier so that every dimension has zero mean
and unit variance) and \emph{False} (which does not standardize the
inputs). For RQ we only explore the regularization hyperparameter $C$
in the range $\{10^{-1},10^{0},10^{1},10^{2},10^{3}\}$.
% \fabsebcomment{What is \textsc{Reg-Q}? This name never occurs
% elsewhere.  Is this what we have called RQ in the previous page?}
Note that the base quantifiers (i.e., CC, PCC, ACC, PACC, SLD) have no
specific internal hyperparameters to be tuned.

The results we have obtained for the different choices of the base
quantifier are reported in Table~\ref{tab:cc_general} for CC,
Table~\ref{tab:pcc_general} for PCC, Table~\ref{tab:acc_general} for
ACC, Table~\ref{tab:pacc_general} for PACC, and
Table~\ref{tab:sld_general} for SLD. The results clearly show (see
especially the last two rows of each table) that there is an ordering
\bqbc\ $\prec$ \bqmc\ $\prec$ \mqbc\ $\prec$ \mqmc, in which $\prec$
means ``performs worse than'', which holds, independently of the base
quantifier of choice, in almost all cases. The same experiments also
indicate that \emph{there is a substantial improvement in performance that
derives from simply replacing the binary classifiers with one
multi-label classifier} (moving from \bqbc\ to \bqmc\ or from \mqbc\ to
\mqmc), i.e., from bringing to bear the class-class correlations at
the classification
stage, %\manucomment{maybe a dot or a semi-colon instead of a subordinate clause?}
and that \emph{there is an equally substantial improvement}
% These results also show that the improvement is even more pronounced
\emph{when binary aggregation is replaced by multi-label aggregation}
(switching from \bqbc\ to \mqbc\ or from \bqmc\ to \mqmc), i.e., when
the class-class correlations are exploited at the aggregation
stage. What also emerges from these results is that, consistently with
the above observations, \emph{the best-performing group of methods is \mqmc},
i.e., methods that explicitly take class dependencies into account
\emph{both} at the classification stage and at the aggregation stage.

% There are three datasets where binary classification and
% quantification sometimes prevail above the multi-label approaches,
% \textit{Genbase}, \textit{Birds} and \textit{Medical}. These are the
% smallest datasets, along with \textit{Emotions}. However, the
% results for the latter are better when using multi-label
% approaches. We claim that the difference in performance may be
% because of two reasons: (1) low ratio between number of labels and
% datapoints; (2) low label cardinalities and densities, which suggest
% that label dependencies are low. \textit{Emotions} has less labels
% for approximately the same number of datapoints, and its cardinality
% and density are the highest among them. Therefore, it seems like it
% is better to apply binary approaches when the multi-label nature of
% a dataset is almost incidental.

% These results also show, somehow unexpectedly, that the
% best-performing method for training base quantifiers is PCC.  From
% the quantification literature we know that this tends to happen in
% situations characterized by low prior probability shift (see,
% e.g.,~\cite{Gao:2016uq}) while other variants, and particularly PACC
% and SLD, tend to excel in situations exhibiting larger amounts of
% shift (see~\cite{Moreo:2022bf}, in which the methods tested
% in~\cite{Gao:2016uq} were reassessed using the APP). This is indeed
% an indication that the amount of shift the ML-APP generates (even in
% the ``high shift'' regime) is somewhat limited. A likely reason for
% this is the fact that, in most datasets, there are only few classes
% exhibiting high correlation with other classes. For reasons
% discussed in Section~\ref{sec:mlapp}, all classes which are weakly
% correlated with the one being actively sampled in the ML-APP tend to
% display prevalence values close to the natural prevalence in the
% test set, which in turn is often close to the natural prevalence in
% the training set. In other words, through the rounds in which the
% ML-APP artificially sets the prevalence value for one class, only
% other few (highly correlated) classes are being affected, while most
% of the (weakly correlated) classes display similar prevalence
% values. Notwithstanding this, \fabsebcomment{Isn't it a bit
% masochistic to say all this?  Some reviewer might use this as a lead
% to claim that the ML-APP is wrong.  Maybe we should say that we will
% subject the ML-APP to a thorough scrutiny in
% Section~\ref{sec:app_vs_npp}.}
Note that methods that learn from the stochastic correlations among
the classes perform much better than methods that do not, even in the
low shift regime. Overall, the best-performing method on average is
\mqmc\ when equipped with PCC as the base quantifier.

The reader might wonder why we do not use as a baseline the system
presented in the only paper in the literature that tackles multi-label
quantification, i.e.,~\cite{Levin:2017dq}. There are several reasons
for this: (a) the authors do not make the code available; (b) the
method is, as already discussed in Section~\ref{sec:multi-label},
computationally expensive, and as a result the authors test it on a
single dataset whose codeframe consists of 16 classes only; using this
method on our 15 datasets, whose codeframes count up to 983 classes,
and 125 classes on average, would be prohibitive; (c) the method is
essentially a calibration strategy for binary classification, which
means that it falls in the group of ``naive'' \bqbc\ methods since it
does not tackle at all, as already mentioned in
Section~\ref{sec:multi-label}, the multi-label nature of the MLQ
problem.

% \alexcomment{Say why we do not use the previous work of multi-label
% as a baseline? i) implementation not available, ii) computationally
% expensive, and tested with few classes only (only 16 -- that would
% be prohibitive in our case), iii) the method is mainly a calibration
% strategy for binary classification, tested with multi-label
% datasets; this means that, should this calibration be better than
% the one we are using, this would only result in an improvement for
% methods of \bqbc\ but also from \mqbc.} \alexcomment{I think it
% might be safer to simply try with PCC-PAV, which mainly consists of
% calibrating the classifier with isotonic calibration. We can say we
% do not try the EPAV variant (forcing the expected value to match the
% training prevalence) since this is counterproductive in this case?
% Not sure ...}

\begin{table}[tb]
  \centering
  \caption{Values of \abse\ obtained in our experiments for different
  amounts of shift using CC as the base quantifier. The number of test
  samples generated for each dataset exceeds 10,000, though there is a
  variable number of samples allocated in each region of
  shift. \textbf{Boldface} indicates the best method for a given
  dataset and shift region. Superscripts $\dag$ and $\ddag$ denote the
  methods (if any) whose scores are not statistically significantly
  different from the best one according to a Wilcoxon signed-rank test
  at different confidence levels: symbol $\dag$ indicates 0.001 $<$
  $p$-value $<$ 0.05 while symbol $\ddag$ indicates 0.05 $\le$
  $p$-value. For ease of readability, for each pair \{dataset, shift\}
  we colour-code cells via intense green for the best result, intense
  red for the worst result, and an interpolated tone for the scores
  in-between.}
  \label{tab:cc_general}
  \input{tables/cc_nocol.app.ae.tex}
\end{table}

\begin{table}[tb]
  \centering
  \caption{Values of \abse\ obtained in our experiments for different
  amounts of shift using PCC as the base quantifier. Notational
  conventions are as in Table~\ref{tab:cc_general}.}
  \label{tab:pcc_general}
  \input{tables/pcc_nocol.app.ae.tex}
\end{table}

\begin{table}[tb]
  \centering
  \caption{Values of \abse\ obtained in our experiments for different
  amounts of shift using ACC as the base quantifier. Notational
  conventions are as in Table~\ref{tab:cc_general}.}
  \label{tab:acc_general}
  \input{tables/acc_nocol.app.ae.tex}
\end{table}

\begin{table}[tb]
  \centering
  \caption{Values of \abse\ obtained in our experiments for different
  amounts of shift using PACC as the base quantifier. Notational
  conventions are as in Table~\ref{tab:cc_general}.}
  \label{tab:pacc_general}
  \input{tables/pacc_nocol.app.ae.tex}
\end{table}

\begin{table}[tb]
  \centering
  \caption{Values of \abse\ obtained in our experiments for different
  amounts of shift using SLD as the base quantifier. Notational
  conventions are as in Table~\ref{tab:cc_general}.}
  \label{tab:sld_general}
  \input{tables/sld_nocol.app.ae.tex}
\end{table}

In the following sections, we turn to explore other instances of
methods of the four groups in Figure~\ref{fig:schema} beyond the ones
we choose in Table~\ref{tab:representative}.

%\alexcomment{Explain why different base quantifiers. Say something
%specific for each one?}

%\alexcomment{The code to reproduce all our experiments is available as
%a \textsc{QuaPy}
%extension.\footnote{\url{https://github.com/manuel-francisco/quapy-ml/}}}

% ----------------------------------------------------------------------

\subsection{Testing Additional Instances of \bqmc}
\label{sec:exp:mlc}

\noindent In this section we explore other methods relying on
different multi-label classifiers, with the aim of studying the extent
to which the results we have obtained in the previous experiments
depend on the choice of the classifier being employed. To this aim, we
focus on the \bqmc\ group of methods, so that the aggregation stage
plays only a minimal role. As a quantification method we adopt PCC,
since this is the base quantifier that has yielded the best
performance overall in the experiments of
Section~\ref{sec:exp:main}. The methods we study here thus
consist of genuinely multi-label classifiers that generate
posterior probabilities, where the latter are then aggregated by computing the
expected value for each class.
%
The aim of this experiment is not to provide an exhaustive evaluation
of existing multi-label classifiers, but rather to study other \bqmc\
configurations in action, and hopefully pinpoint interesting
performance trends. 

With this in mind, we choose some representative
instances from the main families of multi-label classifiers discussed
in Section~\ref{sec:relwork}.
%
% \manucomment{Since tables are large, there may be orphaned text like
% this paragraph. Consider using $[p]$ as modifier for these
% floats. It would also group tables together which is probably the
% best for the reader, so they can easily compare results.}
% \alexcomment{Would you like to try?}
The multi-label classifiers we consider here include (a) multi-label
versions of KNN
(\textsc{ML-knn}),\footnote{\url{http://scikit.ml/api/skmultilearn.adapt.mlknn.html}} %AA
decision trees
(\textsc{DT}),\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html}} %AA
and random forests
(\textsc{RF})\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\#sklearn.ensemble.RandomForestClassifier.fit}} %AA
as representatives of the family of ``algorithm adaptation'' methods
(Section~\ref{sec:relwork:algadapt}); (b) classifier chains
(\textsc{CChains})\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.ClassifierChain.html\#sklearn.multioutput.ClassifierChain}}
as representative of the family of ``problem transformation'' methods
(Section~\ref{sec:relwork:probtrans}); %PT
and (c)
\textsc{CLEMS}\footnote{\url{http://scikit.ml/api/skmultilearn.embedding.clems.html}} %Ensemble
and label space clustering (\textsc{LSC})\footnote{This was
implemented by combining different classes from
\textsc{scikit-multilearn}.} %Ensemble
as representatives of the family of ``ensemble'' methods
(Section~\ref{sec:relwork:ensembles}). For the sake of comparison, we
also include stacked generalization (\textsc{SG} -- another ensemble
method and the multi-label classifier we choose for the experiments of
Section~\ref{sec:exp:main}), and \bqbc\ (with PCC as the binary
quantifier and LR as the binary classifier) acting as a lower bound
baseline. Values for SG and \bqbc\ are taken from
Table~\ref{tab:pcc_general}.
% (all these methods have been discussed in Section~\ref{sec:relwork})
% \alexcomment{Change: random forest should be an ensemble?}
We carry out model selection by optimizing the hyperparameters listed
succinctly in Table~\ref{tab:modsel:mlc}. The results we have obtained
are presented in Table~\ref{tab:mlc}.

\begin{table}[ht]
  \centering
  \caption{Hyperparameters we explore during model selection for
  different multi-label classifiers.}
  \label{tab:modsel:mlc}
  \input{tables/hyper_mlc}
\end{table}

\begin{table}[tb]
  \centering
  \caption{Values of \abse\ obtained for different multi-label
  classifiers using PCC as the base quantifier in \bqmc. (All results
  are reported with only three digits after the decimal point, unlike
  in other tables, in order to maximize readability.)}
  \label{tab:mlc}
  \input{tables/mlc_nocol.drift.app.ae.tex}
\end{table}

These results reveal that, despite the fact that \textsc{SG} is the
best-performing method, other multi-label classifiers work comparably
well and could be used to yield multi-label aggregative quantifiers
with similar performance levels. In particular, \textsc{CChains} tends
to fare very well in all cases, followed by \textsc{RF} and
\textsc{DT}; these results are, by and large, consistent with those
reported in~\cite{Madjarov:2012yl}. The methods \textsc{ML-knn},
\textsc{CLEMS}, and \textsc{LSC}, however, prove inferior, sometimes
performing even worse than the \bqbc\ baseline.

Although the results we report in Table~\ref{tab:mlc} are obtained on
the test set, we confirm that they are strongly correlated with the
performance levels we measured on the held-out validation set. Indeed,
we chose SG as our multi-label classifier for the experiments of
Section~\ref{sec:exp:main} since this was the model yielding the
lowest \abse\ during model selection.

% \alexcomment{Maybe report the memory problems with CLEMS and others
% in the specific datasets.}

% \alexcomment{Say we chose SG over other multi-label classifiers
% because it yields the best performance \textit{in validation}. Say
% the same for regression, and for MLQ.}

% \alexcomment{Maybe we could not break down by shift here since,
% anyway, the shifts do not show anything new. This would allow us add
% the Naive column, that would take all ``red'' values, highlighting
% our point better.}

% ----------------------------------------------------------------------

\subsection{Testing Additional Instances of \mqbc}
\label{sec:exp:mlq}

% \alexcomment{If we move this section before ``instances of \bqmc"
% then we should explain why we use PCC here.}

\noindent In this section we compare the different multi-label
aggregation strategies proposed in Section~\ref{sec:quant:ml:reg} and
\ref{sec:quant:ml:lp}. In order to do so, we focus on the \mqbc\ group
of methods (i.e., those relying on binary classifiers for the label
predictions) so that all the label dependencies are modelled
exclusively at the aggregation stage.

For the label powerset -based strategy (LPQ)  we consider two different ways
for generating the clusters, after which \SLQ\ is applied to the
resulting label powersets of each cluster. In particular, we
investigate:
%
\begin{itemize}
\item \textsc{RakEL-LPQ}: inspired by
  \textsc{RakEL}~\cite{Tsoumakas:2011vp}; generates $k$ disjoint
  random clusters;
\item \textsc{kMeans-LPQ}: inspired by LSC~\cite{Szymanski:2016qj};
  generates clusters via $k$-means.
\end{itemize}
%
\noindent For the regression-based  (RQ) strategy we consider two alternative
regressors (other results exploring further regression algorithms can
be found in Appendix \ref{sec:otherregressors}):
%
\begin{itemize}
\item \textsc{Ridge-RQ}: using ridge
  regression;\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html}}
\item \textsc{RF-RQ}: using random-forest
  regression.\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html}}
\end{itemize}
%
\noindent For the sake of comparison, we add the regression-based
strategy \textsc{SVR-RQ} (Section~\ref{sec:quant:ml:reg}), that
corresponds to our configuration of choice for \mqbc\ in
Section~\ref{sec:exp:main}, and the \bqbc\ system (PCC+LR) as a
lower-bound baseline. The results for \textsc{SVR-RQ} and \bqbc\ are
taken from Table~\ref{tab:pcc_general}.  Model selection is carried
out by exploring, via grid-search optimization, the hyperparameters
indicated in Table~\ref{tab:modsel:mlq}. The results we have obtained
are shown in Table~\ref{tab:mlq}.

\begin{table}[h!]
  \centering
  \caption{Hyperparameters explored during model selection for
  different multi-label quantifiers. All methods are deployed with an
  LR classifier; for the hyperparameters $C$ and
  \emph{ClassWeight}, we explore in the ranges
  $\{10^{-1}, \ldots, 10^{2},10^{3}\}$ and \{None, Balanced\},
  respectively.}
  \label{tab:modsel:mlq}
  \input{tables/hyper_mlq}
\end{table}

\begin{table}[tb]
  \centering
  \caption{\abse\ for different multi-label aggregation methods in
  \mqbc.}
  \label{tab:mlq}
  \input{tables/mlq.drift.app.ae.tex}
\end{table}

% \begin{table}[h!]
%   \centering
%   \caption{number of different multi-label quantifiers}
%   \label{tab:mlq}
%   \input{tables/mlq_nocol.drift.app.ae.tex}
% \end{table}

These results show that all the multi-label aggregation methods
perform comparably in the low-shift regime, although the LP-based
methods tend to perform slightly better. In the mid-shift and
high-shift regimes the regression-based strategies tend to fare
better. These results, obtained on the test set, are well correlated
with the results we obtain during model selection on the validation
set; our choice of \textsc{SVR-RQ} as a representative method for
\mqbc\ was indeed based on the performance of the different
multi-label aggregation methods obtained in the validation phase. 

The
most important observation we can draw from this table is that all
these methods tend to outperform not only the \bqbc\ system (as
expected) but also all the variants from the \bqmc\ group explored in
Section~\ref{sec:exp:mlc}, which may be an indication that in \MLQ,
bringing to bear the stochastic correlations among classes at the
aggregation phase is more effective
% fruitful or rewarding
than doing so at the classification phase.

% \begin{table}[h!]
%   \centering
%   \caption{number of different regressors for multi-label
%   quantifiers}
%   \label{tab:mlqreg}
%   \input{tables/mlqreg_nocol.drift.app.ae.tex}
% \end{table}

% \subsection{Results and Discussion}
% In this section, we present and discuss the results of the
% experiments performed. Subsection~\ref{subsec:general_experiments}
% explores the behaviour of the four different approaches to
% multi-label quantification
% tasks. Subsection~\ref{subsec:mlc_experiments} surveys the
% improvements of different multi-label classifiers within the same
% quantifier. Meanwhile, in subsection~\ref{subsec:mlq_experiments},
% we examine the improvements of different regressors for multi-label
% quantifiers. Lastly, subsection~\ref{subsec:mlc_mlq_experiments}
% present results for top performing models, which we suggest to use
% as baselines for multi-label quantification tasks.

% \subsubsection{General Exploration}
% Tables~\ref{tab:cc_general}, \ref{tab:pcc_general},
% \ref{tab:acc_general} and \ref{tab:pacc_general} present absolute
% errors for different combinations of binary and multi-label
% classifiers for CC, PCC, ACC and PACC based quantifiers. Results are
% presented grouped in three bins for low, medium and high prevalence
% shift after applying artificial sampling.

% Naive approaches are, expectedly, the worst performers. Results
% suggest that the use of multi-label classifiers alone with binary
% quantifiers is not enough to capture label dependencies when the
% task is prevalence prediction, since they rank second to
% last. However, multi-label quantifiers yield the minimum absolute
% errors regardless that the classifiers are binary or
% multi-label. Although the full multi-label approaches offer the best
% average result.

% There are three datasets where binary classification and
% quantification sometimes prevail above the multi-label approaches,
% \textit{genbase}, \textit{birds} and \textit{medical}. These are the
% smallest datasets, along with \textit{emotions}. However, the
% results for the latter are better when using multi-label
% approaches. We claim that the difference in performance may be
% because of two reasons: (1) low ratio between number of labels and
% instances; (2) low label cardinalities and densities, which suggest
% that label dependencies are low. \textit{Emotions} has less labels
% for approximately the same number of instances, and its cardinality
% and density are the highest among them. Therefore, it seems like it
% is better to apply binary approaches when the multi-label nature of
% a dataset is almost incidental.

% ----------------------------------------------------------------------

% \subsection{Is the ML-APP a Good Protocol for MLQ?}
% \label{sec:app_vs_npp}

% \noindent In this section we test the ML-APP protocol by comparing the
% shift it generates with the shift the NPP protocol (see
% Section~\ref{sec:mlapp}) would generate by using uniform sampling.
% For this experiment we generate, for each dataset, 1000 test samples
% of 100 datapoints each.
% % \alexcomment{For Delicious, due to an error in the code, we are
% % averaging only across 21 samples. I am redoing these experiments,
% % although I think this is something we can fix even after we have
% % sent the paper for review.}
% Figure~\ref{fig:drift:appvsnpp} displays the results of this
% comparison.

% \begin{figure}[h!]
%   \centering \includegraphics[trim={0 0 0
%   1cm},clip,width=\textwidth]{figures/app_npp_overlayed.pdf}
%   \caption{Shifts generated via the NPP (red) and via the proposed
%   ML-APP (blue).}
%   \label{fig:drift:appvsnpp}
% \end{figure}

% Note that most of the samples generated by the NPP would exhibit a
% shift that falls within what we have called the ``low shift''
% region. Some exceptions to this include the \verb+Birds+ and
% \verb+Genbase+ datasets (and, to a lesser extent, \verb+Emotions+),
% for which the NPP manages to generate some samples of the ``mid
% shift'' region. In many cases, though, the shift generated by the NPP
% is very small, with notable examples including \verb+RCV1-v2+,
% \verb+Reuters-21578+, \verb+Mediamill+, and \verb+Delicious+.

% This poses the legitimate question on whether the trends we have
% observed using the ML-APP so far stand when using the NPP. In
% Figure~\ref{tab:npp} we report the results the different methods score
% when confronted with samples generated via the NPP.

% \begin{table}[tb]
%   \centering
%   \caption{\abse\ for different MLQ methods evaluated with NPP instead
%   of with the ML-APP.}
%   \label{tab:npp}
%   \resizebox{\textwidth}{!}{%
%   \input{tables/simple.npp.ae} }%
% \end{table}

% These results confirm what we had seen in the ``low shift'' blocks of
% Tables~\ref{tab:cc_general}-\ref{tab:sld_general}. In most cases, the
% best-performing group of methods is \mqmc\ or \mqbc. One interesting
% exception is when PCC is the base quantifier, since in this case the
% best-performing group of methods happens to be \bqmc, and this is the
% configuration yielding the lowest \abse\ error overall (in line with
% what reported in Table~\ref{tab:pcc_general}, for the block ``low
% shift''). It seems reasonable to conjecture that, in the presence of
% the very low shift generated by the NPP, the role of the multi-label
% regressor in charge of correcting the prevalence estimates is less
% important, and not attempting to correct for the bias of the
% classifier works in PCC's favour. Aside from this, the improvement of
% \mqbc\ with respect to \bqbc\ is clear, independently of the base
% quantifier.

% \alexcomment{I don't like the idea of presenting as the last
% experiment one in which the best-performing method is not an instance
% of \mqmc. One option could be to present this experiment \emph{before}
% the other experiments, then maybe criticize the NPP for not being able
% to generate interesting shift, and go on.  I am not sure about
% this. Suggestions?}  \alexcomment{I am now leaning towards removing
% these results (they are anyway similar to the low-shift ones) and
% simply show Figure~\ref{fig:drift:appvsnpp} along with the dataset, as
% a proof that the ML-APP generates higher shift than NPP, and then go
% on with the rest of the experiments.}

% ----------------------------------------------------------------------

\subsection{Multi-Label Aggregation for Non-Aggregative Quantifiers}
\label{sec:MLAfornonaggregative}

\noindent Since the methods of type \mqmc\ that we have proposed in this paper have proven 
to be the most effective in all our experiments, we want to add an 
important observation about them.

%We here add a final note about non-aggregative quantification methods.
Concerning our regression-based RQ method described in
Section~\ref{sec:quant:ml:reg}, although we have assumed, for ease of
exposition, that the quantifier $q$ is an aggregative one, this
assumption is not strictly necessary, since the regressor $r$ does not look at
predicted class labels for individual datapoints, but only at the
class prevalence estimates returned by the underlying quantifier $q$. 
A similar observation can be made for our label powerset -based LPQ method 
described in
Section~\ref{sec:quant:ml:lp}; this method leverages a single-label multiclass quantifier $q$ and uses its class prevalence estimates, and does not require any prediction at the level of the individual datapoint, which means that aggregative methods and non-aggregative methods are equally suitable for training $q$. In other words, both RQ and LPQ can use any type of quantification method, aggregative or non-aggregative.

The reasons why in this paper we have focused on aggregative quantifiers are (i) ease of explanation, and (b) the fact that, as a recent large-scale experimental study has confirmed~\cite{Castano:2021le}, non-aggregative quantification methods (such as the HDx method of~\cite{Gonzalez-Castro:2013fk}) are, from the point of view of sheer performance, not yet on a par with aggregative methods. However, the above observations indicate that, should high-performance non-aggregative quantification methods spring up in the future, RQ and LPQ can be used in connection with them straightaway.
%

% ----------------------------------------------------------------------

\section{Conclusions}
\label{sec:conclusions}

\noindent In this paper we have investigated \MLQ, a quantification
task which had remained, since the origins of quantification research,
essentially unexplored. We have proposed the first protocol for the
evaluation of \MLQ\ systems that is able to confront these systems
with samples that exhibit from low to high levels of prior probability
shift. For ease of exposition we have particularly focused on multi-label quantifiers 
that work by aggregating predictions for individual datapoints issued by 
a classifier (``aggregative'' multi-label quantifiers), and have subdivided them in four groups, based on whether the correlations between classes are brought to bear in the classification stage (\bqmc), in the quantification stage (\mqbc), in both stages (\mqmc), or in neither of the two stages (\bqbc).

We have also described and experimentally compared a number of MLQ methods; 
some of them (specifically: those in the \bqbc\ and \bqmc\ groups) are 
trivial combinations of available classification and quantification methods, while others (specifically: those in the \mqbc\ and \mqmc\ groups) are non-obvious, and proposed here for the first time. The thorough experimentation that we have carried out on an extensive number of datasets has clearly shown that there is a substantial improvement in performance that
derives from simply replacing binary classifiers with truly
multi-label classifiers (i.e., from switching from BC to MLC), and that there is an equally substantial improvement when binary aggregation is replaced by truly multi-label aggregation (i.e., when  switching from BA to MLA). Consistently with these two intuitions, \mqmc\ methods unequivocally prove the best of the lot; of the two \mqmc\ methods we have proposed, RQ proves clearly superior to LPQ.  In the light of this superiority of MLA with respect to BA, it is also interesting that both RQ and LPQ can be straightforwardly used in association to non-aggregative quantifiers too.

% For future work, it would also be interesting to study methods dedicated to
% hierarchical codeframes, i.e., multi-label problems in which there
% are taxonomical relations among labels.  \manucomment{offtopic:
% sinceramente, precioso. Me ha encantado seguir el desarrollo de este
% artículo y la evolución del manuscrito. Gracias por dejarme
% participar ;)}

% --------------------------------------------------------------------

\section*{Acknowledgments}
  \noindent The work of A.\ Moreo and F.\ Sebastiani has been
  supported by the \textsf{SoBigData++} project, funded by the
  European Commission (Grant 871042) under the H2020 Programme
  INFRAIA-2019-1, and by the \textsf{AI4Media} project, funded by the
  European Commission (Grant 951911) under the H2020 Programme
  ICT-48-2020; the authors' opinions do not necessarily reflect those
  of the European Commission. The work of M.\ Francisco has been
  supported by the FPI 2017 predoctoral programme, from the Spanish
  Ministry of Economy and Competitiveness (MINECO), grant
  BES-2017-081202.
%\end{acks}

% ----------------------------------------------------------------------



\bibliographystyle{unsrt}
%\bibliography{MultiLabelQuantification}

\begin{thebibliography}{10}

\bibitem{Hopkins:2010fk}
Daniel~J. Hopkins and Gary King.
\newblock A method of automated nonparametric content analysis for social
  science.
\newblock {\em American Journal of Political Science}, 54(1):229--247, 2010.

\bibitem{King:2008fk}
Gary King and Ying Lu.
\newblock Verbal autopsy methods with multiple causes of death.
\newblock {\em Statistical Science}, 23(1):78--91, 2008.

\bibitem{Bunse:2022dz}
Mirko Bunse, Alejandro Moreo, Fabrizio Sebastiani, and Martin Senz.
\newblock Ordinal quantification through regularization.
\newblock In {\em Proceedings of the 33rd European Conference on Machine
  Learning and Principles and Practice of Knowledge Discovery in Databases
  (ECML / PKDD 2022)}, Grenoble, FR, 2022.
\newblock Forthcoming.

\bibitem{Forman:2008kx}
George Forman.
\newblock Quantifying counts and costs via classification.
\newblock {\em Data Mining and Knowledge Discovery}, 17(2):164--206, 2008.

\bibitem{Gonzalez:2017it}
Pablo Gonz{\'{a}}lez, Alberto Casta{\~{n}}o, Nitesh~V. Chawla, and
  Juan~Jos{\'{e}} del Coz.
\newblock A review on quantification learning.
\newblock {\em ACM Computing Surveys}, 50(5):74:1--74:40, 2017.

\bibitem{Moreo:2022bf}
Alejandro Moreo and Fabrizio Sebastiani.
\newblock Tweet sentiment quantification: {A}n experimental re-evaluation.
\newblock {\em PLOS ONE}, 17(9):1--23, September 2022.

\bibitem{Schumacher:2021ty}
Tobias Schumacher, Markus Strohmaier, and Florian Lemmerich.
\newblock A comparative evaluation of quantification methods, 2021.
\newblock arXiv:2103.03223.

\bibitem{Moreno-Torres:2012ay}
Jose~G. Moreno-Torres, Troy Raeder, Rocío Alaíz-Rodríguez, Nitesh~V. Chawla,
  and Francisco Herrera.
\newblock A unifying view on dataset shift in classification.
\newblock {\em Pattern Recognition}, 45(1):521--530, 2012.

\bibitem{Storkey:2009lp}
Amos Storkey.
\newblock When training and test sets are different: {C}haracterizing learning
  transfer.
\newblock In Joaquin Quiñonero-Candela, Masashi Sugiyama, Anton Schwaighofer,
  and Neil~D. Lawrence, editors, {\em Dataset shift in machine learning}, pages
  3--28. The {MIT} Press, Cambridge, {US}, 2009.

\bibitem{Card:2018pb}
Dallas Card and Noah~A. Smith.
\newblock The importance of calibration for estimating proportions from
  annotations.
\newblock In {\em Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics (HLT-NAACL 2018)},
  pages 1636--1646, New Orleans, US, 2018.

\bibitem{Bella:2010kx}
Antonio Bella, Cèsar Ferri, José Hernández-Orallo, and María~José
  Ramírez-Quintana.
\newblock Quantification via probability estimators.
\newblock In {\em Proceedings of the 11th IEEE International Conference on Data
  Mining (ICDM 2010)}, pages 737--742, Sydney, {AU}, 2010.

\bibitem{Esuli:2015gh}
Andrea Esuli and Fabrizio Sebastiani.
\newblock Optimizing text quantifiers for multivariate loss functions.
\newblock {\em ACM Transactions on Knowledge Discovery and Data}, 9(4):Article
  27, 2015.

\bibitem{Hassan:2020kq}
Waqar Hassan, Andr{\'{e}}~Gustavo Maletzke, and Gustavo~E. Batista.
\newblock Accurately quantifying a billion instances per second.
\newblock In {\em Proceedings of the 7th {IEEE} International Conference on
  Data Science and Advanced Analytics (DSAA 2020)}, pages 1--10, Sydney, AU,
  2020.

\bibitem{Bunse:2022qq}
Mirko Bunse.
\newblock {\em Machine learning for acquiring knowledge in astro-particle
  physics}.
\newblock PhD thesis, University of Dortmund, Dortmund, {DE}, 2022.

\bibitem{Firat:2016uq}
Aykut Firat.
\newblock Unified framework for quantification.
\newblock arXiv:1606.00868v1 [cs.LG] 2 Jun 2016, 2016.

\bibitem{Gao:2016uq}
Wei Gao and Fabrizio Sebastiani.
\newblock From classification to quantification in tweet sentiment analysis.
\newblock {\em Social Network Analysis and Mining}, 6(19):1--22, 2016.

\bibitem{DaSanMartino:2016jk}
Giovanni {Da San Martino}, Wei Gao, and Fabrizio Sebastiani.
\newblock Ordinal text quantification.
\newblock In {\em Proceedings of the 39th ACM Conference on Research and
  Development in Information Retrieval (SIGIR 2016)}, pages 937--940, Pisa,
  {IT}, 2016.

\bibitem{Castano:2022nz}
Alberto Castaño, Pablo González, Jaime~Alonso González, and Juan~José del
  Coz.
\newblock Matching distributions algorithms based on the {E}arth mover's
  distance for ordinal quantification.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems},
  2022.
\newblock Forthcoming.

\bibitem{Janjua:2022yi}
Zaffar~Haider Janjua, David Kerins, Brendan O’Flynn, and Salvatore Tedesco.
\newblock Knowledge-driven feature engineering to detect multiple symptoms
  using ambulatory blood pressure monitoring data.
\newblock {\em Computer Methods and Programs in Biomedicine}, 217:106638, 2022.

\bibitem{Csanyi:2022my}
Gergely~Márk Csányi, Renátó Vági, Dániel Nagy, István Üveges,
  János~Pál Vadász, Andrea Megyeri, and Tamás Orosz.
\newblock Building a production-ready multi-label classifier for legal
  documents with digital-twin-distiller.
\newblock {\em Applied Sciences}, 12(3):1470, 2022.

\bibitem{Taqvi:2022oh}
S.A.A. Taqvi, H.~Zabiri, F.~Uddin, M.~Naqvi, L.D. Tufa, M.~Kazmi, S.~Rubab,
  S.R. Naqvi, and A.S. Maulud.
\newblock Simultaneous fault diagnosis based on multiple kernel support vector
  machine in nonlinear dynamic distillation column.
\newblock {\em Energy Science and Engineering}, 10(3):814--839, 2022.

\bibitem{Mukherjee:2022xw}
D.~Mukherjee, S.~Chakraborty, and S.~Ghosh.
\newblock Deep learning-based multilabel classification for locational
  detection of false data injection attack in smart grids.
\newblock {\em Electrical Engineering}, 104(1):259--282, 2022.

\bibitem{Elisseeff:2001iz}
Andr{\'{e}} Elisseeff and Jason Weston.
\newblock A kernel method for multi-labelled classification.
\newblock In {\em Proceedings of the 15th Annual Conference on Neural
  Information Processing Systems (NIPS 2001)}, pages 681--687, Vancouver, CA,
  2001.

\bibitem{Zhang:2007as}
Min-Ling Zhang and Zhi-Hua Zhou.
\newblock {Ml-KNN: A} lazy learning approach to multi-label learning.
\newblock {\em Pattern Recognition}, 40(7):2038--2048, 2007.

\bibitem{Montanes:2014fu}
Elena Monta{\~{n}}{\'{e}}s, Robin Senge, Jos{\'{e}} Barranquero,
  Jos{\'{e}}~Ram{\'{o}}n Quevedo, Juan~Jos{\'{e}} del Coz, and Eyke
  H{\"{u}}llermeier.
\newblock Dependent binary relevance models for multi-label classification.
\newblock {\em Pattern Recognition}, 47(3):1494--1508, 2014.

\bibitem{McCallum:1999zv}
Andrew~K. McCallum.
\newblock Multi-label text classification with a mixture model trained by {EM}.
\newblock In {\em Proceedings of the AAAI 1999 Workshop on Text Learning},
  Orlando, US, 1999.

\bibitem{Gao:2004op}
Sheng Gao, Wen Wu, Chin{-}Hui Lee, and Tat{-}Seng Chua.
\newblock A {MFoM} learning approach to robust multiclass multi-label text
  categorization.
\newblock In {\em Proceedings of the 21st International Conference on Machine
  Learning (ICML 2004)}, Banff, CA, 2004.

\bibitem{Read:2011zc}
Jesse Read, Bernhard Pfahringer, Geoff Holmes, and Eibe Frank.
\newblock Classifier chains for multi-label classification.
\newblock {\em Machine Learning}, 85(3):333--359, 2011.

\bibitem{Zhang:2021ma}
Qian{-}Wen Zhang, Ximing Zhang, Zhao Yan, Ruifang Liu, Yunbo Cao, and
  Min{-}Ling Zhang.
\newblock Correlation-guided representation for multi-label text
  classification.
\newblock In {\em Proceedings of the 30th International Joint Conference on
  Artificial Intelligence (IJCAI 2021)}, pages 3363--3369, Montreal, CA, 2021.

\bibitem{Tsoumakas:2007nl}
Grigorios Tsoumakas and Ioannis Katakis.
\newblock Multi-label classification: {A}n overview.
\newblock {\em International Journal of Data Warehousing and Mining},
  3(3):1--13, 2007.

\bibitem{Herrera:2016xt}
Francisco Herrera, Francisco Charte, Antonio~J. Rivera, and María~J.
  Del~Jesus.
\newblock {\em Multilabel classification: Problem analysis, metrics and
  techniques}.
\newblock Springer, Cham, CH, 2016.

\bibitem{Levin:2017dq}
Roy Levin and Haggai Roitman.
\newblock Enhanced probabilistic classify and count methods for multi-label
  text quantification.
\newblock In {\em Proceedings of the 7th ACM International Conference on the
  Theory of Information Retrieval (ICTIR 2017)}, pages 229--232, Amsterdam,
  {NL}, 2017.

\bibitem{Forman:2005fk}
George Forman.
\newblock Counting positives accurately despite inaccurate classification.
\newblock In {\em Proceedings of the 16th European Conference on Machine
  Learning (ECML 2005)}, pages 564--575, Porto, {PT}, 2005.

\bibitem{Sebastiani:2020qf}
Fabrizio Sebastiani.
\newblock Evaluation measures for quantification: {A}n axiomatic approach.
\newblock {\em Information Retrieval Journal}, 23(3):255--288, 2020.

\bibitem{Sakai:2021lp}
Tetsuya Sakai.
\newblock A closer look at evaluation measures for ordinal quantification.
\newblock In {\em Proceedings of the CIKM 2021 Workshop on Learning to
  Quantify}, Virtual Event, 2021.

\bibitem{Esuli:2022hy}
Andrea Esuli, Alejandro Moreo, and Fabrizio Sebastiani.
\newblock {LeQua@CLEF2022: Learning to Quantify}.
\newblock In {\em Proceedings of the 44th European Conference on Information
  Retrieval (ECIR 2022)}, pages 374--381, Stavanger, {NO}, 2022.

\bibitem{Esuli:2018rm}
Andrea Esuli, Alejandro Moreo, and Fabrizio Sebastiani.
\newblock A recurrent neural network for sentiment quantification.
\newblock In {\em Proceedings of the 27th ACM International Conference on
  Information and Knowledge Management (CIKM 2018)}, pages 1775--1778, Torino,
  {IT}, 2018.

\bibitem{Maletzke:2019qd}
André Maletzke, Denis Moreira~dos Reis, Everton Cherman, and Gustavo Batista.
\newblock {DyS: A} framework for mixture models in quantification.
\newblock In {\em Proceedings of the 33rd AAAI Conference on Artificial
  Intelligence (AAAI 2019)}, pages 4552--4560, Honolulu, {US}, 2019.

\bibitem{Zadrozny:2002eu}
Bianca Zadrozny and Charles Elkan.
\newblock Transforming classifier scores into accurate multiclass probability
  estimates.
\newblock In {\em Proceedings of the 8th ACM International Conference on
  Knowledge Discovery and Data Mining (KDD 2002)}, pages 694--699, Edmonton,
  {CA}, 2002.

\bibitem{Madjarov:2012yl}
Gjorgji Madjarov, Dragi Kocev, Dejan Gjorgjevikj, and Sašo Džeroski.
\newblock An extensive experimental comparison of methods for multi-label
  learning.
\newblock {\em Pattern Recognition}, 45(9):3084--3104, 2012.

\bibitem{Luaces:2012qi}
Oscar Luaces, Jorge D{\'{\i}}ez, Jos{\'{e}} Barranquero, Juan~Jos{\'{e}} del
  Coz, and Antonio Bahamonde.
\newblock Binary relevance efficacy for multilabel classification.
\newblock {\em Progress in Artificial Intelligence}, 1(4):303--313, 2012.

\bibitem{Spolaor:2013ir}
Newton Spolaôr, Everton~A. Cherman, Maria~C. Monard, and Huei~D. Lee.
\newblock A comparison of multi-label feature selection methods using the
  problem transformation approach.
\newblock {\em Electronic Notes in Theoretical Computer Science}, 292:135--151,
  2013.

\bibitem{Dembczynski:2010ei}
Krzysztof Dembczynski, Weiwei Cheng, and Eyke H{\"{u}}llermeier.
\newblock Bayes optimal multilabel classification via probabilistic classifier
  chains.
\newblock In {\em Proceedings of the 27th International Conference on Machine
  Learning (ICML 2010)}, pages 279--286, Haifa, IL, 2010.

\bibitem{Schapire:2000nl}
Robert~E. Schapire and Yoram Singer.
\newblock {BoosTexter: A} boosting-based system for text categorization.
\newblock {\em Machine Learning}, 39(2/3):135--168, 2000.

\bibitem{Xu:2013gy}
Jianhua Xu.
\newblock Fast multi-label core vector machine.
\newblock {\em Pattern Recognition}, 46(3):885--898, 2013.

\bibitem{Chen:2016bs}
Wei-Jie Chen, Yuan-Hai Shao, Chun-Na Li, and Nai-Yang Deng.
\newblock {MLTSVM}: {A} novel twin support vector machine to multi-label
  learning.
\newblock {\em Pattern Recognition}, 52:61--74, 2016.

\bibitem{Ai:2021yp}
Qing Ai, Yude Kang, and Anna Wang.
\newblock A novel semi-supervised multi-label twin support vector machine.
\newblock {\em Intelligent Automation and Soft Computing}, 27(1):205--220,
  2021.

\bibitem{Kumar:2009tt}
M.~Arun Kumar and Madan Gopal.
\newblock Least squares twin support vector machines for pattern
  classification.
\newblock {\em Expert Systems and Applications}, 36(4):7535--7543, 2009.

\bibitem{Rastogi:2022ty}
Reshma Rastogi and Sambhav Jain.
\newblock Multi-label learning via minimax probability machine.
\newblock {\em International Journal of Approximate Reasoning}, 145:1--17,
  2022.

\bibitem{Vens:2008yr}
Celine Vens, Jan Struyf, Leander Schietgat, Saso Dzeroski, and Hendrik
  Blockeel.
\newblock Decision trees for hierarchical multi-label classification.
\newblock {\em Machine Learning}, 73(2):185--214, 2008.

\bibitem{Benites:2010ix}
Fernando Benites, Florian Brucker, and Elena~P. Sapozhnikova.
\newblock Multi-label classification by {ART}-based neural networks and
  hierarchy extraction.
\newblock In {\em Proceedings of the 2010 International Joint Conference on
  Neural Networks (IJCNN 2010)}, pages 1--9, Barcelona, ES, 2010.

\bibitem{Benites:2015nq}
Fernando Benites and Elena~P. Sapozhnikova.
\newblock {HARAM:} {A} hierarchical {ARAM} neural network for large-scale text
  classification.
\newblock In {\em Proceedings of the ICDM 2015 Workshop on High Dimensional
  Data Mining}, pages 847--854, Atlantic City, US, 2015.

\bibitem{Tsoumakas:2008ek}
Grigorios Tsoumakas, Ioannis Katakis, and Ioannis Vlahavas.
\newblock Effective and efficient multilabel classification in domains with
  large number of labels.
\newblock In {\em Proceedings of the ECML/PKDD 2008 Workshop on Mining
  Multidimensional Data (MMD 2008)}, pages 53--59, Antwerp, BE, 2008.

\bibitem{Tsoumakas:2011vp}
Grigorios Tsoumakas, Ioannis Katakis, and Ioannis Vlahavas.
\newblock Random k-labelsets for multilabel classification.
\newblock {\em IEEE Transactions on Knowledge and Data Engineering},
  23(7):1079--1089, 2011.

\bibitem{Szymanski:2016qj}
Piotr Szymański, Tomasz Kajdanowicz, and Kristian Kersting.
\newblock How is a data-driven approach better than random choice in label
  space division for multi-label classification?
\newblock {\em Entropy}, 18(8):282, 2016.

\bibitem{Huang:2017hw}
Kuan-Hao Huang and Hsuan-Tien Lin.
\newblock Cost-sensitive label embedding for multi-label classification.
\newblock {\em Machine Learning}, 106(9-10):1725--1746, 2017.

\bibitem{Szymanski:2017ru}
Piotr Szymanski and Tomasz Kajdanowicz.
\newblock A scikit-based {Python} environment for performing multi-label
  classification.
\newblock arXiv:1702.01460 [cs.LG], 2017.

\bibitem{Wolpert:1992rq}
David~H. Wolpert.
\newblock Stacked generalization.
\newblock {\em Neural Networks}, 5(2):241--259, 1992.

\bibitem{Esuli:2019dp}
Andrea Esuli, Alejandro Moreo, and Fabrizio Sebastiani.
\newblock Funnelling: {A} new ensemble method for heterogeneous transfer
  learning and its application to cross-lingual text classification.
\newblock {\em ACM Transactions on Information Systems}, 37(3):Article 37,
  2019.

\bibitem{Perez-Gallego:2017wt}
Pablo Pérez-Gállego, José~Ramón Quevedo, and Juan~José {del Coz}.
\newblock Using ensembles for problems with characterizable changes in data
  distribution: {A} case study on quantification.
\newblock {\em Information Fusion}, 34:87--100, 2017.

\bibitem{Reis:2018fk}
Denis {Moreira dos Reis}, Andr{\'{e}}~G. Maletzke, Diego~F. Silva, and
  Gustavo~E. Batista.
\newblock Classifying and counting with recurrent contexts.
\newblock In {\em Proceedings of the 24th ACM International Conference on
  Knowledge Discovery and Data Mining (KDD 2018)}, pages 1983--1992, London,
  UK, 2018.

\bibitem{Perez-Gallego:2019vl}
Pablo Pérez-Gállego, Alberto Castaño, José~Ramón Quevedo, and Juan~José
  {del Coz}.
\newblock Dynamic ensemble selection for quantification tasks.
\newblock {\em Information Fusion}, 45:1--15, 2019.

\bibitem{Vaz:2019eu}
Afonso Fernandes~Vaz, Rafael Izbicki, and Rafael Bassi~Stern.
\newblock Quantification under prior probability shift: {T}he ratio estimator
  and its extensions.
\newblock {\em Journal of Machine Learning Research}, 20:79:1--79:33, 2019.

\bibitem{Bunse:2022oj}
Mirko Bunse.
\newblock On multi-class extensions of adjusted classify and count.
\newblock In {\em Proceedings of the 2nd International Workshop on Learning to
  Quantify (LQ 2022)}, pages 43--50, Grenoble, IT, 2022.

\bibitem{Moreo:2021sp}
Alejandro Moreo and Fabrizio Sebastiani.
\newblock Re-assessing the ``classify and count'' quantification method.
\newblock In {\em Proceedings of the 43rd European Conference on Information
  Retrieval (ECIR 2021)}, volume~II, pages 75--91, Lucca, IT, 2021.

\bibitem{Saerens:2002uq}
Marco Saerens, Patrice Latinne, and Christine Decaestecker.
\newblock Adjusting the outputs of a classifier to new a priori probabilities:
  A simple procedure.
\newblock {\em Neural Computation}, 14(1):21--41, 2002.

\bibitem{Sechidis:2011tu}
Konstantinos Sechidis, Grigorios Tsoumakas, and Ioannis Vlahavas.
\newblock On the stratification of multi-label data.
\newblock In {\em Proceedings of the European Conference on Machine Learning
  and Knowledge Discovery in Databases (ECML/PKDD 2011)}, pages 145--158,
  Athens, GR, 2011.

\bibitem{Szymanski:2017yc}
Piotr Szymański and Tomasz Kajdanowicz.
\newblock A network perspective on stratification of multi-label data.
\newblock In {\em Proceedings of the 1st International Workshop on Learning
  with Imbalanced Domains: Theory and Applications (LIDTA 2017)}, pages 22--35,
  Skopje, MK, 2017.

\bibitem{Hersh:1994qm}
William Hersh, Christopher Buckley, T.J. Leone, and David Hickman.
\newblock {OHSUMED}: {A}n interactive retrieval evaluation and new large text
  collection for research.
\newblock In {\em Proceedings of the 17th ACM International Conference on
  Research and Development in Information Retrieval (SIGIR 1994)}, pages
  192--201, Dublin, {IE}, 1994.

\bibitem{Read:2010rk}
Jesse Read.
\newblock {\em Scalable multi-label classification}.
\newblock PhD thesis, University of Waikato, Hamilton, NZ, 2010.

\bibitem{Zhang:2014zn}
Min-Ling Zhang and Zhi-Hua Zhou.
\newblock A review on multi-label learning algorithms.
\newblock {\em IEEE Transactions on Knowledge and Data Engineering},
  26(8):1819--1837, 2014.

\bibitem{Hassan:2021af}
Waqar Hassan, André~Gustavo Maletzke, and Gustavo Batista.
\newblock Pitfalls in quantification assessment.
\newblock In {\em Proceedings of the CIKM 2021 Workshop on Learning to
  Quantify}, Virtual Event, 2021.

\bibitem{Moreo:2021bs}
Alejandro Moreo, Andrea Esuli, and Fabrizio Sebastiani.
\newblock {QuaPy: A Python}-based framework for quantification.
\newblock In {\em Proceedings of the 30th ACM International Conference on
  Knowledge Management (CIKM 2021)}, pages 4534--4543, Gold Coast, AU, 2021.

\bibitem{Castano:2021le}
Alberto Castaño, Laura Morán-Fernández, Jaime Alonso, Verónica
  Bolón-Canedo, Amparo Alonso-Betanzos, and Juan~José {del Coz}.
\newblock A theoretical analysis of quantification methods based on matching
  distributions.
\newblock https://github.com/bertocast/adjust\_dist\_xy, 2021.
\newblock Unpublished manuscript.

\bibitem{Gonzalez-Castro:2013fk}
Víctor González-Castro, Rocío Alaiz-Rodríguez, and Enrique Alegre.
\newblock Class distribution estimation based on the {H}ellinger distance.
\newblock {\em Information Sciences}, 218:146--164, 2013.

\end{thebibliography}


% ----------------------------------------------------------------------
\clearpage
\newpage
\appendix

% ----------------------------------------------------------------------

\section{Evaluation in Terms of Relative Absolute Error}
\label{sec:app:rae}

\noindent While the tables presented in the main body of the paper
report the results of our experiments in terms of the absolute error
(AE) measure, in this section we present, for the sake of
completeness, the results in terms of relative absolute error
(RAE). We do not comment on these results since the trends that emerge
from them are essentially the same as for the AE measure. Tables
\ref{tab:cc_general:mrae}, \ref{tab:pcc_general:mrae},
\ref{tab:acc_general:mrae}, \ref{tab:pacc_general:mrae},
\ref{tab:sld_general:mrae}, \ref{tab:mlc:mrae}, \ref{tab:mlq:mrae},
are the RAE equivalents of Tables \ref{tab:cc_general},
\ref{tab:pcc_general}, \ref{tab:acc_general}, \ref{tab:pacc_general},
\ref{tab:sld_general}, \ref{tab:mlc}, \ref{tab:mlq}, respectively

\begin{table}[h!]
  \centering
  \caption{Values of \rabse\ obtained in our experiments for different
  amounts of shift using CC as the base quantifier. Notational
  conventions are as in Table~\ref{tab:cc_general}.}
  \label{tab:cc_general:mrae}
  \input{tables/cc_nocol.app.mrae.tex}
\end{table}

\begin{table}[h!]
  \centering
  \caption{Values of \rabse\ obtained in our experiments for different
  amounts of shift using PCC as the base quantifier. Notational
  conventions are as in Table~\ref{tab:cc_general}.}
  \label{tab:pcc_general:mrae}
  \input{tables/pcc_nocol.app.mrae.tex}
\end{table}

\begin{table}[h!]
  \centering
  \caption{Values of \rabse\ obtained in our experiments for different
  amounts of shift using ACC as the base quantifier. Notational
  conventions are as in Table~\ref{tab:cc_general}.}
  \label{tab:acc_general:mrae}
  \input{tables/acc_nocol.app.mrae.tex}
\end{table}

\begin{table}[h!]
  \centering
  \caption{Values of \rabse\ obtained in our experiments for different
  amounts of shift using PACC as the base quantifier. Notational
  conventions are as in Table~\ref{tab:cc_general}.}
  \label{tab:pacc_general:mrae}
  \input{tables/pacc_nocol.app.mrae.tex}
\end{table}

\begin{table}[h!]
  \centering
  \caption{Values of \rabse\ obtained in our experiments for different
  amounts of shift using SLD as the base quantifier. Notational
  conventions are as in Table~\ref{tab:cc_general}.}
  \label{tab:sld_general:mrae}
  \input{tables/sld_nocol.app.mrae.tex}
\end{table}


\begin{table}[h!]
  \centering
  \caption{Values of \rabse\ obtained for different multi-label
  classifiers using PCC as the base quantifier in \bqmc.}
  \label{tab:mlc:mrae}
  \input{tables/mlc_nocol.drift.app.mrae.tex}
\end{table}

\begin{table}[h!]
  \centering
  \caption{Values of \rabse\ obtained for different multi-label
  aggregation methods in \mqbc.}
  \label{tab:mlq:mrae}
  \input{tables/mlq.drift.app.mrae.tex}
\end{table}

% ----------------------------------------------------------------------

\clearpage
\newpage

\section{Exploring other Regressors in RQ}
\label{sec:otherregressors}

\noindent We here report additional experiments that extend the ones
presented in Section~\ref{sec:exp:mlq}; the present experiments
concern the use of regression algorithms other than ridge regression (Ridge-RQ), random forest regression (RF-RQ), and linear SVR (SVR-RQ), which were the 
only regression
algorithms we considered in
Section~\ref{sec:exp:mlq}. Tables~\ref{tab:mlqreg}
and~\ref{tab:mlqreg:mrae} report the results of these experiments in
terms of AE and RAE, respectively, obtained by optimizing the hyperparameters shown in Table~\ref{tab:modsel:reg}. These results show that there are no substantial differences in performance for the low-shift regime, while these differences are instead noticeable in the mid-shift and (especially) in the high-shift regimes. These results are well correlated with the results we obtained in the validation phase, on which we relied upon for choosing ridge regression, random forest regression, and linear SVR, as representative regression models.
%\fabsebcomment{Here too we do not
%want to add any further comment? If none of these additional
%regressors beats the two we have used in the main body of the paper,
%we should at least say so.}

\begin{table}[h!]
  \centering
  \caption{\abse\ for different regressors for multi-label
  quantifiers}
  \label{tab:mlqreg}
  \input{tables/mlqreg_nocol.drift.app.ae.tex}
\end{table}

\begin{table}[h!]
  \centering
  \caption{\rabse\ for different regressors for multi-label
  quantifiers.}
  \label{tab:mlqreg:mrae}
  \input{tables/mlqreg_nocol.drift.app.mrae.tex}
\end{table}

\begin{table}[h!]
  \centering
  \caption{Hyperparameters explored during model selection for
  different regressors. Only the hyperparameters which are specific to
  the regressor are listed. All methods are deployed with an LR
  classifier; for hyperparameters $C$ and \emph{ClassWeight},
  we explore in the ranges $\{10^{-1}, \ldots, 10^{2},10^{3}\}$ and
  \{Balanced, None\}, respectively.}
  \label{tab:modsel:reg}
  \input{tables/hyper_reg}
\end{table}

% ----------------------------------------------------------------------

\end{document}

% ----------------------------------------------------------------------

\section{Notes to Ourselves}

\noindent Survey on \MLC~\cite{Tsoumakas:2007nl}

Book about \MLC~\cite{Herrera:2016xt}

\texttt{scikit-multilearn}~\cite{Szymanski:2017ru}

QuaPy\footnote{\url{https://github.com/HLT-ISTI/QuaPy}}
\cite{Moreo:2021bs}

% Dataset
% list\footnote{\url{http://mulan.sourceforge.net/datasets-mlc.html}}

Solving multiclass learning problems via error-correcting output codes
(see in sklearn)~\cite{Dietterich:1994au}

% ML-KNN, Label Embedding for multi-label classification
% ~\cite{Zhang:2007as} (\textbf{citations are relative to that
% article}) ``Multi-label learning originated from the investigation
% of text categorization problem, where each document may belong to
% several predefined topics simultaneously'' (we could use this as a
% motivation for focusing on text-classficiation
% problems...). ``Traditional two-class and multiclass problems can
% both be cast into multi-label ones by restricting each instance to
% have only one label. On the other hand, the generality of
% multi-label problems inevitably makes it more difficult to learn. An
% intuitive approach to solving multi-label problem is to decompose it
% into multiple independent binary classification problems (one per
% category). However, this kind of method does not consider the
% correlations between the different labels of each instance and the
% expressive power of such a system can be weak [1–3]. [...] Until now
% [the paper is from 2007...], only a few literatures on multi-label
% learning are available, which mainly concern the problems of text
% categorization [1,2,6,8,11,12], bioinformatics [3,5,23] and scene
% classification [4].'' ``One famous approach to solving this problem
% is BOOSTEXTER proposed by Schapire and Singer [2], which is in fact
% extended from the popular ensemble learning method ADABOOST [13]."


Dedicated approaches for text-classification [before 2007]:
%
\begin{itemize}
\item~\cite{McCallum:1999zv}: ML with EM -- this seems to be very
  important
\item~\cite{Schapire:2000nl} BoosTexter: a boosting-based system for
  text categorization
\item~\cite{Gao:2004op}: A MFoM learning approach to robust multiclass
  multi-label text categorization
\item~\cite{Kazawa:2004fk}: Maximal margin labelling for multi-topic
  text categorization
\end{itemize}
%
\noindent This article~\cite{Montanes:2014fu} deals with dependent
binary relevance models for \MLC\ (a paper from José del Coz,
Barranquero, et al.). It covers the stacking, Chain classifier, etc.,
and uses our datasets.

% From sklearn's guide: ``Stacked generalization is a method for
% combining estimators to reduce their biases [W1992] [HTF]. More
% precisely, the predictions of each individual estimator are stacked
% together and used as input to a final estimator to compute the
% prediction. This final estimator is trained through
% cross-validation.'' [W1992] Wolpert, David H. “Stacked
% generalization.” Neural networks 5.2 (1992): 241-259.

% Todo: fill the datasest info. Add the iterative method for sampling
% multi-label [it does not seem to improve; it yields almost always
% similar results, but sometimes much worse ones]. Model selection.

% Madjarov et al. divide approaches to multi-label classification into
% three categories, you should select a scikit-multilearn base class
% according to the philosophy behind your classifier: (a) algorithm
% adaptation, currently none in scikit-multilearn in the future they
% will be placed in skmultilearn.adapt; (b) problem transformation,
% such as Binary Relevance, Label Powerset \& more, are now available
% from skmultilearn.problem\_transformation; (c) ensemble
% classification, such as RAkEL or label space partitioning
% classifiers, are now available from skmultilearn.ensemble "

Very recent article about multi-label text classification:
\cite{Zhang:2021ma} Correlation-Guided Representation for Multi-Label
Text Classification. This article names other methods as belonging to
the multi-label text classification task.

A common assumption in \MLC\ upon which most dedicated approaches
hinge, is that the presence of certain class labels might bring to
bear additional insights towards the prediction of certain other
labels. We extend this idea to the realm of quantification, i.e., we
assume that the stochastic dependencies between the
\emph{misclassification errors} (which can be estimated via
validation) might bring to bear additional information into the
process of correcting (i.e., adjusting, as for ACC, PACC) some
preliminary class prevalence estimates.

% Check \url{https://scikit-learn.org/stable/modules/multiclass.html}
% for a brief introduction of multiclass strategies. Check connections
% between multi-label and multi-output. Looks like multi-output means
% multi-label with total independence among classifiers (i.e.,
% multi-label algorithms may attempt to leverage stochastic
% dependencies among classes). No, it's not that: multi-output implies
% $n$ non-binary problems, with $n>2$. Multi-output is akin to
% multi-task


% collect a $|Y|\times |Y|$ matrix of class-conditional predictions
% $Q$, so that $q_{ij}$ reflects $P(y_{j}|\hat{y}_{i})$, i.e., the
% probability that the true class is j given the prediction is i. Use
% this matrix to correct the vector of predictions by multiplying it
% by Q. The original classifier might be probabilistic.

Here is a discussion about multi-label stratification
\url{http://scikit.ml/stratification.html}

From scikit-multilearn ``For many reasons, described here and here
traditional single-label approaches to stratifying data fail to
provide balanced data set divisions which prevents classifiers from
generalizing information''. This might probably be one of the
challenges for training \MLQ\ methods. See papers describing ad-hoc
methods~\cite{Szymanski:2017yc, Sechidis:2011tu}. Might be good to use
\texttt{from skmultilearn.model\_selection import
iterative\_train\_test\_split} instead of random split, when creating
the validation sets (the iterative method presented in
\cite{Sechidis:2011tu}).

% There are some metrics (label density, ecc.) to characterize some
% aspects of multi-label datasets. I think one that might be useful
% is:
% $$||Y_{tr}^{T}Y_{tr} - Y_{te}^{T}Y_{te}||_F$$
% where the $Y$'s label matrices are L1-normalized by columns. This
% aims at quantifying the deviation between the class-conditional
% correlations (the simplest one -- other measures like PMI or IG,
% instead of the dot product, might be useful as well) in training vs
% test (some sort of shift).

We should check (and mention in related work) the ``label graph"
analysis, see \url{http://scikit.ml/labelrelations.html}. In this URL,
there are also some visualization tools (do we want to use them?).

% There is another dataset for multi-label text classification: AAPD
% [Yang et al., 2018] Pengcheng Yang, Xu Sun, Wei Li, Shuming Ma, Wei
% Wu, and Houfeng Wang. Sgm: Sequence generation model for multi-label
% classification. In Proceedings of the 27th International Conference
% on Computational Linguistics, pages 3915–3926, 2018.


We have removed all classes which have less than 2 positive training
datapoints. The reason why, is that many among the quantification
methods we use (e.g., ACC, PACC, HDy) require the training set to be
split in a proper training set and a validation set, and require that
at least one positive is present in each set.

Try to establish an ordering of dataset which reflect how
``multi-label-ish'' is. Candidate functions could be the average
number of labels per datapoints. The idea is to simplify the analysis
in terms of how these datasets are: I would expect methods mining
stochastic class-class correlations to work well only on datasets with
strong multi-label characteristics.

Show cardinality and density, as for~\cite{Luaces:2012qi}; see also
the definition of \textit{dependency} in Equation 11. and some useful
discussions: ``Therefore, in some datasets a hypothesis predicting no
labels for any input will have a very low percentage of
misclassifications. Nevertheless, the key ingredient that makes ML an
interesting research problem is that the labels show some kind of
dependency between them. Otherwise, if the label independence
assumption was fulfilled, BR would be the perfect approach. Thus, we
need datasets with different levels of label dependency to evaluate
the behaviour of ML methods. Unfortunately, how to measure label
dependency is not trivial.''

% ----------------------------------------------------------------------

\subsection{Things to Clarify}

\noindent Check the model selection (when is binary, when is
multi). Maybe set a threshold below which we go with default
parameters.

We set the parameters prevpoints=101 (i.e., stepping by 1\%) for all
datasets, except from tmc20007 (and other dataset?), for which we set
prevpoints=21 (i.e., stepping by 5\% -- otherwise it generates too
many samples, since this is the dataset with the largest
codeframe). We have also varied the number of repeats per dataset to
balance the number of test samples so that all datasets generate
approximately 10,000 samples.

SLD with calibrated LR? Do a quick experiment. Add HDy?

Sample size 100 for all datasets with less than 100 classes. Check if
we could augment it for other datasets.

J.J del Coz carries out model selection independently on each binary
classifier.

Plot showing class-class correlations in our datasets.

Use expression ``learners that explicitly take label dependence into
account'' somewhere

% When using the benchmarks in \texttt{scikit-multilearn}, it often
% happens that no method outperforms any other, including the
% MLPE. The likely reason is that, when the number of classes is high,
% and the prevalence of each one is very low (as it is the case for
% most of these datasets), the stochastic dependencies among classes
% is weak, and predicting very low values of prevalence is typically
% enough (in particular, those close to the prevalence values observed
% in training). This calls into question the validity of these
% datasets for testing the merits of quantification methods. (In
% multi-label classification (and not quantification), the main
% concerns are not only due to the stochastic dependencies among
% classes, but on the efficiency that is requested for classifiers in
% handling a large number of classes.)

% A different, better suited approach, would consist of selecting a
% subset of categories trying to maintain a high degree of dependency
% among the selected classes. We might want to retain only, say, 10
% classes among those exhibiting a higher degree of correlation with
% the others. We might also want to filter-out documents with a small
% number of test datapoints, since they would not allow for a meaningful
% sampling-based evaluation.



% \subsection{A Big Disclaimer}

% [We will likely not show this disclaimer; I leave it here just to
% take some parts that could be useful for explaining the
% experiments...]

% This ``big disclaimer'' is thus to warn the reader that the datasets
% we use here are variants of originally multi-label datasets that
% have been artificially manipulated as to augment the phenomena we
% deem worth investigating for \MLQ\ applications. One such phenomenon
% concerns with the ability of a quantifier to correctly predict class
% prevalence values that might be substantially different from those
% observed in training. This clause is not specific to \MLQ\, and is
% indeed inherited from experimental settings routinely conducted in
% previous quantification research. Artificially modifying the class
% prevalence values of the test samples might be seen as a way of
% producing unnatural samples that may be unlikely to occur in real
% scenarios. For this reason, the APP is not exempt from criticism,
% and has indeed encounter detractors within the quantification
% community. Notwithstanding this, the APP protocol has become a well
% established practice in quantification literature, due to the fact
% that the problem of quantification is inherently related to dataset
% shift and, more specifically, to prior probability shift. Another
% phenomenon concerns instead with preserving the stochastic
% dependencies among the classes. We deem of crucial importance to
% impose this property in our experimental setting since, quite
% obviously, the problem is otherwise no substantially different from
% resolving a set of independent binary quantification problems,
% something that lacks interest for the scope of this research. Yet
% another factor that we have deliberately manipulated is the number
% of classes. While in contexts of multiclass classification (and not
% quantification), being able to efficiently deal with a large number
% of classes is of the utmost importance, it might be
% counterproductive for an experimental setting of multiclass
% quantification. The reason is that datasets with large codeframes
% tend to follow a power-law distribution of datapoints per class, with
% very few high-populated categories and a long tail of severely
% imbalanced categories. This posses a challenge for producing
% meaningful samples at controlled prevalence values, given that the
% few documents from the (many) rare classes are doomed to be picked
% up repeatedly in many samplings. In order to avoid such effect, we
% have reduced the number of classes by removing the low-populated
% ones. While waiting for the advent and availability of interesting
% datasets for \MLQ\ research, we have opted for using a magnifying
% glass on the currently available datasets for text classification,
% so that the prior probability shift and the class-class correlations
% come to play a fundamental role in the evaluation.

\alexcomment{Moved from other section; adapt or remove:} There are
several handicaps that we need to consider in order to address
quantification in multi-label problems~\cite{Zhang:2014zn}:
%
\begin{itemize}
\item High label dimensionality, which result in an exponential number
  of potential label sets.
\item Label dependencies, which are required to model since it would
  facilitate dealing with the high output space.
\item High label imbalance, which is a common problem in some tasks
  such as text classification. It constitutes a drawback both for
  classifiers but also for artificial sampling protocols used to train
  and/or validate quantifiers.
\end{itemize}
%
\noindent Any quantification method for BQ can also be used for
\index{Quantification!multi-label}MLQ, since MLQ can be solved by
deploying $n$ independent binary quantification
\index{Quantification!binary}systems, one for each
$y\in \mathcal{Y}$.\footnote{MLQ \index{Quantification!multi-label}
might in principle by solved in ways other than by recasting the
problem into $n$ independent binary quantification
\index{Quantification!binary}problems, i.e., it might be solved by
attempting to leverage possible stochastic dependencies between the
classes in $\mathcal{Y}$, similarly to what is done in many approaches
to multi-label classification; however, for MLQ
\index{Quantification!multi-label}we are not aware of any attempt in
this direction.} Additionally, any evaluation measure for BQ can be
used for evaluating MLQ, since MLQ can be evaluated by checking, for
each $y\in \mathcal{Y}$, how well $\hat{p}(y)$ approximates $p(y)$ by
means of an evaluation measure for BQ that uses $\{y,\overline{y}\}$
as the binary codeframe.
 
However, for MLQ, the only attempt we are aware of in past literature
is by~\cite{Levin:2017dq}, in which the problem is tackled as a set of
independent binary quantification problems and in which the
correlations among classes are never brought to bear into the
quantification system.

\alexcomment{Double-check if something is missing from the following
old version:}

The choice of models for the experiments was determined by related
work and available implementations. Unless specified otherwise,
single-label classifiers are Logistic Regressions (provided by
\textsc{scikit-learn}). We also selected several \MLC\ approaches,
ensuring that there is at least one representative per group. We list
them below:
%
\begin{itemize}
\item Logistic regression (\textsc{scikit-learn} implementation), used
  as general single-label classifier. Parameters were optimised as
  in~\cite{Montanes:2014fu}, where $C$ was explored in the range
  $[0.1, ..., 1000]$ and class weight was tested for one and also
  balanced w.r.t. class imbalance.
\item Chain classifiers, a multi-label problem transformation
  approach. We performed a joint optimisation in the same terms as
  with Logistic Regression.
\item Stacked classifiers, a multi-label ensemble where the estimators
  are Logistic Regressions. We optimised the final estimator in the
  terms described above, leaving the rest of them with default
  parameters.
\item CLEMS, a multi-label embedding with an underlying MLkNN as
  classifier and Random Forest as a regressor. The number of trees for
  the regressor was explored in the range $[10, 50]$, while $k$ and
  $s$ were explored as described for MLkNN.
\item MLkNN, a multi-label algorithm adaptation. $k$ was explored in
  the range $[1,10]$ and $s$ (smoothing) in the range $[0.5, 1]$.
\item Label Space Clustering, with MLkNN as classifier (with its
  correspondent optimisations) and KMeans as clustering methods. The
  number of clusters was explored in the range $[2, 100]$
\item Decision Tree, a tree-based multi-output classifier. We explored
  \textit{gini} and \textit{entropy} as splitting criteria. We did not
  optimised the maximum depth since it was possible to train them
  until all the leaves were pure.
\item Random Forest, an ensemble multi-output classifier. We explored
  the number of trees in the range $[10, 200]$.
\item Lasso Regressor, a linear model with L1-regularisation. We
  explored the alpha parameter in the range $[0.001,
  1000]$. \manucomment{l1-reg}
\item Ridge Regressor, a linear model with L2-regularisation whose
  alpha was optimised in the range $[0.001, 1000]$. \manucomment{l2}
\item Regressor Chains, ... \manucomment{to be continued...}
\item Stacked Regressors, ... \manucomment{to be continued...}
\end{itemize}

% paves the way for

\end{document}

\endinput
