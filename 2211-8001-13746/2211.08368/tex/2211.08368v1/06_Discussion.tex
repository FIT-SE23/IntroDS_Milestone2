\chapter{Discussion}

This monograph studied how machine learning has been used to improve the performance of \sbmps. This can be achieved by using machine learning models to approximate the primitive operations of a sampling-based planner or to select between different choices of primitive operations. It also discussed a relatively new area of research, where machine learning models have been proposed that approximate the operation of an optimal sampling-based planner. Finally, it briefly covered some of the literature where sampling-based planning can be performed over a learned robot and/or environment model.

Many \sbmps  \ exhibit desirable theoretical properties, such as probabilistic (or resolution) completeness and asymptotic optimality, but may be slow to converge to high quality solutions in practice. One promising direction to improve the quality of solutions is to work within the \sbmp \ framework and provide desirable guarantees, while improving the practical convergence rate by using efficient operations based on machine learning models. This monograph concludes by briefly evaluating the successes (and failures) of the different proposed integration techniques, in the context of the practical challenges described in Section~\ref{sec:intro}.

\section{Computational Efficiency}

The first form of computational efficiency that bears consideration is that of \emph{offline} vs \emph{online} computation. For a machine learning model to capture relevant features of a motion planning problem instance, either in a single workspace or across workspaces, it must have access to a high-quality dataset that does not lead to a significant statistical bias. 

Some works discussed in this survey trade an environment-specific, offline cost, to obtain better performance on new planning problems in the same environment. Alternatives trade a higher offline cost to obtain better performance on new environments (that are similar to the ones seen during training). Deciding which of these trade-offs to use depends on the application where the planner is being deployed, such as whether the environment the robot will be deployed is known or not. 
% \troy{We may also want to discuss environment specific offline costs vs offline costs that do not have to be done on an per-environment basis}

For some problems, such as learning a sampler via supervised learning or learning a collision-checker inside a workspace, it is straightforward to annotate high-quality datasets via significant offline computation. The trained model rewards this offline effort by speeding up the runtime of the planner on a new problem instance. Nevertheless, this survey discussed applications, such as approximating a distance function or sampling strategies for manipulation planning, where obtaining such a dataset is computationally more challenging, which motivates additional research effort in these areas.

A relatively unexplored area of research is the idea of an \sbmp \ that learns from previous planning experience on similar, yet different, problems, and manages to transfer the experience across environments. Such a planner would spend more computational time at the beginning of its life cycle but would eventually gather enough planning experience to find high-quality solutions to new problems quickly. 

A form of computational efficiency that must also be taken into account is online inference time, e.g., when the learned module inside an \sbmp\ uses a large machine learning model, such as a deep neural network. Such an integration may lead to an improvement over an alternative planner in terms of the number of iterations to find a solution. For most practical purposes, however, the metric of interest is \textit{overall planning time}, where the integration of an \sbmp\ with a learned model may under-perform due to inference time. Specialized hardware, such as GPUs, can perform model inference for large machine learning architectures to obtain significant gains. This may not be practical, however, in all applications.

\section{Path Quality}
% Path quality is generally denoted by the path's cost according to a given cost metrics.  Common metrics include the time or the energy required to traverse the path.

For graph-based \sbmps, such as the PRM, the most significant determiners of path quality are the sampling method and the nearest neighbor selection, which is performed according to a distance metric. Learned samplers discussed in Section~\ref{sec:sampling} produce samples along the shortest path and show the most promise for improving path quality. Learning accurate distance metrics, and integrating them efficiently into nearest neighbor search subroutines, remains an open area of research.

% such as \citep{IHP-2018,kumar2019lego} which produce samples along the shortest path show the most promise for improving path quality. 

For tree-based \sbmps, such as the RRT, in addition to node selection, node expansion majorly impacts path quality. Expansion typically involves randomly sampling a state, and then querying a local planner to make progress towards the selected state. This opens the door for learned models to both identify good states to sample (i.e., are likely to lie along a shortest path), and good local plans that bias the final path towards lower costs.

% \aravind{TODO}. For tree-based \sbmps \ such as the RRT, node selection and node expansion are the two main factors which impact path quality.  Node selection requires a distance metric and in many cases a heuristic, and learned heuristics and distance metrics show a great deal of promise towards improving path quality.  Expansion is done by applying controls to step the selected node and learned methods which bias the controls to produce motion in the direction of a likely shortest path will improve path quality.  This opens the door for both models which identify the likely direction of the shortest path and models which bias controls towards a specified direction.

Irrespective of the underlying \sbmp \ being used, it would be interesting to explore the application of machine learning to perform post-processing on paths computed by an \sbmp. Just like machine learning models have been used to identify the order in which edges must be collision-checked, a model could be trained to identify the segments of a tree or a graph that are good candidates for smoothing, or to apply the smoothing directly. Potentially, this can be achieved in conjunction with an optimization process. 

% \aravind{TODO}. A third area which would be interesting to explore is applying learned models to do post-processing on existing paths.  We could, for example, train a model to identify parts of a path that are good candidates for smoothing or train a model which apply smoothing to sections of a path.  



% \section{Dealing with inaccurate and/or incomplete models}


\section{Ease of Use}
One consideration during the deployment of \sbmps \ is that they involve a set of parameters that need to be tuned. Furthermore, the sampling strategy, distance metric, collision detection method, and connection strategies, are all exchangeable components. The selection of these primitives as well as parameter values is non-trivial, and often requires expert knowledge of motion planning for the specific application. Inappropriate selection can handicap the performance of the planner.

% One factor that makes \sbmps \ difficult to deploy is the many parameters which need to be set.  Graph-based methods must select from a variety of samplers, local planners, distance metrics, collision detectors and connection strategies.  Similarly, Tree-based methods must select from a variety of node selection and expansion strategies.  Parameter selection is non-trivial and requires an expert with in-dept knowledge of motion planning, and an inappropriate selection will greatly handicap the performance of the planner.  

Adaptive methods that automatically select combinations of primitive operations and parameter settings offer a solution, which allows non-expert users to make use of \sbmps\ effectively.  Previous work includes adaptive methods for selecting samplers, connection strategies and parameter settings. It would be interesting and useful to combine these methods to create \emph{universal} planning frameworks that use a learned model to adaptively select combinations of primitive operations and parameter settings.  

%\section{Other considerations and possible future work}

\section{Limitations of Existing Methods}

% interaction of different components

Successful motion plans are a rich source of data about multiple facets of the environment or that particular planning instance, including distance between robot configurations, and the validity of different parts of the workspace. The majority of the approaches discussed in Section~\ref{sec:learning-primitives}, however, deal with only a single primitive replaced with a learned module. On the other side of the spectrum, the neural motion planners in Section~\ref{sec:integrated} replace the entire \sbmp \ with learned models. There has not been enough exploration in the literature that focuses on the interaction of multiple learned components within an \sbmp\ and for which purpose they offer the most benefits. 

% inductive bias

Different machine learning models expose different types of \emph{inductive bias}, i.e., the ability of the learning algorithm to predict outputs given inputs that it has not encountered during the training process. Relatively new architectures, such as Graph Neural Networks (GNNs) \citep{Bruce_2014} and Transformers \citep{vaswani2017attention}, have been used in a wide variety of applications in computer vision and natural language processing. These models may enable similar advancements in improving the performance of \sbmps.

Poorly designed and inadequately trained models will significantly handicap planning performance.  Thus, it becomes increasingly important to develop motion planning algorithms that are robust to inaccurate models. A learned model can also potentially adversarially impact the probabilistic guarantees of \sbmps.  Many works discussed in this survey do not discuss the impact of machine learning on the properties (probabilistic completeness or asymptotic optimality) of the \sbmp\ framework. For example, if a learned sampler only generates samples over a subset of $\cspace$, then any \sbmp\ that uses this sampler will not be complete.  It would be interesting to develop learning-based methods that provide theoretical guarantees.


\section{Potential Future Work}
% exploit problem structure

In most robotic applications, there is the consideration of integrating the planning algorithm with the robot's perception. Although machine learning promises end-to-end pipelines that output low-level control policies for a given task, given raw sensory input, these are often data-hungry solutions, and they do not easily generalize across domains and tasks. Nevertheless, there are a lot of opportunities in using machine learning models to learn high-level, task-specific, and interpretable representations of a robot's sensory input, which a downstream \sbmp \ can use.

As there are many avenues for integrating machine learning tools with \sbmps, it is also useful to define clear benchmarks that can evaluate the performance, and highlight the strengths and weaknesses of a new motion planner across a variety of problems. There has been preliminary work in this area \citep{chamzas2021motionbenchmaker}.

Many successful algorithmic solutions that integrate machine learning tools with \sbmps \ exploit the inherent structure present in specific applications, and design a machine learning model that can solve a problem component. Examples in this survey include the design of a learned local planner for systems with significant dynamics, and learning stochastic dynamics models for planning under uncertainty. These solutions are often handcrafted to specific applications, but they offer promising avenues for motion planning researchers with domain expertise to investigate.


\section{Alternative Planning Frameworks}

Although outside the scope of this survey, there are other approaches to the motion planning problem beyond \sbmps. These include search-based approaches, which search for paths from start to goal configurations by combining a series of \textit{motion primitives} (short, kinematically feasible motions). They also include trajectory optimization methods \citep{ratliff2009chomp}, that assign a cost to each robot trajectory and incorporate constraints, such as path smoothness and collisions. They can use a broad class of optimization techniques, such as sequential convex optimization, to obtain a good solution trajectory. There are also efforts that apply machine learning to these alternative planning methodologies \citep{Vemula-RSS-20,mdydb-2018}. 


% Ifeasible gng of n this paper we studied the applications of machine learning to motion planning.  We studied how machine learning has been used to improve the performance of motion planning primitives used by sampling based motion planner.  We also studied how machine learning can be use to adaptivly select these primitives.  We discussed a number of integrated architectures that make use of machine learning and how machine learning has been applied to trajectory optimization.  We discussed how machine learning has been applied to motion planning with constraints including problems with dynamic constraints and we discussed how it has been applied to motion planning for manipulators.  

% Overall, a great deal of work has been done applying machine learning to improve sampling and collision detection for sampling based methods.  Less work has been done on applying learning to distance metrics and to heuristics, and there is a good deal of potential for work in this area.  A good deal of work has been done applying machine learning to dynamics, which is expected given the computational costs associated with dynamics, and we expect to see many further applications to dynamics in the future.  Applications to trajectory optimization are limited and there is likely a great deal of future work that can be done in this area.

% With regards to machine learning methods, we have seen a great deal of recent attempts to apply neural networks to motion planning, which is expected given the recent surge in popularity of neural networks.  Applications of CNNs are especially promising given the importance of spacial properties to motion planning, however CNNs are limited in that they cannot take higher dimensional geometric spaces as input/output and thus cannot be applied to $\cspace$ or to state space.


