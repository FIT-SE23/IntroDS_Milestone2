\chapter{SBMP with Learned Models}
\label{sec:planning_under_uncertainties}

% This section looks at how machine learning has been applied to SBMP for specific variants of the motion planning problem. In particular, it first explores how machine learning has been applied to problems with constraints on robot dynamics, and to robotic manipulation problems where requirements due to interactions with the environment (such as grasping) introduces constraints on the motion.  It also looks at how machine learning has been applied to planning problems that need to reason about uncertainty.

% \section{Planning Under Uncertainty}

% \label{sec:uncertainty}
This section looks into how machine learning has been used to handle, and plan under, uncertainty. Noisy sensors, actuators and external agents are potential sources of uncertainty. Sampling-based planners have been applied to planning under uncertainty through belief space planning. As with kinodynamic planning, many belief-space planning problems do not have access to a steering function, and thus planning must be done using only forward propagation. Uncertainties can also arise from the unavailability to measure parameters like wheel-ground friction, air friction, spring constants etc. %slipage

\begin{mdframed}[hidealllines=true,backgroundcolor=red!20,frametitle=Categories on SBMP with Learned Models]
\begin{myitem}
    \item \textbf{Modeling robot uncertainty} \citep{osti_10145334, 9196564,McConachie_2020, malone2012implementation,doi:10.1177/02783649211004615,curtis2022long,bahnemann2017sampling,burri2018framework,omnirobot}
    \item \textbf{Modeling uncertainty in obstacle dynamics} \citep{Aoude2013ProbabilisticallySM,88149,fulgenzi2008probabilistic,fulgenzi2010risk,zhang2020novel}
\end{myitem}
\end{mdframed}



\section{Modeling Robot Uncertainty}
Learned models have been used for systems where precisely modeling the motion of the objects being manipulated is infeasible (for instance, manipulation with underactuated hands) \citep{osti_10145334}.  This method learns a \textit{stochastic} model of the system's dynamics from a dataset of trajectories with randomly sampled actions. Two choices of stochastic models - a Bayesian neural network and a Gaussian Process (GP) are explored. The trained dynamics model is used with a sampling-based planner that represents beliefs as a particle cloud over the state space. The model forward propagates these particle clouds in order to construct a planning tree. Critic models have also been applied in this domain to estimate the error in the learned transition model \citep{9196564}. The output of the critic model is used as a cost function by an AO planner to direct planning towards regions where there is less uncertainty in the learned dynamics. 
% \troy{I think we should mention that the model for \citep{osti_10145334} is based on a Bayesian Neural Network.  We may also want to have one sentence where we discuss the problems these methods have been applied to} 


Learned models have also been applied to problems where the underlying system may be difficult and/or time consuming to model correctly, and thus the planner acts over a \textit{reduced} state space \citep{McConachie_2020}. Training data for this model is collected by generating plans in the reduced state space, and then applying these plans to the true system. This data is used to train a classifier that labels plans generated in the reduced state space as reliable or unreliable.  The learned model is incorporated into an RRT-based planner in order to bias sampling away from transitions that are labeled as unreliable.  


The \textit{Brain-Emulating Cognition and Control Architecture} (BECCA) \citep{malone2012implementation} uses online reinforcement learning to exploit task structure as well as to address environmental noise and hardware imperfection inherent to manipulation tasks. At every time step, BECCA makes an observation in the world, extracts features from the sensory input, performs an action in response to the input, and receives a reward. The feature extractor identifies patterns and correlations in the input vector in an unsupervised manner. The action selector learns, via online reinforcement learning, a mapping from features to actions that lead to the highest recorded reward. The architecture is trained on a simulated system until it obtains satisfactory performance, and is allowed to update its model after being deployed. It is mapped to a PRM by reducing the agent's state space to roadmap nodes, and limiting the agent's actions to edges between the nodes.

Conditions for pouring or scooping skills are learned using GPs to enable risk-aware predictions \citep{doi:10.1177/02783649211004615}. Alongside active learning, this approach reduces the model's uncertainty. The learned skills are then used by a \textit{RRT-Connect} \citep{kuffner2000rrt} to produce geometric paths for the gripper. A related approach \citep{curtis2022long}, explores ways to implement perceptual learned modules for shape estimation and grasp generation that are then used by a SBMP.

% System identification is performed on an omnidirectional mobile robot to learned friction coefficients in \citep{omnirobot}. The learned values are used to perform multiple experiments including using a SBMP to compute a plan using the learned model which results in superior trajectories than using only the analytical model.

Hybrid data-driven approaches have been used to learn models for robots with imprecise or uncertain dynamics. These techniques combine physics models of a robot with machine learning methods to self-tune the physics models, in order to accommodate robot design imprecision. A crucial component is generating valuable data in order to reduce the tuning time. For this purpose, a modified RRBT planner is used to search for \textit{informative trajectories}, those which maximize the information gain of the specified unknown parameters \citep{bahnemann2017sampling}. This method is used for calibrating a micro aerial vehicle in a constrained environment with minimal user interaction, and is later applied in \cite{burri2018framework} to produce trajectories for accurate parameter estimation based on maximum likelihood. Another system identification approach is to, given the dynamical model of the system, learn the unknown friction coefficients. The learned model is used by a SBMP to generate more reliable trajectories \citep{omnirobot}. 
%This is accomplished by applying GPs to model the forward kinematics of the system along with a neural network to model system dynamics.

% which is used to propagate forward the system dynamics and to model the uncertainty in these propagations.  This work makes use of two stocastic models, one which utilizes Gaussian processes, and a novel data-driven model based on Bayesian Neural Networks.  This method is trained using a training set that is acquired by applying random actions to the system, while recording the observable states, which results in a set of state-action trajectories.  The trained model is then used in combination with a planner which represents beliefs as a particle cloud over state-space.  In particular, the model is used to forward propagate these particle clouds in order to construct a planning tree which is used for to select actions.  Application of this work is shown for a a 2-link acrobot with a 4-dimensional state space, and for a 2D Point system  where noise is introduced into different regions of the state space.

% Critic models \citep{9196564} have also been applied to grasping for underactuated hands.  The critic model is trained to estimate the error in the transtion model and it is used as a cost function by asymptotically optimal motion planners in order to direct planning through regions where there is less error.  This planner constructs a planning tree using transitions given by a neural network while the critic estimates uncertainty in these transitions.  This allows the planner to select safer paths where the neural network tends to be more accurate.  Application of this method is shown using 2 armed Motoman robot.



\section{Modeling Uncertainty in Obstacle Dynamics}
\textit{RR-GP} \citep{Aoude2013ProbabilisticallySM} applies learned Gaussian Processes (GPs) for probabilistic safe motion planning with dynamic obstacles and uncertain motion patterns. RR-GP combines GPs with RRT-Reach to build a learned motion pattern model that can be used to predict obstacle trajectories.  These predictions are conditioned on feasible paths which are identified using reachability analysis.  RR-GP uses a chance-constrained RRT to identify probabilistically feasible paths. 
% Application of this method is shown for a variety of simulated 2D environments with static and dynamic obstacles.  

Hidden Markov Models (HMMs) have also been used to model the possible motion of dynamic obstacles \citep{88149}.  Obstacles are modeled as a stochastic process within the HMM, which is queried to obtain obstacle motions and potential variations of the motion states.  Planning is performed using a trajectory-guided path-planning algorithm which samples and evaluates a set of candidate trajectories.  %These candidate trajectories are obtained from a tessellation of local the path planning space and are evaluated for collision using the Hidden Markov Model.  
% The planner searches through potential motion steps and evaluates the candidate trajectories that could result from each action.  The collision probability of of there being an obstacle along it and trajectories where the probability of collision is above a certain threshold are considered to be invalid.  The method then selects the action based on a value function which evaluates the distance traveled and the probability of encountering an obstacle.
% Application of this method is shown for an agent in a two-dimensional environment with dynamic obstacles.

%Macro-Action Generator-Critic  (MAGIC) \citep{lee2020magic} uses a set of learned macro-actions to reduce the complexity of belief-space planning. he macro-actions are used to create a sparse  belief  tree  that  branches  over  possible  selections  of macro-actions. Application of this method is shown to problems such as robot navigation, purest-evasion and object manipulation (e.g. puck-passing). 

%\troy{Is this sufficient as a conclusion or do we want to expand this paragraph?}  
% Overall, learned models have been successfully used to model unknown or unpredictable processes found in motion planning.  They have been use to model aspects stemming from uncertainty in the robot's perception of the environment, uncertainty in the robot's motions or robotic systems that are too complex to efficiently model directly \citep{lee2020magic,88149}.  They have also been used to model the movement of other agents in the environment whose motions are either nondeterministic \citep{9196771,Aoude2013ProbabilisticallySM} or to complicated to model directly \citep{osti_10145334,9196564}.  As SNMPs are applied to a wider variety of real-world robots it is likely we will encounter many systems and physical process that cannot be modeled exactly.  We therefore expect that there will be a growing number of applications of uncertainty to SBMP and learning provides us with a promising tool for modeling this uncertainty. 

% Integration of motion prediction uncertainty in a SBMP is presented in \citep{fulgenzi2010risk}. The \textit{Risk-RRT} algorithm is introduced, which selects to expand the most \textit{promising} node according to a computed risk of collision. The predicted trajectory of dynamic obstacles is computed using learned GPs.
% \citep{fulgenzi2008probabilistic} uses Gaussian processes to pre-learned patterns to have a medium-term prediction aiming to be more reliable than a simple target tracking algorithm. 

Learning has been used to predict motions of dynamic obstacles, such as pedestrians or vehicles, in order to reduce the risk of collision \citep{fulgenzi2008probabilistic,fulgenzi2010risk}. Motions of obstacles are modeled using GPs, which are learned by observing an environment to capture common behaviors and patterns.  This model provides predictions, which are continuous over space and time, and when applied to planning gives better performance than kinematic-based predictions.

In a similar approach, \cite{zhang2020novel} uses SBMP in the context of autonomous driving. This work proposes labeling and training models to more accurately predict a vehicle’s intention, in order to sample states leading to a high-quality collision-free trajectory. Prediction of surrounding vehicles and imitation learning are used to generate collision-free samples near the human-driving trajectory that are used by the planning algorithm.

\begin{mdframed}[hidealllines=true,backgroundcolor=blue!20,frametitle=Discussion on Planning with Learned Models]
        Machine learning models, such as Bayesian Neural Networks and Gaussian Processes (GPs), allow to reason about uncertainty in a learned model. When SBMP techniques are applied to problems involving robots in the real world, they have to often deal with physical processes that cannot be modeled perfectly. A promising area of research is to use these stochastic machine learning models to improve the efficiency and accuracy of sampling-based planners in a way that allows for the underlying uncertainty of the model. 
\end{mdframed}



% \citep{zhang2020novel} Uses SBMP in the context of autonomous driving, proposing a labeling and training models to improve the accuracy of predicting a vehicle’s intention which only samples the points leading to a high-quality collision-free trajectory. Prediction of surrounding vehicles and imitation learning are used to generate the collision-free sample points near the human-driving trajectory that are used for the planning algorithm.

% \citep{fulgenzi2008probabilistic} uses Gaussian processes to pre-learned patterns to have a medium-term prediction aiming to be more reliable than a simple target tracking algorithm. 

% \citep{bahnemann2017sampling} deals with the system identification problem. Building on top RRBT, the objective of the planner is changed from reaching a goal to producing the \textit{most informative path}, which maximizes the information of the unkown parameters. The method is used for calibrating a micro aerial vehicle in a constrained environment with minimal user interaction. This method is then used in \citep{burri2018framework} to produce trajectories for accurate parameter estimation based on maximum likelihood.