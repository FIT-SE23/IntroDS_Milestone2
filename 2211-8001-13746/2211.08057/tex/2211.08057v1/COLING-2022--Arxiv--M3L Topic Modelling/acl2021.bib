@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}


@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
   publisher = {American Psychological Association},
   address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}}

@inproceedings{hao2018lessons,
  title={Lessons from the Bible on Modern Topics: Low-Resource Multilingual Topic Model Evaluation},
  author={Hao, Shudong and Boyd-Graber, Jordan L and Paul, Michael J},
  booktitle={NAACL-HLT},
  year={2018}
}

@inproceedings{hao2018learning,
  title={Learning multilingual topics from incomparable corpora},
  author={Hao, Shudong and Paul, Michael},
  booktitle={Proceedings of the 27th international conference on computational linguistics},
  pages={2595--2609},
  year={2018}
}

@article{hao2020empirical,
  title={An Empirical Study on Crosslingual Transfer in Probabilistic Topic Models},
  author={Hao, Shudong and Paul, Michael},
  journal={Computational Linguistics},
  volume={46},
  number={1},
  pages={95--134},
  year={2020}
}


@inproceedings{wu2020learning,
  title={Learning Multilingual Topics with Neural Variational Inference},
  author={Wu, Xiaobao and Li, Chunping and Zhu, Yan and Miao, Yishu},
  booktitle={CCF International Conference on Natural Language Processing and Chinese Computing},
  pages={840--851},
  year={2020},
  organization={Springer}
}

@inproceedings{mimno2009polylingual,
  title={Polylingual topic models},
  author={Mimno, David and Wallach, Hanna and Naradowsky, Jason and Smith, David A and McCallum, Andrew},
  booktitle={Proceedings of the 2009 conference on empirical methods in natural language processing},
  pages={880--889},
  year={2009}
}


@article{nguyen2021contrastive,
  title={Contrastive Learning for Neural Topic Model},
  author={Nguyen, Thong and Luu, Anh Tuan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{bianchi-etal-2021-pre,
    title = "Pre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence",
    author = "Bianchi, Federico  and
      Terragni, Silvia  and
      Hovy, Dirk",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-short.96",
    doi = "10.18653/v1/2021.acl-short.96",
    pages = "759--766",
    abstract = "Topic models extract groups of words from documents, whose interpretation as a topic hopefully allows for a better understanding of the data. However, the resulting word groups are often not coherent, making them harder to interpret. Recently, neural topic models have shown improvements in overall coherence. Concurrently, contextual embeddings have advanced the state of the art of neural models in general. In this paper, we combine contextualized representations with neural topic models. We find that our approach produces more meaningful and coherent topics than traditional bag-of-words topic models and recent neural models. Our results indicate that future improvements in language models will translate into better topic models.",
}

@inproceedings{srivastava2017autoencoding,
  title={Autoencoding Variational Inference for Topic Models},
  author={Srivastava, Akash and Sutton, Charles},
  booktitle={5th International Conference on Learning Representations},
  year={2017}
}

@article{dieng2020topic,
  title={Topic modeling in embedding spaces},
  author={Dieng, Adji B and Ruiz, Francisco JR and Blei, David M},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={439--453},
  year={2020},
  publisher={MIT Press}
}

@inproceedings{miao2016neural,
  title={Neural variational inference for text processing},
  author={Miao, Yishu and Yu, Lei and Blunsom, Phil},
  booktitle={International conference on machine learning},
  pages={1727--1736},
  year={2016},
  organization={PMLR}
}

@inproceedings{bianchi-etal-2021-cross,
    title = "Cross-lingual Contextualized Topic Models with Zero-shot Learning",
    author = "Bianchi, Federico  and
      Terragni, Silvia  and
      Hovy, Dirk  and
      Nozza, Debora  and
      Fersini, Elisabetta",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.143",
    doi = "10.18653/v1/2021.eacl-main.143",
    pages = "1676--1683",
    abstract = "Many data sets (e.g., reviews, forums, news, etc.) exist parallelly in multiple languages. They all cover the same content, but the linguistic differences make it impossible to use traditional, bag-of-word-based topic models. Models have to be either single-language or suffer from a huge, but extremely sparse vocabulary. Both issues can be addressed by transfer learning. In this paper, we introduce a zero-shot cross-lingual topic model. Our model learns topics on one language (here, English), and predicts them for unseen documents in different languages (here, Italian, French, German, and Portuguese). We evaluate the quality of the topic predictions for the same document in different languages. Our results show that the transferred topics are coherent and stable across languages, which suggests exciting future research directions.",
}

@article{boyd2012multilingual,
  title={Multilingual topic models for unaligned text},
  author={Boyd-Graber, Jordan and Blei, David},
  journal={arXiv preprint arXiv:1205.2657},
  year={2012}
}

@article{liu2021self,
  title={Self-supervised learning: Generative or contrastive},
  author={Liu, Xiao and Zhang, Fanjin and Hou, Zhenyu and Mian, Li and Wang, Zhaoyu and Zhang, Jing and Tang, Jie},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2021},
  publisher={IEEE}
}

@article{jaiswal2021survey,
  title={A survey on contrastive self-supervised learning},
  author={Jaiswal, Ashish and Babu, Ashwin Ramesh and Zadeh, Mohammad Zaki and Banerjee, Debapriya and Makedon, Fillia},
  journal={Technologies},
  volume={9},
  number={1},
  pages={2},
  year={2021},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@inproceedings{chopra2005learning,
  title={Learning a similarity metric discriminatively, with application to face verification},
  author={Chopra, Sumit and Hadsell, Raia and LeCun, Yann},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
  volume={1},
  pages={539--546},
  year={2005},
  organization={IEEE}
}

@inproceedings{schroff2015facenet,
  title={Facenet: A unified embedding for face recognition and clustering},
  author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={815--823},
  year={2015}
}

@inproceedings{gutmann2010noise,
  title={Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},
  author={Gutmann, Michael and Hyv{\"a}rinen, Aapo},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={297--304},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21271--21284},
  year={2020}
}

@article{caron2020unsupervised,
  title={Unsupervised learning of visual features by contrasting cluster assignments},
  author={Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9912--9924},
  year={2020}
}

@inproceedings{thakur-etal-2021-augmented,
    title = "Augmented {SBERT}: Data Augmentation Method for Improving Bi-Encoders for Pairwise Sentence Scoring Tasks",
    author = "Thakur, Nandan  and
      Reimers, Nils  and
      Daxenberger, Johannes  and
      Gurevych, Iryna",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.28",
    doi = "10.18653/v1/2021.naacl-main.28",
    pages = "296--310",
    abstract = "There are two approaches for pairwise sentence scoring: Cross-encoders, which perform full-attention over the input pair, and Bi-encoders, which map each input independently to a dense vector space. While cross-encoders often achieve higher performance, they are too slow for many practical use cases. Bi-encoders, on the other hand, require substantial training data and fine-tuning over the target task to achieve competitive performance. We present a simple yet efficient data augmentation strategy called Augmented SBERT, where we use the cross-encoder to label a larger set of input pairs to augment the training data for the bi-encoder. We show that, in this process, selecting the sentence pairs is non-trivial and crucial for the success of the method. We evaluate our approach on multiple tasks (in-domain) as well as on a domain adaptation task. Augmented SBERT achieves an improvement of up to 6 points for in-domain and of up to 37 points for domain adaptation tasks compared to the original bi-encoder performance.",
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{srinivasan2021wit,
  title={{WIT}: Wikipedia-based Image Text Dataset for Multimodal Multilingual Machine Learning},
  author={Srinivasan, Krishna and Raman, Karthik and Chen, Jiecao and Bendersky, Michael and Najork, Marc},
  journal={arXiv preprint arXiv:2103.01913},
  year={2021}
}

@article{hoyle2021automated,
  title={Is Automated Topic Model Evaluation Broken? The Incoherence of Coherence},
  author={Hoyle, Alexander and Goel, Pranav and Hian-Cheong, Andrew and Peskov, Denis and Boyd-Graber, Jordan and Resnik, Philip},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{manning1999topics,
  title={Topics in Information Retrieval},
  author={Manning, Christopher and Sch{\"u}tze, Hinrich},
  journal={Chapter 15 in Foundations of Statistical Natural Language Processing},
  year={1999}
}

@inproceedings{zheng2014topic,
  title={Topic modeling of multimodal data: an autoregressive approach},
  author={Zheng, Yin and Zhang, Yu-Jin and Larochelle, Hugo},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1370--1377},
  year={2014}
}

@inproceedings{yan2013biterm,
  title={A biterm topic model for short texts},
  author={Yan, Xiaohui and Guo, Jiafeng and Lan, Yanyan and Cheng, Xueqi},
  booktitle={Proceedings of the 22nd international conference on World Wide Web},
  pages={1445--1456},
  year={2013}
}


@article{dieng2019dynamic,
  title={The dynamic embedded topic model},
  author={Dieng, Adji B and Ruiz, Francisco JR and Blei, David M},
  journal={arXiv preprint arXiv:1907.05545},
  year={2019}
}


@inproceedings{blei2006dynamic,
  title={Dynamic topic models},
  author={Blei, David M and Lafferty, John D},
  booktitle={Proceedings of the 23rd international conference on Machine Learning},
  pages={113--120},
  year={2006}
}

@article{mcauliffe2007supervised,
  title={Supervised topic models},
  author={Mcauliffe, Jon and Blei, David},
  journal={Advances in neural information processing systems},
  volume={20},
  year={2007}
}

@article{gutierrez2016detecting,
  title={Detecting cross-cultural differences using a multilingual topic model},
  author={Guti{\'e}rrez, E Dario and Shutova, Ekaterina and Lichtenstein, Patricia and de Melo, Gerard and Gilardi, Luca},
  journal={Transactions of the Association for Computational Linguistics},
  volume={4},
  pages={47--60},
  year={2016},
  publisher={MIT Press}
}

@inproceedings{shi2016detecting,
  title={Detecting common discussion topics across culture from news reader comments},
  author={Shi, Bei and Lam, Wai and Bing, Lidong and Xu, Yinqing},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={676--685},
  year={2016}
}

@article{vulic2015probabilistic,
  title={Probabilistic topic modeling in multilingual settings: An overview of its methodology and applications},
  author={Vuli{\'c}, Ivan and De Smet, Wim and Tang, Jie and Moens, Marie-Francine},
  journal={Information Processing \& Management},
  volume={51},
  number={1},
  pages={111--147},
  year={2015},
  publisher={Elsevier}
}


@article{wang2019atm,
  title={Atm: Adversarial-neural topic model},
  author={Wang, Rui and Zhou, Deyu and He, Yulan},
  journal={Information Processing \& Management},
  volume={56},
  number={6},
  pages={102098},
  year={2019},
  publisher={Elsevier}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}


@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@Article{
  ModalityGap2022,
  title     = {Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning},
  author    = {Weixin Liang and
               Yuhui Zhang and
               Yongchan Kwon and
               Serena Yeung and
               James Zou},
  journal   = {arXiv preprint arXiv:2203.02053},
  url       = {https://arxiv.org/abs/2203.02053},
  year      = {2022}
}

@article{van2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Van den Oord, Aaron and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv e-prints},
  pages={arXiv--1807},
  year={2018}
}

@inproceedings{pivovarova2021visual,
  title={Visual Topic Modelling for {N}ews{I}mage Task at {M}edia{E}val 2021},
  author={Pivovarova, Lidia and Zosa, Elaine},
  booktitle={Working Notes Proceedings of the MediaEval 2021 Workshop},
  year={2021},
  organization={MediaEval}
}

@article{blei2003latent,
  title={Latent dirichlet allocation},
  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal={Journal of machine Learning research},
  volume={3},
  number={Jan},
  pages={993--1022},
  year={2003}
}

@inproceedings{kim2021vilt,
  title={Vilt: Vision-and-language transformer without convolution or region supervision},
  author={Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle={International Conference on Machine Learning},
  pages={5583--5594},
  year={2021},
  organization={PMLR}
}

@article{barnard2003matching,
  title={Matching words and pictures},
  author={Barnard, Kobus and Duygulu, Pinar and Forsyth, David and De Freitas, Nando and Blei, David M and Jordan, Michael I},
  year={2003},
  publisher={Test accounts}
}

@inproceedings{hoyle2020improving,
  title={Improving Neural Topic Models using Knowledge Distillation},
  author={Hoyle, Alexander Miserlis and Goel, Pranav and Resnik, Philip},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={1752--1771},
  year={2020}
}

@inproceedings{nan-etal-2019-topic,
    title = "Topic Modeling with {W}asserstein Autoencoders",
    author = "Nan, Feng  and
      Ding, Ran  and
      Nallapati, Ramesh  and
      Xiang, Bing",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1640",
    doi = "10.18653/v1/P19-1640",
    pages = "6345--6381",
    abstract = "We propose a novel neural topic model in the Wasserstein autoencoders (WAE) framework. Unlike existing variational autoencoder based models, we directly enforce Dirichlet prior on the latent document-topic vectors. We exploit the structure of the latent space and apply a suitable kernel in minimizing the Maximum Mean Discrepancy (MMD) to perform distribution matching. We discover that MMD performs much better than the Generative Adversarial Network (GAN) in matching high dimensional Dirichlet distribution. We further discover that incorporating randomness in the encoder output during training leads to significantly more coherent topics. To measure the diversity of the produced topics, we propose a simple topic uniqueness metric. Together with the widely used coherence measure NPMI, we offer a more wholistic evaluation of topic quality. Experiments on several real datasets show that our model produces significantly better topics than existing topic models.",
}

@inproceedings{jagarlamudi2010extracting,
  title={Extracting multilingual topics from unaligned comparable corpora},
  author={Jagarlamudi, Jagadeesh and Daum{\'e}, Hal},
  booktitle={European Conference on Information Retrieval},
  pages={444--456},
  year={2010},
  organization={Springer}
}

@inproceedings{roder2015exploring,
  title={Exploring the space of topic coherence measures},
  author={R{\"o}der, Michael and Both, Andreas and Hinneburg, Alexander},
  booktitle={Proceedings of the eighth ACM international conference on Web search and data mining},
  pages={399--408},
  year={2015}
}

@inproceedings{de2009cross,
  title={Cross-language linking of news stories on the web using interlingual topic modelling},
  author={De Smet, Wim and Moens, Marie-Francine},
  booktitle={Proceedings of the 2nd ACM workshop on Social web search and mining},
  pages={57--64},
  year={2009}
}

@article{zhang2020contrastive,
  title={Contrastive learning of medical visual representations from paired images and text},
  author={Zhang, Yuhao and Jiang, Hang and Miura, Yasuhide and Manning, Christopher D and Langlotz, Curtis P},
  journal={arXiv preprint arXiv:2010.00747},
  year={2020}
}

@inproceedings{roller2013multimodal,
  title={A multimodal LDA model integrating textual, cognitive and visual modalities},
  author={Roller, Stephen and Im Walde, Sabine Schulte},
  booktitle={Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
  pages={1146--1157},
  year={2013}
}

@inproceedings{feng2010visual,
  title={Visual information in semantic representation},
  author={Feng, Yansong and Lapata, Mirella},
  booktitle={Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  pages={91--99},
  year={2010}
}

@article{birhane2021multimodal,
  title={Multimodal datasets: misogyny, pornography, and malignant stereotypes},
  author={Birhane, Abeba and Prabhu, Vinay Uday and Kahembwe, Emmanuel},
  journal={arXiv preprint arXiv:2110.01963},
  year={2021}
}

@article{rogers2020primer,
  title={A primer in bertology: What we know about how bert works},
  author={Rogers, Anna and Kovaleva, Olga and Rumshisky, Anna},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={842--866},
  year={2020},
  publisher={MIT Press}
}

@inproceedings{rehurek2010software,
  title={Software framework for topic modelling with large corpora},
  author={Rehurek, Radim and Sojka, Petr},
  booktitle={In Proceedings of the LREC 2010 workshop on new challenges for NLP frameworks},
  year={2010},
  organization={Citeseer}
}

@article{griffiths2007topics,
  title={Topics in semantic representation.},
  author={Griffiths, Thomas L and Steyvers, Mark and Tenenbaum, Joshua B},
  journal={Psychological review},
  volume={114},
  number={2},
  pages={211},
  year={2007},
  publisher={American Psychological Association}
}

@article{li2022vision,
  title={Vision-Language Intelligence: Tasks, Representation Learning, and Large Models},
  author={Li, Feng and Zhang, Hao and Zhang, Yi-Fan and Liu, Shilong and Guo, Jian and Ni, Lionel M and Zhang, PengChuan and Zhang, Lei},
  journal={arXiv preprint arXiv:2203.01922},
  year={2022}
}

@inproceedings{an2020multimodal,
  title={Multimodal Topic-Enriched Auxiliary Learning for Depression Detection},
  author={An, Minghui and Wang, Jingjing and Li, Shoushan and Zhou, Guodong},
  booktitle={Proceedings of the 28th International Conference on Computational Linguistics},
  pages={1078--1089},
  year={2020}
}

@inproceedings{guo2022multilingual,
  title={Multilingual Molecular Representation Learning via Contrastive Pre-training},
  author={Guo, Zhihui and Sharma, Pramod and Martinez, Andy and Du, Liang and Abraham, Robin},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={3441--3453},
  year={2022}
}


@inproceedings{khattar2019mvae,
  title={Mvae: Multimodal variational autoencoder for fake news detection},
  author={Khattar, Dhruv and Goud, Jaipal Singh and Gupta, Manish and Varma, Vasudeva},
  booktitle={The world wide web conference},
  pages={2915--2921},
  year={2019}
}

@inproceedings{bruni2012distributional,
  title={Distributional semantics with eyes: Using image analysis to improve computational representations of word meaning},
  author={Bruni, Elia and Uijlings, Jasper and Baroni, Marco and Sebe, Nicu},
  booktitle={Proceedings of the 20th ACM international conference on Multimedia},
  pages={1219--1228},
  year={2012}
}

@article{barnard2005word,
  title={Word sense disambiguation with pictures},
  author={Barnard, Kobus and Johnson, Matthew},
  journal={Artificial Intelligence},
  volume={167},
  number={1-2},
  pages={13--30},
  year={2005},
  publisher={Elsevier}
}

@inproceedings{khorrami2021evaluation,
  title={Evaluation of audio-visual alignments in visually grounded speech models},
  author={Khorrami, Khazar and R{\"a}s{\"a}nen, Okko},
  booktitle={Interspeech},
  pages={1231--1235},
  year={2021},
  organization={International Speech Communication Association}
}

@inproceedings{mueller2021fine,
  title={Fine-tuning Encoders for Improved Monolingual and Zero-shot Polylingual Neural Topic Modeling},
  author={Mueller, Aaron and Dredze, Mark},
  booktitle={NAACL-HLT},
  year={2021}
}

@inproceedings{yang2019multilingual,
  title={A multilingual topic model for learning weighted topic links across corpora with low comparability},
  author={Yang, Weiwei and Boyd-Graber, Jordan and Resnik, Philip},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={1243--1248},
  year={2019}
}

@inproceedings{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  booktitle={NIPS Deep Learning and Representation Learning Workshop},
  year={2015}
}

@inproceedings{virtanen2012factorized,
  title={Factorized multi-modal topic model},
  author={Virtanen, Seppo and Jia, Yangqing and Klami, Arto and Darrell, Trevor},
  booktitle={Proceedings of the 28th Conference on Uncertainty in
Artificial Intelligence (UAI)},
  pages={843â€“851},    
  year={2012}
}