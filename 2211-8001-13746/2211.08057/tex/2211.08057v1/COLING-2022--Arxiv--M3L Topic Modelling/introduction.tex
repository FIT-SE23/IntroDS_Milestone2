Topic modelling is an unsupervised method initially designed for text data that extracts latent themes in documents through the co-occurrence statistics of the words in the documents. In most probabilistic topic models, a topic is a distribution over a vocabulary and a document is a distribution over topics~\cite{blei2003latent}. Multilingual topic models extend basic topic models for multilingual data by jointly training on multiple languages~\cite{mimno2009polylingual,hao2018learning}. These models learn aligned language-specific topics and have been used in different cross-lingual applications such as multilingual news clustering~\cite{de2009cross} and comparing discourses from different cultures in news and social media~\cite{shi2016detecting,gutierrez2016detecting}.

Most topic models are designed for textual data but there is also a rich body of work on applying topic modelling to images resulting in multimodal topic models~\cite{barnard2003matching,feng2010visual,roller2013multimodal}. These models use natural language supervision to improve the semantic representation of images. Augmenting topical information from text with topic information from visual inputs also produces better semantic representations of words.

Neural topic models have been proposed to improve on classical topic models and have resulted in models that are more computationally efficient and produces more coherent topics~\cite{srivastava2017autoencoding}. Moreover, the neural topic modelling framework has given rise to models that take advantage of information from external sources such as word embeddings~\cite{dieng2020topic} and contextualised language models~\cite{bianchi-etal-2021-pre,bianchi-etal-2021-cross,hoyle2020improving,mueller2021fine}.

In this work, we present a novel neural multilingual \textit{and} multimodal topic model that takes advantage of pretrained document and image embeddings to abstract the complexities between languages and modalities. Our work is based on the contextualized topic model~\cite[CTM,][]{bianchi-etal-2021-pre,bianchi-etal-2021-cross}, a family of topic models that uses contextualized document embeddings as input. 

We show that while ZeroshotTM~\cite{bianchi-etal-2021-cross}, a cross-lingual variant of CTM, can predict relevant topic distributions of documents in languages it has not seen during training, this ability does not transfer well to unseen modalities (e.g. images). Moreover, since ZeroshotTM only sees monolingual data, it produces monolingual topics that are inferred from documents in a single language. This approach does not take into account possible biases in worldviews that are hidden in different languages. %It has also been shown that zero-shot modelling tends to assign documents from an unseen language to only a small subset of available topics~\cite{mueller2021fine}.

Our approach, which we refer to as M3L-Contrast, trains jointly on multilingual texts and images with a contrastive objective. We show that our model produces better topic distributions for comparable texts and images compared to ZeroshotTM even with unaligned embeddings and our model also improves on a classical multilingual topic model for comparable multilingual data. The main contributions of this work are:
\begin{enumerate}[nosep]
    \item  We present a neural multimodal \textit{and} multilingual topic model for comparable data that maps images and texts into a shared topic space;
    \item we show that contrastive learning is effective in mapping embeddings from unaligned encoders into a shared topic space \textit{and} improves on the alignment of aligned embeddings; 
    \item we present a multilingual topic model for comparable multilingual data that uses pretrained embeddings and improves on a classical topic model for comparable data.\footnote{Our code is available at \url{https://github.com/ezosa/M3L-topic-model}}
    %\item We show that joint contrastive training helps produce better topic representation, while taking into account potential differences in worldviews hidden in different data views.
\end{enumerate}





