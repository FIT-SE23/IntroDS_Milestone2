\subsection*{Potential impact and risks}
Our models are currently for research purposes only. We do not advise that it be used in production settings. Our models might associate images of people and objects with negative and insensitive stereotypes if the training data has these associations. Since we use CLIP to encode texts and images in our experiments, our models might also perpetuate the harmful stereotypes found in the CLIP training data discussed in~\cite{birhane2021multimodal}. The same issue applies to the other pretrained encoders we use in our experiments.

%Furthermore, our models might associate images with topics that are inconsistent with the image content. Therefore these outputs must be used with caution in applications such as image tagging and image clustering.

%\subsection*{Intended use of datasets}
%The Wikipedia Image Text (WIT) dataset is for multimodal multilingual models and tasks. The Wikipedia Comparable Corpora is for multilingual/cross-lingual tasks. Since we link the images in WIT with full articles from the Comparable Corpus using article titles, we want to emphasize that these linked articles and images should not be used outside of research settings because we cannot guarantee that all the article-image associations are correct.