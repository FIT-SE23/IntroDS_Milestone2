\label{sec:ablation-study}


\begin{figure}[t!]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/ablation-topic-num-MRR.png}
    \caption{Effect of increasing topic numbers on cross-lingual retrieval performance (MRR).}
    \label{fig:text-only-topic-numbers}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/ablation-topic-num-UAP.png}
    \caption{Effect of increasing topic numbers on text-image retrieval performance (UAP).}
    \label{fig:text-images-topic-numbers}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.55\textwidth]{figures/ablation-M3LContrast-batch-sizes-text-only.png}
    \caption{Effect of different batch sizes on M3L-Contrast trained on multilingual text data.} %Cross-lingual retrieval (MRR) is best with batch size 32. Averaged JSD between matching articles goes down with increasing batch sizes but does not result in better retrieval performance.}
    \label{fig:text-only-batch-sizes}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.55\textwidth]{figures/ablation-M3LContrast-batch-sizes-text-images.png}
    \caption{Effect of different batch sizes for M3L-Contrast trained on multilingual text \textit{and} images.} %We show text-image retrieval (UAP) with English and German as query articles. Batch size 32 is best for English while 64 is best for German. JSD between matching articles and images goes down with increasing batch sizes but does not result in better retrieval performance.}
    \label{fig:text-images-batch-sizes}
\end{figure}

\begin{table*}[t!]
\centering
\begin{tabular}{l l | r r | r r | r r}
%\Xhline{1.5pt}
\hline
\multicolumn{2}{c}{\textbf{Encoders}} & \multicolumn{2}{c}{\textbf{EN-DE text}} &  \multicolumn{2}{c}{\textbf{EN-images}} & \multicolumn{2}{c}{\textbf{DE-images}}\\
%\Xhline{1.5pt} 
%\hline
\textbf{Text} & \textbf{Image}&  \textbf{MRR$\uparrow$} & \textbf{JSD$\downarrow$} & \textbf{UAP$\uparrow$} & \textbf{JSD$\downarrow$}  & \textbf{UAP$\uparrow$} & \textbf{JSD$\downarrow$} \\
\hline 
CLIP & CLIP & {0.613} & {0.035} & \textbf{0.125} & {0.130} & {0.102} & {0.147}\\
\hline
multilingual SBERT & CLIP & \textbf{0.716} & \textbf{0.029} & {0.119} & {0.137} & \textbf{0.114} & {0.147}\\
%\hline
monolingual SBERTs & CLIP & {0.407} & {0.052} & {0.118} & \textbf{0.129} & {0.102} & \textbf{0.141}\\
%\hline
multilingual SBERT & ResNet & {0.659} & {0.028} & {0.053} & {0.160} & {0.047} & {0.167}\\
%\hline
monolingual SBERTs & ResNet & {0.347} & {0.050} & {0.053} & {0.145} & {0.052} & {0.157}\\
\hline
\end{tabular}
\caption{Effect of different encoder combinations for M3L-Contrast trained on \textbf{multilingual text and images} compared to CLIP with 100 topics.}
\label{tab:text-images-encoders}
\end{table*}


\subsection{Topic numbers}
In Figure~\ref{fig:text-only-topic-numbers} we show the models' performance on cross-lingual text retrieval (MRR) for $[25, 50, 100]$ topics. ZeroshotTM performs best for all topic numbers followed by M3L-Contrast. Figure~\ref{fig:text-images-topic-numbers} shows the results for text-image retrieval (UAP). M3L-Contrast performs best for all topic numbers while ZeroshotTM performs worst. In general, performance improves as the topic number increases.

%As can be seen from Figures~\ref{fig:text-only-topic-numbers} and~\ref{fig:text-images-topic-numbers}, the retrieval performance increases with the number of topics. %However, optimizing a topic model with retrieval objective is dangerous since that would diminish the interpretability of the model. We noticed that as the number of topics increases the more topics appear to be redundant and or spurious topics. 
%The topic coherence, measured with NPMI, usually decreases with larger topic numbers. 

\subsection{Batch sizes for M3L-Contrast}
%We experiment with different batch sizes for the M3L-Contrast model is an critical hyperparameter in contrastive learning. 
We check batch sizes $[16, 32, 64, 128]$. Figure~\ref{fig:text-only-batch-sizes} shows the effect of increasing batch sizes for M3L-Contrast trained only on multilingual articles. We find that batch size 32 is the best for the multilingual setting. We also run similar experiments with multilingual text \textit{and} images (Figure~\ref{fig:text-images-batch-sizes}). In the multimodal setting, size 32 performs the best when English articles are matched to images while 64 is best for German. This is why we used batch size 32 for our experiments with M3L-Contrast. %For the rest of our M3L-Contrast experiments, we use batch size 32. 

%Interestingly, in both cases the divergence between corresponding articles decreases as the batch size grows but it does not result in better retrieval performance. This probably indicates the general limitation of topic modelling for retrieval tasks.



\subsection{Encoder combinations for M3L-Contrast}


To show how unaligned encoders perform with M3L-Contrast, we experiment with two encoder combinations: (1) a multilingual text encoder and an unaligned image encoder; and (2) unaligned monolingual text encoders and an unaligned image encoder. For this experiment, we train M3L-Contrast with multilingual articles \textit{and} images and evaluate the models on cross-lingual retrieval and text-image retrieval. Encoder details are in the Appendix. Results are shown in Table~\ref{tab:text-images-encoders}. 

For cross-lingual text retrieval, using a multilingual encoder performs best since this model is trained specifically on multilingual texts and has a larger embedding dimension than CLIP (768 and 512, respectively). For English text-image retrieval, it is expected that CLIP is the best since the text and image embeddings are already aligned (first row). CLIP image embeddings performed better than ResNet on all measures.

It is encouraging that M3L-Contrast with unaligned text and image embeddings still outperform ZeroshotTM and ZeroshotTM-KD (compare with Table~\ref{tab:results-text-images}, top part) even though those models use aligned embeddings. This shows that contrastive learning is effective in mapping unanligned embeddings into a shared topic space and that it is not necessary to use aligned embeddings in multimodal topic modelling. 

