
% gelu and softmax
i-bert approximation
@article{gelu_softmax_approx,
  author={Kim, Sehoon and Gholami, Amir and Yao, Zhewei and Mahoney, Michael W. and Keutzer, Kurt},
  title = {I-BERT: Integer-only BERT Quantization},
  journal = {arXiv preprint arXiv:2101.01321},
  year = {2021}
}

% sigmoid PLAN approximation 
@INPROCEEDINGS{sigmoid_approx,
  author={Tsmots, Ivan and Skorokhoda, Oleksa and Rabyk, Vasyl},
  booktitle={2019 IEEE 15th International Conference on the Experience of Designing and Application of CAD Systems (CADSM)}, 
  title={Hardware Implementation of Sigmoid Activation Functions using FPGA}, 
  year={2019},
  volume={},
  number={},
  pages={34-38},
  doi={10.1109/CADSM.2019.8779253}}

% vitis
@misc{vitis, 
  author = {Xilinx},
  year = {2022},
  title={Vitis Unified Software Platform},
  note = {Last accessed April 21, 2022},
  url={https://www.xilinx.com/products/design-tools/vitis/vitis-platform.html#development}}

% zcu102 
@misc{ZCU102, 
  author = {Xilinx},
  year = {2022},
  title={ZCU102 Evaluation Board - user guide},
  note = {Last accessed April 21, 2022},
  url={https://www.xilinx.com/content/dam/xilinx/support/documents/boards_and_kits/zcu102/ug1182-zcu102-eval-bd.pdf}}
  
  
% FPGA-based transformer
@inproceedings{li2020ftrans,
  title={Ftrans: energy-efficient acceleration of transformers using fpga},
  author={Li, Bingbing and Pandey, Santosh and Fang, Haowen and Lyv, Yanjun and Li, Ji and Chen, Jieyang and Xie, Mimi and Wan, Lipeng and Liu, Hang and Ding, Caiwen},
  pages={175--180},
  booktitle={Proceedings of the ACM/IEEE International Symposium on Low Power Electronics and Design},
  year={2020}
}

inproceedings{DAC22LBR,
  author = {Mengshu Sun and Zhengang Li and Alec Lu and Haoyu Ma and Geng Yuan and Yanyue Xie and Hao Tang and Yanyu Li and Miriam Leeser and Zhangyang Wang and Xue Lin and Zhenman Fang},
  title = {Late Breaking Results: FPGA-Aware Automatic Acceleration Framework for Vision Transformer with Mixed-Scheme Quantization},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 59th Annual Design Automation Conference},
  articleno = {74},
  numpages = {2},
  year = {2022}
}

@inproceedings{DAC22LBR,
  author = {Mengshu Sun and Zhengang Li and Alec Lu and Haoyu Ma and Geng Yuan and Yanyue Xie and Hao Tang and Yanyu Li and Miriam Leeser and Zhangyang Wang and Xue Lin and Zhenman Fang},
  title = {Late Breaking Results: FPGA-Aware Automatic Acceleration Framework for Vision Transformer with Mixed-Scheme Quantization},
  booktitle = {Proceedings of the 59th Annual Design Automation Conference},
  year = {2022}
}

@INPROCEEDINGS{FPT19gemm,
  author={Fox, Sean and Faraone, Julian and Boland, David and Vissers, Kees and Leong, Philip H.W.},
  booktitle={2019 International Conference on Field-Programmable Technology (ICFPT)}, 
  title={Training Deep Neural Networks in Low-Precision with High Accuracy Using FPGAs}, 
  year={2019},
  pages={1-9}
}

@inproceedings{qi2021accommodating,
  title={Accommodating Transformer onto FPGA: Coupling the Balanced Model Compression and FPGA-Implementation Optimization},
  author={Qi, Panjie and Song, Yuhong and Peng, Hongwu and Huang, Shaoyi and Zhuge, Qingfeng and Sha, Edwin Hsing-Mean},
  pages={163--168},
  booktitle={Proceedings of the 2021 on Great Lakes Symposium on VLSI},
  year={2021}
}

@inproceedings{peng2021accelerating,
  title={Accelerating Transformer-based Deep Learning Models on FPGAs using Column Balanced Block Pruning},
  author={Peng, Hongwu and Huang, Shaoyi and Geng, Tong and Li, Ang and Jiang, Weiwen and Liu, Hang and Wang, Shusen and Ding, Caiwen},
  pages={142--148},
  organization={IEEE},
  booktitle={2021 22nd International Symposium on Quality Electronic Design (ISQED)},
  year={2021}
}

@article{zhang2021algorithm,
  title={Algorithm-hardware Co-design of Attention Mechanism on FPGA Devices},
  author={Zhang, Xinyi and Wu, Yawen and Zhou, Peipei and Tang, Xulong and Hu, Jingtong},
  volume={20},
  number={5s},
  pages={1--24},
  journal={ACM Transactions on Embedded Computing Systems (TECS)},
  year={2021},
  publisher={ACM New York, NY}
}

% transformer
@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  pages={5998--6008},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

% Classification
% ViT
@inproceedings{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

% DeiT
@inproceedings{Touvron2021TrainingDI,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Hugo Touvron and Matthieu Cord and Matthijs Douze and Francisco Massa and Alexandre Sablayrolles and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={10347--10357},
  year={2021}
}


@inproceedings{yuan2021tokens,
  title={Tokens-to-token vit: Training vision transformers from scratch on imagenet},
  author={Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zi-Hang and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={558--567},
  year={2021}
}

%%%%%%

@inproceedings{zhang2015optimizing,
  title={Optimizing fpga-based accelerator design for deep convolutional neural networks},
  author={Zhang, Chen and Li, Peng and Sun, Guangyu and Guan, Yijin and Xiao, Bingjun and Cong, Jason},
  booktitle={Proceedings of the 2015 ACM/SIGDA international symposium on field-programmable gate arrays},
  pages={161--170},
  year={2015}
}

@article{zhang2018caffeine,
  title={Caffeine: Toward uniformed representation and acceleration for deep convolutional neural networks},
  author={Zhang, Chen and Sun, Guangyu and Fang, Zhenman and Zhou, Peipei and Pan, Peichen and Cong, Jason},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  volume={38},
  number={11},
  pages={2072--2085},
  year={2018},
  publisher={IEEE}
}

@misc{Torchvision,
author = {{Facebook}},
title={Torchvision},
note = {Last accessed Sept 12, 2021},
year = {2021},
url = {https://pytorch.org/vision/stable/models.html}}

@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{li2021mhformer,
  title={MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation},
  author={Li, Wenhao and Liu, Hong and Tang, Hao and Wang, Pichao and Van Gool, Luc},
  journal={arXiv preprint arXiv:2111.12707},
  year={2021}
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
pages = {234--778},
year = 2005
}

@article{ding2021looking,
  title={Looking Outside the Window: Wide-Context Transformer for the Semantic Segmentation of High-Resolution Remote Sensing Images},
  author={Ding, Lei and Lin, Dong and Lin, Shaofu and Zhang, Jing and Cui, Xiaojie and Wang, Yuebin and Tang, Hao and Bruzzone, Lorenzo},
  journal={arXiv preprint arXiv:2106.15754},
  year={2021}
}


@inproceedings{chen2021aniformer,
  title={AniFormer: Data-driven 3D Animation with Transformer},
  author={Chen, Haoyu and Tang, Hao and Sebe, Nicu and Zhao, Guoying},
  booktitle={BMVC},
  year={2021}
}


@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@inproceedings{yang2021transformers,
  title={Transformer-Based Attention Networks for Continuous Pixel-Wise Prediction},
  author={Yang, Guanglei and Tang, Hao and Ding, Mingli and Sebe, Nicu and Ricci, Elisa},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{
dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations (ICLR)},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}

@inproceedings{dai2021up,
  title={Up-detr: Unsupervised pre-training for object detection with transformers},
  author={Dai, Zhigang and Cai, Bolun and Lin, Yugeng and Chen, Junying},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={1601--1610},
  year={2021}
}
@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={213--229},
  year={2020},
  organization={Springer}
}

@inproceedings{chen2021transformer,
  title={Transformer tracking},
  author={Chen, Xin and Yan, Bin and Zhu, Jiawen and Wang, Dong and Yang, Xiaoyun and Lu, Huchuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={8126--8135},
  year={2021}
}
@inproceedings{zheng2021rethinking,
  title={Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers},
  author={Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={6881--6890},
  year={2021}
}

@inproceedings{yang2020learning,
  title={Learning texture transformer network for image super-resolution},
  author={Yang, Fuzhi and Yang, Huan and Fu, Jianlong and Lu, Hongtao and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={5791--5800},
  year={2020}
}
@inproceedings{chen2021pre,
  title={Pre-trained image processing transformer},
  author={Chen, Hanting and Wang, Yunhe and Guo, Tianyu and Xu, Chang and Deng, Yiping and Liu, Zhenhua and Ma, Siwei and Xu, Chunjing and Xu, Chao and Gao, Wen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={12299--12310},
  year={2021}
}
@inproceedings{guo2020accelerating,
  title={Accelerating sparse dnn models without hardware-support via tile-wise sparsity},
  author={Guo, Cong and Hsueh, Bo Yang and Leng, Jingwen and Qiu, Yuxian and Guan, Yue and Wang, Zehuan and Jia, Xiaoying and Li, Xipeng and Guo, Minyi and Zhu, Yuhao},
  booktitle={SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--15},
  year={2020},
  organization={IEEE}
}

@inproceedings{li2020efficient,
  title={Efficient transformer-based large scale language representations using hardware-friendly block structured pruning},
  author={Li, Bingbing and Kong, Zhenglun and Zhang, Tianyun and Li, Ji and Li, Zhengang and Liu, Hang and Ding, Caiwen},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2020},
  year={2020}
}
@inproceedings{chen2021chasing,
  title={Chasing Sparsity in Vision Transformers: An End-to-End Exploration},
  author={Chen, Tianlong and Cheng, Yu and Gan, Zhe and Yuan, Lu and Zhang, Lei and Wang, Zhangyang},
  booktitle = {Advances in Neural Information Processing Systems},
  year={2021}
}

@inproceedings{rao2021dynamicvit,
  title={DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification},
  author={Rao, Yongming and Zhao, Wenliang and Liu, Benlin and Lu, Jiwen and Zhou, Jie and Hsieh, Cho-Jui},
  booktitle = {Advances in Neural Information Processing Systems},
  year={2021}
}
@inproceedings{pan2021iared2,
      title={IA-RED$^2$: Interpretability-Aware Redundancy Reduction for Vision Transformers}, 
      booktitle = {Advances in Neural Information Processing Systems},
      author={Bowen Pan and Yifan Jiang and Rameswar Panda and Zhangyang Wang and Rogerio Feris and Aude Oliva},
      year={2021},
}
@article{fayyaz2021,
  title={ATS: Adaptive Token Sampling For Efficient Vision Transformers},
  author={Fayyaz, Mohsen and Kouhpayegani, Soroush Abbasi and Jafari, Farnoush Rezaei and Sommerlade, Eric and Joze, Hamid Reza Vaezi and Pirsiavash, Hamed and Gall, Juergen},
  journal={arXiv preprint arXiv:2111.15667},
  year={2021}
}

@article{chen2021exploring,
  title={Exploring and Improving Mobile Level Vision Transformers},
  author={Chen, Pengguang and Chen, Yixin and Liu, Shu and Yang, Mingchang and Jia, Jiaya},
  journal={arXiv preprint arXiv:2108.13015},
  year={2021}
}
@article{xu2021evo,
  title={Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transformer},
  author={Xu, Yifan and Zhang, Zhijie and Zhang, Mengdan and Sheng, Kekai and Li, Ke and Dong, Weiming and Zhang, Liqing and Xu, Changsheng and Sun, Xing},
  journal={arXiv preprint arXiv:2108.01390},
  year={2021}
}

@inproceedings{heo2021pit,
    title={Rethinking Spatial Dimensions of Vision Transformers},
    author={Byeongho Heo and Sangdoo Yun and Dongyoon Han and Sanghyuk Chun and Junsuk Choe and Seong Joon Oh},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year={2021},
}
@article{jiang2021all,
  title={All Tokens Matter: Token Labeling for Training Better Vision Transformers},
  author={Jiang, Zihang and Hou, Qibin and Yuan, Li and Zhou, Daquan and Shi, Yujun and Jin, Xiaojie and Wang, Anran and Feng, Jiashi},
  journal={arXiv preprint arXiv:2104.10858},
  year={2021}
}

@inproceedings{zhu2021visual,
  title={Visual Transformer Pruning},
  author={Zhu, Mingjian and Han, Kai and Tang, Yehui and Wang, Yunhe},
  booktitle={KDD 2021 Workshop on Model Mining},
  year={2021}
}
@inproceedings{ryoo2021tokenlearner,
      title={TokenLearner: What Can 8 Learned Tokens Do for Images and Videos?}, 
      author={Michael S. Ryoo and AJ Piergiovanni and Anurag Arnab and Mostafa Dehghani and Anelia Angelova},
  booktitle = {Advances in Neural Information Processing Systems},
  year={2021}
}
@InProceedings{Yuan_2021_ICCV,
    author    = {Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zi-Hang and Tay, Francis E.H. and Feng, Jiashi and Yan, Shuicheng},
    title     = {Tokens-to-Token ViT: Training Vision Transformers From Scratch on ImageNet},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {558-567}
}
@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={248--255},
  year={2009},
  organization={Ieee}
}
 

@InProceedings{Yue_2021_ICCV,
    author    = {Yue, Xiaoyu and Sun, Shuyang and Kuang, Zhanghui and Wei, Meng and Torr, Philip H.S. and Zhang, Wayne and Lin, Dahua},
    title     = {Vision Transformer With Progressive Sampling},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {387-396}
}
@misc{tang2021patch,
      title={Patch Slimming for Efficient Vision Transformers}, 
      author={Yehui Tang and Kai Han and Yunhe Wang and Chang Xu and Jianyuan Guo and Chao Xu and Dacheng Tao},
      year={2021},
      eprint={2106.02852},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@InProceedings{Graham_2021_ICCV,
    author    = {Graham, Benjamin and El-Nouby, Alaaeldin and Touvron, Hugo and Stock, Pierre and Joulin, Armand and Jegou, Herve and Douze, Matthijs},
    title     = {LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {12259-12269}
}
@article{liu2021Swin,
  title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  journal={International Conference on Computer Vision (ICCV)},
  year={2021}
}
@InProceedings{Yuank_2021_ICCV,
    author    = {Yuan, Kun and Guo, Shaopeng and Liu, Ziwei and Zhou, Aojun and Yu, Fengwei and Wu, Wei},
    title     = {Incorporating Convolution Designs Into Visual Transformers},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {579-588}
}
@inproceedings{wang2021pyramid,
  title={Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021}
}
%added new
@inproceedings{han2021transformer,
  title={Transformer in transformer},
  author={Han, Kai and Xiao, An and Wu, Enhua and Guo, Jianyuan and Xu, Chunjing and Wang, Yunhe},
  booktitle = {Advances in Neural Information Processing Systems},
  year={2021}
}
@article{amini2021t6d,
  title={T6D-Direct: Transformers for Multi-Object 6D Pose Direct Regression},
  author={Amini, Arash and Periyasamy, Arul Selvam and Behnke, Sven},
  journal={arXiv preprint arXiv:2109.10948},
  year={2021}
}
@inproceedings{misra2021-3detr,
    title={{An End-to-End Transformer Model for 3D Object Detection}},
    author={Misra, Ishan and Girdhar, Rohit and Joulin, Armand},
    booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year={2021},
}
@article{chen2021crossvit,
  title={Crossvit: Cross-attention multi-scale vision transformer for image classification},
  author={Chen, Chun-Fu and Fan, Quanfu and Panda, Rameswar},
  journal={arXiv preprint arXiv:2103.14899},
  year={2021}
}
@misc{guo2021sotr,
      title={SOTR: Segmenting Objects with Transformers}, 
      author={Ruohao Guo and Dantong Niu and Liao Qu and Zhenbo Li},
      year={2021},
      eprint={2108.06747},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@inproceedings{wu2021rethinking,
  title={Rethinking and improving relative position encoding for vision transformer},
  author={Wu, Kan and Peng, Houwen and Chen, Minghao and Fu, Jianlong and Chao, Hongyang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={10033--10041},
  year={2021}
}

@inproceedings{chen2021autoformer,
  title={Autoformer: Searching transformers for visual recognition},
  author={Chen, Minghao and Peng, Houwen and Fu, Jianlong and Ling, Haibin},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={12270--12280},
  year={2021}
}
@inproceedings{chefer2021transformer,
  title={Transformer interpretability beyond attention visualization},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={782--791},
  year={2021}
}
@article{lu2021efficient,
  title={Efficient Transformer for Single Image Super-Resolution},
  author={Lu, Zhisheng and Liu, Hong and Li, Juncheng and Zhang, Linlin},
  journal={arXiv preprint arXiv:2108.11084},
  year={2021}
}
@article{cheng2021per,
  title={Per-pixel classification is not all you need for semantic segmentation},
  author={Cheng, Bowen and Schwing, Alexander G and Kirillov, Alexander},
  journal={arXiv preprint arXiv:2107.06278},
  year={2021}
}

@article{raghu2021vision,
  title={Do Vision Transformers See Like Convolutional Neural Networks?},
  author={Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
  journal={arXiv preprint arXiv:2108.08810},
  year={2021}
}
@misc{yang2021focal,
      title={Focal Self-attention for Local-Global Interactions in Vision Transformers}, 
      author={Jianwei Yang and Chunyuan Li and Pengchuan Zhang and Xiyang Dai and Bin Xiao and Lu Yuan and Jianfeng Gao},
      year={2021},
      eprint={2107.00641},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}%
@article{chen2021psvit,
  title={PSViT: Better Vision Transformer via Token Pooling and Attention Sharing},
  author={Chen, Boyu and Li, Peixia and Li, Baopu and Li, Chuming and Bai, Lei and Lin, Chen and Sun, Ming and Yan, Junjie and Ouyang, Wanli},
  journal={arXiv preprint arXiv:2108.03428},
  year={2021}
}
@article{steiner2021train,
  title={How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers},
  author={Steiner, Andreas and Kolesnikov, Alexander and Zhai, Xiaohua and Wightman, Ross and Uszkoreit, Jakob and Beyer, Lucas},
  journal={arXiv preprint arXiv:2106.10270},
  year={2021}
}
@article{el2021xcit,
  title={XCiT: Cross-Covariance Image Transformers},
  author={El-Nouby, Alaaeldin and Touvron, Hugo and Caron, Mathilde and Bojanowski, Piotr and Douze, Matthijs and Joulin, Armand and Laptev, Ivan and Neverova, Natalia and Synnaeve, Gabriel and Verbeek, Jakob and others},
  journal={arXiv preprint arXiv:2106.09681},
  year={2021}
}
@article{zhai2021scaling,
  title={Scaling vision transformers},
  author={Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  journal={arXiv preprint arXiv:2106.04560},
  year={2021}
}
@misc{lin2021cat,
      title={CAT: Cross Attention in Vision Transformer}, 
      author={Hezheng Lin and Xing Cheng and Xiangyu Wu and Fan Yang and Dong Shen and Zhongyuan Wang and Qing Song and Wei Yuan},
      year={2021},
      eprint={2106.05786},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{huang2021shuffle,
      title={Shuffle Transformer: Rethinking Spatial Shuffle for Vision Transformer}, 
      author={Zilong Huang and Youcheng Ben and Guozhong Luo and Pei Cheng and Gang Yu and Bin Fu},
      year={2021},
      eprint={2106.03650},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{liu2021efficient,
  title={Efficient Training of Visual Transformers with Small-Size Datasets},
  author={Liu, Yahui and Sangineto, Enver and Bi, Wei and Sebe, Nicu and Lepri, Bruno and De Nadai, Marco},
  journal={arXiv preprint arXiv:2106.03746},
  year={2021}
}
@misc{zhou2021refiner,
      title={Refiner: Refining Self-attention for Vision Transformers}, 
      author={Daquan Zhou and Yujun Shi and Bingyi Kang and Weihao Yu and Zihang Jiang and Yuan Li and Xiaojie Jin and Qibin Hou and Jiashi Feng},
      year={2021},
      eprint={2106.03714},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{chen2021regionvit,
      title={RegionViT: Regional-to-Local Attention for Vision Transformers}, 
      author={Chun-Fu Chen and Rameswar Panda and Quanfu Fan},
      year={2021},
      eprint={2106.02689},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@inproceedings{yu2021glance,
  title={Glance-and-Gaze Vision Transformer},
  author={Yu, Qihang and Xia, Yingda and Bai, Yutong and Lu, Yongyi and Yuille, Alan and Shen, Wei},
  booktitle = {Advances in Neural Information Processing Systems},
  year={2021}
}
@article{chen2021vision,
  title={When Vision Transformers Outperform ResNets without Pretraining or Strong Data Augmentations},
  author={Chen, Xiangning and Hsieh, Cho-Jui and Gong, Boqing},
  journal={arXiv preprint arXiv:2106.01548},
  year={2021}
}
@article{wang2021kvt,
  title={KVT: k-NN Attention for Boosting Vision Transformers},
  author={Wang, Pichao and Wang, Xue and Wang, Fan and Lin, Ming and Chang, Shuning and Xie, Wen and Li, Hao and Jin, Rong},
  journal={arXiv preprint arXiv:2106.00515},
  year={2021}
}
@misc{li2021localvit,
      title={LocalViT: Bringing Locality to Vision Transformers}, 
      author={Yawei Li and Kai Zhang and Jiezhang Cao and Radu Timofte and Luc Van Gool},
      year={2021},
      eprint={2104.05707},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{sanh2020movement,
  title={Movement pruning: Adaptive sparsity by fine-tuning},
  author={Sanh, Victor and Wolf, Thomas and Rush, Alexander M},
  journal={arXiv preprint arXiv:2005.07683},
  year={2020}
}
@inproceedings{ren2019admm,
  title={Admm-nn: An algorithm-hardware co-design framework of dnns using alternating direction methods of multipliers},
  author={Ren, Ao and Zhang, Tianyun and Ye, Shaokai and Li, Jiayu and Xu, Wenyao and Qian, Xuehai and Lin, Xue and Wang, Yanzhi},
  booktitle={Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems},
  pages={925--938},
  year={2019}
}

@inproceedings{liu2017learning,
  title={Learning efficient convolutional networks through network slimming},
  author={Liu, Zhuang and Li, Jianguo and Shen, Zhiqiang and Huang, Gao and Yan, Shoumeng and Zhang, Changshui},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={2736--2744},
  year={2017}
}
@inproceedings{wang2021spatten,
  title={SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning},
  author={Wang, Hanrui and Zhang, Zhekai and Han, Song},
  booktitle={2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA)},
  pages={97--110},
  year={2021},
  organization={IEEE}
}
@article{xu2021you,
  title={You Only Group Once: Efficient Point-Cloud Processing with Token Representation and Relation Inference Module},
  author={Xu, Chenfeng and Zhai, Bohan and Wu, Bichen and Li, Tian and Zhan, Wei and Vajda, Peter and Keutzer, Kurt and Tomizuka, Masayoshi},
  journal={arXiv preprint arXiv:2103.09975},
  year={2021}
}
@article{wu2020visual,
  title={Visual transformers: Token-based image representation and processing for computer vision},
  author={Wu, Bichen and Xu, Chenfeng and Dai, Xiaoliang and Wan, Alvin and Zhang, Peizhao and Yan, Zhicheng and Tomizuka, Masayoshi and Gonzalez, Joseph and Keutzer, Kurt and Vajda, Peter},
  journal={arXiv preprint arXiv:2006.03677},
  year={2020}
}
@article{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  journal={arXiv preprint arXiv:2104.14294},
  year={2021}
}
@article{bao2021beit,
  title={BEiT: BERT Pre-Training of Image Transformers},
  author={Bao, Hangbo and Dong, Li and Wei, Furu},
  journal={arXiv preprint arXiv:2106.08254},
  year={2021}
}
@inproceedings{yang2021instance,
  title={Instance localization for self-supervised detection pretraining},
  author={Yang, Ceyuan and Wu, Zhirong and Zhou, Bolei and Lin, Stephen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={3987--3996},
  year={2021}
}
%
@article{chen2021pix2seq,
  title={Pix2seq: A Language Modeling Framework for Object Detection},
  author={Chen, Ting and Saxena, Saurabh and Li, Lala and Fleet, David J and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:2109.10852},
  year={2021}
}
@article{hudson2021ganformer,
  title={Generative Adversarial Transformers},
  author={Hudson, Drew A and Zitnick, C. Lawrence},
  journal={International Conference on Machine Learning (ICML)},
  year={2021}
}
@inproceedings{kim2021hotr,
  title={HOTR: End-to-End Human-Object Interaction Detection with Transformers},
  author={Kim, Bumsoo and Lee, Junhyun and Kang, Jaewoo and Kim, Eun-Sol and Kim, Hyunwoo J},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={74--83},
  year={2021}
}
@inproceedings{prillo2020softsort,
  title={SoftSort: A continuous relaxation for the argsort operator},
  author={Prillo, Sebastian and Eisenschlos, Julian},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={7793--7802},
  year={2020},
  organization={PMLR}
}
@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={7132--7141},
  year={2018}
}
@inproceedings{mao2021dual,
  title={Dual-stream Network for Visual Recognition},
  author={Mao, Mingyuan and Zhang, Renrui and Zheng, Honghui and Gao, Peng and Ma, Teli and Peng, Yan and Ding, Errui and Han, Shumin},
  booktitle = {Advances in Neural Information Processing Systems},
  year={2021}
}
@article{gao2021container,
  title={Container: Context Aggregation Network},
  author={Gao, Peng and Lu, Jiasen and Li, Hongsheng and Mottaghi, Roozbeh and Kembhavi, Aniruddha},
  journal={arXiv preprint arXiv:2106.01401},
  year={2021}
}
@article{deng2021transvg,
  title={TransVG: End-to-End Visual Grounding with Transformers},
  author={Deng, Jiajun and Yang, Zhengyuan and Chen, Tianlang and Zhou, Wengang and Li, Houqiang},
  journal={arXiv preprint arXiv:2104.08541},
  year={2021}
}
@inproceedings{xue2021transfer,
  title={TransFER: Learning Relation-aware Facial Expression Representations with Transformers},
  author={Xue, Fanglei and Wang, Qiangchang and Guo, Guodong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={3601--3610},
  year={2021}
}
@article{yan2021learning,
  title={Learning spatio-temporal transformer for visual tracking},
  author={Yan, Bin and Peng, Houwen and Fu, Jianlong and Wang, Dong and Lu, Huchuan},
  journal={arXiv preprint arXiv:2103.17154},
  year={2021}
}
@article{meinhardt2021trackformer,
  title={Trackformer: Multi-object tracking with transformers},
  author={Meinhardt, Tim and Kirillov, Alexander and Leal-Taixe, Laura and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2101.02702},
  year={2021}
}
@inproceedings{zhao2021point,
  title={Point transformer},
  author={Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip HS and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={16259--16268},
  year={2021}
}
@inproceedings{li2021revisiting,
  title={Revisiting stereo depth estimation from a sequence-to-sequence perspective with transformers},
  author={Li, Zhaoshuo and Liu, Xingtong and Drenkow, Nathan and Ding, Andy and Creighton, Francis X and Taylor, Russell H and Unberath, Mathias},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={6197--6206},
  year={2021}
}
@article{Guo_2021,
   title={PCT: Point cloud transformer},
   volume={7},
   ISSN={2096-0662},
   url={http://dx.doi.org/10.1007/s41095-021-0229-5},
   DOI={10.1007/s41095-021-0229-5},
   number={2},
   journal={Computational Visual Media},
   publisher={Springer Science and Business Media LLC},
   author={Guo, Meng-Hao and Cai, Jun-Xiong and Liu, Zheng-Ning and Mu, Tai-Jiang and Martin, Ralph R. and Hu, Shi-Min},
   year={2021},
   month={Apr},
   pages={187–199}
}
@article{chu2021conditional,
  title={Conditional positional encodings for vision transformers},
  author={Chu, Xiangxiang and Tian, Zhi and Zhang, Bo and Wang, Xinlong and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  journal={arXiv preprint arXiv:2102.10882},
  year={2021}
}
@inproceedings{pan2021scalable,
  title={Scalable vision transformers with hierarchical pooling},
  author={Pan, Zizheng and Zhuang, Bohan and Liu, Jing and He, Haoyu and Cai, Jianfei},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={377--386},
  year={2021}
}
@article{jia2021efficient,
  title={Efficient vision transformers via fine-grained manifold distillation},
  author={Jia, Ding and Han, Kai and Wang, Yunhe and Tang, Yehui and Guo, Jianyuan and Zhang, Chao and Tao, Dacheng},
  journal={arXiv preprint arXiv:2107.01378},
  year={2021}
}
@article{xu2021co,
  title={Co-scale conv-attentional image transformers},
  author={Xu, Weijian and Xu, Yifan and Chang, Tyler and Tu, Zhuowen},
  journal={arXiv preprint arXiv:2104.06399},
  year={2021}
}
@article{wu2021cvt,
  title={Cvt: Introducing convolutions to vision transformers},
  author={Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},
  journal={arXiv preprint arXiv:2103.15808},
  year={2021}
}
@inproceedings{radosavovic2020designing,
  title={Designing network design spaces},
  author={Radosavovic, Ilija and Kosaraju, Raj Prateek and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={10428--10436},
  year={2020}
}
@inproceedings{srinivas2021bottleneck,
  title={Bottleneck transformers for visual recognition},
  author={Srinivas, Aravind and Lin, Tsung-Yi and Parmar, Niki and Shlens, Jonathon and Abbeel, Pieter and Vaswani, Ashish},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={16519--16529},
  year={2021}
}
@article{el2021training,
  title={Training vision transformers for image retrieval},
  author={El-Nouby, Alaaeldin and Neverova, Natalia and Laptev, Ivan and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:2102.05644},
  year={2021}
}
@article{yu2021unified,
  title={A Unified Pruning Framework for Vision Transformers},
  author={Yu, Hao and Wu, Jianxin},
  journal={arXiv preprint arXiv:2111.15127},
  year={2021}
}

@inproceedings{miech2021thinking,
  title={Thinking Fast and Slow: Efficient Text-to-Visual Retrieval with Transformers},
  author={Miech, Antoine and Alayrac, Jean-Baptiste and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={9826--9836},
  year={2021}
}

@inproceedings{10.5555/2969239.2969366,
  title={Learning Both Weights and Connections for Efficient Neural Networks},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William J.},
  booktitle = {Advances in Neural Information Processing Systems},
  year={2015}
}

@inproceedings{kornblith2019similarity,
  title={Similarity of neural network representations revisited},
  author={Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={3519--3529},
  year={2019},
  organization={PMLR}
}

% pruning
@article{wen2016learning,
  title={Learning structured sparsity in deep neural networks},
  author={Wen, Wei and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{mao2017exploring,
  title={Exploring the granularity of sparsity in convolutional neural networks},
  author={Mao, Huizi and Han, Song and Pool, Jeff and Li, Wenshuo and Liu, Xingyu and Wang, Yu and Dally, William J},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={13--20},
  year={2017}
}

@inproceedings{ma2020pconv,
  title={Pconv: The missing but desirable sparsity in dnn weight pruning for real-time execution on mobile devices},
  author={Ma, Xiaolong and Guo, Fu-Ming and Niu, Wei and Lin, Xue and Tang, Jian and Ma, Kaisheng and Ren, Bin and Wang, Yanzhi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={5117--5124},
  year={2020}
}
@inproceedings{niu2020patdnn,
  title={Patdnn: Achieving real-time dnn execution on mobile devices with pattern-based weight pruning},
  author={Niu, Wei and Ma, Xiaolong and Lin, Sheng and Wang, Shihao and Qian, Xuehai and Lin, Xue and Wang, Yanzhi and Ren, Bin},
  booktitle={Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems},
  pages={907--922},
  year={2020}
}

@inproceedings{han2015deep,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={International Conference on Learning Representations (ICLR)},
  year={2016}
}

% EViT
@inproceedings{liang2021evit,
  title={EViT: Expediting Vision Transformers via Token Reorganizations},
  author={Liang, Youwei and Chongjian, GE and Tong, Zhan and Song, Yibing and Wang, Jue and Xie, Pengtao},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

% UVC
@inproceedings{yu2022unified,
  title={Unified Visual Transformer Compression},
  author={Shixing Yu and Tianlong Chen and Jiayi Shen and Huan Yuan and Jianchao Tan and Sen Yang and Ji Liu and Zhangyang Wang},
  booktitle={International Conference on Learning Representations},
  year={2022}
}
%%%%%%

@article{basha2020impact,
  title={Impact of fully connected layers on performance of convolutional neural networks for image classification},
  author={Basha, SH Shabbeer and Dubey, Shiv Ram and Pulabaigari, Viswanath and Mukherjee, Snehasis},
  journal={Neurocomputing},
  volume={378},
  pages={112--119},
  year={2020},
  publisher={Elsevier}
}

@article{sun2022vaqf,
  title={VAQF: Fully Automatic Software-hardware Co-design Framework for Low-bit Vision Transformer},
  author={Sun, Mengshu and Ma, Haoyu and Kang, Guoliang and Jiang, Yifan and Chen, Tianlong and Ma, Xiaolong and Wang, Zhangyang and Wang, Yanzhi},
  journal={arXiv preprint arXiv:2201.06618},
  year={2022}
}

@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{agarap2018deep,
  title={Deep learning using rectified linear units (relu)},
  author={Agarap, Abien Fred},
  journal={arXiv preprint arXiv:1803.08375},
  year={2018}
}

@inproceedings{howard2019searching,
  title={Searching for mobilenetv3},
  author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1314--1324},
  year={2019}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{niu2021grim,
  title={Grim: A general, real-time deep learning inference framework for mobile devices based on fine-grained structured weight sparsity},
  author={Niu, Wei and Li, Zhengang and Ma, Xiaolong and Dong, Peiyan and Zhou, Gang and Qian, Xuehai and Lin, Xue and Wang, Yanzhi and Ren, Bin},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2021},
  publisher={IEEE}
}

@article{kong2021spvit,
  title={SPViT: Enabling Faster Vision Transformers via Soft Token Pruning},
  author={Kong, Zhenglun and Dong, Peiyan and Ma, Xiaolong and Meng, Xin and Niu, Wei and Sun, Mengshu and Ren, Bin and Qin, Minghai and Tang, Hao and Wang, Yanzhi},
  journal={arXiv preprint arXiv:2112.13890},
  year={2021}
}

@inproceedings{
liang2022evit,
title={{EV}iT: Expediting Vision Transformers via Token Reorganizations},
author={Youwei Liang and Chongjian GE and Zhan Tong and Yibing Song and Jue Wang and Pengtao Xie},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=BjyvwnXXVn_}
}

%%% FILM-QNN

@inproceedings{sun2022film-qnn,
author = {Sun, Mengshu and Li, Zhengang and Lu, Alec and Li, Yanyu and Chang, Sung-En and Ma, Xiaolong and Lin, Xue and Fang, Zhenman},
title = {FILM-QNN: Efficient FPGA Acceleration of Deep Neural Networks with Intra-Layer, Mixed-Precision Quantization},
year = {2022}, 
booktitle = {Proceedings of the 2022 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA)},
pages = {134–145}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{mitchell1999machine,
  title={Machine learning and data mining},
  author={Mitchell, Tom M},
  journal={Communications of the ACM},
  volume={42},
  number={11},
  pages={30--36},
  year={1999},
  publisher={ACM New York, NY, USA}
}

@inproceedings{fox2019training,
  title={Training deep neural networks in low-precision with high accuracy using FPGAs},
  author={Fox, Sean and Faraone, Julian and Boland, David and Vissers, Kees and Leong, Philip HW},
  booktitle={2019 International Conference on Field-Programmable Technology (ICFPT)},
  pages={1--9},
  year={2019},
  organization={IEEE}
}



@inproceedings{bahdanau2015neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyung Hyun and Bengio, Yoshua},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2015}
}
@inproceedings{parikh2016decomposable,
  title={A Decomposable Attention Model for Natural Language Inference},
  author={Parikh, Ankur and T{\"a}ckstr{\"o}m, Oscar and Das, Dipanjan and Uszkoreit, Jakob},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages={2249--2255},
  year={2016}
}
@inproceedings{kenton2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of NAACL-HLT},
  pages={4171--4186},
  year={2019}
}
@inproceedings{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and  Agarwal, Sandhini and Herbert-Voss, Ariel and  Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and  Gray, Scott and  Chess, Benjamin and  Clark,  Jack and  Berner, Christopher and McCandlish, Sam and  Radford, Alec and  Sutskever, Ilya and Amodei, Dario},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={33},
  pages={1877--1901},
  year={2020}
  }
@inproceedings{zhu2020deformable,
  title={Deformable DETR: Deformable Transformers for End-to-End Object Detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}
@inproceedings{zhou2018end,
  title={End-to-end dense video captioning with masked transformer},
  author={Zhou, Luowei and Zhou, Yingbo and Corso, Jason J and Socher, Richard and Xiong, Caiming},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={8739--8748},
  year={2018}
}
@article{cao2021swin,
  title={Swin-unet: Unet-like pure transformer for medical image segmentation},
  author={Cao, Hu and Wang, Yueyue and Chen, Joy and Jiang, Dongsheng and Zhang, Xiaopeng and Tian, Qi and Wang, Manning},
  journal={arXiv preprint arXiv:2105.05537},
  year={2021}
}
@inproceedings{zhao2020investigation,
  title={An investigation on different underlying quantization schemes for pre-trained language models},
  author={Zhao, Zihan and Liu, Yuncong and Chen, Lu and Liu, Qi and Ma, Rao and Yu, Kai},
  booktitle={CCF International Conference on Natural Language Processing and Chinese Computing},
  pages={359--371},
  year={2020},
  organization={Springer}
}

@inproceedings{prato2020fully,
  title={Fully Quantized Transformer for Machine Translation},
  author={Prato, Gabriele and Charlaix, Ella and Rezagholizadeh, Mehdi},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={1--14},
  year={2020}
}
@inproceedings{liu2021post,
  title={Post-training quantization for vision transformer},
  author={Liu, Zhenhua and Wang, Yunhe and Han, Kai and Zhang, Wei and Ma, Siwei and Gao, Wen},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={34},
  pages={28092--28103},
  year={2021}
}

@inproceedings{guo2019nat,
  title={Nat: Neural architecture transformer for accurate and compact architectures},
  author={Guo, Yong and Zheng, Yin and Tan, Mingkui and Chen, Qi and Chen, Jian and Zhao, Peilin and Huang, Junzhou},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={32},
  year={2019}
}
@inproceedings{so2019evolved,
  title={The evolved transformer},
  author={So, David and Le, Quoc and Liang, Chen},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={5877--5886},
  year={2019},
  organization={PMLR}
}
@inproceedings{li2021bossnas,
  title={Bossnas: Exploring hybrid cnn-transformers with block-wisely self-supervised neural architecture search},
  author={Li, Changlin and Tang, Tao and Wang, Guangrun and Peng, Jiefeng and Wang, Bing and Liang, Xiaodan and Chang, Xiaojun},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={12281--12291},
  year={2021}
}
@article{csaji2001approximation,
  title={Approximation with artificial neural networks},
  author={Cs{\'a}ji, Bal{\'a}zs Csan{\'a}d},
  journal={Faculty of Sciences, Etvs Lornd University, Hungary},
  volume={24},
  number={48},
  pages={7},
  year={2001}
}
@inproceedings{katharopoulos2020transformers,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={5156--5165},
  year={2020},
  organization={PMLR}
}
@inproceedings{zaheer2020big,
  title={Big bird: Transformers for longer sequences},
  author={Zaheer, Manzil and Guruganesh, Guru and Dubey, Kumar Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and Ahmed, Amr},
 booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={33},
  pages={17283--17297},
  year={2020}
}
@inproceedings{yun2020n,
  title={O (n) connections are expressive enough: Universal approximability of sparse transformers},
  author={Yun, Chulhee and Chang, Yin-Wen and Bhojanapalli, Srinadh and Rawat, Ankit Singh and Reddi, Sashank and Kumar, Sanjiv},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={33},
  pages={13783--13794},
  year={2020}
}
@article{chung2002average,
  title={The average distances in random graphs with given expected degrees},
  author={Chung, Fan and Lu, Linyuan},
  journal={Proceedings of the National Academy of Sciences},
  volume={99},
  number={25},
  pages={15879--15882},
  year={2002},
  publisher={National Acad Sciences}
}
  
@inproceedings{peng2021accelerating,
  title={Accelerating Transformer-based Deep Learning Models on FPGAs using Column Balanced Block Pruning},
  author={Peng, Hongwu and Huang, Shaoyi and Geng, Tong and Li, Ang and Jiang, Weiwen and Liu, Hang and Wang, Shusen and Ding, Caiwen},
  pages={142--148},
  organization={IEEE},
  booktitle={The 22nd International Symposium on Quality Electronic Design (ISQED)},
  year={2021}
}

@inproceedings{liu2021hardware,
  title={Hardware acceleration of fully quantized bert for efficient natural language processing},
  author={Liu, Zejian and Li, Gang and Cheng, Jian},
  booktitle={2021 Design, Automation \& Test in Europe Conference \& Exhibition (DATE)},
  pages={513--516},
  year={2021},
  organization={IEEE}
}


@inproceedings{wang2020hat,
  title={HAT: Hardware-Aware Transformers for Efficient Natural Language Processing},
  author={Wang, Hanrui and Wu, Zhanghao and Liu, Zhijian and Cai, Han and Zhu, Ligeng and Gan, Chuang and Han, Song},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)},
  pages={7675--7688},
  year={2020}
}

@inproceedings{chen2021glit,
  title={Glit: Neural architecture search for global and local image transformer},
  author={Chen, Boyu and Li, Peixia and Li, Chuming and Li, Baopu and Bai, Lei and Lin, Chen and Sun, Ming and Yan, Junjie and Ouyang, Wanli},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={12--21},
  year={2021}
}
@inproceedings{chen2021searching,
  title={Searching the Search Space of Vision Transformer},
  author={Chen, Minghao and Wu, Kan and Ni, Bolin and Peng, Houwen and Liu, Bei and Fu, Jianlong and Chao, Hongyang and Ling, Haibin},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={34},
  pages={8714--8726},
  year={2021}
}
@inproceedings{gong2021nasvit,
  title={NASViT: Neural Architecture Search for Efficient Vision Transformers with Gradient Conflict aware Supernet Training},
  author={Gong, Chengyue and Wang, Dilin and Li, Meng and Chen, Xinlei and Yan, Zhicheng and Tian, Yuandong and Chandra, Vikas},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@inproceedings{lizh2022logic,
  title={Auto-ViT-Acc: An FPGA-Aware Automatic Acceleration Framework for Vision Transformer with Mixed-Scheme Quantization},
  author={Zhengang Li and Mengshu Sun and Alec Lu and Haoyu Ma and Geng Yuan and Yanyue Xie and Hao Tang and Yanyu Li and Miriam Leeser and Zhangyang Wang and Xue Lin and Zhenman Fang},
  booktitle={International Conference on Field Programmable Logic and Applications},
  pages={289--300},
  year={2022},
  organization={Springer}
}