{
    "2208.05163": {
        "title": "Auto-ViT-Acc: An FPGA-Aware Automatic Acceleration Framework for Vision Transformer with Mixed-Scheme Quantization",
        "authors": [
            "Z. Li",
            "Mengshu Sun",
            "Alec Lu",
            "Haoyu Ma",
            "Geng Yuan",
            "Yanyue Xie",
            "Hao Tang",
            "Yanyu Li",
            "M. Leeser",
            "Zhangyang Wang",
            "Xue Lin",
            "Zhenman Fang"
        ],
        "submission_date": "2022",
        "SemanticScholarId": "f27c847e2909f30745f4a3528b574f5acfd76ea7"
    },
    "2203.08243": {
        "title": "Unified Visual Transformer Compression",
        "authors": [
            "Shixing Yu",
            "Tianlong Chen",
            "Jiayi Shen",
            "Huan Yuan",
            "Jianchao Tan",
            "Sen Yang",
            "Ji Liu",
            "Zhangyang Wang"
        ],
        "submission_date": "2022",
        "SemanticScholarId": "4c69fdca6e8a1f10871ab9dc47f62c81ba7ead4a"
    },
    "2112.13890": {
        "title": "SPViT: Enabling Faster Vision Transformers via Latency-Aware Soft Token Pruning",
        "authors": [
            "Zhenglun Kong",
            "Peiyan Dong",
            "Xiaolong Ma",
            "Xin Meng",
            "Wei Niu",
            "Mengshu Sun",
            "Bin Ren",
            "Minghai Qin",
            "H. Tang",
            "Yanzhi Wang"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "722d71a19e4049b30a03d1028158881560432135"
    },
    "2111.15127": {
        "title": "A unified pruning framework for vision transformers",
        "authors": [
            "Hao Yu",
            "Jianxin Wu"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "42b7427ea72a7998adcb73132743889d1f32ef7a"
    },
    "2111.14725": {
        "title": "Searching the Search Space of Vision Transformer",
        "authors": [
            "Minghao Chen",
            "Kan Wu",
            "Bolin Ni",
            "Houwen Peng",
            "Bei Liu",
            "Jianlong Fu",
            "Hongyang Chao",
            "Haibin Ling"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "e939b55a6f78bffeb00065aed897950c49d21182"
    },
    "2108.01390": {
        "title": "Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transformer",
        "authors": [
            "Yifan Xu",
            "Zhijie Zhang",
            "Mengdan Zhang",
            "Kekai Sheng",
            "Ke Li",
            "Weiming Dong",
            "Liqing Zhang",
            "Changsheng Xu",
            "Xing Sun"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "d045133e6e022684329ff944d67f91888be1bc3b"
    },
    "2107.02960": {
        "title": "GLiT: Neural Architecture Search for Global and Local Image Transformer",
        "authors": [
            "Boyu Chen",
            "Peixia Li",
            "Chuming Li",
            "Baopu Li",
            "Lei Bai",
            "Chen Lin",
            "Ming Sun",
            "Junjie Yan",
            "Wanli Ouyang"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "66775d9f16b3f4ca43dba2b31c7c42ca6dcba72b"
    },
    "2107.00651": {
        "title": "AutoFormer: Searching Transformers for Visual Recognition",
        "authors": [
            "Minghao Chen",
            "Houwen Peng",
            "Jianlong Fu",
            "Haibin Ling"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "d645bd08fc19d52164695f9cd5ae863345459a06"
    },
    "2106.14156": {
        "title": "Post-Training Quantization for Vision Transformer",
        "authors": [
            "Zhenhua Liu",
            "Yunhe Wang",
            "Kai Han",
            "Siwei Ma",
            "Wen Gao"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "c295391129426d89ec58cebb049d1cd2e976deec"
    },
    "2106.12620": {
        "title": "IA-RED2: Interpretability-Aware Redundancy Reduction for Vision Transformers",
        "authors": [
            "Bowen Pan",
            "Yifan Jiang",
            "Rameswar Panda",
            "Zhangyang Wang",
            "R. Feris",
            "A. Oliva"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "e2f2662f0734e2edc2b4b36a734de111c7f8d54d"
    },
    "2106.04533": {
        "title": "Chasing Sparsity in Vision Transformers: An End-to-End Exploration",
        "authors": [
            "Tianlong Chen",
            "Yu Cheng",
            "Zhe Gan",
            "Lu Yuan",
            "Lei Zhang",
            "Zhangyang Wang"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "efbe9f591090018f78b42c84613c8afda9292fdb"
    },
    "2106.03714": {
        "title": "Refiner: Refining Self-attention for Vision Transformers",
        "authors": [
            "Daquan Zhou",
            "Yujun Shi",
            "Bingyi Kang",
            "Weihao Yu",
            "Zihang Jiang",
            "Yuan Li",
            "Xiaojie Jin",
            "Qibin Hou",
            "Jiashi Feng"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "8602fd5b0ac73bb422f238b265479f363c0ffe61"
    },
    "2106.02852": {
        "title": "Patch Slimming for Efficient Vision Transformers",
        "authors": [
            "Yehui Tang",
            "Kai Han",
            "Yunhe Wang",
            "Chang Xu",
            "Jianyuan Guo",
            "Chao Xu",
            "D. Tao"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "33fd56e5067a1e8a9713378af3e1c1c08d5ce93b"
    },
    "2106.02034": {
        "title": "DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification",
        "authors": [
            "Yongming Rao",
            "Wenliang Zhao",
            "Benlin Liu",
            "Jiwen Lu",
            "Jie Zhou",
            "Cho-Jui Hsieh"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "dbdcabd0444ad50b68ee09e30f39b66e9068f5d2"
    },
    "2105.14734": {
        "title": "Dual-stream Network for Visual Recognition",
        "authors": [
            "Mingyuan Mao",
            "Renrui Zhang",
            "Honghui Zheng",
            "Peng Gao",
            "Teli Ma",
            "Yan Peng",
            "Errui Ding",
            "Shumin Han"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "2444103bfe203802c9344ba0532b088e1d20afee"
    },
    "2105.05537": {
        "title": "Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation",
        "authors": [
            "Hu Cao",
            "Yueyue Wang",
            "Jieneng Chen",
            "Dongsheng Jiang",
            "Xiaopeng Zhang",
            "Qi Tian",
            "Manning Wang"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "ea7cfe7f2340584cbe653da6077ee7c213e49b92"
    },
    "2104.10858": {
        "title": "All Tokens Matter: Token Labeling for Training Better Vision Transformers",
        "authors": [
            "Zihang Jiang",
            "Qibin Hou",
            "Li Yuan",
            "Daquan Zhou",
            "Yujun Shi",
            "Xiaojie Jin",
            "Anran Wang",
            "Jiashi Feng"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "cc9f3a61ea4eaabf43cbb30cd1dd718074932679"
    },
    "2103.16302": {
        "title": "Rethinking Spatial Dimensions of Vision Transformers",
        "authors": [
            "Byeongho Heo",
            "Sangdoo Yun",
            "Dongyoon Han",
            "Sanghyuk Chun",
            "Junsuk Choe",
            "Seong Joon Oh"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "40f4d7fe800810288a80f84cdb357a8f4c28e880"
    },
    "2103.15808": {
        "title": "CvT: Introducing Convolutions to Vision Transformers",
        "authors": [
            "Haiping Wu",
            "Bin Xiao",
            "N. Codella",
            "Mengchen Liu",
            "Xiyang Dai",
            "Lu Yuan",
            "Lei Zhang"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "e775e649d815a02373eac840cf5e33a04ff85c95"
    },
    "2103.12424": {
        "title": "BossNAS: Exploring Hybrid CNN-transformers with Block-wisely Self-supervised Neural Architecture Search",
        "authors": [
            "Changlin Li",
            "Tao Tang",
            "Guangrun Wang",
            "Jiefeng Peng",
            "Bing Wang",
            "Xiaodan Liang",
            "Xiaojun Chang"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "421fba3813d04684b42dd667e16ed22a64f50752"
    },
    "2103.00112": {
        "title": "Transformer in Transformer",
        "authors": [
            "Kai Han",
            "An Xiao",
            "E. Wu",
            "Jianyuan Guo",
            "Chunjing Xu",
            "Yunhe Wang"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "0ae67202f0584afccefa770865d14a46655d2975"
    },
    "2102.12122": {
        "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions",
        "authors": [
            "Wenhai Wang",
            "Enze Xie",
            "Xiang Li",
            "Deng-Ping Fan",
            "Kaitao Song",
            "Ding Liang",
            "Tong Lu",
            "P. Luo",
            "Ling Shao"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "3e398bad2d8636491a1034cc938a5e024c7aa881"
    },
    "2102.08318": {
        "title": "Instance Localization for Self-supervised Detection Pretraining",
        "authors": [
            "Ceyuan Yang",
            "Zhirong Wu",
            "Bolei Zhou",
            "Stephen Lin"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "4f7a77d04e7e1cff1f6e306f082217be78203643"
    },
    "2101.11986": {
        "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet",
        "authors": [
            "Li Yuan",
            "Yunpeng Chen",
            "Tao Wang",
            "Weihao Yu",
            "Yujun Shi",
            "Francis E. H. Tay",
            "Jiashi Feng",
            "Shuicheng Yan"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9"
    },
    "2101.01321": {
        "title": "I-BERT: Integer-only BERT Quantization",
        "authors": [
            "Sehoon Kim",
            "A. Gholami",
            "Z. Yao",
            "Michael W. Mahoney",
            "K. Keutzer"
        ],
        "submission_date": "2021",
        "SemanticScholarId": "d06bda5e759c8e8569754d8f7235cf1a9a1e9985"
    },
    "2012.15840": {
        "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers",
        "authors": [
            "Sixiao Zheng",
            "Jiachen Lu",
            "Hengshuang Zhao",
            "Xiatian Zhu",
            "Zekun Luo",
            "Yabiao Wang",
            "Yanwei Fu",
            "Jianfeng Feng",
            "T. Xiang",
            "Philip H. S. Torr",
            "Li Zhang"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "d29430adccb805ab57b349afa8553954347b3197"
    },
    "2012.12877": {
        "title": "Training data-efficient image transformers & distillation through attention",
        "authors": [
            "Hugo Touvron",
            "M. Cord",
            "Matthijs Douze",
            "Francisco Massa",
            "Alexandre Sablayrolles",
            "Herv'e J'egou"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "ad7ddcc14984caae308c397f1a589aae75d4ab71"
    },
    "2012.00364": {
        "title": "Pre-Trained Image Processing Transformer",
        "authors": [
            "Hanting Chen",
            "Yunhe Wang",
            "Tianyu Guo",
            "Chang Xu",
            "Yiping Deng",
            "Zhenhua Liu",
            "Siwei Ma",
            "Chunjing Xu",
            "Chao Xu",
            "Wen Gao"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "6f6f73e69ee0d9d5d7d088bb882db1851d98175a"
    },
    "2010.11929": {
        "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
        "authors": [
            "Alexey Dosovitskiy",
            "Lucas Beyer",
            "Alexander Kolesnikov",
            "Dirk Weissenborn",
            "Xiaohua Zhai",
            "Thomas Unterthiner",
            "Mostafa Dehghani",
            "M. Minderer",
            "G. Heigold",
            "S. Gelly",
            "Jakob Uszkoreit",
            "N. Houlsby"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a"
    },
    "2010.07109": {
        "title": "An Investigation on Different Underlying Quantization Schemes for Pre-trained Language Models",
        "authors": [
            "Zihan Zhao",
            "Yuncong Liu",
            "Lu Chen",
            "Qi Liu",
            "Rao Ma",
            "Kai Yu"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "9169f9afdd42aaa60e34f57ff89c882a50e71229"
    },
    "2010.04159": {
        "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection",
        "authors": [
            "Xizhou Zhu",
            "Weijie Su",
            "Lewei Lu",
            "Bin Li",
            "Xiaogang Wang",
            "Jifeng Dai"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504"
    },
    "2007.08563": {
        "title": "FTRANS: energy-efficient acceleration of transformers using FPGA",
        "authors": [
            "Bingbing Li",
            "Santosh Pandey",
            "Haowen Fang",
            "Yanjun Lyv",
            "Ji Li",
            "Jieyang Chen",
            "Mimi Xie",
            "Lipeng Wan",
            "Hang Liu",
            "Caiwen Ding"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "7c6c31412c5dad22543bb71e31620e8868d644a3"
    },
    "2006.16038": {
        "title": "SoftSort: A Continuous Relaxation for the argsort Operator",
        "authors": [
            "Sebastian Prillo",
            "Julian Martin Eisenschlos"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "1648e353100681dc5747fbb8aa887fde4b5c105e"
    },
    "2005.14165": {
        "title": "Language Models are Few-Shot Learners",
        "authors": [
            "Tom B. Brown",
            "Benjamin Mann",
            "Nick Ryder",
            "Melanie Subbiah",
            "J. Kaplan",
            "Prafulla Dhariwal",
            "Arvind Neelakantan",
            "Pranav Shyam",
            "Girish Sastry",
            "Amanda Askell",
            "Sandhini Agarwal",
            "Ariel Herbert-Voss",
            "Gretchen Krueger",
            "T. Henighan",
            "R. Child",
            "A. Ramesh",
            "Daniel M. Ziegler",
            "Jeff Wu",
            "Clemens Winter",
            "Christopher Hesse",
            "Mark Chen",
            "Eric Sigler",
            "Ma-teusz Litwin",
            "Scott Gray",
            "Benjamin Chess",
            "Jack Clark",
            "Christopher Berner",
            "Sam McCandlish",
            "Alec Radford",
            "I. Sutskever",
            "Dario Amodei"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0"
    },
    "2005.14187": {
        "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language Processing",
        "authors": [
            "Hanrui Wang",
            "Zhanghao Wu",
            "Zhijian Liu",
            "Han Cai",
            "Ligeng Zhu",
            "Chuang Gan",
            "Song Han"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7"
    },
    "2005.12872": {
        "title": "End-to-End Object Detection with Transformers",
        "authors": [
            "Nicolas Carion",
            "Francisco Massa",
            "Gabriel Synnaeve",
            "Nicolas Usunier",
            "Alexander Kirillov",
            "Sergey Zagoruyko"
        ],
        "submission_date": "2020",
        "SemanticScholarId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e"
    },
    "1910.14488": {
        "title": "NAT: Neural Architecture Transformer for Accurate and Compact Architectures",
        "authors": [
            "Yong Guo",
            "Yin Zheng",
            "Mingkui Tan",
            "Qi Chen",
            "Jian Chen",
            "P. Zhao",
            "Junzhou Huang"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "59c7f27be8b09596714384f4a35face7cb74ad11"
    },
    "1910.10485": {
        "title": "Fully Quantized Transformer for Machine Translation",
        "authors": [
            "Gabriele Prato",
            "Ella Charlaix",
            "Mehdi Rezagholizadeh"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "132ae47905b1a648c095da54b8533e87cf642897"
    },
    "1905.02244": {
        "title": "Searching for MobileNetV3",
        "authors": [
            "Andrew G. Howard",
            "M. Sandler",
            "Grace Chu",
            "Liang-Chieh Chen",
            "Bo Chen",
            "Mingxing Tan",
            "Weijun Wang",
            "Yukun Zhu",
            "Ruoming Pang",
            "Vijay Vasudevan",
            "Quoc V. Le",
            "Hartwig Adam"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "5e19eba1e6644f7c83f607383d256deea71f87ae"
    },
    "1905.00414": {
        "title": "Similarity of Neural Network Representations Revisited",
        "authors": [
            "Simon Kornblith",
            "Mohammad Norouzi",
            "Honglak Lee",
            "Geoffrey E. Hinton"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "726320cdbd04804ffa8f3a78c095bd1b55a2a695"
    },
    "1901.11117": {
        "title": "The Evolved Transformer",
        "authors": [
            "David R. So",
            "Chen Liang",
            "Quoc V. Le"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "16c844fd4d97f3c6eb38b0d6527c87d184efedc3"
    },
    "1804.00819": {
        "title": "End-to-End Dense Video Captioning with Masked Transformer",
        "authors": [
            "Luowei Zhou",
            "Yingbo Zhou",
            "Jason J. Corso",
            "R. Socher",
            "Caiming Xiong"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "35ed258aede3df17ee20a6635364cb5fd2461049"
    },
    "1803.08375": {
        "title": "Deep Learning using Rectified Linear Units (ReLU)",
        "authors": [
            "Abien Fred Agarap"
        ],
        "submission_date": "2018",
        "SemanticScholarId": "b79e5e4622a95417deec313cd543617b19611bea"
    },
    "1709.01507": {
        "title": "Squeeze-and-Excitation Networks",
        "authors": [
            "Jie Hu",
            "Li Shen",
            "Samuel Albanie",
            "Gang Sun",
            "E. Wu"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "fb37561499573109fc2cebb6a7b08f44917267dd"
    },
    "1706.03762": {
        "title": "Attention is All you Need",
        "authors": [
            "Ashish Vaswani",
            "Noam M. Shazeer",
            "Niki Parmar",
            "Jakob Uszkoreit",
            "Llion Jones",
            "Aidan N. Gomez",
            "Lukasz Kaiser",
            "I. Polosukhin"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776"
    },
    "1703.06870": {
        "title": "Mask R-CNN",
        "authors": [
            "Kaiming He",
            "Georgia Gkioxari",
            "Piotr Dollár",
            "Ross B. Girshick"
        ],
        "submission_date": "2017",
        "SemanticScholarId": "1a0912bb76777469295bb2c059faee907e7f3258"
    },
    "1606.08415": {
        "title": "Gaussian Error Linear Units (GELUs)",
        "authors": [
            "Dan Hendrycks",
            "Kevin Gimpel"
        ],
        "submission_date": "2016",
        "SemanticScholarId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d"
    },
    "1606.01933": {
        "title": "A Decomposable Attention Model for Natural Language Inference",
        "authors": [
            "Ankur P. Parikh",
            "Oscar Täckström",
            "Dipanjan Das",
            "Jakob Uszkoreit"
        ],
        "submission_date": "2016",
        "SemanticScholarId": "2cd8e8f510c89c7c18268e8ad51c061e459ad321"
    },
    "1409.0473": {
        "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
        "authors": [
            "Dzmitry Bahdanau",
            "Kyunghyun Cho",
            "Yoshua Bengio"
        ],
        "submission_date": "2014",
        "SemanticScholarId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5"
    },
    "1405.0312": {
        "title": "Microsoft COCO: Common Objects in Context",
        "authors": [
            "Tsung-Yi Lin",
            "M. Maire",
            "Serge J. Belongie",
            "James Hays",
            "P. Perona",
            "Deva Ramanan",
            "Piotr Dollár",
            "C. L. Zitnick"
        ],
        "submission_date": "2014",
        "SemanticScholarId": "71b7178df5d2b112d07e45038cb5637208659ff7"
    },
    "1810.04805": {
        "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "authors": [
            "Jacob Devlin",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "submission_date": "2019",
        "SemanticScholarId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992"
    }
}