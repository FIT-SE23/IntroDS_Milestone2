\pdfoutput=1

\documentclass[11pt]{article}

\usepackage{EMNLP2022}

\usepackage{times}
\usepackage{latexsym}

\usepackage{tabularx}

\usepackage[T1]{fontenc}

\usepackage[utf8]{inputenc}

\usepackage{microtype}

\usepackage{inconsolata}
\usepackage{soul}
\usepackage{verbatim}


\title{Pragmatics in Grounded Language Learning: \\ Phenomena, Tasks, and Modeling Approaches}


\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\}
  \author{
Daniel Fried$^{1}$\thanks{~~Equal contribution.} \quad
Nicholas Tomlin$^{2*}$  \quad
Jennifer Hu$^{3}$
\\
\textbf{%
Roma Patel$^{4,5}$ \quad
Aida Nematzadeh$^{5}$}
\\
Carnegie Mellon$^1$ \quad UC Berkeley$^2$ \quad MIT$^3$ \quad Brown University$^4$ \quad DeepMind$^5$\\
\texttt{dfried@cs.cmu.edu} \quad \texttt{nicholas\_tomlin@berkeley.edu} \\ \texttt{jennhu@mit.edu} \quad \texttt{\{romapatel,nematzadeh\}@deepmind.com}
} 

  
\usepackage{xcolor}
\newcommand{\ignore}[1]{}
\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\todo}[1]{{\color{red}TODO: #1}}
\newcommand\aida[1]{\textcolor{teal}{Aida: #1}}
\newcommand\nick[1]{\textcolor{olive}{Nick: #1}}
\newcommand\roma[1]{\textcolor{blue}{Roma: #1}}
\newcommand\jenn[1]{\textcolor{purple}{Jenn: #1}}
\newcommand\daniel[1]{\textcolor{orange}{Daniel: #1}}

\renewcommand{\todo}[1]{}
\renewcommand{\red}[1]{{}}
\renewcommand\aida[1]{}
\renewcommand\nick[1]{}
\renewcommand\roma[1]{}
\renewcommand\jenn[1]{}
\renewcommand\daniel[1]{}

\usepackage{booktabs}
\usepackage{cleveref}
\usepackage{pifont}%
\newcommand{\yes}{\ding{51}}
\newcommand{\no}{\ding{55}}

\usepackage{multirow}
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}
\usepackage{rotating}
\usepackage{float}

\AtBeginDocument{\def\sectionautorefname{Section}}%
\AtBeginDocument{\def\subsectionautorefname{Section}}%
\newcommand\eg[0]{e.g., }
\newcommand\ie[0]{i.e., }
\newcommand\interalia[1]{\citep[][\emph{inter alia}]{#1}}

\begin{document}
\maketitle
\begin{abstract}
People rely heavily on context to enrich meaning beyond what is literally said, enabling concise but effective communication. 
To interact successfully and naturally with people, user-facing artificial intelligence systems will require similar skills in \emph{pragmatics}: relying on various types of context---from shared linguistic goals and conventions, to the visual and embodied world---to use language effectively.

We survey existing grounded settings and pragmatic modeling approaches and analyze how the task goals, environmental contexts, and communicative affordances in each work enrich linguistic meaning.
We present recommendations for future grounded task design to naturally elicit pragmatic phenomena, and suggest directions that focus on a broader range of communicative contexts and affordances. 



\end{abstract}

\section{Using Language in Context}
\aida{Consider all tasks in the goal-oriented framework where there might be some uncertainty in defining what the goal is}

\daniel{\st{take out intentions, just use goals}}
\daniel{framing about the uncertainty of the goals, and how to express them. these can interact}



When communicating, people often only sketch their intended meanings and rely on context to let their conversational partners fill in the details.
A simple sentence such as ``it's nice out today'' can invoke different meanings depending on the situation---it can be an implicit invitation, a statement contrasting the weather with a previous day, %
or even ironic if the weather is poor.
People often use language to achieve communicative goals~\cite{Wittgenstein1953-philosophical-investigations,Searle1969-speech-acts,Austin1975-things-with-words,Clark1996-using-language,frank2012predicting}, %
producing effects on other people and on the world.
To achieve their goals efficiently, people rely on various types of context
to allow their conversational partners to enrich meaning beyond what the speaker has literally said, making language highly context-dependent.
This broad ability to use language in context to achieve goals is known as \emph{pragmatics}.
\aida{to me, the phrasing ``language use is inentional'' is a bit strong; is all language use intentional? if we are going to claim this, we need to back it up. Similarly, ``people choose utterances to realise communicative goals''. Is this always true or is it a rational account of communication? We also need to decide if we are going to focus on the ``to achieve goal" part; I do not think we have addressed it in the survey.}
\daniel{I softened the language and took out "intentional". I think we still need do more though to address this, esp. \emph{achieve goals} -- emphasize this more in the tasks? or take out}

\roma{maybe elaborate on user-facing and accessible systems more}
User-facing artificial intelligence systems 
require similar pragmatic skills to interact successfully and efficiently with people. Recent work 
has focused on 
general-purpose 
models \interalia{Tan2019-lxmert,Brown2020-gpt3,Radford2021-clip,bommasani2021opportunities} that have achieved remarkable performance on a variety of task benchmarks intended to measure literal, semantic meaning. %
We believe the time is right %
to move beyond these popular benchmark tasks, to tests that require %
communicating
collaboratively with people %
in rich contexts: %
ones that elicit pragmatic phenomena from people, and benefit from pragmatic abilities in systems.
\aida{``that require using language to achieve collaborative goals by communicating with people in rich contexts'': I think we need to make this a bit more focused/specific to our paper. For example, we can have applications that require pragmatics (meaning in context) but are not collaborative nor require communicating with people.}
\daniel{I think our tasks are all goal-oriented, and we could definitely make an argument for focusing on goal-oriented tasks; but we may not want to do this and should minimally make this clearer in the body. I took out "goals" for now}
We focus on work
that incorporates multimodal context in pragmatic reasoning, motivated by the fact that language use is typically multimodal---our understanding of language is shaped by the environments that we use it in %
\citep{Harnad1990-grounding}.
\daniel{other cites -- Allen?}
\roma{motivate communicative function and then talk about dialogue}

We first survey how various communicative and environmental context types elicit pragmatic phenomena. %
Using these context types and phenomena, we then survey representative tasks and datasets which have been used both to study pragmatic communication in people, and to build goal-oriented multimodal systems.
We present tasks along a spectrum of complexity, ranging from constrained reference games to goal-oriented embodied dialogue.
We discuss how choices in task design---including environment properties, context types, and communicative affordances---shape the pragmatic phenomena that arise in tasks, and provide suggestions for future task and dataset designers. %
To model these tasks and phenomena, we give an overview of a range of computational pragmatic approaches that view communication as goal-directed actions by agents in context.
We illustrate how to apply these in grounded language settings,
and suggest future work to further integrate computational pragmatics with NLP, in order to build systems that communicate more successfully and efficiently with people. %

\daniel{short concluding para here, summarizing if possible the discussion to prime people for takeaways throughout the paper}




\ignore{ %

Most recent work on pragmatics has simplified the dialogue task in different ways:
Limiting number of turns – how many back and forth are there between the participants ? This affects the shared history (and common-ground) among participants, which in turns determines the types of pragmatics phenomena that can be studied.
Defining specific roles, such as follower and speaker. 
Using tasks with easier automatic evaluation such as selecting referents or following a set of instructions.

Both defining roles for participants and assigning tasks make the interactions to be goal-oriented (as opposed to open-ended dialogue). This might encourage participants to engage in certain pragmatic behaviors (such as forming convention); but it might also discourage participants from other behaviors, for example to avoid being vague or to get more points in the task. An study of how task design changes language production and use would be an interesting future work.

Though these simplifying assumptions make it possible to make faster progress, it is not clear if they cover a broad range of pragmatic phenomena; training models that perform well on these tasks does not necessarily guarantee pragmatic understanding. The benefits of these tasks, however, is in modeling innovations (examples) as well as studying certain aspects of pragmatics. 

Some benchmarks (and their associated tasks) have potential real-world applications (such as instruction following). For these benchmarks, it is useful to specify the role of pragmatic understanding – guidelines to do so? What baselines should be considered, etc.
Many tasks are different variations of signaling games. It is useful to specify the design choices of these tasks using a shared protocol (provide guidelines).  It is less clear if such tasks are tied to real world applications, so they are probably more useful to study pragmatics.
What phenomena can and cannot be studied in this paradigm?
How each dataset contributes to our understanding of pragmatic reasoning in humans or gives an opportunity for modeling innovations?

}


\section{Pragmatic Phenomena}
\label{sec:phenomena}

In linguistics and cognitive science, \emph{pragmatics} is often defined in contrast to \emph{semantics}. Broadly speaking, semantics characterises the literal meanings of linguistic expressions, %
whereas pragmatics captures the context-dependent components of meaning, %
which may contain the bulk of actual communication. Pragmatic communication draws upon many different sources of information, ranging from environmental factors to inferences about other agents' unspoken information and goals. %
This makes pragmatics both a critical and challenging component for designing NLP systems that interact 
with people. In this section, we discuss the types of context in which language can be situated and the non-literal inferences that arise as a result of these contextual pressures.










\subsection{Types of Context}\label{types-context}

Many aspects of pragmatics involve the maintenance of \emph{common ground}, a set of contextual information shared between communicative partners \citep[e.g.,][]{lewis_convention_1969,
clark_grounding_1991,traum1994computational,stalnaker_common_2002,clark_common_2015}. Key elements of common ground include (1) social and communicative norms, (2) task goals and collaborative actions, (3) common knowledge, and (4) discourse context. We focus in particular on pragmatic reasoning that also requires multimodal context, such as  (5) visual information or (6) embodied interaction. See Appendix~\ref{ax:context} for definitions and examples for each of these types of context;
we also  point readers to \citet{Levinson1983-pragmatics} and \citet{birner2012introduction} %
for a more comprehensive discussion.




























\subsection{Roles of Pragmatics} \label{sec:roles-pragmatics}
In this section, we survey broad roles that pragmatics plays in modeling human behavior and improving the ability of systems to interact with people. Rather than focusing on linguistic phenomena like \textit{deixis} and \textit{presupposition}, we take a task-driven approach and highlight ways that pragmatic reasoning may be involved in grounded language tasks. We do not intend this taxonomy to be fully exhaustive, and we caveat that some categories may partially overlap with one another.


\paragraph{Reasoning About Alternatives.} Much of linguistic meaning comes not just from what we say, but from what we do not say. The utterances that speakers choose \emph{not} to say i.e., the set of alternative utterances which are likely in a context, can reveal their intended meanings and mental states \cite{Horn1984-implicature,fox2011characterization,degen2013alternatives,buccola2022conceptual}, 
\eg \emph{some of the apples are red} likely conveys that some are not, since the speaker did not say all were red.
Many of the following roles of pragmatics also often involve reasoning over alternatives.

\paragraph{Understanding Ambiguity.} Language is frequently ambiguous for many reasons \citep{piantadosi_communicative_2012}: ambiguity may be used strategically to achieve communicative efficiency or to remove information that is unhelpful to the task at hand. Moreover, ambiguous instructions often require listeners to reason pragmatically about alternative intentions that speakers might have. For example, when asked to \textit{pass the knife} in a cooking scenario, a pragmatic agent might have to reason about the context to determine whether to provide a butter, bread, or steak knife. By relying on contextual information to resolve ambiguities in situations such as these, pragmatic interlocutors can communicate more efficiently \citep{sole_ambiguity_2015,fortuny_origin_2013}.








\paragraph{Collaborative Planning.}
Many grounded dialogue tasks require agents to coordinate to carry out joint activities, \eg collaboratively agree to a goal before executing it. 
To succeed at tasks like these, participants often must reason about each other's possible goals, for example in a collaborative building setting, inferring that \emph{four planks} can be either a command or a description depending on what effect the speaker is trying to produce on the listener. %
In environments with many world states, there are a combinatorial number of goals to reason about and actions to take, but a participant can usually only communicate with their partner for a limited time. Therefore, participants must trade-off between communicating efficiently and acting. %


\paragraph{Convention Formation and Abstraction.} Conventions, as characterised by \citet{lewis_convention_1969}, are arbitrary but stable solutions to recurring coordination problems that typically form out of the maxims of rational communication \cite{grice1975logic}. For example, a team of workers who communicate with one another daily might initially have lengthy descriptions to refer to certain items, but after a while, might start to develop a common ground of simpler words to refer to them. These abstractions or conventions are hypothesised to emerge as a result of repeated interactions \cite{garrod1994conversation}. One theory is that conventions form to help resolve ambiguity, yielding more efficient communication at the levels of individuals \citep{hawkins2017convention} or populations \citep{hawkins2022partners}. %


\paragraph{Efficiency and Mutual Exclusivity.} For many grounded tasks where the goal is to learn a correspondence between meanings and utterances, pragmatic reasoning can be used to avoid  learning degenerate mappings. For example, on learning that a certain label (e.g., \textit{cat}) refers to an object, an agent might use mutual exclusivity to rule out the possibility of another label (e.g., \textit{dog}) also referring to the object \cite{markman1988children,Clark1988-contrast}.
Models of pragmatic reasoning often induce biases toward mutual exclusivity that can lead to more efficient learning \citep{wang-etal-2016-learning-language, mcdowell-goodman-2019-learning}.
More broadly, pragmatic reasoning may be used to manage the dual pressures of informativity and conciseness \citep{zipf_human_1949,Horn1984-implicature,blutner1998lexical}, which are explicitly factored into pragmatic models such as RSA (cf. Section~\ref{sec:rsa}). As a result, pragmatics may lead to communicative efficiency both during language learning and language use. %




\begin{table*}[h!]
\centering
\footnotesize
\scalebox{0.92}{
\begin{tabularx}{1.09\linewidth}{Xllccc}
\toprule
Task (Dataset) & Types of Context & Role of Pragmatics & Par.Ob. & Sym. & Iter.  \\

\midrule 
\textbf{Reference Game} & & &&&  \\
\parbox{3.8cm}{\textit{Colors in Context} \newline \citet{monroe-etal-2017-colors}} & \parbox{4.6cm}{Visual} & \parbox{4.8cm}{Reasoning about alternatives, understanding ambiguity} & \xmark & \xmark & \cmark \vspace{0.2cm} \\
\midrule 
\textbf{Image Captioning} & & &&&  \\
\parbox{3.8cm}{\textit{Abstract Scenes} \newline \citet{andreas-klein-2016-reasoning}} & \parbox{4.6cm}{Visual, common knowledge} & \parbox{4.8cm}{Reasoning about alternatives} & \xmark & \xmark & \xmark \vspace{0.2cm} \\
\parbox{3.8cm}{\textit{Conceptual Captions} \newline \citet{alikhani-etal-2020-cross}} & \parbox{4.6cm}{Visual, common knowledge, joint goals, norms of interaction} & \parbox{4.8cm}{Efficiency considerations} & \xmark & \xmark & \xmark \vspace{0.1cm} \\
\midrule 
\textbf{Instruction Following} & & &&&  \\
\parbox{3.8cm}{\textit{SHRDLURN} \newline \citet{wang-etal-2016-learning-language}} & \parbox{4.6cm}{Visual} & \parbox{4.8cm}{Mutual exclusivity, convention formation, efficiency considerations} & \xmark & \xmark & \cmark \vspace{0.2cm} \\
\parbox{3.8cm}{\textit{CerealBar} \newline \citet{suhr-etal-2019-executing}} & \parbox{4.6cm}{Visual, embodied} & \parbox{4.8cm}{Collaborative planning, understanding abstractions and conventions} & \cmark & \xmark & \cmark \vspace{0.2cm} \\
\parbox{3.8cm}{\textit{Hexagons} \newline \citet{lachmy2022hexagons}} & \parbox{4.6cm}{Visual, norms of interaction} & \parbox{4.8cm}{Understanding ambiguity and abstractions, efficiency considerations} & \xmark & \xmark & \cmark \vspace{0.1cm} \\
\midrule
\textbf{Grounded Dialogue} & & &&& \\
\parbox{3.8cm}{\textit{Cards Corpus} \newline \citet{potts2012goal}} & \parbox{4.6cm}{Visual, embodied, joint goals, norms of interaction, discourse} & \parbox{4.8cm}{Collaborative planning, understanding ambiguity, efficiency} & \cmark & \cmark & \xmark \vspace{0.2cm} \\
\parbox{3.8cm}{\textit{OneCommon} \newline \citet{udagawa2019natural}} & \parbox{4.6cm}{Visual, joint goals, norms of interaction, discourse} & \parbox{4.8cm}{Collaborative planning, understanding ambiguity, efficiency} & \cmark & \cmark & \xmark \vspace{0.2cm} \\
\parbox{3.8cm}{\textit{PhotoBook} \newline \citet{haber_photobook_2019}} & \parbox{4.6cm}{Visual, common knowledge, joint goals, norms of interaction, discourse} & \parbox{4.8cm}{Convention formation, understanding ambiguity, efficiency} & \cmark & \cmark & \cmark \vspace{0.1cm} \\
\bottomrule
\end{tabularx}
}
\vspace{-.5em}
\caption{Example grounded language learning datasets that involve pragmatic reasoning, organized by task type.  
The task attributes refer to: partially observable, symmetric, and iterated (multi-turn) interactions.
We observe that grounded dialogue and instruction following tasks often involve a broader range of pragmatic reasoning behaviors.}
\label{tab:main}
\vspace{-1.5em}
\end{table*}

\section{Existing Tasks and Environments}
\label{sec:tasks}

In this section, we critically evaluate several well-studied grounded language tasks. 
We focus on tasks in multimodal domains that make use of natural language data.\footnote{We omit large bodies of work on unimodal pragmatics \interalia{degen2013alternatives, jeretic-etal-2020-natural, choi-etal-2021-decontextualization} %
or language that might be grounded, but is synthetically generated \citep{johnson2017clevr, bastings-etal-2018-jump, zhong2020rtfm}.} %



\subsection{Types of Tasks}

Grounded, task-oriented dialogue provides a general setting to study pragmatics. Dialogue tasks provide rich and varied contexts
(\eg different types of common ground, goals, and environments)
as well as communicative affordances (\eg the ability to ask questions, provide information in installments, and adapt to a partner's conventions). 
These contexts and affordances interact to produce a diverse range of pragmatic behavior~\citep{Clark1996-using-language}.
However, many of these contexts, affordances, and behaviors are also present in more restricted and controlled tasks for which
data collection, analysis, modeling, and evaluation are often more tractable.
For example, image captioning tasks simplify data collection and modeling by limiting the number of conversational turns to one; instruction interpretation tasks 
additionally simplify evaluation (so long as it is possible to carry out and validate actions in the world). %

We focus on reference games, image captioning, instruction following, and grounded dialogue tasks that give us a broad characterization of the different properties that tasks might have, as summarized in Table~\ref{tab:main}.\footnote{This is not an exhaustive taxonomy of grounded language learning tasks. For example, VQA \citep{antol2015vqa}, NLVR2 \citep{suhr-etal-2019-corpus}, the Hateful Memes Challenge \citep{kirk-etal-2021-memes}, and Winoground \citep{thrush2022winoground} do not fit perfectly into any of the above categories, although most bear some similarities to image captioning.} For each task, we specify what type of context is needed, how pragmatic behavior is typically exhibited, and several important elements of task design: partial observability, symmetry, and iterated interaction (see Section~\ref{sec:task-design}). We present these domains in order of increasing complexity, finding that the most complex grounded dialogue tasks are more likely to involve features like partial observability or symmetry which induce additional pragmatic phenomena.


 
\paragraph{Reference Games.}
Reference games typically involve two players, a listener and a speaker agent. Both players are presented with a shared set of referents, \eg images, objects, or abstract illustrations, and the speaker is tasked with describing a target referent to the listener, who must then guess the target~\citep{clark1986referring,Gorniak2004-gg,Steels2005-rn,golland-etal-2010-game,frank2012predicting,Kennington2015-hp}. 
An example reference game is the Colors in Context \citep{monroe-etal-2017-colors} task, in which players are presented with three color swatches and asked to describe one of them. Even simple phrases like \textit{plain blue} may have different meanings depending on visual context in this task. 




\paragraph{Image Captioning.}

A broad class of image captioning tasks require producing text to describe an image~\citep{Barnard2003-matching,Farhadi2010-sentences-from-images,Mitchell2012-midge,Kulkarni2013-babytalk}.
Most captioning work has only been implicitly goal-oriented: 
corpora have been constructed
by asking annotators to determine and describe the important parts of an image \citep{Hodosh2013-image-description,Young2014-flickr30k,Chen2015-mscoco}. 
Systems are evaluated on how closely their descriptions match these human-written references, which poses challenges given considerable variation in what annotators chose to describe and how they wrote the descriptions~\citep{Anderson2016-spice}.

Other work, particularly in the computational pragmatics literature, has formulated captioning as a contrastive task~\citep{andreas-klein-2016-reasoning,Vedantam2017-captions,cohn-gordon-etal-2018-pragmatically}, where a target image must be described to contrast it from other similar, \emph{distractor} images.
This setting can be viewed as a scaled-up reference game involving complex visual inputs,
and many such pragmatically-motivated variations on standard image captioning have appeared in recent years:
\citet{nie-etal-2020-pragmatic} define \textit{issue-sensitive image captioning}, in which models implicitly caption several target images at a time, while 
\citet{alikhani-etal-2020-cross} train \textit{coherence-aware} captioning models which may vary in the degree of subjectivity or the extent to which inferences about target images are made.

Of the task categories we discuss, image captioning has the most immediate real-world applicability, especially for accessibility e.g., to provide descriptions that could substitute for images for visually-impaired users on the web~\citep{Pont-Tuset2020-localized}.
Additionally, practical considerations in this domain often require pragmatic reasoning e.g., specifically describing salient characteristics of an image (\eg \emph{a man} versus \emph{Barack Obama}), being concise, or describing the relevance of the image to document context. We refer the reader to \citet{macleod2017understanding} and \citet{kreiss2021concadia} for further information on this topic. 


\paragraph{Instruction Following.}
Instruction following tasks require a listener to take instructions from a speaker, predicting \emph{trajectories} in an environment~\citep{Branavan09PG,vogel2010learning,chen2011navigation,tellex2011understanding,anderson2018vision}.
Trajectories can be grammar-based actions (\eg \textsc{Add(Leftmost(With(Brown)), Orange)}, to specify \emph{add an orange block to the left-most brown block} in the block-stacking setting of \citealt{wang-etal-2016-learning-language}), sequences of discrete movements (\eg between nodes in a navigation graph in \citealt{Chen2019-touchdown, ku-etal-2020-room}), or continuous sequences (\eg of orientations in \citealt{ku-etal-2020-room}).


A speaker must describe a target trajectory in a way that allows the listener to correctly carry it out in the presence of (often exponentially many) alternative trajectories (\eg \emph{left} versus \emph{sharp left}).
These environments often involve visually-grounded observations~\citep{anderson2018vision,Chen2019-touchdown,ku-etal-2020-room}, action hierarchies or abstractions~\citep{shridhar2020alfred,lachmy2022hexagons} and some parts of the environment may be unobserved to the speaker, the listener, or both (see \autoref{sec:task-design}), causing language to be more ambiguous and context-dependent.

\paragraph{Grounded Goal-Oriented Dialogue.}
We focus on grounded dialogue tasks that
involve
two-way communication between partners to achieve a shared goal~\citep[\eg][]{Chai2004-multimodal-ui,rieser-lemon-2008-learning,das2017visual,De_Vries2017-guess-what,kim-etal-2019-codraw,narayan-chen-etal-2019-collaborative,ilinykh2019meetup}.\footnote{Our focus is on task-oriented dialogue, given that communicative goals are less explicit in chit-chat settings (but see \citet{Kim2020-persona-dialogue} for a recent pragmatic treatment).}
These tasks generalize the one-way communication settings above;
however, two-way communication provides additional affordances---allowing players to ask clarification questions, acknowledge understanding, and coordinate actions.
For example, in the Cards task~\citep{potts2012goal},
players collaboratively collect a set of cards in a grid world environment by communicating with other players while moving around to pick up cards. Observability is limited to parts of the environment close to the players, requiring them to pool information, and they must collaboratively plan to agree on one of the multiple possible sets of cards they can collect.

The multi-turn nature of dialogue also necessitates reasoning about past actions and interactions 
(perform \emph{inference}) 
and likely outcomes in the future
(\emph{planning}).
These are particularly evidenced in collaborative reference tasks such as OneCommon~\citep{udagawa2019natural}, where players must infer which items they share with their partners, aggregating information over the course of a dialogue.
Finally, repeated interactions in dialogue can allow linguistic adaptation. For example, in PhotoBook task~\citep{haber_photobook_2019}---a collaborative reference task where players have repeated conversations about photographs---players adapt their language over time to match each other, becoming more efficient over time (\eg reducing \emph{the strange bike with three wheels} to \emph{strange bike}).

\subsection{Elements of Task Design} \label{sec:task-design}
We now outline three especially pragmatically-relevant dimensions to consider when designing tasks and describe how they induce various types of pragmatic phenomena.

\paragraph{Observability.}
In \emph{partially observable} tasks, participants can only see a limited portion of the environment, for example seeing only the parts of the grid closest to them in the Cards task~\citep{potts2012goal}. This can make language more context-dependent, in particular creating a dependence on \emph{when} or \emph{where} the language was produced.
The most complex partially-observable settings, including all of the collaborative dialogue tasks in \autoref{tab:main}, involve participants observing different views of the environment --- requiring them to collaboratively plan to pool their information. Different views can also lead to false agreements where participants believe they have coordinated but actually disagree \cite{Chai2014-bn,udagawa2019natural}, requiring more explicit pragmatic modeling of the partner's perspective to avoid and resolve ambiguity.

\paragraph{Symmetry.} Tasks differ in the types of roles performed by the communicating agents, which in turn shapes the type of language produced and actions taken. We distinguish between \emph{asymmetric} and \emph{symmetric} roles. In an asymmetric setting --- e.g., speaker and listener, or teacher and follower --- pragmatics may be helpful for production and comprehension of language utterances. Symmetric settings \citep{vogel-etal-2013-emergence, vogel2013implicatures} may be more naturalistic and are often used in coordination tasks, although designing such settings is often more complicated. Asymmetric settings \citep{monroe-etal-2017-colors, andreas-klein-2016-reasoning} are often the simplest way to introduce pragmatic phenomena, since asymmetry occurs when one agent is missing information. 

\paragraph{Interaction.} The nature of interaction(s) between communicating agents affects the language that is produced. In a \emph{one-turn} interaction, all usable information must be expressed in a single utterance, forcing speakers to balance informativity and conciseness. In \emph{iterated one-sided} interactions, 
the speaker has the opportunity to respond to the listener's actions before planning each new utterance. Finally, in \emph{dialogue}, agents can freely coordinate and participate in speech acts---they can jointly build common ground, ask clarification questions, and share useful information.
These repeated interactions between agents
require attention to conversation history, and may give rise to the formation of conventions  \citep[e.g.,][]{hawkins2017convention}. 





\subsection{Evaluating Pragmatic Models}
The ultimate goal for user-facing, situated agents is to communicate (1) successfully and (2) efficiently with people.
Human evaluations, where agents are paired with people at test-time, are an ideal way to measure this~\interalia{Walker1997-paradise,Koller2010-give,Parent2010-entrainment,suhr-etal-2019-executing}, but are not always feasible to carry out since they complicate controlling and replicating experimental setups.
Thus, evaluation often resorts either to static, human-produced corpora or automated model-based evaluations.

\paragraph{Task success.}
Interpretation tasks are typically amenable to corpora-based evaluation.
For example, listener agents in reference games can be easily evaluated based on the accuracy of referent selection.
In contrast, evaluating language generation tasks for speaker agents is more challenging, given that many classical reference-based automated NLG metrics 
are unable to measure whether or not generated language will be understood correctly by human listeners
\citep{Krahmer2010-empirical-nlg,fried-etal-2018-unified,Zhao2021-evaluation-instructions,Gehrmann2022-evaluation}. %
Automated proxies for human listeners are models of how people interpret and respond to a system's language, known as \emph{user simulation} or \emph{self-play}~\citep{Georgila2006-tx,Rieser2011-rl-dialogue,lewis-etal-2017-deal,kim-etal-2019-codraw} in dialogue and \emph{communication-based evaluation}
\citep{newman-etal-2020-communication} in reference games,
where speaker generations are fed to a listener model and evaluated on task success.
Automated models can only give rough indicators of how humans might interpret the system's language.
For this reason, we stress the importance of making the evaluation model dissimilar from the system 
and augmenting 
with human evaluations whenever possible.

\paragraph{Communicative efficiency.} Beyond task success, a secondary criterion for situated agents is efficient communication.
For example, if the language generated by a speaker, although correct, is difficult to understand, this calls for unnecessary interpretation effort from the other agent. 
To measure whether pragmatic agents enable efficient communication, evaluations can use metrics of communicative cost~\citep{Walker1997-paradise} such as time to task completion, utterance length and complexity \citep{effenberger-etal-2021-analysis-language}, measures such as lexical entrainment \citep{clark1986referring,Parent2010-entrainment,hawkins2020characterizing}, and quality ratings~\citep{Kojima2021-continual-learning}.


\ignore{ %
Multimodal dialogue settings are arguably most likely to produce the fullest range of pragmatic phenomena given their rich communicative affordances and interactive nature with which participants co-adapt.
However, collecting large-scale datasets for open-ended dialogue is challenging due to cost and privacy concerns.
Including multimodal data makes this even more difficult. \aida{add why}  Moreover, automatic evaluation of open-ended dialogue and broadly, natural language generation, is still an open problem \citep{Gehrmann2022-evaluation}.
Past work has focused on a range of task complexities
which simplify the unrestricted dialogue setting in various ways and make data collection, analysis, modeling, and evaluation more tractable.
For example, image captioning tasks simplify data collection and modeling by limiting the number of conversational turns to one; reference game tasks additionally simplify evaluation to a classification task (\ie to pick the intended referent).

While pragmatics plays a role in all of the works that we survey, 
some emphasize producing broad and rich pragmatic phenomena through careful task construction (\eg reasoning about objects in simulated worlds) while others are motivated primarily
by applications to real-world systems (\eg image captioning).
We argue that both approaches are valuable research directions and that each work should be evaluated on its own terms: datasets collected to study pragmatics should be evaluated on the range of phenomena they enable studying and the suitability of the data for the phenomena; 
datasets collected with an eye toward improving task performance should be evaluated on the importance of the task and the benefits of the dataset for the task.
Additionally, these need not be distinct camps --- many datasets and tasks are motivated by both aims to various degrees, and modeling approaches will ideally be general enough to work on all of them. We encourage future work to consider, if not aim for, both objectives when feasible, \eg collecting iterated data in naturalistic collaborative settings and analyzing it for pragmatic phenomena.

}%


























\section{Modeling Pragmatics} \label{sec:pragmods}



In this section, we discuss frameworks that have been proposed to characterize \emph{how} listeners can derive pragmatic meaning, providing a starting point for modeling the phenomena and tasks above. %



\daniel{maybe make it clearer what the points of these works are: some focus on modeling human behavior; others focus on improving AI agents' ability to interact with people.}

\subsection{Gricean Maxims}
\label{sec:gricean-maxims}
In his seminal proposal, \citet{grice1975logic} argues that 
speakers and listeners are guided by an underlying \emph{cooperative principle}: 
taking action to jointly achieve communicative goals, and assuming that other agents are acting similarly.
Grice divides this principle up into a set of maxims.
However, attempts to directly implement the Gricean maxims computationally  \cite[\eg][]{Hirschberg1985-thesis} have had to grapple with substantial underspecification and overlap in Grice's proposal.
Later \emph{neo-Gricean} work in linguistics has streamlined the maxims considerably~\citep{Horn1984-implicature,levinson_presumptive_2000} and characterizes many pragmatic effects in terms of the tradeoff between speaker and listener effort in achieving cooperative goals.
\daniel{is this accurate?}
These approaches have had few direct computational implementations; however, a line of computational work, which we outline in Sections~\ref{sec:rsa} and \ref{sec:modeling-multi-turn},
\emph{derives} maxim-like behavior through multi-agent modeling rather than by prescriptively implementing the maxims.


\subsection{Multi-Agent Reasoning}\label{sec:rsa}
A number of computational frameworks view utterance generation and interpretation using a multi-agent or game-theoretic lens~\cite{rosenberg1964,Cohen1990-rational-interaction,%
golland-etal-2010-game,jager2012game,franke2013game%
}. %
Many of these frameworks derive pragmatic behavior 
by modeling communication partners as rational agents who jointly try to optimize a communicative utility function using theory-of-mind reasoning about other agents. %
We focus on one representative of these, the Rational Speech Acts (RSA) framework~\citep{frank2012predicting,goodman2016pragmatic}, as it has been successfully applied across a range of grounded language settings.
\daniel{too abstract; define utility?}

RSA defines a recursive reasoning process where speakers and listeners model each other's goals and interpretations. %
A \emph{rational speaker} chooses utterances using an embedded model of how the listener will likely interpret utterances %
A \emph{rational listener}, in turn, reasons counterfactually about a rational speaker generating language in this way---reasoning about why the speaker choose an observed utterance rather than alternatives---which can resolve ambiguity in the speaker's utterances.
\aida{Might need a figure to explain this.} 

Theoretical work on the RSA framework has used it to model interpretation and generation of pragmatic phenomena such as scalar implicature \citep{goodman2016pragmatic}, M-implicature \citep{bergen2016pragmatic}, metaphor \citep{kao2014formalizing}, and hyperbole \citep{kao2014nonliteral}. In practice, most RSA implementations involve speaker agents which sample candidate generations from a conditional language model, and listener agents which execute these generations in the environment \citep{andreas-klein-2016-reasoning}. 
A variety of work has also applied RSA to improve performance of NLP systems on a range of tasks involving complex natural language utterances,
including reference games \citep{monroe-etal-2017-colors}, instruction following and generation \citep{fried-etal-2018-unified,fried2018speaker}, image captioning \cite{andreas-klein-2016-reasoning,cohn-gordon-etal-2018-pragmatically}, summarization~\citep{Shen2019-generation}, MT~\citep{Cohn-Gordon2019-mt}, and dialogue~\citep{Kim2020-persona-dialogue,fried-etal-2021-reference}. 
A number of rational communication frameworks also include noteworthy variations on the core RSA setup, include varying the utility function~\cite{zaslavsky-etal-2021-rate}, modeling mis-aligned objectives~\cite{Asher2013-strategic}, using deeper levels of recursive reasoning between agents~\cite{Wang2020-mathematical}, and modeling forms of non-linguistic communication~\citep{Hadfield-Menell2017-inverse-reward-design,jeon2020reward,Pu2020-pragmatic-synthesis}. %

One key limitation of RSA is that it models speakers as choosing their utterances from a known and fixed set of candidate utterances.
Because using the full space of possible natural language utterances is intractable for most tasks, some recent work has proposed incremental models which process one word or character at a time, leading to promising results on constrastive image captioning \citep{cohn-gordon-etal-2018-pragmatically, nie-etal-2020-pragmatic}. \nick{Do we want to add equations? Add discussion of faithfulness/whether existing RSA approaches target semantics more than pragmatics...}
A second notable limitation is that, with a few exceptions \citep[\eg][]{khani-etal-2018-planning}, applications of full recursive reasoning frameworks have been limited to single-turn interactions. 
However, the multi-turn approaches that we outline in \autoref{sec:modeling-multi-turn} allow modeling repeated interactions by making the framework simpler along certain axes (\eg removing higher-order theory-of-mind).

\daniel{Efstathiou et al.}

\daniel{limitations: single turn, and assumes the alternative sets are known}

\subsection{Multi-Turn Approaches}
\label{sec:modeling-multi-turn}
A variety of approaches to multi-turn pragmatics have arisen in work on task-oriented dialogue. Many of these treat communication as goal-directed decision-making under uncertainty~\citep{Rieser2011-rl-dialogue,young2013pomdp}, and can be broadly viewed as generalizing the single-turn frameworks of \autoref{sec:rsa}.
For generation, a variety of dialogue systems explicitly \emph{plan} utterances or speech acts to convey information to their partners~\interalia{cohen1979-speech-acts,traum1994computational,Walker2004-generation,Rieser2009-planning,Kim2020-persona-dialogue}.  
For interpretation, many systems \emph{infer} the latent intent or state of the user~\interalia{Allen1980-intention,Paek2000-conversation,Williams2007-pomdp,Schlangen2009-filtering,young2013pomdp}.


Planning and inference are classic AI tasks with broad applicability, and most of the works above 
are closely related to general machinery developed for \emph{decentralized POMDPs}~\citep{bernstein2002complexity,oliehoek2016concise}. 
However, given computational challenges, past work on algorithmic applications of POMDP algorithms to communication 
have focused on 
domain-specific formalisms (the works above) or restricted language settings~\citep{zettlemoyer2008multi,vogel-etal-2013-emergence,Hadfield-Menell2016-cirl,Foerster2019-bad,jaques2019social}. %
To enable pragmatic modeling and interaction with people in naturalistic grounded dialogue settings, future work 
might draw on further progress that the multi-agent reinforcement learning and planning communities make on these underlying algorithmic challenges.


\ignore{
\section{Future Work}
With the possible exception of image captioning, many benchmark tasks discussed in this paper were developed as scaled-down models of more naturalistic pragmatic language situations. Training data for such tasks is often limited in scope, size, and ecological validity \citep{devries2020towards}.
As the field of grounded language learning matures, we anticipate the development of increasingly complex, real-world environments with orders of magnitude more data. Methods for vision-and-language pretraining \citep{lu2019vilbert, sun2019videobert} as well as reinforcement learning pretraining \citep{pmlr-v119-laskin20a, NEURIPS2021_99bf3d15} will likely unlock new grounded language domains, shifting our focus to richer contexts with a different distribution of pragmatic phenomena. For example, future dialogue systems may rely on context from past interactions \citep{lin2022inferring}, and future instruction-following systems may need to integrate information about the preferences of multiple users.

Despite the expected rise in scale, we predict that data sparsity will continue to be a critical issue in interactive language domains, such as those with dyadic communication, due to the the wide range of possible contexts and the difficulties of collecting interactive data. \citet{wang-etal-2016-learning-language} and \citet{mcdowell-goodman-2019-learning} have argued that one role of explicit pragmatic reasoning is the ability to ground language with less data, due to mutual exclusivity-like phenomena, and such benefits may be especially important at scale. Adding inductive biases toward pragmatic language behavior into future multimodal foundation models, such as by integrating alternatives into the pretraining objective, is one possible future direction.
Alternatively, we may find that future multimodal pretraining methods can inherently learn pragmatic language behavior. Recently developed datasets such as Winoground \citep{thrush2022winoground} aim to evaluate semantic compositionality in pretrained language-and-vision models, and we encourage similar diagnostic work in the domain of pragmatics, with a focus on investigating different types of pragmatic phenomena.
}




\section{Moving Forward} \label{sec:discussion}

Human communication relies on pragmatics, making it a crucial component of machine learning systems that communicate effectively with people. In this section, we argue that pragmatics may help bridge the gap between current NLP benchmarks and real-world applications. 
We begin by discussing open questions in computational pragmatics and then propose ways to integrate pragmatic phenomena into 
tasks. We conclude with reflections on large-scale, multimodal pretraining and the role of pragmatics in the era of big models.

\paragraph{Better Understanding Pragmatic Phenomena.}

In Section~\ref{sec:roles-pragmatics}, we proposed a taxonomy of context-dependent phenomena that differs from traditional linguistic views of pragmatics \citep{birner2012introduction}. We believe this taxonomy is well-suited to the description of grounded language tasks and hope it will guide future work on task development and evaluation. 
We note that some tasks or datasets are designed to study specific phenomena \citep[\eg][]{monroe-etal-2017-colors} while others are intended to improve a real-world application \citep[\eg][]{alikhani-etal-2020-cross}. We argue that both approaches are valuable research directions and that each work should be evaluated on its own terms: datasets collected to study pragmatics should be evaluated on the range of phenomena they enable studying and the suitability of the data for the phenomena; datasets collected with an eye toward improving task performance should be evaluated on the importance of the task and the benefits of the dataset for the task.

Our taxonomy also invites new scientific questions about computational models of pragmatics. 
Can existing reasoning-based computational frameworks (\eg RSA) be extended to account for a wider range of phenomena, such as collaborative planning, convention formation, and discourse coherence? These frameworks derive a wide range of pragmatic phenomena, but make assumptions about communicative rationality and access to sets of alternative utterances --- what could have been said but wasn't. 
In contrast, language models are extremely flexible and powerful, but --- as argued recently by \citet{bisk2020experience} and \citet{bender_climbing_2020} --- their ability to learn grounded meaning depends heavily on the 
data available to train them on.
Similarly, we can ask: how much pragmatic behavior can be learned by large models pretrained solely on text in context?

We may find that pretraining methods can learn aspects of pragmatic behavior simply by predicting linguistic content,
paralleling recent work showing that modern language models learn correlates of syntax \cite{baroni_proper_2022,wilcox_learning_2022} and human processing effort  during language comprehension \citep[e.g.,][]{aurnhammer_comparing_2019,wilcox_predictive_2020,merkx_human_2021}.
As such, language models have the potential to serve as \emph{implemented models} of cognitive theories proposing that pragmatic behaviors arise from linguistic prediction --- for example, based on surface-level linguistic patterns associated with certain inferences \citep[e.g.,][]{schuster_harnessing_2020}. 
We invite future work to extend our taxonomy of pragmatic roles, and measure the extent to which these modeling approaches can complement each other and account for --- and produce --- pragmatic behavior.



\paragraph{Building Pragmatically Informed Tasks.}
The tasks we survey differ in the constraints of their task design, eliciting varying types of pragmatic behavior. For example, iterated reference games encourage participants to form conventions to communicate more efficiently; on the other hand, it is harder to study conventions in non-iterated tasks such as image captioning. 
Instruction following and goal-oriented dialogue tasks provide an agent with a larger space of possible actions that can be taken, eliciting collaborative planning. However, the rich affordances of such tasks often force datasets to trade off between scope, size, and ecological validity \citep{devries2020towards}, often resulting in scaled-down models of more naturalistic goal-oriented tasks.

We suggest that integrating additional pragmatic roles into existing tasks may lead to models which are more useful in the real world. For example, modeling user-specific conventions in digital assistants could lead to more personalized responses, whereas better handling of ambiguity might allow users to speak more naturally. Image captioning for accessibility provides a prime example of this approach: whereas traditional image captioning involves relatively little pragmatics, several recent works have highlighted the importance of context-dependence when generating image captions for visually-impaired users on the web \citep{macleod2017understanding, Pont-Tuset2020-localized, kreiss2021concadia}. We also encourage the development of new grounded dialogue tasks which push the boundary of pragmatic reasoning, especially in less explored domains such as collaborative planning.



\paragraph{Modeling Pragmatics at Scale.}
We predict that the rise of multimodal pretraining \citep{lu2019vilbert, sun2019videobert, pmlr-v119-laskin20a, NEURIPS2021_99bf3d15} will unlock a broad range of pragmatically rich tasks. Data sparsity is a major obstacle in many current grounded language learning environments, and improved representations of linguistic and visual contexts should allow researchers to revisit challenging tasks for which existing training data is insufficient. Nevertheless, sparsity will likely continue to be an issue in interactive language domains, such as those with dyadic communication, due to the wide range of possible contexts and the difficulties of collecting interactive data. As a result, reasoning-based pragmatics, and the efficient language learning it enables, may increase in importance.
As NLP expands to an ever-wider range of contexts, we encourage work to include pragmatics as a central component, with the goal of communicating successfully --- and efficiently --- with people in challenging and useful settings.
























\clearpage\newpage
\section*{Limitations}
Although we aim to describe a representative sample of tasks in Table~\ref{tab:main}, our coverage is necessarily incomplete, especially in domains such as image captioning, instruction-following, and collaborative dialogue, so we refer readers to other surveys on these issues \citep[e.g.,][]{luketina2019survey}.
As noted in Section~\ref{sec:tasks}, we focus exclusively on task-oriented grounded domains involving natural language data. Our survey therefore includes limited discussion of pragmatic phenomena in unimodal text domains such as chitchat dialogue, purely textual task-oriented dialogue, and language classification tasks (although c.f.\ Section~\ref{sec:modeling-multi-turn} and Appendix~\ref{sec:unimodal}), and omits much work on analyzing the abilities of models to perform classic pragmatic tasks such as implicature and presupposition~\citep[\eg][]{ross-pavlick-2019-well,jeretic-etal-2020-natural}.
We also do not discuss tasks involving synthetic or emergent language, but see \citet{lazaridou2020emergent} for a survey of the latter.

Our discussion of modeling frameworks for pragmatics in \Cref{sec:pragmods} focuses on approaches that distinguish between semantics and pragmatics through social reasoning about other agents' beliefs and goals. Due to space limitations, we did not discuss alternate theories proposing that pragmatically enriched meanings are derived within the grammar of a language, without recourse to probabilistic social reasoning \citep[e.g.,][]{fox_free_2007,chierchia_grammatical_2012,asherov_irrelevance_2021}. These theories remain difficult to implement at scale, but we encourage future work to explore them as candidate hypotheses alongside the frameworks discussed in \Cref{sec:pragmods}.

There is also rich body of work on formalizing and modeling discourse context beyond the approaches we cover here, including conversational analysis~\citep{Schegloff1968-conversational-openings,Sacks1974-turn-taking} and discourse coherence and structure~\citep{Hobbs1979-coherence,Grosz1986-discourse,Webber1991-deixis,Kamp1993-discourse,Grosz1995-centering,Webber2003-anaphora,Asher2003-conversation,Barzilay2008-coherence}. We refer to \citet{Cohen1990-intentions-communication}, \citet{Clark1996-using-language}, \citet{Jurafsky2014-slp}, and \citet{alikhani-stone-2020-achieving} %
for entry points.

\section*{Acknowledgments} 
We are grateful to Alane Suhr, Justin Chiu, Jessy Lin, Kevin Yang, Ge Gao, Ana Smith, and Herbert Clark for early discussions that led to this survey. We also thank Chris Potts, Alane Suhr, Ari Holtzman, Victor Zhong, Laura Rimell, Chris Dyer, Saujas Vaduguru, Tao Yu, Allen Nie, and Dan Klein for their comments on drafts of our paper. Nicholas Tomlin is supported by the DARPA XAI and LwLL programs and a NSF Graduate Research Fellowship. Jennifer Hu is supported by a NSF Graduate Research Fellowship and a NSF Doctoral Dissertation Research Improvement Grant.

\daniel{collaborative construction tasks}


\bibliography{references}
\bibliographystyle{acl_natbib}

\clearpage\newpage
\appendix
\section{Types of Context}\label{ax:context}

In this section, we outline the broad types of context that lead to pragmatic enrichment of language, and point readers to \citet{levinson_presumptive_2000}, \citet{birner2012introduction}, or \citet{yule_pragmatics_1996}  for a more comprehensive discussion. 
In this paper we focus mainly on visual and embodied contexts, for several reasons. First, human communication is typically situated in settings with modalities beyond language, which makes it important to capture in order to build NLP models that interact naturally with humans in the world. Indeed, recent work has argued that grounding is an essential component of language understanding \citep[e.g.,][]{bisk2020experience,bender_climbing_2020}. Second, visual and embodied settings introduce enough complexity to elicit interesting linguistic behaviors and serve as a challenge for models, while still allowing researchers to control experimental aspects of the tasks. Finally, there has been a rapid increase in research on multimodal language learning, which makes studying pragmatics in these models and tasks timely and relevant.



\subsection{Common Ground}\label{subsec:common-ground}

To communicate successfully, speakers and listeners need to maintain a shared set of information, taken collectively to be \emph{common ground} \citep[e.g.,][]{lewis_convention_1969,stalnaker1978assertion,clark_grounding_1991,traum1994computational,stalnaker_common_2002,clark_common_2015}. 
A large body of work has demonstrated that humans produce and comprehend language in ways that depend on assumptions about the knowledge of their communicative partners \citep[e.g.,][]{krauss_concurrent_1966,horton_when_1996,nadig_evidence_2002,clark_repetition_2008,hilliard_bridging_2016,yoon_audience_2019,hawkins_partners_2021}.
Even in one-shot encounters where there is minimal partner-specific knowledge, the success of computational models of pragmatics \citep{frank2012predicting,goodman2016pragmatic} 
suggests that humans leverage a rich set of shared assumptions in pragmatic communication -- from broad expectations that their partners abide by cooperative principles \citep[e.g.,][]{grice1975logic,Horn1984-implicature} to fine-grained knowledge of the potential utterances, meanings, and utterance-meaning mappings under joint consideration. Below, we discuss some key elements of common ground that give rise to pragmatically enriched meanings in naturalistic communication.


\paragraph{Norms of Interaction.} As language is a social behavior, speakers and listeners typically abide by a set of norms. For example, \citet{grice1975logic} argues that it is generally understood that conversational partners act cooperatively and rationally. \citeauthor{grice1975logic} also proposes a set of maxims that govern communication---rational speakers should be concise, informative, and relevant. These norms in turn give rise to a variety of nonliteral inferences known as \emph{conversational implicatures}. 
Suppose, for example, Alice says to Bob: ``Carl ate some of the cookies that we baked for the party''. Bob likely draws the inference that Carl did not eat \emph{all} of the cookies, even though the literal meaning of the utterance -- that Carl ate at least one of the cookies -- is logically compatible with such a scenario. This inference can be explained in the following way: if Alice knows that Carl ate all the cookies, and if she wants to be informative, then she would have said ``Carl ate all of the cookies'' instead. 



\paragraph{Goals and Joint Actions.}
In addition to general norms of interaction, the particular social or task-related goals that elicit a linguistic expression can affect its meaning. The theory of \emph{speech acts}~\citep{Searle1969-speech-acts,Austin1975-things-with-words} frames utterances (\eg ``please stand up'') as actions on several levels: \emph{locutionary}, the utterance itself; \emph{illocutionary}, the intention (\eg asking the listener to stand up); and \emph{perlocutionary}, the actual effect that the action has in the world (\eg the listener stands up). 
Context can have strong effects on the illocutionary and perlocutionary levels. This is particularly true for formal speech acts which can only take effect under \emph{felicity conditions}, e.g. making a promise, or performing a marriage, but also occurs in commonplace situations \eg asking ``Did you get my email?'' might be an indirect request to reply, or a direct question while debugging an internet connection.
More generally, interlocutors typically recognize that they are undertaking \emph{joint activities} together with their partners~\citep{Clark1996-using-language} and try to collaboratively plan and act to coordinate on and realize the relevant goals.
These shared goals provide a source of context that enriches language.

\paragraph{Common Knowledge.} Interpretation is aided by prior information that interlocutors bring to an interaction. %
For example, suppose Alice asks ``What color was the woman's scarf?'' and Bob answers ``green''. If Bob is a fashion designer with a keen eye for color palettes, this might implicate that the scarf was a rather prototypical shade of green, and not olive green or chartreuse. On the other hand, if Bob doesn't know many specific color terms, Alice doesn't have grounds to infer that Bob meant to refer to a specific subspace of green. The world knowledge and commonsense relationships shared by conversational partners can also give rise to scalar implicatures formed by ad-hoc ordering relationships \citep{hirschberg_theory_1985} and lead to pedagogic behavior~\citep{Chai2019-interaction}. %

\paragraph{Discourse Context.} Communication is most often not a one-shot utterance, but instead unfolds over time. As a document or a conversation proceeds, the common ground can be updated with new information from the discourse context. At a basic level, discourse context includes previously-established information which can be referred to later on, whether explicitly (\eg \emph{a dog bounded into the room... \emph{it} barked}) or implicitly (\eg \emph{a dog bounded into the room... Sam was surprised}). Information can also be introduced implicitly, for example through presupposition and accommodation (\eg \emph{Alex stopped smoking} presupposes that Alex smoked). Implicitly-introduced information can in some cases (implicature) also be reinforced or denied, \eg \emph{Carl ate some of the cookies; indeed, he ate all of them!}.


\subsection{Multimodal Context}

So far, we have discussed aspects of context given by social or linguistic factors. While all of the above types of context also arise in grounded and multimodal settings, 
the physical context in which communication is situated also plays an additional component in deriving linguistic meaning. As mentioned above, we focus on visual and embodied contexts in this paper, as these contexts reflect naturalistic communication while also allowing for fine-grained experimental control.


\paragraph{Visual.} 
Visual context serves to disambiguate and enrich the language of meaning on multiple levels.
On a level close to semantics, visual context can disambiguate word senses: \eg ``bank'' likely has a different meaning in the caption of a photo of a river than in a photo of a city street.
Referring expressions (\eg \emph{the red one}) often can only be resolved in a visual context, and deictic expressions, like English \textit{here, there, this} and \textit{that}, are frequently used in language to individuate referents in their immediate context, relying on mutual knowledge of what the speaker and listener can see~\citep{Clark1981-definite-knowledge}. 
Reference intepretation can also be affected by the location of the speaker and hearer in the world~\citep{birner2012introduction},
and can involve physical analogues of implicature (\eg \emph{the black one} might be a good description for a dark grey object if all other visible objects are lighter)~\citep{golland-etal-2010-game,udagawa-etal-2020-linguistic}. 



\paragraph{Embodied.}
Facial expressions, gaze, and gestures~\citep{Cassell1994-animated,Traum2002-embodied,Sidner2005-explorations,Prasov2008-zf,Bohus2010-gaze,koller-etal-2012-enhancing,Yu2015-coordination} can aid interpretation if they are available, \eg a speaker first making eye contact with a listener, then looking at an intended object. 
Speakers can issue corrections if they are able to observe a listener carrying out actions~\cite{Clark2004-monitoring,Koller2010-give,Thomason2019-dialog-navigation,suhr-etal-2019-executing},
and the physical movements of the listener can intentionally convey uncertainty~\cite{Hough2017-grounding-uncertainty} and intent~\citep{Dragan2013-legibility}.
Physical properties of the environment and tasks~\citep{Chai2019-interaction} and the capabilities of the speaker and listener~\citep{Chai2014-bn}, also affect the interpretation and generation of commands and requests --- \eg the classic pragmatic example \emph{Can you pass the salt?}, which typically is an indirect request when spoken to a person, may have a literal interpretation when spoken to a robot with a faulty gripper.

\section{Unimodal Pragmatics}
\label{sec:unimodal}

Although we primarily focus on the role of pragmatics in grounded environments, several text-only tasks that emphasize specific pragmatic phenomena also exist. For example, IMPPRES \citep{jeretic-etal-2020-natural} and NOPE \citep{parrish-etal-2021-nope} are benchmark datasets designed to test whether large language models can reliably predict implicatures and presuppositions, respectively. Similarly, \citet{schuster_harnessing_2020} and \citet{li_predicting_2021} evaluate the ability of sentence encoding models to predict the rate at which humans draw scalar implicatures. Other datasets like the Self-Annotated Reddit Corpus (SARC) for sarcasm detection \citep{khodak-etal-2018-large} may also be viewed as pragmatic in nature \citep{kolchinski-potts-2018-representing}. While these datasets are limited to unimodal text, they have two main advantages over many multimodal tasks: (1) many unimodal pragmatic datasets are naturally-occurring, resulting in larger datasets with more realistic language, and (2) all of these datasets focus on specific pragmatic phenomena, such as presupposition. We suggest that future work on multimodal pragmatics should take inspiration from these properties and build larger and more targeted datasets.

A separate body of work has investigated situated language understanding through interactive fiction (IF) games \citep[e.g.,][]{ammanabrolu_situated_2021,hausknecht_interactive_2020,urbanek_learning_2019}.
IF games offer a framework for investigating goal-driven linguistic behaviors in a dynamic, richly structured world. Players observe natural-language descriptions of the simulated world, take actions via natural language, and receive scores based on their actions. The simulations are also partially observable, in that players must reason about the unerlying world state through incomplete textual descriptions of immediate surroundings. In this way, IF games avoid some of the practical issues of grounding in visual environments, while still requiring actions to be situated in rich, dynamic contexts. Furthermore, \citet{shridhar_alfworld_2021} demonstrate that commonsense priors learned through IF games can be leveraged for better generalization in visually grounded environments, suggesting that text-only games induce representations that can be adapted to multimodal settings.

\end{document}
