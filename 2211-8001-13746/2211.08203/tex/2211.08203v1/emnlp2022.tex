
% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
%\usepackage[review]{EMNLP2022}
\usepackage{EMNLP2022}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% FV Custom packages
\usepackage{todonotes}
\usepackage{amsmath} 
\usepackage[shortlabels]{enumitem}
\usepackage{comment}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{float}
\usepackage{xcolor}

% FV colores
\definecolor{verde}{rgb}{0.0, 0.5, 0.0}
\newcommand{\fv}[1]{{\color{verde} {#1}}}

% FV estamos usando el template de EMNLP 2022


% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}


% If the title and author information does not fit in the area allocated, uncomment the following
%
\setlength\titlebox{7.5cm}
%
% and set <dim> to something 5cm or larger.

\title{The Dependence on Frequency of Word Embedding Similarity Measures}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

%\author{First Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  \texttt{email@domain} \\\And
%  Second Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  \texttt{email@domain} \\}

\author{
    Francisco Valentini \\ 
        ICC (UBA-CONICET) \\ 
        Maestría en Data Mining (UBA) \\
        Buenos Aires, Argentina \\
        \texttt{ft.valentini@gmail.com} \\
    \AND
    Diego Fernandez Slezak \\
        ICC (UBA-CONICET) \\
        Buenos Aires, Argentina \\
        \texttt{dfslezak@dc.uba.ar} \\
    \And
    Edgar Altszyler \\
        ICC (UBA-CONICET) \\ 
        Maestría en Data Mining (UBA) \\
        Buenos Aires, Argentina \\
        \texttt{ealtszyler@dc.uba.ar} \\
}

%    \And
%    Germán Rosati \\
%        Escuela IDAES (UNSAM) \\
%        Buenos Aires, Argentina \\
%        \texttt{grosati@unsam.edu.ar} \\ 


\begin{document}
\maketitle
\begin{abstract}
Recent research has shown that static word embeddings can encode word frequency information. However, little has been studied about this phenomenon and its effects on downstream tasks. In the present work, we systematically study the association between frequency and semantic similarity in several static word embeddings. We find that Skip-gram, GloVe and FastText embeddings tend to produce higher semantic similarity between high-frequency words than between other frequency combinations. We show that the association between frequency and similarity also appears when words are randomly shuffled. This proves that the patterns found are not due to real semantic associations present in the texts, but are an artifact produced by the word embeddings. Finally, we provide an example of how word frequency can strongly impact the measurement of gender bias with embedding-based metrics. In particular, we carry out a controlled experiment that shows that biases can even change sign or reverse their order by manipulating word frequencies. 
\end{abstract}

\section{Introduction} \label{sec:introduction}

Static word embeddings have proven to encode semantic information of words and are therefore useful to solve tasks such as synonym selection and analogical reasoning  \citep{mikolov2013distributed, levy2015improving}. More recent contextualized representations have achieved better results \citep{ethayarajh2019contextual}, specially in tasks where the local context of words is important \citep{sezerer2021survey}. However, static word embeddings are still widely used in computational social science applications that study global aspects of specific corpora. For example, embeddings are trained on specific corpora and these are used to compute metrics that quantify societal biases and stereotypes that might be present in the text \citep{garg2018word, kozlowski2019geometry, defranza2020language, jones2020stereotypical, lewis2020gender, charlesworth2021gender}. Static word embeddings are also used in a large variety of applications such as topic coherence evaluation \cite{aletras2013evaluating}, dream theory analysis \cite{altszyler2017interpretation}, literature studies \cite{diuk2012quantitative}, and cognitive science studies \cite{mota2022imagetic}. 

Previous research has found static word embeddings appear to be associated with word frequency in various ways: word frequency correlates with embedding norm \citep{wilson2015controlled, arora2016latent}, the nearest neighbors of the embeddings of medium-frequency English words are more unstable \citep{hellrich2016bad}, there are frequency-related differences in the distribution of the inner products between target and context vectors \citep{mimno2017strange}, embeddings can accurately predict whether a word is frequent or rare \citep{schnabel2015evaluation}, and the visual inspection of their top principal components suggest they encode frequency \citep{gong2018frage, mu2018allbutthetop}. When it comes to using embeddings to measure bias in text, \citet{valentini2022undesirable} found that embedding-based bias metrics spuriously depend on word frequency. 

Even if it has been pointed out that embeddings can encode frequency, no research has been conducted to: 

\begin{itemize}
    \item Comprehensively describe the association between frequency and vector similarity in the most commonly used embeddings
    \item Determine if embeddings encode frequency due to undesirable properties of embeddings or actual properties of corpora
    \item Assess the repercussions of this frequency-based effect on a downstream task, such as bias measurement
    %\item Assess the repercussions of this frequency-based effect on computational social science bias measurements
\end{itemize}

This paper’s contribution is to address these still unexplored issues.

%\footnote{Code for the paper is available at \url{https://github.com/ftvalentini/EmbeddingsBiasFrequency}}

\section{The dependence of word embeddings on frequency} \label{sec:dependence}

As a first approach, we aim at describing the association between word frequency and cosine similarity, which is commonly used to measure semantic closeness between words.

We use a corpus built from the 2021 English Wikipedia dump, which is freely available, easily accessible and has been used in previous experiments \citep{levy2015improving}. We train embeddings with word2vec with skip-gram with negative-sampling (SGNS) \citep{mikolov2013distributed}, GloVe \citep{pennington2014glove} and FastText \citep{bojanowski2017enriching} with default hyperparameters (see details in Appendix \ref{app:methods}).

Words in the vocabulary are assigned to frequency bins according to the $\log_{10}$ of their frequency. We use matrices to represent the mean cosine similarity of randomly sampled pairs of words from the vocabulary, stratifying by frequency bins. 500 pairs are sampled for each combination of bins, excluding comparisons between the same word.  

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=\linewidth]{img/grid_heatmap-cosine.png}
    \caption{Mean cosine similarities between 500 random samples of word pairs for each combination of frequency bins, in embeddings trained on 2021 English Wikipedia.}
    \label{fig:cosine_unshuffled}
\end{figure*}

For the three methodologies considered, the mean cosine similarity is higher between high frequency words than between any other combination of frequencies (Figure \ref{fig:cosine_unshuffled}). Unlike SGNS and FastText, the mean similarity computed with GloVe is moderate to high between words of the same frequency range (the matrix diagonal) and low between words of different frequencies (e.g. words with $10^6$ vs $10^2$ frequencies). 

These results seem to suggest that word frequencies have an impact on how similar two words are, and raise the following questions: Does this originate from an artifact of the embeddings? Or does it reveal actual properties of the corpus? -- for example, that high-frequency words are actually semantically closer on average between themselves than with the rest of the vocabulary? We conduct the following study to answer this.


\subsection{Experiments} \label{sec:experiments}

Following \citet{valentini2022undesirable}’s approach, we create a randomly shuffled version of the Wikipedia corpus where tokens are randomly located across the text. Here words preserve their frequency but any contextual information is lost because co-occurrences are random. We train embeddings on this corpus and replicate the analysis from the previous section (as in Figure \ref{fig:cosine_unshuffled}). 

If any association is found between similarity and frequency in this setting, it should be explained only by the frequencies of the words. That is, if embeddings don’t capture frequency, we would expect a uniform distribution of the cosine similarity between embeddings across all frequency combinations: the similarity of any given pair of words should be on average the same.


\begin{figure*}[!ht]
    \centering
    \includegraphics[width=\linewidth]{img/grid_heatmap-cosine_shuffled.png}
    \caption{Mean cosine similarities between 500 random samples of word pairs for each combination of frequency bins, in embeddings trained on a shuffled version of 2021 English Wikipedia.}
    \label{fig:cosine_shuffled}
\end{figure*}

The mean cosine similarities of embeddings trained on the shuffled corpus turns out to depend on the frequencies of the words involved, and this happens in different ways depending on the methodology used (Figure \ref{fig:cosine_shuffled}). All three embeddings tend to yield high similarities when comparing frequent words between themselves (frequency around $10^4$ and above); and similarity tends to decrease when making other comparisons, in different ways depending on the embedding method. 

When employing a similarity measure based on euclidean distance, we find qualitatively the same result: the similarity of any two words depends heavily on their frequencies (Figure \ref{fig:euclidian_shuffled}). Therefore the frequency-based effect is not caused by the choice of cosine similarity metric. 

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=\linewidth]{img/grid_heatmap-euclidian_shuffled.png}
    \caption{Mean negative euclidean distance between 500 random samples of word pairs for each combination of frequency bins, in embeddings trained on a shuffled version of 2021 English Wikipedia.}
    \label{fig:euclidian_shuffled}
\end{figure*}


Shuffling words before training embeddings does not produce a uniform distribution of similarity across frequencies. This suggests that embeddings have a tendency to encode frequency. To further assess this we perform PCA on the embeddings of a sample of words stratified by frequency and plot the centroids of the top two components of each frequency bin (Figure \ref{fig:pca_centroids_unshuffled}). The plots show that the geometry of embeddings trained on the original corpus encodes frequency in training data. These results are consistent with the literature’s previous findings that word embeddings can encode word frequency (see section \ref{sec:introduction}). 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\linewidth]{img/grid_pca-centroids_wiki2021.png}
    \caption{Centroids of the top two principal components for each frequency bin in unshuffled Wikipedia. PCA was performed on the embeddings of a sample of 17 hundred words stratified by frequency (100 words by frequency bin). Figure \ref{fig:pca_points} in Appendix \ref{app:pca} contains the points used to compute these centroids.}
    \label{fig:pca_centroids_unshuffled}
\end{figure}

To validate that this does not originate from properties of the corpus, but is rather an artifact of embeddings, we also perform PCA on the embeddings trained on the shuffled corpus (Figure \ref{fig:pca_centroids_shuffled}). The same behavior is present to a larger degree: words of different frequencies tend to occupy different regions in the embedding space. Thus embedding-based similarity metrics will detect closeness even when there should be none.
 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\linewidth]{img/grid_pca-centroids_wiki2021s1.png}
    \caption{Centroids of the top two principal components for each frequency bin in shuffled Wikipedia. PCA was performed on the embeddings of a sample of 17 hundred words stratified by frequency (100 words by frequency bin). Figure \ref{fig:pca_points} in Appendix \ref{app:pca} contains the points used to compute these centroids.}
    \label{fig:pca_centroids_shuffled}
\end{figure}


\section{Assessing the impact} \label{sec:impact}

In computational social science, static word embeddings are typically used to measure societal biases and stereotypes potentially present in corpora. Here we study the impact of the dependence of embeddings on frequency on this type of studies. We highlight that this is different from measuring or mitigating biases in models or NLP. Our goal is to determine how much the individual frequency of words might distort the results obtained when measuring the biases and stereotypes of specific corpora using word embeddings.

To measure the bias of a target word $x$ we use the difference between the mean similarity of words of context groups $A$ and $B$ with respect to $x$:
%
\begin{equation} \label{eq:BiasWE} 
    \text{Bias}_{\text{WE}} = 
        \underset{a \in A}{\mathrm{mean}} \; \text{cos}(w_x,w_a) - 
        \underset{b \in B}{\mathrm{mean}} \; \text{cos}(w_x,w_b),
\end{equation}
%
where $w_i$ is the word embedding of word $i$ and $\text{cos}(w_i,w_j)$ is the cosine similarity between vectors.

$A$ and $B$ are set according to the bias to be measured. For example, to measure binary (female/male) gender bias, $A$ and $B$ are typically composed of gendered nouns and pronouns \citep{caliskan2017semantics,lewis2020gender,kozlowski2019geometry}. 

\subsection{Experimental setup} \label{sec:impact_experiment}

To measure the sensitivity of embedding-based bias with respect to changes in the frequencies of context words, we use the female/male gender bias as a test case which has been thoroughly studied in previous work and has shown to correlate with human judgment \citep{garg2018word, kozlowski2019geometry, defranza2020language, jones2020stereotypical, lewis2020gender, charlesworth2021gender}. 

We measure gender bias with equation \ref{eq:BiasWE} using $A=\{\textit{she}\}$ and $B=\{\textit{he}\}$. We seek to train embeddings on corpora where one of the words ($A$) retains the frequency from the original corpus, whereas the other word ($B$) has a desired frequency level. To achieve this we randomly drop sentences containing $B$ until achieving the target frequency. We define three target frequencies for $B$: $10^4$, $10^5$, and $10^6$. This implies creating three additional resampled corpora (see Table \ref{tab:downsampling_freqs} for reference). 


%\begin{table}[H]
\begin{table}
\centering
\begin{tabular}{|c|c|c|}
\hline
                        & \emph{she} ($A$)  & \emph{he} ($B$)  \\ \hline
Wikipedia               & $10^{6.55}$       & $10^{7.07}$  \\ \hline
Downsampled Wikipedia 1 & $10^{6.53}$          & $10^{6}$  \\ \hline
Downsampled Wikipedia 2 & $10^{6.52}$          & $10^{5}$  \\ \hline
Downsampled Wikipedia 3 & $10^{6.52}$          & $10^{4}$  \\ \hline
\end{tabular}
\caption{Frequencies of context words in the downsampling experiment. When randomly dropping sentences containing word $B$, the frequency of word $A$ also decreases but only to a minor extent.}
\label{tab:downsampling_freqs}
\end{table}


With the embeddings trained on the resampled corpora and on the original Wikipedia, we compute equation \ref{eq:BiasWE} on a large set of target words where gender bias has been previously measured. These are the words from the Glasgow Norms, a set of around 5,500 words with a score of gender association as perceived by human judgment \citep{scott2019glasgow}. See details in Appendix \ref{app:impact}.

Given the results of section \ref{sec:dependence}, our hypothesis is that bias can be heavily dependent on the frequencies of the context words. In other words, answers to questions of the type "\emph{what are the most gender-biased words in this corpus?}" can be highly dependent on the frequencies of words in the corpus being studied.

Whereas previous works usually assign multiple gendered words to the context groups, we choose to use only one word in each group because it allows us to ascribe any shifts in bias to the variation in the frequency of one of the words. This simplifies the experiment and the conclusions we can derive from it.


\subsection{Results} \label{sec:impact_results}

The impact of the frequency effect on gender bias measurements varies according to the set of embeddings used (Figure \ref{fig:impact_gender}). 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\linewidth]{img/grid_impact-gender.png}
    \caption{Female/male gender bias of a selection of 4,384 target words according to their frequencies. Each value in the horizontal axis represents a different corpus where the frequency of $B$ (\textit{he}) varies and the frequency of $A$ (\textit{she}) is approximately constant (see Table \ref{tab:downsampling_freqs} for reference). The mean bias for each frequency bin is plotted together with bootstrap confidence intervals.}
    \label{fig:impact_gender}
\end{figure}

SGNS exhibits a problem when measuring bias in high frequency words. In these words the association between $\text{Bias}_{\operatorname{WE}}$ and the frequency of $B$ is negative (yellow curve in Figure \ref{fig:impact_gender}), while it is approximately constant for the rest of the frequency ranges. 

When using FastText embeddings, this negative association is observed across all frequency ranges. Moreover, when the frequency of \textit{he} is low enough, all words have a positive (female) bias. This means the bias of specific target words might appear to be high, when in fact the average bias of \textit{all} words is high.

%that if bias is computed with context words of different frequencies,
%(as we move to the left on the horizontal axis)

The frequency of context words has the most influence on gender bias when measured with GloVe, as there are very different effects depending on the frequency range of the target words. Not only the value of bias, but the ranking of bias, is highly dependent on the frequencies of the words being compared. More frequent target words tend to stick to the more frequent context word and less frequent words are attracted to the less frequent context. 

For all three embeddings we see that the values of bias can change substantially even if the underlying distribution of co-occurrences remains constant. These shifts are attributable to the change in the frequencies of context words, and this is an undesirable property in similarity measurements. In Appendix \ref{app:impact} we show that when undersampling word $A$ instead of $B$ the frequency dependence still exists.  

This frequency-based effect can lead to erroneous conclusions when studying the bias of specific words. To portray this we perform a qualitative analysis of $\text{Bias}_{\operatorname{WE}}$ with GloVe, which seems to have the strongest frequency-based distortion. 

We classify words by their perceived genderedness according to human judgment: “male” if their Glasgow gender norm is equal to or less than 2, “female” if it is 6 or higher, and “neutral” otherwise. For each class of words we sample a word for each one of five frequency bins and we study the changes in bias according to the frequency of \textit{he} in the corpus (Figure \ref{fig:impact_gender_words_glove}).

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=\linewidth]{img/impact-gender-words_glove.png}
    \caption{Female/male gender bias of words measured with GloVe. We sampled one word for each frequency bin and each class of words according to their perceived genderedness by human judgment ("female-associated", "male-associated", and "neutral"). Each value in the horizontal axis represents a different corpus where the frequency of $B$ (\textit{he}) varies and the frequency of $A$ (\textit{she}) is approximately constant (see Table \ref{tab:downsampling_freqs} for reference).}
    \label{fig:impact_gender_words_glove}
\end{figure*}


As observed previously in Figure \ref{fig:impact_gender}, the $\text{Bias}_{\operatorname{WE}}$ of frequent words (frequency $10^5$ onwards) is inversely correlated to the frequency of \textit{he}, while the association is positive for less frequent words (below $10^4$ occurrences). This occurs regardless of whether the words are perceived to be "male", "female" or "neutral". 

The bias is so dependent on the frequencies of the context words that the ranking of words can be reverted. For instance, if the frequency of \textit{he} is low enough, we might end up believing that “male-associated” words like \textit{war} and \textit{battle}, or “neutral” words as \textit{new} or \textit{art}, are female-biased words in our corpus, with even larger values than \textit{hostess}. At the same time, \textit{lioness} might tend to appear as male-biased, even more than \textit{wrestler}, \textit{battle} or \textit{war}.\footnote{We provide figures for the same words with SGNS and FastText in Appendix \ref{app:impact}.} 


\section{Conclusions} \label{sec:conclusion}

Static word embeddings serve as useful tools for computing semantic similarity between words since they capture the semantics of words. To assess biases in texts, computational social scientists frequently use word embedding similarity as a metric.

Static word embeddings can encode information on word frequency, according to earlier research. We examine the relationship between frequency and semantic similarity in SGNS, FastText, and GloVe embeddings in greater detail in this work. We find that the frequency of the words being compared affects their similarity score. This dependence is also present when words in the training corpus are randomly shuffled, demonstrating that the behavior is an artifact of the embeddings and not a result of actual associations found in the text.

In computational social science applications like bias measurement, the propensity of embeddings to encode frequency hampers their ability to measure semantic closeness. We conduct a controlled experiment that illustrates how measuring gender bias using embedding-based metrics might produce inaccurate results. The results indicate that the frequency of words in the corpus can have a significant impact on the answers to questions like "\emph{what are the most gender biased terms?}" as biases can change sign or ranking when word frequencies are changed.

%In order to neutralize the frequency-based distortion, using context words with similar frequencies while computing bias seems to be a smart idea, if possible. Another option might be to use groups of context words which on average have similar frequencies. By doing this, many studies unintentionally get around the frequency problem. We show that word frequencies should not be ignored when measuring semantic similarity and that it is not advisable to treat this "unintentionally”.



%\section*{Limitations} \label{sec:limitations}

%Our analyses are restricted to the English language and are based on a binary understanding of gender (see \nameref{sec:limitations}).

%We use sets of context words typically used in the gender bias literature. These words imply a binary understanding of gender, excluding other gender representations from the bias measurement. Moreover, we focus exclusively on the English Wikipedia corpus and do not apply methods on corpora of other domains, which might yield different distributions of gender bias. 

%We report results using default hyperparameters. This intends to mimic the typical experimental setup found in the Computational Social Science literature. Hyperparameters are left at their default values because there is no ground truth for biases, i.e. there are no annotations indicating the level of bias of words.

%The studies conducted in this work can be adapted to other languages, other biases and other corpora. We hope further research can assess the frequency-based distortion in these settings as well as the influence of hyperparameter choices.


% Entries for the entire Anthology, followed by custom entries
\bibliographystyle{acl_natbib}
\bibliography{custom}
%\bibliography{anthology,custom}

\appendix

\section{Data and methods} \label{app:methods}

We built the Wikipedia corpus from April 2021 English Wikipedia dump (\url{https://archive.org/download/enwiki-20210401}), removing articles with less than 50 words. Pre-processing includes sentence splitting, lowercasing and removing non alpha-numeric symbols, and produces a corpus of 78 million sentences and 1.2 billion tokens.

We train word embeddings with 300 dimensions. All words with less than 100 occurrences are removed before obtaining word-context pairs and we use a sliding window size of 10 tokens. SGNS and FastText are trained with Gensim's implementation \citep{rehurek2010gensim}, and GloVe is trained with \citet{pennington2014glove}'s implementation. 


\section{Principal Components Analysis} \label{app:pca}

Figure \ref{fig:pca_points} displays the principal components of the words used to perform PCA, which are used to compute the centroids in Figures \ref{fig:pca_centroids_unshuffled} and \ref{fig:pca_centroids_shuffled}.

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\linewidth]{img/grid_pca-scatter.png}
    \caption{Top two principal components of embeddings trained on unshuffled Wikipedia (left) and shuffled Wikipedia (right). The points represent the sample of 17 hundred words stratified by frequency used to perform PCA (100 words by frequency bin). These points are used to compute the centroids in Figures \ref{fig:pca_centroids_unshuffled} and \ref{fig:pca_centroids_shuffled}.}
    \label{fig:pca_points}
\end{figure*}


\section{Impact on gender bias measurement} \label{app:impact}

The Glasgow Norms \citep{scott2019glasgow} comprise a set of 5,553 English words rated by subjects who were asked to measure the degree to which each word is associated with male or female behavior on a scale from 1 (feminine) to 7 (masculine). We flip the scale so that the norm represents femaleness according to human judgment. 

We discard the norms of homonyms and of words with uppercase characters. Moreover, we only consider words that are in the vocabularies of all embeddings trained on the original corpus and the downsampled corpora. Finally, we drop any words that change their frequency bin between different corpora. This results in a set of 4,384 words to make Figure \ref{fig:impact_gender}.

%(see Table \ref{tab:downsampling_freqs} for reference)

In Figures \ref{fig:impact_gender_words_sgns} and \ref{fig:impact_gender_words_fasttext} we replicate the analysis of specific words for SGNS and FastText, respectively. These words are a subset of the words used to make Figure \ref{fig:impact_gender}. 

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\linewidth]{img/impact-gender-words_sgns.png}
    \caption{SGNS female/male gender bias of words in the experiment that downsamples $B$ (\textit{he}).}
    \label{fig:impact_gender_words_sgns}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\linewidth]{img/impact-gender-words_fasttext.png}
    \caption{FastText female/male gender bias of words in the experiment that downsamples $B$ (\textit{he}).}
    \label{fig:impact_gender_words_fasttext}
\end{figure*}


Figure \ref{fig:impact_gender_she} shows the effect of undersampling word $A$ (\textit{she}) instead of $B$ (\textit{he}). The frequencies employed in this experiment are in Table \ref{tab:downsampling_freqs_she}. In the same manner as in section \ref{sec:impact_results}, GloVe exhibits the highest frequency-based distortion, as more frequent target words stick to the more frequent context word (here, \textit{he}) and less frequent words are attracted to the less frequent context (\textit{she}). SGNS also presents the same effect in high frequency words as the one observed in Figure \ref{fig:impact_gender}. The main difference with respect to the experiment in section \ref{sec:impact_results} occurs with FastText. We have no hypothesis about the reason for this discrepancy.  

%\begin{table}[H]
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
                        & \emph{she} ($A$)  & \emph{he} ($B$)  \\ \hline
Wikipedia               & $10^{6.55}$       & $10^{7.07}$  \\ \hline
Downsampled Wikipedia 1 & $10^{6}$          & $10^{7.07}$  \\ \hline
Downsampled Wikipedia 2 & $10^{5}$          & $10^{7.07}$  \\ \hline
Downsampled Wikipedia 3 & $10^{4}$          & $10^{7.07}$  \\ \hline
\end{tabular}
\caption{Frequencies of context words in the downsampling experiment that varies the frequency of word $A$. When randomly dropping sentences containing $A$, the frequency of word $B$ also decreases but to a minor extent.}
\label{tab:downsampling_freqs_she}
\end{table}



\begin{figure*}[ht]
    \centering
    \includegraphics[width=\linewidth]{img/grid_impact-gender_SHE.png}
    \caption{Female/male gender bias of a selection of 4,384 target words according to their frequencies. Each value in the horizontal axis represents a different corpus where the frequency of $A$ (\textit{she}) varies and the frequency of $B$ (\textit{he}) is approximately constant (see Table \ref{tab:downsampling_freqs_she} for reference). The mean bias for each frequency bin is plotted together with bootstrap confidence intervals.}
    \label{fig:impact_gender_she}
\end{figure*}




%We measure female vs. male gender using gendered nouns and pronouns \citep{caliskan2017semantics,lewis2020gender}, namely, A=\textit{\{female, woman, girl, sister, she, her, hers, daughter\}} and B=\textit{\{male, man, boy, brother, he, him, his, son\}}. 

%Tables \ref{tab:female_frequencies} and \ref{tab:male_frequencies} display the frequency of each of these words in the pre-processed Wikipedia corpus.

%\begin{table}[H]
%\centering
%\begin{tabular}{lr}
%\toprule
%Word & Frequency\\
%\midrule
%her & 3,720,408\\
%she & 3,517,570\\
%daughter & 294,043\\
%female & 282,159\\
%woman & 236,954\\
%sister & 179,511\\
%girl & 141,616\\
%hers & 5,706\\
%\bottomrule
%\end{tabular}
%\caption{Frequencies of female context words in the Wikipedia corpus}
%\label{tab:female_frequencies}
%\end{table}

%We exclude words with fewer than 100 occurrences, which yields a vocabulary of 222,144 words. Table \ref{tab:frequency_distribution} displays the distribution of these words according to their frequencies, excluding the female and male context words. 

%\begin{table}[H]
%\centering
%\begin{tabular}{lr}
%\toprule
%Frequency & \# words\\
%\midrule
%$[10^{2},10^{2.5}]$ & 116,340\\
%$(10^{2.5},10^{3}]$ & 54,187\\
%$(10^{3},10^{3.5}]$ & 26,617\\
%$(10^{3.5},10^{4}]$ & 13,144\\
%$(10^{4},10^{4.5}]$ & 6,579\\
%$(10^{4.5},10^{5}]$ & 3,255\\
%$(10^{5},10^{5.5}]$ & 1,448\\
%$(10^{5.5},10^{6}]$ & 441\\
%$(10^{6},10^{8.12}]$ & 117\\
%\bottomrule
%\end{tabular}
%\caption{Number of words in each frequency range in the Wikipedia corpus}
%\label{tab:frequency_distribution}
%\end{table}

%In section \ref{sec:experiments} we use pretrained GloVe embeddings trained on Wikipedia 2014 and Gigaword 5 \citep{pennington2014glove}, and Word2Vec SGNS embeddings trained on Google News \citep{mikolov2013distributed}, both with 300 dimensions. %These were downloaded and used with the gensim library (ref).

%All methods employed in sections \ref{sec:bias_unshuffled} and \ref{sec:bias_shuffled} (GloVe, SGNS and PMI) use a window size of 10 and remove out-of-vocabulary tokens before the corpus is processed into word-context pairs \citep{levy2015improving}.

%For SGNS we use the Word2Vec implementation available in the Gensim library \citep{rehurek2010gensim} with default hyperparameters. GloVe is trained with \citet{pennington2014glove}’s implementation with 100 iterations. 
%This version uses additive word representations, such that each word embedding is the sum of its corresponding context and word vectors. 

%For PMI, we count co-occurrences with the GloVe module \citep{pennington2014glove} and set the smoothing parameter $\epsilon$ to 0.01, so that it can be computed whenever there are no co-occurrences between the target word and any of the context words. 

%All computations were performed on a desktop machine with 4 cores Intel Core i5-4460 CPU @ 3.20GHz and 32 GB RAM. Training took around 30 minutes per iteration with GloVe and 2 hours per epoch with SGNS.


% FV templates de tabla:

%\begin{table*}
%\centering
%\begin{tabular}{lll}
%\hline
%\textbf{Output} & \textbf{natbib command} & \textbf{Old ACL-style command}\\
%\hline
%\citealp{ct1965} & \verb|\citealp| & no equivalent \\
%\citeyearpar{ct1965} & \verb|\citeyearpar| & \verb|\shortcite| \\
%\citeposs{ct1965} & \verb|\citeposs| & no equivalent \\
%\citep[FFT;][]{ct1965} &  \verb|\citep[FFT;][]| & no equivalent\\
%\hline
%\end{tabular}
%\caption{\label{citation-guide}
%XYZ.
%}
%\end{table*}

%\begin{table}
%\centering
%\begin{tabular}{lc}
%\hline
%\textbf{Command} & \textbf{Output}\\
%\hline
%\verb|{\"a}| & {\"a} \\
%\verb|{\aa}| & {\aa}  \\\hline
%\end{tabular}
%\begin{tabular}{lc}
%\hline
%\textbf{Command} & \textbf{Output}\\
%\hline
%\verb|{\c c}| & {\c c} \\ 
%\verb|{\ss}| & {\ss} \\
%\hline
%\end{tabular}
%\caption{XYZ \emph{e.g.}, XYZ.}
%\label{tab:accents}
%\end{table}


%\begin{figure*}[!h]
%  \begin{center}
%    \includegraphics[width=\linewidth]{wefats_grid.png}
%  \end{center}


%\begin{description}[wide,itemindent=\labelsep]
%\item[Methods and data] We measure the gender bias of words in the vocabulary of the 2021 English Wikipedia with $\text{Bias}_{\operatorname{PMI}}$ and $\text{Bias}_{\operatorname{WE}}$ and assess the association with word frequency. 
%\end{description}


%\begin{table}[H]
%\centering
%\begin{tabular}{|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|} 
% \hline
% Context word  & Wiki. frequency &  Downsampled Wiki. 1 frequency &  Downsampled Wiki. 2 frequency &  Downsampled Wiki. 3 frequency &   \\ \hline
% \emph{she} ($A$)  & $10^{6.55}$ & $10^6$ & $10^5$ & $10^4$ \\ \hline
% \emph{she} ($A$)  & $10^6.55$ & $10^6$ & $10^5$ & $10^4$ \\ \hline
%\end{tabular}
%\caption{Frequencies of context words in the downsampling experiment that %varies the frequency of word $A$. When randomly dropping sentences containing %$A$, the frequency of word B also decreases but to a minor extent.}
%\label{tab:downsampling_freqs_she}
%\end{table}
%


%\begin{figure}[!ht]
%    \centering
%    \includegraphics[width=\linewidth]{img/grid_pca-scatter_wiki2021s1.png}
%    \caption{Top two principal components of embeddings trained on shuffled Wikipedia of a sample of 17 hundred words stratified by frequency (100 words by frequency bin). These points are used to compute the centroids in Figure \ref{fig:pca_centroids_shuffled}.}
%    \label{fig:pca_points_shuffled}
%\end{figure}



\end{document}
