\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{color}
\usepackage{epstopdf}
\usepackage{setspace} 

\linespread{1.2}

\def\eg{\emph{e.g.}}
\def\Eg{\emph{E.g.}}
\def\etal{\emph{et~al.}}
\def\ie{\emph{i.e.}}
\usepackage[a4paper, total={6in, 9in}]{geometry}
\pagenumbering{arabic}
\usepackage{fancyhdr}
\pagestyle{fancy}
\chead{Submission to IEEE Transactions on Pattern Analysis and Machine Intelligence}



\begin{document}
\setlength{\baselineskip}{1.5\baselineskip}
\noindent Dear Editor and Reviewers,
\vspace{1em}

We wish to submit our original research manuscript entitled ``Integrating Uncertainty into Gait Recognition for Out-of-Target-Scope Recognition'' by Heming Du, Chen Liu, Ming Wang, Lincheng Li, Shunli Zhang, and Xin Yu, for consideration by IEEE Transactions on Pattern Analysis and Machine Intelligence.

The work described has not been submitted elsewhere for publication, in whole or in part, and all the authors listed have approved the manuscript that is enclosed.


We believe the paper may be of particular interest to the readers of IEEE Transactions on Pattern Analysis and Machine Intelligence as it focuses on the topic of gait recognition. The novelties and contributions of the paper are summarized as follows:
\begin{enumerate}
    \vspace{-1em}
    \item Unlike existing gait recognition methods that focus only on In-Target-Scope (ITS) queries, we propose a unified uncertainty-aware gait recognition framework that can tackle both ITS and Out-of-Target-Scope (OTS) queries.
    \vspace{-1em}
    \item We model the uncertainty of the retrieved identity by applying the theory of evidential deep learning to represent the probability density. 
    \vspace{-1em}
    \item Our method is agnostic against gait recognition backbones. It can be adopted by existing methods with minimal effort to address OTS queries, thus significantly improving their robustness.
    \vspace{-1em}
\end{enumerate}

Experimental results show that achieves state-of-the-art performance on several commonly used benchmark datasets.

Thank you very much for your attention to our paper.


\vspace{2em}
\hfill \noindent Yours sincerely,

\hfill \noindent Heming Du, Chen Liu, Ming Wang, Lincheng Li, Shunli Zhang, and Xin Yu\\

\vspace{7em}
\noindent Corresponding author:\\
Name: Xin Yu,\\
Address: School of Electrical Engineering and Computer Science, The University of Queensland, Brisbane, Queensland, Australia\\
Phone: +61 410015363\\
Email: xin.yu@uq.edu.au
\newpage
\end{document}