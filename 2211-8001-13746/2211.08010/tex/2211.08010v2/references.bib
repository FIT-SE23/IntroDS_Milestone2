@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial Intelligence and Statistics},
  pages={1273--1282},
  year={2017}
}

@inproceedings{yurochkin2019bayesian,
  title={{B}ayesian Nonparametric Federated Learning of Neural Networks},
  author={Yurochkin, Mikhail and Agarwal, Mayank and Ghosh, Soumya and Greenewald, Kristjan and Hoang, Nghia and Khazaeni, Yasaman},
  booktitle={International Conference on Machine Learning},
  pages={7252--7261},
  year={2019}
}

@article{wang2020federated,
  title={Federated learning with matched averaging},
  author={Wang, Hongyi and Yurochkin, Mikhail and Sun, Yuekai and Papailiopoulos, Dimitris and Khazaeni, Yasaman},
  journal={arXiv preprint arXiv:2002.06440},
  year={2020}
}

@article{xiao2020averaging,
  title={Averaging is probably not the optimum way of aggregating parameters in federated learning},
  author={Xiao, Peng and Cheng, Samuel and Stankovic, Vladimir and Vukobratovic, Dejan},
  journal={Entropy},
  volume={22},
  number={3},
  pages={314},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{li2018federated,
  title={Federated optimization in heterogeneous networks},
  author={Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  journal={arXiv preprint arXiv:1812.06127},
  year={2018}
}

@inproceedings{teh2007stick,
  title={Stick-breaking construction for the {I}ndian buffet process},
  author={Teh, Yee Whye and Gr{\"u}r, Dilan and Ghahramani, Zoubin},
  booktitle={Artificial Intelligence and Statistics},
  pages={556--563},
  year={2007}
}

@article{kuhn1955hungarian,
  title={The {H}ungarian method for the assignment problem},
  author={Kuhn, Harold W},
  journal={Naval research logistics quarterly},
  volume={2},
  number={1-2},
  pages={83--97},
  year={1955},
  publisher={Wiley Online Library}
}

@article{2007Hierarchical,
  title={Hierarchical {B}eta Processes and the {I}ndian Buffet Process},
  author={ Thibaux, Romain  and  Jordan, Michael I. },
  journal={Journal of Machine Learning Research},
  volume={2},
  number={3},
  pages={564-571},
  year={2007},
}

@article{2011The,
  title={The {I}ndian Buffet Process: An Introduction and Review},
  author={ Griffiths, Thomas L.  and  Ghahramani, Zoubin },
  journal={Journal of Machine Learning Research},
  volume={12},
  number={2},
  pages={1185-1224},
  year={2011},
}

@inproceedings{smith2017federated,
  title={Federated multi-task learning},
  author={Smith, Virginia and Chiang, Chao-Kai and Sanjabi, Maziar and Talwalkar, Ameet S},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4424--4434},
  year={2017}
}

@inproceedings{mohri2019agnostic,
  title={Agnostic Federated Learning},
  author={Mohri, Mehryar and Sivek, Gary and Suresh, Ananda Theertha},
  booktitle={International Conference on Machine Learning},
  pages={4615--4625},
  year={2019}
}

@article{claici2020model,
  title={Model Fusion with {K}ullback--{L}eibler Divergence},
  author={Claici, Sebastian and Yurochkin, Mikhail and Ghosh, Soumya and Solomon, Justin},
  journal={arXiv preprint arXiv:2007.06168},
  year={2020}
}

@article{paszke2017automatic,
  title={Automatic differentiation in pytorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}

@inproceedings{reddi2018convergence,
  title={On the Convergence of {A}dam and Beyond},
  author={Reddi, Sashank J and Kale, Satyen and Kumar, Sanjiv},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{dekel2012optimal,
  title={Optimal distributed online prediction using mini-batches},
  author={Dekel, Ofer and Gilad-Bachrach, Ran and Shamir, Ohad and Xiao, Lin},
  journal={The Journal of Machine Learning Research},
  volume={13},
  pages={165--202},
  year={2012},
  publisher={JMLR. org}
}

@inproceedings{dean2012large,
  title={Large scale distributed deep networks},
  author={Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Ranzato, Marc'aurelio and Senior, Andrew and Tucker, Paul and Yang, Ke and others},
  booktitle={Advances in neural information processing systems},
  pages={1223--1231},
  year={2012}
}

@article{zhang2013communication,
  title={Communication-efficient algorithms for statistical optimization},
  author={Zhang, Yuchen and Duchi, John C and Wainwright, Martin J},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={3321--3363},
  year={2013},
  publisher={JMLR. org}
}

@inproceedings{li2014communication,
  title={Communication efficient distributed machine learning with the parameter server},
  author={Li, Mu and Andersen, David G and Smola, Alexander J and Yu, Kai},
  booktitle={Advances in Neural Information Processing Systems},
  pages={19--27},
  year={2014}
}

@inproceedings{shamir2014communication,
  title={Communication-efficient distributed optimization using an approximate newton-type method},
  author={Shamir, Ohad and Srebro, Nati and Zhang, Tong},
  booktitle={International conference on machine learning},
  pages={1000--1008},
  year={2014}
}

@article{gao2020federated,
  title={Federated Region-Learning for Environment Sensing in Edge Computing System},
  author={Gao, Yujia and Liu, Liang and Hu, Binxuan and Lei, Tianzi and Ma, Huadong},
  journal={IEEE Transactions on Network Science and Engineering},
  year={2020},
  publisher={IEEE}
}

@article{wang2020learning,
  title={Learning in the Air: Secure Federated Learning for {UAV}-Assisted Crowdsensing},
  author={Wang, Yuntao and Su, Zhou and Zhang, Ning and Benslimane, Abderrahim},
  journal={IEEE Transactions on Network Science and Engineering},
  year={2020},
  publisher={IEEE}
}

@article{kairouz2019advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Keith and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={arXiv preprint arXiv:1912.04977},
  year={2019}
}

@article{bonawitz2019towards,
  title={Towards federated learning at scale: System design},
  author={Bonawitz, Keith and Eichner, Hubert and Grieskamp, Wolfgang and Huba, Dzmitry and Ingerman, Alex and Ivanov, Vladimir and Kiddon, Chloe and Kone{\v{c}}n{\`y}, Jakub and Mazzocchi, Stefano and McMahan, H Brendan and others},
  journal={arXiv preprint arXiv:1902.01046},
  year={2019}
}

@inproceedings{thibaux2007hierarchical,
  title={Hierarchical {B}eta processes and the {I}ndian buffet process},
  author={Thibaux, Romain and Jordan, Michael I},
  booktitle={Artificial Intelligence and Statistics},
  pages={564--571},
  year={2007}
}

@inproceedings{ghahramani2006infinite,
  title={Infinite latent feature models and the {I}ndian buffet process},
  author={Ghahramani, Zoubin and Griffiths, Thomas L},
  booktitle={Advances in neural information processing systems},
  pages={475--482},
  year={2006}
}

@inproceedings{karimireddy2020scaffold,
  title={Scaffold: Stochastic controlled averaging for federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={International Conference on Machine Learning},
  pages={5132--5143},
  year={2020},
  organization={PMLR}
}

@article{zhang2020fedpd,
  title={Fedpd: A federated learning framework with optimal rates and adaptivity to non-iid data},
  author={Zhang, Xinwei and Hong, Mingyi and Dhople, Sairaj and Yin, Wotao and Liu, Yang},
  journal={arXiv preprint arXiv:2005.11418},
  year={2020}
}

@article{deng2021distributionally,
  title={Distributionally robust federated averaging},
  author={Deng, Yuyang and Kamani, Mohammad Mahdi and Mahdavi, Mehrdad},
  journal={arXiv preprint arXiv:2102.12660},
  year={2021}
}

@article{singh2020model,
  title={Model fusion via optimal transport},
  author={Singh, Sidak Pal and Jaggi, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{leontev2020non,
  title={Non-iterative knowledge fusion in deep convolutional neural networks},
  author={Leontev, Mikhail Iu and Islenteva, Viktoriia and Sukhov, Sergey V},
  journal={Neural Processing Letters},
  volume={51},
  number={1},
  pages={1--22},
  year={2020},
  publisher={Springer}
}

@article{lin2020ensemble,
  title={Ensemble distillation for robust model fusion in federated learning},
  author={Lin, Tao and Kong, Lingjing and Stich, Sebastian U and Jaggi, Martin},
  journal={arXiv preprint arXiv:2006.07242},
  year={2020}
}
















@article{2011The,
  title={The {I}ndian Buffet Process: An Introduction and Review},
  author={ Griffiths, Thomas L.  and  Ghahramani, Zoubin },
  journal={Journal of Machine Learning Research},
  volume={12},
  number={2},
  pages={1185-1224},
  year={2011},
}




@article{dekel2012optimal,
  title={Optimal distributed online prediction using mini-batches},
  author={Dekel, Ofer and Gilad-Bachrach, Ran and Shamir, Ohad and Xiao, Lin},
  journal={The Journal of Machine Learning Research},
  volume={13},
  pages={165--202},
  year={2012},
  publisher={JMLR. org}
}

@inproceedings{dean2012large,
  title={Large scale distributed deep networks},
  author={Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Ranzato, Marc'aurelio and Senior, Andrew and Tucker, Paul and Yang, Ke and others},
  booktitle={Advances in neural information processing systems},
  pages={1223--1231},
  year={2012}
}

@article{zhang2013communication,
  title={Communication-efficient algorithms for statistical optimization},
  author={Zhang, Yuchen and Duchi, John C and Wainwright, Martin J},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={3321--3363},
  year={2013},
  publisher={JMLR. org}
}

@inproceedings{li2014communication,
  title={Communication efficient distributed machine learning with the parameter server},
  author={Li, Mu and Andersen, David G and Smola, Alexander J and Yu, Kai},
  booktitle={Advances in Neural Information Processing Systems},
  pages={19--27},
  year={2014}
}

@inproceedings{shamir2014communication,
  title={Communication-efficient distributed optimization using an approximate newton-type method},
  author={Shamir, Ohad and Srebro, Nati and Zhang, Tong},
  booktitle={International conference on machine learning},
  pages={1000--1008},
  year={2014}
}

@article{gao2020federated,
  title={Federated Region-Learning for Environment Sensing in Edge Computing System},
  author={Gao, Yujia and Liu, Liang and Hu, Binxuan and Lei, Tianzi and Ma, Huadong},
  journal={IEEE Transactions on Network Science and Engineering},
  year={2020},
  publisher={IEEE}
}


@article{kairouz2019advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Keith and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={arXiv preprint arXiv:1912.04977},
  year={2019}
}

@article{bonawitz2019towards,
  title={Towards federated learning at scale: System design},
  author={Bonawitz, Keith and Eichner, Hubert and Grieskamp, Wolfgang and Huba, Dzmitry and Ingerman, Alex and Ivanov, Vladimir and Kiddon, Chloe and Kone{\v{c}}n{\`y}, Jakub and Mazzocchi, Stefano and McMahan, H Brendan and others},
  journal={arXiv preprint arXiv:1902.01046},
  year={2019}
}


@article{chen2020fedbe,
  title={Fedbe: Making {B}ayesian model ensemble applicable to federated learning},
  author={Chen, Hong-You and Chao, Wei-Lun},
  journal={arXiv preprint arXiv:2009.01974},
  year={2020}
}

@article{zhu2021data,
  title={Data-Free Knowledge Distillation for Heterogeneous Federated Learning},
  author={Zhu, Zhuangdi and Hong, Junyuan and Zhou, Jiayu},
  journal={arXiv preprint arXiv:2105.10056},
  year={2021}
}
@article{yurochkin2018scalable,
  title={Scalable inference of topic evolution via models for latent geometric structures},
  author={Yurochkin, Mikhail and Fan, Zhiwei and Guha, Aritra and Koutris, Paraschos and Nguyen, XuanLong},
  journal={arXiv preprint arXiv:1809.08738},
  year={2018}
}

@article{yurochkin2019statistical,
  title={Statistical model aggregation via parameter matching},
  author={Yurochkin, Mikhail and Agarwal, Mayank and Ghosh, Soumya and Greenewald, Kristjan and Hoang, Nghia},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={10956--10966},
  year={2019}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@inproceedings{bucilua2006model,
  title={Model compression},
  author={Bucilu«é, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
  booktitle={Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={535--541},
  year={2006}
}

@article{schmidhuber1992learning,
  title={Learning complex, extended sequences using the principle of history compression},
  author={Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={4},
  number={2},
  pages={234--242},
  year={1992},
  publisher={MIT Press}
}

@inproceedings{choromanska2019beyond,
  title={Beyond backprop: Online alternating minimization with auxiliary variables},
  author={Choromanska, Anna and Cowen, Benjamin and Kumaravel, Sadhana and Luss, Ronny and Rigotti, Mattia and Rish, Irina and Diachille, Paolo and Gurev, Viatcheslav and Kingsbury, Brian and Tejwani, Ravi and others},
  booktitle={International Conference on Machine Learning},
  pages={1193--1202},
  year={2019},
  organization={PMLR}
}


@inproceedings{zeng2019global,
  title={Global convergence of block coordinate descent in deep learning},
  author={Zeng, Jinshan and Lau, Tim Tsz-Kit and Lin, Shaobo and Yao, Yuan},
  booktitle={International Conference on Machine Learning},
  pages={7313--7323},
  year={2019},
  organization={PMLR}
}


@inproceedings{zhang2017convergence,
  title={On the convergence of block coordinate descent in training DNNs with {T}ikhonov regularization},
  author={Zhang, Ziming and Brand, Matthew},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1719--1728},
  year={2017}
}

@article{yang2019federated,
  title={Federated machine learning: Concept and applications},
  author={Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={10},
  number={2},
  pages={1--19},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}


@article{li2020federated,
  title={Federated learning: Challenges, methods, and future directions},
  author={Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
  journal={IEEE Signal Processing Magazine},
  volume={37},
  number={3},
  pages={50--60},
  year={2020},
  publisher={IEEE}
}


@article{zhang2021understanding,
  title={Understanding deep learning (still) requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={Communications of the ACM},
  volume={64},
  number={3},
  pages={107--115},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{zhou2021over,
  title={Why over-parameterization of deep neural networks does not overfit?},
  author={Zhou, Zhi-Hua},
  journal={Science China Information Sciences},
  volume={64},
  number={1},
  pages={1--3},
  year={2021},
  publisher={Science China Press}
}


@article{blalock2020state,
  title={What is the state of neural network pruning?},
  author={Blalock, Davis and Ortiz, Jose Javier Gonzalez and Frankle, Jonathan and Guttag, John},
  journal={arXiv preprint arXiv:2003.03033},
  year={2020}
}

@article{cheng2017survey,
  title={A survey of model compression and acceleration for deep neural networks},
  author={Cheng, Yu and Wang, Duo and Zhou, Pan and Zhang, Tao},
  journal={arXiv preprint arXiv:1710.09282},
  year={2017}
}

@article{du2020medical,
  title={Medical image segmentation based on {U}-net: A review},
  author={Du, Getao and Cao, Xu and Liang, Jimin and Chen, Xueli and Zhan, Yonghua},
  journal={Journal of Imaging Science and Technology},
  volume={64},
  number={2},
  pages={20508--1},
  year={2020},
  publisher={Society for Imaging Science and Technology}
}

@incollection{bottou2010large,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{hinton2012neural,
  title={Neural networks for machine learning lecture 6a overview of mini-batch gradient descent},
  author={Hinton, Geoffrey and Srivastava, Nitish and Swersky, Kevin},
  journal={Cited on},
  volume={14},
  number={8},
  pages={2},
  year={2012}
}

@article{duchi2007derivations,
  title={Derivations for linear algebra and optimization},
  author={Duchi, John},
  journal={Berkeley, California},
  volume={3},
  number={1},
  pages={2325--5870},
  year={2007}
}