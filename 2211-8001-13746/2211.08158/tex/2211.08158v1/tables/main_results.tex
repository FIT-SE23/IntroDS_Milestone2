\begin{table}[tp!]
\centering
\scalebox{0.6}{
\begin{tabular}{lccc}
\toprule
                                   &\textbf{Extra}     & \textbf{CoNLL-14-\textit{test}}     & \textbf{BEA-19-\textit{test}}     \\
                                 \textbf{Model}& \textbf{Data Size}  & \textbf{P/R/$\mbox{\textbf{F}}_{0.5}$}    & \textbf{P/R/$\mbox{\textbf{F}}_{0.5}$} \\ \hline
                                  \multicolumn{4}{c}{\textbf{w/o PLM}} \\ \hline
                                  \multicolumn{4}{l}{\textbf{w/o syntax}}     \\
                                   \citet{kiyono2019empirical} &   70M         & 67.9/44.1/61.3          & 65.5/59.4/64.2          \\
                                  \citet{lichtarge-etal-2020-data}&   340M        & 69.4/43.9/62.1          & 67.6/62.5/66.5          \\
                                  \citet{stahlberg2021synthetic}&   540M     & 72.8/49.5/\textbf{66.6}          & 72.1/64.4/\textbf{70.4}        \\
                                  \textbf{Our Baseline} &   2.4M &  66.9/40.3/59.1   & 66.8/55.5/64.2         \\
                                  \hdashline 
                                  \multicolumn{4}{l}{\textbf{w/ syntax}} \\ 
                                   \citet{wan2021syntax} &   10M       & 74.4/39.5/63.2          & 74.5/48.6/67.3          \\
                                 \citet{li2022syntax} &   30M      & 66.7/38.3/58.1          & -/-/-          \\
                                  \textbf{DSynGEC} \cite{zhang2022syngec} &   2.4M  & 70.0/46.2/\textbf{63.5}          & 70.9/59.9/\textbf{68.4}          \\
                                    \textbf{CSynGEC} (this work) &   2.4M  & 69.7/46.3/63.3          & 69.4/60.3/67.4 
                                  \\\hline \hline
                                     \multicolumn{4}{c}{\textbf{w/ PLM}} \\ \hline 
                                     \citet{DBLP:conf/acl/SunGWW20}&   300M          & 71.0/52.8/66.4       & 74.7/66.4/72.9          \\
                                      \citet{rothe2021recipe}$^{*}$ &   2.4M         & -/-/\textbf{68.8}          & -/-/\textbf{75.9}          \\  \textbf{Our Baseline} &   2.4M &  73.6/48.6/66.7   & 74.0/64.9/72.0         \\
                                       \textbf{DSynGEC} \cite{zhang2022syngec} &   2.4M  & 74.7/49.0/67.6          & 75.1/65.5/72.9          \\
                                       \textbf{CSynGEC} (this work) &   2.4M  & 74.0/50.7/67.7         & 74.4/66.1/72.6          \\
                                      
                                
\bottomrule
\end{tabular}
}
\caption{\textbf{Single-model} results. ``\textbf{w/ syntax}'' means using syntactic knowledge. ``\textbf{w/ PLM}'' means using pre-trained language models. $^{*}$ denotes current SOTA.}

\label{tab:main:results}
\end{table}