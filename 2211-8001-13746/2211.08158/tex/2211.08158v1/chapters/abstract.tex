\begin{abstract}
Recently, \citet{zhang2022syngec} propose a syntax-aware grammatical error correction (GEC) approach, named SynGEC, showing that incorporating tailored dependency-based syntax of the input sentence is quite beneficial to GEC. 
This work considers 
another mainstream syntax formalism, i.e.,  constituent-based syntax.
\textcolor{black}{
By drawing on the successful experience of SynGEC, 
we first propose an extended constituent-based syntax scheme to accommodate errors in ungrammatical sentences.
Then, we automatically obtain constituency trees of ungrammatical sentences to train a GEC-oriented constituency parser by using parallel GEC data as a pivot.
For syntax encoding, we employ the graph convolutional network (GCN).
}
Experimental results show that our method, named CSynGEC, yields substantial improvements over strong baselines. 
Moreover, we investigate the integration of constituent-based and dependency-based syntax for GEC in two ways: 
\textcolor{black}{
1) intra-model combination, which means using separate GCNs to encode both kinds of syntax for decoding in a single model; 2)inter-model combination, which means gathering and selecting edits predicted by different models to achieve final corrections. 
We find that the former method improves recall over using one standalone syntax formalism while the latter improves precision, and both lead to better F${_{0.5}}$ values. \blfootnote{$^*$ Corresponding author.}
}

\end{abstract}