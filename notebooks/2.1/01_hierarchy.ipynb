{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c961a512-b86b-4c15-b330-ac27d4724431",
   "metadata": {},
   "source": [
    "### 0. Import libraries and implement functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af9fddae-53b6-47c1-afd0-334fd7327c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylatexenc.latexwalker import LatexWalker, LatexEnvironmentNode, LatexCharsNode, LatexCommentNode,\\\n",
    "                                    LatexGroupNode, LatexMathNode, LatexMacroNode, LatexSpecialsNode\n",
    "import sys, re, os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0141011f-5f72-4c24-bfba-c62469f61772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tex_files(dir, max_depth):\n",
    "    if max_depth == 0 or not os.path.isdir(dir):\n",
    "        return []\n",
    "\n",
    "    fs = os.listdir(dir)\n",
    "\n",
    "    if dir != \".\":\n",
    "        fs = [dir + \"/\" + f for f in fs]\n",
    "\n",
    "    sub = [f for f in fs if os.path.isdir(f)]\n",
    "    fs = [f for f in fs if os.path.isfile(f) and f.endswith(\".tex\")]\n",
    "\n",
    "    for d in sub:\n",
    "        fs.extend(find_tex_files(d, max_depth - 1))\n",
    "    return fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03ce43a3-471c-4036-90f9-4242c9edacce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_begin_document(files):\n",
    "    for file in files:\n",
    "        with open(file, \"r\") as f:\n",
    "            text = f.read()\n",
    "            if r\"\\begin{document}\" in text:\n",
    "                return file\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5449c50-5e32-42f1-8831-e330dce3c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latex_nodes(fp):\n",
    "    with open(fp, \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    newcommand_pattern = r\"^\\\\newcommand\\{([^}]+)\\}(?:\\[[^]]+\\])?\\{(.+)\\}$\"\n",
    "    newcommands = re.findall(newcommand_pattern, text, flags=re.M)\n",
    "    # print(newcommands)\n",
    "    for (short_hand, cmd) in newcommands:\n",
    "        short_hand = short_hand.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "        cmd = cmd.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "        text = re.sub(short_hand, cmd, text)\n",
    "\n",
    "    text = re.sub(newcommand_pattern, \"\", text)\n",
    "\n",
    "    bibitem_pattern = r\"^\\\\bibitem{([^}]+)}\\s+(.+)$\"\n",
    "    text = re.sub(bibitem_pattern, \"\", text)\n",
    "\n",
    "    cmds_to_remove = r\"\\\\(centering|newpage|clearpage|tableofcontents|maketitle|hrule|vfill)\"\n",
    "    text = re.sub(cmds_to_remove, \"\", text)\n",
    "    text = re.sub(r\"\\\\[hv]space\\{.*?\\}\", \"\", text)\n",
    "    # text = re.sub(r\"\\s+:\", \" \", text).strip()\n",
    "    \n",
    "    w = LatexWalker(text)\n",
    "    nodes, _, _ = w.get_latex_nodes()\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6725286-7dd3-4e8a-b1e7-e4f628db6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_PATTERN = re.compile(r\"(?<!\\b[A-Z])(?<![Ee][Tt] [Aa][Ll])\\.\\s+(?=[A-Z])\")\n",
    "\n",
    "def split_sentences(text, level):\n",
    "    sentences = SENTENCE_PATTERN.split(text)\n",
    "    sentences = [(sentence.strip(), level) for sentence in sentences]\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11883365-066b-4143-b992-a1910971761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEVELS = {\n",
    "    \"document\": 0,\n",
    "    \"abstract\": 1,\n",
    "    \"section\": 1,\n",
    "    \"subsection\": 2,\n",
    "    \"subsubsection\": 3,\n",
    "    \"paragraph\": 4,\n",
    "    \"subparagraph\": 5,\n",
    "    \"itemize\": 6,\n",
    "    \"item\": 7,\n",
    "    \"leaf\": 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c8a3170-a61f-4310-94c4-e5aeba572524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchy_nodes(nodes, working_dir, append_trailing=False):\n",
    "    text = \"\"\n",
    "    tokens = []\n",
    "    for node in nodes:\n",
    "        if node == None or isinstance(node, LatexCommentNode):\n",
    "            continue\n",
    "\n",
    "        if isinstance(node, LatexCharsNode):\n",
    "            chars = node.chars\n",
    "            text += chars\n",
    "        elif isinstance(node, LatexMathNode):\n",
    "            text += node.latex_verbatim()\n",
    "        elif isinstance(node, LatexGroupNode):\n",
    "            text += node.latex_verbatim()\n",
    "            # tokens.extend(node.nodelist)\n",
    "        elif isinstance(node, LatexEnvironmentNode):\n",
    "            env_name = node.environmentname.lower()\n",
    "            if env_name in [\"figure\", \"figure*\", \"equation\", \"equation*\", \"align\", \"align*\", \"table\", \"remark\", \"remark*\"]:\n",
    "                tokens.extend(split_sentences(text, LEVELS[\"leaf\"]))\n",
    "                tokens.append((node.latex_verbatim(), LEVELS[\"leaf\"]))\n",
    "                text = \"\"\n",
    "            elif env_name == \"itemize\":\n",
    "                tokens.extend(split_sentences(text, LEVELS[\"leaf\"]))\n",
    "                tokens.append((env_name, LEVELS[env_name]))\n",
    "                latex = node.latex_verbatim()\n",
    "                # pattern = r\"\\\\(begin|end)\\{\" + env_name + r\"\\}\" + r\"(\\[[^]]+\\])?\"\n",
    "                pattern = r\"\\\\(begin|end)\\{itemize\\}(\\[[^]]+\\])?\"\n",
    "                latex = re.sub(pattern, \"\", latex, flags=re.IGNORECASE).strip()\n",
    "\n",
    "                items = re.split(r\"\\\\item\", latex, flags=re.IGNORECASE)\n",
    "                for item in items:\n",
    "                    item = item.strip()\n",
    "                    if len(item) == 0:\n",
    "                        continue\n",
    "\n",
    "                    tokens.append((\"item\", LEVELS[\"item\"]))\n",
    "                    tokens.extend(split_sentences(item, LEVELS[\"leaf\"]))\n",
    "\n",
    "            elif env_name in \"document\":\n",
    "                tokens.append((env_name, LEVELS[env_name]))\n",
    "                sub_tokens = hierarchy_nodes(node.nodelist, working_dir, True)\n",
    "                tokens.extend(sub_tokens)\n",
    "            elif env_name in \"abstract\":\n",
    "                tokens.append((env_name, LEVELS[env_name]))\n",
    "                latex = node.latex_verbatim()\n",
    "                latex = re.sub(r\"\\\\(begin|end)\\{abstract\\}\", \"\", latex, flags=re.IGNORECASE).strip()\n",
    "                tokens.extend(split_sentences(latex, LEVELS[\"leaf\"]))\n",
    "            else:\n",
    "                # print(env_name, \"[Environment]\")\n",
    "                sub_tokens = hierarchy_nodes(node.nodelist, working_dir, True)\n",
    "                tokens.extend(sub_tokens)\n",
    "        elif isinstance(node, LatexMacroNode):\n",
    "            if node.macroname in [\"input\", \"include\"]:\n",
    "                if node.nodeargd and node.nodeargd.argnlist:\n",
    "                    arg_node = node.nodeargd.argnlist[0]\n",
    "                    fname = \"\"\n",
    "                    if hasattr(arg_node, 'nodelist') and arg_node.nodelist:\n",
    "                         if isinstance(arg_node.nodelist[0], LatexCharsNode):\n",
    "                             fname = arg_node.nodelist[0].chars\n",
    "                    elif isinstance(arg_node, LatexCharsNode):\n",
    "                        fname = arg_node.chars\n",
    "                        \n",
    "                    if fname:\n",
    "                        if not fname.endswith('.tex'): fname += '.tex'\n",
    "                        \n",
    "                        full_path = os.path.join(working_dir, fname)\n",
    "                        if os.path.exists(full_path):\n",
    "                            print(f\"    -> Parsing input: {fname}\")\n",
    "                            try:\n",
    "                                sub_tokens = get_latex_nodes(full_path)\n",
    "                                tokens.extend(hierarchy_nodes(sub_tokens, working_dir, True))\n",
    "                            except Exception as e:\n",
    "                                print(f\"    [Error] Failed to parse input {fname}: {e}\")\n",
    "            elif node.macroname in [\"section\", \"subsection\", \"subsubsection\", \"paragraph\", \"subparagraph\"]:\n",
    "                tokens.extend(split_sentences(text, LEVELS[\"leaf\"]))\n",
    "                latex = node.latex_verbatim()\n",
    "                latex = re.sub(r\"\\\\\" + node.macroname + r\"\\{\", \"\", latex, flags=re.IGNORECASE).strip()\n",
    "                tokens.append((latex[:-1], LEVELS[node.macroname]))\n",
    "                text = \"\"\n",
    "            elif node.macroname in [\"label\", \"footnote\"]:\n",
    "                latex = node.latex_verbatim()\n",
    "                pattern = fr\"\\\\{node.macroname}\" + \"{[^}]+}\"\n",
    "                latex = re.sub(pattern, \"\", latex)\n",
    "                text += latex\n",
    "            elif node.macroname in [\"cite\", \"citep\", \"citet\"]:\n",
    "                pass\n",
    "            else:\n",
    "                text += node.latex_verbatim()\n",
    "        elif isinstance(node, LatexSpecialsNode):\n",
    "            text += node.specials_chars\n",
    "\n",
    "    if append_trailing and text != \"\":\n",
    "        tokens.extend(split_sentences(text, LEVELS[\"leaf\"]))\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0db536c8-548f-48dc-b858-a3c6e655cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node(root, stack, elements):\n",
    "    key = elements[stack[0]][0]\n",
    "    if len(stack) == 1:\n",
    "        root[key] = {}\n",
    "    else:\n",
    "        if key in root:\n",
    "            add_node(root[key], stack[1:], elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aca8668e-9707-4132-86dc-6ed4171c60dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_version_elements(version_directory):\n",
    "    main_tex_fp = os.path.join(version_directory, \"main.tex\")\n",
    "\n",
    "    if not os.path.exists(main_tex_fp):\n",
    "        depth1_tex_files = find_tex_files(version_directory, 1)\n",
    "        main_tex_fp = find_begin_document(depth1_tex_files)\n",
    "        if main_tex_fp == None:\n",
    "            print(\"Not found main tex file\")\n",
    "            return None\n",
    "\n",
    "    nodes = get_latex_nodes(main_tex_fp)\n",
    "    nodes = hierarchy_nodes(nodes, version_directory)\n",
    "    nodes = [node for node in nodes if len(node[0]) > 0]\n",
    "\n",
    "    ignore_idx = 0\n",
    "    while ignore_idx < len(nodes) and nodes[ignore_idx] != (\"document\", 0):\n",
    "        ignore_idx += 1\n",
    "    elements = nodes[ignore_idx:]\n",
    "\n",
    "    return elements\n",
    "\n",
    "def hierarchy_elements(elements):\n",
    "    root = {}\n",
    "    node_stack = []\n",
    "    \n",
    "    for i in range(len(elements)):\n",
    "        if len(node_stack) > 0:\n",
    "            last_node_level = elements[node_stack[-1]][1]\n",
    "        else:\n",
    "            last_node_level = 0\n",
    "\n",
    "        current_node_level = elements[i][1]\n",
    "\n",
    "        if current_node_level > last_node_level:\n",
    "            node_stack.append(i)\n",
    "        elif current_node_level == last_node_level:\n",
    "            if len(node_stack) > 0:\n",
    "                node_stack[-1] = i\n",
    "            else:\n",
    "                node_stack.append(i)\n",
    "        else:\n",
    "            while len(node_stack) > 0 and current_node_level <= elements[node_stack[-1]][1]:\n",
    "                node_stack.pop()\n",
    "\n",
    "            node_stack.append(i)\n",
    "        add_node(root, node_stack, elements)\n",
    "\n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c4818-3d77-46d8-bd95-8526a5cf1dd8",
   "metadata": {},
   "source": [
    "### 1. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d9d0bbc-218e-46ae-83e3-f6bce71e97c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_id(root, new_root, prefix, ids):\n",
    "    for key, value in root.items():\n",
    "        # print(key)\n",
    "        new_key = prefix + str(ids[key])\n",
    "        if value != {}:\n",
    "            new_root[new_key] = {}\n",
    "            replace_with_id(value, new_root[new_key], prefix, ids)\n",
    "        else:\n",
    "            new_root[new_key] = value\n",
    "\n",
    "def flatten_tree(root):\n",
    "    parents = {}\n",
    "\n",
    "    def flatten_tree_recurse(node, parent):\n",
    "        if isinstance(node, dict):\n",
    "            for key, child in node.items():\n",
    "                if parent != None:\n",
    "                    parents[key] = parent\n",
    "                flatten_tree_recurse(child, key)\n",
    "\n",
    "    flatten_tree_recurse(root, None)\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f86e2c17-b992-463d-82df-dd4f3056af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2210.16298...\n",
      "../../../23127247_milestone1/2210.16298/tex/2210.16298v1\n",
      "    -> Parsing input: sections/intro.tex\n",
      "    -> Parsing input: sections/methodology.tex\n",
      "    -> Parsing input: sections/exp.tex\n",
      "    -> Parsing input: sections/related_work.tex\n",
      "    -> Parsing input: sections/discussion.tex\n",
      "    -> Parsing input: sections/app.tex\n",
      "../../../23127247_milestone1/2210.16298/tex/2210.16298v2\n",
      "Saving data...\n",
      "Processing 2210.16299...\n",
      "../../../23127247_milestone1/2210.16299/tex/2210.16299v1\n",
      "../../../23127247_milestone1/2210.16299/tex/2210.16299v2\n",
      "../../../23127247_milestone1/2210.16299/tex/2210.16299v3\n",
      "../../../23127247_milestone1/2210.16299/tex/2210.16299v4\n",
      "../../../23127247_milestone1/2210.16299/tex/2210.16299v5\n",
      "Saving data...\n",
      "Processing 2210.16300...\n",
      "../../../23127247_milestone1/2210.16300/tex/2210.16300v1\n",
      "../../../23127247_milestone1/2210.16300/tex/2210.16300v2\n",
      "../../../23127247_milestone1/2210.16300/tex/2210.16300v3\n",
      "Saving data...\n",
      "Processing 2210.16301...\n",
      "../../../23127247_milestone1/2210.16301/tex/2210.16301v1\n",
      "../../../23127247_milestone1/2210.16301/tex/2210.16301v2\n",
      "../../../23127247_milestone1/2210.16301/tex/2210.16301v3\n",
      "../../../23127247_milestone1/2210.16301/tex/2210.16301v4\n",
      "../../../23127247_milestone1/2210.16301/tex/2210.16301v5\n",
      "Saving data...\n",
      "Processing 2210.16302...\n",
      "../../../23127247_milestone1/2210.16302/tex/2210.16302v1\n",
      "../../../23127247_milestone1/2210.16302/tex/2210.16302v2\n",
      "../../../23127247_milestone1/2210.16302/tex/2210.16302v3\n",
      "Saving data...\n"
     ]
    }
   ],
   "source": [
    "# nodes, node_hierarchy, refs = hierarchy_version(\"../../23127247_milestone1/2210.16424/tex/2210.16424v1/\")\n",
    "raw_prefix_dir = os.path.join(\"..\", \"..\", \"..\", \"23127247_milestone1\")\n",
    "parsed_prefix_dir = os.path.join(\".\")\n",
    "\n",
    "paper_ids = [d for d in os.listdir(raw_prefix_dir) if os.path.isdir(os.path.join(raw_prefix_dir, d))]\n",
    "paper_ids.sort()\n",
    "\n",
    "for paper_id in paper_ids[:5]:\n",
    "    print(f\"Processing {paper_id}...\")\n",
    "    version = 1\n",
    "    \n",
    "    all_version_elements = []\n",
    "    paper_elements = set()\n",
    "    while True:\n",
    "        version_dir = os.path.join(raw_prefix_dir, paper_id, \"tex\", paper_id + \"v\" + str(version))\n",
    "        print(version_dir)\n",
    "        if not os.path.exists(version_dir):\n",
    "            break\n",
    "        version_elements = find_version_elements(version_dir)\n",
    "        all_version_elements.append(version_elements)\n",
    "        set_version_elements = [ele[0] for ele in version_elements]\n",
    "        paper_elements |= set(set_version_elements)\n",
    "        version += 1\n",
    "    \n",
    "    paper_elements = list(paper_elements)\n",
    "    paper_elements_dict = {paper_elements[i]: i for i in range(len(paper_elements))}\n",
    "    # print(json.dumps(paper_elements_dict, indent=4))\n",
    "    \n",
    "    hierarchy = {}\n",
    "    for i in range(len(all_version_elements)):\n",
    "        version_elements = all_version_elements[i]\n",
    "        root = hierarchy_elements(version_elements)\n",
    "        new_root = {}\n",
    "        replace_with_id(root, new_root, paper_id + \"_\", paper_elements_dict)\n",
    "        new_root = flatten_tree(new_root)\n",
    "        hierarchy[str(i + 1)] = new_root\n",
    "    \n",
    "    elements = {paper_id + \"_\" + str(value): key for key, value in paper_elements_dict.items()}\n",
    "    \n",
    "    final_form = {\n",
    "        \"elements\": elements,\n",
    "        \"hierarchy\": hierarchy,\n",
    "    }\n",
    "\n",
    "    print(\"Saving data...\")\n",
    "    \n",
    "    # print(json.dumps(final_form, indent=4))\n",
    "    target_dir = os.path.join(parsed_prefix_dir, paper_id)\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    with open(os.path.join(target_dir, \"hierarchy.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(final_form, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e993acc-d3c3-44a9-9417-0982197850bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
